{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification: Cats VS Dogs\n",
    "\n",
    "We downloaded the dataset from kaggle. The training archive contains 25,000 images of dogs and cats. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using own data with included Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mxnet as mx\n",
    "import matplotlib.pyplot as plt\n",
    "from mxnet import gluon\n",
    "from mxnet import nd, autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aug_transform(data, label):\n",
    "    data = data.astype('float32')/255 # normalize the data\n",
    "    size= 224\n",
    "    aug = mx.image.ForceResizeAug((size,size)) # resize the image to 224x224\n",
    "    data = aug(data)\n",
    "    data=data.transpose((2, 0, 1))\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = nd.random_normal(shape=(10,224,224,3))\n",
    "# y = aug_transform(x,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data\"\n",
    "dataset_name = \"CatsVsDogs\"\n",
    "\n",
    "training_path = os.path.join(data_folder, dataset_name)\n",
    "\n",
    "train_dataset = mx.gluon.data.vision.datasets.ImageFolderDataset(training_path,transform=aug_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type: (3, 224, 224)\n",
      "Label: 1\n",
      "Label description: dog\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 17990\n",
    "sample = train_dataset[sample_idx]\n",
    "data = sample[0]\n",
    "label = sample[1]\n",
    "\n",
    "#plt.imshow(data.asnumpy(), cmap='gray')\n",
    "print(\"Data type: {}\".format(data.shape))\n",
    "print(\"Label: {}\".format(label))\n",
    "print(\"Label description: {}\".format(train_dataset.synsets[label]))\n",
    "assert label == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch size and DataLoader for train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_data = gluon.data.DataLoader(train_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The AlexNet architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "alex_net = gluon.nn.Sequential()\n",
    "with alex_net.name_scope():\n",
    "    #  First convolutional layer\n",
    "    alex_net.add(gluon.nn.Conv2D(channels=96, kernel_size=11, strides=(4,4), activation='relu'))\n",
    "    alex_net.add(gluon.nn.MaxPool2D(pool_size=3, strides=2))\n",
    "    #  Second convolutional layer\n",
    "    alex_net.add(gluon.nn.Conv2D(channels=192, kernel_size=5, activation='relu'))\n",
    "    alex_net.add(gluon.nn.MaxPool2D(pool_size=3, strides=(2,2)))\n",
    "    # Third convolutional layer\n",
    "    alex_net.add(gluon.nn.Conv2D(channels=384, kernel_size=3, activation='relu'))\n",
    "    # Fourth convolutional layer\n",
    "    alex_net.add(gluon.nn.Conv2D(channels=384, kernel_size=3, activation='relu'))\n",
    "    # Fifth convolutional layer\n",
    "    alex_net.add(gluon.nn.Conv2D(channels=256, kernel_size=3, activation='relu'))\n",
    "    alex_net.add(gluon.nn.MaxPool2D(pool_size=3, strides=2))\n",
    "    # Flatten and apply fullly connected layers\n",
    "    alex_net.add(gluon.nn.Flatten())\n",
    "    alex_net.add(gluon.nn.Dense(4096, activation=\"relu\"))\n",
    "    alex_net.add(gluon.nn.Dense(4096, activation=\"relu\"))\n",
    "    alex_net.add(gluon.nn.Dense(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mx.gpu()\n",
    "alex_net.collect_params().initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(alex_net.collect_params(), 'sgd', {'learning_rate': .001})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iterator, net):\n",
    "    acc = mx.metric.Accuracy()\n",
    "    for d, l in data_iterator:\n",
    "        data = d.as_in_context(ctx)\n",
    "        label = l.as_in_context(ctx)\n",
    "        output = net(data)\n",
    "        predictions = nd.argmax(output, axis=1)\n",
    "        acc.update(preds=predictions, labels=label)\n",
    "        return acc.get()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss: 2.302673, Train_acc 0.0\n",
      "\n",
      "Epoch 0. Loss: 2.3026653957366943, Train_acc 0.0\n",
      "\n",
      "Epoch 0. Loss: 2.302648757266998, Train_acc 0.0\n",
      "\n",
      "Epoch 0. Loss: 2.3026248727483747, Train_acc 0.0\n",
      "\n",
      "Epoch 0. Loss: 2.3025930612386034, Train_acc 0.0046875\n",
      "\n",
      "Epoch 0. Loss: 2.302552350581662, Train_acc 0.033854166666666664\n",
      "\n",
      "Epoch 0. Loss: 2.3025056907919708, Train_acc 0.07924107142857142\n",
      "\n",
      "Epoch 0. Loss: 2.3024510671192195, Train_acc 0.1279296875\n",
      "\n",
      "Epoch 0. Loss: 2.3023884447613208, Train_acc 0.1675347222222222\n",
      "\n",
      "Epoch 0. Loss: 2.302318523593432, Train_acc 0.2015625\n",
      "\n",
      "Epoch 0. Loss: 2.302241228784133, Train_acc 0.2315340909090909\n",
      "\n",
      "Epoch 0. Loss: 2.302156464792648, Train_acc 0.2571614583333333\n",
      "\n",
      "Epoch 0. Loss: 2.302065300516273, Train_acc 0.2782451923076923\n",
      "\n",
      "Epoch 0. Loss: 2.301966460045443, Train_acc 0.2935267857142857\n",
      "\n",
      "Epoch 0. Loss: 2.301859898548626, Train_acc 0.3104166666666667\n",
      "\n",
      "Epoch 0. Loss: 2.3017458720500175, Train_acc 0.326171875\n",
      "\n",
      "Epoch 0. Loss: 2.301625797496235, Train_acc 0.3382352941176471\n",
      "\n",
      "Epoch 0. Loss: 2.301499732983644, Train_acc 0.3472222222222222\n",
      "\n",
      "Epoch 0. Loss: 2.3013680507401726, Train_acc 0.3540296052631579\n",
      "\n",
      "Epoch 0. Loss: 2.3012291427814464, Train_acc 0.35859375\n",
      "\n",
      "Epoch 0. Loss: 2.301082888245569, Train_acc 0.3664434523809524\n",
      "\n",
      "Epoch 0. Loss: 2.3009312083423006, Train_acc 0.3700284090909091\n",
      "\n",
      "Epoch 0. Loss: 2.3007728627124298, Train_acc 0.37533967391304346\n",
      "\n",
      "Epoch 0. Loss: 2.3006062347780545, Train_acc 0.3837890625\n",
      "\n",
      "Epoch 0. Loss: 2.300435937315223, Train_acc 0.386875\n",
      "\n",
      "Epoch 0. Loss: 2.3002572577211233, Train_acc 0.39302884615384615\n",
      "\n",
      "Epoch 0. Loss: 2.3000724255842804, Train_acc 0.39814814814814814\n",
      "\n",
      "Epoch 0. Loss: 2.2998828256532358, Train_acc 0.40150669642857145\n",
      "\n",
      "Epoch 0. Loss: 2.2996855110685783, Train_acc 0.40651939655172414\n",
      "\n",
      "Epoch 0. Loss: 2.299483775243476, Train_acc 0.41015625\n",
      "\n",
      "Epoch 0. Loss: 2.2992747536836684, Train_acc 0.41481854838709675\n",
      "\n",
      "Epoch 0. Loss: 2.299061370732708, Train_acc 0.417724609375\n",
      "\n",
      "Epoch 0. Loss: 2.298845038527151, Train_acc 0.41761363636363635\n",
      "\n",
      "Epoch 0. Loss: 2.2986176994013396, Train_acc 0.4216452205882353\n",
      "\n",
      "Epoch 0. Loss: 2.2983860580823747, Train_acc 0.42544642857142856\n",
      "\n",
      "Epoch 0. Loss: 2.298149976394068, Train_acc 0.4266493055555556\n",
      "\n",
      "Epoch 0. Loss: 2.2979109721669313, Train_acc 0.42694256756756754\n",
      "\n",
      "Epoch 0. Loss: 2.2976643444017437, Train_acc 0.42886513157894735\n",
      "\n",
      "Epoch 0. Loss: 2.2974136287874685, Train_acc 0.430088141025641\n",
      "\n",
      "Epoch 0. Loss: 2.2971573951599633, Train_acc 0.4310546875\n",
      "\n",
      "Epoch 0. Loss: 2.296897112521535, Train_acc 0.43159298780487804\n",
      "\n",
      "Epoch 0. Loss: 2.2966305778434633, Train_acc 0.4330357142857143\n",
      "\n",
      "Epoch 0. Loss: 2.2963575198601336, Train_acc 0.43586482558139533\n",
      "\n",
      "Epoch 0. Loss: 2.296078478257571, Train_acc 0.43803267045454547\n",
      "\n",
      "Epoch 0. Loss: 2.295794654896962, Train_acc 0.4401041666666667\n",
      "\n",
      "Epoch 0. Loss: 2.2955083220412296, Train_acc 0.44106657608695654\n",
      "\n",
      "Epoch 0. Loss: 2.2952172898767254, Train_acc 0.44148936170212766\n",
      "\n",
      "Epoch 0. Loss: 2.29491947393444, Train_acc 0.443359375\n",
      "\n",
      "Epoch 0. Loss: 2.2946195769093287, Train_acc 0.44371811224489793\n",
      "\n",
      "Epoch 0. Loss: 2.2943118975663217, Train_acc 0.44546875\n",
      "\n",
      "Epoch 0. Loss: 2.293999737147787, Train_acc 0.44684436274509803\n",
      "\n",
      "Epoch 0. Loss: 2.293682475276645, Train_acc 0.44876802884615385\n",
      "\n",
      "Epoch 0. Loss: 2.2933622419774307, Train_acc 0.4498820754716981\n",
      "\n",
      "Epoch 0. Loss: 2.293036270314492, Train_acc 0.4515335648148148\n",
      "\n",
      "Epoch 0. Loss: 2.2927058169169197, Train_acc 0.45298295454545456\n",
      "\n",
      "Epoch 0. Loss: 2.2923717253042994, Train_acc 0.4546595982142857\n",
      "\n",
      "Epoch 0. Loss: 2.292032670488695, Train_acc 0.45586622807017546\n",
      "\n",
      "Epoch 0. Loss: 2.2916895532564645, Train_acc 0.45716594827586204\n",
      "\n",
      "Epoch 0. Loss: 2.291346004815575, Train_acc 0.4568326271186441\n",
      "\n",
      "Epoch 0. Loss: 2.2909961643810663, Train_acc 0.4576822916666667\n",
      "\n",
      "Epoch 0. Loss: 2.2906402665342527, Train_acc 0.45914446721311475\n",
      "\n",
      "Epoch 0. Loss: 2.29028198389073, Train_acc 0.4596774193548387\n",
      "\n",
      "Epoch 0. Loss: 2.2899186175582926, Train_acc 0.4603174603174603\n",
      "\n",
      "Epoch 0. Loss: 2.2895554087462964, Train_acc 0.4599609375\n",
      "\n",
      "Epoch 0. Loss: 2.2891864192569167, Train_acc 0.4606971153846154\n",
      "\n",
      "Epoch 0. Loss: 2.288816534873155, Train_acc 0.4601089015151515\n",
      "\n",
      "Epoch 0. Loss: 2.288438595297281, Train_acc 0.4609375\n",
      "\n",
      "Epoch 0. Loss: 2.2880538946317834, Train_acc 0.4622012867647059\n",
      "\n",
      "Epoch 0. Loss: 2.2876634183990885, Train_acc 0.46433423913043476\n",
      "\n",
      "Epoch 0. Loss: 2.2872730179263403, Train_acc 0.46495535714285713\n",
      "\n",
      "Epoch 0. Loss: 2.2868789683577337, Train_acc 0.4659991197183099\n",
      "\n",
      "Epoch 0. Loss: 2.2864818259367294, Train_acc 0.4665798611111111\n",
      "\n",
      "Epoch 0. Loss: 2.2860798119948367, Train_acc 0.4673587328767123\n",
      "\n",
      "Epoch 0. Loss: 2.2856754762581586, Train_acc 0.4680109797297297\n",
      "\n",
      "Epoch 0. Loss: 2.2852654778584918, Train_acc 0.4690625\n",
      "\n",
      "Epoch 0. Loss: 2.2848491462458003, Train_acc 0.4702919407894737\n",
      "\n",
      "Epoch 0. Loss: 2.284430426206682, Train_acc 0.4718952922077922\n",
      "\n",
      "Epoch 0. Loss: 2.2840159362832995, Train_acc 0.4713541666666667\n",
      "\n",
      "Epoch 0. Loss: 2.283589183292537, Train_acc 0.4730023734177215\n",
      "\n",
      "Epoch 0. Loss: 2.2831658824401413, Train_acc 0.473046875\n",
      "\n",
      "Epoch 0. Loss: 2.2827454246159538, Train_acc 0.47270447530864196\n",
      "\n",
      "Epoch 0. Loss: 2.282314120005109, Train_acc 0.4730373475609756\n",
      "\n",
      "Epoch 0. Loss: 2.281882667628758, Train_acc 0.4729856927710843\n",
      "\n",
      "Epoch 0. Loss: 2.2814384160905625, Train_acc 0.47451636904761907\n",
      "\n",
      "Epoch 0. Loss: 2.2809980277106017, Train_acc 0.4748161764705882\n",
      "\n",
      "Epoch 0. Loss: 2.280555760884881, Train_acc 0.47519985465116277\n",
      "\n",
      "Epoch 0. Loss: 2.2801161214355172, Train_acc 0.47467672413793105\n",
      "\n",
      "Epoch 0. Loss: 2.279666654328218, Train_acc 0.4753196022727273\n",
      "\n",
      "Epoch 0. Loss: 2.279209136306359, Train_acc 0.476123595505618\n",
      "\n",
      "Epoch 0. Loss: 2.2787588971314054, Train_acc 0.4756944444444444\n",
      "\n",
      "Epoch 0. Loss: 2.278296487736965, Train_acc 0.4766483516483517\n",
      "\n",
      "Epoch 0. Loss: 2.2778346326313237, Train_acc 0.4769870923913043\n",
      "\n",
      "Epoch 0. Loss: 2.277371278255999, Train_acc 0.4772345430107527\n",
      "\n",
      "Epoch 0. Loss: 2.2769093673838396, Train_acc 0.4769780585106383\n",
      "\n",
      "Epoch 0. Loss: 2.2764435211617835, Train_acc 0.4767269736842105\n",
      "\n",
      "Epoch 0. Loss: 2.2759688508313, Train_acc 0.4773763020833333\n",
      "\n",
      "Epoch 0. Loss: 2.2754945832176094, Train_acc 0.47760953608247425\n",
      "\n",
      "Epoch 0. Loss: 2.275020680914944, Train_acc 0.4772799744897959\n",
      "\n",
      "Epoch 0. Loss: 2.2745378324088645, Train_acc 0.4777462121212121\n",
      "\n",
      "Epoch 0. Loss: 2.2740582912773113, Train_acc 0.4775\n",
      "\n",
      "[Epoch 0 Batch 100] Loss: 2.273571555486731 Training: accuracy=0.477877\n",
      "Epoch 0. Loss: 2.273571555486731, Train_acc 0.4778774752475248\n",
      "\n",
      "Epoch 0. Loss: 2.2730828444408355, Train_acc 0.47809436274509803\n",
      "\n",
      "Epoch 0. Loss: 2.272586865926237, Train_acc 0.4787621359223301\n",
      "\n",
      "Epoch 0. Loss: 2.2720962668134836, Train_acc 0.47866586538461536\n",
      "\n",
      "Epoch 0. Loss: 2.2716023577876214, Train_acc 0.4783482142857143\n",
      "\n",
      "Epoch 0. Loss: 2.271099344997709, Train_acc 0.4789946933962264\n",
      "\n",
      "Epoch 0. Loss: 2.270597175705447, Train_acc 0.4791910046728972\n",
      "\n",
      "Epoch 0. Loss: 2.2700965710367105, Train_acc 0.47902199074074076\n",
      "\n",
      "Epoch 0. Loss: 2.269590558291126, Train_acc 0.479286123853211\n",
      "\n",
      "Epoch 0. Loss: 2.2690818618375483, Train_acc 0.47933238636363634\n",
      "\n",
      "Epoch 0. Loss: 2.268573953661525, Train_acc 0.47923704954954954\n",
      "\n",
      "Epoch 0. Loss: 2.268058018697969, Train_acc 0.47970145089285715\n",
      "\n",
      "Epoch 0. Loss: 2.267545783962344, Train_acc 0.4794662610619469\n",
      "\n",
      "Epoch 0. Loss: 2.267029344639261, Train_acc 0.47937225877192985\n",
      "\n",
      "Epoch 0. Loss: 2.2665076150547154, Train_acc 0.4796195652173913\n",
      "\n",
      "Epoch 0. Loss: 2.2659898439159174, Train_acc 0.4794585129310345\n",
      "\n",
      "Epoch 0. Loss: 2.265459438236463, Train_acc 0.4798344017094017\n",
      "\n",
      "Epoch 0. Loss: 2.264924728345065, Train_acc 0.4806673728813559\n",
      "\n",
      "Epoch 0. Loss: 2.264394726590789, Train_acc 0.4808298319327731\n",
      "\n",
      "Epoch 0. Loss: 2.263860747987143, Train_acc 0.48118489583333335\n",
      "\n",
      "Epoch 0. Loss: 2.263329009728005, Train_acc 0.48114669421487605\n",
      "\n",
      "Epoch 0. Loss: 2.2627934025836063, Train_acc 0.4813652663934426\n",
      "\n",
      "Epoch 0. Loss: 2.2622593225082706, Train_acc 0.4813262195121951\n",
      "\n",
      "Epoch 0. Loss: 2.261719730419968, Train_acc 0.4812878024193548\n",
      "\n",
      "Epoch 0. Loss: 2.261182377590561, Train_acc 0.481\n",
      "\n",
      "Epoch 0. Loss: 2.260637263809925, Train_acc 0.48127480158730157\n",
      "\n",
      "Epoch 0. Loss: 2.2600867769636044, Train_acc 0.4818528543307087\n",
      "\n",
      "Epoch 0. Loss: 2.2595379683675523, Train_acc 0.4818115234375\n",
      "\n",
      "Epoch 0. Loss: 2.258990332481179, Train_acc 0.4818919573643411\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss: 2.2584392155676523, Train_acc 0.4815504807692308\n",
      "\n",
      "Epoch 0. Loss: 2.2578835509434088, Train_acc 0.4817509541984733\n",
      "\n",
      "Epoch 0. Loss: 2.2573249314221338, Train_acc 0.4823626893939394\n",
      "\n",
      "Epoch 0. Loss: 2.2567699359111657, Train_acc 0.48214285714285715\n",
      "\n",
      "Epoch 0. Loss: 2.256210431475455, Train_acc 0.482334421641791\n",
      "\n",
      "Epoch 0. Loss: 2.2556461079605667, Train_acc 0.4826388888888889\n",
      "\n",
      "Epoch 0. Loss: 2.2550832625082498, Train_acc 0.4824793198529412\n",
      "\n",
      "Epoch 0. Loss: 2.2545155360194893, Train_acc 0.48266423357664234\n",
      "\n",
      "Epoch 0. Loss: 2.253950444574547, Train_acc 0.48278985507246375\n",
      "\n",
      "Epoch 0. Loss: 2.253381751018999, Train_acc 0.4829136690647482\n",
      "\n",
      "Epoch 0. Loss: 2.252819864966329, Train_acc 0.4825892857142857\n",
      "\n",
      "Epoch 0. Loss: 2.2522468560215607, Train_acc 0.4824911347517731\n",
      "\n",
      "Epoch 0. Loss: 2.2516728203837086, Train_acc 0.4824493838028169\n",
      "\n",
      "Epoch 0. Loss: 2.2510984025131235, Train_acc 0.48240821678321677\n",
      "\n",
      "Epoch 0. Loss: 2.250527015617814, Train_acc 0.48193359375\n",
      "\n",
      "Epoch 0. Loss: 2.2499521968547636, Train_acc 0.4816271551724138\n",
      "\n",
      "Epoch 0. Loss: 2.2493684945311436, Train_acc 0.4815924657534247\n",
      "\n",
      "Epoch 0. Loss: 2.248784756981157, Train_acc 0.4817708333333333\n",
      "\n",
      "Epoch 0. Loss: 2.24820072229663, Train_acc 0.48178842905405406\n",
      "\n",
      "Epoch 0. Loss: 2.2476119231005494, Train_acc 0.4816484899328859\n",
      "\n",
      "Epoch 0. Loss: 2.2470318228514774, Train_acc 0.48130208333333335\n",
      "\n",
      "Epoch 0. Loss: 2.246441599627998, Train_acc 0.48121895695364236\n",
      "\n",
      "Epoch 0. Loss: 2.245854520133793, Train_acc 0.4809827302631579\n",
      "\n",
      "Epoch 0. Loss: 2.245262995062612, Train_acc 0.4809027777777778\n",
      "\n",
      "Epoch 0. Loss: 2.2446693767620713, Train_acc 0.4809760551948052\n",
      "\n",
      "Epoch 0. Loss: 2.2440715952335255, Train_acc 0.4809475806451613\n",
      "\n",
      "Epoch 0. Loss: 2.243468523858217, Train_acc 0.4814202724358974\n",
      "\n",
      "Epoch 0. Loss: 2.2428670581478327, Train_acc 0.48168789808917195\n",
      "\n",
      "Epoch 0. Loss: 2.242263286286142, Train_acc 0.4816554588607595\n",
      "\n",
      "Epoch 0. Loss: 2.241654472831697, Train_acc 0.48191823899371067\n",
      "\n",
      "Epoch 0. Loss: 2.241046576212816, Train_acc 0.482275390625\n",
      "\n",
      "Epoch 0. Loss: 2.240439565803471, Train_acc 0.4819972826086957\n",
      "\n",
      "Epoch 0. Loss: 2.23983127266924, Train_acc 0.48210841049382713\n",
      "\n",
      "Epoch 0. Loss: 2.2392137750670593, Train_acc 0.4823140337423313\n",
      "\n",
      "Epoch 0. Loss: 2.2386033989626597, Train_acc 0.48218368902439024\n",
      "\n",
      "Epoch 0. Loss: 2.237989370531047, Train_acc 0.48233901515151517\n",
      "\n",
      "Epoch 0. Loss: 2.2373756768913493, Train_acc 0.4822571536144578\n",
      "\n",
      "Epoch 0. Loss: 2.2367616161292103, Train_acc 0.4823166167664671\n",
      "\n",
      "Epoch 0. Loss: 2.2361442450622175, Train_acc 0.48232886904761907\n",
      "\n",
      "Epoch 0. Loss: 2.23551883795858, Train_acc 0.4825258875739645\n",
      "\n",
      "Epoch 0. Loss: 2.234894978543228, Train_acc 0.48267463235294117\n",
      "\n",
      "Epoch 0. Loss: 2.2342746540553424, Train_acc 0.4826388888888889\n",
      "\n",
      "Epoch 0. Loss: 2.233652972559192, Train_acc 0.48278524709302323\n",
      "\n",
      "Epoch 0. Loss: 2.2330254915816163, Train_acc 0.4828395953757225\n",
      "\n",
      "Epoch 0. Loss: 2.2323950323887614, Train_acc 0.48302801724137934\n",
      "\n",
      "Epoch 0. Loss: 2.2317583560440606, Train_acc 0.4833482142857143\n",
      "\n",
      "Epoch 0. Loss: 2.2311319469907613, Train_acc 0.48335404829545453\n",
      "\n",
      "Epoch 0. Loss: 2.2305057152016703, Train_acc 0.483448093220339\n",
      "\n",
      "Epoch 0. Loss: 2.2298593551779495, Train_acc 0.4843311095505618\n",
      "\n",
      "Epoch 0. Loss: 2.229218559916423, Train_acc 0.48450593575418993\n",
      "\n",
      "Epoch 0. Loss: 2.2285821818123757, Train_acc 0.48420138888888886\n",
      "\n",
      "Epoch 0. Loss: 2.2279450721524547, Train_acc 0.48420234806629836\n",
      "\n",
      "Epoch 0. Loss: 2.227299904496726, Train_acc 0.4844179258241758\n",
      "\n",
      "Epoch 0. Loss: 2.2266593765363534, Train_acc 0.4844176912568306\n",
      "\n",
      "Epoch 0. Loss: 2.226011857115625, Train_acc 0.48458729619565216\n",
      "\n",
      "Epoch 0. Loss: 2.2253644542655993, Train_acc 0.48458614864864863\n",
      "\n",
      "Epoch 0. Loss: 2.2247220210228393, Train_acc 0.4845010080645161\n",
      "\n",
      "Epoch 0. Loss: 2.224075643288502, Train_acc 0.484375\n",
      "\n",
      "Epoch 0. Loss: 2.2234288461871294, Train_acc 0.48408410904255317\n",
      "\n",
      "Epoch 0. Loss: 2.2227857871640397, Train_acc 0.48383763227513227\n",
      "\n",
      "Epoch 0. Loss: 2.222137361779887, Train_acc 0.4838404605263158\n",
      "\n",
      "Epoch 0. Loss: 2.221478612139749, Train_acc 0.4839659685863874\n",
      "\n",
      "Epoch 0. Loss: 2.2208283883390605, Train_acc 0.4840087890625\n",
      "\n",
      "Epoch 0. Loss: 2.2201643320557674, Train_acc 0.484375\n",
      "\n",
      "Epoch 0. Loss: 2.219497465422832, Train_acc 0.4848179768041237\n",
      "\n",
      "Epoch 0. Loss: 2.218832801876239, Train_acc 0.4852163461538462\n",
      "\n",
      "Epoch 0. Loss: 2.218175919837549, Train_acc 0.48512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "smoothing_constant = .01\n",
    "metric = mx.metric.Accuracy()\n",
    "\n",
    "for e in range(epochs):\n",
    "    metric.reset()\n",
    "    for i, (d, l) in enumerate(train_data):\n",
    "        data = d.as_in_context(ctx)\n",
    "        label = l.as_in_context(ctx)\n",
    "        with autograd.record():\n",
    "            output = alex_net(data)\n",
    "            loss = softmax_cross_entropy(output, label)\n",
    "        \n",
    "        loss.backward()\n",
    "        trainer.step(data.shape[0])\n",
    "                \n",
    "        ##########################\n",
    "        #  Keep a moving average of the losses\n",
    "        ##########################\n",
    "        metric.update([label], [output])\n",
    "        curr_loss = nd.mean(loss).asscalar()\n",
    "        moving_loss = (curr_loss if ((i == 0) and (e == 0))\n",
    "                       else (1 - smoothing_constant) * moving_loss + (smoothing_constant) * curr_loss)\n",
    "\n",
    "        \n",
    "        if i % 100 == 0 and i > 0:\n",
    "                name, acc = metric.get()\n",
    "                print('[Epoch %d Batch %d] Loss: %s Training: %s=%f'%(e, i, moving_loss, name, acc))\n",
    "\n",
    "        _, train_accuracy = metric.get()\n",
    "        print(\"Epoch %s. Loss: %s, Train_acc %s\\n\" % (e, moving_loss, train_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
