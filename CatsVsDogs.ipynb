{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification: Cats VS Dogs\n",
    "\n",
    "We downloaded the dataset from kaggle. The training archive contains 25,000 images of dogs and cats. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using own data with included Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mxnet as mx\n",
    "import matplotlib.pyplot as plt\n",
    "from mxnet import gluon\n",
    "from mxnet import nd, autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aug_transform(data, label):\n",
    "    data = data.astype('float32')/255 # normalize the data\n",
    "    size= 224\n",
    "    aug = mx.image.ForceResizeAug((size,size)) # resize the image to 224x224\n",
    "    data = aug(data)\n",
    "    data=data.transpose((2, 0, 1))\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = nd.random_normal(shape=(10,224,224,3))\n",
    "# y = aug_transform(x,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data\"\n",
    "dataset_name = \"CatsVsDogs\"\n",
    "\n",
    "training_path = os.path.join(data_folder, dataset_name)\n",
    "\n",
    "train_dataset = mx.gluon.data.vision.datasets.ImageFolderDataset(training_path,transform=aug_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type: (3, 224, 224)\n",
      "Label: 1\n",
      "Label description: dog\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 17990\n",
    "sample = train_dataset[sample_idx]\n",
    "data = sample[0]\n",
    "label = sample[1]\n",
    "\n",
    "#plt.imshow(data.asnumpy(), cmap='gray')\n",
    "print(\"Data type: {}\".format(data.shape))\n",
    "print(\"Label: {}\".format(label))\n",
    "print(\"Label description: {}\".format(train_dataset.synsets[label]))\n",
    "assert label == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch size and DataLoader for train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_data = gluon.data.DataLoader(train_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The AlexNet architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "alex_net = gluon.nn.Sequential()\n",
    "with alex_net.name_scope():\n",
    "    #  First convolutional layer\n",
    "    alex_net.add(gluon.nn.Conv2D(channels=96, kernel_size=11, strides=(4,4), activation='relu'))\n",
    "    alex_net.add(gluon.nn.MaxPool2D(pool_size=3, strides=2))\n",
    "    #  Second convolutional layer\n",
    "    alex_net.add(gluon.nn.Conv2D(channels=192, kernel_size=5, activation='relu'))\n",
    "    alex_net.add(gluon.nn.MaxPool2D(pool_size=3, strides=(2,2)))\n",
    "    # Third convolutional layer\n",
    "    alex_net.add(gluon.nn.Conv2D(channels=384, kernel_size=3, activation='relu'))\n",
    "    # Fourth convolutional layer\n",
    "    alex_net.add(gluon.nn.Conv2D(channels=384, kernel_size=3, activation='relu'))\n",
    "    # Fifth convolutional layer\n",
    "    alex_net.add(gluon.nn.Conv2D(channels=256, kernel_size=3, activation='relu'))\n",
    "    alex_net.add(gluon.nn.MaxPool2D(pool_size=3, strides=2))\n",
    "    # Flatten and apply fullly connected layers\n",
    "    alex_net.add(gluon.nn.Flatten())\n",
    "    alex_net.add(gluon.nn.Dense(4096, activation=\"relu\"))\n",
    "    alex_net.add(gluon.nn.Dense(4096, activation=\"relu\"))\n",
    "    alex_net.add(gluon.nn.Dense(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mx.gpu()\n",
    "alex_net.collect_params().initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(alex_net.collect_params(), 'adam', {'learning_rate': .0001})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iterator, net):\n",
    "    acc = mx.metric.Accuracy()\n",
    "    for d, l in data_iterator:\n",
    "        data = d.as_in_context(ctx)\n",
    "        label = l.as_in_context(ctx)\n",
    "        output = net(data)\n",
    "        predictions = nd.argmax(output, axis=1)\n",
    "        acc.update(preds=predictions, labels=label)\n",
    "        return acc.get()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss: 2.3018034, Train_acc 0.5078125\n",
      "\n",
      "Epoch 0. Loss: 2.299548125267029, Train_acc 0.48828125\n",
      "\n",
      "Epoch 0. Loss: 2.2920658373832703, Train_acc 0.4973958333333333\n",
      "\n",
      "Epoch 0. Loss: 2.2749305770397186, Train_acc 0.5078125\n",
      "\n",
      "Epoch 0. Loss: 2.240529877448082, Train_acc 0.4875\n",
      "\n",
      "Epoch 0. Loss: 2.1778787337279324, Train_acc 0.48046875\n",
      "\n",
      "Epoch 0. Loss: 2.0786148633840087, Train_acc 0.484375\n",
      "\n",
      "Epoch 0. Loss: 1.953319626416183, Train_acc 0.48828125\n",
      "\n",
      "Epoch 0. Loss: 1.82948418620117, Train_acc 0.4861111111111111\n",
      "\n",
      "Epoch 0. Loss: 1.7214135780592634, Train_acc 0.49296875\n",
      "\n",
      "Epoch 0. Loss: 1.6181722928279525, Train_acc 0.4992897727272727\n",
      "\n",
      "Epoch 0. Loss: 1.542740450727393, Train_acc 0.4954427083333333\n",
      "\n",
      "Epoch 0. Loss: 1.4658534643895473, Train_acc 0.49459134615384615\n",
      "\n",
      "Epoch 0. Loss: 1.3928355381948097, Train_acc 0.49497767857142855\n",
      "\n",
      "Epoch 0. Loss: 1.338249338215203, Train_acc 0.49583333333333335\n",
      "\n",
      "Epoch 0. Loss: 1.2752333216776945, Train_acc 0.4921875\n",
      "\n",
      "Epoch 0. Loss: 1.2474314331630318, Train_acc 0.49264705882352944\n",
      "\n",
      "Epoch 0. Loss: 1.1972720586913332, Train_acc 0.4913194444444444\n",
      "\n",
      "Epoch 0. Loss: 1.1620054987362778, Train_acc 0.49300986842105265\n",
      "\n",
      "Epoch 0. Loss: 1.132607514914133, Train_acc 0.49609375\n",
      "\n",
      "Epoch 0. Loss: 1.093938543131582, Train_acc 0.49516369047619047\n",
      "\n",
      "Epoch 0. Loss: 1.053877658007114, Train_acc 0.4992897727272727\n",
      "\n",
      "Epoch 0. Loss: 1.039782488069745, Train_acc 0.499320652173913\n",
      "\n",
      "Epoch 0. Loss: 1.023415354241561, Train_acc 0.498046875\n",
      "\n",
      "Epoch 0. Loss: 0.9939605480578224, Train_acc 0.498125\n",
      "\n",
      "Epoch 0. Loss: 0.96392941053033, Train_acc 0.49609375\n",
      "\n",
      "Epoch 0. Loss: 0.9384527883707297, Train_acc 0.49623842592592593\n",
      "\n",
      "Epoch 0. Loss: 0.9183633460204731, Train_acc 0.49609375\n",
      "\n",
      "Epoch 0. Loss: 0.8953864753485558, Train_acc 0.49919181034482757\n",
      "\n",
      "Epoch 0. Loss: 0.8769994300819193, Train_acc 0.5002604166666667\n",
      "\n",
      "Epoch 0. Loss: 0.8602792908743102, Train_acc 0.5020161290322581\n",
      "\n",
      "Epoch 0. Loss: 0.8462362369890583, Train_acc 0.50244140625\n",
      "\n",
      "Epoch 0. Loss: 0.8358298493321751, Train_acc 0.5009469696969697\n",
      "\n",
      "Epoch 0. Loss: 0.8232742148246778, Train_acc 0.5013786764705882\n",
      "\n",
      "Epoch 0. Loss: 0.812320393109895, Train_acc 0.5029017857142857\n",
      "\n",
      "Epoch 0. Loss: 0.8026566879015362, Train_acc 0.5030381944444444\n",
      "\n",
      "Epoch 0. Loss: 0.7952502408082363, Train_acc 0.5012668918918919\n",
      "\n",
      "Epoch 0. Loss: 0.787414083342708, Train_acc 0.5028782894736842\n",
      "\n",
      "Epoch 0. Loss: 0.7803477312275382, Train_acc 0.5038060897435898\n",
      "\n",
      "Epoch 0. Loss: 0.7734602211548638, Train_acc 0.505078125\n",
      "\n",
      "Epoch 0. Loss: 0.7673924015730994, Train_acc 0.5059070121951219\n",
      "\n",
      "Epoch 0. Loss: 0.7609632533881405, Train_acc 0.5061383928571429\n",
      "\n",
      "Epoch 0. Loss: 0.756269430109263, Train_acc 0.5052688953488372\n",
      "\n",
      "Epoch 0. Loss: 0.7510220065609221, Train_acc 0.5053267045454546\n",
      "\n",
      "Epoch 0. Loss: 0.7447729815449361, Train_acc 0.5067708333333333\n",
      "\n",
      "Epoch 0. Loss: 0.7421492853229682, Train_acc 0.5049252717391305\n",
      "\n",
      "Epoch 0. Loss: 0.7380257950841284, Train_acc 0.5044880319148937\n",
      "\n",
      "Epoch 0. Loss: 0.7344095921473708, Train_acc 0.5029296875\n",
      "\n",
      "Epoch 0. Loss: 0.7303357019386, Train_acc 0.5041454081632653\n",
      "\n",
      "Epoch 0. Loss: 0.7268428111995434, Train_acc 0.504375\n",
      "\n",
      "Epoch 0. Loss: 0.7222637508742669, Train_acc 0.5056678921568627\n",
      "\n",
      "Epoch 0. Loss: 0.7223798967390649, Train_acc 0.5046574519230769\n",
      "\n",
      "Epoch 0. Loss: 0.7195446375300937, Train_acc 0.5054540094339622\n",
      "\n",
      "Epoch 0. Loss: 0.7178113952240752, Train_acc 0.5056423611111112\n",
      "\n",
      "Epoch 0. Loss: 0.7163732494379348, Train_acc 0.5052556818181818\n",
      "\n",
      "Epoch 0. Loss: 0.7142987053512275, Train_acc 0.5054408482142857\n",
      "\n",
      "Epoch 0. Loss: 0.7122613073216743, Train_acc 0.5052083333333334\n",
      "\n",
      "Epoch 0. Loss: 0.7103523088240802, Train_acc 0.5053879310344828\n",
      "\n",
      "Epoch 0. Loss: 0.7093378966519993, Train_acc 0.5054290254237288\n",
      "\n",
      "Epoch 0. Loss: 0.7106554149511244, Train_acc 0.5044270833333333\n",
      "\n",
      "Epoch 0. Loss: 0.7101305936803924, Train_acc 0.5042264344262295\n",
      "\n",
      "Epoch 0. Loss: 0.7098163856593228, Train_acc 0.5027721774193549\n",
      "\n",
      "Epoch 0. Loss: 0.7080736601526251, Train_acc 0.5029761904761905\n",
      "\n",
      "Epoch 0. Loss: 0.7058060327924529, Train_acc 0.5037841796875\n",
      "\n",
      "Epoch 0. Loss: 0.703418030717126, Train_acc 0.5048076923076923\n",
      "\n",
      "Epoch 0. Loss: 0.7030578861041232, Train_acc 0.5053267045454546\n",
      "\n",
      "Epoch 0. Loss: 0.7040376433196692, Train_acc 0.5057136194029851\n",
      "\n",
      "Epoch 0. Loss: 0.7059078605588998, Train_acc 0.5057444852941176\n",
      "\n",
      "Epoch 0. Loss: 0.7086201660290413, Train_acc 0.5050951086956522\n",
      "\n",
      "Epoch 0. Loss: 0.7087909238745319, Train_acc 0.5046875\n",
      "\n",
      "Epoch 0. Loss: 0.7076868823656035, Train_acc 0.5044014084507042\n",
      "\n",
      "Epoch 0. Loss: 0.7067436168928676, Train_acc 0.5033637152777778\n",
      "\n",
      "Epoch 0. Loss: 0.7053553870624065, Train_acc 0.5039597602739726\n",
      "\n",
      "Epoch 0. Loss: 0.7047001968001508, Train_acc 0.504222972972973\n",
      "\n",
      "Epoch 0. Loss: 0.7057758376158938, Train_acc 0.5035416666666667\n",
      "\n",
      "Epoch 0. Loss: 0.7058887843928634, Train_acc 0.5034950657894737\n",
      "\n",
      "Epoch 0. Loss: 0.7058390645362644, Train_acc 0.5035511363636364\n",
      "\n",
      "Epoch 0. Loss: 0.7059169472614862, Train_acc 0.5034054487179487\n",
      "\n",
      "Epoch 0. Loss: 0.7060634012246076, Train_acc 0.5029667721518988\n",
      "\n",
      "Epoch 0. Loss: 0.7053538842699478, Train_acc 0.50302734375\n",
      "\n",
      "Epoch 0. Loss: 0.7045307889909938, Train_acc 0.5031828703703703\n",
      "\n",
      "Epoch 0. Loss: 0.7036235036252196, Train_acc 0.5040967987804879\n",
      "\n",
      "Epoch 0. Loss: 0.7029856057582726, Train_acc 0.5046121987951807\n",
      "\n",
      "Epoch 0. Loss: 0.7026841293232229, Train_acc 0.5038132440476191\n",
      "\n",
      "Epoch 0. Loss: 0.7021315142920542, Train_acc 0.5038602941176471\n",
      "\n",
      "Epoch 0. Loss: 0.7015016119549509, Train_acc 0.5037245639534884\n",
      "\n",
      "Epoch 0. Loss: 0.7012958741965742, Train_acc 0.5029633620689655\n",
      "\n",
      "Epoch 0. Loss: 0.7009378865465091, Train_acc 0.5022194602272727\n",
      "\n",
      "Epoch 0. Loss: 0.7004557664785892, Train_acc 0.5022823033707865\n",
      "\n",
      "Epoch 0. Loss: 0.7000785364741782, Train_acc 0.5019965277777778\n",
      "\n",
      "Epoch 0. Loss: 0.6992287481458217, Train_acc 0.5023179945054945\n",
      "\n",
      "Epoch 0. Loss: 0.6997109989492205, Train_acc 0.5016134510869565\n",
      "\n",
      "Epoch 0. Loss: 0.6991425341518022, Train_acc 0.5017641129032258\n",
      "\n",
      "Epoch 0. Loss: 0.6988052594200936, Train_acc 0.5015791223404256\n",
      "\n",
      "Epoch 0. Loss: 0.698331064063564, Train_acc 0.5010690789473684\n",
      "\n",
      "Epoch 0. Loss: 0.6976363176807061, Train_acc 0.50146484375\n",
      "\n",
      "Epoch 0. Loss: 0.6986114068064955, Train_acc 0.5008859536082474\n",
      "\n",
      "Epoch 0. Loss: 0.6983794823199988, Train_acc 0.5007174744897959\n",
      "\n",
      "Epoch 0. Loss: 0.6977844227770401, Train_acc 0.5009469696969697\n",
      "\n",
      "Epoch 0. Loss: 0.6973591079788893, Train_acc 0.501328125\n",
      "\n",
      "[Epoch 0 Batch 100] Loss: 0.6978345123360298 Training: accuracy=0.500928\n",
      "Epoch 0. Loss: 0.6978345123360298, Train_acc 0.5009282178217822\n",
      "\n",
      "Epoch 0. Loss: 0.6976166791406043, Train_acc 0.5006893382352942\n",
      "\n",
      "Epoch 0. Loss: 0.6973372840899319, Train_acc 0.5006067961165048\n",
      "\n",
      "Epoch 0. Loss: 0.6956237564103088, Train_acc 0.5015024038461539\n",
      "\n",
      "Epoch 0. Loss: 0.6970880040183319, Train_acc 0.5014880952380952\n",
      "\n",
      "Epoch 0. Loss: 0.6976238377679576, Train_acc 0.5016214622641509\n",
      "\n",
      "Epoch 0. Loss: 0.6996341366579404, Train_acc 0.5013142523364486\n",
      "\n",
      "Epoch 0. Loss: 0.7007416324922684, Train_acc 0.5007957175925926\n",
      "\n",
      "Epoch 0. Loss: 0.699717632273666, Train_acc 0.5012184633027523\n",
      "\n",
      "Epoch 0. Loss: 0.699047587519734, Train_acc 0.501278409090909\n",
      "\n",
      "Epoch 0. Loss: 0.6979050715617975, Train_acc 0.501829954954955\n",
      "\n",
      "Epoch 0. Loss: 0.6985117506849147, Train_acc 0.5016741071428571\n",
      "\n",
      "Epoch 0. Loss: 0.6984368364692369, Train_acc 0.5017284292035398\n",
      "\n",
      "Epoch 0. Loss: 0.6985728204858874, Train_acc 0.5019188596491229\n",
      "\n",
      "Epoch 0. Loss: 0.6992035800766266, Train_acc 0.5019021739130435\n",
      "\n",
      "Epoch 0. Loss: 0.6996839607850895, Train_acc 0.5018184267241379\n",
      "\n",
      "Epoch 0. Loss: 0.6986880152013468, Train_acc 0.5022702991452992\n",
      "\n",
      "Epoch 0. Loss: 0.6998718066739947, Train_acc 0.5014565677966102\n",
      "\n",
      "Epoch 0. Loss: 0.6993760899062077, Train_acc 0.5015099789915967\n",
      "\n",
      "Epoch 0. Loss: 0.6991362424512315, Train_acc 0.5014973958333333\n",
      "\n",
      "Epoch 0. Loss: 0.6996969209748156, Train_acc 0.5010976239669421\n",
      "\n",
      "Epoch 0. Loss: 0.6999175155136866, Train_acc 0.5009605532786885\n",
      "\n",
      "Epoch 0. Loss: 0.6989416245198742, Train_acc 0.5015243902439024\n",
      "\n",
      "Epoch 0. Loss: 0.6998089578965153, Train_acc 0.5013230846774194\n",
      "\n",
      "Epoch 0. Loss: 0.6992853665845554, Train_acc 0.5015625\n",
      "\n",
      "Epoch 0. Loss: 0.6997694597688581, Train_acc 0.5011160714285714\n",
      "\n",
      "Epoch 0. Loss: 0.6997495734137832, Train_acc 0.5004306102362205\n",
      "\n",
      "Epoch 0. Loss: 0.6992582896449452, Train_acc 0.5003662109375\n",
      "\n",
      "Epoch 0. Loss: 0.6982634263424532, Train_acc 0.5006056201550387\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss: 0.6982272145618609, Train_acc 0.5006610576923077\n",
      "\n",
      "Epoch 0. Loss: 0.6995081493976365, Train_acc 0.5005963740458015\n",
      "\n",
      "Epoch 0. Loss: 0.6994662216057763, Train_acc 0.5007694128787878\n",
      "\n",
      "Epoch 0. Loss: 0.6985311446264731, Train_acc 0.5011748120300752\n",
      "\n",
      "Epoch 0. Loss: 0.6992211345739974, Train_acc 0.5011077425373134\n",
      "\n",
      "Epoch 0. Loss: 0.6990769687808585, Train_acc 0.5010416666666667\n",
      "\n",
      "Epoch 0. Loss: 0.698974023775789, Train_acc 0.5011488970588235\n",
      "\n",
      "Epoch 0. Loss: 0.6984446381180281, Train_acc 0.5009694343065694\n",
      "\n",
      "Epoch 0. Loss: 0.69855930220921, Train_acc 0.5004528985507246\n",
      "\n",
      "Epoch 0. Loss: 0.6987108332977221, Train_acc 0.5001124100719424\n",
      "\n",
      "Epoch 0. Loss: 0.698220235979455, Train_acc 0.5002232142857143\n",
      "\n",
      "Epoch 0. Loss: 0.6976365174733674, Train_acc 0.5005540780141844\n",
      "\n",
      "Epoch 0. Loss: 0.6971177630916008, Train_acc 0.5007702464788732\n",
      "\n",
      "Epoch 0. Loss: 0.6968664205039831, Train_acc 0.500819493006993\n",
      "\n",
      "Epoch 0. Loss: 0.6970046707360708, Train_acc 0.5005425347222222\n",
      "\n",
      "Epoch 0. Loss: 0.6966802431674686, Train_acc 0.5007004310344828\n",
      "\n",
      "Epoch 0. Loss: 0.6963054317413467, Train_acc 0.5012842465753424\n",
      "\n",
      "Epoch 0. Loss: 0.6963293830912142, Train_acc 0.5007971938775511\n",
      "\n",
      "Epoch 0. Loss: 0.6958684039438512, Train_acc 0.5012668918918919\n",
      "\n",
      "Epoch 0. Loss: 0.6952508132748079, Train_acc 0.5015729865771812\n",
      "\n",
      "Epoch 0. Loss: 0.6946397579692845, Train_acc 0.501875\n",
      "\n",
      "Epoch 0. Loss: 0.695529969660912, Train_acc 0.5017591059602649\n",
      "\n",
      "Epoch 0. Loss: 0.6953887332634395, Train_acc 0.5019017269736842\n",
      "\n",
      "Epoch 0. Loss: 0.6957569291433334, Train_acc 0.5017871732026143\n",
      "\n",
      "Epoch 0. Loss: 0.6950191292381859, Train_acc 0.5020799512987013\n",
      "\n",
      "Epoch 0. Loss: 0.6948137551441708, Train_acc 0.5021169354838709\n",
      "\n",
      "Epoch 0. Loss: 0.6946739676500785, Train_acc 0.5020532852564102\n",
      "\n",
      "Epoch 0. Loss: 0.6944614758704986, Train_acc 0.5020899681528662\n",
      "\n",
      "Epoch 0. Loss: 0.6939333001328902, Train_acc 0.5025217563291139\n",
      "\n",
      "Epoch 0. Loss: 0.6935375082093534, Train_acc 0.502751572327044\n",
      "\n",
      "Epoch 0. Loss: 0.6947537852166347, Train_acc 0.502490234375\n",
      "\n",
      "Epoch 0. Loss: 0.6959585243020879, Train_acc 0.5021350931677019\n",
      "\n",
      "Epoch 0. Loss: 0.6956612730223918, Train_acc 0.5021701388888888\n",
      "\n",
      "Epoch 0. Loss: 0.6956343827425525, Train_acc 0.5017254601226994\n",
      "\n",
      "Epoch 0. Loss: 0.6957254151504414, Train_acc 0.5013338414634146\n",
      "\n",
      "Epoch 0. Loss: 0.6953768914939026, Train_acc 0.5018465909090909\n",
      "\n",
      "Epoch 0. Loss: 0.6951003598571771, Train_acc 0.5020707831325302\n",
      "\n",
      "Epoch 0. Loss: 0.6949024969995875, Train_acc 0.5023858532934131\n",
      "\n",
      "Epoch 0. Loss: 0.6947252846951061, Train_acc 0.5025111607142857\n",
      "\n",
      "Epoch 0. Loss: 0.6952646342392064, Train_acc 0.5021727071005917\n",
      "\n",
      "Epoch 0. Loss: 0.6952735156543818, Train_acc 0.5021139705882353\n",
      "\n",
      "Epoch 0. Loss: 0.6949440393502503, Train_acc 0.5021929824561403\n",
      "\n",
      "Epoch 0. Loss: 0.6946799534846833, Train_acc 0.5025890261627907\n",
      "\n",
      "Epoch 0. Loss: 0.6945443551203153, Train_acc 0.502528901734104\n",
      "\n",
      "Epoch 0. Loss: 0.6944672644550092, Train_acc 0.5023347701149425\n",
      "\n",
      "Epoch 0. Loss: 0.6942322236670095, Train_acc 0.5025\n",
      "\n",
      "Epoch 0. Loss: 0.6943356021380162, Train_acc 0.5022194602272727\n",
      "\n",
      "Epoch 0. Loss: 0.6942762396456958, Train_acc 0.5021627824858758\n",
      "\n",
      "Epoch 0. Loss: 0.6940731997837569, Train_acc 0.5024139747191011\n",
      "\n",
      "Epoch 0. Loss: 0.6939611073329996, Train_acc 0.503098812849162\n",
      "\n",
      "Epoch 0. Loss: 0.6940343412156359, Train_acc 0.5029513888888889\n",
      "\n",
      "Epoch 0. Loss: 0.6944517283793201, Train_acc 0.5024602900552486\n",
      "\n",
      "Epoch 0. Loss: 0.6942583849271456, Train_acc 0.5028331043956044\n",
      "\n",
      "Epoch 0. Loss: 0.694478440008192, Train_acc 0.5026895491803278\n",
      "\n",
      "Epoch 0. Loss: 0.6946936139955778, Train_acc 0.5025050951086957\n",
      "\n",
      "Epoch 0. Loss: 0.6943117400552028, Train_acc 0.502660472972973\n",
      "\n",
      "Epoch 0. Loss: 0.6941275138150329, Train_acc 0.5027301747311828\n",
      "\n",
      "Epoch 0. Loss: 0.6939296250185973, Train_acc 0.5028409090909091\n",
      "\n",
      "Epoch 0. Loss: 0.6937476567603595, Train_acc 0.5031166888297872\n",
      "\n",
      "Epoch 0. Loss: 0.6932508324543339, Train_acc 0.5035135582010583\n",
      "\n",
      "Epoch 0. Loss: 0.6926124669575425, Train_acc 0.5038240131578947\n",
      "\n",
      "Epoch 0. Loss: 0.692329643141961, Train_acc 0.5040903141361257\n",
      "\n",
      "Epoch 0. Loss: 0.6942335229859374, Train_acc 0.5039469401041666\n",
      "\n",
      "Epoch 0. Loss: 0.6951630826365014, Train_acc 0.5039669689119171\n",
      "\n",
      "Epoch 0. Loss: 0.6954926653716916, Train_acc 0.50390625\n",
      "\n",
      "Epoch 0. Loss: 0.6950561407816965, Train_acc 0.5040064102564102\n",
      "\n",
      "Epoch 0. Loss: 0.6946935358893178, Train_acc 0.50412\n",
      "\n",
      "Epoch 1. Loss: 0.6949559840486618, Train_acc 0.4921875\n",
      "\n",
      "Epoch 1. Loss: 0.6952127927177701, Train_acc 0.5\n",
      "\n",
      "Epoch 1. Loss: 0.6949321192771394, Train_acc 0.5104166666666666\n",
      "\n",
      "Epoch 1. Loss: 0.6948301639202414, Train_acc 0.515625\n",
      "\n",
      "Epoch 1. Loss: 0.6954841416516762, Train_acc 0.5125\n",
      "\n",
      "Epoch 1. Loss: 0.694938671717542, Train_acc 0.5169270833333334\n",
      "\n",
      "Epoch 1. Loss: 0.6953231025899925, Train_acc 0.5122767857142857\n",
      "\n",
      "Epoch 1. Loss: 0.6956780191509854, Train_acc 0.5009765625\n",
      "\n",
      "Epoch 1. Loss: 0.6957814547046064, Train_acc 0.4947916666666667\n",
      "\n",
      "Epoch 1. Loss: 0.6953843819460904, Train_acc 0.49921875\n",
      "\n",
      "Epoch 1. Loss: 0.6965402651454481, Train_acc 0.4950284090909091\n",
      "\n",
      "Epoch 1. Loss: 0.6968398233019238, Train_acc 0.4954427083333333\n",
      "\n",
      "Epoch 1. Loss: 0.6973901396777862, Train_acc 0.49399038461538464\n",
      "\n",
      "Epoch 1. Loss: 0.6969984655785532, Train_acc 0.4955357142857143\n",
      "\n",
      "Epoch 1. Loss: 0.696536041963813, Train_acc 0.4979166666666667\n",
      "\n",
      "Epoch 1. Loss: 0.6960681059974885, Train_acc 0.5029296875\n",
      "\n",
      "Epoch 1. Loss: 0.695695887120228, Train_acc 0.5045955882352942\n",
      "\n",
      "Epoch 1. Loss: 0.6951611370846579, Train_acc 0.5065104166666666\n",
      "\n",
      "Epoch 1. Loss: 0.6946219621007099, Train_acc 0.5082236842105263\n",
      "\n",
      "Epoch 1. Loss: 0.6951952831063677, Train_acc 0.50546875\n",
      "\n",
      "Epoch 1. Loss: 0.6945066502196201, Train_acc 0.5081845238095238\n",
      "\n",
      "Epoch 1. Loss: 0.6941240475031086, Train_acc 0.5092329545454546\n",
      "\n",
      "Epoch 1. Loss: 0.6939473610030724, Train_acc 0.5095108695652174\n",
      "\n",
      "Epoch 1. Loss: 0.6932478959179325, Train_acc 0.5123697916666666\n",
      "\n",
      "Epoch 1. Loss: 0.6927422357931498, Train_acc 0.5140625\n",
      "\n",
      "Epoch 1. Loss: 0.6923342114688243, Train_acc 0.5150240384615384\n",
      "\n",
      "Epoch 1. Loss: 0.6930877595545011, Train_acc 0.5130208333333334\n",
      "\n",
      "Epoch 1. Loss: 0.6929114010394655, Train_acc 0.5131138392857143\n",
      "\n",
      "Epoch 1. Loss: 0.6927680623347499, Train_acc 0.513739224137931\n",
      "\n",
      "Epoch 1. Loss: 0.6924274490906243, Train_acc 0.5161458333333333\n",
      "\n",
      "Epoch 1. Loss: 0.692669736740003, Train_acc 0.5141129032258065\n",
      "\n",
      "Epoch 1. Loss: 0.6921387142512292, Train_acc 0.516357421875\n",
      "\n",
      "Epoch 1. Loss: 0.6919074678337357, Train_acc 0.5168087121212122\n",
      "\n",
      "Epoch 1. Loss: 0.6913301906510396, Train_acc 0.5186121323529411\n",
      "\n",
      "Epoch 1. Loss: 0.6908245648316327, Train_acc 0.51875\n",
      "\n",
      "Epoch 1. Loss: 0.6894427626167342, Train_acc 0.5197482638888888\n",
      "\n",
      "Epoch 1. Loss: 0.6875740071089212, Train_acc 0.5215371621621622\n",
      "\n",
      "Epoch 1. Loss: 0.689103267784519, Train_acc 0.5217927631578947\n",
      "\n",
      "Epoch 1. Loss: 0.6900714119037417, Train_acc 0.5220352564102564\n",
      "\n",
      "Epoch 1. Loss: 0.6899881732249642, Train_acc 0.5220703125\n",
      "\n",
      "Epoch 1. Loss: 0.6897636149928914, Train_acc 0.5232469512195121\n",
      "\n",
      "Epoch 1. Loss: 0.6903569902127338, Train_acc 0.5225074404761905\n",
      "\n",
      "Epoch 1. Loss: 0.6916101758312004, Train_acc 0.5221656976744186\n",
      "\n",
      "Epoch 1. Loss: 0.692400620993747, Train_acc 0.5216619318181818\n",
      "\n",
      "Epoch 1. Loss: 0.6917987644226316, Train_acc 0.5222222222222223\n",
      "\n",
      "Epoch 1. Loss: 0.6914198380307225, Train_acc 0.5224184782608695\n",
      "\n",
      "Epoch 1. Loss: 0.6901983125444532, Train_acc 0.5231050531914894\n",
      "\n",
      "Epoch 1. Loss: 0.6920443984958184, Train_acc 0.521484375\n",
      "\n",
      "Epoch 1. Loss: 0.6931348752760279, Train_acc 0.5207270408163265\n",
      "\n",
      "Epoch 1. Loss: 0.6934066633984495, Train_acc 0.519375\n",
      "\n",
      "Epoch 1. Loss: 0.6936452764813645, Train_acc 0.5183823529411765\n",
      "\n",
      "Epoch 1. Loss: 0.6946106891522894, Train_acc 0.5177283653846154\n",
      "\n",
      "Epoch 1. Loss: 0.6945415145775756, Train_acc 0.5184257075471698\n",
      "\n",
      "Epoch 1. Loss: 0.696242434378363, Train_acc 0.5179398148148148\n",
      "\n",
      "Epoch 1. Loss: 0.6977696263157404, Train_acc 0.5163352272727273\n",
      "\n",
      "Epoch 1. Loss: 0.697034642997063, Train_acc 0.5164620535714286\n",
      "\n",
      "Epoch 1. Loss: 0.6966859393441768, Train_acc 0.5167214912280702\n",
      "\n",
      "Epoch 1. Loss: 0.6946481370738826, Train_acc 0.5180495689655172\n",
      "\n",
      "Epoch 1. Loss: 0.6955897781680539, Train_acc 0.5180084745762712\n",
      "\n",
      "Epoch 1. Loss: 0.6974396562663181, Train_acc 0.5173177083333333\n",
      "\n",
      "Epoch 1. Loss: 0.700362508543205, Train_acc 0.5157530737704918\n",
      "\n",
      "Epoch 1. Loss: 0.6996480927299307, Train_acc 0.5158770161290323\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1. Loss: 0.6984852944699685, Train_acc 0.5163690476190477\n",
      "\n",
      "Epoch 1. Loss: 0.69746470405648, Train_acc 0.5184326171875\n",
      "\n",
      "Epoch 1. Loss: 0.697316509073882, Train_acc 0.5181490384615385\n",
      "\n",
      "Epoch 1. Loss: 0.6973600222938436, Train_acc 0.5176373106060606\n",
      "\n",
      "Epoch 1. Loss: 0.6971027524119476, Train_acc 0.5173740671641791\n",
      "\n",
      "Epoch 1. Loss: 0.6964395944040292, Train_acc 0.517578125\n",
      "\n",
      "Epoch 1. Loss: 0.6952609989429659, Train_acc 0.5182291666666666\n",
      "\n",
      "Epoch 1. Loss: 0.6942941701458525, Train_acc 0.5180803571428572\n",
      "\n",
      "Epoch 1. Loss: 0.694457360152599, Train_acc 0.5162852112676056\n",
      "\n",
      "Epoch 1. Loss: 0.6939477873243661, Train_acc 0.5163845486111112\n",
      "\n",
      "Epoch 1. Loss: 0.6935753660557662, Train_acc 0.516695205479452\n",
      "\n",
      "Epoch 1. Loss: 0.6933442447028751, Train_acc 0.5166807432432432\n",
      "\n",
      "Epoch 1. Loss: 0.692554452429014, Train_acc 0.516875\n",
      "\n",
      "Epoch 1. Loss: 0.6904192254630902, Train_acc 0.5177837171052632\n",
      "\n",
      "Epoch 1. Loss: 0.6906194167454403, Train_acc 0.5170454545454546\n",
      "\n",
      "Epoch 1. Loss: 0.6907474884795571, Train_acc 0.5182291666666666\n",
      "\n",
      "Epoch 1. Loss: 0.6909860631293736, Train_acc 0.517998417721519\n",
      "\n",
      "Epoch 1. Loss: 0.6921977335631861, Train_acc 0.5171875\n",
      "\n",
      "Epoch 1. Loss: 0.6939162553328289, Train_acc 0.5166859567901234\n",
      "\n",
      "Epoch 1. Loss: 0.6910107500235451, Train_acc 0.5180068597560976\n",
      "\n",
      "Epoch 1. Loss: 0.6872411698293875, Train_acc 0.5192018072289156\n",
      "\n",
      "Epoch 1. Loss: 0.6889535901122263, Train_acc 0.5196242559523809\n",
      "\n",
      "Epoch 1. Loss: 0.6996257171487485, Train_acc 0.5188419117647058\n",
      "\n",
      "Epoch 1. Loss: 0.7070187269558617, Train_acc 0.5173510174418605\n",
      "\n",
      "Epoch 1. Loss: 0.7097384398201205, Train_acc 0.5158045977011494\n",
      "\n",
      "Epoch 1. Loss: 0.707781296821156, Train_acc 0.5161576704545454\n",
      "\n",
      "Epoch 1. Loss: 0.7060552792415489, Train_acc 0.5158883426966292\n",
      "\n",
      "Epoch 1. Loss: 0.7065513929723622, Train_acc 0.5151909722222222\n",
      "\n",
      "Epoch 1. Loss: 0.7044431806503763, Train_acc 0.5157108516483516\n",
      "\n",
      "Epoch 1. Loss: 0.7037896908133355, Train_acc 0.5158797554347826\n",
      "\n",
      "Epoch 1. Loss: 0.7031474885471876, Train_acc 0.5159610215053764\n",
      "\n",
      "Epoch 1. Loss: 0.70272402558877, Train_acc 0.515625\n",
      "\n",
      "Epoch 1. Loss: 0.7023538284971171, Train_acc 0.5152138157894737\n",
      "\n",
      "Epoch 1. Loss: 0.7015261352187862, Train_acc 0.5157063802083334\n",
      "\n",
      "Epoch 1. Loss: 0.7023800820225301, Train_acc 0.5149001288659794\n",
      "\n",
      "Epoch 1. Loss: 0.701854057024165, Train_acc 0.5148278061224489\n",
      "\n",
      "Epoch 1. Loss: 0.7015363635810411, Train_acc 0.5147569444444444\n",
      "\n",
      "Epoch 1. Loss: 0.7008173461728271, Train_acc 0.514765625\n",
      "\n",
      "[Epoch 1 Batch 100] Loss: 0.7005610343193688 Training: accuracy=0.514001\n",
      "Epoch 1. Loss: 0.7005610343193688, Train_acc 0.5140006188118812\n",
      "\n",
      "Epoch 1. Loss: 0.6996759721376608, Train_acc 0.5138633578431373\n",
      "\n",
      "Epoch 1. Loss: 0.6988258494798639, Train_acc 0.5140321601941747\n",
      "\n",
      "Epoch 1. Loss: 0.6998008251664906, Train_acc 0.5130709134615384\n",
      "\n",
      "Epoch 1. Loss: 0.6993535662124636, Train_acc 0.5125744047619047\n",
      "\n",
      "Epoch 1. Loss: 0.6991178486731722, Train_acc 0.5120135613207547\n",
      "\n",
      "Epoch 1. Loss: 0.6989209676373369, Train_acc 0.5116822429906542\n",
      "\n",
      "Epoch 1. Loss: 0.6978218160201639, Train_acc 0.5120081018518519\n",
      "\n",
      "Epoch 1. Loss: 0.6974701466080127, Train_acc 0.5118262614678899\n",
      "\n",
      "Epoch 1. Loss: 0.696377967171363, Train_acc 0.5120738636363636\n",
      "\n",
      "Epoch 1. Loss: 0.6950106391660797, Train_acc 0.5129504504504504\n",
      "\n",
      "Epoch 1. Loss: 0.6944317432659055, Train_acc 0.5132533482142857\n",
      "\n",
      "Epoch 1. Loss: 0.6940630804673301, Train_acc 0.5133434734513275\n",
      "\n",
      "Epoch 1. Loss: 0.6949912665345193, Train_acc 0.5130208333333334\n",
      "\n",
      "Epoch 1. Loss: 0.6945367417983341, Train_acc 0.5130434782608696\n",
      "\n",
      "Epoch 1. Loss: 0.6944691922294016, Train_acc 0.5122575431034483\n",
      "\n",
      "Epoch 1. Loss: 0.6945138978386148, Train_acc 0.5115518162393162\n",
      "\n",
      "Epoch 1. Loss: 0.694031567045232, Train_acc 0.512447033898305\n",
      "\n",
      "Epoch 1. Loss: 0.6938155984892074, Train_acc 0.5125393907563025\n",
      "\n",
      "Epoch 1. Loss: 0.6928195443165562, Train_acc 0.512890625\n",
      "\n",
      "Epoch 1. Loss: 0.694948341227674, Train_acc 0.512396694214876\n",
      "\n",
      "Epoch 1. Loss: 0.6944578520450922, Train_acc 0.5124871926229508\n",
      "\n",
      "Epoch 1. Loss: 0.6945026366705239, Train_acc 0.5120045731707317\n",
      "\n",
      "Epoch 1. Loss: 0.6946501656288987, Train_acc 0.5118447580645161\n",
      "\n",
      "Epoch 1. Loss: 0.692084424845733, Train_acc 0.512625\n",
      "\n",
      "Epoch 1. Loss: 0.6908482013514856, Train_acc 0.5131448412698413\n",
      "\n",
      "Epoch 1. Loss: 0.6895173160765666, Train_acc 0.5137180118110236\n",
      "\n",
      "Epoch 1. Loss: 0.6971774609566419, Train_acc 0.51318359375\n",
      "\n",
      "Epoch 1. Loss: 0.6978431920719763, Train_acc 0.5128997093023255\n",
      "\n",
      "Epoch 1. Loss: 0.6971192163687308, Train_acc 0.5129206730769231\n",
      "\n",
      "Epoch 1. Loss: 0.6984602215106511, Train_acc 0.512106393129771\n",
      "\n",
      "Epoch 1. Loss: 0.698513394792249, Train_acc 0.5120738636363636\n",
      "\n",
      "Epoch 1. Loss: 0.6989037211531731, Train_acc 0.5116306390977443\n",
      "\n",
      "Epoch 1. Loss: 0.6980430736357867, Train_acc 0.5121851679104478\n",
      "\n",
      "Epoch 1. Loss: 0.6974338639570682, Train_acc 0.5127314814814815\n",
      "\n",
      "Epoch 1. Loss: 0.6973449959272214, Train_acc 0.5126378676470589\n",
      "\n",
      "Epoch 1. Loss: 0.6963734543842734, Train_acc 0.5127737226277372\n",
      "\n",
      "Epoch 1. Loss: 0.6979130908718104, Train_acc 0.5124547101449275\n",
      "\n",
      "Epoch 1. Loss: 0.6971650366369243, Train_acc 0.5124213129496403\n",
      "\n",
      "Epoch 1. Loss: 0.6979097465619465, Train_acc 0.5122767857142857\n",
      "\n",
      "Epoch 1. Loss: 0.6974173432539421, Train_acc 0.5119126773049646\n",
      "\n",
      "Epoch 1. Loss: 0.6969854157522783, Train_acc 0.5123239436619719\n",
      "\n",
      "Epoch 1. Loss: 0.6966492522974729, Train_acc 0.5121831293706294\n",
      "\n",
      "Epoch 1. Loss: 0.6960006286996531, Train_acc 0.5125868055555556\n",
      "\n",
      "Epoch 1. Loss: 0.6951523897318178, Train_acc 0.5127693965517242\n",
      "\n",
      "Epoch 1. Loss: 0.6946771631182551, Train_acc 0.5128424657534246\n",
      "\n",
      "Epoch 1. Loss: 0.6955781957097041, Train_acc 0.5125956632653061\n",
      "\n",
      "Epoch 1. Loss: 0.6955123168755044, Train_acc 0.5123521959459459\n",
      "\n",
      "Epoch 1. Loss: 0.6952746173019829, Train_acc 0.5122692953020134\n",
      "\n",
      "Epoch 1. Loss: 0.6968058222778698, Train_acc 0.51171875\n",
      "\n",
      "Epoch 1. Loss: 0.6972263223750645, Train_acc 0.5111237582781457\n",
      "\n",
      "Epoch 1. Loss: 0.6961820334336092, Train_acc 0.511461759868421\n",
      "\n",
      "Epoch 1. Loss: 0.6950998970992205, Train_acc 0.5115910947712419\n",
      "\n",
      "Epoch 1. Loss: 0.6971321942621622, Train_acc 0.5114650974025974\n",
      "\n",
      "Epoch 1. Loss: 0.6989220656944055, Train_acc 0.5113407258064516\n",
      "\n",
      "Epoch 1. Loss: 0.7006475816362565, Train_acc 0.5109675480769231\n",
      "\n",
      "Epoch 1. Loss: 0.6994903585487722, Train_acc 0.5112460191082803\n",
      "\n",
      "Epoch 1. Loss: 0.6987941236353622, Train_acc 0.5108287183544303\n",
      "\n",
      "Epoch 1. Loss: 0.6979925070157682, Train_acc 0.5107606132075472\n",
      "\n",
      "Epoch 1. Loss: 0.6963885993317696, Train_acc 0.510986328125\n",
      "\n",
      "Epoch 1. Loss: 0.6973086032768427, Train_acc 0.5105784161490683\n",
      "\n",
      "Epoch 1. Loss: 0.6970733851343697, Train_acc 0.5105131172839507\n",
      "\n",
      "Epoch 1. Loss: 0.695863060666648, Train_acc 0.5109758435582822\n",
      "\n",
      "Epoch 1. Loss: 0.6953706912817307, Train_acc 0.5113376524390244\n",
      "\n",
      "Epoch 1. Loss: 0.6956223284562004, Train_acc 0.5111742424242425\n",
      "\n",
      "Epoch 1. Loss: 0.6956322701596832, Train_acc 0.5110598644578314\n",
      "\n",
      "Epoch 1. Loss: 0.6947769741854325, Train_acc 0.5112275449101796\n",
      "\n",
      "Epoch 1. Loss: 0.6931565362788369, Train_acc 0.5115327380952381\n",
      "\n",
      "Epoch 1. Loss: 0.6915004037538585, Train_acc 0.5122503698224852\n",
      "\n",
      "Epoch 1. Loss: 0.6903274222659543, Train_acc 0.5127757352941177\n",
      "\n",
      "Epoch 1. Loss: 0.690756258170081, Train_acc 0.512609649122807\n",
      "\n",
      "Epoch 1. Loss: 0.689095273733383, Train_acc 0.5131268168604651\n",
      "\n",
      "Epoch 1. Loss: 0.6875551418545057, Train_acc 0.5135928468208093\n",
      "\n",
      "Epoch 1. Loss: 0.6864879020526001, Train_acc 0.5136943247126436\n",
      "\n",
      "Epoch 1. Loss: 0.6874533672756543, Train_acc 0.5138392857142857\n",
      "\n",
      "Epoch 1. Loss: 0.686969302263253, Train_acc 0.5140269886363636\n",
      "\n",
      "Epoch 1. Loss: 0.6866490681466995, Train_acc 0.5145656779661016\n",
      "\n",
      "Epoch 1. Loss: 0.6831506943253461, Train_acc 0.5152738764044944\n",
      "\n",
      "Epoch 1. Loss: 0.6868989219261215, Train_acc 0.515013966480447\n",
      "\n",
      "Epoch 1. Loss: 0.6919324651354258, Train_acc 0.5146267361111111\n",
      "\n",
      "Epoch 1. Loss: 0.6907836605602836, Train_acc 0.5151502071823204\n",
      "\n",
      "Epoch 1. Loss: 0.6870563932801189, Train_acc 0.5161401098901099\n",
      "\n",
      "Epoch 1. Loss: 0.6892027951966139, Train_acc 0.5159665300546448\n",
      "\n",
      "Epoch 1. Loss: 0.6922055629811059, Train_acc 0.5157523777173914\n",
      "\n",
      "Epoch 1. Loss: 0.6927670789886747, Train_acc 0.5157939189189189\n",
      "\n",
      "Epoch 1. Loss: 0.6935097473677309, Train_acc 0.515625\n",
      "\n",
      "Epoch 1. Loss: 0.6957964150145332, Train_acc 0.5156667780748663\n",
      "\n",
      "Epoch 1. Loss: 0.6968884928257476, Train_acc 0.515625\n",
      "\n",
      "Epoch 1. Loss: 0.6977324184684047, Train_acc 0.5155009920634921\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1. Loss: 0.6975821581698737, Train_acc 0.5156661184210526\n",
      "\n",
      "Epoch 1. Loss: 0.6954570287958337, Train_acc 0.5159931282722513\n",
      "\n",
      "Epoch 1. Loss: 0.6995936698760586, Train_acc 0.515625\n",
      "\n",
      "Epoch 1. Loss: 0.6995521843772529, Train_acc 0.5157464378238342\n",
      "\n",
      "Epoch 1. Loss: 0.7018602246351301, Train_acc 0.5153833762886598\n",
      "\n",
      "Epoch 1. Loss: 0.7001549203074509, Train_acc 0.5155849358974359\n",
      "\n",
      "Epoch 1. Loss: 0.7015025257059813, Train_acc 0.51532\n",
      "\n",
      "Epoch 2. Loss: 0.7020762359191965, Train_acc 0.453125\n",
      "\n",
      "Epoch 2. Loss: 0.7023771341225497, Train_acc 0.48046875\n",
      "\n",
      "Epoch 2. Loss: 0.7038523020369701, Train_acc 0.4713541666666667\n",
      "\n",
      "Epoch 2. Loss: 0.7041801210066282, Train_acc 0.482421875\n",
      "\n",
      "Epoch 2. Loss: 0.703405189140493, Train_acc 0.4953125\n",
      "\n",
      "Epoch 2. Loss: 0.7031431504701267, Train_acc 0.4947916666666667\n",
      "\n",
      "Epoch 2. Loss: 0.702195552761676, Train_acc 0.49776785714285715\n",
      "\n",
      "Epoch 2. Loss: 0.7012004623788495, Train_acc 0.5078125\n",
      "\n",
      "Epoch 2. Loss: 0.7002105924467354, Train_acc 0.5060763888888888\n",
      "\n",
      "Epoch 2. Loss: 0.7002565097493032, Train_acc 0.50234375\n",
      "\n",
      "Epoch 2. Loss: 0.7006158559038133, Train_acc 0.49857954545454547\n",
      "\n",
      "Epoch 2. Loss: 0.7002713199121258, Train_acc 0.494140625\n",
      "\n",
      "Epoch 2. Loss: 0.699439792245254, Train_acc 0.4951923076923077\n",
      "\n",
      "Epoch 2. Loss: 0.699471725591682, Train_acc 0.49497767857142855\n",
      "\n",
      "Epoch 2. Loss: 0.7015456917005741, Train_acc 0.4890625\n",
      "\n",
      "Epoch 2. Loss: 0.70053912658554, Train_acc 0.49072265625\n",
      "\n",
      "Epoch 2. Loss: 0.6998635124480278, Train_acc 0.4885110294117647\n",
      "\n",
      "Epoch 2. Loss: 0.6980571560247735, Train_acc 0.4947916666666667\n",
      "\n",
      "Epoch 2. Loss: 0.6971450816557404, Train_acc 0.4975328947368421\n",
      "\n",
      "Epoch 2. Loss: 0.6970604036121604, Train_acc 0.498828125\n",
      "\n",
      "Epoch 2. Loss: 0.6935299909593795, Train_acc 0.5055803571428571\n",
      "\n",
      "Epoch 2. Loss: 0.6952628561689378, Train_acc 0.5046164772727273\n",
      "\n",
      "Epoch 2. Loss: 0.6975891294032861, Train_acc 0.5030570652173914\n",
      "\n",
      "Epoch 2. Loss: 0.6991204531744596, Train_acc 0.5\n",
      "\n",
      "Epoch 2. Loss: 0.6978256325503119, Train_acc 0.503125\n",
      "\n",
      "Epoch 2. Loss: 0.6977464515489276, Train_acc 0.5009014423076923\n",
      "\n",
      "Epoch 2. Loss: 0.6972397945989909, Train_acc 0.5014467592592593\n",
      "\n",
      "Epoch 2. Loss: 0.6969281896355518, Train_acc 0.501953125\n",
      "\n",
      "Epoch 2. Loss: 0.6972916183831783, Train_acc 0.5016163793103449\n",
      "\n",
      "Epoch 2. Loss: 0.6970729522075497, Train_acc 0.5026041666666666\n",
      "\n",
      "Epoch 2. Loss: 0.6965486370473722, Train_acc 0.5037802419354839\n",
      "\n",
      "Epoch 2. Loss: 0.6960589077725667, Train_acc 0.504638671875\n",
      "\n",
      "Epoch 2. Loss: 0.6961805391300909, Train_acc 0.5033143939393939\n",
      "\n",
      "Epoch 2. Loss: 0.695450183867442, Train_acc 0.5062040441176471\n",
      "\n",
      "Epoch 2. Loss: 0.6948102210036164, Train_acc 0.5091517857142858\n",
      "\n",
      "Epoch 2. Loss: 0.6943482125465196, Train_acc 0.5095486111111112\n",
      "\n",
      "Epoch 2. Loss: 0.6951126841900457, Train_acc 0.5082347972972973\n",
      "\n",
      "Epoch 2. Loss: 0.6942210961757042, Train_acc 0.5086348684210527\n",
      "\n",
      "Epoch 2. Loss: 0.6942005547324959, Train_acc 0.5074118589743589\n",
      "\n",
      "Epoch 2. Loss: 0.6931612306034693, Train_acc 0.5083984375\n",
      "\n",
      "Epoch 2. Loss: 0.6932441544410106, Train_acc 0.5083841463414634\n",
      "\n",
      "Epoch 2. Loss: 0.6924145893940196, Train_acc 0.5104166666666666\n",
      "\n",
      "Epoch 2. Loss: 0.691614938678342, Train_acc 0.5112645348837209\n",
      "\n",
      "Epoch 2. Loss: 0.6907873984295111, Train_acc 0.5111860795454546\n",
      "\n",
      "Epoch 2. Loss: 0.690810778986035, Train_acc 0.5111111111111111\n",
      "\n",
      "Epoch 2. Loss: 0.6902826004480883, Train_acc 0.5113790760869565\n",
      "\n",
      "Epoch 2. Loss: 0.6886057889391988, Train_acc 0.5131316489361702\n",
      "\n",
      "Epoch 2. Loss: 0.6884104283985504, Train_acc 0.51318359375\n",
      "\n",
      "Epoch 2. Loss: 0.6879938190284677, Train_acc 0.5135522959183674\n",
      "\n",
      "Epoch 2. Loss: 0.6877267013582564, Train_acc 0.51296875\n",
      "\n",
      "Epoch 2. Loss: 0.6880941495829501, Train_acc 0.5127144607843137\n",
      "\n",
      "Epoch 2. Loss: 0.6880820726335358, Train_acc 0.513671875\n",
      "\n",
      "Epoch 2. Loss: 0.6874561013263742, Train_acc 0.5141509433962265\n",
      "\n",
      "Epoch 2. Loss: 0.6891300530566824, Train_acc 0.5131655092592593\n",
      "\n",
      "Epoch 2. Loss: 0.6903399334550547, Train_acc 0.5119318181818182\n",
      "\n",
      "Epoch 2. Loss: 0.6891830777705296, Train_acc 0.5135323660714286\n",
      "\n",
      "Epoch 2. Loss: 0.6889168932062909, Train_acc 0.5148026315789473\n",
      "\n",
      "Epoch 2. Loss: 0.6880430979152792, Train_acc 0.5161637931034483\n",
      "\n",
      "Epoch 2. Loss: 0.6876521351295954, Train_acc 0.5162870762711864\n",
      "\n",
      "Epoch 2. Loss: 0.691096804352842, Train_acc 0.5154947916666667\n",
      "\n",
      "Epoch 2. Loss: 0.6917186574449321, Train_acc 0.5148565573770492\n",
      "\n",
      "Epoch 2. Loss: 0.6895356771031184, Train_acc 0.5167590725806451\n",
      "\n",
      "Epoch 2. Loss: 0.6880658504378048, Train_acc 0.5181051587301587\n",
      "\n",
      "Epoch 2. Loss: 0.6881143424222989, Train_acc 0.518798828125\n",
      "\n",
      "Epoch 2. Loss: 0.6880195713022461, Train_acc 0.5197115384615385\n",
      "\n",
      "Epoch 2. Loss: 0.688034872053186, Train_acc 0.5197679924242424\n",
      "\n",
      "Epoch 2. Loss: 0.687269389484632, Train_acc 0.5208722014925373\n",
      "\n",
      "Epoch 2. Loss: 0.6856277881750238, Train_acc 0.5229779411764706\n",
      "\n",
      "Epoch 2. Loss: 0.6854348926563953, Train_acc 0.5240036231884058\n",
      "\n",
      "Epoch 2. Loss: 0.68467700023829, Train_acc 0.5246651785714286\n",
      "\n",
      "Epoch 2. Loss: 0.6845408577267444, Train_acc 0.5253080985915493\n",
      "\n",
      "Epoch 2. Loss: 0.6847646622548208, Train_acc 0.5250651041666666\n",
      "\n",
      "Epoch 2. Loss: 0.6830358197113608, Train_acc 0.5262200342465754\n",
      "\n",
      "Epoch 2. Loss: 0.6825263818938198, Train_acc 0.5258657094594594\n",
      "\n",
      "Epoch 2. Loss: 0.6811598230158086, Train_acc 0.5263541666666667\n",
      "\n",
      "Epoch 2. Loss: 0.6814073165137883, Train_acc 0.5267269736842105\n",
      "\n",
      "Epoch 2. Loss: 0.6803420340906963, Train_acc 0.5276988636363636\n",
      "\n",
      "Epoch 2. Loss: 0.6791375239990399, Train_acc 0.5282451923076923\n",
      "\n",
      "Epoch 2. Loss: 0.6795869493754727, Train_acc 0.5291732594936709\n",
      "\n",
      "Epoch 2. Loss: 0.6763459048514386, Train_acc 0.53037109375\n",
      "\n",
      "Epoch 2. Loss: 0.676606899664833, Train_acc 0.5302854938271605\n",
      "\n",
      "Epoch 2. Loss: 0.6735792751604621, Train_acc 0.5314405487804879\n",
      "\n",
      "Epoch 2. Loss: 0.6709863062644873, Train_acc 0.5326618975903614\n",
      "\n",
      "Epoch 2. Loss: 0.6713326498220749, Train_acc 0.5325520833333334\n",
      "\n",
      "Epoch 2. Loss: 0.6689634255484093, Train_acc 0.5337316176470588\n",
      "\n",
      "Epoch 2. Loss: 0.6727183519526138, Train_acc 0.5333393895348837\n",
      "\n",
      "Epoch 2. Loss: 0.6684605531743598, Train_acc 0.5342133620689655\n",
      "\n",
      "Epoch 2. Loss: 0.6660821425483912, Train_acc 0.5355113636363636\n",
      "\n",
      "Epoch 2. Loss: 0.6662820328086277, Train_acc 0.5357268258426966\n",
      "\n",
      "Epoch 2. Loss: 0.663900895310312, Train_acc 0.5368923611111112\n",
      "\n",
      "Epoch 2. Loss: 0.6684631318386223, Train_acc 0.5366586538461539\n",
      "\n",
      "Epoch 2. Loss: 0.6663747379662834, Train_acc 0.5376188858695652\n",
      "\n",
      "Epoch 2. Loss: 0.6647592082156756, Train_acc 0.5383904569892473\n",
      "\n",
      "Epoch 2. Loss: 0.6649348939538615, Train_acc 0.5391456117021277\n",
      "\n",
      "Epoch 2. Loss: 0.6632444624674873, Train_acc 0.5401315789473684\n",
      "\n",
      "Epoch 2. Loss: 0.6618702260767718, Train_acc 0.541015625\n",
      "\n",
      "Epoch 2. Loss: 0.66865358186799, Train_acc 0.5403511597938144\n",
      "\n",
      "Epoch 2. Loss: 0.6729941198203359, Train_acc 0.5400191326530612\n",
      "\n",
      "Epoch 2. Loss: 0.6752798523581082, Train_acc 0.5395359848484849\n",
      "\n",
      "Epoch 2. Loss: 0.6755262761780072, Train_acc 0.539453125\n",
      "\n",
      "[Epoch 2 Batch 100] Loss: 0.674053622734706 Training: accuracy=0.540532\n",
      "Epoch 2. Loss: 0.674053622734706, Train_acc 0.5405321782178217\n",
      "\n",
      "Epoch 2. Loss: 0.6766741396059041, Train_acc 0.5406709558823529\n",
      "\n",
      "Epoch 2. Loss: 0.6794108797075847, Train_acc 0.5408828883495146\n",
      "\n",
      "Epoch 2. Loss: 0.680322836246714, Train_acc 0.5406400240384616\n",
      "\n",
      "Epoch 2. Loss: 0.6770606610834226, Train_acc 0.5419642857142857\n",
      "\n",
      "Epoch 2. Loss: 0.675644151001539, Train_acc 0.5428213443396226\n",
      "\n",
      "Epoch 2. Loss: 0.6761333629155453, Train_acc 0.5432973130841121\n",
      "\n",
      "Epoch 2. Loss: 0.6736586765644814, Train_acc 0.5442708333333334\n",
      "\n",
      "Epoch 2. Loss: 0.6712702402053355, Train_acc 0.5453698394495413\n",
      "\n",
      "Epoch 2. Loss: 0.6711798389474821, Train_acc 0.5459517045454545\n",
      "\n",
      "Epoch 2. Loss: 0.6716331493604426, Train_acc 0.5460304054054054\n",
      "\n",
      "Epoch 2. Loss: 0.6700602875722865, Train_acc 0.5466657366071429\n",
      "\n",
      "Epoch 2. Loss: 0.6670706367409307, Train_acc 0.5476355088495575\n",
      "\n",
      "Epoch 2. Loss: 0.6680707063599894, Train_acc 0.5478344298245614\n",
      "\n",
      "Epoch 2. Loss: 0.6678530567578498, Train_acc 0.5480978260869566\n",
      "\n",
      "Epoch 2. Loss: 0.6681411558710357, Train_acc 0.5484913793103449\n",
      "\n",
      "Epoch 2. Loss: 0.6651971007278104, Train_acc 0.5489449786324786\n",
      "\n",
      "Epoch 2. Loss: 0.6613530515036469, Train_acc 0.550052966101695\n",
      "\n",
      "Epoch 2. Loss: 0.6572422920228378, Train_acc 0.5511423319327731\n",
      "\n",
      "Epoch 2. Loss: 0.6525519673730138, Train_acc 0.5518229166666667\n",
      "\n",
      "Epoch 2. Loss: 0.6545271323357704, Train_acc 0.5520402892561983\n",
      "\n",
      "Epoch 2. Loss: 0.6553887348980918, Train_acc 0.5528944672131147\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2. Loss: 0.6570613463173403, Train_acc 0.5533536585365854\n",
      "\n",
      "Epoch 2. Loss: 0.6665207933887922, Train_acc 0.5535534274193549\n",
      "\n",
      "Epoch 2. Loss: 0.6774810664211288, Train_acc 0.553125\n",
      "\n",
      "Epoch 2. Loss: 0.6742299657184996, Train_acc 0.5536334325396826\n",
      "\n",
      "Epoch 2. Loss: 0.6778430874156164, Train_acc 0.5535187007874016\n",
      "\n",
      "Epoch 2. Loss: 0.6851719619340187, Train_acc 0.55328369140625\n",
      "\n",
      "Epoch 2. Loss: 0.687853562966569, Train_acc 0.5530523255813954\n",
      "\n",
      "Epoch 2. Loss: 0.6865132464190576, Train_acc 0.5533052884615385\n",
      "\n",
      "Epoch 2. Loss: 0.684998710145377, Train_acc 0.5539718511450382\n",
      "\n",
      "Epoch 2. Loss: 0.6841179482845869, Train_acc 0.5545099431818182\n",
      "\n",
      "Epoch 2. Loss: 0.6828942852653629, Train_acc 0.5544525375939849\n",
      "\n",
      "Epoch 2. Loss: 0.6839275500867575, Train_acc 0.5544542910447762\n",
      "\n",
      "Epoch 2. Loss: 0.6887805648172328, Train_acc 0.5538194444444444\n",
      "\n",
      "Epoch 2. Loss: 0.6871696401409294, Train_acc 0.5539981617647058\n",
      "\n",
      "Epoch 2. Loss: 0.6910078366492974, Train_acc 0.5532048357664233\n",
      "\n",
      "Epoch 2. Loss: 0.6889780855084765, Train_acc 0.5533854166666666\n",
      "\n",
      "Epoch 2. Loss: 0.6903340663825251, Train_acc 0.5530013489208633\n",
      "\n",
      "Epoch 2. Loss: 0.6910978775901894, Train_acc 0.5526785714285715\n",
      "\n",
      "Epoch 2. Loss: 0.6898779173210234, Train_acc 0.5528590425531915\n",
      "\n",
      "Epoch 2. Loss: 0.687642440156487, Train_acc 0.5532570422535211\n",
      "\n",
      "Epoch 2. Loss: 0.6880822524038083, Train_acc 0.5533763111888111\n",
      "\n",
      "Epoch 2. Loss: 0.6858307550496274, Train_acc 0.5538736979166666\n",
      "\n",
      "Epoch 2. Loss: 0.6849348333608879, Train_acc 0.5540948275862069\n",
      "\n",
      "Epoch 2. Loss: 0.6837547827182806, Train_acc 0.5547945205479452\n",
      "\n",
      "Epoch 2. Loss: 0.6824339695351062, Train_acc 0.5553252551020408\n",
      "\n",
      "Epoch 2. Loss: 0.6826579333165351, Train_acc 0.5552681587837838\n",
      "\n",
      "Epoch 2. Loss: 0.6812601948516724, Train_acc 0.5555788590604027\n",
      "\n",
      "Epoch 2. Loss: 0.68162731511031, Train_acc 0.5556770833333333\n",
      "\n",
      "Epoch 2. Loss: 0.6807504551050163, Train_acc 0.5557740066225165\n",
      "\n",
      "Epoch 2. Loss: 0.6797028949651507, Train_acc 0.5563322368421053\n",
      "\n",
      "Epoch 2. Loss: 0.6785852763766098, Train_acc 0.5563214869281046\n",
      "\n",
      "Epoch 2. Loss: 0.6758492100579185, Train_acc 0.5569703733766234\n",
      "\n",
      "Epoch 2. Loss: 0.672678599507449, Train_acc 0.5574596774193549\n",
      "\n",
      "Epoch 2. Loss: 0.676030847207461, Train_acc 0.5566907051282052\n",
      "\n",
      "Epoch 2. Loss: 0.6779971236965843, Train_acc 0.5564789012738853\n",
      "\n",
      "Epoch 2. Loss: 0.6753216667457033, Train_acc 0.5568136867088608\n",
      "\n",
      "Epoch 2. Loss: 0.6753567651048549, Train_acc 0.5568003144654088\n",
      "\n",
      "Epoch 2. Loss: 0.676988368791513, Train_acc 0.556396484375\n",
      "\n",
      "Epoch 2. Loss: 0.676497667040383, Train_acc 0.5562402950310559\n",
      "\n",
      "Epoch 2. Loss: 0.6745701393538313, Train_acc 0.5565200617283951\n",
      "\n",
      "Epoch 2. Loss: 0.6752288545119999, Train_acc 0.5565088190184049\n",
      "\n",
      "Epoch 2. Loss: 0.6770374481333706, Train_acc 0.5562118902439024\n",
      "\n",
      "Epoch 2. Loss: 0.6712110732007098, Train_acc 0.5570075757575758\n",
      "\n",
      "Epoch 2. Loss: 0.6719034755833214, Train_acc 0.5577936746987951\n",
      "\n",
      "Epoch 2. Loss: 0.6770673910922348, Train_acc 0.5575879491017964\n",
      "\n",
      "Epoch 2. Loss: 0.6755669760835058, Train_acc 0.5578031994047619\n",
      "\n",
      "Epoch 2. Loss: 0.6737657888053554, Train_acc 0.5581545857988166\n",
      "\n",
      "Epoch 2. Loss: 0.6744709166871338, Train_acc 0.5584558823529412\n",
      "\n",
      "Epoch 2. Loss: 0.6766243296551849, Train_acc 0.5584338450292398\n",
      "\n",
      "Epoch 2. Loss: 0.6747181043942105, Train_acc 0.55859375\n",
      "\n",
      "Epoch 2. Loss: 0.6739962422179578, Train_acc 0.5590679190751445\n",
      "\n",
      "Epoch 2. Loss: 0.6728973200911937, Train_acc 0.5591774425287356\n",
      "\n",
      "Epoch 2. Loss: 0.6741539964969151, Train_acc 0.5591517857142857\n",
      "\n",
      "Epoch 2. Loss: 0.6757705387379402, Train_acc 0.5592595880681818\n",
      "\n",
      "Epoch 2. Loss: 0.6760873237465925, Train_acc 0.5591454802259888\n",
      "\n",
      "Epoch 2. Loss: 0.6730355178608096, Train_acc 0.5593837780898876\n",
      "\n",
      "Epoch 2. Loss: 0.6716425676906345, Train_acc 0.5597067039106145\n",
      "\n",
      "Epoch 2. Loss: 0.6651217692879651, Train_acc 0.5605034722222222\n",
      "\n",
      "Epoch 2. Loss: 0.6627932089973522, Train_acc 0.5609892955801105\n",
      "\n",
      "Epoch 2. Loss: 0.6655747978456944, Train_acc 0.5608688186813187\n",
      "\n",
      "Epoch 2. Loss: 0.6603947063000318, Train_acc 0.561646174863388\n",
      "\n",
      "Epoch 2. Loss: 0.6630811553935394, Train_acc 0.5617357336956522\n",
      "\n",
      "Epoch 2. Loss: 0.6624968345529008, Train_acc 0.562035472972973\n",
      "\n",
      "Epoch 2. Loss: 0.6595247652142794, Train_acc 0.5624159946236559\n",
      "\n",
      "Epoch 2. Loss: 0.6639145314105944, Train_acc 0.5622075534759359\n",
      "\n",
      "Epoch 2. Loss: 0.662061241216236, Train_acc 0.5624584441489362\n",
      "\n",
      "Epoch 2. Loss: 0.6585979464174273, Train_acc 0.5629960317460317\n",
      "\n",
      "Epoch 2. Loss: 0.6597890021670725, Train_acc 0.5630345394736842\n",
      "\n",
      "Epoch 2. Loss: 0.6604510571600972, Train_acc 0.5631953534031413\n",
      "\n",
      "Epoch 2. Loss: 0.6613086962141376, Train_acc 0.5633951822916666\n",
      "\n",
      "Epoch 2. Loss: 0.6581418487523002, Train_acc 0.563916774611399\n",
      "\n",
      "Epoch 2. Loss: 0.6580875968719127, Train_acc 0.5639094716494846\n",
      "\n",
      "Epoch 2. Loss: 0.6556994190023484, Train_acc 0.5643429487179488\n",
      "\n",
      "Epoch 2. Loss: 0.6541463139837512, Train_acc 0.56452\n",
      "\n",
      "Epoch 3. Loss: 0.651571643637317, Train_acc 0.6484375\n",
      "\n",
      "Epoch 3. Loss: 0.6499152651012221, Train_acc 0.64453125\n",
      "\n",
      "Epoch 3. Loss: 0.6472581628483783, Train_acc 0.6536458333333334\n",
      "\n",
      "Epoch 3. Loss: 0.6432116273214445, Train_acc 0.6640625\n",
      "\n",
      "Epoch 3. Loss: 0.6398160555812741, Train_acc 0.6625\n",
      "\n",
      "Epoch 3. Loss: 0.6385735838579856, Train_acc 0.6653645833333334\n",
      "\n",
      "Epoch 3. Loss: 0.6390008421809426, Train_acc 0.6584821428571429\n",
      "\n",
      "Epoch 3. Loss: 0.6393168054882542, Train_acc 0.6611328125\n",
      "\n",
      "Epoch 3. Loss: 0.6398613407788148, Train_acc 0.6579861111111112\n",
      "\n",
      "Epoch 3. Loss: 0.6428695399681453, Train_acc 0.65\n",
      "\n",
      "Epoch 3. Loss: 0.6452984105753653, Train_acc 0.6441761363636364\n",
      "\n",
      "Epoch 3. Loss: 0.6488137207515018, Train_acc 0.6432291666666666\n",
      "\n",
      "Epoch 3. Loss: 0.6461649383980312, Train_acc 0.6466346153846154\n",
      "\n",
      "Epoch 3. Loss: 0.6474064987193, Train_acc 0.6434151785714286\n",
      "\n",
      "Epoch 3. Loss: 0.6497876764497565, Train_acc 0.6411458333333333\n",
      "\n",
      "Epoch 3. Loss: 0.6456154693211383, Train_acc 0.64453125\n",
      "\n",
      "Epoch 3. Loss: 0.6522113063077868, Train_acc 0.6355698529411765\n",
      "\n",
      "Epoch 3. Loss: 0.6493207792765565, Train_acc 0.6384548611111112\n",
      "\n",
      "Epoch 3. Loss: 0.6448109907203914, Train_acc 0.639391447368421\n",
      "\n",
      "Epoch 3. Loss: 0.6448586072588564, Train_acc 0.6390625\n",
      "\n",
      "Epoch 3. Loss: 0.6386259215531886, Train_acc 0.6413690476190477\n",
      "\n",
      "Epoch 3. Loss: 0.6375853852145201, Train_acc 0.6416903409090909\n",
      "\n",
      "Epoch 3. Loss: 0.6375366958122546, Train_acc 0.6413043478260869\n",
      "\n",
      "Epoch 3. Loss: 0.6366745572216298, Train_acc 0.6402994791666666\n",
      "\n",
      "Epoch 3. Loss: 0.6387692160243081, Train_acc 0.6390625\n",
      "\n",
      "Epoch 3. Loss: 0.6367344617993493, Train_acc 0.6403245192307693\n",
      "\n",
      "Epoch 3. Loss: 0.6350093746320182, Train_acc 0.6414930555555556\n",
      "\n",
      "Epoch 3. Loss: 0.6356140909316338, Train_acc 0.6403459821428571\n",
      "\n",
      "Epoch 3. Loss: 0.6367064479937133, Train_acc 0.6400862068965517\n",
      "\n",
      "Epoch 3. Loss: 0.6330843535616973, Train_acc 0.64140625\n",
      "\n",
      "Epoch 3. Loss: 0.6326624185641092, Train_acc 0.641633064516129\n",
      "\n",
      "Epoch 3. Loss: 0.6339322952150835, Train_acc 0.640625\n",
      "\n",
      "Epoch 3. Loss: 0.6325106049525321, Train_acc 0.6403882575757576\n",
      "\n",
      "Epoch 3. Loss: 0.6363540612114292, Train_acc 0.6387867647058824\n",
      "\n",
      "Epoch 3. Loss: 0.6384744157599945, Train_acc 0.6363839285714286\n",
      "\n",
      "Epoch 3. Loss: 0.6397480169124192, Train_acc 0.6356336805555556\n",
      "\n",
      "Epoch 3. Loss: 0.6471222459542858, Train_acc 0.6332347972972973\n",
      "\n",
      "Epoch 3. Loss: 0.6462061005176402, Train_acc 0.6342516447368421\n",
      "\n",
      "Epoch 3. Loss: 0.6498481152064768, Train_acc 0.6318108974358975\n",
      "\n",
      "Epoch 3. Loss: 0.6451959238297196, Train_acc 0.6328125\n",
      "\n",
      "Epoch 3. Loss: 0.6420724653464364, Train_acc 0.6331935975609756\n",
      "\n",
      "Epoch 3. Loss: 0.6389313933189339, Train_acc 0.6331845238095238\n",
      "\n",
      "Epoch 3. Loss: 0.6358620044829512, Train_acc 0.634265988372093\n",
      "\n",
      "Epoch 3. Loss: 0.6365697727121769, Train_acc 0.6349431818181818\n",
      "\n",
      "Epoch 3. Loss: 0.6393247317240708, Train_acc 0.6342013888888889\n",
      "\n",
      "Epoch 3. Loss: 0.634949756053037, Train_acc 0.6355298913043478\n",
      "\n",
      "Epoch 3. Loss: 0.6279695025565742, Train_acc 0.6387965425531915\n",
      "\n",
      "Epoch 3. Loss: 0.6281385712160932, Train_acc 0.638671875\n",
      "\n",
      "Epoch 3. Loss: 0.6331593774855973, Train_acc 0.6380739795918368\n",
      "\n",
      "Epoch 3. Loss: 0.6299497410447158, Train_acc 0.63859375\n",
      "\n",
      "Epoch 3. Loss: 0.629489462803968, Train_acc 0.6386335784313726\n",
      "\n",
      "Epoch 3. Loss: 0.6343768905679895, Train_acc 0.6370192307692307\n",
      "\n",
      "Epoch 3. Loss: 0.6371832493913633, Train_acc 0.636497641509434\n",
      "\n",
      "Epoch 3. Loss: 0.635948038456362, Train_acc 0.6361400462962963\n",
      "\n",
      "Epoch 3. Loss: 0.6496159461356892, Train_acc 0.6328125\n",
      "\n",
      "Epoch 3. Loss: 0.6517116988197887, Train_acc 0.6316964285714286\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3. Loss: 0.647282954856389, Train_acc 0.6330866228070176\n",
      "\n",
      "Epoch 3. Loss: 0.6499856264632642, Train_acc 0.6318696120689655\n",
      "\n",
      "Epoch 3. Loss: 0.6486726955689519, Train_acc 0.6308262711864406\n",
      "\n",
      "Epoch 3. Loss: 0.6474797448024926, Train_acc 0.630859375\n",
      "\n",
      "Epoch 3. Loss: 0.6488965499853293, Train_acc 0.6306352459016393\n",
      "\n",
      "Epoch 3. Loss: 0.6482981695343732, Train_acc 0.6306703629032258\n",
      "\n",
      "Epoch 3. Loss: 0.6519880342730594, Train_acc 0.6294642857142857\n",
      "\n",
      "Epoch 3. Loss: 0.6476346059067887, Train_acc 0.630126953125\n",
      "\n",
      "Epoch 3. Loss: 0.647698384829507, Train_acc 0.6301682692307692\n",
      "\n",
      "Epoch 3. Loss: 0.6516215404642931, Train_acc 0.6300899621212122\n",
      "\n",
      "Epoch 3. Loss: 0.6495700717663745, Train_acc 0.6300139925373134\n",
      "\n",
      "Epoch 3. Loss: 0.65016176468396, Train_acc 0.6299402573529411\n",
      "\n",
      "Epoch 3. Loss: 0.6479225054347261, Train_acc 0.6308876811594203\n",
      "\n",
      "Epoch 3. Loss: 0.6498648430374632, Train_acc 0.6296875\n",
      "\n",
      "Epoch 3. Loss: 0.6506632601142558, Train_acc 0.6290713028169014\n",
      "\n",
      "Epoch 3. Loss: 0.6462893398035138, Train_acc 0.6298828125\n",
      "\n",
      "Epoch 3. Loss: 0.6468305270160944, Train_acc 0.630244006849315\n",
      "\n",
      "Epoch 3. Loss: 0.6435769152896742, Train_acc 0.6308065878378378\n",
      "\n",
      "Epoch 3. Loss: 0.6392303126088208, Train_acc 0.6315625\n",
      "\n",
      "Epoch 3. Loss: 0.6378747597662889, Train_acc 0.6319901315789473\n",
      "\n",
      "Epoch 3. Loss: 0.6379351474638238, Train_acc 0.6310876623376623\n",
      "\n",
      "Epoch 3. Loss: 0.6361008695777167, Train_acc 0.6318108974358975\n",
      "\n",
      "Epoch 3. Loss: 0.6395560811772265, Train_acc 0.631131329113924\n",
      "\n",
      "Epoch 3. Loss: 0.6387989560497688, Train_acc 0.63056640625\n",
      "\n",
      "Epoch 3. Loss: 0.6283189213037091, Train_acc 0.6317515432098766\n",
      "\n",
      "Epoch 3. Loss: 0.6250436802887558, Train_acc 0.6325266768292683\n",
      "\n",
      "Epoch 3. Loss: 0.6178381651804125, Train_acc 0.6333772590361446\n",
      "\n",
      "Epoch 3. Loss: 0.6183852383642146, Train_acc 0.6335565476190477\n",
      "\n",
      "Epoch 3. Loss: 0.6104022469355538, Train_acc 0.6347426470588236\n",
      "\n",
      "Epoch 3. Loss: 0.6064406817764527, Train_acc 0.635719476744186\n",
      "\n",
      "Epoch 3. Loss: 0.6036852883348305, Train_acc 0.6363146551724138\n",
      "\n",
      "Epoch 3. Loss: 0.6065566677197313, Train_acc 0.6363636363636364\n",
      "\n",
      "Epoch 3. Loss: 0.6167280201623883, Train_acc 0.6357092696629213\n",
      "\n",
      "Epoch 3. Loss: 0.6214281789520424, Train_acc 0.6356770833333333\n",
      "\n",
      "Epoch 3. Loss: 0.6198536043219901, Train_acc 0.6361607142857143\n",
      "\n",
      "Epoch 3. Loss: 0.620315970616323, Train_acc 0.6362092391304348\n",
      "\n",
      "Epoch 3. Loss: 0.6194884910912355, Train_acc 0.6363407258064516\n",
      "\n",
      "Epoch 3. Loss: 0.6191613556204176, Train_acc 0.6366356382978723\n",
      "\n",
      "Epoch 3. Loss: 0.6180615199736895, Train_acc 0.6372532894736842\n",
      "\n",
      "Epoch 3. Loss: 0.6135773277102836, Train_acc 0.6388346354166666\n",
      "\n",
      "Epoch 3. Loss: 0.6118854715662237, Train_acc 0.6388530927835051\n",
      "\n",
      "Epoch 3. Loss: 0.6112604052636358, Train_acc 0.6397480867346939\n",
      "\n",
      "Epoch 3. Loss: 0.6097286800277232, Train_acc 0.6403093434343434\n",
      "\n",
      "Epoch 3. Loss: 0.6110207611082791, Train_acc 0.64078125\n",
      "\n",
      "[Epoch 3 Batch 100] Loss: 0.6112024164580225 Training: accuracy=0.641166\n",
      "Epoch 3. Loss: 0.6112024164580225, Train_acc 0.6411664603960396\n",
      "\n",
      "Epoch 3. Loss: 0.6106576600417125, Train_acc 0.6413143382352942\n",
      "\n",
      "Epoch 3. Loss: 0.6088127564261521, Train_acc 0.642066140776699\n",
      "\n",
      "Epoch 3. Loss: 0.6151764277401714, Train_acc 0.6419771634615384\n",
      "\n",
      "Epoch 3. Loss: 0.6189902738138868, Train_acc 0.6415178571428571\n",
      "\n",
      "Epoch 3. Loss: 0.6213532491390259, Train_acc 0.6418042452830188\n",
      "\n",
      "Epoch 3. Loss: 0.6172439042208508, Train_acc 0.6423773364485982\n",
      "\n",
      "Epoch 3. Loss: 0.6197792098055407, Train_acc 0.6426504629629629\n",
      "\n",
      "Epoch 3. Loss: 0.6247107093152515, Train_acc 0.6422018348623854\n",
      "\n",
      "Epoch 3. Loss: 0.6262936685637038, Train_acc 0.6421875\n",
      "\n",
      "Epoch 3. Loss: 0.6277975762625398, Train_acc 0.6425253378378378\n",
      "\n",
      "Epoch 3. Loss: 0.625794195360529, Train_acc 0.6427176339285714\n",
      "\n",
      "Epoch 3. Loss: 0.6215571134328136, Train_acc 0.643183075221239\n",
      "\n",
      "Epoch 3. Loss: 0.6209016951059659, Train_acc 0.6435718201754386\n",
      "\n",
      "Epoch 3. Loss: 0.6167804341437245, Train_acc 0.6442934782608696\n",
      "\n",
      "Epoch 3. Loss: 0.6201682037939272, Train_acc 0.6443292025862069\n",
      "\n",
      "Epoch 3. Loss: 0.6228758824017324, Train_acc 0.6443643162393162\n",
      "\n",
      "Epoch 3. Loss: 0.6252642928493033, Train_acc 0.6445974576271186\n",
      "\n",
      "Epoch 3. Loss: 0.6210886054276237, Train_acc 0.6448266806722689\n",
      "\n",
      "Epoch 3. Loss: 0.6231227588390239, Train_acc 0.6445963541666667\n",
      "\n",
      "Epoch 3. Loss: 0.6247277085544104, Train_acc 0.6447572314049587\n",
      "\n",
      "Epoch 3. Loss: 0.6225922070051523, Train_acc 0.645171618852459\n",
      "\n",
      "Epoch 3. Loss: 0.6199467625116072, Train_acc 0.6452616869918699\n",
      "\n",
      "Epoch 3. Loss: 0.6263179164434757, Train_acc 0.6447202620967742\n",
      "\n",
      "Epoch 3. Loss: 0.6255696101163584, Train_acc 0.644625\n",
      "\n",
      "Epoch 3. Loss: 0.6173879161335312, Train_acc 0.6453373015873016\n",
      "\n",
      "Epoch 3. Loss: 0.6104462016991332, Train_acc 0.6459768700787402\n",
      "\n",
      "Epoch 3. Loss: 0.6096930506263574, Train_acc 0.64605712890625\n",
      "\n",
      "Epoch 3. Loss: 0.611160230854249, Train_acc 0.646015019379845\n",
      "\n",
      "Epoch 3. Loss: 0.6155868818334603, Train_acc 0.6461538461538462\n",
      "\n",
      "Epoch 3. Loss: 0.6156606480454085, Train_acc 0.6459327290076335\n",
      "\n",
      "Epoch 3. Loss: 0.616990703789116, Train_acc 0.6463068181818182\n",
      "\n",
      "Epoch 3. Loss: 0.6151016698310267, Train_acc 0.6466165413533834\n",
      "\n",
      "Epoch 3. Loss: 0.6196056734945915, Train_acc 0.6461637126865671\n",
      "\n",
      "Epoch 3. Loss: 0.6193068025791534, Train_acc 0.6461805555555555\n",
      "\n",
      "Epoch 3. Loss: 0.622854375685801, Train_acc 0.6463120404411765\n",
      "\n",
      "Epoch 3. Loss: 0.6264314745475799, Train_acc 0.6458713503649635\n",
      "\n",
      "Epoch 3. Loss: 0.6273417080590085, Train_acc 0.6456068840579711\n",
      "\n",
      "Epoch 3. Loss: 0.6252241735293528, Train_acc 0.645908273381295\n",
      "\n",
      "Epoch 3. Loss: 0.624694246468013, Train_acc 0.6457589285714286\n",
      "\n",
      "Epoch 3. Loss: 0.623441700712203, Train_acc 0.6459995567375887\n",
      "\n",
      "Epoch 3. Loss: 0.6198544304746618, Train_acc 0.6464018485915493\n",
      "\n",
      "Epoch 3. Loss: 0.6177827001671402, Train_acc 0.6469624125874126\n",
      "\n",
      "Epoch 3. Loss: 0.6210132492536672, Train_acc 0.6466471354166666\n",
      "\n",
      "Epoch 3. Loss: 0.6220910238880845, Train_acc 0.6467133620689656\n",
      "\n",
      "Epoch 3. Loss: 0.621502240388894, Train_acc 0.6466716609589042\n",
      "\n",
      "Epoch 3. Loss: 0.6216805933916306, Train_acc 0.6469494047619048\n",
      "\n",
      "Epoch 3. Loss: 0.613688280493355, Train_acc 0.6475401182432432\n",
      "\n",
      "Epoch 3. Loss: 0.6125016483458902, Train_acc 0.6478607382550335\n",
      "\n",
      "Epoch 3. Loss: 0.6096153145545445, Train_acc 0.6480208333333334\n",
      "\n",
      "Epoch 3. Loss: 0.6075894372624506, Train_acc 0.648385761589404\n",
      "\n",
      "Epoch 3. Loss: 0.6111899140741542, Train_acc 0.6483861019736842\n",
      "\n",
      "Epoch 3. Loss: 0.6088159730970367, Train_acc 0.6484375\n",
      "\n",
      "Epoch 3. Loss: 0.609481839919642, Train_acc 0.6484375\n",
      "\n",
      "Epoch 3. Loss: 0.6049291091423231, Train_acc 0.648991935483871\n",
      "\n",
      "Epoch 3. Loss: 0.6146070299083887, Train_acc 0.6485877403846154\n",
      "\n",
      "Epoch 3. Loss: 0.6129536513270347, Train_acc 0.6486863057324841\n",
      "\n",
      "Epoch 3. Loss: 0.606412722210414, Train_acc 0.649278085443038\n",
      "\n",
      "Epoch 3. Loss: 0.6029200138512195, Train_acc 0.6499115566037735\n",
      "\n",
      "Epoch 3. Loss: 0.5952056332108028, Train_acc 0.650439453125\n",
      "\n",
      "Epoch 3. Loss: 0.5991905287215097, Train_acc 0.6502814440993789\n",
      "\n",
      "Epoch 3. Loss: 0.5926697095014736, Train_acc 0.6505594135802469\n",
      "\n",
      "Epoch 3. Loss: 0.5844764208595232, Train_acc 0.6512653374233128\n",
      "\n",
      "Epoch 3. Loss: 0.583006658774639, Train_acc 0.6515815548780488\n",
      "\n",
      "Epoch 3. Loss: 0.5815754103261455, Train_acc 0.6522727272727272\n",
      "\n",
      "Epoch 3. Loss: 0.5834360987780891, Train_acc 0.6524849397590361\n",
      "\n",
      "Epoch 3. Loss: 0.5914613071833613, Train_acc 0.6523671407185628\n",
      "\n",
      "Epoch 3. Loss: 0.5926415500421431, Train_acc 0.6524832589285714\n",
      "\n",
      "Epoch 3. Loss: 0.592819748286525, Train_acc 0.652967825443787\n",
      "\n",
      "Epoch 3. Loss: 0.5915388387120839, Train_acc 0.6533547794117647\n",
      "\n",
      "Epoch 3. Loss: 0.5891688038418064, Train_acc 0.6537372076023392\n",
      "\n",
      "Epoch 3. Loss: 0.5853945287623438, Train_acc 0.6541606104651163\n",
      "\n",
      "Epoch 3. Loss: 0.5790522223018199, Train_acc 0.6548500722543352\n",
      "\n",
      "Epoch 3. Loss: 0.5836530737849405, Train_acc 0.6548581178160919\n",
      "\n",
      "Epoch 3. Loss: 0.5845399569963513, Train_acc 0.6549553571428571\n",
      "\n",
      "Epoch 3. Loss: 0.5772695605303435, Train_acc 0.6554066051136364\n",
      "\n",
      "Epoch 3. Loss: 0.5727291164707173, Train_acc 0.6558968926553672\n",
      "\n",
      "Epoch 3. Loss: 0.5643734566489783, Train_acc 0.6565572331460674\n",
      "\n",
      "Epoch 3. Loss: 0.5730221002209122, Train_acc 0.65625\n",
      "\n",
      "Epoch 3. Loss: 0.5775204535342396, Train_acc 0.65625\n",
      "\n",
      "Epoch 3. Loss: 0.5760149153486319, Train_acc 0.6568111187845304\n",
      "\n",
      "Epoch 3. Loss: 0.5678837709798301, Train_acc 0.6576236263736264\n",
      "\n",
      "Epoch 3. Loss: 0.5704175245619313, Train_acc 0.657744193989071\n",
      "\n",
      "Epoch 3. Loss: 0.5673551212420906, Train_acc 0.6581182065217391\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3. Loss: 0.5654445574287337, Train_acc 0.6585304054054054\n",
      "\n",
      "Epoch 3. Loss: 0.5612933831456687, Train_acc 0.659148185483871\n",
      "\n",
      "Epoch 3. Loss: 0.5677048859337018, Train_acc 0.6591326871657754\n",
      "\n",
      "Epoch 3. Loss: 0.5675070074801785, Train_acc 0.6592835771276596\n",
      "\n",
      "Epoch 3. Loss: 0.5696242500190564, Train_acc 0.6594742063492064\n",
      "\n",
      "Epoch 3. Loss: 0.5781198783675994, Train_acc 0.6592927631578948\n",
      "\n",
      "Epoch 3. Loss: 0.5775043765270859, Train_acc 0.6595631544502618\n",
      "\n",
      "Epoch 3. Loss: 0.579716807564868, Train_acc 0.6596272786458334\n",
      "\n",
      "Epoch 3. Loss: 0.5843191378957988, Train_acc 0.6593669041450777\n",
      "\n",
      "Epoch 3. Loss: 0.5891995936912562, Train_acc 0.6591897551546392\n",
      "\n",
      "Epoch 3. Loss: 0.5903143742932915, Train_acc 0.6592147435897436\n",
      "\n",
      "Epoch 3. Loss: 0.5946870439577734, Train_acc 0.65916\n",
      "\n",
      "Epoch 4. Loss: 0.5960762792821499, Train_acc 0.59375\n",
      "\n",
      "Epoch 4. Loss: 0.5981597030755078, Train_acc 0.6171875\n",
      "\n",
      "Epoch 4. Loss: 0.5955744795140202, Train_acc 0.6536458333333334\n",
      "\n",
      "Epoch 4. Loss: 0.5914455961111106, Train_acc 0.67578125\n",
      "\n",
      "Epoch 4. Loss: 0.5961804489126429, Train_acc 0.6734375\n",
      "\n",
      "Epoch 4. Loss: 0.6015263885108195, Train_acc 0.66015625\n",
      "\n",
      "Epoch 4. Loss: 0.5993344148857203, Train_acc 0.6629464285714286\n",
      "\n",
      "Epoch 4. Loss: 0.5942486489590532, Train_acc 0.671875\n",
      "\n",
      "Epoch 4. Loss: 0.5859948842027658, Train_acc 0.6822916666666666\n",
      "\n",
      "Epoch 4. Loss: 0.5928291006355472, Train_acc 0.678125\n",
      "\n",
      "Epoch 4. Loss: 0.5888086667778183, Train_acc 0.6818181818181818\n",
      "\n",
      "Epoch 4. Loss: 0.5812436083962401, Train_acc 0.689453125\n",
      "\n",
      "Epoch 4. Loss: 0.5725940114268554, Train_acc 0.6989182692307693\n",
      "\n",
      "Epoch 4. Loss: 0.562689880669912, Train_acc 0.7059151785714286\n",
      "\n",
      "Epoch 4. Loss: 0.5656133414573672, Train_acc 0.7072916666666667\n",
      "\n",
      "Epoch 4. Loss: 0.5663828779399874, Train_acc 0.70703125\n",
      "\n",
      "Epoch 4. Loss: 0.5677409823960498, Train_acc 0.7077205882352942\n",
      "\n",
      "Epoch 4. Loss: 0.5688474168979913, Train_acc 0.7074652777777778\n",
      "\n",
      "Epoch 4. Loss: 0.5565895727816633, Train_acc 0.712171052631579\n",
      "\n",
      "Epoch 4. Loss: 0.5525727651903104, Train_acc 0.714453125\n",
      "\n",
      "Epoch 4. Loss: 0.5529969974508051, Train_acc 0.7172619047619048\n",
      "\n",
      "Epoch 4. Loss: 0.5480465928450373, Train_acc 0.7176846590909091\n",
      "\n",
      "Epoch 4. Loss: 0.5396107589961721, Train_acc 0.7190896739130435\n",
      "\n",
      "Epoch 4. Loss: 0.5382696112181217, Train_acc 0.7200520833333334\n",
      "\n",
      "Epoch 4. Loss: 0.5529479909109, Train_acc 0.7153125\n",
      "\n",
      "Epoch 4. Loss: 0.5458541448265544, Train_acc 0.7163461538461539\n",
      "\n",
      "Epoch 4. Loss: 0.5507079841509668, Train_acc 0.7155671296296297\n",
      "\n",
      "Epoch 4. Loss: 0.5544577850534208, Train_acc 0.7145647321428571\n",
      "\n",
      "Epoch 4. Loss: 0.5478878569871504, Train_acc 0.7157866379310345\n",
      "\n",
      "Epoch 4. Loss: 0.5460063355210708, Train_acc 0.7166666666666667\n",
      "\n",
      "Epoch 4. Loss: 0.5459241810777742, Train_acc 0.7169858870967742\n",
      "\n",
      "Epoch 4. Loss: 0.5502774664764665, Train_acc 0.717041015625\n",
      "\n",
      "Epoch 4. Loss: 0.55467999121592, Train_acc 0.7161458333333334\n",
      "\n",
      "Epoch 4. Loss: 0.5630617213938733, Train_acc 0.7143841911764706\n",
      "\n",
      "Epoch 4. Loss: 0.5705823128843994, Train_acc 0.7125\n",
      "\n",
      "Epoch 4. Loss: 0.565263190158429, Train_acc 0.7137586805555556\n",
      "\n",
      "Epoch 4. Loss: 0.5740691288902362, Train_acc 0.7122043918918919\n",
      "\n",
      "Epoch 4. Loss: 0.5738334415490032, Train_acc 0.712171052631579\n",
      "\n",
      "Epoch 4. Loss: 0.5709913693190753, Train_acc 0.7129407051282052\n",
      "\n",
      "Epoch 4. Loss: 0.5710227896858281, Train_acc 0.71328125\n",
      "\n",
      "Epoch 4. Loss: 0.570793826289984, Train_acc 0.7128429878048781\n",
      "\n",
      "Epoch 4. Loss: 0.5818522085917107, Train_acc 0.7107514880952381\n",
      "\n",
      "Epoch 4. Loss: 0.5767961600576739, Train_acc 0.7120276162790697\n",
      "\n",
      "Epoch 4. Loss: 0.5770394556958884, Train_acc 0.7123579545454546\n",
      "\n",
      "Epoch 4. Loss: 0.5787187236463497, Train_acc 0.7121527777777777\n",
      "\n",
      "Epoch 4. Loss: 0.5752263621612314, Train_acc 0.7133152173913043\n",
      "\n",
      "Epoch 4. Loss: 0.5770780702940157, Train_acc 0.7122672872340425\n",
      "\n",
      "Epoch 4. Loss: 0.5752875322560844, Train_acc 0.71240234375\n",
      "\n",
      "Epoch 4. Loss: 0.5714447839075664, Train_acc 0.7130102040816326\n",
      "\n",
      "Epoch 4. Loss: 0.5756383964134162, Train_acc 0.71203125\n",
      "\n",
      "Epoch 4. Loss: 0.5699143256586408, Train_acc 0.7126225490196079\n",
      "\n",
      "Epoch 4. Loss: 0.566815654561664, Train_acc 0.7130408653846154\n",
      "\n",
      "Epoch 4. Loss: 0.5582212926081527, Train_acc 0.7149174528301887\n",
      "\n",
      "Epoch 4. Loss: 0.5487553108750322, Train_acc 0.7168692129629629\n",
      "\n",
      "Epoch 4. Loss: 0.5435221459584121, Train_acc 0.7170454545454545\n",
      "\n",
      "Epoch 4. Loss: 0.5366081833347693, Train_acc 0.7181919642857143\n",
      "\n",
      "Epoch 4. Loss: 0.5439739858661606, Train_acc 0.7176535087719298\n",
      "\n",
      "Epoch 4. Loss: 0.5358934523661001, Train_acc 0.71875\n",
      "\n",
      "Epoch 4. Loss: 0.5295208443998453, Train_acc 0.7202065677966102\n",
      "\n",
      "Epoch 4. Loss: 0.5229200050055227, Train_acc 0.721484375\n",
      "\n",
      "Epoch 4. Loss: 0.5224473230379142, Train_acc 0.7222079918032787\n",
      "\n",
      "Epoch 4. Loss: 0.5256020145717846, Train_acc 0.7225302419354839\n",
      "\n",
      "Epoch 4. Loss: 0.528415314892255, Train_acc 0.7223462301587301\n",
      "\n",
      "Epoch 4. Loss: 0.5230293713861609, Train_acc 0.7235107421875\n",
      "\n",
      "Epoch 4. Loss: 0.5210690477061782, Train_acc 0.7236778846153846\n",
      "\n",
      "Epoch 4. Loss: 0.5158332447917922, Train_acc 0.7245501893939394\n",
      "\n",
      "Epoch 4. Loss: 0.5144583994786438, Train_acc 0.7250466417910447\n",
      "\n",
      "Epoch 4. Loss: 0.5053648693538156, Train_acc 0.7261029411764706\n",
      "\n",
      "Epoch 4. Loss: 0.5142429777839583, Train_acc 0.7256567028985508\n",
      "\n",
      "Epoch 4. Loss: 0.5158023037486198, Train_acc 0.7258928571428571\n",
      "\n",
      "Epoch 4. Loss: 0.5161122141456237, Train_acc 0.7263424295774648\n",
      "\n",
      "Epoch 4. Loss: 0.5173555306949285, Train_acc 0.7269965277777778\n",
      "\n",
      "Epoch 4. Loss: 0.5226557337365806, Train_acc 0.727097602739726\n",
      "\n",
      "Epoch 4. Loss: 0.5179773643424147, Train_acc 0.7278293918918919\n",
      "\n",
      "Epoch 4. Loss: 0.5114794082769781, Train_acc 0.7284375\n",
      "\n",
      "Epoch 4. Loss: 0.514056829273316, Train_acc 0.7284128289473685\n",
      "\n",
      "Epoch 4. Loss: 0.5117762872513646, Train_acc 0.728997564935065\n",
      "\n",
      "Epoch 4. Loss: 0.5128865947368605, Train_acc 0.7294671474358975\n",
      "\n",
      "Epoch 4. Loss: 0.5095008501448807, Train_acc 0.7294303797468354\n",
      "\n",
      "Epoch 4. Loss: 0.5152633686994234, Train_acc 0.72919921875\n",
      "\n",
      "Epoch 4. Loss: 0.5061044097067164, Train_acc 0.7302276234567902\n",
      "\n",
      "Epoch 4. Loss: 0.5169799983609837, Train_acc 0.7298018292682927\n",
      "\n",
      "Epoch 4. Loss: 0.5150655144550612, Train_acc 0.7302334337349398\n",
      "\n",
      "Epoch 4. Loss: 0.5139933080164979, Train_acc 0.7303757440476191\n",
      "\n",
      "Epoch 4. Loss: 0.513149969341313, Train_acc 0.7309742647058823\n",
      "\n",
      "Epoch 4. Loss: 0.5265987329738931, Train_acc 0.7301053779069767\n",
      "\n",
      "Epoch 4. Loss: 0.5287428450337884, Train_acc 0.7297952586206896\n",
      "\n",
      "Epoch 4. Loss: 0.5268484191672657, Train_acc 0.7301136363636364\n",
      "\n",
      "Epoch 4. Loss: 0.5279676827707875, Train_acc 0.7301615168539326\n",
      "\n",
      "Epoch 4. Loss: 0.5271514457093766, Train_acc 0.7302083333333333\n",
      "\n",
      "Epoch 4. Loss: 0.5293878139520071, Train_acc 0.7302541208791209\n",
      "\n",
      "Epoch 4. Loss: 0.5353279192564829, Train_acc 0.7297044836956522\n",
      "\n",
      "Epoch 4. Loss: 0.5302289705858777, Train_acc 0.7305947580645161\n",
      "\n",
      "Epoch 4. Loss: 0.5223391307639614, Train_acc 0.7315492021276596\n",
      "\n",
      "Epoch 4. Loss: 0.5257431673926892, Train_acc 0.7314967105263158\n",
      "\n",
      "Epoch 4. Loss: 0.5211185551812753, Train_acc 0.7320149739583334\n",
      "\n",
      "Epoch 4. Loss: 0.5302533093509529, Train_acc 0.7313949742268041\n",
      "\n",
      "Epoch 4. Loss: 0.5234765991643776, Train_acc 0.7317442602040817\n",
      "\n",
      "Epoch 4. Loss: 0.5170542822845915, Train_acc 0.7324021464646465\n",
      "\n",
      "Epoch 4. Loss: 0.5165585243613844, Train_acc 0.733125\n",
      "\n",
      "[Epoch 4 Batch 100] Loss: 0.5145227131764285 Training: accuracy=0.733292\n",
      "Epoch 4. Loss: 0.5145227131764285, Train_acc 0.7332920792079208\n",
      "\n",
      "Epoch 4. Loss: 0.5136186794209652, Train_acc 0.7329963235294118\n",
      "\n",
      "Epoch 4. Loss: 0.505775193789736, Train_acc 0.7339199029126213\n",
      "\n",
      "Epoch 4. Loss: 0.5038050327472111, Train_acc 0.7344501201923077\n",
      "\n",
      "Epoch 4. Loss: 0.5038539570962388, Train_acc 0.7345238095238096\n",
      "\n",
      "Epoch 4. Loss: 0.5084196092839538, Train_acc 0.7343012971698113\n",
      "\n",
      "Epoch 4. Loss: 0.5064499940415172, Train_acc 0.7345210280373832\n",
      "\n",
      "Epoch 4. Loss: 0.5085253625458432, Train_acc 0.734375\n",
      "\n",
      "Epoch 4. Loss: 0.5083615043174583, Train_acc 0.7343033256880734\n",
      "\n",
      "Epoch 4. Loss: 0.5112150900135659, Train_acc 0.734375\n",
      "\n",
      "Epoch 4. Loss: 0.5089633964809974, Train_acc 0.7349380630630631\n",
      "\n",
      "Epoch 4. Loss: 0.5079860779625058, Train_acc 0.7350725446428571\n",
      "\n",
      "Epoch 4. Loss: 0.5052315139456285, Train_acc 0.7355503318584071\n",
      "\n",
      "Epoch 4. Loss: 0.5016191432193243, Train_acc 0.7358826754385965\n",
      "\n",
      "Epoch 4. Loss: 0.5032576348765484, Train_acc 0.7362092391304348\n",
      "\n",
      "Epoch 4. Loss: 0.4992706083998494, Train_acc 0.7364628232758621\n",
      "\n",
      "Epoch 4. Loss: 0.5026680443059277, Train_acc 0.7365785256410257\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4. Loss: 0.5060136032138054, Train_acc 0.7365598516949152\n",
      "\n",
      "Epoch 4. Loss: 0.5019100647002862, Train_acc 0.7370667016806722\n",
      "\n",
      "Epoch 4. Loss: 0.49625558026108796, Train_acc 0.7376302083333334\n",
      "\n",
      "Epoch 4. Loss: 0.4907998147679, Train_acc 0.7381844008264463\n",
      "\n",
      "Epoch 4. Loss: 0.4890356811647978, Train_acc 0.7386014344262295\n",
      "\n",
      "Epoch 4. Loss: 0.48766279990363415, Train_acc 0.7390116869918699\n",
      "\n",
      "Epoch 4. Loss: 0.48252267040212415, Train_acc 0.7397303427419355\n",
      "\n",
      "Epoch 4. Loss: 0.479527313089962, Train_acc 0.740375\n",
      "\n",
      "Epoch 4. Loss: 0.4828099774509029, Train_acc 0.7403273809523809\n",
      "\n",
      "Epoch 4. Loss: 0.48773771231079316, Train_acc 0.7402189960629921\n",
      "\n",
      "Epoch 4. Loss: 0.4852728161636372, Train_acc 0.74066162109375\n",
      "\n",
      "Epoch 4. Loss: 0.4871996861776751, Train_acc 0.7406734496124031\n",
      "\n",
      "Epoch 4. Loss: 0.4887551506234147, Train_acc 0.7408052884615385\n",
      "\n",
      "Epoch 4. Loss: 0.5011116659527663, Train_acc 0.7403983778625954\n",
      "\n",
      "Epoch 4. Loss: 0.5004288133280554, Train_acc 0.7401160037878788\n",
      "\n",
      "Epoch 4. Loss: 0.4967399039534103, Train_acc 0.740484022556391\n",
      "\n",
      "Epoch 4. Loss: 0.4950596539974842, Train_acc 0.7404967350746269\n",
      "\n",
      "Epoch 4. Loss: 0.49248523850446646, Train_acc 0.7403935185185185\n",
      "\n",
      "Epoch 4. Loss: 0.4914924324083838, Train_acc 0.7406364889705882\n",
      "\n",
      "Epoch 4. Loss: 0.48092363064246, Train_acc 0.7413891423357665\n",
      "\n",
      "Epoch 4. Loss: 0.47169071541509, Train_acc 0.7420742753623188\n",
      "\n",
      "Epoch 4. Loss: 0.4694662133420792, Train_acc 0.7422999100719424\n",
      "\n",
      "Epoch 4. Loss: 0.4698412155716378, Train_acc 0.7422991071428572\n",
      "\n",
      "Epoch 4. Loss: 0.46310148259479633, Train_acc 0.7430186170212766\n",
      "\n",
      "Epoch 4. Loss: 0.482842710201253, Train_acc 0.742462588028169\n",
      "\n",
      "Epoch 4. Loss: 0.479523104355612, Train_acc 0.7428977272727273\n",
      "\n",
      "Epoch 4. Loss: 0.4831366675429451, Train_acc 0.7430013020833334\n",
      "\n",
      "Epoch 4. Loss: 0.48254153168197644, Train_acc 0.7430495689655172\n",
      "\n",
      "Epoch 4. Loss: 0.4733965429901735, Train_acc 0.7436857876712328\n",
      "\n",
      "Epoch 4. Loss: 0.4764917164957216, Train_acc 0.7437287414965986\n",
      "\n",
      "Epoch 4. Loss: 0.4752765598817787, Train_acc 0.7439822635135135\n",
      "\n",
      "Epoch 4. Loss: 0.4751699956885685, Train_acc 0.7442323825503355\n",
      "\n",
      "Epoch 4. Loss: 0.4854079239933231, Train_acc 0.74375\n",
      "\n",
      "Epoch 4. Loss: 0.4837615150244718, Train_acc 0.7441018211920529\n",
      "\n",
      "Epoch 4. Loss: 0.47795137387797404, Train_acc 0.7445004111842105\n",
      "\n",
      "Epoch 4. Loss: 0.4713597383107409, Train_acc 0.7449448529411765\n",
      "\n",
      "Epoch 4. Loss: 0.47250212007811654, Train_acc 0.744825487012987\n",
      "\n",
      "Epoch 4. Loss: 0.46631521380589297, Train_acc 0.7452116935483871\n",
      "\n",
      "Epoch 4. Loss: 0.46388906595092316, Train_acc 0.7455428685897436\n",
      "\n",
      "Epoch 4. Loss: 0.4772774668662068, Train_acc 0.7451234076433121\n",
      "\n",
      "Epoch 4. Loss: 0.4757195078249261, Train_acc 0.745401503164557\n",
      "\n",
      "Epoch 4. Loss: 0.47567083802063637, Train_acc 0.7454304245283019\n",
      "\n",
      "Epoch 4. Loss: 0.4703038665614072, Train_acc 0.745703125\n",
      "\n",
      "Epoch 4. Loss: 0.4695849418307731, Train_acc 0.7459724378881988\n",
      "\n",
      "Epoch 4. Loss: 0.4799029230772307, Train_acc 0.7459008487654321\n",
      "\n",
      "Epoch 4. Loss: 0.47912288305451134, Train_acc 0.7460697852760736\n",
      "\n",
      "Epoch 4. Loss: 0.4797082030530839, Train_acc 0.7461413871951219\n",
      "\n",
      "Epoch 4. Loss: 0.47884373817647125, Train_acc 0.7466382575757575\n",
      "\n",
      "Epoch 4. Loss: 0.4765196527880844, Train_acc 0.7468938253012049\n",
      "\n",
      "Epoch 4. Loss: 0.48174664549610763, Train_acc 0.7468188622754491\n",
      "\n",
      "Epoch 4. Loss: 0.48253894900603667, Train_acc 0.7471633184523809\n",
      "\n",
      "Epoch 4. Loss: 0.47621299375882964, Train_acc 0.7473650147928994\n",
      "\n",
      "Epoch 4. Loss: 0.4742615480702331, Train_acc 0.7473345588235294\n",
      "\n",
      "Epoch 4. Loss: 0.4883548610938678, Train_acc 0.7468932748538012\n",
      "\n",
      "Epoch 4. Loss: 0.48704377951023786, Train_acc 0.7470021802325582\n",
      "\n",
      "Epoch 4. Loss: 0.48663326032576987, Train_acc 0.747154985549133\n",
      "\n",
      "Epoch 4. Loss: 0.4895856254781904, Train_acc 0.7470815373563219\n",
      "\n",
      "Epoch 4. Loss: 0.4849057144062777, Train_acc 0.7473660714285715\n",
      "\n",
      "Epoch 4. Loss: 0.47789082641634884, Train_acc 0.7476917613636364\n",
      "\n",
      "Epoch 4. Loss: 0.47539437456637806, Train_acc 0.7479696327683616\n",
      "\n",
      "Epoch 4. Loss: 0.47571132758596707, Train_acc 0.7481127106741573\n",
      "\n",
      "Epoch 4. Loss: 0.4679585323870704, Train_acc 0.7486033519553073\n",
      "\n",
      "Epoch 4. Loss: 0.47266894812648225, Train_acc 0.7486111111111111\n",
      "\n",
      "Epoch 4. Loss: 0.47281041951714214, Train_acc 0.7489209254143646\n",
      "\n",
      "Epoch 4. Loss: 0.47650896798138254, Train_acc 0.7487122252747253\n",
      "\n",
      "Epoch 4. Loss: 0.47355501017479096, Train_acc 0.7490607923497268\n",
      "\n",
      "Epoch 4. Loss: 0.49044240857518906, Train_acc 0.7485139266304348\n",
      "\n",
      "Epoch 4. Loss: 0.4854720682980763, Train_acc 0.7487331081081081\n",
      "\n",
      "Epoch 4. Loss: 0.4997185931577218, Train_acc 0.7485719086021505\n",
      "\n",
      "Epoch 4. Loss: 0.49919580513005846, Train_acc 0.7486631016042781\n",
      "\n",
      "Epoch 4. Loss: 0.500379929784823, Train_acc 0.748794880319149\n",
      "\n",
      "Epoch 4. Loss: 0.5006328551565605, Train_acc 0.7488012566137566\n",
      "\n",
      "Epoch 4. Loss: 0.4994922186668216, Train_acc 0.7488898026315789\n",
      "\n",
      "Epoch 4. Loss: 0.5021420930983572, Train_acc 0.7486910994764397\n",
      "\n",
      "Epoch 4. Loss: 0.4954880668367698, Train_acc 0.7490641276041666\n",
      "\n",
      "Epoch 4. Loss: 0.49302356782368617, Train_acc 0.7492308937823834\n",
      "\n",
      "Epoch 4. Loss: 0.49060875185857833, Train_acc 0.7492348582474226\n",
      "\n",
      "Epoch 4. Loss: 0.4936060727405306, Train_acc 0.7491586538461539\n",
      "\n",
      "Epoch 4. Loss: 0.5010837513894817, Train_acc 0.74908\n",
      "\n",
      "Epoch 5. Loss: 0.500935578229217, Train_acc 0.7578125\n",
      "\n",
      "Epoch 5. Loss: 0.48857447256045483, Train_acc 0.8125\n",
      "\n",
      "Epoch 5. Loss: 0.4855356313234295, Train_acc 0.7994791666666666\n",
      "\n",
      "Epoch 5. Loss: 0.48058881438783335, Train_acc 0.802734375\n",
      "\n",
      "Epoch 5. Loss: 0.4770541913242179, Train_acc 0.8015625\n",
      "\n",
      "Epoch 5. Loss: 0.4754604780910347, Train_acc 0.7942708333333334\n",
      "\n",
      "Epoch 5. Loss: 0.46979626574259403, Train_acc 0.7924107142857143\n",
      "\n",
      "Epoch 5. Loss: 0.46633760236032074, Train_acc 0.7880859375\n",
      "\n",
      "Epoch 5. Loss: 0.46084405871326267, Train_acc 0.7934027777777778\n",
      "\n",
      "Epoch 5. Loss: 0.46003056370104434, Train_acc 0.79140625\n",
      "\n",
      "Epoch 5. Loss: 0.4534088862200238, Train_acc 0.7940340909090909\n",
      "\n",
      "Epoch 5. Loss: 0.44157719244894306, Train_acc 0.80078125\n",
      "\n",
      "Epoch 5. Loss: 0.4417183008522116, Train_acc 0.7986778846153846\n",
      "\n",
      "Epoch 5. Loss: 0.45189180434319287, Train_acc 0.7963169642857143\n",
      "\n",
      "Epoch 5. Loss: 0.45151011163508514, Train_acc 0.7953125\n",
      "\n",
      "Epoch 5. Loss: 0.45327953113182445, Train_acc 0.79345703125\n",
      "\n",
      "Epoch 5. Loss: 0.4552109147286182, Train_acc 0.7927389705882353\n",
      "\n",
      "Epoch 5. Loss: 0.4502469395258217, Train_acc 0.7960069444444444\n",
      "\n",
      "Epoch 5. Loss: 0.45833037745876803, Train_acc 0.7911184210526315\n",
      "\n",
      "Epoch 5. Loss: 0.46183175550631017, Train_acc 0.788671875\n",
      "\n",
      "Epoch 5. Loss: 0.46377929186878797, Train_acc 0.7875744047619048\n",
      "\n",
      "Epoch 5. Loss: 0.45942071201853335, Train_acc 0.7876420454545454\n",
      "\n",
      "Epoch 5. Loss: 0.46147660722540956, Train_acc 0.7870244565217391\n",
      "\n",
      "Epoch 5. Loss: 0.46812382617778014, Train_acc 0.7854817708333334\n",
      "\n",
      "Epoch 5. Loss: 0.47161906909215245, Train_acc 0.7834375\n",
      "\n",
      "Epoch 5. Loss: 0.46389674202741205, Train_acc 0.7830528846153846\n",
      "\n",
      "Epoch 5. Loss: 0.45750801911480143, Train_acc 0.7847222222222222\n",
      "\n",
      "Epoch 5. Loss: 0.46059566870802865, Train_acc 0.78515625\n",
      "\n",
      "Epoch 5. Loss: 0.458458400983878, Train_acc 0.7839439655172413\n",
      "\n",
      "Epoch 5. Loss: 0.45925087680155163, Train_acc 0.78359375\n",
      "\n",
      "Epoch 5. Loss: 0.45164326682449096, Train_acc 0.7850302419354839\n",
      "\n",
      "Epoch 5. Loss: 0.46701793540800257, Train_acc 0.78173828125\n",
      "\n",
      "Epoch 5. Loss: 0.45829614403204305, Train_acc 0.7836174242424242\n",
      "\n",
      "Epoch 5. Loss: 0.45783167245110434, Train_acc 0.7835477941176471\n",
      "\n",
      "Epoch 5. Loss: 0.4592707678269198, Train_acc 0.7830357142857143\n",
      "\n",
      "Epoch 5. Loss: 0.4631354264549181, Train_acc 0.783203125\n",
      "\n",
      "Epoch 5. Loss: 0.4611318038819818, Train_acc 0.7837837837837838\n",
      "\n",
      "Epoch 5. Loss: 0.4665607387052705, Train_acc 0.782483552631579\n",
      "\n",
      "Epoch 5. Loss: 0.4638814843499717, Train_acc 0.7830528846153846\n",
      "\n",
      "Epoch 5. Loss: 0.4602078363422206, Train_acc 0.78359375\n",
      "\n",
      "Epoch 5. Loss: 0.4617611377051757, Train_acc 0.7827743902439024\n",
      "\n",
      "Epoch 5. Loss: 0.4729221947739678, Train_acc 0.78125\n",
      "\n",
      "Epoch 5. Loss: 0.47018424759061556, Train_acc 0.7814316860465116\n",
      "\n",
      "Epoch 5. Loss: 0.46876195451395, Train_acc 0.7807173295454546\n",
      "\n",
      "Epoch 5. Loss: 0.47212761086919564, Train_acc 0.7805555555555556\n",
      "\n",
      "Epoch 5. Loss: 0.4739895770791053, Train_acc 0.7795516304347826\n",
      "\n",
      "Epoch 5. Loss: 0.47361412434365263, Train_acc 0.7795877659574468\n",
      "\n",
      "Epoch 5. Loss: 0.4682508568935327, Train_acc 0.7805989583333334\n",
      "\n",
      "Epoch 5. Loss: 0.471825265375322, Train_acc 0.7794961734693877\n",
      "\n",
      "Epoch 5. Loss: 0.47005319013078145, Train_acc 0.7796875\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5. Loss: 0.4624474234629792, Train_acc 0.7809436274509803\n",
      "\n",
      "Epoch 5. Loss: 0.45514367704830666, Train_acc 0.7807992788461539\n",
      "\n",
      "Epoch 5. Loss: 0.448238951133866, Train_acc 0.7819870283018868\n",
      "\n",
      "Epoch 5. Loss: 0.4536584754292777, Train_acc 0.7816840277777778\n",
      "\n",
      "Epoch 5. Loss: 0.44742119367461897, Train_acc 0.7819602272727273\n",
      "\n",
      "Epoch 5. Loss: 0.43714430679865035, Train_acc 0.7830636160714286\n",
      "\n",
      "Epoch 5. Loss: 0.43123924210656306, Train_acc 0.7838541666666666\n",
      "\n",
      "Epoch 5. Loss: 0.43900625236322244, Train_acc 0.7838092672413793\n",
      "\n",
      "Epoch 5. Loss: 0.4372291981651464, Train_acc 0.784030720338983\n",
      "\n",
      "Epoch 5. Loss: 0.4401228326088857, Train_acc 0.7841145833333333\n",
      "\n",
      "Epoch 5. Loss: 0.4471739677363638, Train_acc 0.7840676229508197\n",
      "\n",
      "Epoch 5. Loss: 0.4348083628214005, Train_acc 0.78515625\n",
      "\n",
      "Epoch 5. Loss: 0.44921658274501, Train_acc 0.7843501984126984\n",
      "\n",
      "Epoch 5. Loss: 0.4458145067420849, Train_acc 0.78466796875\n",
      "\n",
      "Epoch 5. Loss: 0.4422560213798805, Train_acc 0.7848557692307693\n",
      "\n",
      "Epoch 5. Loss: 0.4391518782491557, Train_acc 0.7855113636363636\n",
      "\n",
      "Epoch 5. Loss: 0.43591142752007295, Train_acc 0.7862639925373134\n",
      "\n",
      "Epoch 5. Loss: 0.4348753368100731, Train_acc 0.7865349264705882\n",
      "\n",
      "Epoch 5. Loss: 0.42533204036127403, Train_acc 0.7878170289855072\n",
      "\n",
      "Epoch 5. Loss: 0.43007359275672624, Train_acc 0.7876116071428572\n",
      "\n",
      "Epoch 5. Loss: 0.43083042832720686, Train_acc 0.787962147887324\n",
      "\n",
      "Epoch 5. Loss: 0.4297358000204719, Train_acc 0.7881944444444444\n",
      "\n",
      "Epoch 5. Loss: 0.4444701973133466, Train_acc 0.7873501712328768\n",
      "\n",
      "Epoch 5. Loss: 0.43775529296992854, Train_acc 0.7876900337837838\n",
      "\n",
      "Epoch 5. Loss: 0.44290052025138116, Train_acc 0.7875\n",
      "\n",
      "Epoch 5. Loss: 0.44615482242660626, Train_acc 0.787828947368421\n",
      "\n",
      "Epoch 5. Loss: 0.45346996443054294, Train_acc 0.7870332792207793\n",
      "\n",
      "Epoch 5. Loss: 0.44971819451374906, Train_acc 0.7875600961538461\n",
      "\n",
      "Epoch 5. Loss: 0.4524376189493218, Train_acc 0.7874802215189873\n",
      "\n",
      "Epoch 5. Loss: 0.4728283222719799, Train_acc 0.78564453125\n",
      "\n",
      "Epoch 5. Loss: 0.4753268929903004, Train_acc 0.7849151234567902\n",
      "\n",
      "Epoch 5. Loss: 0.4762897705362106, Train_acc 0.7850609756097561\n",
      "\n",
      "Epoch 5. Loss: 0.48191731113128644, Train_acc 0.7842620481927711\n",
      "\n",
      "Epoch 5. Loss: 0.48047312144577015, Train_acc 0.7838541666666666\n",
      "\n",
      "Epoch 5. Loss: 0.48133756855850973, Train_acc 0.7839154411764706\n",
      "\n",
      "Epoch 5. Loss: 0.4820450854872962, Train_acc 0.7836119186046512\n",
      "\n",
      "Epoch 5. Loss: 0.4820061724700302, Train_acc 0.7833153735632183\n",
      "\n",
      "Epoch 5. Loss: 0.48298729669908613, Train_acc 0.7829367897727273\n",
      "\n",
      "Epoch 5. Loss: 0.4833261806833142, Train_acc 0.7830056179775281\n",
      "\n",
      "Epoch 5. Loss: 0.47755949548489396, Train_acc 0.7831597222222222\n",
      "\n",
      "Epoch 5. Loss: 0.47322305308228624, Train_acc 0.7831387362637363\n",
      "\n",
      "Epoch 5. Loss: 0.4800639176348975, Train_acc 0.7830332880434783\n",
      "\n",
      "Epoch 5. Loss: 0.4823270878774044, Train_acc 0.7833501344086021\n",
      "\n",
      "Epoch 5. Loss: 0.4756087340338931, Train_acc 0.7837433510638298\n",
      "\n",
      "Epoch 5. Loss: 0.4751994351229583, Train_acc 0.7835526315789474\n",
      "\n",
      "Epoch 5. Loss: 0.4713121062232418, Train_acc 0.7837727864583334\n",
      "\n",
      "Epoch 5. Loss: 0.4629431282621649, Train_acc 0.7839884020618557\n",
      "\n",
      "Epoch 5. Loss: 0.4618352992959643, Train_acc 0.7841198979591837\n",
      "\n",
      "Epoch 5. Loss: 0.4702636310721479, Train_acc 0.78353851010101\n",
      "\n",
      "Epoch 5. Loss: 0.47000806414470453, Train_acc 0.783359375\n",
      "\n",
      "[Epoch 5 Batch 100] Loss: 0.47315806940244476 Training: accuracy=0.782797\n",
      "Epoch 5. Loss: 0.47315806940244476, Train_acc 0.7827970297029703\n",
      "\n",
      "Epoch 5. Loss: 0.46597545857769407, Train_acc 0.7833180147058824\n",
      "\n",
      "Epoch 5. Loss: 0.4642200575668409, Train_acc 0.7835254854368932\n",
      "\n",
      "Epoch 5. Loss: 0.4566102361439581, Train_acc 0.7837289663461539\n",
      "\n",
      "Epoch 5. Loss: 0.45977338574161375, Train_acc 0.7834077380952381\n",
      "\n",
      "Epoch 5. Loss: 0.45498239179101807, Train_acc 0.7837558962264151\n",
      "\n",
      "Epoch 5. Loss: 0.4532811151115348, Train_acc 0.7839515186915887\n",
      "\n",
      "Epoch 5. Loss: 0.4559417163880095, Train_acc 0.7839265046296297\n",
      "\n",
      "Epoch 5. Loss: 0.4569021936253988, Train_acc 0.7838302752293578\n",
      "\n",
      "Epoch 5. Loss: 0.4526871510740772, Train_acc 0.783877840909091\n",
      "\n",
      "Epoch 5. Loss: 0.45354986504286426, Train_acc 0.7838541666666666\n",
      "\n",
      "Epoch 5. Loss: 0.4516841320595434, Train_acc 0.7839704241071429\n",
      "\n",
      "Epoch 5. Loss: 0.44813650087129686, Train_acc 0.7841537610619469\n",
      "\n",
      "Epoch 5. Loss: 0.44163809331308257, Train_acc 0.7848821271929824\n",
      "\n",
      "Epoch 5. Loss: 0.4418845037703256, Train_acc 0.7846467391304348\n",
      "\n",
      "Epoch 5. Loss: 0.44103720427315296, Train_acc 0.7850215517241379\n",
      "\n",
      "Epoch 5. Loss: 0.44592975950921354, Train_acc 0.7847222222222222\n",
      "\n",
      "Epoch 5. Loss: 0.44673816302434904, Train_acc 0.7850238347457628\n",
      "\n",
      "Epoch 5. Loss: 0.4464882666380671, Train_acc 0.7849264705882353\n",
      "\n",
      "Epoch 5. Loss: 0.4424911428551198, Train_acc 0.78515625\n",
      "\n",
      "Epoch 5. Loss: 0.4395285030359317, Train_acc 0.7851239669421488\n",
      "\n",
      "Epoch 5. Loss: 0.44266437114664525, Train_acc 0.7848360655737705\n",
      "\n",
      "Epoch 5. Loss: 0.436997693372267, Train_acc 0.7849339430894309\n",
      "\n",
      "Epoch 5. Loss: 0.4318531050614991, Train_acc 0.7852192540322581\n",
      "\n",
      "Epoch 5. Loss: 0.4375601495205592, Train_acc 0.78525\n",
      "\n",
      "Epoch 5. Loss: 0.45098844929628656, Train_acc 0.7849702380952381\n",
      "\n",
      "Epoch 5. Loss: 0.43771112946355123, Train_acc 0.7855561023622047\n",
      "\n",
      "Epoch 5. Loss: 0.4340863018126826, Train_acc 0.7857666015625\n",
      "\n",
      "Epoch 5. Loss: 0.4319062461458034, Train_acc 0.7859132751937985\n",
      "\n",
      "Epoch 5. Loss: 0.4374585536124456, Train_acc 0.7856370192307692\n",
      "\n",
      "Epoch 5. Loss: 0.4306283611359133, Train_acc 0.7859017175572519\n",
      "\n",
      "Epoch 5. Loss: 0.43950613304691916, Train_acc 0.7859256628787878\n",
      "\n",
      "Epoch 5. Loss: 0.4347509768430955, Train_acc 0.7862429511278195\n",
      "\n",
      "Epoch 5. Loss: 0.4372800672195465, Train_acc 0.7858558768656716\n",
      "\n",
      "Epoch 5. Loss: 0.4336603895552853, Train_acc 0.7859953703703704\n",
      "\n",
      "Epoch 5. Loss: 0.4333641185517221, Train_acc 0.7859604779411765\n",
      "\n",
      "Epoch 5. Loss: 0.4204086054106155, Train_acc 0.7867244525547445\n",
      "\n",
      "Epoch 5. Loss: 0.42128443021234263, Train_acc 0.7868546195652174\n",
      "\n",
      "Epoch 5. Loss: 0.4255741384505307, Train_acc 0.786814298561151\n",
      "\n",
      "Epoch 5. Loss: 0.4195154857825406, Train_acc 0.7871651785714285\n",
      "\n",
      "Epoch 5. Loss: 0.42140054573337743, Train_acc 0.7873448581560284\n",
      "\n",
      "Epoch 5. Loss: 0.4185288805042551, Train_acc 0.7875220070422535\n",
      "\n",
      "Epoch 5. Loss: 0.420044346893565, Train_acc 0.787423513986014\n",
      "\n",
      "Epoch 5. Loss: 0.41550898931449903, Train_acc 0.7877604166666666\n",
      "\n",
      "Epoch 5. Loss: 0.41998876376771554, Train_acc 0.7877155172413793\n",
      "\n",
      "Epoch 5. Loss: 0.4142777911766496, Train_acc 0.7880993150684932\n",
      "\n",
      "Epoch 5. Loss: 0.41354166495300476, Train_acc 0.7881058673469388\n",
      "\n",
      "Epoch 5. Loss: 0.40693409169462746, Train_acc 0.7882706925675675\n",
      "\n",
      "Epoch 5. Loss: 0.4075439327187606, Train_acc 0.7884857382550335\n",
      "\n",
      "Epoch 5. Loss: 0.40339664696698796, Train_acc 0.78875\n",
      "\n",
      "Epoch 5. Loss: 0.4047814733896739, Train_acc 0.7888555463576159\n",
      "\n",
      "Epoch 5. Loss: 0.40058593694395606, Train_acc 0.7892680921052632\n",
      "\n",
      "Epoch 5. Loss: 0.3950495220186721, Train_acc 0.7895220588235294\n",
      "\n",
      "Epoch 5. Loss: 0.4074596908952961, Train_acc 0.789265422077922\n",
      "\n",
      "Epoch 5. Loss: 0.4018448335468325, Train_acc 0.7894657258064516\n",
      "\n",
      "Epoch 5. Loss: 0.4152070053702193, Train_acc 0.7892127403846154\n",
      "\n",
      "Epoch 5. Loss: 0.4175313653009174, Train_acc 0.7893610668789809\n",
      "\n",
      "Epoch 5. Loss: 0.4200034297815297, Train_acc 0.7893591772151899\n",
      "\n",
      "Epoch 5. Loss: 0.41796920513910063, Train_acc 0.7896521226415094\n",
      "\n",
      "Epoch 5. Loss: 0.43085544540705095, Train_acc 0.7890625\n",
      "\n",
      "Epoch 5. Loss: 0.43760715038378667, Train_acc 0.7890139751552795\n",
      "\n",
      "Epoch 5. Loss: 0.4321051547896829, Train_acc 0.7895447530864198\n",
      "\n",
      "Epoch 5. Loss: 0.4326687434290618, Train_acc 0.7897814417177914\n",
      "\n",
      "Epoch 5. Loss: 0.4348701279438827, Train_acc 0.7895865091463414\n",
      "\n",
      "Epoch 5. Loss: 0.42877991864776255, Train_acc 0.7895833333333333\n",
      "\n",
      "Epoch 5. Loss: 0.4293320614370314, Train_acc 0.7897213855421686\n",
      "\n",
      "Epoch 5. Loss: 0.4352959547882624, Train_acc 0.7894835329341318\n",
      "\n",
      "Epoch 5. Loss: 0.4358133990566743, Train_acc 0.7894810267857143\n",
      "\n",
      "Epoch 5. Loss: 0.4382320331633818, Train_acc 0.7896172337278107\n",
      "\n",
      "Epoch 5. Loss: 0.4323239523560463, Train_acc 0.7899816176470589\n",
      "\n",
      "Epoch 5. Loss: 0.43190451846039224, Train_acc 0.7900676169590644\n",
      "\n",
      "Epoch 5. Loss: 0.4375705634252661, Train_acc 0.7899709302325582\n",
      "\n",
      "Epoch 5. Loss: 0.43587344718245574, Train_acc 0.7901914739884393\n",
      "\n",
      "Epoch 5. Loss: 0.42433102874995393, Train_acc 0.7904992816091954\n",
      "\n",
      "Epoch 5. Loss: 0.4281176353905301, Train_acc 0.7904464285714285\n",
      "\n",
      "Epoch 5. Loss: 0.43138328421834415, Train_acc 0.7905717329545454\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5. Loss: 0.42624899353435614, Train_acc 0.790916313559322\n",
      "\n",
      "Epoch 5. Loss: 0.41888731663689893, Train_acc 0.7910814606741573\n",
      "\n",
      "Epoch 5. Loss: 0.4103100741976429, Train_acc 0.7914629888268156\n",
      "\n",
      "Epoch 5. Loss: 0.41252279088562094, Train_acc 0.7915364583333333\n",
      "\n",
      "Epoch 5. Loss: 0.41170151059924387, Train_acc 0.791565953038674\n",
      "\n",
      "Epoch 5. Loss: 0.40704811535864016, Train_acc 0.7919814560439561\n",
      "\n",
      "Epoch 5. Loss: 0.40774525632788783, Train_acc 0.792050887978142\n",
      "\n",
      "Epoch 5. Loss: 0.4091054627030794, Train_acc 0.7921620244565217\n",
      "\n",
      "Epoch 5. Loss: 0.40580151933995223, Train_acc 0.792356418918919\n",
      "\n",
      "Epoch 5. Loss: 0.3979485195151031, Train_acc 0.7926747311827957\n",
      "\n",
      "Epoch 5. Loss: 0.39320331167617983, Train_acc 0.7929060828877005\n",
      "\n",
      "Epoch 5. Loss: 0.38901226536726546, Train_acc 0.7932596409574468\n",
      "\n",
      "Epoch 5. Loss: 0.39476446047093505, Train_acc 0.7932374338624338\n",
      "\n",
      "Epoch 5. Loss: 0.3904556876540128, Train_acc 0.7935032894736842\n",
      "\n",
      "Epoch 5. Loss: 0.38339443619131536, Train_acc 0.7939708769633508\n",
      "\n",
      "Epoch 5. Loss: 0.3800992216027929, Train_acc 0.794189453125\n",
      "\n",
      "Epoch 5. Loss: 0.3806346427223522, Train_acc 0.7943248056994818\n",
      "\n",
      "Epoch 5. Loss: 0.37612906135512336, Train_acc 0.7948614690721649\n",
      "\n",
      "Epoch 5. Loss: 0.38898599479251755, Train_acc 0.7947115384615384\n",
      "\n",
      "Epoch 5. Loss: 0.3946404665737181, Train_acc 0.79468\n",
      "\n",
      "Epoch 6. Loss: 0.3878557929422405, Train_acc 0.8359375\n",
      "\n",
      "Epoch 6. Loss: 0.3818758293115449, Train_acc 0.85546875\n",
      "\n",
      "Epoch 6. Loss: 0.38074747301250866, Train_acc 0.8463541666666666\n",
      "\n",
      "Epoch 6. Loss: 0.37925652781525404, Train_acc 0.845703125\n",
      "\n",
      "Epoch 6. Loss: 0.37087546097695073, Train_acc 0.859375\n",
      "\n",
      "Epoch 6. Loss: 0.3743793276619248, Train_acc 0.8502604166666666\n",
      "\n",
      "Epoch 6. Loss: 0.3718440628949999, Train_acc 0.8515625\n",
      "\n",
      "Epoch 6. Loss: 0.381299516281861, Train_acc 0.8408203125\n",
      "\n",
      "Epoch 6. Loss: 0.39475571577672175, Train_acc 0.8324652777777778\n",
      "\n",
      "Epoch 6. Loss: 0.39729247806898366, Train_acc 0.83203125\n",
      "\n",
      "Epoch 6. Loss: 0.39312699721841465, Train_acc 0.8330965909090909\n",
      "\n",
      "Epoch 6. Loss: 0.4006123449199359, Train_acc 0.8255208333333334\n",
      "\n",
      "Epoch 6. Loss: 0.40271487287816055, Train_acc 0.8239182692307693\n",
      "\n",
      "Epoch 6. Loss: 0.39852047370794397, Train_acc 0.8264508928571429\n",
      "\n",
      "Epoch 6. Loss: 0.3936362869166402, Train_acc 0.8276041666666667\n",
      "\n",
      "Epoch 6. Loss: 0.4012207752427222, Train_acc 0.82421875\n",
      "\n",
      "Epoch 6. Loss: 0.39535247677213803, Train_acc 0.8285845588235294\n",
      "\n",
      "Epoch 6. Loss: 0.3900150423674004, Train_acc 0.8289930555555556\n",
      "\n",
      "Epoch 6. Loss: 0.39259116042508635, Train_acc 0.826891447368421\n",
      "\n",
      "Epoch 6. Loss: 0.38575602342653825, Train_acc 0.828515625\n",
      "\n",
      "Epoch 6. Loss: 0.3873095134195854, Train_acc 0.8288690476190477\n",
      "\n",
      "Epoch 6. Loss: 0.3875816362467858, Train_acc 0.8267045454545454\n",
      "\n",
      "Epoch 6. Loss: 0.38440241492099636, Train_acc 0.8274456521739131\n",
      "\n",
      "Epoch 6. Loss: 0.386698562589053, Train_acc 0.8274739583333334\n",
      "\n",
      "Epoch 6. Loss: 0.38627557637104126, Train_acc 0.8284375\n",
      "\n",
      "Epoch 6. Loss: 0.3822224499148911, Train_acc 0.8287259615384616\n",
      "\n",
      "Epoch 6. Loss: 0.3884530926969158, Train_acc 0.8263888888888888\n",
      "\n",
      "Epoch 6. Loss: 0.3885600446367121, Train_acc 0.8258928571428571\n",
      "\n",
      "Epoch 6. Loss: 0.39131055581902174, Train_acc 0.8246228448275862\n",
      "\n",
      "Epoch 6. Loss: 0.3930945543199901, Train_acc 0.8255208333333334\n",
      "\n",
      "Epoch 6. Loss: 0.39518382082135595, Train_acc 0.8261088709677419\n",
      "\n",
      "Epoch 6. Loss: 0.3990374976076286, Train_acc 0.82568359375\n",
      "\n",
      "Epoch 6. Loss: 0.3984991765330077, Train_acc 0.8248106060606061\n",
      "\n",
      "Epoch 6. Loss: 0.403104071883247, Train_acc 0.8235294117647058\n",
      "\n",
      "Epoch 6. Loss: 0.4014603421698979, Train_acc 0.8229910714285714\n",
      "\n",
      "Epoch 6. Loss: 0.3988153718958174, Train_acc 0.8231336805555556\n",
      "\n",
      "Epoch 6. Loss: 0.40042244044392183, Train_acc 0.8234797297297297\n",
      "\n",
      "Epoch 6. Loss: 0.3920633552740414, Train_acc 0.825452302631579\n",
      "\n",
      "Epoch 6. Loss: 0.39353451355729097, Train_acc 0.8247195512820513\n",
      "\n",
      "Epoch 6. Loss: 0.38327922127634517, Train_acc 0.8263671875\n",
      "\n",
      "Epoch 6. Loss: 0.379734140950354, Train_acc 0.8267911585365854\n",
      "\n",
      "Epoch 6. Loss: 0.3747100940208841, Train_acc 0.8273809523809523\n",
      "\n",
      "Epoch 6. Loss: 0.37321467794727164, Train_acc 0.8273982558139535\n",
      "\n",
      "Epoch 6. Loss: 0.37448387680427025, Train_acc 0.8277698863636364\n",
      "\n",
      "Epoch 6. Loss: 0.384921535891078, Train_acc 0.8270833333333333\n",
      "\n",
      "Epoch 6. Loss: 0.39327437732379034, Train_acc 0.8260869565217391\n",
      "\n",
      "Epoch 6. Loss: 0.3943414096870458, Train_acc 0.8252992021276596\n",
      "\n",
      "Epoch 6. Loss: 0.3989699070011171, Train_acc 0.8248697916666666\n",
      "\n",
      "Epoch 6. Loss: 0.4059465215523177, Train_acc 0.8233418367346939\n",
      "\n",
      "Epoch 6. Loss: 0.4128293471860111, Train_acc 0.82265625\n",
      "\n",
      "Epoch 6. Loss: 0.4110673735136289, Train_acc 0.8224571078431373\n",
      "\n",
      "Epoch 6. Loss: 0.4074173423285334, Train_acc 0.8228665865384616\n",
      "\n",
      "Epoch 6. Loss: 0.4128300564856871, Train_acc 0.8223761792452831\n",
      "\n",
      "Epoch 6. Loss: 0.41287801719053485, Train_acc 0.8214699074074074\n",
      "\n",
      "Epoch 6. Loss: 0.412771267202591, Train_acc 0.821875\n",
      "\n",
      "Epoch 6. Loss: 0.41202139482536476, Train_acc 0.8221261160714286\n",
      "\n",
      "Epoch 6. Loss: 0.4151282277015319, Train_acc 0.8212719298245614\n",
      "\n",
      "Epoch 6. Loss: 0.4126292973435644, Train_acc 0.8205818965517241\n",
      "\n",
      "Epoch 6. Loss: 0.4140848019430093, Train_acc 0.8196504237288136\n",
      "\n",
      "Epoch 6. Loss: 0.4175495235957848, Train_acc 0.819140625\n",
      "\n",
      "Epoch 6. Loss: 0.4155888016973269, Train_acc 0.8192879098360656\n",
      "\n",
      "Epoch 6. Loss: 0.4091536959368884, Train_acc 0.8201864919354839\n",
      "\n",
      "Epoch 6. Loss: 0.4088520431839435, Train_acc 0.8199404761904762\n",
      "\n",
      "Epoch 6. Loss: 0.40263175287750447, Train_acc 0.820556640625\n",
      "\n",
      "Epoch 6. Loss: 0.39939084636187927, Train_acc 0.8205528846153847\n",
      "\n",
      "Epoch 6. Loss: 0.39113270330741745, Train_acc 0.8211410984848485\n",
      "\n",
      "Epoch 6. Loss: 0.39100953717513154, Train_acc 0.8208955223880597\n",
      "\n",
      "Epoch 6. Loss: 0.3863547066999966, Train_acc 0.8213465073529411\n",
      "\n",
      "Epoch 6. Loss: 0.3945288795370007, Train_acc 0.8212182971014492\n",
      "\n",
      "Epoch 6. Loss: 0.39258784098668204, Train_acc 0.8212053571428571\n",
      "\n",
      "Epoch 6. Loss: 0.3958550367645321, Train_acc 0.8207526408450704\n",
      "\n",
      "Epoch 6. Loss: 0.3959308451913504, Train_acc 0.8205295138888888\n",
      "\n",
      "Epoch 6. Loss: 0.3960619824978151, Train_acc 0.8204195205479452\n",
      "\n",
      "Epoch 6. Loss: 0.40070960442892656, Train_acc 0.819995777027027\n",
      "\n",
      "Epoch 6. Loss: 0.3935376064837451, Train_acc 0.82\n",
      "\n",
      "Epoch 6. Loss: 0.38455808075015024, Train_acc 0.8209292763157895\n",
      "\n",
      "Epoch 6. Loss: 0.39090012829075105, Train_acc 0.8210227272727273\n",
      "\n",
      "Epoch 6. Loss: 0.38546262968096, Train_acc 0.8214142628205128\n",
      "\n",
      "Epoch 6. Loss: 0.3796999703810769, Train_acc 0.8214992088607594\n",
      "\n",
      "Epoch 6. Loss: 0.37856449940498094, Train_acc 0.8212890625\n",
      "\n",
      "Epoch 6. Loss: 0.3771775328400322, Train_acc 0.8213734567901234\n",
      "\n",
      "Epoch 6. Loss: 0.3765062060906817, Train_acc 0.821265243902439\n",
      "\n",
      "Epoch 6. Loss: 0.377396246816605, Train_acc 0.8211596385542169\n",
      "\n",
      "Epoch 6. Loss: 0.37818799408604775, Train_acc 0.8215215773809523\n",
      "\n",
      "Epoch 6. Loss: 0.37537583701905675, Train_acc 0.8223345588235295\n",
      "\n",
      "Epoch 6. Loss: 0.3722898244240618, Train_acc 0.8223110465116279\n",
      "\n",
      "Epoch 6. Loss: 0.37440452093291904, Train_acc 0.8222880747126436\n",
      "\n",
      "Epoch 6. Loss: 0.37265935046442117, Train_acc 0.8226207386363636\n",
      "\n",
      "Epoch 6. Loss: 0.3711451307204464, Train_acc 0.8222436797752809\n",
      "\n",
      "Epoch 6. Loss: 0.3667453958332926, Train_acc 0.8225694444444445\n",
      "\n",
      "Epoch 6. Loss: 0.36766763631168514, Train_acc 0.8225446428571429\n",
      "\n",
      "Epoch 6. Loss: 0.3642540136307196, Train_acc 0.8230298913043478\n",
      "\n",
      "Epoch 6. Loss: 0.3632321738597497, Train_acc 0.8230006720430108\n",
      "\n",
      "Epoch 6. Loss: 0.3633765354809235, Train_acc 0.8229720744680851\n",
      "\n",
      "Epoch 6. Loss: 0.36584307030353586, Train_acc 0.8227796052631579\n",
      "\n",
      "Epoch 6. Loss: 0.36627260990900073, Train_acc 0.8230794270833334\n",
      "\n",
      "Epoch 6. Loss: 0.36751761568750985, Train_acc 0.8227287371134021\n",
      "\n",
      "Epoch 6. Loss: 0.3681824135765378, Train_acc 0.8227838010204082\n",
      "\n",
      "Epoch 6. Loss: 0.36142148029669624, Train_acc 0.8233901515151515\n",
      "\n",
      "Epoch 6. Loss: 0.34995678024170845, Train_acc 0.824296875\n",
      "\n",
      "[Epoch 6 Batch 100] Loss: 0.34375173112760227 Training: accuracy=0.824954\n",
      "Epoch 6. Loss: 0.34375173112760227, Train_acc 0.8249535891089109\n",
      "\n",
      "Epoch 6. Loss: 0.3444915854425154, Train_acc 0.8253676470588235\n",
      "\n",
      "Epoch 6. Loss: 0.3457103470108738, Train_acc 0.8253944174757282\n",
      "\n",
      "Epoch 6. Loss: 0.342429897112414, Train_acc 0.8257962740384616\n",
      "\n",
      "Epoch 6. Loss: 0.33785430871495437, Train_acc 0.8263392857142857\n",
      "\n",
      "Epoch 6. Loss: 0.3411185587917164, Train_acc 0.8265035377358491\n",
      "\n",
      "Epoch 6. Loss: 0.34538714994261216, Train_acc 0.8261536214953271\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6. Loss: 0.3470319054359456, Train_acc 0.8262442129629629\n",
      "\n",
      "Epoch 6. Loss: 0.3623757727594012, Train_acc 0.825759747706422\n",
      "\n",
      "Epoch 6. Loss: 0.3626477003977448, Train_acc 0.8259232954545455\n",
      "\n",
      "Epoch 6. Loss: 0.37449478038124, Train_acc 0.8257319819819819\n",
      "\n",
      "Epoch 6. Loss: 0.3895991706368782, Train_acc 0.8249162946428571\n",
      "\n",
      "Epoch 6. Loss: 0.39157441230274365, Train_acc 0.8245990044247787\n",
      "\n",
      "Epoch 6. Loss: 0.3933209923355918, Train_acc 0.8244243421052632\n",
      "\n",
      "Epoch 6. Loss: 0.41682556397758197, Train_acc 0.8233016304347827\n",
      "\n",
      "Epoch 6. Loss: 0.42870667392351275, Train_acc 0.8227370689655172\n",
      "\n",
      "Epoch 6. Loss: 0.42409496439401545, Train_acc 0.8225827991452992\n",
      "\n",
      "Epoch 6. Loss: 0.4257434511146328, Train_acc 0.822166313559322\n",
      "\n",
      "Epoch 6. Loss: 0.44141343569410274, Train_acc 0.8213629201680672\n",
      "\n",
      "Epoch 6. Loss: 0.44417418839620737, Train_acc 0.8208984375\n",
      "\n",
      "Epoch 6. Loss: 0.43884126367050874, Train_acc 0.8206998966942148\n",
      "\n",
      "Epoch 6. Loss: 0.4433298053313357, Train_acc 0.8200563524590164\n",
      "\n",
      "Epoch 6. Loss: 0.43701210695228543, Train_acc 0.8199314024390244\n",
      "\n",
      "Epoch 6. Loss: 0.4239612020050427, Train_acc 0.8206275201612904\n",
      "\n",
      "Epoch 6. Loss: 0.4190376696284063, Train_acc 0.820625\n",
      "\n",
      "Epoch 6. Loss: 0.4243933168615801, Train_acc 0.8201264880952381\n",
      "\n",
      "Epoch 6. Loss: 0.43088363476686803, Train_acc 0.8200049212598425\n",
      "\n",
      "Epoch 6. Loss: 0.42575206340634636, Train_acc 0.81976318359375\n",
      "\n",
      "Epoch 6. Loss: 0.4322134552712782, Train_acc 0.8194646317829457\n",
      "\n",
      "Epoch 6. Loss: 0.4378329960985968, Train_acc 0.8188100961538461\n",
      "\n",
      "Epoch 6. Loss: 0.4269029481843701, Train_acc 0.8192390267175572\n",
      "\n",
      "Epoch 6. Loss: 0.42131150218566576, Train_acc 0.8193063446969697\n",
      "\n",
      "Epoch 6. Loss: 0.4236152123158007, Train_acc 0.8189027255639098\n",
      "\n",
      "Epoch 6. Loss: 0.4286241964171674, Train_acc 0.8182719216417911\n",
      "\n",
      "Epoch 6. Loss: 0.43412870487603666, Train_acc 0.818113425925926\n",
      "\n",
      "Epoch 6. Loss: 0.4327513067814689, Train_acc 0.8176125919117647\n",
      "\n",
      "Epoch 6. Loss: 0.43193222483035754, Train_acc 0.8174612226277372\n",
      "\n",
      "Epoch 6. Loss: 0.42260288953814057, Train_acc 0.8176517210144928\n",
      "\n",
      "Epoch 6. Loss: 0.4307396032813175, Train_acc 0.8174460431654677\n",
      "\n",
      "Epoch 6. Loss: 0.42392099068191497, Train_acc 0.8179129464285714\n",
      "\n",
      "Epoch 6. Loss: 0.41369992642665077, Train_acc 0.8183732269503546\n",
      "\n",
      "Epoch 6. Loss: 0.4184005989050642, Train_acc 0.8178917253521126\n",
      "\n",
      "Epoch 6. Loss: 0.4087124168946542, Train_acc 0.8180725524475524\n",
      "\n",
      "Epoch 6. Loss: 0.4076826602286873, Train_acc 0.8179253472222222\n",
      "\n",
      "Epoch 6. Loss: 0.40523000032306716, Train_acc 0.8180495689655173\n",
      "\n",
      "Epoch 6. Loss: 0.4023795915001721, Train_acc 0.8181720890410958\n",
      "\n",
      "Epoch 6. Loss: 0.4049634211379967, Train_acc 0.8180272108843537\n",
      "\n",
      "Epoch 6. Loss: 0.4031655615376248, Train_acc 0.8180954391891891\n",
      "\n",
      "Epoch 6. Loss: 0.40430908135832677, Train_acc 0.8180578859060402\n",
      "\n",
      "Epoch 6. Loss: 0.40596107899184225, Train_acc 0.8180208333333333\n",
      "\n",
      "Epoch 6. Loss: 0.40553460352750303, Train_acc 0.8181912251655629\n",
      "\n",
      "Epoch 6. Loss: 0.4030087754112334, Train_acc 0.8182051809210527\n",
      "\n",
      "Epoch 6. Loss: 0.3939144878073202, Train_acc 0.8187295751633987\n",
      "\n",
      "Epoch 6. Loss: 0.3833516599372327, Train_acc 0.819145698051948\n",
      "\n",
      "Epoch 6. Loss: 0.38162891223746237, Train_acc 0.819304435483871\n",
      "\n",
      "Epoch 6. Loss: 0.3806049539570603, Train_acc 0.8194110576923077\n",
      "\n",
      "Epoch 6. Loss: 0.3818957192234331, Train_acc 0.8195163216560509\n",
      "\n",
      "Epoch 6. Loss: 0.38149404369581946, Train_acc 0.8193730221518988\n",
      "\n",
      "Epoch 6. Loss: 0.38478051283469095, Train_acc 0.81937893081761\n",
      "\n",
      "Epoch 6. Loss: 0.38399119965890316, Train_acc 0.819482421875\n",
      "\n",
      "Epoch 6. Loss: 0.3832507293760115, Train_acc 0.819439052795031\n",
      "\n",
      "Epoch 6. Loss: 0.3805765892272593, Train_acc 0.8194926697530864\n",
      "\n",
      "Epoch 6. Loss: 0.37580870257664334, Train_acc 0.8197852760736196\n",
      "\n",
      "Epoch 6. Loss: 0.3788064420239503, Train_acc 0.8197408536585366\n",
      "\n",
      "Epoch 6. Loss: 0.376354193688903, Train_acc 0.8198863636363637\n",
      "\n",
      "Epoch 6. Loss: 0.37254914283884205, Train_acc 0.8201242469879518\n",
      "\n",
      "Epoch 6. Loss: 0.3686413166534838, Train_acc 0.8204060628742516\n",
      "\n",
      "Epoch 6. Loss: 0.3670610425721351, Train_acc 0.8203590029761905\n",
      "\n",
      "Epoch 6. Loss: 0.3631389592156479, Train_acc 0.8205898668639053\n",
      "\n",
      "Epoch 6. Loss: 0.35995677894941, Train_acc 0.8206801470588235\n",
      "\n",
      "Epoch 6. Loss: 0.3608570199005993, Train_acc 0.8208607456140351\n",
      "\n",
      "Epoch 6. Loss: 0.3641595453733079, Train_acc 0.8207212936046512\n",
      "\n",
      "Epoch 6. Loss: 0.3637347648185974, Train_acc 0.8208995664739884\n",
      "\n",
      "Epoch 6. Loss: 0.3721128579654532, Train_acc 0.8208961925287356\n",
      "\n",
      "Epoch 6. Loss: 0.37332612365587686, Train_acc 0.8209375\n",
      "\n",
      "Epoch 6. Loss: 0.3724561401316894, Train_acc 0.8210227272727273\n",
      "\n",
      "Epoch 6. Loss: 0.3696210117437875, Train_acc 0.8210628531073446\n",
      "\n",
      "Epoch 6. Loss: 0.3801540253727229, Train_acc 0.820970856741573\n",
      "\n",
      "Epoch 6. Loss: 0.3761361764224105, Train_acc 0.8211417597765364\n",
      "\n",
      "Epoch 6. Loss: 0.378872420759654, Train_acc 0.8210069444444444\n",
      "\n",
      "Epoch 6. Loss: 0.3726643380865359, Train_acc 0.8213052486187845\n",
      "\n",
      "Epoch 6. Loss: 0.3719522736082885, Train_acc 0.8213856456043956\n",
      "\n",
      "Epoch 6. Loss: 0.3694262130508196, Train_acc 0.8216359289617486\n",
      "\n",
      "Epoch 6. Loss: 0.37167374105298856, Train_acc 0.8215438179347826\n",
      "\n",
      "Epoch 6. Loss: 0.3737136734519393, Train_acc 0.8214527027027027\n",
      "\n",
      "Epoch 6. Loss: 0.38044632193392436, Train_acc 0.821278561827957\n",
      "\n",
      "Epoch 6. Loss: 0.3741643075669937, Train_acc 0.8213987299465241\n",
      "\n",
      "Epoch 6. Loss: 0.38580828111098403, Train_acc 0.8212682845744681\n",
      "\n",
      "Epoch 6. Loss: 0.3803941476409989, Train_acc 0.8213872354497355\n",
      "\n",
      "Epoch 6. Loss: 0.3741089106856606, Train_acc 0.8216694078947369\n",
      "\n",
      "Epoch 6. Loss: 0.3719998122387071, Train_acc 0.821744109947644\n",
      "\n",
      "Epoch 6. Loss: 0.3645489443361407, Train_acc 0.8220621744791666\n",
      "\n",
      "Epoch 6. Loss: 0.358192911358444, Train_acc 0.8222555051813472\n",
      "\n",
      "Epoch 6. Loss: 0.3501567667231871, Train_acc 0.8225676546391752\n",
      "\n",
      "Epoch 6. Loss: 0.3460919790422243, Train_acc 0.8229567307692308\n",
      "\n",
      "Epoch 6. Loss: 0.35201102491813796, Train_acc 0.82292\n",
      "\n",
      "Epoch 7. Loss: 0.34676012691793945, Train_acc 0.8671875\n",
      "\n",
      "Epoch 7. Loss: 0.34890342918281053, Train_acc 0.84375\n",
      "\n",
      "Epoch 7. Loss: 0.34682949632922677, Train_acc 0.8359375\n",
      "\n",
      "Epoch 7. Loss: 0.34823307022917155, Train_acc 0.830078125\n",
      "\n",
      "Epoch 7. Loss: 0.3508976515424361, Train_acc 0.828125\n",
      "\n",
      "Epoch 7. Loss: 0.3533736601137021, Train_acc 0.8294270833333334\n",
      "\n",
      "Epoch 7. Loss: 0.35412900161709476, Train_acc 0.8325892857142857\n",
      "\n",
      "Epoch 7. Loss: 0.347062908219988, Train_acc 0.83984375\n",
      "\n",
      "Epoch 7. Loss: 0.3445776545474185, Train_acc 0.84375\n",
      "\n",
      "Epoch 7. Loss: 0.3431382754566598, Train_acc 0.84296875\n",
      "\n",
      "Epoch 7. Loss: 0.33807259611388996, Train_acc 0.8494318181818182\n",
      "\n",
      "Epoch 7. Loss: 0.34110701810211796, Train_acc 0.8489583333333334\n",
      "\n",
      "Epoch 7. Loss: 0.3312980910917299, Train_acc 0.8557692307692307\n",
      "\n",
      "Epoch 7. Loss: 0.3253408295613686, Train_acc 0.8588169642857143\n",
      "\n",
      "Epoch 7. Loss: 0.3236125638516688, Train_acc 0.859375\n",
      "\n",
      "Epoch 7. Loss: 0.3149530408172557, Train_acc 0.86376953125\n",
      "\n",
      "Epoch 7. Loss: 0.30790113217134024, Train_acc 0.8653492647058824\n",
      "\n",
      "Epoch 7. Loss: 0.3107109857186563, Train_acc 0.8641493055555556\n",
      "\n",
      "Epoch 7. Loss: 0.3154072367475826, Train_acc 0.8634868421052632\n",
      "\n",
      "Epoch 7. Loss: 0.3286420705908297, Train_acc 0.861328125\n",
      "\n",
      "Epoch 7. Loss: 0.33700566318575376, Train_acc 0.8604910714285714\n",
      "\n",
      "Epoch 7. Loss: 0.3527331813598618, Train_acc 0.8561789772727273\n",
      "\n",
      "Epoch 7. Loss: 0.3544729648016344, Train_acc 0.8552989130434783\n",
      "\n",
      "Epoch 7. Loss: 0.3528653113230274, Train_acc 0.853515625\n",
      "\n",
      "Epoch 7. Loss: 0.35510802818991594, Train_acc 0.853125\n",
      "\n",
      "Epoch 7. Loss: 0.35508853990129696, Train_acc 0.8515625\n",
      "\n",
      "Epoch 7. Loss: 0.3516759705390817, Train_acc 0.8530092592592593\n",
      "\n",
      "Epoch 7. Loss: 0.3476026861530202, Train_acc 0.8543526785714286\n",
      "\n",
      "Epoch 7. Loss: 0.34785963374331513, Train_acc 0.8545258620689655\n",
      "\n",
      "Epoch 7. Loss: 0.35274687359888784, Train_acc 0.85390625\n",
      "\n",
      "Epoch 7. Loss: 0.3458561088159034, Train_acc 0.8550907258064516\n",
      "\n",
      "Epoch 7. Loss: 0.35112652351090456, Train_acc 0.853759765625\n",
      "\n",
      "Epoch 7. Loss: 0.3503625616696103, Train_acc 0.8536931818181818\n",
      "\n",
      "Epoch 7. Loss: 0.3537025682866535, Train_acc 0.8524816176470589\n",
      "\n",
      "Epoch 7. Loss: 0.3596354156202043, Train_acc 0.8513392857142857\n",
      "\n",
      "Epoch 7. Loss: 0.35488792623275206, Train_acc 0.8506944444444444\n",
      "\n",
      "Epoch 7. Loss: 0.36383055775040707, Train_acc 0.8490287162162162\n",
      "\n",
      "Epoch 7. Loss: 0.37997206266529254, Train_acc 0.8460115131578947\n",
      "\n",
      "Epoch 7. Loss: 0.3812469501716515, Train_acc 0.8447516025641025\n",
      "\n",
      "Epoch 7. Loss: 0.3741798811634738, Train_acc 0.8458984375\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7. Loss: 0.3849559289348446, Train_acc 0.8433689024390244\n",
      "\n",
      "Epoch 7. Loss: 0.38436016399851347, Train_acc 0.8431919642857143\n",
      "\n",
      "Epoch 7. Loss: 0.38159443699590184, Train_acc 0.8432049418604651\n",
      "\n",
      "Epoch 7. Loss: 0.3815353253180249, Train_acc 0.8423295454545454\n",
      "\n",
      "Epoch 7. Loss: 0.378782701971632, Train_acc 0.8425347222222223\n",
      "\n",
      "Epoch 7. Loss: 0.386385997369142, Train_acc 0.8418817934782609\n",
      "\n",
      "Epoch 7. Loss: 0.3772542121120557, Train_acc 0.8427526595744681\n",
      "\n",
      "Epoch 7. Loss: 0.3744297303654192, Train_acc 0.84326171875\n",
      "\n",
      "Epoch 7. Loss: 0.37226089339531404, Train_acc 0.84375\n",
      "\n",
      "Epoch 7. Loss: 0.3659800276256526, Train_acc 0.8440625\n",
      "\n",
      "Epoch 7. Loss: 0.373895983555638, Train_acc 0.8431372549019608\n",
      "\n",
      "Epoch 7. Loss: 0.37559284626727396, Train_acc 0.8431490384615384\n",
      "\n",
      "Epoch 7. Loss: 0.37192108505325105, Train_acc 0.84375\n",
      "\n",
      "Epoch 7. Loss: 0.36885507947227286, Train_acc 0.8438946759259259\n",
      "\n",
      "Epoch 7. Loss: 0.3788862500729048, Train_acc 0.8428977272727273\n",
      "\n",
      "Epoch 7. Loss: 0.38533314235286864, Train_acc 0.8413783482142857\n",
      "\n",
      "Epoch 7. Loss: 0.38657971770116945, Train_acc 0.8412828947368421\n",
      "\n",
      "Epoch 7. Loss: 0.38723102406158383, Train_acc 0.8409213362068966\n",
      "\n",
      "Epoch 7. Loss: 0.3860227989747614, Train_acc 0.8404396186440678\n",
      "\n",
      "Epoch 7. Loss: 0.37702789553354593, Train_acc 0.8412760416666667\n",
      "\n",
      "Epoch 7. Loss: 0.37665205581501493, Train_acc 0.8410604508196722\n",
      "\n",
      "Epoch 7. Loss: 0.36817772135301263, Train_acc 0.8416078629032258\n",
      "\n",
      "Epoch 7. Loss: 0.36571588169184777, Train_acc 0.8415178571428571\n",
      "\n",
      "Epoch 7. Loss: 0.3595031504390906, Train_acc 0.8414306640625\n",
      "\n",
      "Epoch 7. Loss: 0.35837928097471033, Train_acc 0.840985576923077\n",
      "\n",
      "Epoch 7. Loss: 0.3517169205041924, Train_acc 0.8411458333333334\n",
      "\n",
      "Epoch 7. Loss: 0.3542140764914929, Train_acc 0.8411847014925373\n",
      "\n",
      "Epoch 7. Loss: 0.35238919939902236, Train_acc 0.8412224264705882\n",
      "\n",
      "Epoch 7. Loss: 0.35021563428318625, Train_acc 0.8413722826086957\n",
      "\n",
      "Epoch 7. Loss: 0.3521336292416703, Train_acc 0.8411830357142858\n",
      "\n",
      "Epoch 7. Loss: 0.3579515077344344, Train_acc 0.8403389084507042\n",
      "\n",
      "Epoch 7. Loss: 0.36541166225121313, Train_acc 0.8399522569444444\n",
      "\n",
      "Epoch 7. Loss: 0.3650576858435204, Train_acc 0.8398972602739726\n",
      "\n",
      "Epoch 7. Loss: 0.3543889989299295, Train_acc 0.8410050675675675\n",
      "\n",
      "Epoch 7. Loss: 0.35610079197669486, Train_acc 0.8408333333333333\n",
      "\n",
      "Epoch 7. Loss: 0.35201948966310437, Train_acc 0.8411800986842105\n",
      "\n",
      "Epoch 7. Loss: 0.3481118954932036, Train_acc 0.841112012987013\n",
      "\n",
      "Epoch 7. Loss: 0.3466876933916219, Train_acc 0.8413461538461539\n",
      "\n",
      "Epoch 7. Loss: 0.3518015375683136, Train_acc 0.8415743670886076\n",
      "\n",
      "Epoch 7. Loss: 0.3515599725499237, Train_acc 0.8416015625\n",
      "\n",
      "Epoch 7. Loss: 0.3439265511501865, Train_acc 0.8423032407407407\n",
      "\n",
      "Epoch 7. Loss: 0.3427303840579721, Train_acc 0.8429878048780488\n",
      "\n",
      "Epoch 7. Loss: 0.3398668506618261, Train_acc 0.8432793674698795\n",
      "\n",
      "Epoch 7. Loss: 0.3455107664056945, Train_acc 0.8430059523809523\n",
      "\n",
      "Epoch 7. Loss: 0.3415415038157995, Train_acc 0.8433823529411765\n",
      "\n",
      "Epoch 7. Loss: 0.3371114328047182, Train_acc 0.8435683139534884\n",
      "\n",
      "Epoch 7. Loss: 0.33627697180574057, Train_acc 0.8434806034482759\n",
      "\n",
      "Epoch 7. Loss: 0.329347917594298, Train_acc 0.8442826704545454\n",
      "\n",
      "Epoch 7. Loss: 0.3229051016191699, Train_acc 0.844627808988764\n",
      "\n",
      "Epoch 7. Loss: 0.3212526454705052, Train_acc 0.8448784722222222\n",
      "\n",
      "Epoch 7. Loss: 0.3172619385282444, Train_acc 0.8451236263736264\n",
      "\n",
      "Epoch 7. Loss: 0.3123105921828968, Train_acc 0.845703125\n",
      "\n",
      "Epoch 7. Loss: 0.3113244794444045, Train_acc 0.8459341397849462\n",
      "\n",
      "Epoch 7. Loss: 0.3082336207600654, Train_acc 0.8463264627659575\n",
      "\n",
      "Epoch 7. Loss: 0.3161777186726529, Train_acc 0.8462171052631579\n",
      "\n",
      "Epoch 7. Loss: 0.32092066660538304, Train_acc 0.8462727864583334\n",
      "\n",
      "Epoch 7. Loss: 0.3215405379684119, Train_acc 0.8461662371134021\n",
      "\n",
      "Epoch 7. Loss: 0.3272447736517801, Train_acc 0.8459821428571429\n",
      "\n",
      "Epoch 7. Loss: 0.3251357303371621, Train_acc 0.8461174242424242\n",
      "\n",
      "Epoch 7. Loss: 0.32119561072980696, Train_acc 0.846328125\n",
      "\n",
      "[Epoch 7 Batch 100] Loss: 0.3175805703115046 Training: accuracy=0.846612\n",
      "Epoch 7. Loss: 0.3175805703115046, Train_acc 0.846612004950495\n",
      "\n",
      "Epoch 7. Loss: 0.3190489198546034, Train_acc 0.8466605392156863\n",
      "\n",
      "Epoch 7. Loss: 0.3224592851800104, Train_acc 0.8466322815533981\n",
      "\n",
      "Epoch 7. Loss: 0.3268280905964118, Train_acc 0.8467548076923077\n",
      "\n",
      "Epoch 7. Loss: 0.325088949425412, Train_acc 0.8469494047619047\n",
      "\n",
      "Epoch 7. Loss: 0.3219025386184986, Train_acc 0.8469192216981132\n",
      "\n",
      "Epoch 7. Loss: 0.33167733724211473, Train_acc 0.8466705607476636\n",
      "\n",
      "Epoch 7. Loss: 0.32932878114546676, Train_acc 0.8468605324074074\n",
      "\n",
      "Epoch 7. Loss: 0.3265188268819333, Train_acc 0.8471903669724771\n",
      "\n",
      "Epoch 7. Loss: 0.3302779136895133, Train_acc 0.8469460227272727\n",
      "\n",
      "Epoch 7. Loss: 0.3333205883621269, Train_acc 0.8468468468468469\n",
      "\n",
      "Epoch 7. Loss: 0.3340654943811083, Train_acc 0.8468191964285714\n",
      "\n",
      "Epoch 7. Loss: 0.33484082589392516, Train_acc 0.8469994469026548\n",
      "\n",
      "Epoch 7. Loss: 0.33475881668786395, Train_acc 0.8471080043859649\n",
      "\n",
      "Epoch 7. Loss: 0.3319739149766581, Train_acc 0.8472826086956522\n",
      "\n",
      "Epoch 7. Loss: 0.32692034364558015, Train_acc 0.84765625\n",
      "\n",
      "Epoch 7. Loss: 0.3289241253210612, Train_acc 0.8476228632478633\n",
      "\n",
      "Epoch 7. Loss: 0.3293787919467844, Train_acc 0.847854872881356\n",
      "\n",
      "Epoch 7. Loss: 0.3252275421905062, Train_acc 0.8480173319327731\n",
      "\n",
      "Epoch 7. Loss: 0.33234079790301996, Train_acc 0.8477864583333333\n",
      "\n",
      "Epoch 7. Loss: 0.3340779493348707, Train_acc 0.8476239669421488\n",
      "\n",
      "Epoch 7. Loss: 0.3330569937911847, Train_acc 0.8477202868852459\n",
      "\n",
      "Epoch 7. Loss: 0.3374975629228847, Train_acc 0.8474339430894309\n",
      "\n",
      "Epoch 7. Loss: 0.34126468666599663, Train_acc 0.8470892137096774\n",
      "\n",
      "Epoch 7. Loss: 0.3337942257661206, Train_acc 0.847375\n",
      "\n",
      "Epoch 7. Loss: 0.3327591563885137, Train_acc 0.84765625\n",
      "\n",
      "Epoch 7. Loss: 0.32859783282501026, Train_acc 0.8479330708661418\n",
      "\n",
      "Epoch 7. Loss: 0.321684952771269, Train_acc 0.84808349609375\n",
      "\n",
      "Epoch 7. Loss: 0.32070776182019956, Train_acc 0.8481710271317829\n",
      "\n",
      "Epoch 7. Loss: 0.31629759691003784, Train_acc 0.8484375\n",
      "\n",
      "Epoch 7. Loss: 0.320859375195299, Train_acc 0.8482228053435115\n",
      "\n",
      "Epoch 7. Loss: 0.3181974791853974, Train_acc 0.8484256628787878\n",
      "\n",
      "Epoch 7. Loss: 0.31573854416930824, Train_acc 0.8485667293233082\n",
      "\n",
      "Epoch 7. Loss: 0.31631039557150736, Train_acc 0.8485307835820896\n",
      "\n",
      "Epoch 7. Loss: 0.31973826566897395, Train_acc 0.8483796296296297\n",
      "\n",
      "Epoch 7. Loss: 0.3182436646183958, Train_acc 0.8482881433823529\n",
      "\n",
      "Epoch 7. Loss: 0.31473248194104114, Train_acc 0.8485401459854015\n",
      "\n",
      "Epoch 7. Loss: 0.3127385585645945, Train_acc 0.8487884963768116\n",
      "\n",
      "Epoch 7. Loss: 0.3064632751768927, Train_acc 0.8490894784172662\n",
      "\n",
      "Epoch 7. Loss: 0.3072535101973504, Train_acc 0.8492745535714286\n",
      "\n",
      "Epoch 7. Loss: 0.3162241671446106, Train_acc 0.8491799645390071\n",
      "\n",
      "Epoch 7. Loss: 0.3087082112398572, Train_acc 0.8495818661971831\n",
      "\n",
      "Epoch 7. Loss: 0.3016358513742829, Train_acc 0.8500874125874126\n",
      "\n",
      "Epoch 7. Loss: 0.3004873662391434, Train_acc 0.8502061631944444\n",
      "\n",
      "Epoch 7. Loss: 0.29011668585531086, Train_acc 0.850646551724138\n",
      "\n",
      "Epoch 7. Loss: 0.2875796212803618, Train_acc 0.8508668664383562\n",
      "\n",
      "Epoch 7. Loss: 0.29043531901102926, Train_acc 0.8509778911564626\n",
      "\n",
      "Epoch 7. Loss: 0.2928766234498769, Train_acc 0.8509818412162162\n",
      "\n",
      "Epoch 7. Loss: 0.2904123387141421, Train_acc 0.8513527684563759\n",
      "\n",
      "Epoch 7. Loss: 0.29007035387188745, Train_acc 0.85140625\n",
      "\n",
      "Epoch 7. Loss: 0.29231479667988913, Train_acc 0.851459023178808\n",
      "\n",
      "Epoch 7. Loss: 0.29703920695216207, Train_acc 0.8513569078947368\n",
      "\n",
      "Epoch 7. Loss: 0.29175803613392187, Train_acc 0.8516135620915033\n",
      "\n",
      "Epoch 7. Loss: 0.2996759702419729, Train_acc 0.8515625\n",
      "\n",
      "Epoch 7. Loss: 0.2943179866363547, Train_acc 0.8519153225806452\n",
      "\n",
      "Epoch 7. Loss: 0.29129220193832595, Train_acc 0.8519631410256411\n",
      "\n",
      "Epoch 7. Loss: 0.28715770822354686, Train_acc 0.8522093949044586\n",
      "\n",
      "Epoch 7. Loss: 0.2922617618583608, Train_acc 0.852254746835443\n",
      "\n",
      "Epoch 7. Loss: 0.29491509416785555, Train_acc 0.85249606918239\n",
      "\n",
      "Epoch 7. Loss: 0.2921519942798023, Train_acc 0.852783203125\n",
      "\n",
      "Epoch 7. Loss: 0.29597377786497514, Train_acc 0.852921195652174\n",
      "\n",
      "Epoch 7. Loss: 0.28420505979174593, Train_acc 0.853491512345679\n",
      "\n",
      "Epoch 7. Loss: 0.2897980337606152, Train_acc 0.8534317484662577\n",
      "\n",
      "Epoch 7. Loss: 0.2901819221913469, Train_acc 0.8535632621951219\n",
      "\n",
      "Epoch 7. Loss: 0.28833938891348115, Train_acc 0.8535984848484849\n",
      "\n",
      "Epoch 7. Loss: 0.2907184563993532, Train_acc 0.853539156626506\n",
      "\n",
      "Epoch 7. Loss: 0.29965755369536146, Train_acc 0.8533869760479041\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7. Loss: 0.30377191924696023, Train_acc 0.8531436011904762\n",
      "\n",
      "Epoch 7. Loss: 0.3036721762148576, Train_acc 0.8533653846153846\n",
      "\n",
      "Epoch 7. Loss: 0.31060785795402857, Train_acc 0.8529871323529412\n",
      "\n",
      "Epoch 7. Loss: 0.3142820842130691, Train_acc 0.8528874269005848\n",
      "\n",
      "Epoch 7. Loss: 0.31037092629644664, Train_acc 0.8530614098837209\n",
      "\n",
      "Epoch 7. Loss: 0.315428701849938, Train_acc 0.8529172687861272\n",
      "\n",
      "Epoch 7. Loss: 0.30623829467191743, Train_acc 0.8533135775862069\n",
      "\n",
      "Epoch 7. Loss: 0.3161287078538041, Train_acc 0.8530803571428571\n",
      "\n",
      "Epoch 7. Loss: 0.31609626733766505, Train_acc 0.8531605113636364\n",
      "\n",
      "Epoch 7. Loss: 0.3111483227328048, Train_acc 0.853416313559322\n",
      "\n",
      "Epoch 7. Loss: 0.31177516321381205, Train_acc 0.8534497893258427\n",
      "\n",
      "Epoch 7. Loss: 0.30633162146842724, Train_acc 0.8534828910614525\n",
      "\n",
      "Epoch 7. Loss: 0.30082320588263495, Train_acc 0.8537326388888888\n",
      "\n",
      "Epoch 7. Loss: 0.30329848901122175, Train_acc 0.8538069751381215\n",
      "\n",
      "Epoch 7. Loss: 0.30103115060051705, Train_acc 0.8538804945054945\n",
      "\n",
      "Epoch 7. Loss: 0.29556585387695217, Train_acc 0.8540385928961749\n",
      "\n",
      "Epoch 7. Loss: 0.2984492513803397, Train_acc 0.854110054347826\n",
      "\n",
      "Epoch 7. Loss: 0.3003675460756798, Train_acc 0.8541385135135136\n",
      "\n",
      "Epoch 7. Loss: 0.29957095860907246, Train_acc 0.8542086693548387\n",
      "\n",
      "Epoch 7. Loss: 0.2969480313015176, Train_acc 0.8544034090909091\n",
      "\n",
      "Epoch 7. Loss: 0.2999952039556676, Train_acc 0.8544298537234043\n",
      "\n",
      "Epoch 7. Loss: 0.2992239595744288, Train_acc 0.8546213624338624\n",
      "\n",
      "Epoch 7. Loss: 0.2983464331591078, Train_acc 0.8546463815789473\n",
      "\n",
      "Epoch 7. Loss: 0.30427407602941525, Train_acc 0.8541803010471204\n",
      "\n",
      "Epoch 7. Loss: 0.2999183360976774, Train_acc 0.8544514973958334\n",
      "\n",
      "Epoch 7. Loss: 0.2908340505578636, Train_acc 0.8548818005181347\n",
      "\n",
      "Epoch 7. Loss: 0.2940069954233038, Train_acc 0.8550257731958762\n",
      "\n",
      "Epoch 7. Loss: 0.29247513001889, Train_acc 0.8552483974358974\n",
      "\n",
      "Epoch 7. Loss: 0.2992756895935238, Train_acc 0.85516\n",
      "\n",
      "Epoch 8. Loss: 0.3198395490094156, Train_acc 0.796875\n",
      "\n",
      "Epoch 8. Loss: 0.31346019084252097, Train_acc 0.84375\n",
      "\n",
      "Epoch 8. Loss: 0.3068449286371217, Train_acc 0.8645833333333334\n",
      "\n",
      "Epoch 8. Loss: 0.31389428267625685, Train_acc 0.857421875\n",
      "\n",
      "Epoch 8. Loss: 0.306233436671624, Train_acc 0.865625\n",
      "\n",
      "Epoch 8. Loss: 0.3157967008421386, Train_acc 0.8541666666666666\n",
      "\n",
      "Epoch 8. Loss: 0.32303548550035643, Train_acc 0.8493303571428571\n",
      "\n",
      "Epoch 8. Loss: 0.3132997783609577, Train_acc 0.857421875\n",
      "\n",
      "Epoch 8. Loss: 0.30669609003558884, Train_acc 0.8602430555555556\n",
      "\n",
      "Epoch 8. Loss: 0.311787104248659, Train_acc 0.85703125\n",
      "\n",
      "Epoch 8. Loss: 0.31588627306192174, Train_acc 0.8551136363636364\n",
      "\n",
      "Epoch 8. Loss: 0.3088709569654082, Train_acc 0.8587239583333334\n",
      "\n",
      "Epoch 8. Loss: 0.3097045978916778, Train_acc 0.8623798076923077\n",
      "\n",
      "Epoch 8. Loss: 0.3186569029998565, Train_acc 0.8582589285714286\n",
      "\n",
      "Epoch 8. Loss: 0.31205278172300316, Train_acc 0.8619791666666666\n",
      "\n",
      "Epoch 8. Loss: 0.3116606134254282, Train_acc 0.86181640625\n",
      "\n",
      "Epoch 8. Loss: 0.3168715797136914, Train_acc 0.8616727941176471\n",
      "\n",
      "Epoch 8. Loss: 0.3177025254610799, Train_acc 0.8615451388888888\n",
      "\n",
      "Epoch 8. Loss: 0.318806371335115, Train_acc 0.8618421052631579\n",
      "\n",
      "Epoch 8. Loss: 0.31198951117151325, Train_acc 0.863671875\n",
      "\n",
      "Epoch 8. Loss: 0.304825131702006, Train_acc 0.8664434523809523\n",
      "\n",
      "Epoch 8. Loss: 0.2945227306552948, Train_acc 0.8689630681818182\n",
      "\n",
      "Epoch 8. Loss: 0.29093815816654756, Train_acc 0.8705842391304348\n",
      "\n",
      "Epoch 8. Loss: 0.29029756128681294, Train_acc 0.8717447916666666\n",
      "\n",
      "Epoch 8. Loss: 0.29303084021710685, Train_acc 0.8703125\n",
      "\n",
      "Epoch 8. Loss: 0.2835345554879606, Train_acc 0.8722956730769231\n",
      "\n",
      "Epoch 8. Loss: 0.29267373876553476, Train_acc 0.8715277777777778\n",
      "\n",
      "Epoch 8. Loss: 0.2856452870081219, Train_acc 0.873046875\n",
      "\n",
      "Epoch 8. Loss: 0.30052221486362996, Train_acc 0.8720366379310345\n",
      "\n",
      "Epoch 8. Loss: 0.2939966738467799, Train_acc 0.8729166666666667\n",
      "\n",
      "Epoch 8. Loss: 0.29175844373512744, Train_acc 0.8729838709677419\n",
      "\n",
      "Epoch 8. Loss: 0.2856692992050214, Train_acc 0.874267578125\n",
      "\n",
      "Epoch 8. Loss: 0.28400416872490314, Train_acc 0.8745265151515151\n",
      "\n",
      "Epoch 8. Loss: 0.28372624547710007, Train_acc 0.8745404411764706\n",
      "\n",
      "Epoch 8. Loss: 0.2760556909271775, Train_acc 0.8758928571428571\n",
      "\n",
      "Epoch 8. Loss: 0.27884522135514306, Train_acc 0.8758680555555556\n",
      "\n",
      "Epoch 8. Loss: 0.2785517727326598, Train_acc 0.8758445945945946\n",
      "\n",
      "Epoch 8. Loss: 0.27793002918284354, Train_acc 0.876233552631579\n",
      "\n",
      "Epoch 8. Loss: 0.2785582136653771, Train_acc 0.8756009615384616\n",
      "\n",
      "Epoch 8. Loss: 0.2833388678618887, Train_acc 0.874609375\n",
      "\n",
      "Epoch 8. Loss: 0.28520711055892284, Train_acc 0.8748094512195121\n",
      "\n",
      "Epoch 8. Loss: 0.27990325502900104, Train_acc 0.8755580357142857\n",
      "\n",
      "Epoch 8. Loss: 0.2853790719421013, Train_acc 0.8748183139534884\n",
      "\n",
      "Epoch 8. Loss: 0.2848286747137878, Train_acc 0.8757102272727273\n",
      "\n",
      "Epoch 8. Loss: 0.284068499732033, Train_acc 0.8756944444444444\n",
      "\n",
      "Epoch 8. Loss: 0.2780843285274645, Train_acc 0.8765285326086957\n",
      "\n",
      "Epoch 8. Loss: 0.2765636629657871, Train_acc 0.8771609042553191\n",
      "\n",
      "Epoch 8. Loss: 0.2813678133604163, Train_acc 0.8772786458333334\n",
      "\n",
      "Epoch 8. Loss: 0.2768193854198367, Train_acc 0.8778698979591837\n",
      "\n",
      "Epoch 8. Loss: 0.27435537934054527, Train_acc 0.8784375\n",
      "\n",
      "Epoch 8. Loss: 0.2740759142614865, Train_acc 0.8782169117647058\n",
      "\n",
      "Epoch 8. Loss: 0.27524337962664336, Train_acc 0.8780048076923077\n",
      "\n",
      "Epoch 8. Loss: 0.266276424784039, Train_acc 0.8789799528301887\n",
      "\n",
      "Epoch 8. Loss: 0.27417907028666844, Train_acc 0.8781828703703703\n",
      "\n",
      "Epoch 8. Loss: 0.2800788424247954, Train_acc 0.8769886363636363\n",
      "\n",
      "Epoch 8. Loss: 0.2887864656896401, Train_acc 0.8763950892857143\n",
      "\n",
      "Epoch 8. Loss: 0.29393252262333114, Train_acc 0.8751370614035088\n",
      "\n",
      "Epoch 8. Loss: 0.29152618821435344, Train_acc 0.875\n",
      "\n",
      "Epoch 8. Loss: 0.2961568502423749, Train_acc 0.8744703389830508\n",
      "\n",
      "Epoch 8. Loss: 0.3079434336278664, Train_acc 0.873046875\n",
      "\n",
      "Epoch 8. Loss: 0.29985818574313766, Train_acc 0.873719262295082\n",
      "\n",
      "Epoch 8. Loss: 0.31151802518502875, Train_acc 0.8722278225806451\n",
      "\n",
      "Epoch 8. Loss: 0.3152716980445624, Train_acc 0.8712797619047619\n",
      "\n",
      "Epoch 8. Loss: 0.30977749759568934, Train_acc 0.8717041015625\n",
      "\n",
      "Epoch 8. Loss: 0.3066000276918486, Train_acc 0.8725961538461539\n",
      "\n",
      "Epoch 8. Loss: 0.3099007964833327, Train_acc 0.8719223484848485\n",
      "\n",
      "Epoch 8. Loss: 0.307692819300629, Train_acc 0.8716184701492538\n",
      "\n",
      "Epoch 8. Loss: 0.30171746772230024, Train_acc 0.8718979779411765\n",
      "\n",
      "Epoch 8. Loss: 0.3049634047898682, Train_acc 0.8712635869565217\n",
      "\n",
      "Epoch 8. Loss: 0.29983753102001837, Train_acc 0.8717633928571429\n",
      "\n",
      "Epoch 8. Loss: 0.30028653863350113, Train_acc 0.871919014084507\n",
      "\n",
      "Epoch 8. Loss: 0.2890052278931101, Train_acc 0.8728298611111112\n",
      "\n",
      "Epoch 8. Loss: 0.29410837412731294, Train_acc 0.8720034246575342\n",
      "\n",
      "Epoch 8. Loss: 0.293494364507703, Train_acc 0.872043918918919\n",
      "\n",
      "Epoch 8. Loss: 0.30684739728663085, Train_acc 0.8713541666666667\n",
      "\n",
      "Epoch 8. Loss: 0.304000983058456, Train_acc 0.8716077302631579\n",
      "\n",
      "Epoch 8. Loss: 0.298823776321748, Train_acc 0.8717532467532467\n",
      "\n",
      "Epoch 8. Loss: 0.2979806475136928, Train_acc 0.8716947115384616\n",
      "\n",
      "Epoch 8. Loss: 0.2921537857318746, Train_acc 0.8720332278481012\n",
      "\n",
      "Epoch 8. Loss: 0.28931950936301, Train_acc 0.87216796875\n",
      "\n",
      "Epoch 8. Loss: 0.29214884110912787, Train_acc 0.8721064814814815\n",
      "\n",
      "Epoch 8. Loss: 0.2999294692453007, Train_acc 0.8716653963414634\n",
      "\n",
      "Epoch 8. Loss: 0.29490575738336977, Train_acc 0.8717996987951807\n",
      "\n",
      "Epoch 8. Loss: 0.30642516506540485, Train_acc 0.8714657738095238\n",
      "\n",
      "Epoch 8. Loss: 0.30064456545854545, Train_acc 0.8716911764705882\n",
      "\n",
      "Epoch 8. Loss: 0.3030806888658846, Train_acc 0.8715479651162791\n",
      "\n",
      "Epoch 8. Loss: 0.30551138009301226, Train_acc 0.8713182471264368\n",
      "\n",
      "Epoch 8. Loss: 0.30529361801449717, Train_acc 0.8713600852272727\n",
      "\n",
      "Epoch 8. Loss: 0.30640595111642116, Train_acc 0.8709620786516854\n",
      "\n",
      "Epoch 8. Loss: 0.30214134711081236, Train_acc 0.87109375\n",
      "\n",
      "Epoch 8. Loss: 0.3033287393276791, Train_acc 0.8707074175824175\n",
      "\n",
      "Epoch 8. Loss: 0.2951413989566178, Train_acc 0.8708389945652174\n",
      "\n",
      "Epoch 8. Loss: 0.29408068065366844, Train_acc 0.871051747311828\n",
      "\n",
      "Epoch 8. Loss: 0.289473673145667, Train_acc 0.8712599734042553\n",
      "\n",
      "Epoch 8. Loss: 0.2868643108970183, Train_acc 0.8716282894736842\n",
      "\n",
      "Epoch 8. Loss: 0.28413842653926535, Train_acc 0.8719889322916666\n",
      "\n",
      "Epoch 8. Loss: 0.2792017626973658, Train_acc 0.8722615979381443\n",
      "\n",
      "Epoch 8. Loss: 0.27336556925290845, Train_acc 0.8728475765306123\n",
      "\n",
      "Epoch 8. Loss: 0.2680618409566345, Train_acc 0.8731849747474747\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8. Loss: 0.2625724817143913, Train_acc 0.873515625\n",
      "\n",
      "[Epoch 8 Batch 100] Loss: 0.267795492246184 Training: accuracy=0.873685\n",
      "Epoch 8. Loss: 0.267795492246184, Train_acc 0.8736850247524752\n",
      "\n",
      "Epoch 8. Loss: 0.2630637994716465, Train_acc 0.874234068627451\n",
      "\n",
      "Epoch 8. Loss: 0.26452899974375066, Train_acc 0.8742415048543689\n",
      "\n",
      "Epoch 8. Loss: 0.26358443500211026, Train_acc 0.8742487980769231\n",
      "\n",
      "Epoch 8. Loss: 0.260802720501514, Train_acc 0.8745535714285714\n",
      "\n",
      "Epoch 8. Loss: 0.26072757349713893, Train_acc 0.8745577830188679\n",
      "\n",
      "Epoch 8. Loss: 0.25867943083915934, Train_acc 0.8747079439252337\n",
      "\n",
      "Epoch 8. Loss: 0.2691801677555486, Train_acc 0.8744936342592593\n",
      "\n",
      "Epoch 8. Loss: 0.2713719508419017, Train_acc 0.8742115825688074\n",
      "\n",
      "Epoch 8. Loss: 0.27967811537113013, Train_acc 0.8737926136363636\n",
      "\n",
      "Epoch 8. Loss: 0.2773755035906394, Train_acc 0.8740146396396397\n",
      "\n",
      "Epoch 8. Loss: 0.2790386535623097, Train_acc 0.8740931919642857\n",
      "\n",
      "Epoch 8. Loss: 0.27590994756505705, Train_acc 0.8743777654867256\n",
      "\n",
      "Epoch 8. Loss: 0.2752449934579654, Train_acc 0.8743832236842105\n",
      "\n",
      "Epoch 8. Loss: 0.2743282280770889, Train_acc 0.8743885869565218\n",
      "\n",
      "Epoch 8. Loss: 0.2864344563252882, Train_acc 0.8739224137931034\n",
      "\n",
      "Epoch 8. Loss: 0.2800171342045506, Train_acc 0.874198717948718\n",
      "\n",
      "Epoch 8. Loss: 0.27980003653917673, Train_acc 0.8740068855932204\n",
      "\n",
      "Epoch 8. Loss: 0.26855368225831355, Train_acc 0.8745404411764706\n",
      "\n",
      "Epoch 8. Loss: 0.27177863546364217, Train_acc 0.874609375\n",
      "\n",
      "Epoch 8. Loss: 0.27416741455929916, Train_acc 0.8743543388429752\n",
      "\n",
      "Epoch 8. Loss: 0.2672214144945512, Train_acc 0.8746798155737705\n",
      "\n",
      "Epoch 8. Loss: 0.26150769303563565, Train_acc 0.8750635162601627\n",
      "\n",
      "Epoch 8. Loss: 0.2813142148583233, Train_acc 0.8746849798387096\n",
      "\n",
      "Epoch 8. Loss: 0.28190117549262345, Train_acc 0.874625\n",
      "\n",
      "Epoch 8. Loss: 0.2733195198002032, Train_acc 0.875062003968254\n",
      "\n",
      "Epoch 8. Loss: 0.26650617174111946, Train_acc 0.875246062992126\n",
      "\n",
      "Epoch 8. Loss: 0.2669245331150574, Train_acc 0.875244140625\n",
      "\n",
      "Epoch 8. Loss: 0.27385335522850895, Train_acc 0.875\n",
      "\n",
      "Epoch 8. Loss: 0.2770604553040315, Train_acc 0.8750600961538462\n",
      "\n",
      "Epoch 8. Loss: 0.2743852372959062, Train_acc 0.8752385496183206\n",
      "\n",
      "Epoch 8. Loss: 0.27095995569182674, Train_acc 0.8754734848484849\n",
      "\n",
      "Epoch 8. Loss: 0.27646286687809146, Train_acc 0.8753524436090225\n",
      "\n",
      "Epoch 8. Loss: 0.27512013973198457, Train_acc 0.8755247201492538\n",
      "\n",
      "Epoch 8. Loss: 0.27876585478844157, Train_acc 0.8755787037037037\n",
      "\n",
      "Epoch 8. Loss: 0.28615214307840386, Train_acc 0.8752297794117647\n",
      "\n",
      "Epoch 8. Loss: 0.29086049687626114, Train_acc 0.875\n",
      "\n",
      "Epoch 8. Loss: 0.2903794463732435, Train_acc 0.8748301630434783\n",
      "\n",
      "Epoch 8. Loss: 0.29064341332840266, Train_acc 0.8749437949640287\n",
      "\n",
      "Epoch 8. Loss: 0.2894248689382733, Train_acc 0.8752232142857143\n",
      "\n",
      "Epoch 8. Loss: 0.293722515568387, Train_acc 0.8751662234042553\n",
      "\n",
      "Epoch 8. Loss: 0.29177268022172287, Train_acc 0.875275088028169\n",
      "\n",
      "Epoch 8. Loss: 0.2954001337934074, Train_acc 0.8751092657342657\n",
      "\n",
      "Epoch 8. Loss: 0.2871142396910671, Train_acc 0.87548828125\n",
      "\n",
      "Epoch 8. Loss: 0.29104130890223534, Train_acc 0.8754310344827586\n",
      "\n",
      "Epoch 8. Loss: 0.2890156694613679, Train_acc 0.875535102739726\n",
      "\n",
      "Epoch 8. Loss: 0.29003202811146833, Train_acc 0.875531462585034\n",
      "\n",
      "Epoch 8. Loss: 0.29278972651301377, Train_acc 0.875316722972973\n",
      "\n",
      "Epoch 8. Loss: 0.2898646882689466, Train_acc 0.8754718959731543\n",
      "\n",
      "Epoch 8. Loss: 0.2863634638354007, Train_acc 0.8753645833333333\n",
      "\n",
      "Epoch 8. Loss: 0.2863416682807943, Train_acc 0.8754656456953642\n",
      "\n",
      "Epoch 8. Loss: 0.2830792735035725, Train_acc 0.8756167763157895\n",
      "\n",
      "Epoch 8. Loss: 0.2862382414950884, Train_acc 0.8755106209150327\n",
      "\n",
      "Epoch 8. Loss: 0.29198188331848, Train_acc 0.8753551136363636\n",
      "\n",
      "Epoch 8. Loss: 0.28675458801203024, Train_acc 0.875554435483871\n",
      "\n",
      "Epoch 8. Loss: 0.2813803014672969, Train_acc 0.8758513621794872\n",
      "\n",
      "Epoch 8. Loss: 0.2837919316456176, Train_acc 0.8758459394904459\n",
      "\n",
      "Epoch 8. Loss: 0.2920209337859264, Train_acc 0.875692246835443\n",
      "\n",
      "Epoch 8. Loss: 0.29785233464141886, Train_acc 0.8753930817610063\n",
      "\n",
      "Epoch 8. Loss: 0.2923577910032887, Train_acc 0.87568359375\n",
      "\n",
      "Epoch 8. Loss: 0.2883218305141048, Train_acc 0.8757278726708074\n",
      "\n",
      "Epoch 8. Loss: 0.2845985034254476, Train_acc 0.8758198302469136\n",
      "\n",
      "Epoch 8. Loss: 0.2876657491159992, Train_acc 0.8757668711656442\n",
      "\n",
      "Epoch 8. Loss: 0.28358716624074193, Train_acc 0.8757621951219512\n",
      "\n",
      "Epoch 8. Loss: 0.28700255623841, Train_acc 0.8757575757575757\n",
      "\n",
      "Epoch 8. Loss: 0.2871398592416976, Train_acc 0.8757530120481928\n",
      "\n",
      "Epoch 8. Loss: 0.28061731139640816, Train_acc 0.876122754491018\n",
      "\n",
      "Epoch 8. Loss: 0.2806947691424561, Train_acc 0.8762555803571429\n",
      "\n",
      "Epoch 8. Loss: 0.28309270112370305, Train_acc 0.8762943786982249\n",
      "\n",
      "Epoch 8. Loss: 0.2816418621121781, Train_acc 0.8763786764705882\n",
      "\n",
      "Epoch 8. Loss: 0.2822615456443075, Train_acc 0.8762792397660819\n",
      "\n",
      "Epoch 8. Loss: 0.27350238876292504, Train_acc 0.8765897529069767\n",
      "\n",
      "Epoch 8. Loss: 0.27853304967358167, Train_acc 0.8763547687861272\n",
      "\n",
      "Epoch 8. Loss: 0.2840047016001444, Train_acc 0.8761673850574713\n",
      "\n",
      "Epoch 8. Loss: 0.2847523421874673, Train_acc 0.8761607142857143\n",
      "\n",
      "Epoch 8. Loss: 0.28321729280033986, Train_acc 0.8763760653409091\n",
      "\n",
      "Epoch 8. Loss: 0.28586482862364604, Train_acc 0.8762800141242938\n",
      "\n",
      "Epoch 8. Loss: 0.28022348159311433, Train_acc 0.8764922752808989\n",
      "\n",
      "Epoch 8. Loss: 0.28112623340271314, Train_acc 0.8764839385474861\n",
      "\n",
      "Epoch 8. Loss: 0.27679365497573377, Train_acc 0.8765625\n",
      "\n",
      "Epoch 8. Loss: 0.28643799384007596, Train_acc 0.8761654005524862\n",
      "\n",
      "Epoch 8. Loss: 0.28205251597973474, Train_acc 0.8762877747252747\n",
      "\n",
      "Epoch 8. Loss: 0.2857469848121354, Train_acc 0.8761953551912568\n",
      "\n",
      "Epoch 8. Loss: 0.29168971759007717, Train_acc 0.8759341032608695\n",
      "\n",
      "Epoch 8. Loss: 0.28861356123023935, Train_acc 0.8760557432432432\n",
      "\n",
      "Epoch 8. Loss: 0.2841990814542804, Train_acc 0.8761760752688172\n",
      "\n",
      "Epoch 8. Loss: 0.287177338534835, Train_acc 0.8761280080213903\n",
      "\n",
      "Epoch 8. Loss: 0.2764364460118798, Train_acc 0.8765791223404256\n",
      "\n",
      "Epoch 8. Loss: 0.2681838314838577, Train_acc 0.876901455026455\n",
      "\n",
      "Epoch 8. Loss: 0.26145494947797376, Train_acc 0.8770970394736842\n",
      "\n",
      "Epoch 8. Loss: 0.25837306949466154, Train_acc 0.8771678664921466\n",
      "\n",
      "Epoch 8. Loss: 0.24973288869532662, Train_acc 0.8774007161458334\n",
      "\n",
      "Epoch 8. Loss: 0.2439970764130895, Train_acc 0.8776311528497409\n",
      "\n",
      "Epoch 8. Loss: 0.24672436946128706, Train_acc 0.8776578608247423\n",
      "\n",
      "Epoch 8. Loss: 0.24218243867303343, Train_acc 0.877764423076923\n",
      "\n",
      "Epoch 8. Loss: 0.25758964279424024, Train_acc 0.87764\n",
      "\n",
      "Epoch 9. Loss: 0.2580239575427551, Train_acc 0.8671875\n",
      "\n",
      "Epoch 9. Loss: 0.2556141496886413, Train_acc 0.88671875\n",
      "\n",
      "Epoch 9. Loss: 0.25421210508253583, Train_acc 0.8958333333333334\n",
      "\n",
      "Epoch 9. Loss: 0.24852443081772096, Train_acc 0.904296875\n",
      "\n",
      "Epoch 9. Loss: 0.24650530823441535, Train_acc 0.9046875\n",
      "\n",
      "Epoch 9. Loss: 0.2483799708638089, Train_acc 0.90234375\n",
      "\n",
      "Epoch 9. Loss: 0.2513323711830524, Train_acc 0.8995535714285714\n",
      "\n",
      "Epoch 9. Loss: 0.2595536727438701, Train_acc 0.890625\n",
      "\n",
      "Epoch 9. Loss: 0.25679774898859853, Train_acc 0.8914930555555556\n",
      "\n",
      "Epoch 9. Loss: 0.2576238377562731, Train_acc 0.89375\n",
      "\n",
      "Epoch 9. Loss: 0.2553809193079087, Train_acc 0.8963068181818182\n",
      "\n",
      "Epoch 9. Loss: 0.25302271461228243, Train_acc 0.8977864583333334\n",
      "\n",
      "Epoch 9. Loss: 0.252673909804878, Train_acc 0.8972355769230769\n",
      "\n",
      "Epoch 9. Loss: 0.25828990257530576, Train_acc 0.8934151785714286\n",
      "\n",
      "Epoch 9. Loss: 0.25644696876480433, Train_acc 0.89375\n",
      "\n",
      "Epoch 9. Loss: 0.25091942362553704, Train_acc 0.89453125\n",
      "\n",
      "Epoch 9. Loss: 0.24672809433251766, Train_acc 0.8933823529411765\n",
      "\n",
      "Epoch 9. Loss: 0.24158253542760147, Train_acc 0.8953993055555556\n",
      "\n",
      "Epoch 9. Loss: 0.24474194293182316, Train_acc 0.8947368421052632\n",
      "\n",
      "Epoch 9. Loss: 0.24007334093714855, Train_acc 0.896484375\n",
      "\n",
      "Epoch 9. Loss: 0.24378380877195388, Train_acc 0.8943452380952381\n",
      "\n",
      "Epoch 9. Loss: 0.24498086305634909, Train_acc 0.89453125\n",
      "\n",
      "Epoch 9. Loss: 0.24456548808971107, Train_acc 0.8950407608695652\n",
      "\n",
      "Epoch 9. Loss: 0.25651182042621723, Train_acc 0.8929036458333334\n",
      "\n",
      "Epoch 9. Loss: 0.26044505811092095, Train_acc 0.89125\n",
      "\n",
      "Epoch 9. Loss: 0.24976558068117652, Train_acc 0.8939302884615384\n",
      "\n",
      "Epoch 9. Loss: 0.24759534220744212, Train_acc 0.8938078703703703\n",
      "\n",
      "Epoch 9. Loss: 0.2574662764744375, Train_acc 0.892578125\n",
      "\n",
      "Epoch 9. Loss: 0.25798927842465763, Train_acc 0.8917025862068966\n",
      "\n",
      "Epoch 9. Loss: 0.2531795033713078, Train_acc 0.8932291666666666\n",
      "\n",
      "Epoch 9. Loss: 0.24964956303535957, Train_acc 0.8939012096774194\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9. Loss: 0.24845461273281924, Train_acc 0.89453125\n",
      "\n",
      "Epoch 9. Loss: 0.24521846375545103, Train_acc 0.8946496212121212\n",
      "\n",
      "Epoch 9. Loss: 0.24594721914839957, Train_acc 0.89453125\n",
      "\n",
      "Epoch 9. Loss: 0.24233068723838522, Train_acc 0.8953125\n",
      "\n",
      "Epoch 9. Loss: 0.24247635632182057, Train_acc 0.8951822916666666\n",
      "\n",
      "Epoch 9. Loss: 0.24527487065873949, Train_acc 0.8946368243243243\n",
      "\n",
      "Epoch 9. Loss: 0.25095823323561917, Train_acc 0.8937088815789473\n",
      "\n",
      "Epoch 9. Loss: 0.2640232227668241, Train_acc 0.8930288461538461\n",
      "\n",
      "Epoch 9. Loss: 0.2574071227692135, Train_acc 0.8935546875\n",
      "\n",
      "Epoch 9. Loss: 0.25543513499342513, Train_acc 0.8942454268292683\n",
      "\n",
      "Epoch 9. Loss: 0.25225279870012207, Train_acc 0.89453125\n",
      "\n",
      "Epoch 9. Loss: 0.25024427004795197, Train_acc 0.8951671511627907\n",
      "\n",
      "Epoch 9. Loss: 0.2509393962753498, Train_acc 0.8954190340909091\n",
      "\n",
      "Epoch 9. Loss: 0.25446522288316636, Train_acc 0.8946180555555555\n",
      "\n",
      "Epoch 9. Loss: 0.25495105432981985, Train_acc 0.8943614130434783\n",
      "\n",
      "Epoch 9. Loss: 0.24980113012356822, Train_acc 0.8949468085106383\n",
      "\n",
      "Epoch 9. Loss: 0.2509769568094307, Train_acc 0.8948567708333334\n",
      "\n",
      "Epoch 9. Loss: 0.24659549318987378, Train_acc 0.8954081632653061\n",
      "\n",
      "Epoch 9. Loss: 0.25192791035686357, Train_acc 0.89453125\n",
      "\n",
      "Epoch 9. Loss: 0.24452681670410414, Train_acc 0.8950674019607843\n",
      "\n",
      "Epoch 9. Loss: 0.24811149534424826, Train_acc 0.8946814903846154\n",
      "\n",
      "Epoch 9. Loss: 0.24366836306608336, Train_acc 0.8948997641509434\n",
      "\n",
      "Epoch 9. Loss: 0.23585624000868158, Train_acc 0.8953993055555556\n",
      "\n",
      "Epoch 9. Loss: 0.2365376696119394, Train_acc 0.8955965909090909\n",
      "\n",
      "Epoch 9. Loss: 0.2383060078438836, Train_acc 0.8955078125\n",
      "\n",
      "Epoch 9. Loss: 0.23459681456834533, Train_acc 0.8961074561403509\n",
      "\n",
      "Epoch 9. Loss: 0.2408905409474712, Train_acc 0.8962823275862069\n",
      "\n",
      "Epoch 9. Loss: 0.23840713048275186, Train_acc 0.8957891949152542\n",
      "\n",
      "Epoch 9. Loss: 0.24848534057404884, Train_acc 0.8947916666666667\n",
      "\n",
      "Epoch 9. Loss: 0.2350666647243466, Train_acc 0.8961321721311475\n",
      "\n",
      "Epoch 9. Loss: 0.23336115107726746, Train_acc 0.8960433467741935\n",
      "\n",
      "Epoch 9. Loss: 0.23171982728652682, Train_acc 0.8960813492063492\n",
      "\n",
      "Epoch 9. Loss: 0.22994602230083222, Train_acc 0.896484375\n",
      "\n",
      "Epoch 9. Loss: 0.22976156479321072, Train_acc 0.8965144230769231\n",
      "\n",
      "Epoch 9. Loss: 0.23337346976580156, Train_acc 0.8960700757575758\n",
      "\n",
      "Epoch 9. Loss: 0.22998701929076254, Train_acc 0.8964552238805971\n",
      "\n",
      "Epoch 9. Loss: 0.24057055770478017, Train_acc 0.896484375\n",
      "\n",
      "Epoch 9. Loss: 0.24321341746259958, Train_acc 0.896286231884058\n",
      "\n",
      "Epoch 9. Loss: 0.24745747655519154, Train_acc 0.8958705357142858\n",
      "\n",
      "Epoch 9. Loss: 0.2402376745035199, Train_acc 0.8963468309859155\n",
      "\n",
      "Epoch 9. Loss: 0.23835709964245091, Train_acc 0.8961588541666666\n",
      "\n",
      "Epoch 9. Loss: 0.2305202151090759, Train_acc 0.8967251712328768\n",
      "\n",
      "Epoch 9. Loss: 0.22602187526978773, Train_acc 0.8968538851351351\n",
      "\n",
      "Epoch 9. Loss: 0.21987331896505705, Train_acc 0.8973958333333333\n",
      "\n",
      "Epoch 9. Loss: 0.21248588999642687, Train_acc 0.8980263157894737\n",
      "\n",
      "Epoch 9. Loss: 0.21498661673546215, Train_acc 0.8981331168831169\n",
      "\n",
      "Epoch 9. Loss: 0.21743852886391027, Train_acc 0.8982371794871795\n",
      "\n",
      "Epoch 9. Loss: 0.2219565927341492, Train_acc 0.8981408227848101\n",
      "\n",
      "Epoch 9. Loss: 0.22444607192470828, Train_acc 0.898046875\n",
      "\n",
      "Epoch 9. Loss: 0.2234927851634699, Train_acc 0.8982445987654321\n",
      "\n",
      "Epoch 9. Loss: 0.232802555442823, Train_acc 0.8979611280487805\n",
      "\n",
      "Epoch 9. Loss: 0.22983465684739324, Train_acc 0.8982492469879518\n",
      "\n",
      "Epoch 9. Loss: 0.22866550618369197, Train_acc 0.8980654761904762\n",
      "\n",
      "Epoch 9. Loss: 0.2279502856787337, Train_acc 0.8983455882352941\n",
      "\n",
      "Epoch 9. Loss: 0.222989226107862, Train_acc 0.8988008720930233\n",
      "\n",
      "Epoch 9. Loss: 0.229509596280813, Train_acc 0.8987068965517241\n",
      "\n",
      "Epoch 9. Loss: 0.22953496955564, Train_acc 0.8987038352272727\n",
      "\n",
      "Epoch 9. Loss: 0.22367853745279054, Train_acc 0.8991397471910112\n",
      "\n",
      "Epoch 9. Loss: 0.2272789075177074, Train_acc 0.8990451388888889\n",
      "\n",
      "Epoch 9. Loss: 0.22822858937393076, Train_acc 0.8987809065934066\n",
      "\n",
      "Epoch 9. Loss: 0.22759158207008642, Train_acc 0.8989470108695652\n",
      "\n",
      "Epoch 9. Loss: 0.23014528566327158, Train_acc 0.8989415322580645\n",
      "\n",
      "Epoch 9. Loss: 0.23248930287712632, Train_acc 0.8990192819148937\n",
      "\n",
      "Epoch 9. Loss: 0.22856052081901268, Train_acc 0.8993421052631579\n",
      "\n",
      "Epoch 9. Loss: 0.22137570704029594, Train_acc 0.89990234375\n",
      "\n",
      "Epoch 9. Loss: 0.22673062376683886, Train_acc 0.8997261597938144\n",
      "\n",
      "Epoch 9. Loss: 0.2229442676231796, Train_acc 0.9003507653061225\n",
      "\n",
      "Epoch 9. Loss: 0.2307128739648045, Train_acc 0.9000157828282829\n",
      "\n",
      "Epoch 9. Loss: 0.23506385376688665, Train_acc 0.899921875\n",
      "\n",
      "[Epoch 9 Batch 100] Loss: 0.24463175497028375 Training: accuracy=0.899830\n",
      "Epoch 9. Loss: 0.24463175497028375, Train_acc 0.8998298267326733\n",
      "\n",
      "Epoch 9. Loss: 0.2332135000369532, Train_acc 0.9005821078431373\n",
      "\n",
      "Epoch 9. Loss: 0.23728052603080124, Train_acc 0.9004854368932039\n",
      "\n",
      "Epoch 9. Loss: 0.23981943869776357, Train_acc 0.9003155048076923\n",
      "\n",
      "Epoch 9. Loss: 0.23778478483128695, Train_acc 0.9004464285714285\n",
      "\n",
      "Epoch 9. Loss: 0.24159057599098815, Train_acc 0.9003537735849056\n",
      "\n",
      "Epoch 9. Loss: 0.2468128174107492, Train_acc 0.9002628504672897\n",
      "\n",
      "Epoch 9. Loss: 0.24798506226192893, Train_acc 0.9002459490740741\n",
      "\n",
      "Epoch 9. Loss: 0.2470265691821365, Train_acc 0.9002293577981652\n",
      "\n",
      "Epoch 9. Loss: 0.25175985086064834, Train_acc 0.8999289772727272\n",
      "\n",
      "Epoch 9. Loss: 0.24731876005024878, Train_acc 0.9001266891891891\n",
      "\n",
      "Epoch 9. Loss: 0.25144992067776173, Train_acc 0.8998325892857143\n",
      "\n",
      "Epoch 9. Loss: 0.24651146049227163, Train_acc 0.9001659292035398\n",
      "\n",
      "Epoch 9. Loss: 0.2568418721699045, Train_acc 0.8995339912280702\n",
      "\n",
      "Epoch 9. Loss: 0.2695090329954022, Train_acc 0.8992527173913043\n",
      "\n",
      "Epoch 9. Loss: 0.26783177163979355, Train_acc 0.8989762931034483\n",
      "\n",
      "Epoch 9. Loss: 0.26784662222964417, Train_acc 0.898704594017094\n",
      "\n",
      "Epoch 9. Loss: 0.2668598873862879, Train_acc 0.898636122881356\n",
      "\n",
      "Epoch 9. Loss: 0.2646143570645979, Train_acc 0.8985688025210085\n",
      "\n",
      "Epoch 9. Loss: 0.26307375446894743, Train_acc 0.8986979166666667\n",
      "\n",
      "Epoch 9. Loss: 0.2668835093015937, Train_acc 0.8983729338842975\n",
      "\n",
      "Epoch 9. Loss: 0.2721735271305896, Train_acc 0.8981173155737705\n",
      "\n",
      "Epoch 9. Loss: 0.2726555197677962, Train_acc 0.8979293699186992\n",
      "\n",
      "Epoch 9. Loss: 0.27417576276439, Train_acc 0.8978704637096774\n",
      "\n",
      "Epoch 9. Loss: 0.2867333408878228, Train_acc 0.897125\n",
      "\n",
      "Epoch 9. Loss: 0.2917475268262012, Train_acc 0.896453373015873\n",
      "\n",
      "Epoch 9. Loss: 0.29314985558546036, Train_acc 0.8962844488188977\n",
      "\n",
      "Epoch 9. Loss: 0.28629296140512633, Train_acc 0.89642333984375\n",
      "\n",
      "Epoch 9. Loss: 0.2808547507224155, Train_acc 0.896499515503876\n",
      "\n",
      "Epoch 9. Loss: 0.2767299986330574, Train_acc 0.8964543269230769\n",
      "\n",
      "Epoch 9. Loss: 0.27115443734358896, Train_acc 0.8966483778625954\n",
      "\n",
      "Epoch 9. Loss: 0.26476003427533346, Train_acc 0.8966619318181818\n",
      "\n",
      "Epoch 9. Loss: 0.26152004926706585, Train_acc 0.896734022556391\n",
      "\n",
      "Epoch 9. Loss: 0.25851069506381663, Train_acc 0.8968050373134329\n",
      "\n",
      "Epoch 9. Loss: 0.26532487824298184, Train_acc 0.8962962962962963\n",
      "\n",
      "Epoch 9. Loss: 0.25713203926149525, Train_acc 0.896484375\n",
      "\n",
      "Epoch 9. Loss: 0.25569157224235106, Train_acc 0.8966697080291971\n",
      "\n",
      "Epoch 9. Loss: 0.24845576364997476, Train_acc 0.8970221920289855\n",
      "\n",
      "Epoch 9. Loss: 0.2535258628058742, Train_acc 0.8967513489208633\n",
      "\n",
      "Epoch 9. Loss: 0.25242570314958485, Train_acc 0.8968191964285714\n",
      "\n",
      "Epoch 9. Loss: 0.24421395904560203, Train_acc 0.8971631205673759\n",
      "\n",
      "Epoch 9. Loss: 0.24234389257495983, Train_acc 0.897337147887324\n",
      "\n",
      "Epoch 9. Loss: 0.23918202810345934, Train_acc 0.8974541083916084\n",
      "\n",
      "Epoch 9. Loss: 0.23687845730357332, Train_acc 0.8974066840277778\n",
      "\n",
      "Epoch 9. Loss: 0.2370253795108762, Train_acc 0.8974137931034483\n",
      "\n",
      "Epoch 9. Loss: 0.23142541292800606, Train_acc 0.8975813356164384\n",
      "\n",
      "Epoch 9. Loss: 0.23891342738414498, Train_acc 0.8974277210884354\n",
      "\n",
      "Epoch 9. Loss: 0.2300834512038054, Train_acc 0.8978040540540541\n",
      "\n",
      "Epoch 9. Loss: 0.2284310300937017, Train_acc 0.8978083053691275\n",
      "\n",
      "Epoch 9. Loss: 0.23946844397104264, Train_acc 0.8975\n",
      "\n",
      "Epoch 9. Loss: 0.24146111778721047, Train_acc 0.8972475165562914\n",
      "\n",
      "Epoch 9. Loss: 0.24579849218402655, Train_acc 0.8970497532894737\n",
      "\n",
      "Epoch 9. Loss: 0.24468798674709516, Train_acc 0.8970077614379085\n",
      "\n",
      "Epoch 9. Loss: 0.24271231357068046, Train_acc 0.8970170454545454\n",
      "\n",
      "Epoch 9. Loss: 0.23727471051046453, Train_acc 0.8972278225806452\n",
      "\n",
      "Epoch 9. Loss: 0.23537276015367392, Train_acc 0.897285657051282\n",
      "\n",
      "Epoch 9. Loss: 0.23229544602948085, Train_acc 0.8972929936305732\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9. Loss: 0.22963432887003712, Train_acc 0.8973991297468354\n",
      "\n",
      "Epoch 9. Loss: 0.23525881247644925, Train_acc 0.8974547955974843\n",
      "\n",
      "Epoch 9. Loss: 0.23869026431672546, Train_acc 0.89716796875\n",
      "\n",
      "Epoch 9. Loss: 0.2408293252816746, Train_acc 0.8969332298136646\n",
      "\n",
      "Epoch 9. Loss: 0.24366005053796913, Train_acc 0.8968942901234568\n",
      "\n",
      "Epoch 9. Loss: 0.2382488962174524, Train_acc 0.8970954754601227\n",
      "\n",
      "Epoch 9. Loss: 0.24250236596117045, Train_acc 0.8969131097560976\n",
      "\n",
      "Epoch 9. Loss: 0.24619464378460906, Train_acc 0.8966856060606061\n",
      "\n",
      "Epoch 9. Loss: 0.24369857133243678, Train_acc 0.8966961596385542\n",
      "\n",
      "Epoch 9. Loss: 0.2413231216741878, Train_acc 0.8968469311377245\n",
      "\n",
      "Epoch 9. Loss: 0.2427729919141482, Train_acc 0.8967633928571429\n",
      "\n",
      "Epoch 9. Loss: 0.23325926106446543, Train_acc 0.8970044378698225\n",
      "\n",
      "Epoch 9. Loss: 0.23100661970323527, Train_acc 0.8971966911764706\n",
      "\n",
      "Epoch 9. Loss: 0.2292362428052384, Train_acc 0.8971582602339181\n",
      "\n",
      "Epoch 9. Loss: 0.2286446371385299, Train_acc 0.8972111191860465\n",
      "\n",
      "Epoch 9. Loss: 0.2320090543069401, Train_acc 0.8969924132947977\n",
      "\n",
      "Epoch 9. Loss: 0.23480224706273903, Train_acc 0.8969558189655172\n",
      "\n",
      "Epoch 9. Loss: 0.24393896547742155, Train_acc 0.8965625\n",
      "\n",
      "Epoch 9. Loss: 0.24235482771206618, Train_acc 0.8965731534090909\n",
      "\n",
      "Epoch 9. Loss: 0.25378674947329216, Train_acc 0.8961864406779662\n",
      "\n",
      "Epoch 9. Loss: 0.2561592401543962, Train_acc 0.8961551966292135\n",
      "\n",
      "Epoch 9. Loss: 0.26069312168476344, Train_acc 0.895949720670391\n",
      "\n",
      "Epoch 9. Loss: 0.2649190205930236, Train_acc 0.8958333333333334\n",
      "\n",
      "Epoch 9. Loss: 0.26401168214665915, Train_acc 0.8958477209944752\n",
      "\n",
      "Epoch 9. Loss: 0.2603717664544618, Train_acc 0.8959478021978022\n",
      "\n",
      "Epoch 9. Loss: 0.2771773475108894, Train_acc 0.8954064207650273\n",
      "\n",
      "Epoch 9. Loss: 0.2788116458980756, Train_acc 0.8952955163043478\n",
      "\n",
      "Epoch 9. Loss: 0.2794360927279458, Train_acc 0.8950168918918919\n",
      "\n",
      "Epoch 9. Loss: 0.2762624989332854, Train_acc 0.8948252688172043\n",
      "\n",
      "Epoch 9. Loss: 0.28128512236911946, Train_acc 0.8945939171122995\n",
      "\n",
      "Epoch 9. Loss: 0.28161472857092823, Train_acc 0.8943650265957447\n",
      "\n",
      "Epoch 9. Loss: 0.278457806528464, Train_acc 0.8943865740740741\n",
      "\n",
      "Epoch 9. Loss: 0.288013088125755, Train_acc 0.8939967105263158\n",
      "\n",
      "Epoch 9. Loss: 0.28251727886685996, Train_acc 0.8940608638743456\n",
      "\n",
      "Epoch 9. Loss: 0.28000844539126096, Train_acc 0.8940022786458334\n",
      "\n",
      "Epoch 9. Loss: 0.2708849163733751, Train_acc 0.8941466968911918\n",
      "\n",
      "Epoch 9. Loss: 0.27103350030328305, Train_acc 0.8940480025773195\n",
      "\n",
      "Epoch 9. Loss: 0.2651179266000879, Train_acc 0.894150641025641\n",
      "\n",
      "Epoch 9. Loss: 0.2633671640180134, Train_acc 0.89412\n",
      "\n",
      "Epoch 10. Loss: 0.26046407927476617, Train_acc 0.890625\n",
      "\n",
      "Epoch 10. Loss: 0.25638047494950816, Train_acc 0.8984375\n",
      "\n",
      "Epoch 10. Loss: 0.25031531576928134, Train_acc 0.90625\n",
      "\n",
      "Epoch 10. Loss: 0.24696835778310866, Train_acc 0.90625\n",
      "\n",
      "Epoch 10. Loss: 0.24776049168844497, Train_acc 0.9\n",
      "\n",
      "Epoch 10. Loss: 0.24335533271973858, Train_acc 0.9010416666666666\n",
      "\n",
      "Epoch 10. Loss: 0.2350253840453523, Train_acc 0.9095982142857143\n",
      "\n",
      "Epoch 10. Loss: 0.23359551550451796, Train_acc 0.908203125\n",
      "\n",
      "Epoch 10. Loss: 0.2332247035637845, Train_acc 0.9079861111111112\n",
      "\n",
      "Epoch 10. Loss: 0.22985669406670478, Train_acc 0.91015625\n",
      "\n",
      "Epoch 10. Loss: 0.23195968358890548, Train_acc 0.9098011363636364\n",
      "\n",
      "Epoch 10. Loss: 0.23433592280009094, Train_acc 0.9049479166666666\n",
      "\n",
      "Epoch 10. Loss: 0.2324732261323217, Train_acc 0.9056490384615384\n",
      "\n",
      "Epoch 10. Loss: 0.22993961430400162, Train_acc 0.9068080357142857\n",
      "\n",
      "Epoch 10. Loss: 0.23411485067137672, Train_acc 0.9052083333333333\n",
      "\n",
      "Epoch 10. Loss: 0.2287553385895067, Train_acc 0.90576171875\n",
      "\n",
      "Epoch 10. Loss: 0.2219563546182132, Train_acc 0.9085477941176471\n",
      "\n",
      "Epoch 10. Loss: 0.22452219328892972, Train_acc 0.9075520833333334\n",
      "\n",
      "Epoch 10. Loss: 0.21236396135341598, Train_acc 0.9120065789473685\n",
      "\n",
      "Epoch 10. Loss: 0.2099740621577335, Train_acc 0.912890625\n",
      "\n",
      "Epoch 10. Loss: 0.2111163214263886, Train_acc 0.9125744047619048\n",
      "\n",
      "Epoch 10. Loss: 0.20859556276359287, Train_acc 0.9133522727272727\n",
      "\n",
      "Epoch 10. Loss: 0.21480550359569306, Train_acc 0.9120244565217391\n",
      "\n",
      "Epoch 10. Loss: 0.2074596612830369, Train_acc 0.9127604166666666\n",
      "\n",
      "Epoch 10. Loss: 0.20427531264836266, Train_acc 0.91375\n",
      "\n",
      "Epoch 10. Loss: 0.20016299720956093, Train_acc 0.9143629807692307\n",
      "\n",
      "Epoch 10. Loss: 0.19746471377926952, Train_acc 0.9137731481481481\n",
      "\n",
      "Epoch 10. Loss: 0.19800541936800975, Train_acc 0.9137834821428571\n",
      "\n",
      "Epoch 10. Loss: 0.19750312244396895, Train_acc 0.9127155172413793\n",
      "\n",
      "Epoch 10. Loss: 0.20172184356005332, Train_acc 0.9125\n",
      "\n",
      "Epoch 10. Loss: 0.19707452340082535, Train_acc 0.9133064516129032\n",
      "\n",
      "Epoch 10. Loss: 0.20038000866612382, Train_acc 0.913330078125\n",
      "\n",
      "Epoch 10. Loss: 0.20408683232820563, Train_acc 0.9135890151515151\n",
      "\n",
      "Epoch 10. Loss: 0.1993063021810937, Train_acc 0.9147518382352942\n",
      "\n",
      "Epoch 10. Loss: 0.19205225668359588, Train_acc 0.9158482142857143\n",
      "\n",
      "Epoch 10. Loss: 0.19741847957976572, Train_acc 0.9155815972222222\n",
      "\n",
      "Epoch 10. Loss: 0.20376646082825584, Train_acc 0.9153293918918919\n",
      "\n",
      "Epoch 10. Loss: 0.2059985926260989, Train_acc 0.9157072368421053\n",
      "\n",
      "Epoch 10. Loss: 0.2134437230685748, Train_acc 0.914863782051282\n",
      "\n",
      "Epoch 10. Loss: 0.20985601849490976, Train_acc 0.91484375\n",
      "\n",
      "Epoch 10. Loss: 0.21036741888941446, Train_acc 0.9146341463414634\n",
      "\n",
      "Epoch 10. Loss: 0.20559467455525207, Train_acc 0.9151785714285714\n",
      "\n",
      "Epoch 10. Loss: 0.20475733799438783, Train_acc 0.9156976744186046\n",
      "\n",
      "Epoch 10. Loss: 0.19976657798321046, Train_acc 0.9156605113636364\n",
      "\n",
      "Epoch 10. Loss: 0.19771122786788045, Train_acc 0.9159722222222222\n",
      "\n",
      "Epoch 10. Loss: 0.20755238401938586, Train_acc 0.9149116847826086\n",
      "\n",
      "Epoch 10. Loss: 0.21884172321601908, Train_acc 0.9137300531914894\n",
      "\n",
      "Epoch 10. Loss: 0.21864169980207862, Train_acc 0.9137369791666666\n",
      "\n",
      "Epoch 10. Loss: 0.22488210927057073, Train_acc 0.9126275510204082\n",
      "\n",
      "Epoch 10. Loss: 0.21839193997330492, Train_acc 0.9125\n",
      "\n",
      "Epoch 10. Loss: 0.22076936212969148, Train_acc 0.9123774509803921\n",
      "\n",
      "Epoch 10. Loss: 0.22165794802718453, Train_acc 0.9119591346153846\n",
      "\n",
      "Epoch 10. Loss: 0.2237087276549318, Train_acc 0.9118514150943396\n",
      "\n",
      "Epoch 10. Loss: 0.2277670997653465, Train_acc 0.9114583333333334\n",
      "\n",
      "Epoch 10. Loss: 0.22672873421973533, Train_acc 0.9112215909090909\n",
      "\n",
      "Epoch 10. Loss: 0.2359878690642108, Train_acc 0.9098772321428571\n",
      "\n",
      "Epoch 10. Loss: 0.2360297043563714, Train_acc 0.9096765350877193\n",
      "\n",
      "Epoch 10. Loss: 0.23191998297945773, Train_acc 0.9098868534482759\n",
      "\n",
      "Epoch 10. Loss: 0.23324015344658003, Train_acc 0.9095603813559322\n",
      "\n",
      "Epoch 10. Loss: 0.2299875998986826, Train_acc 0.9100260416666667\n",
      "\n",
      "Epoch 10. Loss: 0.22373956899282924, Train_acc 0.9104764344262295\n",
      "\n",
      "Epoch 10. Loss: 0.2166384902039551, Train_acc 0.9110383064516129\n",
      "\n",
      "Epoch 10. Loss: 0.22124209819192142, Train_acc 0.9113343253968254\n",
      "\n",
      "Epoch 10. Loss: 0.22549461261589335, Train_acc 0.9111328125\n",
      "\n",
      "Epoch 10. Loss: 0.23134486320160932, Train_acc 0.9106971153846154\n",
      "\n",
      "Epoch 10. Loss: 0.23288755514511264, Train_acc 0.9107481060606061\n",
      "\n",
      "Epoch 10. Loss: 0.2297577819075179, Train_acc 0.9105643656716418\n",
      "\n",
      "Epoch 10. Loss: 0.2308026487391584, Train_acc 0.91015625\n",
      "\n",
      "Epoch 10. Loss: 0.22584454579008156, Train_acc 0.9103260869565217\n",
      "\n",
      "Epoch 10. Loss: 0.22452269818948986, Train_acc 0.9103794642857143\n",
      "\n",
      "Epoch 10. Loss: 0.2228634699574168, Train_acc 0.9103213028169014\n",
      "\n",
      "Epoch 10. Loss: 0.22269416699329514, Train_acc 0.9098307291666666\n",
      "\n",
      "Epoch 10. Loss: 0.22054828866886647, Train_acc 0.9097816780821918\n",
      "\n",
      "Epoch 10. Loss: 0.2228909313491066, Train_acc 0.9097339527027027\n",
      "\n",
      "Epoch 10. Loss: 0.2179930326173675, Train_acc 0.91\n",
      "\n",
      "Epoch 10. Loss: 0.22145472617417325, Train_acc 0.9097450657894737\n",
      "\n",
      "Epoch 10. Loss: 0.2242632655930795, Train_acc 0.9092938311688312\n",
      "\n",
      "Epoch 10. Loss: 0.22142554807355502, Train_acc 0.9091546474358975\n",
      "\n",
      "Epoch 10. Loss: 0.21626086373052447, Train_acc 0.909315664556962\n",
      "\n",
      "Epoch 10. Loss: 0.21823192243803843, Train_acc 0.908984375\n",
      "\n",
      "Epoch 10. Loss: 0.22377432231631256, Train_acc 0.9080825617283951\n",
      "\n",
      "Epoch 10. Loss: 0.22472166280024986, Train_acc 0.9076791158536586\n",
      "\n",
      "Epoch 10. Loss: 0.23072728449172145, Train_acc 0.9072853915662651\n",
      "\n",
      "Epoch 10. Loss: 0.2274694943493578, Train_acc 0.9073660714285714\n",
      "\n",
      "Epoch 10. Loss: 0.2200474101960039, Train_acc 0.9078125\n",
      "\n",
      "Epoch 10. Loss: 0.21556320714885377, Train_acc 0.9081577034883721\n",
      "\n",
      "Epoch 10. Loss: 0.21347574974239814, Train_acc 0.908135775862069\n",
      "\n",
      "Epoch 10. Loss: 0.21612594799823417, Train_acc 0.9082919034090909\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10. Loss: 0.21960666725003888, Train_acc 0.9079178370786517\n",
      "\n",
      "Epoch 10. Loss: 0.2102437491622344, Train_acc 0.9084201388888888\n",
      "\n",
      "Epoch 10. Loss: 0.2116727121538021, Train_acc 0.9084821428571429\n",
      "\n",
      "Epoch 10. Loss: 0.21335550885195415, Train_acc 0.9085427989130435\n",
      "\n",
      "Epoch 10. Loss: 0.21304351604695512, Train_acc 0.9086021505376344\n",
      "\n",
      "Epoch 10. Loss: 0.20135846301956825, Train_acc 0.9093251329787234\n",
      "\n",
      "Epoch 10. Loss: 0.20662238507011996, Train_acc 0.9090460526315789\n",
      "\n",
      "Epoch 10. Loss: 0.20344174184089422, Train_acc 0.9092610677083334\n",
      "\n",
      "Epoch 10. Loss: 0.1961641098053949, Train_acc 0.9098743556701031\n",
      "\n",
      "Epoch 10. Loss: 0.19253662690446052, Train_acc 0.9103156887755102\n",
      "\n",
      "Epoch 10. Loss: 0.19331463096969076, Train_acc 0.9104324494949495\n",
      "\n",
      "Epoch 10. Loss: 0.19384466187744812, Train_acc 0.9103125\n",
      "\n",
      "[Epoch 10 Batch 100] Loss: 0.197294991403128 Training: accuracy=0.910195\n",
      "Epoch 10. Loss: 0.197294991403128, Train_acc 0.9101949257425742\n",
      "\n",
      "Epoch 10. Loss: 0.19466519611117716, Train_acc 0.9103860294117647\n",
      "\n",
      "Epoch 10. Loss: 0.1985096745822204, Train_acc 0.9103458737864077\n",
      "\n",
      "Epoch 10. Loss: 0.19522938249707575, Train_acc 0.9105318509615384\n",
      "\n",
      "Epoch 10. Loss: 0.196562005146149, Train_acc 0.9107142857142857\n",
      "\n",
      "Epoch 10. Loss: 0.1987622795079379, Train_acc 0.9108195754716981\n",
      "\n",
      "Epoch 10. Loss: 0.20041396626003644, Train_acc 0.9109228971962616\n",
      "\n",
      "Epoch 10. Loss: 0.19823587454707678, Train_acc 0.9110243055555556\n",
      "\n",
      "Epoch 10. Loss: 0.20011870429531864, Train_acc 0.9108371559633027\n",
      "\n",
      "Epoch 10. Loss: 0.198830899884845, Train_acc 0.9110795454545455\n",
      "\n",
      "Epoch 10. Loss: 0.1962350016449796, Train_acc 0.911106418918919\n",
      "\n",
      "Epoch 10. Loss: 0.1908575659049964, Train_acc 0.9114815848214286\n",
      "\n",
      "Epoch 10. Loss: 0.18836507782817627, Train_acc 0.9117118362831859\n",
      "\n",
      "Epoch 10. Loss: 0.1889711149228878, Train_acc 0.9119380482456141\n",
      "\n",
      "Epoch 10. Loss: 0.19016377428411846, Train_acc 0.9118885869565218\n",
      "\n",
      "Epoch 10. Loss: 0.19343230246817533, Train_acc 0.9117726293103449\n",
      "\n",
      "Epoch 10. Loss: 0.1927629719911408, Train_acc 0.9117922008547008\n",
      "\n",
      "Epoch 10. Loss: 0.19501352406189368, Train_acc 0.9118776483050848\n",
      "\n",
      "Epoch 10. Loss: 0.19894552317242795, Train_acc 0.9120273109243697\n",
      "\n",
      "Epoch 10. Loss: 0.1952282883552996, Train_acc 0.9122395833333333\n",
      "\n",
      "Epoch 10. Loss: 0.19659298638954353, Train_acc 0.9120609504132231\n",
      "\n",
      "Epoch 10. Loss: 0.19670691472698384, Train_acc 0.9123335040983607\n",
      "\n",
      "Epoch 10. Loss: 0.19526085301407398, Train_acc 0.9125381097560976\n",
      "\n",
      "Epoch 10. Loss: 0.19183160255105694, Train_acc 0.9126764112903226\n",
      "\n",
      "Epoch 10. Loss: 0.18959269872085513, Train_acc 0.9128125\n",
      "\n",
      "Epoch 10. Loss: 0.1879824246535563, Train_acc 0.9130704365079365\n",
      "\n",
      "Epoch 10. Loss: 0.18763326664893598, Train_acc 0.9130167322834646\n",
      "\n",
      "Epoch 10. Loss: 0.18800716304894186, Train_acc 0.9130859375\n",
      "\n",
      "Epoch 10. Loss: 0.1843275714288583, Train_acc 0.9133357558139535\n",
      "\n",
      "Epoch 10. Loss: 0.19028603628609453, Train_acc 0.9133413461538461\n",
      "\n",
      "Epoch 10. Loss: 0.2036501133024741, Train_acc 0.9129293893129771\n",
      "\n",
      "Epoch 10. Loss: 0.2080859777551933, Train_acc 0.9126420454545454\n",
      "\n",
      "Epoch 10. Loss: 0.21026623283821738, Train_acc 0.9127702067669173\n",
      "\n",
      "Epoch 10. Loss: 0.20510865332184788, Train_acc 0.9129547574626866\n",
      "\n",
      "Epoch 10. Loss: 0.20224054081587692, Train_acc 0.9131365740740741\n",
      "\n",
      "Epoch 10. Loss: 0.21579594990624815, Train_acc 0.9125689338235294\n",
      "\n",
      "Epoch 10. Loss: 0.21675690633964984, Train_acc 0.9125798357664233\n",
      "\n",
      "Epoch 10. Loss: 0.21326153686266344, Train_acc 0.912703804347826\n",
      "\n",
      "Epoch 10. Loss: 0.20990969130952242, Train_acc 0.9129383992805755\n",
      "\n",
      "Epoch 10. Loss: 0.21485333492957726, Train_acc 0.9127232142857142\n",
      "\n",
      "Epoch 10. Loss: 0.22393953666630245, Train_acc 0.9125110815602837\n",
      "\n",
      "Epoch 10. Loss: 0.21904621004053523, Train_acc 0.9126320422535211\n",
      "\n",
      "Epoch 10. Loss: 0.22804876994182383, Train_acc 0.9124781468531469\n",
      "\n",
      "Epoch 10. Loss: 0.24023239759585008, Train_acc 0.9120551215277778\n",
      "\n",
      "Epoch 10. Loss: 0.24179177833778331, Train_acc 0.9120150862068965\n",
      "\n",
      "Epoch 10. Loss: 0.2355922507034183, Train_acc 0.9120826198630136\n",
      "\n",
      "Epoch 10. Loss: 0.22800573230860594, Train_acc 0.9120429421768708\n",
      "\n",
      "Epoch 10. Loss: 0.2241472261048373, Train_acc 0.9118982263513513\n",
      "\n",
      "Epoch 10. Loss: 0.22312922688397915, Train_acc 0.9118603187919463\n",
      "\n",
      "Epoch 10. Loss: 0.2246450326926096, Train_acc 0.9116666666666666\n",
      "\n",
      "Epoch 10. Loss: 0.2175205506759808, Train_acc 0.9118894867549668\n",
      "\n",
      "Epoch 10. Loss: 0.21071758489709427, Train_acc 0.9122121710526315\n",
      "\n",
      "Epoch 10. Loss: 0.2140170137962818, Train_acc 0.9122242647058824\n",
      "\n",
      "Epoch 10. Loss: 0.22767526515255448, Train_acc 0.9116781655844156\n",
      "\n",
      "Epoch 10. Loss: 0.22590753532585572, Train_acc 0.9117943548387096\n",
      "\n",
      "Epoch 10. Loss: 0.23657859054628377, Train_acc 0.9114082532051282\n",
      "\n",
      "Epoch 10. Loss: 0.24543155748328596, Train_acc 0.9110768312101911\n",
      "\n",
      "Epoch 10. Loss: 0.2425266669870707, Train_acc 0.9111946202531646\n",
      "\n",
      "Epoch 10. Loss: 0.24493852555882567, Train_acc 0.9110161163522013\n",
      "\n",
      "Epoch 10. Loss: 0.25480723947404293, Train_acc 0.910693359375\n",
      "\n",
      "Epoch 10. Loss: 0.25092659804330886, Train_acc 0.9108113354037267\n",
      "\n",
      "Epoch 10. Loss: 0.25481784713065586, Train_acc 0.9106385030864198\n",
      "\n",
      "Epoch 10. Loss: 0.25045512054976193, Train_acc 0.9107553680981595\n",
      "\n",
      "Epoch 10. Loss: 0.2554801577444348, Train_acc 0.9103944359756098\n",
      "\n",
      "Epoch 10. Loss: 0.2527959860070473, Train_acc 0.9104640151515152\n",
      "\n",
      "Epoch 10. Loss: 0.25086921304797466, Train_acc 0.9105327560240963\n",
      "\n",
      "Epoch 10. Loss: 0.24718221292199496, Train_acc 0.9105538922155688\n",
      "\n",
      "Epoch 10. Loss: 0.24894285737247887, Train_acc 0.9105282738095238\n",
      "\n",
      "Epoch 10. Loss: 0.24977171306703946, Train_acc 0.9105029585798816\n",
      "\n",
      "Epoch 10. Loss: 0.25306889311874925, Train_acc 0.9102022058823529\n",
      "\n",
      "Epoch 10. Loss: 0.24631376471881586, Train_acc 0.9103161549707602\n",
      "\n",
      "Epoch 10. Loss: 0.26177781587926613, Train_acc 0.9097020348837209\n",
      "\n",
      "Epoch 10. Loss: 0.2573442646809346, Train_acc 0.9096820809248555\n",
      "\n",
      "Epoch 10. Loss: 0.2511568089379006, Train_acc 0.9096623563218391\n",
      "\n",
      "Epoch 10. Loss: 0.24743833721159103, Train_acc 0.9095982142857143\n",
      "\n",
      "Epoch 10. Loss: 0.26032443565557783, Train_acc 0.9090909090909091\n",
      "\n",
      "Epoch 10. Loss: 0.2564129089334344, Train_acc 0.9091189971751412\n",
      "\n",
      "Epoch 10. Loss: 0.2528866742568077, Train_acc 0.9091906601123596\n",
      "\n",
      "Epoch 10. Loss: 0.24589170943351343, Train_acc 0.9092615223463687\n",
      "\n",
      "Epoch 10. Loss: 0.24244680938707372, Train_acc 0.9092447916666667\n",
      "\n",
      "Epoch 10. Loss: 0.2297052131973497, Train_acc 0.9094440607734806\n",
      "\n",
      "Epoch 10. Loss: 0.23686319770361117, Train_acc 0.9090831043956044\n",
      "\n",
      "Epoch 10. Loss: 0.2361055986459118, Train_acc 0.9089395491803278\n",
      "\n",
      "Epoch 10. Loss: 0.23726691541448788, Train_acc 0.9087550951086957\n",
      "\n",
      "Epoch 10. Loss: 0.24022695187367996, Train_acc 0.9086148648648649\n",
      "\n",
      "Epoch 10. Loss: 0.2331985616413176, Train_acc 0.9088541666666666\n",
      "\n",
      "Epoch 10. Loss: 0.23046550009197772, Train_acc 0.9088402406417112\n",
      "\n",
      "Epoch 10. Loss: 0.23088053333950143, Train_acc 0.9087849069148937\n",
      "\n",
      "Epoch 10. Loss: 0.23414216162138074, Train_acc 0.9085648148148148\n",
      "\n",
      "Epoch 10. Loss: 0.2300579195145329, Train_acc 0.9086348684210527\n",
      "\n",
      "Epoch 10. Loss: 0.2291283275118673, Train_acc 0.9086632853403142\n",
      "\n",
      "Epoch 10. Loss: 0.23169418264310399, Train_acc 0.9085286458333334\n",
      "\n",
      "Epoch 10. Loss: 0.22640234311414514, Train_acc 0.9085573186528497\n",
      "\n",
      "Epoch 10. Loss: 0.23198060464852532, Train_acc 0.9083843427835051\n",
      "\n",
      "Epoch 10. Loss: 0.22926222478145492, Train_acc 0.908573717948718\n",
      "\n",
      "Epoch 10. Loss: 0.223810948682971, Train_acc 0.9086\n",
      "\n",
      "Epoch 11. Loss: 0.21894743986709167, Train_acc 0.9375\n",
      "\n",
      "Epoch 11. Loss: 0.2157418216566734, Train_acc 0.9375\n",
      "\n",
      "Epoch 11. Loss: 0.21449241357748144, Train_acc 0.9270833333333334\n",
      "\n",
      "Epoch 11. Loss: 0.21081337616775422, Train_acc 0.921875\n",
      "\n",
      "Epoch 11. Loss: 0.200369382970935, Train_acc 0.93125\n",
      "\n",
      "Epoch 11. Loss: 0.20322613275653653, Train_acc 0.9244791666666666\n",
      "\n",
      "Epoch 11. Loss: 0.19495486786907792, Train_acc 0.9274553571428571\n",
      "\n",
      "Epoch 11. Loss: 0.19205364201318514, Train_acc 0.9306640625\n",
      "\n",
      "Epoch 11. Loss: 0.19376612854466996, Train_acc 0.9296875\n",
      "\n",
      "Epoch 11. Loss: 0.19305783348500277, Train_acc 0.92890625\n",
      "\n",
      "Epoch 11. Loss: 0.18853803429501842, Train_acc 0.9296875\n",
      "\n",
      "Epoch 11. Loss: 0.18002473819402687, Train_acc 0.9329427083333334\n",
      "\n",
      "Epoch 11. Loss: 0.17670207179916947, Train_acc 0.9326923076923077\n",
      "\n",
      "Epoch 11. Loss: 0.17666444144248708, Train_acc 0.9313616071428571\n",
      "\n",
      "Epoch 11. Loss: 0.17167745496272813, Train_acc 0.9322916666666666\n",
      "\n",
      "Epoch 11. Loss: 0.16995667784309182, Train_acc 0.93310546875\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11. Loss: 0.16849277051296052, Train_acc 0.9319852941176471\n",
      "\n",
      "Epoch 11. Loss: 0.1716113087416251, Train_acc 0.9309895833333334\n",
      "\n",
      "Epoch 11. Loss: 0.17331496747260328, Train_acc 0.9313322368421053\n",
      "\n",
      "Epoch 11. Loss: 0.17273282592229577, Train_acc 0.93125\n",
      "\n",
      "Epoch 11. Loss: 0.1653938450044322, Train_acc 0.9330357142857143\n",
      "\n",
      "Epoch 11. Loss: 0.16022346013420177, Train_acc 0.9339488636363636\n",
      "\n",
      "Epoch 11. Loss: 0.15474266344577092, Train_acc 0.9354619565217391\n",
      "\n",
      "Epoch 11. Loss: 0.15716745139005797, Train_acc 0.9345703125\n",
      "\n",
      "Epoch 11. Loss: 0.15774011326589898, Train_acc 0.9346875\n",
      "\n",
      "Epoch 11. Loss: 0.15713317137442873, Train_acc 0.9359975961538461\n",
      "\n",
      "Epoch 11. Loss: 0.15517858661546868, Train_acc 0.9366319444444444\n",
      "\n",
      "Epoch 11. Loss: 0.14847818908692506, Train_acc 0.9380580357142857\n",
      "\n",
      "Epoch 11. Loss: 0.15273956266881028, Train_acc 0.9380387931034483\n",
      "\n",
      "Epoch 11. Loss: 0.15290774829245507, Train_acc 0.9380208333333333\n",
      "\n",
      "Epoch 11. Loss: 0.15689318710914463, Train_acc 0.9375\n",
      "\n",
      "Epoch 11. Loss: 0.16333168447927723, Train_acc 0.9375\n",
      "\n",
      "Epoch 11. Loss: 0.15572478056773026, Train_acc 0.9386837121212122\n",
      "\n",
      "Epoch 11. Loss: 0.15625801248095464, Train_acc 0.9384191176470589\n",
      "\n",
      "Epoch 11. Loss: 0.15371972378559737, Train_acc 0.9388392857142858\n",
      "\n",
      "Epoch 11. Loss: 0.15884747108639327, Train_acc 0.9381510416666666\n",
      "\n",
      "Epoch 11. Loss: 0.15974625200767262, Train_acc 0.9375\n",
      "\n",
      "Epoch 11. Loss: 0.1550416678256298, Train_acc 0.9381167763157895\n",
      "\n",
      "Epoch 11. Loss: 0.15483094424603924, Train_acc 0.938301282051282\n",
      "\n",
      "Epoch 11. Loss: 0.15923136029182566, Train_acc 0.937890625\n",
      "\n",
      "Epoch 11. Loss: 0.15905661928837325, Train_acc 0.9382621951219512\n",
      "\n",
      "Epoch 11. Loss: 0.1668371696607902, Train_acc 0.9371279761904762\n",
      "\n",
      "Epoch 11. Loss: 0.1696076860430808, Train_acc 0.9367732558139535\n",
      "\n",
      "Epoch 11. Loss: 0.17864235076930862, Train_acc 0.9353693181818182\n",
      "\n",
      "Epoch 11. Loss: 0.17635268122220107, Train_acc 0.9350694444444444\n",
      "\n",
      "Epoch 11. Loss: 0.17474002227423252, Train_acc 0.9347826086956522\n",
      "\n",
      "Epoch 11. Loss: 0.16884995030079183, Train_acc 0.9351728723404256\n",
      "\n",
      "Epoch 11. Loss: 0.16828102642339973, Train_acc 0.9348958333333334\n",
      "\n",
      "Epoch 11. Loss: 0.16559168494381762, Train_acc 0.9347895408163265\n",
      "\n",
      "Epoch 11. Loss: 0.16440685805652966, Train_acc 0.935\n",
      "\n",
      "Epoch 11. Loss: 0.16043333158172157, Train_acc 0.9352022058823529\n",
      "\n",
      "Epoch 11. Loss: 0.15724506776282476, Train_acc 0.9353966346153846\n",
      "\n",
      "Epoch 11. Loss: 0.15788878620340782, Train_acc 0.9352889150943396\n",
      "\n",
      "Epoch 11. Loss: 0.17309366721517763, Train_acc 0.9343171296296297\n",
      "\n",
      "Epoch 11. Loss: 0.17101844303554525, Train_acc 0.9345170454545455\n",
      "\n",
      "Epoch 11. Loss: 0.17390211361121743, Train_acc 0.9342912946428571\n",
      "\n",
      "Epoch 11. Loss: 0.17676275465612062, Train_acc 0.9340734649122807\n",
      "\n",
      "Epoch 11. Loss: 0.18220480227820082, Train_acc 0.9339978448275862\n",
      "\n",
      "Epoch 11. Loss: 0.18122909317331318, Train_acc 0.933792372881356\n",
      "\n",
      "Epoch 11. Loss: 0.18262235984131817, Train_acc 0.93359375\n",
      "\n",
      "Epoch 11. Loss: 0.1795926198207598, Train_acc 0.9336577868852459\n",
      "\n",
      "Epoch 11. Loss: 0.1724226493993337, Train_acc 0.9340977822580645\n",
      "\n",
      "Epoch 11. Loss: 0.1699963139914514, Train_acc 0.9342757936507936\n",
      "\n",
      "Epoch 11. Loss: 0.16887431091872226, Train_acc 0.934326171875\n",
      "\n",
      "Epoch 11. Loss: 0.16102347743637002, Train_acc 0.9348557692307692\n",
      "\n",
      "Epoch 11. Loss: 0.16158884738796922, Train_acc 0.9348958333333334\n",
      "\n",
      "Epoch 11. Loss: 0.16520230300647593, Train_acc 0.9348180970149254\n",
      "\n",
      "Epoch 11. Loss: 0.16475297654350915, Train_acc 0.9343979779411765\n",
      "\n",
      "Epoch 11. Loss: 0.1606541192055969, Train_acc 0.9345561594202898\n",
      "\n",
      "Epoch 11. Loss: 0.17126368721019286, Train_acc 0.9340401785714286\n",
      "\n",
      "Epoch 11. Loss: 0.16897511696539277, Train_acc 0.933868838028169\n",
      "\n",
      "Epoch 11. Loss: 0.16394681974400838, Train_acc 0.9340277777777778\n",
      "\n",
      "Epoch 11. Loss: 0.1629150054825821, Train_acc 0.9339683219178082\n",
      "\n",
      "Epoch 11. Loss: 0.17257444041730272, Train_acc 0.9336993243243243\n",
      "\n",
      "Epoch 11. Loss: 0.17626993040229058, Train_acc 0.9329166666666666\n",
      "\n",
      "Epoch 11. Loss: 0.1752613024114237, Train_acc 0.9329769736842105\n",
      "\n",
      "Epoch 11. Loss: 0.18134096290457244, Train_acc 0.9325284090909091\n",
      "\n",
      "Epoch 11. Loss: 0.18039827369858025, Train_acc 0.9325921474358975\n",
      "\n",
      "Epoch 11. Loss: 0.18391802450903535, Train_acc 0.9322587025316456\n",
      "\n",
      "Epoch 11. Loss: 0.19118655807574048, Train_acc 0.93173828125\n",
      "\n",
      "Epoch 11. Loss: 0.1895141072881173, Train_acc 0.9315200617283951\n",
      "\n",
      "Epoch 11. Loss: 0.19950059364544906, Train_acc 0.9309260670731707\n",
      "\n",
      "Epoch 11. Loss: 0.20637479999936423, Train_acc 0.9300640060240963\n",
      "\n",
      "Epoch 11. Loss: 0.20376447063037872, Train_acc 0.9299665178571429\n",
      "\n",
      "Epoch 11. Loss: 0.1966366370440941, Train_acc 0.9304227941176471\n",
      "\n",
      "Epoch 11. Loss: 0.21526018976462669, Train_acc 0.9291424418604651\n",
      "\n",
      "Epoch 11. Loss: 0.21425098954998958, Train_acc 0.9288793103448276\n",
      "\n",
      "Epoch 11. Loss: 0.20840796034959116, Train_acc 0.9290660511363636\n",
      "\n",
      "Epoch 11. Loss: 0.20542818189943277, Train_acc 0.9289852528089888\n",
      "\n",
      "Epoch 11. Loss: 0.2160079975243012, Train_acc 0.9282118055555556\n",
      "\n",
      "Epoch 11. Loss: 0.2159064888342261, Train_acc 0.928228021978022\n",
      "\n",
      "Epoch 11. Loss: 0.21631791407323242, Train_acc 0.9280740489130435\n",
      "\n",
      "Epoch 11. Loss: 0.22202397478630864, Train_acc 0.9275873655913979\n",
      "\n",
      "Epoch 11. Loss: 0.21234006964871935, Train_acc 0.9278590425531915\n",
      "\n",
      "Epoch 11. Loss: 0.2116555984351902, Train_acc 0.9280427631578947\n",
      "\n",
      "Epoch 11. Loss: 0.2088650121272089, Train_acc 0.927978515625\n",
      "\n",
      "Epoch 11. Loss: 0.20393819844548242, Train_acc 0.9282377577319587\n",
      "\n",
      "Epoch 11. Loss: 0.20506963344655338, Train_acc 0.9277742346938775\n",
      "\n",
      "Epoch 11. Loss: 0.20178447555519854, Train_acc 0.9277935606060606\n",
      "\n",
      "Epoch 11. Loss: 0.19812997780160055, Train_acc 0.927578125\n",
      "\n",
      "[Epoch 11 Batch 100] Loss: 0.19283448101803016 Training: accuracy=0.927599\n",
      "Epoch 11. Loss: 0.19283448101803016, Train_acc 0.9275990099009901\n",
      "\n",
      "Epoch 11. Loss: 0.18905243970505314, Train_acc 0.9276194852941176\n",
      "\n",
      "Epoch 11. Loss: 0.18668673662142682, Train_acc 0.9274878640776699\n",
      "\n",
      "Epoch 11. Loss: 0.18155131245669778, Train_acc 0.9275841346153846\n",
      "\n",
      "Epoch 11. Loss: 0.18289996688083163, Train_acc 0.9273065476190476\n",
      "\n",
      "Epoch 11. Loss: 0.1822510853813471, Train_acc 0.9273290094339622\n",
      "\n",
      "Epoch 11. Loss: 0.17924629706797438, Train_acc 0.9274240654205608\n",
      "\n",
      "Epoch 11. Loss: 0.18239159636489247, Train_acc 0.9274450231481481\n",
      "\n",
      "Epoch 11. Loss: 0.18550172376148427, Train_acc 0.927322247706422\n",
      "\n",
      "Epoch 11. Loss: 0.1821452655867862, Train_acc 0.9275568181818182\n",
      "\n",
      "Epoch 11. Loss: 0.17973934368575759, Train_acc 0.927857545045045\n",
      "\n",
      "Epoch 11. Loss: 0.18635543068902327, Train_acc 0.927734375\n",
      "\n",
      "Epoch 11. Loss: 0.1916489709674415, Train_acc 0.9276825221238938\n",
      "\n",
      "Epoch 11. Loss: 0.18610001289180786, Train_acc 0.9280427631578947\n",
      "\n",
      "Epoch 11. Loss: 0.1790565671026576, Train_acc 0.928328804347826\n",
      "\n",
      "Epoch 11. Loss: 0.17527057720719594, Train_acc 0.9284752155172413\n",
      "\n",
      "Epoch 11. Loss: 0.18779274815468924, Train_acc 0.9280849358974359\n",
      "\n",
      "Epoch 11. Loss: 0.1853356420470679, Train_acc 0.9279661016949152\n",
      "\n",
      "Epoch 11. Loss: 0.18721137578547636, Train_acc 0.9277179621848739\n",
      "\n",
      "Epoch 11. Loss: 0.19277841867739537, Train_acc 0.9275390625\n",
      "\n",
      "Epoch 11. Loss: 0.19081213791729132, Train_acc 0.9275568181818182\n",
      "\n",
      "Epoch 11. Loss: 0.1870899622401099, Train_acc 0.9276383196721312\n",
      "\n",
      "Epoch 11. Loss: 0.18486545009259886, Train_acc 0.9277820121951219\n",
      "\n",
      "Epoch 11. Loss: 0.18205480744997715, Train_acc 0.9280493951612904\n",
      "\n",
      "Epoch 11. Loss: 0.18091068241500904, Train_acc 0.9280625\n",
      "\n",
      "Epoch 11. Loss: 0.18422962790880248, Train_acc 0.9279513888888888\n",
      "\n",
      "Epoch 11. Loss: 0.18031706422108693, Train_acc 0.9280265748031497\n",
      "\n",
      "Epoch 11. Loss: 0.183925862695619, Train_acc 0.92791748046875\n",
      "\n",
      "Epoch 11. Loss: 0.18194537662194182, Train_acc 0.9279312015503876\n",
      "\n",
      "Epoch 11. Loss: 0.18356881710343967, Train_acc 0.9277644230769231\n",
      "\n",
      "Epoch 11. Loss: 0.1778108820836551, Train_acc 0.9278387404580153\n",
      "\n",
      "Epoch 11. Loss: 0.1701189901400334, Train_acc 0.9281486742424242\n",
      "\n",
      "Epoch 11. Loss: 0.16430710190254985, Train_acc 0.9285126879699248\n",
      "\n",
      "Epoch 11. Loss: 0.16672921866522913, Train_acc 0.9282882462686567\n",
      "\n",
      "Epoch 11. Loss: 0.1641121687622072, Train_acc 0.9283564814814815\n",
      "\n",
      "Epoch 11. Loss: 0.16839338232259765, Train_acc 0.9283088235294118\n",
      "\n",
      "Epoch 11. Loss: 0.16927353789670005, Train_acc 0.9282618613138686\n",
      "\n",
      "Epoch 11. Loss: 0.17069408223267854, Train_acc 0.928328804347826\n",
      "\n",
      "Epoch 11. Loss: 0.1720611595383566, Train_acc 0.9283947841726619\n",
      "\n",
      "Epoch 11. Loss: 0.16836753576439156, Train_acc 0.9286272321428571\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11. Loss: 0.1673200317273277, Train_acc 0.9286347517730497\n",
      "\n",
      "Epoch 11. Loss: 0.1688429255530004, Train_acc 0.928587147887324\n",
      "\n",
      "Epoch 11. Loss: 0.17113373928470293, Train_acc 0.9284309440559441\n",
      "\n",
      "Epoch 11. Loss: 0.1720108263480921, Train_acc 0.9286024305555556\n",
      "\n",
      "Epoch 11. Loss: 0.16612568999423916, Train_acc 0.9288254310344828\n",
      "\n",
      "Epoch 11. Loss: 0.17142752264524402, Train_acc 0.9287243150684932\n",
      "\n",
      "Epoch 11. Loss: 0.1730022202842078, Train_acc 0.9285714285714286\n",
      "\n",
      "Epoch 11. Loss: 0.1697508830648042, Train_acc 0.9287901182432432\n",
      "\n",
      "Epoch 11. Loss: 0.17541551191997923, Train_acc 0.9287437080536913\n",
      "\n",
      "Epoch 11. Loss: 0.17261239230089545, Train_acc 0.92875\n",
      "\n",
      "Epoch 11. Loss: 0.17475826298701608, Train_acc 0.9286009933774835\n",
      "\n",
      "Epoch 11. Loss: 0.17127523799694638, Train_acc 0.9287623355263158\n",
      "\n",
      "Epoch 11. Loss: 0.17152190339526888, Train_acc 0.9288194444444444\n",
      "\n",
      "Epoch 11. Loss: 0.16598263873423358, Train_acc 0.9289772727272727\n",
      "\n",
      "Epoch 11. Loss: 0.16691627347855467, Train_acc 0.9290322580645162\n",
      "\n",
      "Epoch 11. Loss: 0.16975184003462226, Train_acc 0.9291866987179487\n",
      "\n",
      "Epoch 11. Loss: 0.16808063733532874, Train_acc 0.9290406050955414\n",
      "\n",
      "Epoch 11. Loss: 0.17039070380885765, Train_acc 0.9290941455696202\n",
      "\n",
      "Epoch 11. Loss: 0.16680123972737224, Train_acc 0.9293435534591195\n",
      "\n",
      "Epoch 11. Loss: 0.1703929802880594, Train_acc 0.929248046875\n",
      "\n",
      "Epoch 11. Loss: 0.17031042287700554, Train_acc 0.9292507763975155\n",
      "\n",
      "Epoch 11. Loss: 0.18140627005654436, Train_acc 0.9290605709876543\n",
      "\n",
      "Epoch 11. Loss: 0.18649229758046146, Train_acc 0.9288247699386503\n",
      "\n",
      "Epoch 11. Loss: 0.18303082900996873, Train_acc 0.9288776676829268\n",
      "\n",
      "Epoch 11. Loss: 0.1913873361148465, Train_acc 0.9285037878787878\n",
      "\n",
      "Epoch 11. Loss: 0.18735171168428913, Train_acc 0.9286050451807228\n",
      "\n",
      "Epoch 11. Loss: 0.18468496629043452, Train_acc 0.9286115269461078\n",
      "\n",
      "Epoch 11. Loss: 0.18496894474426537, Train_acc 0.9285249255952381\n",
      "\n",
      "Epoch 11. Loss: 0.18991115065455105, Train_acc 0.9282544378698225\n",
      "\n",
      "Epoch 11. Loss: 0.1905237767580718, Train_acc 0.9280330882352941\n",
      "\n",
      "Epoch 11. Loss: 0.19580977858456108, Train_acc 0.9279513888888888\n",
      "\n",
      "Epoch 11. Loss: 0.19420952678935646, Train_acc 0.9279160610465116\n",
      "\n",
      "Epoch 11. Loss: 0.19558052791252958, Train_acc 0.9277005057803468\n",
      "\n",
      "Epoch 11. Loss: 0.19434119379307535, Train_acc 0.9274874281609196\n",
      "\n",
      "Epoch 11. Loss: 0.18903657599495985, Train_acc 0.9275446428571429\n",
      "\n",
      "Epoch 11. Loss: 0.1949975890297336, Train_acc 0.9272017045454546\n",
      "\n",
      "Epoch 11. Loss: 0.20363879225063108, Train_acc 0.9270391949152542\n",
      "\n",
      "Epoch 11. Loss: 0.1973316045529346, Train_acc 0.9271857443820225\n",
      "\n",
      "Epoch 11. Loss: 0.19649219112932984, Train_acc 0.9269378491620112\n",
      "\n",
      "Epoch 11. Loss: 0.20491306123739753, Train_acc 0.9266059027777778\n",
      "\n",
      "Epoch 11. Loss: 0.21276022914892084, Train_acc 0.9264071132596685\n",
      "\n",
      "Epoch 11. Loss: 0.20370919636349957, Train_acc 0.9265539148351648\n",
      "\n",
      "Epoch 11. Loss: 0.21500478802437556, Train_acc 0.9262295081967213\n",
      "\n",
      "Epoch 11. Loss: 0.23516436474008834, Train_acc 0.9256114130434783\n",
      "\n",
      "Epoch 11. Loss: 0.2243574922366453, Train_acc 0.9258868243243243\n",
      "\n",
      "Epoch 11. Loss: 0.23249421999605113, Train_acc 0.9256552419354839\n",
      "\n",
      "Epoch 11. Loss: 0.248691694311067, Train_acc 0.9249247994652406\n",
      "\n",
      "Epoch 11. Loss: 0.24211367938378262, Train_acc 0.925033244680851\n",
      "\n",
      "Epoch 11. Loss: 0.23788082873933442, Train_acc 0.9249338624338624\n",
      "\n",
      "Epoch 11. Loss: 0.23378610261779662, Train_acc 0.9250411184210526\n",
      "\n",
      "Epoch 11. Loss: 0.2367017714545277, Train_acc 0.9247791230366492\n",
      "\n",
      "Epoch 11. Loss: 0.2333631558744741, Train_acc 0.9247639973958334\n",
      "\n",
      "Epoch 11. Loss: 0.23210972638684207, Train_acc 0.9245871113989638\n",
      "\n",
      "Epoch 11. Loss: 0.24110641859553184, Train_acc 0.9242509664948454\n",
      "\n",
      "Epoch 11. Loss: 0.2438973079554611, Train_acc 0.9241586538461538\n",
      "\n",
      "Epoch 11. Loss: 0.24140925619891648, Train_acc 0.92404\n",
      "\n",
      "Epoch 12. Loss: 0.2299221224834743, Train_acc 0.9453125\n",
      "\n",
      "Epoch 12. Loss: 0.22992157494278753, Train_acc 0.921875\n",
      "\n",
      "Epoch 12. Loss: 0.2257596870236278, Train_acc 0.90625\n",
      "\n",
      "Epoch 12. Loss: 0.21711570650094872, Train_acc 0.91796875\n",
      "\n",
      "Epoch 12. Loss: 0.2065775242127847, Train_acc 0.921875\n",
      "\n",
      "Epoch 12. Loss: 0.20491782099108738, Train_acc 0.91796875\n",
      "\n",
      "Epoch 12. Loss: 0.2046704510161356, Train_acc 0.9151785714285714\n",
      "\n",
      "Epoch 12. Loss: 0.20427962118170342, Train_acc 0.9140625\n",
      "\n",
      "Epoch 12. Loss: 0.19605487710638358, Train_acc 0.9201388888888888\n",
      "\n",
      "Epoch 12. Loss: 0.19560885691407484, Train_acc 0.91875\n",
      "\n",
      "Epoch 12. Loss: 0.1967317813375279, Train_acc 0.9176136363636364\n",
      "\n",
      "Epoch 12. Loss: 0.19891873184490366, Train_acc 0.9166666666666666\n",
      "\n",
      "Epoch 12. Loss: 0.19555995926542427, Train_acc 0.9182692307692307\n",
      "\n",
      "Epoch 12. Loss: 0.19636183737471713, Train_acc 0.9168526785714286\n",
      "\n",
      "Epoch 12. Loss: 0.1887234360762389, Train_acc 0.9192708333333334\n",
      "\n",
      "Epoch 12. Loss: 0.18015583403002783, Train_acc 0.92138671875\n",
      "\n",
      "Epoch 12. Loss: 0.17218135488413183, Train_acc 0.9241727941176471\n",
      "\n",
      "Epoch 12. Loss: 0.1692290666018344, Train_acc 0.9249131944444444\n",
      "\n",
      "Epoch 12. Loss: 0.16091932317445432, Train_acc 0.9263980263157895\n",
      "\n",
      "Epoch 12. Loss: 0.15874589497592825, Train_acc 0.927734375\n",
      "\n",
      "Epoch 12. Loss: 0.15491455657553774, Train_acc 0.9281994047619048\n",
      "\n",
      "Epoch 12. Loss: 0.15051506784503552, Train_acc 0.9289772727272727\n",
      "\n",
      "Epoch 12. Loss: 0.15766480708371008, Train_acc 0.9276494565217391\n",
      "\n",
      "Epoch 12. Loss: 0.14970557148084407, Train_acc 0.9300130208333334\n",
      "\n",
      "Epoch 12. Loss: 0.16071239043616087, Train_acc 0.9278125\n",
      "\n",
      "Epoch 12. Loss: 0.15899273242958933, Train_acc 0.9281850961538461\n",
      "\n",
      "Epoch 12. Loss: 0.1653417109227945, Train_acc 0.9270833333333334\n",
      "\n",
      "Epoch 12. Loss: 0.16561947096378532, Train_acc 0.9268973214285714\n",
      "\n",
      "Epoch 12. Loss: 0.16244125660351746, Train_acc 0.927801724137931\n",
      "\n",
      "Epoch 12. Loss: 0.15847884606801121, Train_acc 0.928125\n",
      "\n",
      "Epoch 12. Loss: 0.15489487118854509, Train_acc 0.9284274193548387\n",
      "\n",
      "Epoch 12. Loss: 0.15638776660562503, Train_acc 0.92822265625\n",
      "\n",
      "Epoch 12. Loss: 0.158557968204626, Train_acc 0.9277935606060606\n",
      "\n",
      "Epoch 12. Loss: 0.15819770711547904, Train_acc 0.9276194852941176\n",
      "\n",
      "Epoch 12. Loss: 0.15971047834652757, Train_acc 0.9276785714285715\n",
      "\n",
      "Epoch 12. Loss: 0.16675629755346266, Train_acc 0.9264322916666666\n",
      "\n",
      "Epoch 12. Loss: 0.16169794014532823, Train_acc 0.9277871621621622\n",
      "\n",
      "Epoch 12. Loss: 0.16548516700958724, Train_acc 0.9274259868421053\n",
      "\n",
      "Epoch 12. Loss: 0.16510418966676754, Train_acc 0.9274839743589743\n",
      "\n",
      "Epoch 12. Loss: 0.17424643559991687, Train_acc 0.926953125\n",
      "\n",
      "Epoch 12. Loss: 0.17326750627523096, Train_acc 0.9274009146341463\n",
      "\n",
      "Epoch 12. Loss: 0.18391732518105597, Train_acc 0.9267113095238095\n",
      "\n",
      "Epoch 12. Loss: 0.18022281656469905, Train_acc 0.926780523255814\n",
      "\n",
      "Epoch 12. Loss: 0.17846636679595115, Train_acc 0.9268465909090909\n",
      "\n",
      "Epoch 12. Loss: 0.18063920176171128, Train_acc 0.9263888888888889\n",
      "\n",
      "Epoch 12. Loss: 0.17876376452573714, Train_acc 0.9264605978260869\n",
      "\n",
      "Epoch 12. Loss: 0.17433113374586623, Train_acc 0.9268617021276596\n",
      "\n",
      "Epoch 12. Loss: 0.1686522567416047, Train_acc 0.9278971354166666\n",
      "\n",
      "Epoch 12. Loss: 0.16590743399961128, Train_acc 0.9284119897959183\n",
      "\n",
      "Epoch 12. Loss: 0.16734362069341543, Train_acc 0.928125\n",
      "\n",
      "Epoch 12. Loss: 0.16728642812585537, Train_acc 0.9281556372549019\n",
      "\n",
      "Epoch 12. Loss: 0.16855701861872407, Train_acc 0.9278846153846154\n",
      "\n",
      "Epoch 12. Loss: 0.1601927777358365, Train_acc 0.9286556603773585\n",
      "\n",
      "Epoch 12. Loss: 0.15897836538211751, Train_acc 0.9285300925925926\n",
      "\n",
      "Epoch 12. Loss: 0.16016208754828198, Train_acc 0.928409090909091\n",
      "\n",
      "Epoch 12. Loss: 0.16199429446623287, Train_acc 0.9285714285714286\n",
      "\n",
      "Epoch 12. Loss: 0.15733560574798788, Train_acc 0.9290021929824561\n",
      "\n",
      "Epoch 12. Loss: 0.15663580733015245, Train_acc 0.9290140086206896\n",
      "\n",
      "Epoch 12. Loss: 0.15099975962168669, Train_acc 0.9296875\n",
      "\n",
      "Epoch 12. Loss: 0.15094559042507436, Train_acc 0.930078125\n",
      "\n",
      "Epoch 12. Loss: 0.15098112507630015, Train_acc 0.930327868852459\n",
      "\n",
      "Epoch 12. Loss: 0.15072317436905466, Train_acc 0.9305695564516129\n",
      "\n",
      "Epoch 12. Loss: 0.1468268798193791, Train_acc 0.9310515873015873\n",
      "\n",
      "Epoch 12. Loss: 0.14111054686320948, Train_acc 0.931640625\n",
      "\n",
      "Epoch 12. Loss: 0.13790356440198237, Train_acc 0.9322115384615385\n",
      "\n",
      "Epoch 12. Loss: 0.1432137488381727, Train_acc 0.931936553030303\n",
      "\n",
      "Epoch 12. Loss: 0.14973443440109463, Train_acc 0.9317863805970149\n",
      "\n",
      "Epoch 12. Loss: 0.14411238156118963, Train_acc 0.9324448529411765\n",
      "\n",
      "Epoch 12. Loss: 0.14536295374356784, Train_acc 0.9325181159420289\n",
      "\n",
      "Epoch 12. Loss: 0.15377442276587855, Train_acc 0.93203125\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12. Loss: 0.1597439265499482, Train_acc 0.9316681338028169\n",
      "\n",
      "Epoch 12. Loss: 0.16332898434251275, Train_acc 0.9315321180555556\n",
      "\n",
      "Epoch 12. Loss: 0.1639294615052616, Train_acc 0.9315068493150684\n",
      "\n",
      "Epoch 12. Loss: 0.1669693610664435, Train_acc 0.9313766891891891\n",
      "\n",
      "Epoch 12. Loss: 0.1682637099858726, Train_acc 0.9313541666666667\n",
      "\n",
      "Epoch 12. Loss: 0.16563151756852312, Train_acc 0.9314350328947368\n",
      "\n",
      "Epoch 12. Loss: 0.16894369554456573, Train_acc 0.9313108766233766\n",
      "\n",
      "Epoch 12. Loss: 0.17384773849192114, Train_acc 0.9308894230769231\n",
      "\n",
      "Epoch 12. Loss: 0.1681592034585135, Train_acc 0.9312697784810127\n",
      "\n",
      "Epoch 12. Loss: 0.167685487921851, Train_acc 0.9310546875\n",
      "\n",
      "Epoch 12. Loss: 0.16921735917551858, Train_acc 0.9308449074074074\n",
      "\n",
      "Epoch 12. Loss: 0.16492813034376688, Train_acc 0.9312118902439024\n",
      "\n",
      "Epoch 12. Loss: 0.17370633664895166, Train_acc 0.9302522590361446\n",
      "\n",
      "Epoch 12. Loss: 0.1707251791641331, Train_acc 0.9302455357142857\n",
      "\n",
      "Epoch 12. Loss: 0.16770679573582556, Train_acc 0.9304227941176471\n",
      "\n",
      "Epoch 12. Loss: 0.16415611195892346, Train_acc 0.930686773255814\n",
      "\n",
      "Epoch 12. Loss: 0.16505596001443493, Train_acc 0.9304058908045977\n",
      "\n",
      "Epoch 12. Loss: 0.15971580856588985, Train_acc 0.9307528409090909\n",
      "\n",
      "Epoch 12. Loss: 0.1512286920566634, Train_acc 0.9312675561797753\n",
      "\n",
      "Epoch 12. Loss: 0.15507419638806066, Train_acc 0.9311631944444444\n",
      "\n",
      "Epoch 12. Loss: 0.1571403270927681, Train_acc 0.931146978021978\n",
      "\n",
      "Epoch 12. Loss: 0.15034247794457795, Train_acc 0.9315557065217391\n",
      "\n",
      "Epoch 12. Loss: 0.16341061018742792, Train_acc 0.9311155913978495\n",
      "\n",
      "Epoch 12. Loss: 0.16440243383798903, Train_acc 0.9307679521276596\n",
      "\n",
      "Epoch 12. Loss: 0.16555248821276938, Train_acc 0.9310032894736842\n",
      "\n",
      "Epoch 12. Loss: 0.15770062915532454, Train_acc 0.9314778645833334\n",
      "\n",
      "Epoch 12. Loss: 0.15443703632398245, Train_acc 0.9317010309278351\n",
      "\n",
      "Epoch 12. Loss: 0.1561900356487375, Train_acc 0.9313616071428571\n",
      "\n",
      "Epoch 12. Loss: 0.15925870350682214, Train_acc 0.9315814393939394\n",
      "\n",
      "Epoch 12. Loss: 0.15262804488852746, Train_acc 0.93203125\n",
      "\n",
      "[Epoch 12 Batch 100] Loss: 0.1548113947556775 Training: accuracy=0.931931\n",
      "Epoch 12. Loss: 0.1548113947556775, Train_acc 0.931930693069307\n",
      "\n",
      "Epoch 12. Loss: 0.15755585212525974, Train_acc 0.9317555147058824\n",
      "\n",
      "Epoch 12. Loss: 0.15219913091376946, Train_acc 0.9321146844660194\n",
      "\n",
      "Epoch 12. Loss: 0.15096539705498987, Train_acc 0.9322415865384616\n",
      "\n",
      "Epoch 12. Loss: 0.14834494843635537, Train_acc 0.9324404761904762\n",
      "\n",
      "Epoch 12. Loss: 0.1509443889965437, Train_acc 0.9322670990566038\n",
      "\n",
      "Epoch 12. Loss: 0.14304479249505597, Train_acc 0.9326810747663551\n",
      "\n",
      "Epoch 12. Loss: 0.13901634697486517, Train_acc 0.9329427083333334\n",
      "\n",
      "Epoch 12. Loss: 0.1483874203357359, Train_acc 0.932769495412844\n",
      "\n",
      "Epoch 12. Loss: 0.14464248403250518, Train_acc 0.9329545454545455\n",
      "\n",
      "Epoch 12. Loss: 0.14404431448286187, Train_acc 0.9331362612612613\n",
      "\n",
      "Epoch 12. Loss: 0.14799808084284138, Train_acc 0.93310546875\n",
      "\n",
      "Epoch 12. Loss: 0.14626580285413449, Train_acc 0.9332134955752213\n",
      "\n",
      "Epoch 12. Loss: 0.14852690673515248, Train_acc 0.9332510964912281\n",
      "\n",
      "Epoch 12. Loss: 0.14551014208774313, Train_acc 0.9333559782608696\n",
      "\n",
      "Epoch 12. Loss: 0.1502359196899582, Train_acc 0.9333243534482759\n",
      "\n",
      "Epoch 12. Loss: 0.1433355303428992, Train_acc 0.9336271367521367\n",
      "\n",
      "Epoch 12. Loss: 0.1444258384545825, Train_acc 0.9337261652542372\n",
      "\n",
      "Epoch 12. Loss: 0.1404790700352355, Train_acc 0.9340861344537815\n",
      "\n",
      "Epoch 12. Loss: 0.13781280331696547, Train_acc 0.9342447916666666\n",
      "\n",
      "Epoch 12. Loss: 0.130705949034263, Train_acc 0.9346590909090909\n",
      "\n",
      "Epoch 12. Loss: 0.12667586329517005, Train_acc 0.9350025614754098\n",
      "\n",
      "Epoch 12. Loss: 0.1257927455568663, Train_acc 0.9350228658536586\n",
      "\n",
      "Epoch 12. Loss: 0.12826995593884752, Train_acc 0.9351058467741935\n",
      "\n",
      "Epoch 12. Loss: 0.12694836669486015, Train_acc 0.9351875\n",
      "\n",
      "Epoch 12. Loss: 0.1362267987130992, Train_acc 0.9350818452380952\n",
      "\n",
      "Epoch 12. Loss: 0.13694322611679843, Train_acc 0.9351008858267716\n",
      "\n",
      "Epoch 12. Loss: 0.13638701742103884, Train_acc 0.9351806640625\n",
      "\n",
      "Epoch 12. Loss: 0.13774054978976719, Train_acc 0.9353803294573644\n",
      "\n",
      "Epoch 12. Loss: 0.13801889927408165, Train_acc 0.9352163461538462\n",
      "\n",
      "Epoch 12. Loss: 0.13665527979631184, Train_acc 0.9351741412213741\n",
      "\n",
      "Epoch 12. Loss: 0.1349751461753156, Train_acc 0.9353101325757576\n",
      "\n",
      "Epoch 12. Loss: 0.13540086977561472, Train_acc 0.9354440789473685\n",
      "\n",
      "Epoch 12. Loss: 0.14555870443177366, Train_acc 0.9352262126865671\n",
      "\n",
      "Epoch 12. Loss: 0.1449283654951347, Train_acc 0.9351851851851852\n",
      "\n",
      "Epoch 12. Loss: 0.14529896188944216, Train_acc 0.9352022058823529\n",
      "\n",
      "Epoch 12. Loss: 0.1439932353124288, Train_acc 0.935276003649635\n",
      "\n",
      "Epoch 12. Loss: 0.1514745518706978, Train_acc 0.9351788949275363\n",
      "\n",
      "Epoch 12. Loss: 0.1530054284759826, Train_acc 0.935251798561151\n",
      "\n",
      "Epoch 12. Loss: 0.15351618739621042, Train_acc 0.93515625\n",
      "\n",
      "Epoch 12. Loss: 0.1556726581989783, Train_acc 0.9351728723404256\n",
      "\n",
      "Epoch 12. Loss: 0.15742794160298032, Train_acc 0.9352992957746479\n",
      "\n",
      "Epoch 12. Loss: 0.15179551378713418, Train_acc 0.9353693181818182\n",
      "\n",
      "Epoch 12. Loss: 0.1477739355190966, Train_acc 0.935546875\n",
      "\n",
      "Epoch 12. Loss: 0.14782540570715427, Train_acc 0.9356681034482759\n",
      "\n",
      "Epoch 12. Loss: 0.14781239245253228, Train_acc 0.9357341609589042\n",
      "\n",
      "Epoch 12. Loss: 0.14935099137351593, Train_acc 0.9356930272108843\n",
      "\n",
      "Epoch 12. Loss: 0.15263616787665202, Train_acc 0.9357052364864865\n",
      "\n",
      "Epoch 12. Loss: 0.15222194862907928, Train_acc 0.9357172818791947\n",
      "\n",
      "Epoch 12. Loss: 0.1573945946026963, Train_acc 0.93546875\n",
      "\n",
      "Epoch 12. Loss: 0.15444383023939628, Train_acc 0.9356374172185431\n",
      "\n",
      "Epoch 12. Loss: 0.15621984152879206, Train_acc 0.9354954769736842\n",
      "\n",
      "Epoch 12. Loss: 0.16240962578850288, Train_acc 0.9352022058823529\n",
      "\n",
      "Epoch 12. Loss: 0.17239757985470266, Train_acc 0.934862012987013\n",
      "\n",
      "Epoch 12. Loss: 0.17004009435115075, Train_acc 0.9348790322580646\n",
      "\n",
      "Epoch 12. Loss: 0.164701442565362, Train_acc 0.9349959935897436\n",
      "\n",
      "Epoch 12. Loss: 0.1579102097265485, Train_acc 0.9353105095541401\n",
      "\n",
      "Epoch 12. Loss: 0.15888842358999522, Train_acc 0.9352254746835443\n",
      "\n",
      "Epoch 12. Loss: 0.16388474030625588, Train_acc 0.9351906446540881\n",
      "\n",
      "Epoch 12. Loss: 0.15674923396109136, Train_acc 0.935302734375\n",
      "\n",
      "Epoch 12. Loss: 0.15338439377545052, Train_acc 0.9354619565217391\n",
      "\n",
      "Epoch 12. Loss: 0.1491745610451585, Train_acc 0.9356192129629629\n",
      "\n",
      "Epoch 12. Loss: 0.15383009160303052, Train_acc 0.9353431748466258\n",
      "\n",
      "Epoch 12. Loss: 0.14692922572561778, Train_acc 0.935546875\n",
      "\n",
      "Epoch 12. Loss: 0.14339693239571463, Train_acc 0.9356534090909091\n",
      "\n",
      "Epoch 12. Loss: 0.1410891109815998, Train_acc 0.9358057228915663\n",
      "\n",
      "Epoch 12. Loss: 0.14724295980737476, Train_acc 0.9356287425149701\n",
      "\n",
      "Epoch 12. Loss: 0.13967214730685237, Train_acc 0.9359188988095238\n",
      "\n",
      "Epoch 12. Loss: 0.13526879138325407, Train_acc 0.9361593934911243\n",
      "\n",
      "Epoch 12. Loss: 0.13861984658159096, Train_acc 0.9360753676470588\n",
      "\n",
      "Epoch 12. Loss: 0.13930297030136538, Train_acc 0.9360836988304093\n",
      "\n",
      "Epoch 12. Loss: 0.14008980959468084, Train_acc 0.9360919331395349\n",
      "\n",
      "Epoch 12. Loss: 0.14232627573442158, Train_acc 0.9360097543352601\n",
      "\n",
      "Epoch 12. Loss: 0.13954182585625377, Train_acc 0.9360632183908046\n",
      "\n",
      "Epoch 12. Loss: 0.142370596115725, Train_acc 0.9361160714285715\n",
      "\n",
      "Epoch 12. Loss: 0.15210497789228272, Train_acc 0.9360795454545454\n",
      "\n",
      "Epoch 12. Loss: 0.15643658112863584, Train_acc 0.9359551553672316\n",
      "\n",
      "Epoch 12. Loss: 0.15538107339781418, Train_acc 0.9359638342696629\n",
      "\n",
      "Epoch 12. Loss: 0.15994227067448402, Train_acc 0.9359724162011173\n",
      "\n",
      "Epoch 12. Loss: 0.16056298436955546, Train_acc 0.9360243055555556\n",
      "\n",
      "Epoch 12. Loss: 0.16517610003563107, Train_acc 0.9358598066298343\n",
      "\n",
      "Epoch 12. Loss: 0.16098893567930764, Train_acc 0.9359546703296703\n",
      "\n",
      "Epoch 12. Loss: 0.16224026726196206, Train_acc 0.936005806010929\n",
      "\n",
      "Epoch 12. Loss: 0.1603415314541161, Train_acc 0.9360563858695652\n",
      "\n",
      "Epoch 12. Loss: 0.15800674595110714, Train_acc 0.9360219594594594\n",
      "\n",
      "Epoch 12. Loss: 0.15378148112600834, Train_acc 0.9360299059139785\n",
      "\n",
      "Epoch 12. Loss: 0.15580066222464256, Train_acc 0.9360377673796791\n",
      "\n",
      "Epoch 12. Loss: 0.15068917583091748, Train_acc 0.9361286569148937\n",
      "\n",
      "Epoch 12. Loss: 0.15023742715117655, Train_acc 0.9360945767195767\n",
      "\n",
      "Epoch 12. Loss: 0.15170636415121547, Train_acc 0.9361430921052631\n",
      "\n",
      "Epoch 12. Loss: 0.15097731327686542, Train_acc 0.936068390052356\n",
      "\n",
      "Epoch 12. Loss: 0.14623576753443926, Train_acc 0.9362386067708334\n",
      "\n",
      "Epoch 12. Loss: 0.1456760259250383, Train_acc 0.9363261010362695\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12. Loss: 0.14310184494670455, Train_acc 0.9363321520618557\n",
      "\n",
      "Epoch 12. Loss: 0.14224129059329235, Train_acc 0.9364583333333333\n",
      "\n",
      "Epoch 12. Loss: 0.1546802682138795, Train_acc 0.93648\n",
      "\n",
      "Epoch 13. Loss: 0.15249612144744226, Train_acc 0.9375\n",
      "\n",
      "Epoch 13. Loss: 0.14871859144075958, Train_acc 0.9453125\n",
      "\n",
      "Epoch 13. Loss: 0.14851681224320157, Train_acc 0.9401041666666666\n",
      "\n",
      "Epoch 13. Loss: 0.14778670220208606, Train_acc 0.943359375\n",
      "\n",
      "Epoch 13. Loss: 0.1502460528787891, Train_acc 0.9375\n",
      "\n",
      "Epoch 13. Loss: 0.14522611552866577, Train_acc 0.9427083333333334\n",
      "\n",
      "Epoch 13. Loss: 0.1394677977656628, Train_acc 0.9453125\n",
      "\n",
      "Epoch 13. Loss: 0.1343138087596272, Train_acc 0.951171875\n",
      "\n",
      "Epoch 13. Loss: 0.1345627756839193, Train_acc 0.9513888888888888\n",
      "\n",
      "Epoch 13. Loss: 0.13822924660967562, Train_acc 0.94765625\n",
      "\n",
      "Epoch 13. Loss: 0.13202297151678896, Train_acc 0.9495738636363636\n",
      "\n",
      "Epoch 13. Loss: 0.13033843303257908, Train_acc 0.951171875\n",
      "\n",
      "Epoch 13. Loss: 0.13515304563523547, Train_acc 0.9477163461538461\n",
      "\n",
      "Epoch 13. Loss: 0.12996629808617727, Train_acc 0.9497767857142857\n",
      "\n",
      "Epoch 13. Loss: 0.1340737515771964, Train_acc 0.9494791666666667\n",
      "\n",
      "Epoch 13. Loss: 0.13812193936865735, Train_acc 0.94873046875\n",
      "\n",
      "Epoch 13. Loss: 0.1360102571555484, Train_acc 0.9489889705882353\n",
      "\n",
      "Epoch 13. Loss: 0.1341645406939246, Train_acc 0.9483506944444444\n",
      "\n",
      "Epoch 13. Loss: 0.13334518706121962, Train_acc 0.9481907894736842\n",
      "\n",
      "Epoch 13. Loss: 0.12862903805362214, Train_acc 0.948828125\n",
      "\n",
      "Epoch 13. Loss: 0.13261782167959538, Train_acc 0.9479166666666666\n",
      "\n",
      "Epoch 13. Loss: 0.13830454235024744, Train_acc 0.9463778409090909\n",
      "\n",
      "Epoch 13. Loss: 0.13902742789459968, Train_acc 0.9456521739130435\n",
      "\n",
      "Epoch 13. Loss: 0.13729576134329508, Train_acc 0.9462890625\n",
      "\n",
      "Epoch 13. Loss: 0.13118814257066372, Train_acc 0.9471875\n",
      "\n",
      "Epoch 13. Loss: 0.12743474910212388, Train_acc 0.9477163461538461\n",
      "\n",
      "Epoch 13. Loss: 0.1263839113970354, Train_acc 0.9479166666666666\n",
      "\n",
      "Epoch 13. Loss: 0.12380541040835571, Train_acc 0.9483816964285714\n",
      "\n",
      "Epoch 13. Loss: 0.1251720339745682, Train_acc 0.9477370689655172\n",
      "\n",
      "Epoch 13. Loss: 0.12807637608263506, Train_acc 0.9471354166666667\n",
      "\n",
      "Epoch 13. Loss: 0.13045039763641608, Train_acc 0.9465725806451613\n",
      "\n",
      "Epoch 13. Loss: 0.13225635281734693, Train_acc 0.945556640625\n",
      "\n",
      "Epoch 13. Loss: 0.13903800748169148, Train_acc 0.9443655303030303\n",
      "\n",
      "Epoch 13. Loss: 0.13691373111945146, Train_acc 0.9443933823529411\n",
      "\n",
      "Epoch 13. Loss: 0.1412427166891851, Train_acc 0.94375\n",
      "\n",
      "Epoch 13. Loss: 0.14039611278111558, Train_acc 0.9442274305555556\n",
      "\n",
      "Epoch 13. Loss: 0.15306165329934499, Train_acc 0.9425675675675675\n",
      "\n",
      "Epoch 13. Loss: 0.15894562166024453, Train_acc 0.9409950657894737\n",
      "\n",
      "Epoch 13. Loss: 0.15407742927452214, Train_acc 0.9417067307692307\n",
      "\n",
      "Epoch 13. Loss: 0.1492015178797867, Train_acc 0.942578125\n",
      "\n",
      "Epoch 13. Loss: 0.1529734273968541, Train_acc 0.9418826219512195\n",
      "\n",
      "Epoch 13. Loss: 0.15209842087790995, Train_acc 0.9421502976190477\n",
      "\n",
      "Epoch 13. Loss: 0.1477525102671888, Train_acc 0.942405523255814\n",
      "\n",
      "Epoch 13. Loss: 0.1512739137628889, Train_acc 0.9419389204545454\n",
      "\n",
      "Epoch 13. Loss: 0.1440123849349513, Train_acc 0.9425347222222222\n",
      "\n",
      "Epoch 13. Loss: 0.14576584099864612, Train_acc 0.9425951086956522\n",
      "\n",
      "Epoch 13. Loss: 0.14353917240323708, Train_acc 0.9428191489361702\n",
      "\n",
      "Epoch 13. Loss: 0.1460180389811583, Train_acc 0.9423828125\n",
      "\n",
      "Epoch 13. Loss: 0.14929900836318621, Train_acc 0.9419642857142857\n",
      "\n",
      "Epoch 13. Loss: 0.14794807676705618, Train_acc 0.94234375\n",
      "\n",
      "Epoch 13. Loss: 0.14600782135933252, Train_acc 0.9428615196078431\n",
      "\n",
      "Epoch 13. Loss: 0.14326050987669478, Train_acc 0.9432091346153846\n",
      "\n",
      "Epoch 13. Loss: 0.15388025740529881, Train_acc 0.9422169811320755\n",
      "\n",
      "Epoch 13. Loss: 0.15850316941510845, Train_acc 0.9416956018518519\n",
      "\n",
      "Epoch 13. Loss: 0.15133610629830846, Train_acc 0.9420454545454545\n",
      "\n",
      "Epoch 13. Loss: 0.15782675978953323, Train_acc 0.94140625\n",
      "\n",
      "Epoch 13. Loss: 0.15796635303570045, Train_acc 0.9407894736842105\n",
      "\n",
      "Epoch 13. Loss: 0.150488392296492, Train_acc 0.94140625\n",
      "\n",
      "Epoch 13. Loss: 0.14612395535384917, Train_acc 0.941604872881356\n",
      "\n",
      "Epoch 13. Loss: 0.14225538719125366, Train_acc 0.9416666666666667\n",
      "\n",
      "Epoch 13. Loss: 0.1356975300469498, Train_acc 0.9418545081967213\n",
      "\n",
      "Epoch 13. Loss: 0.12688834637628496, Train_acc 0.9425403225806451\n",
      "\n",
      "Epoch 13. Loss: 0.1227122426351294, Train_acc 0.9429563492063492\n",
      "\n",
      "Epoch 13. Loss: 0.1257638660359727, Train_acc 0.9427490234375\n",
      "\n",
      "Epoch 13. Loss: 0.12429992279008151, Train_acc 0.9430288461538462\n",
      "\n",
      "Epoch 13. Loss: 0.12269599664743353, Train_acc 0.9431818181818182\n",
      "\n",
      "Epoch 13. Loss: 0.11714986945869572, Train_acc 0.9436800373134329\n",
      "\n",
      "Epoch 13. Loss: 0.11684553461386604, Train_acc 0.9437040441176471\n",
      "\n",
      "Epoch 13. Loss: 0.11519427347583036, Train_acc 0.943953804347826\n",
      "\n",
      "Epoch 13. Loss: 0.11668667121293361, Train_acc 0.9441964285714286\n",
      "\n",
      "Epoch 13. Loss: 0.11953529796208931, Train_acc 0.9437720070422535\n",
      "\n",
      "Epoch 13. Loss: 0.12045510781889553, Train_acc 0.9439019097222222\n",
      "\n",
      "Epoch 13. Loss: 0.11613358264939841, Train_acc 0.9443493150684932\n",
      "\n",
      "Epoch 13. Loss: 0.10947172825732997, Train_acc 0.944995777027027\n",
      "\n",
      "Epoch 13. Loss: 0.10436396958111975, Train_acc 0.945625\n",
      "\n",
      "Epoch 13. Loss: 0.10160800512146281, Train_acc 0.9461348684210527\n",
      "\n",
      "Epoch 13. Loss: 0.10070991616408223, Train_acc 0.9464285714285714\n",
      "\n",
      "Epoch 13. Loss: 0.10665693075323279, Train_acc 0.9464142628205128\n",
      "\n",
      "Epoch 13. Loss: 0.10774087554989017, Train_acc 0.9465981012658228\n",
      "\n",
      "Epoch 13. Loss: 0.1106193868527808, Train_acc 0.94638671875\n",
      "\n",
      "Epoch 13. Loss: 0.108441524196565, Train_acc 0.9465663580246914\n",
      "\n",
      "Epoch 13. Loss: 0.1048779435356556, Train_acc 0.9468368902439024\n",
      "\n",
      "Epoch 13. Loss: 0.11041186130643774, Train_acc 0.9468185240963856\n",
      "\n",
      "Epoch 13. Loss: 0.10711073467076619, Train_acc 0.947265625\n",
      "\n",
      "Epoch 13. Loss: 0.10778694530374527, Train_acc 0.9473345588235295\n",
      "\n",
      "Epoch 13. Loss: 0.11685359638971138, Train_acc 0.9472202034883721\n",
      "\n",
      "Epoch 13. Loss: 0.12050829972662373, Train_acc 0.9471084770114943\n",
      "\n",
      "Epoch 13. Loss: 0.12471560966227511, Train_acc 0.9470880681818182\n",
      "\n",
      "Epoch 13. Loss: 0.12072739301253015, Train_acc 0.9471558988764045\n",
      "\n",
      "Epoch 13. Loss: 0.1205998574029981, Train_acc 0.9473090277777778\n",
      "\n",
      "Epoch 13. Loss: 0.12201181778296044, Train_acc 0.9472870879120879\n",
      "\n",
      "Epoch 13. Loss: 0.11955895181582163, Train_acc 0.9473505434782609\n",
      "\n",
      "Epoch 13. Loss: 0.11570942094402722, Train_acc 0.9476646505376344\n",
      "\n",
      "Epoch 13. Loss: 0.12583863458464037, Train_acc 0.9472240691489362\n",
      "\n",
      "Epoch 13. Loss: 0.12745417107429646, Train_acc 0.9471217105263158\n",
      "\n",
      "Epoch 13. Loss: 0.12252989887553344, Train_acc 0.947509765625\n",
      "\n",
      "Epoch 13. Loss: 0.11943480801008245, Train_acc 0.9475676546391752\n",
      "\n",
      "Epoch 13. Loss: 0.11542830554922313, Train_acc 0.9477838010204082\n",
      "\n",
      "Epoch 13. Loss: 0.1184241550112953, Train_acc 0.9476799242424242\n",
      "\n",
      "Epoch 13. Loss: 0.11576812657223853, Train_acc 0.947890625\n",
      "\n",
      "[Epoch 13 Batch 100] Loss: 0.11845948868250888 Training: accuracy=0.947942\n",
      "Epoch 13. Loss: 0.11845948868250888, Train_acc 0.9479424504950495\n",
      "\n",
      "Epoch 13. Loss: 0.11836150950124302, Train_acc 0.9479932598039216\n",
      "\n",
      "Epoch 13. Loss: 0.1203135058217982, Train_acc 0.9479672330097088\n",
      "\n",
      "Epoch 13. Loss: 0.11813695921901521, Train_acc 0.9481670673076923\n",
      "\n",
      "Epoch 13. Loss: 0.11639304111364773, Train_acc 0.9483630952380953\n",
      "\n",
      "Epoch 13. Loss: 0.11558610334959589, Train_acc 0.9483343160377359\n",
      "\n",
      "Epoch 13. Loss: 0.10923699335724381, Train_acc 0.9486711448598131\n",
      "\n",
      "Epoch 13. Loss: 0.11065421965542675, Train_acc 0.9487123842592593\n",
      "\n",
      "Epoch 13. Loss: 0.11508891552826679, Train_acc 0.9486811926605505\n",
      "\n",
      "Epoch 13. Loss: 0.10916414174563512, Train_acc 0.9490767045454546\n",
      "\n",
      "Epoch 13. Loss: 0.11748975795322797, Train_acc 0.9488316441441441\n",
      "\n",
      "Epoch 13. Loss: 0.11930582328272589, Train_acc 0.9488699776785714\n",
      "\n",
      "Epoch 13. Loss: 0.11179300870268996, Train_acc 0.9491841814159292\n",
      "\n",
      "Epoch 13. Loss: 0.10860465370806564, Train_acc 0.9493558114035088\n",
      "\n",
      "Epoch 13. Loss: 0.11474490079157808, Train_acc 0.949116847826087\n",
      "\n",
      "Epoch 13. Loss: 0.10995632332152061, Train_acc 0.9493534482758621\n",
      "\n",
      "Epoch 13. Loss: 0.11460252036082089, Train_acc 0.9493189102564102\n",
      "\n",
      "Epoch 13. Loss: 0.11092098143184786, Train_acc 0.9495497881355932\n",
      "\n",
      "Epoch 13. Loss: 0.11346068012551612, Train_acc 0.9494485294117647\n",
      "\n",
      "Epoch 13. Loss: 0.1134966003403319, Train_acc 0.949609375\n",
      "\n",
      "Epoch 13. Loss: 0.11196407713042973, Train_acc 0.9497675619834711\n",
      "\n",
      "Epoch 13. Loss: 0.11244917992544722, Train_acc 0.9497950819672131\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13. Loss: 0.10936639309340015, Train_acc 0.9498856707317073\n",
      "\n",
      "Epoch 13. Loss: 0.10829088032615151, Train_acc 0.9501008064516129\n",
      "\n",
      "Epoch 13. Loss: 0.10951813108061523, Train_acc 0.95\n",
      "\n",
      "Epoch 13. Loss: 0.11146418940724227, Train_acc 0.9499627976190477\n",
      "\n",
      "Epoch 13. Loss: 0.1071960600468632, Train_acc 0.9502337598425197\n",
      "\n",
      "Epoch 13. Loss: 0.10738667523143737, Train_acc 0.95025634765625\n",
      "\n",
      "Epoch 13. Loss: 0.10201235570262118, Train_acc 0.9505208333333334\n",
      "\n",
      "Epoch 13. Loss: 0.10265616066232541, Train_acc 0.9506009615384615\n",
      "\n",
      "Epoch 13. Loss: 0.0964683024910857, Train_acc 0.9508587786259542\n",
      "\n",
      "Epoch 13. Loss: 0.09880906899223654, Train_acc 0.9509943181818182\n",
      "\n",
      "Epoch 13. Loss: 0.09942599811658201, Train_acc 0.9510690789473685\n",
      "\n",
      "Epoch 13. Loss: 0.1054649681911314, Train_acc 0.9510261194029851\n",
      "\n",
      "Epoch 13. Loss: 0.11024078557480374, Train_acc 0.9508680555555555\n",
      "\n",
      "Epoch 13. Loss: 0.1263956263326615, Train_acc 0.9505974264705882\n",
      "\n",
      "Epoch 13. Loss: 0.1225310662087509, Train_acc 0.9507299270072993\n",
      "\n",
      "Epoch 13. Loss: 0.12330766904622695, Train_acc 0.9506340579710145\n",
      "\n",
      "Epoch 13. Loss: 0.12112535585406764, Train_acc 0.9507643884892086\n",
      "\n",
      "Epoch 13. Loss: 0.1256818462858499, Train_acc 0.9506696428571428\n",
      "\n",
      "Epoch 13. Loss: 0.13278083110897848, Train_acc 0.9504100177304965\n",
      "\n",
      "Epoch 13. Loss: 0.12702481542571584, Train_acc 0.9506492077464789\n",
      "\n",
      "Epoch 13. Loss: 0.13551746691355884, Train_acc 0.9505026223776224\n",
      "\n",
      "Epoch 13. Loss: 0.13447952763816517, Train_acc 0.9505208333333334\n",
      "\n",
      "Epoch 13. Loss: 0.13081132393998626, Train_acc 0.9506465517241379\n",
      "\n",
      "Epoch 13. Loss: 0.13143536617090754, Train_acc 0.9503959760273972\n",
      "\n",
      "Epoch 13. Loss: 0.131224021342967, Train_acc 0.9504145408163265\n",
      "\n",
      "Epoch 13. Loss: 0.12787237765870157, Train_acc 0.9505384290540541\n",
      "\n",
      "Epoch 13. Loss: 0.12465553583933411, Train_acc 0.950503355704698\n",
      "\n",
      "Epoch 13. Loss: 0.1258919576010123, Train_acc 0.9505208333333334\n",
      "\n",
      "Epoch 13. Loss: 0.123958288657756, Train_acc 0.9504863410596026\n",
      "\n",
      "Epoch 13. Loss: 0.11975965860017361, Train_acc 0.9507092927631579\n",
      "\n",
      "Epoch 13. Loss: 0.11737762060041626, Train_acc 0.9508272058823529\n",
      "\n",
      "Epoch 13. Loss: 0.11903263032086552, Train_acc 0.9507406655844156\n",
      "\n",
      "Epoch 13. Loss: 0.12405317485017651, Train_acc 0.9506552419354839\n",
      "\n",
      "Epoch 13. Loss: 0.1327242281408585, Train_acc 0.9504206730769231\n",
      "\n",
      "Epoch 13. Loss: 0.13640914199097248, Train_acc 0.9502388535031847\n",
      "\n",
      "Epoch 13. Loss: 0.13838129792222345, Train_acc 0.950059335443038\n",
      "\n",
      "Epoch 13. Loss: 0.14715387422092824, Train_acc 0.9499803459119497\n",
      "\n",
      "Epoch 13. Loss: 0.14659577010495722, Train_acc 0.949951171875\n",
      "\n",
      "Epoch 13. Loss: 0.1479249676921063, Train_acc 0.9498738354037267\n",
      "\n",
      "Epoch 13. Loss: 0.14966152735275864, Train_acc 0.9497492283950617\n",
      "\n",
      "Epoch 13. Loss: 0.14856013620844044, Train_acc 0.9496740797546013\n",
      "\n",
      "Epoch 13. Loss: 0.1539167296733012, Train_acc 0.9495045731707317\n",
      "\n",
      "Epoch 13. Loss: 0.15201658444215804, Train_acc 0.9494791666666667\n",
      "\n",
      "Epoch 13. Loss: 0.15265269669839696, Train_acc 0.9493128765060241\n",
      "\n",
      "Epoch 13. Loss: 0.1465586774910893, Train_acc 0.9494292664670658\n",
      "\n",
      "Epoch 13. Loss: 0.14191030443001443, Train_acc 0.9494977678571429\n",
      "\n",
      "Epoch 13. Loss: 0.14758750778694738, Train_acc 0.9493343195266272\n",
      "\n",
      "Epoch 13. Loss: 0.145667013367353, Train_acc 0.9493566176470588\n",
      "\n",
      "Epoch 13. Loss: 0.1458518327835245, Train_acc 0.9491959064327485\n",
      "\n",
      "Epoch 13. Loss: 0.14479224874642876, Train_acc 0.9491733284883721\n",
      "\n",
      "Epoch 13. Loss: 0.14542725676954438, Train_acc 0.9491961705202312\n",
      "\n",
      "Epoch 13. Loss: 0.1389954588829933, Train_acc 0.9493085488505747\n",
      "\n",
      "Epoch 13. Loss: 0.13768332916672155, Train_acc 0.9492410714285714\n",
      "\n",
      "Epoch 13. Loss: 0.13176552252329998, Train_acc 0.9493963068181818\n",
      "\n",
      "Epoch 13. Loss: 0.1243301544757868, Train_acc 0.9495939265536724\n",
      "\n",
      "Epoch 13. Loss: 0.12581101186622845, Train_acc 0.9495259831460674\n",
      "\n",
      "Epoch 13. Loss: 0.13534790093496146, Train_acc 0.9492842178770949\n",
      "\n",
      "Epoch 13. Loss: 0.13292337415928873, Train_acc 0.9493923611111111\n",
      "\n",
      "Epoch 13. Loss: 0.13282147012634782, Train_acc 0.9493266574585635\n",
      "\n",
      "Epoch 13. Loss: 0.13204737272098996, Train_acc 0.9491328983516484\n",
      "\n",
      "Epoch 13. Loss: 0.12831024765582685, Train_acc 0.9491547131147541\n",
      "\n",
      "Epoch 13. Loss: 0.13012679016243045, Train_acc 0.9490489130434783\n",
      "\n",
      "Epoch 13. Loss: 0.12628074969932995, Train_acc 0.949070945945946\n",
      "\n",
      "Epoch 13. Loss: 0.12823027657942976, Train_acc 0.9490087365591398\n",
      "\n",
      "Epoch 13. Loss: 0.13489887077340787, Train_acc 0.9487800802139037\n",
      "\n",
      "Epoch 13. Loss: 0.13245264701899265, Train_acc 0.9487616356382979\n",
      "\n",
      "Epoch 13. Loss: 0.12932319503596162, Train_acc 0.9487847222222222\n",
      "\n",
      "Epoch 13. Loss: 0.12597752715561453, Train_acc 0.9488075657894737\n",
      "\n",
      "Epoch 13. Loss: 0.13187596743178664, Train_acc 0.9486256544502618\n",
      "\n",
      "Epoch 13. Loss: 0.13144537697618275, Train_acc 0.9486083984375\n",
      "\n",
      "Epoch 13. Loss: 0.13344421139703755, Train_acc 0.9486318005181347\n",
      "\n",
      "Epoch 13. Loss: 0.1400903178871861, Train_acc 0.9483327963917526\n",
      "\n",
      "Epoch 13. Loss: 0.14083200516890207, Train_acc 0.9483573717948718\n",
      "\n",
      "Epoch 13. Loss: 0.14562347968748854, Train_acc 0.94832\n",
      "\n",
      "Epoch 14. Loss: 0.14782152271567267, Train_acc 0.921875\n",
      "\n",
      "Epoch 14. Loss: 0.14259739246635272, Train_acc 0.9453125\n",
      "\n",
      "Epoch 14. Loss: 0.13623590269686553, Train_acc 0.9557291666666666\n",
      "\n",
      "Epoch 14. Loss: 0.13502250610889588, Train_acc 0.955078125\n",
      "\n",
      "Epoch 14. Loss: 0.12982622235210176, Train_acc 0.959375\n",
      "\n",
      "Epoch 14. Loss: 0.12437072499863597, Train_acc 0.9609375\n",
      "\n",
      "Epoch 14. Loss: 0.12228265795951151, Train_acc 0.9587053571428571\n",
      "\n",
      "Epoch 14. Loss: 0.1149538906113362, Train_acc 0.9619140625\n",
      "\n",
      "Epoch 14. Loss: 0.11145625725651286, Train_acc 0.9635416666666666\n",
      "\n",
      "Epoch 14. Loss: 0.10747323750195951, Train_acc 0.96484375\n",
      "\n",
      "Epoch 14. Loss: 0.10417023288075374, Train_acc 0.9644886363636364\n",
      "\n",
      "Epoch 14. Loss: 0.10960998523411972, Train_acc 0.9615885416666666\n",
      "\n",
      "Epoch 14. Loss: 0.105843025191228, Train_acc 0.9633413461538461\n",
      "\n",
      "Epoch 14. Loss: 0.10569813496792352, Train_acc 0.9614955357142857\n",
      "\n",
      "Epoch 14. Loss: 0.10786840152970584, Train_acc 0.9614583333333333\n",
      "\n",
      "Epoch 14. Loss: 0.11182112394778398, Train_acc 0.96044921875\n",
      "\n",
      "Epoch 14. Loss: 0.10667752607770384, Train_acc 0.9613970588235294\n",
      "\n",
      "Epoch 14. Loss: 0.10859859035111327, Train_acc 0.9605034722222222\n",
      "\n",
      "Epoch 14. Loss: 0.10496480431285672, Train_acc 0.9609375\n",
      "\n",
      "Epoch 14. Loss: 0.09921313747281288, Train_acc 0.962109375\n",
      "\n",
      "Epoch 14. Loss: 0.10152172602278997, Train_acc 0.9624255952380952\n",
      "\n",
      "Epoch 14. Loss: 0.09718514582869121, Train_acc 0.9630681818181818\n",
      "\n",
      "Epoch 14. Loss: 0.09524315984270014, Train_acc 0.9629755434782609\n",
      "\n",
      "Epoch 14. Loss: 0.09193478650946352, Train_acc 0.9635416666666666\n",
      "\n",
      "Epoch 14. Loss: 0.08888385484009027, Train_acc 0.9646875\n",
      "\n",
      "Epoch 14. Loss: 0.0948978137021277, Train_acc 0.9630408653846154\n",
      "\n",
      "Epoch 14. Loss: 0.09674517253443721, Train_acc 0.9623842592592593\n",
      "\n",
      "Epoch 14. Loss: 0.09441670646731666, Train_acc 0.962890625\n",
      "\n",
      "Epoch 14. Loss: 0.10155880633411954, Train_acc 0.9620150862068966\n",
      "\n",
      "Epoch 14. Loss: 0.10628199741320149, Train_acc 0.9614583333333333\n",
      "\n",
      "Epoch 14. Loss: 0.10650864987143578, Train_acc 0.9611895161290323\n",
      "\n",
      "Epoch 14. Loss: 0.10882244779379996, Train_acc 0.9609375\n",
      "\n",
      "Epoch 14. Loss: 0.10859716108779757, Train_acc 0.9609375\n",
      "\n",
      "Epoch 14. Loss: 0.10784167651540622, Train_acc 0.9611672794117647\n",
      "\n",
      "Epoch 14. Loss: 0.11124282125419305, Train_acc 0.9604910714285714\n",
      "\n",
      "Epoch 14. Loss: 0.1055810976962977, Train_acc 0.9611545138888888\n",
      "\n",
      "Epoch 14. Loss: 0.10445473229355216, Train_acc 0.9611486486486487\n",
      "\n",
      "Epoch 14. Loss: 0.10084231095433176, Train_acc 0.9615542763157895\n",
      "\n",
      "Epoch 14. Loss: 0.10076023322570271, Train_acc 0.9615384615384616\n",
      "\n",
      "Epoch 14. Loss: 0.1023978793522234, Train_acc 0.9609375\n",
      "\n",
      "Epoch 14. Loss: 0.09996941720549898, Train_acc 0.9613185975609756\n",
      "\n",
      "Epoch 14. Loss: 0.0926014694729862, Train_acc 0.9620535714285714\n",
      "\n",
      "Epoch 14. Loss: 0.09078874556655443, Train_acc 0.9622093023255814\n",
      "\n",
      "Epoch 14. Loss: 0.08844757931025109, Train_acc 0.9621803977272727\n",
      "\n",
      "Epoch 14. Loss: 0.0884435506754334, Train_acc 0.9619791666666667\n",
      "\n",
      "Epoch 14. Loss: 0.08412416305481331, Train_acc 0.962296195652174\n",
      "\n",
      "Epoch 14. Loss: 0.08692870238130335, Train_acc 0.9624335106382979\n",
      "\n",
      "Epoch 14. Loss: 0.09708776502643565, Train_acc 0.96142578125\n",
      "\n",
      "Epoch 14. Loss: 0.09973146255762463, Train_acc 0.9612563775510204\n",
      "\n",
      "Epoch 14. Loss: 0.09898818048195022, Train_acc 0.96125\n",
      "\n",
      "Epoch 14. Loss: 0.10312974762042741, Train_acc 0.9609375\n",
      "\n",
      "Epoch 14. Loss: 0.1003684757154022, Train_acc 0.9612379807692307\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14. Loss: 0.10250141841180631, Train_acc 0.9610849056603774\n",
      "\n",
      "Epoch 14. Loss: 0.10727126260406532, Train_acc 0.9605034722222222\n",
      "\n",
      "Epoch 14. Loss: 0.10552952313250384, Train_acc 0.9603693181818181\n",
      "\n",
      "Epoch 14. Loss: 0.10475948265635443, Train_acc 0.9603794642857143\n",
      "\n",
      "Epoch 14. Loss: 0.1023265538642717, Train_acc 0.9605263157894737\n",
      "\n",
      "Epoch 14. Loss: 0.10741696220903808, Train_acc 0.9603987068965517\n",
      "\n",
      "Epoch 14. Loss: 0.10839059319140805, Train_acc 0.9604078389830508\n",
      "\n",
      "Epoch 14. Loss: 0.10806752770580912, Train_acc 0.9604166666666667\n",
      "\n",
      "Epoch 14. Loss: 0.108378619218809, Train_acc 0.960297131147541\n",
      "\n",
      "Epoch 14. Loss: 0.11251965933884017, Train_acc 0.9604334677419355\n",
      "\n",
      "Epoch 14. Loss: 0.1101538086579278, Train_acc 0.9604414682539683\n",
      "\n",
      "Epoch 14. Loss: 0.10944148701244905, Train_acc 0.9608154296875\n",
      "\n",
      "Epoch 14. Loss: 0.10664810137582703, Train_acc 0.9610576923076923\n",
      "\n",
      "Epoch 14. Loss: 0.1021273294535239, Train_acc 0.9612926136363636\n",
      "\n",
      "Epoch 14. Loss: 0.10760296965661284, Train_acc 0.960820895522388\n",
      "\n",
      "Epoch 14. Loss: 0.1023629933746693, Train_acc 0.9612821691176471\n",
      "\n",
      "Epoch 14. Loss: 0.09714806647467947, Train_acc 0.9616168478260869\n",
      "\n",
      "Epoch 14. Loss: 0.10189895246656241, Train_acc 0.9612723214285714\n",
      "\n",
      "Epoch 14. Loss: 0.10210747195093187, Train_acc 0.9610475352112676\n",
      "\n",
      "Epoch 14. Loss: 0.10988892173297721, Train_acc 0.9603949652777778\n",
      "\n",
      "Epoch 14. Loss: 0.10823487987095878, Train_acc 0.9602953767123288\n",
      "\n",
      "Epoch 14. Loss: 0.10714477822162002, Train_acc 0.9601984797297297\n",
      "\n",
      "Epoch 14. Loss: 0.11029411129633149, Train_acc 0.9601041666666666\n",
      "\n",
      "Epoch 14. Loss: 0.11039027740788068, Train_acc 0.9600123355263158\n",
      "\n",
      "Epoch 14. Loss: 0.11188445243446475, Train_acc 0.9597199675324676\n",
      "\n",
      "Epoch 14. Loss: 0.11056902634985846, Train_acc 0.9595352564102564\n",
      "\n",
      "Epoch 14. Loss: 0.10618931690950037, Train_acc 0.9597507911392406\n",
      "\n",
      "Epoch 14. Loss: 0.10873778587668098, Train_acc 0.95966796875\n",
      "\n",
      "Epoch 14. Loss: 0.11145008587320707, Train_acc 0.9594907407407407\n",
      "\n",
      "Epoch 14. Loss: 0.11871835574638899, Train_acc 0.9594131097560976\n",
      "\n",
      "Epoch 14. Loss: 0.11706113503991415, Train_acc 0.9596197289156626\n",
      "\n",
      "Epoch 14. Loss: 0.11123694124775098, Train_acc 0.9599144345238095\n",
      "\n",
      "Epoch 14. Loss: 0.11074071058294445, Train_acc 0.9597426470588235\n",
      "\n",
      "Epoch 14. Loss: 0.11250959421987478, Train_acc 0.9595748546511628\n",
      "\n",
      "Epoch 14. Loss: 0.11102254616435, Train_acc 0.9595007183908046\n",
      "\n",
      "Epoch 14. Loss: 0.10869725803031591, Train_acc 0.9596058238636364\n",
      "\n",
      "Epoch 14. Loss: 0.10413744979644479, Train_acc 0.9598841292134831\n",
      "\n",
      "Epoch 14. Loss: 0.10321921497772332, Train_acc 0.9598958333333333\n",
      "\n",
      "Epoch 14. Loss: 0.10114996037057217, Train_acc 0.9599072802197802\n",
      "\n",
      "Epoch 14. Loss: 0.09775033504817941, Train_acc 0.9601732336956522\n",
      "\n",
      "Epoch 14. Loss: 0.0995829529558485, Train_acc 0.959929435483871\n",
      "\n",
      "Epoch 14. Loss: 0.09908224064065801, Train_acc 0.9599401595744681\n",
      "\n",
      "Epoch 14. Loss: 0.0980156578238647, Train_acc 0.9601151315789473\n",
      "\n",
      "Epoch 14. Loss: 0.10412680366180904, Train_acc 0.9599609375\n",
      "\n",
      "Epoch 14. Loss: 0.10193688951619775, Train_acc 0.9601320876288659\n",
      "\n",
      "Epoch 14. Loss: 0.09805369182844441, Train_acc 0.9602200255102041\n",
      "\n",
      "Epoch 14. Loss: 0.09294554788845313, Train_acc 0.9604640151515151\n",
      "\n",
      "Epoch 14. Loss: 0.09109871788898885, Train_acc 0.960546875\n",
      "\n",
      "[Epoch 14 Batch 100] Loss: 0.09379759613346857 Training: accuracy=0.960473\n",
      "Epoch 14. Loss: 0.09379759613346857, Train_acc 0.9604733910891089\n",
      "\n",
      "Epoch 14. Loss: 0.091511935147689, Train_acc 0.9606311274509803\n",
      "\n",
      "Epoch 14. Loss: 0.09692044867847523, Train_acc 0.9605582524271845\n",
      "\n",
      "Epoch 14. Loss: 0.09886883181727672, Train_acc 0.9604116586538461\n",
      "\n",
      "Epoch 14. Loss: 0.10152386858221958, Train_acc 0.9604166666666667\n",
      "\n",
      "Epoch 14. Loss: 0.09717635125658278, Train_acc 0.9606426886792453\n",
      "\n",
      "Epoch 14. Loss: 0.09415072927541761, Train_acc 0.9606454439252337\n",
      "\n",
      "Epoch 14. Loss: 0.09208309557736422, Train_acc 0.9607204861111112\n",
      "\n",
      "Epoch 14. Loss: 0.08981771087676738, Train_acc 0.9607941513761468\n",
      "\n",
      "Epoch 14. Loss: 0.09087388798025656, Train_acc 0.9607244318181818\n",
      "\n",
      "Epoch 14. Loss: 0.0933478169241018, Train_acc 0.9605855855855856\n",
      "\n",
      "Epoch 14. Loss: 0.0980258830724776, Train_acc 0.9603097098214286\n",
      "\n",
      "Epoch 14. Loss: 0.10152656272100988, Train_acc 0.9600387168141593\n",
      "\n",
      "Epoch 14. Loss: 0.11771431060177906, Train_acc 0.9593612938596491\n",
      "\n",
      "Epoch 14. Loss: 0.1133679702121868, Train_acc 0.959578804347826\n",
      "\n",
      "Epoch 14. Loss: 0.11212276258219966, Train_acc 0.9595231681034483\n",
      "\n",
      "Epoch 14. Loss: 0.12109601352944692, Train_acc 0.9589342948717948\n",
      "\n",
      "Epoch 14. Loss: 0.12295919228495408, Train_acc 0.9588188559322034\n",
      "\n",
      "Epoch 14. Loss: 0.12341961177201197, Train_acc 0.9587053571428571\n",
      "\n",
      "Epoch 14. Loss: 0.122455143141846, Train_acc 0.9587890625\n",
      "\n",
      "Epoch 14. Loss: 0.12119573790559185, Train_acc 0.9587422520661157\n",
      "\n",
      "Epoch 14. Loss: 0.12172558401878786, Train_acc 0.9587602459016393\n",
      "\n",
      "Epoch 14. Loss: 0.1212699859874497, Train_acc 0.9585873983739838\n",
      "\n",
      "Epoch 14. Loss: 0.12222163077030035, Train_acc 0.9586063508064516\n",
      "\n",
      "Epoch 14. Loss: 0.12077741499990331, Train_acc 0.9585625\n",
      "\n",
      "Epoch 14. Loss: 0.12497369059547878, Train_acc 0.9584573412698413\n",
      "\n",
      "Epoch 14. Loss: 0.12367511339746502, Train_acc 0.9583538385826772\n",
      "\n",
      "Epoch 14. Loss: 0.12093903092529702, Train_acc 0.958251953125\n",
      "\n",
      "Epoch 14. Loss: 0.11491193779992755, Train_acc 0.9583938953488372\n",
      "\n",
      "Epoch 14. Loss: 0.11415212668795315, Train_acc 0.9584134615384615\n",
      "\n",
      "Epoch 14. Loss: 0.11209262595610851, Train_acc 0.9582538167938931\n",
      "\n",
      "Epoch 14. Loss: 0.10931671726140708, Train_acc 0.9583333333333334\n",
      "\n",
      "Epoch 14. Loss: 0.10771263004034755, Train_acc 0.9584116541353384\n",
      "\n",
      "Epoch 14. Loss: 0.11519081766030191, Train_acc 0.9582555970149254\n",
      "\n",
      "Epoch 14. Loss: 0.11958100683648287, Train_acc 0.9580439814814815\n",
      "\n",
      "Epoch 14. Loss: 0.12124350476705044, Train_acc 0.9578354779411765\n",
      "\n",
      "Epoch 14. Loss: 0.11584998719492265, Train_acc 0.9579721715328468\n",
      "\n",
      "Epoch 14. Loss: 0.12547385292588512, Train_acc 0.9573709239130435\n",
      "\n",
      "Epoch 14. Loss: 0.12202865419392742, Train_acc 0.9574527877697842\n",
      "\n",
      "Epoch 14. Loss: 0.12240936044697426, Train_acc 0.9573102678571429\n",
      "\n",
      "Epoch 14. Loss: 0.12506370857814963, Train_acc 0.9570589539007093\n",
      "\n",
      "Epoch 14. Loss: 0.1314824263643624, Train_acc 0.956756161971831\n",
      "\n",
      "Epoch 14. Loss: 0.1240748966835202, Train_acc 0.9570039335664335\n",
      "\n",
      "Epoch 14. Loss: 0.12539634750207615, Train_acc 0.9569227430555556\n",
      "\n",
      "Epoch 14. Loss: 0.13081034105348902, Train_acc 0.9566810344827587\n",
      "\n",
      "Epoch 14. Loss: 0.12821788488025948, Train_acc 0.956763698630137\n",
      "\n",
      "Epoch 14. Loss: 0.12315605340774792, Train_acc 0.9567920918367347\n",
      "\n",
      "Epoch 14. Loss: 0.11966988675334397, Train_acc 0.9567673141891891\n",
      "\n",
      "Epoch 14. Loss: 0.12016261576895425, Train_acc 0.9567953020134228\n",
      "\n",
      "Epoch 14. Loss: 0.11737460681156375, Train_acc 0.9568229166666666\n",
      "\n",
      "Epoch 14. Loss: 0.1107858273836022, Train_acc 0.957005380794702\n",
      "\n",
      "Epoch 14. Loss: 0.11270879388916898, Train_acc 0.9568256578947368\n",
      "\n",
      "Epoch 14. Loss: 0.11140193654061921, Train_acc 0.9569035947712419\n",
      "\n",
      "Epoch 14. Loss: 0.10889218550588102, Train_acc 0.95703125\n",
      "\n",
      "Epoch 14. Loss: 0.10842810691891978, Train_acc 0.9569556451612903\n",
      "\n",
      "Epoch 14. Loss: 0.10227922756819907, Train_acc 0.9571814903846154\n",
      "\n",
      "Epoch 14. Loss: 0.1067294164837806, Train_acc 0.9569566082802548\n",
      "\n",
      "Epoch 14. Loss: 0.10558315077496248, Train_acc 0.9569323575949367\n",
      "\n",
      "Epoch 14. Loss: 0.10313535668616901, Train_acc 0.9570066823899371\n",
      "\n",
      "Epoch 14. Loss: 0.10175784472971032, Train_acc 0.95703125\n",
      "\n",
      "Epoch 14. Loss: 0.10399504641606394, Train_acc 0.9570069875776398\n",
      "\n",
      "Epoch 14. Loss: 0.10402619144243583, Train_acc 0.9567418981481481\n",
      "\n",
      "Epoch 14. Loss: 0.10084343225588725, Train_acc 0.9569114263803681\n",
      "\n",
      "Epoch 14. Loss: 0.10264207366851263, Train_acc 0.9568883384146342\n",
      "\n",
      "Epoch 14. Loss: 0.10569869676602447, Train_acc 0.9567234848484848\n",
      "\n",
      "Epoch 14. Loss: 0.11396321087514666, Train_acc 0.9565606174698795\n",
      "\n",
      "Epoch 14. Loss: 0.12212867673726654, Train_acc 0.9563061377245509\n",
      "\n",
      "Epoch 14. Loss: 0.11840780648432771, Train_acc 0.9563337053571429\n",
      "\n",
      "Epoch 14. Loss: 0.13975175684251726, Train_acc 0.9558062130177515\n",
      "\n",
      "Epoch 14. Loss: 0.14181377707920975, Train_acc 0.9556525735294118\n",
      "\n",
      "Epoch 14. Loss: 0.13697124244870998, Train_acc 0.9556377923976608\n",
      "\n",
      "Epoch 14. Loss: 0.14726552118750447, Train_acc 0.9553960755813954\n",
      "\n",
      "Epoch 14. Loss: 0.15717133060001168, Train_acc 0.9551571531791907\n",
      "\n",
      "Epoch 14. Loss: 0.15499698676082044, Train_acc 0.9550556752873564\n",
      "\n",
      "Epoch 14. Loss: 0.1521765728957583, Train_acc 0.9551785714285714\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14. Loss: 0.15050841929022638, Train_acc 0.9550337357954546\n",
      "\n",
      "Epoch 14. Loss: 0.1541712453499809, Train_acc 0.9548022598870056\n",
      "\n",
      "Epoch 14. Loss: 0.15711446588057654, Train_acc 0.9546172752808989\n",
      "\n",
      "Epoch 14. Loss: 0.15473333881633022, Train_acc 0.9546525837988827\n",
      "\n",
      "Epoch 14. Loss: 0.15250312137308603, Train_acc 0.9546006944444444\n",
      "\n",
      "Epoch 14. Loss: 0.15182334644528822, Train_acc 0.9545493784530387\n",
      "\n",
      "Epoch 14. Loss: 0.15713901039599715, Train_acc 0.9542410714285714\n",
      "\n",
      "Epoch 14. Loss: 0.15212780132865314, Train_acc 0.9541922814207651\n",
      "\n",
      "Epoch 14. Loss: 0.14904715548433725, Train_acc 0.9541015625\n",
      "\n",
      "Epoch 14. Loss: 0.14208747235367772, Train_acc 0.954222972972973\n",
      "\n",
      "Epoch 14. Loss: 0.1344410370656557, Train_acc 0.9543010752688172\n",
      "\n",
      "Epoch 14. Loss: 0.13762879290002944, Train_acc 0.9540858957219251\n",
      "\n",
      "Epoch 14. Loss: 0.1374365829034301, Train_acc 0.9540392287234043\n",
      "\n",
      "Epoch 14. Loss: 0.1389171996060299, Train_acc 0.9538690476190477\n",
      "\n",
      "Epoch 14. Loss: 0.1380814568707306, Train_acc 0.9537417763157895\n",
      "\n",
      "Epoch 14. Loss: 0.1397821968652867, Train_acc 0.9535749345549738\n",
      "\n",
      "Epoch 14. Loss: 0.14696771495265332, Train_acc 0.953369140625\n",
      "\n",
      "Epoch 14. Loss: 0.14905401700189025, Train_acc 0.953125\n",
      "\n",
      "Epoch 14. Loss: 0.1440932628522841, Train_acc 0.9531652706185567\n",
      "\n",
      "Epoch 14. Loss: 0.13838047477697088, Train_acc 0.9532051282051283\n",
      "\n",
      "Epoch 14. Loss: 0.14209470623518305, Train_acc 0.95312\n",
      "\n",
      "Epoch 15. Loss: 0.1340257385264511, Train_acc 0.984375\n",
      "\n",
      "Epoch 15. Loss: 0.12506476235902386, Train_acc 0.98828125\n",
      "\n",
      "Epoch 15. Loss: 0.11866513402029345, Train_acc 0.9869791666666666\n",
      "\n",
      "Epoch 15. Loss: 0.11410936499325457, Train_acc 0.986328125\n",
      "\n",
      "Epoch 15. Loss: 0.11154502512235662, Train_acc 0.9828125\n",
      "\n",
      "Epoch 15. Loss: 0.10584727717535991, Train_acc 0.9830729166666666\n",
      "\n",
      "Epoch 15. Loss: 0.10171637126592367, Train_acc 0.984375\n",
      "\n",
      "Epoch 15. Loss: 0.09852132668007228, Train_acc 0.982421875\n",
      "\n",
      "Epoch 15. Loss: 0.09598143669881355, Train_acc 0.9809027777777778\n",
      "\n",
      "Epoch 15. Loss: 0.09448145648465692, Train_acc 0.98046875\n",
      "\n",
      "Epoch 15. Loss: 0.0883908918853951, Train_acc 0.9815340909090909\n",
      "\n",
      "Epoch 15. Loss: 0.08604010057655148, Train_acc 0.9811197916666666\n",
      "\n",
      "Epoch 15. Loss: 0.08338186692184663, Train_acc 0.9807692307692307\n",
      "\n",
      "Epoch 15. Loss: 0.08004761048543266, Train_acc 0.9810267857142857\n",
      "\n",
      "Epoch 15. Loss: 0.07765899092007707, Train_acc 0.98125\n",
      "\n",
      "Epoch 15. Loss: 0.0750152698759648, Train_acc 0.9814453125\n",
      "\n",
      "Epoch 15. Loss: 0.07079433261791583, Train_acc 0.9820772058823529\n",
      "\n",
      "Epoch 15. Loss: 0.0704355122992967, Train_acc 0.9813368055555556\n",
      "\n",
      "Epoch 15. Loss: 0.06820559455599556, Train_acc 0.9819078947368421\n",
      "\n",
      "Epoch 15. Loss: 0.07582358378451619, Train_acc 0.98046875\n",
      "\n",
      "Epoch 15. Loss: 0.07152279637707669, Train_acc 0.9806547619047619\n",
      "\n",
      "Epoch 15. Loss: 0.08664389332342207, Train_acc 0.9786931818181818\n",
      "\n",
      "Epoch 15. Loss: 0.09013344985432678, Train_acc 0.977921195652174\n",
      "\n",
      "Epoch 15. Loss: 0.09004444607067634, Train_acc 0.9775390625\n",
      "\n",
      "Epoch 15. Loss: 0.09721067900629517, Train_acc 0.9753125\n",
      "\n",
      "Epoch 15. Loss: 0.0959586577579827, Train_acc 0.9747596153846154\n",
      "\n",
      "Epoch 15. Loss: 0.10424217375804044, Train_acc 0.9733796296296297\n",
      "\n",
      "Epoch 15. Loss: 0.0988915916623687, Train_acc 0.9737723214285714\n",
      "\n",
      "Epoch 15. Loss: 0.10051037576872247, Train_acc 0.9730603448275862\n",
      "\n",
      "Epoch 15. Loss: 0.11701283491025691, Train_acc 0.9697916666666667\n",
      "\n",
      "Epoch 15. Loss: 0.11714008274409465, Train_acc 0.969758064516129\n",
      "\n",
      "Epoch 15. Loss: 0.11149823618888818, Train_acc 0.969970703125\n",
      "\n",
      "Epoch 15. Loss: 0.10382290999257532, Train_acc 0.9706439393939394\n",
      "\n",
      "Epoch 15. Loss: 0.11020132589486809, Train_acc 0.9692095588235294\n",
      "\n",
      "Epoch 15. Loss: 0.10523003507984494, Train_acc 0.9694196428571429\n",
      "\n",
      "Epoch 15. Loss: 0.10318162667154802, Train_acc 0.9689670138888888\n",
      "\n",
      "Epoch 15. Loss: 0.10387610236465515, Train_acc 0.96875\n",
      "\n",
      "Epoch 15. Loss: 0.10793136363917215, Train_acc 0.9681332236842105\n",
      "\n",
      "Epoch 15. Loss: 0.1101052356275346, Train_acc 0.9677483974358975\n",
      "\n",
      "Epoch 15. Loss: 0.10825946264080043, Train_acc 0.96796875\n",
      "\n",
      "Epoch 15. Loss: 0.10717402695964429, Train_acc 0.9674161585365854\n",
      "\n",
      "Epoch 15. Loss: 0.10132835402504194, Train_acc 0.9676339285714286\n",
      "\n",
      "Epoch 15. Loss: 0.09778281981720556, Train_acc 0.9678415697674418\n",
      "\n",
      "Epoch 15. Loss: 0.09412391574657586, Train_acc 0.9678622159090909\n",
      "\n",
      "Epoch 15. Loss: 0.0914326221478876, Train_acc 0.9682291666666667\n",
      "\n",
      "Epoch 15. Loss: 0.09055429047938256, Train_acc 0.9685801630434783\n",
      "\n",
      "Epoch 15. Loss: 0.09051233541902365, Train_acc 0.9685837765957447\n",
      "\n",
      "Epoch 15. Loss: 0.09352674867453989, Train_acc 0.9680989583333334\n",
      "\n",
      "Epoch 15. Loss: 0.09455383302935497, Train_acc 0.9677933673469388\n",
      "\n",
      "Epoch 15. Loss: 0.0877786172822285, Train_acc 0.9684375\n",
      "\n",
      "Epoch 15. Loss: 0.08544460550503448, Train_acc 0.9685968137254902\n",
      "\n",
      "Epoch 15. Loss: 0.08514759792885049, Train_acc 0.9684495192307693\n",
      "\n",
      "Epoch 15. Loss: 0.08570874426365671, Train_acc 0.9686025943396226\n",
      "\n",
      "Epoch 15. Loss: 0.08309130767226915, Train_acc 0.96875\n",
      "\n",
      "Epoch 15. Loss: 0.08024563662028938, Train_acc 0.9690340909090909\n",
      "\n",
      "Epoch 15. Loss: 0.08218298797443477, Train_acc 0.9688895089285714\n",
      "\n",
      "Epoch 15. Loss: 0.07784744451613695, Train_acc 0.9692982456140351\n",
      "\n",
      "Epoch 15. Loss: 0.07525212183748012, Train_acc 0.9695581896551724\n",
      "\n",
      "Epoch 15. Loss: 0.07222421346742802, Train_acc 0.9699417372881356\n",
      "\n",
      "Epoch 15. Loss: 0.07200864817475285, Train_acc 0.9700520833333334\n",
      "\n",
      "Epoch 15. Loss: 0.06992756455339497, Train_acc 0.9702868852459017\n",
      "\n",
      "Epoch 15. Loss: 0.07406924407956755, Train_acc 0.9702620967741935\n",
      "\n",
      "Epoch 15. Loss: 0.0735371760244169, Train_acc 0.9704861111111112\n",
      "\n",
      "Epoch 15. Loss: 0.0697743838323651, Train_acc 0.970703125\n",
      "\n",
      "Epoch 15. Loss: 0.06599233555437609, Train_acc 0.9711538461538461\n",
      "\n",
      "Epoch 15. Loss: 0.07047238803781405, Train_acc 0.9712357954545454\n",
      "\n",
      "Epoch 15. Loss: 0.07258014476487638, Train_acc 0.9710820895522388\n",
      "\n",
      "Epoch 15. Loss: 0.0721273773567939, Train_acc 0.9710477941176471\n",
      "\n",
      "Epoch 15. Loss: 0.06884763795051553, Train_acc 0.9713541666666666\n",
      "\n",
      "Epoch 15. Loss: 0.06545604385060291, Train_acc 0.9715401785714286\n",
      "\n",
      "Epoch 15. Loss: 0.06387033231963712, Train_acc 0.9717209507042254\n",
      "\n",
      "Epoch 15. Loss: 0.06842259393253922, Train_acc 0.9714626736111112\n",
      "\n",
      "Epoch 15. Loss: 0.06847609200583994, Train_acc 0.9717465753424658\n",
      "\n",
      "Epoch 15. Loss: 0.06883563654280096, Train_acc 0.971706081081081\n",
      "\n",
      "Epoch 15. Loss: 0.07190937227001538, Train_acc 0.97125\n",
      "\n",
      "Epoch 15. Loss: 0.06938502349845246, Train_acc 0.9715254934210527\n",
      "\n",
      "Epoch 15. Loss: 0.06783880136959264, Train_acc 0.9715909090909091\n",
      "\n",
      "Epoch 15. Loss: 0.06468431361811616, Train_acc 0.971854967948718\n",
      "\n",
      "Epoch 15. Loss: 0.06769703067806893, Train_acc 0.9717167721518988\n",
      "\n",
      "Epoch 15. Loss: 0.06440015125990689, Train_acc 0.97197265625\n",
      "\n",
      "Epoch 15. Loss: 0.0650459646170209, Train_acc 0.9719328703703703\n",
      "\n",
      "Epoch 15. Loss: 0.0658248754428211, Train_acc 0.9718940548780488\n",
      "\n",
      "Epoch 15. Loss: 0.06534842629012912, Train_acc 0.9719503012048193\n",
      "\n",
      "Epoch 15. Loss: 0.06706755216816768, Train_acc 0.9719122023809523\n",
      "\n",
      "Epoch 15. Loss: 0.06666138639360403, Train_acc 0.9719669117647058\n",
      "\n",
      "Epoch 15. Loss: 0.06521638664880158, Train_acc 0.9721111918604651\n",
      "\n",
      "Epoch 15. Loss: 0.06505786865900841, Train_acc 0.9721623563218391\n",
      "\n",
      "Epoch 15. Loss: 0.06115825279013115, Train_acc 0.9723899147727273\n",
      "\n",
      "Epoch 15. Loss: 0.06766497764100848, Train_acc 0.9720856741573034\n",
      "\n",
      "Epoch 15. Loss: 0.06614941848615008, Train_acc 0.9721354166666667\n",
      "\n",
      "Epoch 15. Loss: 0.0665830939409065, Train_acc 0.9720982142857143\n",
      "\n",
      "Epoch 15. Loss: 0.06743585193725775, Train_acc 0.9719769021739131\n",
      "\n",
      "Epoch 15. Loss: 0.07176404632245616, Train_acc 0.971690188172043\n",
      "\n",
      "Epoch 15. Loss: 0.07014725301070615, Train_acc 0.9716589095744681\n",
      "\n",
      "Epoch 15. Loss: 0.0733230906135166, Train_acc 0.9715460526315789\n",
      "\n",
      "Epoch 15. Loss: 0.0707148095136575, Train_acc 0.9715983072916666\n",
      "\n",
      "Epoch 15. Loss: 0.06999690578869212, Train_acc 0.9717300257731959\n",
      "\n",
      "Epoch 15. Loss: 0.06764360737643745, Train_acc 0.9718590561224489\n",
      "\n",
      "Epoch 15. Loss: 0.06880208824731802, Train_acc 0.9715909090909091\n",
      "\n",
      "Epoch 15. Loss: 0.06778335101596619, Train_acc 0.97171875\n",
      "\n",
      "[Epoch 15 Batch 100] Loss: 0.06792763793938254 Training: accuracy=0.971689\n",
      "Epoch 15. Loss: 0.06792763793938254, Train_acc 0.9716893564356436\n",
      "\n",
      "Epoch 15. Loss: 0.06809553734486903, Train_acc 0.9717371323529411\n",
      "\n",
      "Epoch 15. Loss: 0.06779734699748997, Train_acc 0.9718598300970874\n",
      "\n",
      "Epoch 15. Loss: 0.06512090705772976, Train_acc 0.9721304086538461\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15. Loss: 0.06477564924604362, Train_acc 0.9720982142857143\n",
      "\n",
      "Epoch 15. Loss: 0.06298527214211225, Train_acc 0.9722140330188679\n",
      "\n",
      "Epoch 15. Loss: 0.0625321202869594, Train_acc 0.9721816588785047\n",
      "\n",
      "Epoch 15. Loss: 0.0639046475346726, Train_acc 0.9722222222222222\n",
      "\n",
      "Epoch 15. Loss: 0.06438424543045537, Train_acc 0.9722620412844036\n",
      "\n",
      "Epoch 15. Loss: 0.06837309618743578, Train_acc 0.9721590909090909\n",
      "\n",
      "Epoch 15. Loss: 0.07055447223739911, Train_acc 0.9720579954954955\n",
      "\n",
      "Epoch 15. Loss: 0.06683702072164793, Train_acc 0.97216796875\n",
      "\n",
      "Epoch 15. Loss: 0.0657097441017155, Train_acc 0.9722068584070797\n",
      "\n",
      "Epoch 15. Loss: 0.0685506262236408, Train_acc 0.9719709429824561\n",
      "\n",
      "Epoch 15. Loss: 0.07699959854962572, Train_acc 0.9716032608695652\n",
      "\n",
      "Epoch 15. Loss: 0.07750293952836525, Train_acc 0.9715786637931034\n",
      "\n",
      "Epoch 15. Loss: 0.07619813018394052, Train_acc 0.9714877136752137\n",
      "\n",
      "Epoch 15. Loss: 0.0775389188529778, Train_acc 0.9713320974576272\n",
      "\n",
      "Epoch 15. Loss: 0.07888432270303922, Train_acc 0.9713103991596639\n",
      "\n",
      "Epoch 15. Loss: 0.07611818843497833, Train_acc 0.9714192708333333\n",
      "\n",
      "Epoch 15. Loss: 0.08097224742246271, Train_acc 0.9712680785123967\n",
      "\n",
      "Epoch 15. Loss: 0.08443505892222467, Train_acc 0.9711193647540983\n",
      "\n",
      "Epoch 15. Loss: 0.08031445961354979, Train_acc 0.9712906504065041\n",
      "\n",
      "Epoch 15. Loss: 0.08561065394722349, Train_acc 0.9711441532258065\n",
      "\n",
      "Epoch 15. Loss: 0.08746262951829667, Train_acc 0.971\n",
      "\n",
      "Epoch 15. Loss: 0.08395333049421283, Train_acc 0.9710441468253969\n",
      "\n",
      "Epoch 15. Loss: 0.0948119413053224, Train_acc 0.9706569881889764\n",
      "\n",
      "Epoch 15. Loss: 0.08645169950531986, Train_acc 0.97088623046875\n",
      "\n",
      "Epoch 15. Loss: 0.08624739289588094, Train_acc 0.9707485465116279\n",
      "\n",
      "Epoch 15. Loss: 0.08598635724460806, Train_acc 0.9706730769230769\n",
      "\n",
      "Epoch 15. Loss: 0.08776654569455139, Train_acc 0.9705987595419847\n",
      "\n",
      "Epoch 15. Loss: 0.09090097339285749, Train_acc 0.9704663825757576\n",
      "\n",
      "Epoch 15. Loss: 0.08677608191668992, Train_acc 0.9705709586466166\n",
      "\n",
      "Epoch 15. Loss: 0.08707950788468127, Train_acc 0.9706739738805971\n",
      "\n",
      "Epoch 15. Loss: 0.08395317035374049, Train_acc 0.9707175925925926\n",
      "\n",
      "Epoch 15. Loss: 0.08417911905756893, Train_acc 0.970703125\n",
      "\n",
      "Epoch 15. Loss: 0.08301608260313842, Train_acc 0.9706318430656934\n",
      "\n",
      "Epoch 15. Loss: 0.08359592478728449, Train_acc 0.9705615942028986\n",
      "\n",
      "Epoch 15. Loss: 0.08283265594771048, Train_acc 0.9704923561151079\n",
      "\n",
      "Epoch 15. Loss: 0.08218076375839597, Train_acc 0.9704799107142857\n",
      "\n",
      "Epoch 15. Loss: 0.07987345238969462, Train_acc 0.97052304964539\n",
      "\n",
      "Epoch 15. Loss: 0.07565947306554678, Train_acc 0.9706205985915493\n",
      "\n",
      "Epoch 15. Loss: 0.07145120552838889, Train_acc 0.970771416083916\n",
      "\n",
      "Epoch 15. Loss: 0.07563299031550628, Train_acc 0.9706488715277778\n",
      "\n",
      "Epoch 15. Loss: 0.07586478598262318, Train_acc 0.9705818965517241\n",
      "\n",
      "Epoch 15. Loss: 0.07533041006933552, Train_acc 0.9705693493150684\n",
      "\n",
      "Epoch 15. Loss: 0.07634090661952705, Train_acc 0.9705569727891157\n",
      "\n",
      "Epoch 15. Loss: 0.08105800700142812, Train_acc 0.9703336148648649\n",
      "\n",
      "Epoch 15. Loss: 0.07944953428466467, Train_acc 0.9704278523489933\n",
      "\n",
      "Epoch 15. Loss: 0.0794042548843564, Train_acc 0.9703645833333333\n",
      "\n",
      "Epoch 15. Loss: 0.07547291268184854, Train_acc 0.9705091059602649\n",
      "\n",
      "Epoch 15. Loss: 0.07188572793550856, Train_acc 0.9706517269736842\n",
      "\n",
      "Epoch 15. Loss: 0.0782344145418486, Train_acc 0.9704350490196079\n",
      "\n",
      "Epoch 15. Loss: 0.08006282325160036, Train_acc 0.9703226461038961\n",
      "\n",
      "Epoch 15. Loss: 0.07648804419253645, Train_acc 0.970413306451613\n",
      "\n",
      "Epoch 15. Loss: 0.0731703129382227, Train_acc 0.9705528846153846\n",
      "\n",
      "Epoch 15. Loss: 0.07036873060208208, Train_acc 0.970640923566879\n",
      "\n",
      "Epoch 15. Loss: 0.07701110861666483, Train_acc 0.9705300632911392\n",
      "\n",
      "Epoch 15. Loss: 0.08008281831712259, Train_acc 0.9703714622641509\n",
      "\n",
      "Epoch 15. Loss: 0.07598855893108904, Train_acc 0.9705078125\n",
      "\n",
      "Epoch 15. Loss: 0.08306915432477288, Train_acc 0.9703998447204969\n",
      "\n",
      "Epoch 15. Loss: 0.07807033765552306, Train_acc 0.9704861111111112\n",
      "\n",
      "Epoch 15. Loss: 0.08604070104573247, Train_acc 0.9702837423312883\n",
      "\n",
      "Epoch 15. Loss: 0.08446335396838854, Train_acc 0.9703696646341463\n",
      "\n",
      "Epoch 15. Loss: 0.08555656911438111, Train_acc 0.9702651515151515\n",
      "\n",
      "Epoch 15. Loss: 0.0852346285418159, Train_acc 0.9702560240963856\n",
      "\n",
      "Epoch 15. Loss: 0.08663468935210882, Train_acc 0.9702470059880239\n",
      "\n",
      "Epoch 15. Loss: 0.09039406518446844, Train_acc 0.9700985863095238\n",
      "\n",
      "Epoch 15. Loss: 0.09611340350187517, Train_acc 0.9698594674556213\n",
      "\n",
      "Epoch 15. Loss: 0.09899779396900561, Train_acc 0.9696691176470589\n",
      "\n",
      "Epoch 15. Loss: 0.0984464130191418, Train_acc 0.9696637426900585\n",
      "\n",
      "Epoch 15. Loss: 0.0996872648347985, Train_acc 0.9696130087209303\n",
      "\n",
      "Epoch 15. Loss: 0.10140325409915191, Train_acc 0.9694725433526011\n",
      "\n",
      "Epoch 15. Loss: 0.10195944264006146, Train_acc 0.9693336925287356\n",
      "\n",
      "Epoch 15. Loss: 0.1029541169506746, Train_acc 0.9692410714285714\n",
      "\n",
      "Epoch 15. Loss: 0.10203203930578568, Train_acc 0.96923828125\n",
      "\n",
      "Epoch 15. Loss: 0.1026083689104492, Train_acc 0.969191384180791\n",
      "\n",
      "Epoch 15. Loss: 0.09656061965265643, Train_acc 0.9693205758426966\n",
      "\n",
      "Epoch 15. Loss: 0.09463478837643956, Train_acc 0.9693173882681564\n",
      "\n",
      "Epoch 15. Loss: 0.10266927225203719, Train_acc 0.9690104166666667\n",
      "\n",
      "Epoch 15. Loss: 0.10455108591447539, Train_acc 0.9689226519337016\n",
      "\n",
      "Epoch 15. Loss: 0.10467246316549421, Train_acc 0.9687070741758241\n",
      "\n",
      "Epoch 15. Loss: 0.10011258290121472, Train_acc 0.9687073087431693\n",
      "\n",
      "Epoch 15. Loss: 0.09938830047168896, Train_acc 0.9686226222826086\n",
      "\n",
      "Epoch 15. Loss: 0.09329521276937634, Train_acc 0.96875\n",
      "\n",
      "Epoch 15. Loss: 0.09088376344788114, Train_acc 0.968792002688172\n",
      "\n",
      "Epoch 15. Loss: 0.09190260408712661, Train_acc 0.9687082219251337\n",
      "\n",
      "Epoch 15. Loss: 0.08863823932462844, Train_acc 0.9688331117021277\n",
      "\n",
      "Epoch 15. Loss: 0.08831154694009347, Train_acc 0.968832671957672\n",
      "\n",
      "Epoch 15. Loss: 0.08596803894503584, Train_acc 0.9688322368421053\n",
      "\n",
      "Epoch 15. Loss: 0.08252914831814472, Train_acc 0.9688727094240838\n",
      "\n",
      "Epoch 15. Loss: 0.08327122630873893, Train_acc 0.9688313802083334\n",
      "\n",
      "Epoch 15. Loss: 0.08071995394408323, Train_acc 0.9688714378238342\n",
      "\n",
      "Epoch 15. Loss: 0.07921998605411902, Train_acc 0.9689110824742269\n",
      "\n",
      "Epoch 15. Loss: 0.07842270274712135, Train_acc 0.9688301282051283\n",
      "\n",
      "Epoch 15. Loss: 0.07478694608587166, Train_acc 0.96884\n",
      "\n",
      "Epoch 16. Loss: 0.07284597671727665, Train_acc 0.9765625\n",
      "\n",
      "Epoch 16. Loss: 0.07258964583307798, Train_acc 0.9765625\n",
      "\n",
      "Epoch 16. Loss: 0.06991108697679903, Train_acc 0.9765625\n",
      "\n",
      "Epoch 16. Loss: 0.0677681425991112, Train_acc 0.978515625\n",
      "\n",
      "Epoch 16. Loss: 0.06574227562091833, Train_acc 0.978125\n",
      "\n",
      "Epoch 16. Loss: 0.0630763812411614, Train_acc 0.9778645833333334\n",
      "\n",
      "Epoch 16. Loss: 0.06358190121192822, Train_acc 0.9754464285714286\n",
      "\n",
      "Epoch 16. Loss: 0.06195958659296414, Train_acc 0.9775390625\n",
      "\n",
      "Epoch 16. Loss: 0.06274559979359967, Train_acc 0.9765625\n",
      "\n",
      "Epoch 16. Loss: 0.06411868975806828, Train_acc 0.97734375\n",
      "\n",
      "Epoch 16. Loss: 0.06411426272614536, Train_acc 0.9779829545454546\n",
      "\n",
      "Epoch 16. Loss: 0.06361098034641507, Train_acc 0.9778645833333334\n",
      "\n",
      "Epoch 16. Loss: 0.06266103485341099, Train_acc 0.9789663461538461\n",
      "\n",
      "Epoch 16. Loss: 0.06652362018032575, Train_acc 0.9771205357142857\n",
      "\n",
      "Epoch 16. Loss: 0.06204579020324681, Train_acc 0.9786458333333333\n",
      "\n",
      "Epoch 16. Loss: 0.07288437257513404, Train_acc 0.97509765625\n",
      "\n",
      "Epoch 16. Loss: 0.07015496532891691, Train_acc 0.9761029411764706\n",
      "\n",
      "Epoch 16. Loss: 0.07063319197989554, Train_acc 0.9756944444444444\n",
      "\n",
      "Epoch 16. Loss: 0.0754181347343062, Train_acc 0.9745065789473685\n",
      "\n",
      "Epoch 16. Loss: 0.07756935078377139, Train_acc 0.97421875\n",
      "\n",
      "Epoch 16. Loss: 0.07356273064143609, Train_acc 0.9750744047619048\n",
      "\n",
      "Epoch 16. Loss: 0.07257768895441727, Train_acc 0.9751420454545454\n",
      "\n",
      "Epoch 16. Loss: 0.07413405674291644, Train_acc 0.9748641304347826\n",
      "\n",
      "Epoch 16. Loss: 0.07713605312341147, Train_acc 0.9739583333333334\n",
      "\n",
      "Epoch 16. Loss: 0.07323047829717719, Train_acc 0.9746875\n",
      "\n",
      "Epoch 16. Loss: 0.07027827483162574, Train_acc 0.9750600961538461\n",
      "\n",
      "Epoch 16. Loss: 0.07030246286164486, Train_acc 0.9751157407407407\n",
      "\n",
      "Epoch 16. Loss: 0.06814911629471866, Train_acc 0.9751674107142857\n",
      "\n",
      "Epoch 16. Loss: 0.06480063608926852, Train_acc 0.9757543103448276\n",
      "\n",
      "Epoch 16. Loss: 0.0676766755727737, Train_acc 0.975\n",
      "\n",
      "Epoch 16. Loss: 0.06655999176631648, Train_acc 0.9750504032258065\n",
      "\n",
      "Epoch 16. Loss: 0.0717562644445623, Train_acc 0.974609375\n",
      "\n",
      "Epoch 16. Loss: 0.07303962487850116, Train_acc 0.9741950757575758\n",
      "\n",
      "Epoch 16. Loss: 0.07495094280427866, Train_acc 0.9735753676470589\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16. Loss: 0.07379444635796105, Train_acc 0.9741071428571428\n",
      "\n",
      "Epoch 16. Loss: 0.07388607290584642, Train_acc 0.9737413194444444\n",
      "\n",
      "Epoch 16. Loss: 0.07346834952114938, Train_acc 0.9738175675675675\n",
      "\n",
      "Epoch 16. Loss: 0.07386484412383065, Train_acc 0.9736842105263158\n",
      "\n",
      "Epoch 16. Loss: 0.07511279286173904, Train_acc 0.9735576923076923\n",
      "\n",
      "Epoch 16. Loss: 0.07422813148404292, Train_acc 0.9736328125\n",
      "\n",
      "Epoch 16. Loss: 0.07464711550866185, Train_acc 0.9735137195121951\n",
      "\n",
      "Epoch 16. Loss: 0.07144269884223894, Train_acc 0.9737723214285714\n",
      "\n",
      "Epoch 16. Loss: 0.07070428169305762, Train_acc 0.9734738372093024\n",
      "\n",
      "Epoch 16. Loss: 0.06637030239286101, Train_acc 0.9740767045454546\n",
      "\n",
      "Epoch 16. Loss: 0.0680606966797895, Train_acc 0.9739583333333334\n",
      "\n",
      "Epoch 16. Loss: 0.06550100309411169, Train_acc 0.974014945652174\n",
      "\n",
      "Epoch 16. Loss: 0.06277516994857324, Train_acc 0.9744015957446809\n",
      "\n",
      "Epoch 16. Loss: 0.06158702572271406, Train_acc 0.9744466145833334\n",
      "\n",
      "Epoch 16. Loss: 0.0626193709679113, Train_acc 0.9744897959183674\n",
      "\n",
      "Epoch 16. Loss: 0.06234780721434947, Train_acc 0.97453125\n",
      "\n",
      "Epoch 16. Loss: 0.060823675446829165, Train_acc 0.9747242647058824\n",
      "\n",
      "Epoch 16. Loss: 0.0595984650729188, Train_acc 0.9749098557692307\n",
      "\n",
      "Epoch 16. Loss: 0.061230064309664545, Train_acc 0.9747936320754716\n",
      "\n",
      "Epoch 16. Loss: 0.05728922192188619, Train_acc 0.9751157407407407\n",
      "\n",
      "Epoch 16. Loss: 0.05753104563593136, Train_acc 0.9751420454545454\n",
      "\n",
      "Epoch 16. Loss: 0.05880634048020184, Train_acc 0.9750279017857143\n",
      "\n",
      "Epoch 16. Loss: 0.05651305593641407, Train_acc 0.975328947368421\n",
      "\n",
      "Epoch 16. Loss: 0.053866589241550626, Train_acc 0.9756196120689655\n",
      "\n",
      "Epoch 16. Loss: 0.05311967693864667, Train_acc 0.9757680084745762\n",
      "\n",
      "Epoch 16. Loss: 0.04999806408374933, Train_acc 0.976171875\n",
      "\n",
      "Epoch 16. Loss: 0.049156810411418325, Train_acc 0.9763063524590164\n",
      "\n",
      "Epoch 16. Loss: 0.04881306788498597, Train_acc 0.9764364919354839\n",
      "\n",
      "Epoch 16. Loss: 0.04959568799592051, Train_acc 0.9765625\n",
      "\n",
      "Epoch 16. Loss: 0.05327839557281429, Train_acc 0.9764404296875\n",
      "\n",
      "Epoch 16. Loss: 0.05248031306819285, Train_acc 0.9765625\n",
      "\n",
      "Epoch 16. Loss: 0.05049622912904171, Train_acc 0.9767992424242424\n",
      "\n",
      "Epoch 16. Loss: 0.04985481859475864, Train_acc 0.9767957089552238\n",
      "\n",
      "Epoch 16. Loss: 0.050279327731405137, Train_acc 0.9767922794117647\n",
      "\n",
      "Epoch 16. Loss: 0.053032703847653656, Train_acc 0.9765625\n",
      "\n",
      "Epoch 16. Loss: 0.05645749731448322, Train_acc 0.9763392857142857\n",
      "\n",
      "Epoch 16. Loss: 0.05707189080345955, Train_acc 0.9762323943661971\n",
      "\n",
      "Epoch 16. Loss: 0.06083373624588543, Train_acc 0.9761284722222222\n",
      "\n",
      "Epoch 16. Loss: 0.06918901114319706, Train_acc 0.9758133561643836\n",
      "\n",
      "Epoch 16. Loss: 0.08114257969249736, Train_acc 0.9750844594594594\n",
      "\n",
      "Epoch 16. Loss: 0.07902442158272371, Train_acc 0.9751041666666667\n",
      "\n",
      "Epoch 16. Loss: 0.07766953624198293, Train_acc 0.9751233552631579\n",
      "\n",
      "Epoch 16. Loss: 0.08848470464565864, Train_acc 0.9743303571428571\n",
      "\n",
      "Epoch 16. Loss: 0.09068453996078829, Train_acc 0.9740584935897436\n",
      "\n",
      "Epoch 16. Loss: 0.09011995812085266, Train_acc 0.9738924050632911\n",
      "\n",
      "Epoch 16. Loss: 0.08933491575563247, Train_acc 0.973828125\n",
      "\n",
      "Epoch 16. Loss: 0.10312901944974925, Train_acc 0.9731867283950617\n",
      "\n",
      "Epoch 16. Loss: 0.11264459053629518, Train_acc 0.9727515243902439\n",
      "\n",
      "Epoch 16. Loss: 0.10808959835726512, Train_acc 0.9727033132530121\n",
      "\n",
      "Epoch 16. Loss: 0.10702659249864661, Train_acc 0.9724702380952381\n",
      "\n",
      "Epoch 16. Loss: 0.11444609219338873, Train_acc 0.9715992647058823\n",
      "\n",
      "Epoch 16. Loss: 0.1142534928426717, Train_acc 0.9714752906976745\n",
      "\n",
      "Epoch 16. Loss: 0.11095760615815886, Train_acc 0.9715337643678161\n",
      "\n",
      "Epoch 16. Loss: 0.10859388949409278, Train_acc 0.9713245738636364\n",
      "\n",
      "Epoch 16. Loss: 0.1059400693351193, Train_acc 0.9713834269662921\n",
      "\n",
      "Epoch 16. Loss: 0.10758980713255678, Train_acc 0.9713541666666666\n",
      "\n",
      "Epoch 16. Loss: 0.10090409273178108, Train_acc 0.9714972527472527\n",
      "\n",
      "Epoch 16. Loss: 0.101087173559702, Train_acc 0.9715523097826086\n",
      "\n",
      "Epoch 16. Loss: 0.09741398236611773, Train_acc 0.971690188172043\n",
      "\n",
      "Epoch 16. Loss: 0.09881012551301083, Train_acc 0.9714095744680851\n",
      "\n",
      "Epoch 16. Loss: 0.10530503760856415, Train_acc 0.9709703947368421\n",
      "\n",
      "Epoch 16. Loss: 0.10867404941691779, Train_acc 0.9707845052083334\n",
      "\n",
      "Epoch 16. Loss: 0.10602031055665453, Train_acc 0.9708440721649485\n",
      "\n",
      "Epoch 16. Loss: 0.10330346289494431, Train_acc 0.9706632653061225\n",
      "\n",
      "Epoch 16. Loss: 0.0992759240855467, Train_acc 0.9708017676767676\n",
      "\n",
      "Epoch 16. Loss: 0.097574584769281, Train_acc 0.970859375\n",
      "\n",
      "[Epoch 16 Batch 100] Loss: 0.10109195985234283 Training: accuracy=0.970606\n",
      "Epoch 16. Loss: 0.10109195985234283, Train_acc 0.9706064356435643\n",
      "\n",
      "Epoch 16. Loss: 0.10443040023299904, Train_acc 0.9705882352941176\n",
      "\n",
      "Epoch 16. Loss: 0.10281597784208821, Train_acc 0.9706462378640777\n",
      "\n",
      "Epoch 16. Loss: 0.10143985936982244, Train_acc 0.9704777644230769\n",
      "\n",
      "Epoch 16. Loss: 0.10183188399621378, Train_acc 0.9703125\n",
      "\n",
      "Epoch 16. Loss: 0.10147817207230804, Train_acc 0.9701503537735849\n",
      "\n",
      "Epoch 16. Loss: 0.10602307265568087, Train_acc 0.9699182242990654\n",
      "\n",
      "Epoch 16. Loss: 0.10334724884243288, Train_acc 0.9699074074074074\n",
      "\n",
      "Epoch 16. Loss: 0.09986443699310552, Train_acc 0.9698967889908257\n",
      "\n",
      "Epoch 16. Loss: 0.10032719118216929, Train_acc 0.9697443181818182\n",
      "\n",
      "Epoch 16. Loss: 0.10074444630282489, Train_acc 0.9696649774774775\n",
      "\n",
      "Epoch 16. Loss: 0.09358690025094779, Train_acc 0.9699358258928571\n",
      "\n",
      "Epoch 16. Loss: 0.0973104641588059, Train_acc 0.9695105088495575\n",
      "\n",
      "Epoch 16. Loss: 0.09905990860624853, Train_acc 0.9692982456140351\n",
      "\n",
      "Epoch 16. Loss: 0.09474722208169468, Train_acc 0.9694293478260869\n",
      "\n",
      "Epoch 16. Loss: 0.09593291650641592, Train_acc 0.9693561422413793\n",
      "\n",
      "Epoch 16. Loss: 0.09457410860444872, Train_acc 0.969284188034188\n",
      "\n",
      "Epoch 16. Loss: 0.09341377307521494, Train_acc 0.9692796610169492\n",
      "\n",
      "Epoch 16. Loss: 0.089265296216731, Train_acc 0.9693408613445378\n",
      "\n",
      "Epoch 16. Loss: 0.09513578357332175, Train_acc 0.969140625\n",
      "\n",
      "Epoch 16. Loss: 0.0915276613119235, Train_acc 0.9692665289256198\n",
      "\n",
      "Epoch 16. Loss: 0.09566980209496531, Train_acc 0.9690061475409836\n",
      "\n",
      "Epoch 16. Loss: 0.0940988319207452, Train_acc 0.9690040650406504\n",
      "\n",
      "Epoch 16. Loss: 0.09445069495641192, Train_acc 0.96875\n",
      "\n",
      "Epoch 16. Loss: 0.0913810679060489, Train_acc 0.96875\n",
      "\n",
      "Epoch 16. Loss: 0.08626938227494985, Train_acc 0.968812003968254\n",
      "\n",
      "Epoch 16. Loss: 0.08579042133999255, Train_acc 0.968873031496063\n",
      "\n",
      "Epoch 16. Loss: 0.08433935264330257, Train_acc 0.96893310546875\n",
      "\n",
      "Epoch 16. Loss: 0.0856079501174195, Train_acc 0.9688105620155039\n",
      "\n",
      "Epoch 16. Loss: 0.08502224018534751, Train_acc 0.9688100961538462\n",
      "\n",
      "Epoch 16. Loss: 0.08117300917530715, Train_acc 0.9688692748091603\n",
      "\n",
      "Epoch 16. Loss: 0.0799196815475046, Train_acc 0.9688683712121212\n",
      "\n",
      "Epoch 16. Loss: 0.07989442700006538, Train_acc 0.9689262218045113\n",
      "\n",
      "Epoch 16. Loss: 0.07802652138940669, Train_acc 0.9690415111940298\n",
      "\n",
      "Epoch 16. Loss: 0.07439465248708883, Train_acc 0.9691550925925926\n",
      "\n",
      "Epoch 16. Loss: 0.07388330481164121, Train_acc 0.9692095588235294\n",
      "\n",
      "Epoch 16. Loss: 0.07421469076018748, Train_acc 0.9692062043795621\n",
      "\n",
      "Epoch 16. Loss: 0.06961632583476202, Train_acc 0.9694293478260869\n",
      "\n",
      "Epoch 16. Loss: 0.06526335646751907, Train_acc 0.9695930755395683\n",
      "\n",
      "Epoch 16. Loss: 0.06342222492435623, Train_acc 0.9696986607142857\n",
      "\n",
      "Epoch 16. Loss: 0.069052508776239, Train_acc 0.9696919326241135\n",
      "\n",
      "Epoch 16. Loss: 0.06972288904027771, Train_acc 0.9697403169014085\n",
      "\n",
      "Epoch 16. Loss: 0.06715156123730509, Train_acc 0.9697333916083916\n",
      "\n",
      "Epoch 16. Loss: 0.06355168974274071, Train_acc 0.9699435763888888\n",
      "\n",
      "Epoch 16. Loss: 0.06517481853848998, Train_acc 0.9699353448275863\n",
      "\n",
      "Epoch 16. Loss: 0.06480425268667613, Train_acc 0.9699807363013698\n",
      "\n",
      "Epoch 16. Loss: 0.06309760737649507, Train_acc 0.9700786564625851\n",
      "\n",
      "Epoch 16. Loss: 0.06298148672192014, Train_acc 0.9700696790540541\n",
      "\n",
      "Epoch 16. Loss: 0.06262108421691105, Train_acc 0.970060822147651\n",
      "\n",
      "Epoch 16. Loss: 0.06000717046589714, Train_acc 0.9702083333333333\n",
      "\n",
      "Epoch 16. Loss: 0.059034950847009375, Train_acc 0.9701986754966887\n",
      "\n",
      "Epoch 16. Loss: 0.05871092325262388, Train_acc 0.9702919407894737\n",
      "\n",
      "Epoch 16. Loss: 0.05589106347392941, Train_acc 0.9703839869281046\n",
      "\n",
      "Epoch 16. Loss: 0.05589870549348841, Train_acc 0.9704241071428571\n",
      "\n",
      "Epoch 16. Loss: 0.05405571665264234, Train_acc 0.9705141129032258\n",
      "\n",
      "Epoch 16. Loss: 0.05440622215775012, Train_acc 0.9706530448717948\n",
      "\n",
      "Epoch 16. Loss: 0.05824493299699449, Train_acc 0.9705911624203821\n",
      "\n",
      "Epoch 16. Loss: 0.058440651125698906, Train_acc 0.9705795094936709\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16. Loss: 0.05635014865725305, Train_acc 0.9707154088050315\n",
      "\n",
      "Epoch 16. Loss: 0.055854161699972156, Train_acc 0.97080078125\n",
      "\n",
      "Epoch 16. Loss: 0.05817171122464085, Train_acc 0.9707880434782609\n",
      "\n",
      "Epoch 16. Loss: 0.055771085046224696, Train_acc 0.9708719135802469\n",
      "\n",
      "Epoch 16. Loss: 0.05318336926921568, Train_acc 0.970954754601227\n",
      "\n",
      "Epoch 16. Loss: 0.05193014697454299, Train_acc 0.9710365853658537\n",
      "\n",
      "Epoch 16. Loss: 0.05357046877940231, Train_acc 0.9710227272727273\n",
      "\n",
      "Epoch 16. Loss: 0.0564969088637805, Train_acc 0.9710090361445783\n",
      "\n",
      "Epoch 16. Loss: 0.0535836230743506, Train_acc 0.9711358532934131\n",
      "\n",
      "Epoch 16. Loss: 0.051491640004090525, Train_acc 0.9712146577380952\n",
      "\n",
      "Epoch 16. Loss: 0.04979791186085825, Train_acc 0.9712925295857988\n",
      "\n",
      "Epoch 16. Loss: 0.04726774063108699, Train_acc 0.9714613970588235\n",
      "\n",
      "Epoch 16. Loss: 0.050308202055677806, Train_acc 0.9713541666666666\n",
      "\n",
      "Epoch 16. Loss: 0.048224524011538955, Train_acc 0.9714752906976745\n",
      "\n",
      "Epoch 16. Loss: 0.05402464152901757, Train_acc 0.9714143786127167\n",
      "\n",
      "Epoch 16. Loss: 0.05747351257380297, Train_acc 0.9713541666666666\n",
      "\n",
      "Epoch 16. Loss: 0.0539891242984812, Train_acc 0.9714732142857143\n",
      "\n",
      "Epoch 16. Loss: 0.06057262748514537, Train_acc 0.9714577414772727\n",
      "\n",
      "Epoch 16. Loss: 0.05984506231577627, Train_acc 0.971530720338983\n",
      "\n",
      "Epoch 16. Loss: 0.05763165366975754, Train_acc 0.9716028792134831\n",
      "\n",
      "Epoch 16. Loss: 0.05544474687273761, Train_acc 0.971717877094972\n",
      "\n",
      "Epoch 16. Loss: 0.05419864847745413, Train_acc 0.9717881944444444\n",
      "\n",
      "Epoch 16. Loss: 0.06335907364922089, Train_acc 0.9716419198895028\n",
      "\n",
      "Epoch 16. Loss: 0.06315296494994153, Train_acc 0.9716689560439561\n",
      "\n",
      "Epoch 16. Loss: 0.06125322040051451, Train_acc 0.9716530054644809\n",
      "\n",
      "Epoch 16. Loss: 0.059588247294398225, Train_acc 0.9717221467391305\n",
      "\n",
      "Epoch 16. Loss: 0.06885090806052573, Train_acc 0.9716638513513514\n",
      "\n",
      "Epoch 16. Loss: 0.06634376686482567, Train_acc 0.9717741935483871\n",
      "\n",
      "Epoch 16. Loss: 0.06641702197494154, Train_acc 0.9717997994652406\n",
      "\n",
      "Epoch 16. Loss: 0.06400513247402351, Train_acc 0.9718251329787234\n",
      "\n",
      "Epoch 16. Loss: 0.0666481563069091, Train_acc 0.9717675264550265\n",
      "\n",
      "Epoch 16. Loss: 0.0682286337272226, Train_acc 0.9717516447368421\n",
      "\n",
      "Epoch 16. Loss: 0.06556448178791098, Train_acc 0.9718177356020943\n",
      "\n",
      "Epoch 16. Loss: 0.06311769973310613, Train_acc 0.9718831380208334\n",
      "\n",
      "Epoch 16. Loss: 0.05857867955630526, Train_acc 0.9720288212435233\n",
      "\n",
      "Epoch 16. Loss: 0.05847944618283664, Train_acc 0.9720521907216495\n",
      "\n",
      "Epoch 16. Loss: 0.0584480610580947, Train_acc 0.9721153846153846\n",
      "\n",
      "Epoch 16. Loss: 0.053980114982280676, Train_acc 0.97216\n",
      "\n",
      "Epoch 17. Loss: 0.05137054846503158, Train_acc 0.984375\n",
      "\n",
      "Epoch 17. Loss: 0.05124068536595541, Train_acc 0.98046875\n",
      "\n",
      "Epoch 17. Loss: 0.04937432023795877, Train_acc 0.984375\n",
      "\n",
      "Epoch 17. Loss: 0.04720871169488818, Train_acc 0.986328125\n",
      "\n",
      "Epoch 17. Loss: 0.05367895232845417, Train_acc 0.9796875\n",
      "\n",
      "Epoch 17. Loss: 0.05218176223822598, Train_acc 0.9817708333333334\n",
      "\n",
      "Epoch 17. Loss: 0.05063531595159916, Train_acc 0.9832589285714286\n",
      "\n",
      "Epoch 17. Loss: 0.05012407941540493, Train_acc 0.982421875\n",
      "\n",
      "Epoch 17. Loss: 0.04784773756939542, Train_acc 0.9835069444444444\n",
      "\n",
      "Epoch 17. Loss: 0.0443853817981038, Train_acc 0.98515625\n",
      "\n",
      "Epoch 17. Loss: 0.04471344866766514, Train_acc 0.9850852272727273\n",
      "\n",
      "Epoch 17. Loss: 0.04350952649188621, Train_acc 0.986328125\n",
      "\n",
      "Epoch 17. Loss: 0.045668868816547845, Train_acc 0.9849759615384616\n",
      "\n",
      "Epoch 17. Loss: 0.043529088658082415, Train_acc 0.9849330357142857\n",
      "\n",
      "Epoch 17. Loss: 0.04445929745911473, Train_acc 0.984375\n",
      "\n",
      "Epoch 17. Loss: 0.042474939145853347, Train_acc 0.98486328125\n",
      "\n",
      "Epoch 17. Loss: 0.04235877317328175, Train_acc 0.9848345588235294\n",
      "\n",
      "Epoch 17. Loss: 0.048589257646849036, Train_acc 0.9839409722222222\n",
      "\n",
      "Epoch 17. Loss: 0.04969039104811872, Train_acc 0.9839638157894737\n",
      "\n",
      "Epoch 17. Loss: 0.05203908943324559, Train_acc 0.983984375\n",
      "\n",
      "Epoch 17. Loss: 0.048426717265152394, Train_acc 0.9847470238095238\n",
      "\n",
      "Epoch 17. Loss: 0.047639902079436296, Train_acc 0.9847301136363636\n",
      "\n",
      "Epoch 17. Loss: 0.048017259145676894, Train_acc 0.984375\n",
      "\n",
      "Epoch 17. Loss: 0.04441873941263539, Train_acc 0.9850260416666666\n",
      "\n",
      "Epoch 17. Loss: 0.044034820840725145, Train_acc 0.985\n",
      "\n",
      "Epoch 17. Loss: 0.042797673460217275, Train_acc 0.9852764423076923\n",
      "\n",
      "Epoch 17. Loss: 0.0442770119455802, Train_acc 0.9849537037037037\n",
      "\n",
      "Epoch 17. Loss: 0.04513563477522262, Train_acc 0.9849330357142857\n",
      "\n",
      "Epoch 17. Loss: 0.04464140993529077, Train_acc 0.9846443965517241\n",
      "\n",
      "Epoch 17. Loss: 0.045055881549479204, Train_acc 0.9846354166666667\n",
      "\n",
      "Epoch 17. Loss: 0.04367878287395385, Train_acc 0.9848790322580645\n",
      "\n",
      "Epoch 17. Loss: 0.043120264628772866, Train_acc 0.985107421875\n",
      "\n",
      "Epoch 17. Loss: 0.040669717299263115, Train_acc 0.9855587121212122\n",
      "\n",
      "Epoch 17. Loss: 0.04132798425017634, Train_acc 0.9850643382352942\n",
      "\n",
      "Epoch 17. Loss: 0.041843141496111506, Train_acc 0.9850446428571429\n",
      "\n",
      "Epoch 17. Loss: 0.04068297312104364, Train_acc 0.9852430555555556\n",
      "\n",
      "Epoch 17. Loss: 0.04075617714622909, Train_acc 0.9852195945945946\n",
      "\n",
      "Epoch 17. Loss: 0.04183705485373104, Train_acc 0.9849917763157895\n",
      "\n",
      "Epoch 17. Loss: 0.04050544484564094, Train_acc 0.985176282051282\n",
      "\n",
      "Epoch 17. Loss: 0.037993712171391504, Train_acc 0.985546875\n",
      "\n",
      "Epoch 17. Loss: 0.03764039168758022, Train_acc 0.9857088414634146\n",
      "\n",
      "Epoch 17. Loss: 0.03643773081156159, Train_acc 0.9858630952380952\n",
      "\n",
      "Epoch 17. Loss: 0.03645109831320534, Train_acc 0.985828488372093\n",
      "\n",
      "Epoch 17. Loss: 0.03452910418683847, Train_acc 0.9861505681818182\n",
      "\n",
      "Epoch 17. Loss: 0.0319690691117158, Train_acc 0.9864583333333333\n",
      "\n",
      "Epoch 17. Loss: 0.02996677246097122, Train_acc 0.9867527173913043\n",
      "\n",
      "Epoch 17. Loss: 0.028329074782759495, Train_acc 0.9870345744680851\n",
      "\n",
      "Epoch 17. Loss: 0.034046517672506466, Train_acc 0.98681640625\n",
      "\n",
      "Epoch 17. Loss: 0.031882102403671286, Train_acc 0.9869260204081632\n",
      "\n",
      "Epoch 17. Loss: 0.034252113950518435, Train_acc 0.98703125\n",
      "\n",
      "Epoch 17. Loss: 0.03245023468339533, Train_acc 0.9872855392156863\n",
      "\n",
      "Epoch 17. Loss: 0.03342251326922259, Train_acc 0.9872295673076923\n",
      "\n",
      "Epoch 17. Loss: 0.03259666517779542, Train_acc 0.9874705188679245\n",
      "\n",
      "Epoch 17. Loss: 0.04064077218239289, Train_acc 0.9869791666666666\n",
      "\n",
      "Epoch 17. Loss: 0.040289615436179475, Train_acc 0.9869318181818182\n",
      "\n",
      "Epoch 17. Loss: 0.041219773003861045, Train_acc 0.9868861607142857\n",
      "\n",
      "Epoch 17. Loss: 0.04115335608369535, Train_acc 0.9868421052631579\n",
      "\n",
      "Epoch 17. Loss: 0.03792701183122182, Train_acc 0.9870689655172413\n",
      "\n",
      "Epoch 17. Loss: 0.04059609936203168, Train_acc 0.987155720338983\n",
      "\n",
      "Epoch 17. Loss: 0.038524989409973676, Train_acc 0.9873697916666667\n",
      "\n",
      "Epoch 17. Loss: 0.041528180948254875, Train_acc 0.9871926229508197\n",
      "\n",
      "Epoch 17. Loss: 0.04242408562721975, Train_acc 0.9870211693548387\n",
      "\n",
      "Epoch 17. Loss: 0.039810547767777746, Train_acc 0.9872271825396826\n",
      "\n",
      "Epoch 17. Loss: 0.03723943881425217, Train_acc 0.9874267578125\n",
      "\n",
      "Epoch 17. Loss: 0.03665939705580135, Train_acc 0.9875\n",
      "\n",
      "Epoch 17. Loss: 0.03587222162195736, Train_acc 0.9875710227272727\n",
      "\n",
      "Epoch 17. Loss: 0.03903140407778645, Train_acc 0.9875233208955224\n",
      "\n",
      "Epoch 17. Loss: 0.039784008922974685, Train_acc 0.9873621323529411\n",
      "\n",
      "Epoch 17. Loss: 0.03836477517735996, Train_acc 0.9873188405797102\n",
      "\n",
      "Epoch 17. Loss: 0.03926890167282854, Train_acc 0.9872767857142857\n",
      "\n",
      "Epoch 17. Loss: 0.03913199594038875, Train_acc 0.9871258802816901\n",
      "\n",
      "Epoch 17. Loss: 0.038617884580059214, Train_acc 0.9871961805555556\n",
      "\n",
      "Epoch 17. Loss: 0.04024151009061637, Train_acc 0.9870505136986302\n",
      "\n",
      "Epoch 17. Loss: 0.04237793721323045, Train_acc 0.9870143581081081\n",
      "\n",
      "Epoch 17. Loss: 0.041118826009912776, Train_acc 0.9870833333333333\n",
      "\n",
      "Epoch 17. Loss: 0.04138860676117256, Train_acc 0.987047697368421\n",
      "\n",
      "Epoch 17. Loss: 0.042912308038123084, Train_acc 0.987012987012987\n",
      "\n",
      "Epoch 17. Loss: 0.04172939147279945, Train_acc 0.9871794871794872\n",
      "\n",
      "Epoch 17. Loss: 0.04243584128373522, Train_acc 0.9871439873417721\n",
      "\n",
      "Epoch 17. Loss: 0.04451297359603934, Train_acc 0.9869140625\n",
      "\n",
      "Epoch 17. Loss: 0.0439279236966815, Train_acc 0.9868827160493827\n",
      "\n",
      "Epoch 17. Loss: 0.04253275154451547, Train_acc 0.9868521341463414\n",
      "\n",
      "Epoch 17. Loss: 0.04235031418579833, Train_acc 0.9869164156626506\n",
      "\n",
      "Epoch 17. Loss: 0.04749774973909274, Train_acc 0.9867001488095238\n",
      "\n",
      "Epoch 17. Loss: 0.04476510621297552, Train_acc 0.986764705882353\n",
      "\n",
      "Epoch 17. Loss: 0.047879077230586355, Train_acc 0.9867369186046512\n",
      "\n",
      "Epoch 17. Loss: 0.046893761814856896, Train_acc 0.9867097701149425\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17. Loss: 0.05215919279565606, Train_acc 0.9865056818181818\n",
      "\n",
      "Epoch 17. Loss: 0.04923830342450911, Train_acc 0.9865695224719101\n",
      "\n",
      "Epoch 17. Loss: 0.04789374652945257, Train_acc 0.9864583333333333\n",
      "\n",
      "Epoch 17. Loss: 0.047173227445273906, Train_acc 0.9863495879120879\n",
      "\n",
      "Epoch 17. Loss: 0.04440678595839975, Train_acc 0.9864130434782609\n",
      "\n",
      "Epoch 17. Loss: 0.04402653967743252, Train_acc 0.986307123655914\n",
      "\n",
      "Epoch 17. Loss: 0.04266667227809252, Train_acc 0.9863696808510638\n",
      "\n",
      "Epoch 17. Loss: 0.04924984002886374, Train_acc 0.9861019736842105\n",
      "\n",
      "Epoch 17. Loss: 0.04911929011146569, Train_acc 0.9859212239583334\n",
      "\n",
      "Epoch 17. Loss: 0.04807478910506079, Train_acc 0.985985824742268\n",
      "\n",
      "Epoch 17. Loss: 0.0486064707561163, Train_acc 0.9858896683673469\n",
      "\n",
      "Epoch 17. Loss: 0.04847255396757971, Train_acc 0.9857954545454546\n",
      "\n",
      "Epoch 17. Loss: 0.047680531870553954, Train_acc 0.98578125\n",
      "\n",
      "[Epoch 17 Batch 100] Loss: 0.046760034499672115 Training: accuracy=0.985845\n",
      "Epoch 17. Loss: 0.046760034499672115, Train_acc 0.9858446782178217\n",
      "\n",
      "Epoch 17. Loss: 0.046894732360339524, Train_acc 0.9857536764705882\n",
      "\n",
      "Epoch 17. Loss: 0.04963765434410843, Train_acc 0.9855885922330098\n",
      "\n",
      "Epoch 17. Loss: 0.05164097748982912, Train_acc 0.9853515625\n",
      "\n",
      "Epoch 17. Loss: 0.04954727257300621, Train_acc 0.9854910714285714\n",
      "\n",
      "Epoch 17. Loss: 0.04708591172852402, Train_acc 0.9854805424528302\n",
      "\n",
      "Epoch 17. Loss: 0.04758493999920742, Train_acc 0.9854702102803738\n",
      "\n",
      "Epoch 17. Loss: 0.04551356196656039, Train_acc 0.9854600694444444\n",
      "\n",
      "Epoch 17. Loss: 0.0435753348641474, Train_acc 0.9854501146788991\n",
      "\n",
      "Epoch 17. Loss: 0.04522354191597214, Train_acc 0.9854403409090909\n",
      "\n",
      "Epoch 17. Loss: 0.04770329850366036, Train_acc 0.9852899774774775\n",
      "\n",
      "Epoch 17. Loss: 0.04713044545755076, Train_acc 0.9852818080357143\n",
      "\n",
      "Epoch 17. Loss: 0.05173589570854862, Train_acc 0.985066371681416\n",
      "\n",
      "Epoch 17. Loss: 0.05389956414879643, Train_acc 0.9849232456140351\n",
      "\n",
      "Epoch 17. Loss: 0.05053380121452764, Train_acc 0.9850543478260869\n",
      "\n",
      "Epoch 17. Loss: 0.04718438657072028, Train_acc 0.9851831896551724\n",
      "\n",
      "Epoch 17. Loss: 0.04821271409344829, Train_acc 0.9850427350427351\n",
      "\n",
      "Epoch 17. Loss: 0.05277525299565932, Train_acc 0.9849046610169492\n",
      "\n",
      "Epoch 17. Loss: 0.054521325204762286, Train_acc 0.9847689075630253\n",
      "\n",
      "Epoch 17. Loss: 0.05162362126170915, Train_acc 0.9848958333333333\n",
      "\n",
      "Epoch 17. Loss: 0.0537112104981481, Train_acc 0.9847623966942148\n",
      "\n",
      "Epoch 17. Loss: 0.050670835018694904, Train_acc 0.9848232581967213\n",
      "\n",
      "Epoch 17. Loss: 0.051981874681002356, Train_acc 0.9848831300813008\n",
      "\n",
      "Epoch 17. Loss: 0.051725084000664764, Train_acc 0.9849420362903226\n",
      "\n",
      "Epoch 17. Loss: 0.050913703662608105, Train_acc 0.984875\n",
      "\n",
      "Epoch 17. Loss: 0.05018946764390531, Train_acc 0.9848710317460317\n",
      "\n",
      "Epoch 17. Loss: 0.05044163417089757, Train_acc 0.984744094488189\n",
      "\n",
      "Epoch 17. Loss: 0.05037902170063952, Train_acc 0.984619140625\n",
      "\n",
      "Epoch 17. Loss: 0.05169940999426156, Train_acc 0.9844961240310077\n",
      "\n",
      "Epoch 17. Loss: 0.04853359079758265, Train_acc 0.9846153846153847\n",
      "\n",
      "Epoch 17. Loss: 0.04868279590964262, Train_acc 0.9846135496183206\n",
      "\n",
      "Epoch 17. Loss: 0.04744629288995216, Train_acc 0.984670928030303\n",
      "\n",
      "Epoch 17. Loss: 0.05043424494818404, Train_acc 0.9844337406015038\n",
      "\n",
      "Epoch 17. Loss: 0.051242237488230064, Train_acc 0.984316697761194\n",
      "\n",
      "Epoch 17. Loss: 0.056151811212122434, Train_acc 0.9841435185185186\n",
      "\n",
      "Epoch 17. Loss: 0.05589268670662045, Train_acc 0.9840303308823529\n",
      "\n",
      "Epoch 17. Loss: 0.054840706135485764, Train_acc 0.9839758211678832\n",
      "\n",
      "Epoch 17. Loss: 0.052861069377351584, Train_acc 0.983978713768116\n",
      "\n",
      "Epoch 17. Loss: 0.04975313911833356, Train_acc 0.9840939748201439\n",
      "\n",
      "Epoch 17. Loss: 0.04781274247167698, Train_acc 0.9841517857142857\n",
      "\n",
      "Epoch 17. Loss: 0.04630537329314522, Train_acc 0.9842087765957447\n",
      "\n",
      "Epoch 17. Loss: 0.0470442771750543, Train_acc 0.9841549295774648\n",
      "\n",
      "Epoch 17. Loss: 0.04431596136133553, Train_acc 0.9842111013986014\n",
      "\n",
      "Epoch 17. Loss: 0.04567176165617122, Train_acc 0.9841579861111112\n",
      "\n",
      "Epoch 17. Loss: 0.046756417489975215, Train_acc 0.9839978448275862\n",
      "\n",
      "Epoch 17. Loss: 0.04395862678014892, Train_acc 0.984107448630137\n",
      "\n",
      "Epoch 17. Loss: 0.04880308666220598, Train_acc 0.9838966836734694\n",
      "\n",
      "Epoch 17. Loss: 0.04791416801564061, Train_acc 0.9839527027027027\n",
      "\n",
      "Epoch 17. Loss: 0.048479574494530234, Train_acc 0.9839555369127517\n",
      "\n",
      "Epoch 17. Loss: 0.04922687753108395, Train_acc 0.98390625\n",
      "\n",
      "Epoch 17. Loss: 0.050363855383401386, Train_acc 0.9838576158940397\n",
      "\n",
      "Epoch 17. Loss: 0.0519808517291593, Train_acc 0.9838096217105263\n",
      "\n",
      "Epoch 17. Loss: 0.050700674479703375, Train_acc 0.9838643790849673\n",
      "\n",
      "Epoch 17. Loss: 0.052834646426588534, Train_acc 0.9837662337662337\n",
      "\n",
      "Epoch 17. Loss: 0.05170434365238271, Train_acc 0.9837197580645162\n",
      "\n",
      "Epoch 17. Loss: 0.05359723552673032, Train_acc 0.9836738782051282\n",
      "\n",
      "Epoch 17. Loss: 0.05554264904209051, Train_acc 0.9835788216560509\n",
      "\n",
      "Epoch 17. Loss: 0.053650816123021305, Train_acc 0.983534414556962\n",
      "\n",
      "Epoch 17. Loss: 0.05242811129122913, Train_acc 0.9835397012578616\n",
      "\n",
      "Epoch 17. Loss: 0.056306083371906936, Train_acc 0.9833984375\n",
      "\n",
      "Epoch 17. Loss: 0.0544177995955969, Train_acc 0.9834530279503105\n",
      "\n",
      "Epoch 17. Loss: 0.050643703207614285, Train_acc 0.9835069444444444\n",
      "\n",
      "Epoch 17. Loss: 0.05265912490955793, Train_acc 0.9835122699386503\n",
      "\n",
      "Epoch 17. Loss: 0.058655098031805186, Train_acc 0.983374618902439\n",
      "\n",
      "Epoch 17. Loss: 0.05545608210639318, Train_acc 0.9834280303030303\n",
      "\n",
      "Epoch 17. Loss: 0.05878206126161957, Train_acc 0.983386671686747\n",
      "\n",
      "Epoch 17. Loss: 0.06906182943822632, Train_acc 0.9831586826347305\n",
      "\n",
      "Epoch 17. Loss: 0.07341639738418183, Train_acc 0.9829334077380952\n",
      "\n",
      "Epoch 17. Loss: 0.07442499584976603, Train_acc 0.9828032544378699\n",
      "\n",
      "Epoch 17. Loss: 0.07281198028049263, Train_acc 0.9827665441176471\n",
      "\n",
      "Epoch 17. Loss: 0.0719017558394795, Train_acc 0.9826845760233918\n",
      "\n",
      "Epoch 17. Loss: 0.07090846990933346, Train_acc 0.9826489825581395\n",
      "\n",
      "Epoch 17. Loss: 0.06593236442259247, Train_acc 0.9827041184971098\n",
      "\n",
      "Epoch 17. Loss: 0.06448524325357045, Train_acc 0.9826688218390804\n",
      "\n",
      "Epoch 17. Loss: 0.06372315514921695, Train_acc 0.9826339285714286\n",
      "\n",
      "Epoch 17. Loss: 0.06483920138036803, Train_acc 0.9825994318181818\n",
      "\n",
      "Epoch 17. Loss: 0.0657314432050788, Train_acc 0.982521186440678\n",
      "\n",
      "Epoch 17. Loss: 0.0641866443204287, Train_acc 0.9824877106741573\n",
      "\n",
      "Epoch 17. Loss: 0.07097410717434316, Train_acc 0.9822363826815642\n",
      "\n",
      "Epoch 17. Loss: 0.0700220761492249, Train_acc 0.9822482638888889\n",
      "\n",
      "Epoch 17. Loss: 0.06596199477860898, Train_acc 0.9822600138121547\n",
      "\n",
      "Epoch 17. Loss: 0.06882884626224253, Train_acc 0.9820999313186813\n",
      "\n",
      "Epoch 17. Loss: 0.06913028679461432, Train_acc 0.982026980874317\n",
      "\n",
      "Epoch 17. Loss: 0.0688383707896276, Train_acc 0.9819548233695652\n",
      "\n",
      "Epoch 17. Loss: 0.06753839369077119, Train_acc 0.9819679054054054\n",
      "\n",
      "Epoch 17. Loss: 0.07547237410061329, Train_acc 0.9816028225806451\n",
      "\n",
      "Epoch 17. Loss: 0.07123558089655134, Train_acc 0.9816594251336899\n",
      "\n",
      "Epoch 17. Loss: 0.07082528798748397, Train_acc 0.9816323138297872\n",
      "\n",
      "Epoch 17. Loss: 0.07399286415251503, Train_acc 0.9815641534391535\n",
      "\n",
      "Epoch 17. Loss: 0.06907853207205901, Train_acc 0.9816611842105263\n",
      "\n",
      "Epoch 17. Loss: 0.06591793943537924, Train_acc 0.981675392670157\n",
      "\n",
      "Epoch 17. Loss: 0.06636451154136944, Train_acc 0.9816487630208334\n",
      "\n",
      "Epoch 17. Loss: 0.0670545709358241, Train_acc 0.9816628886010362\n",
      "\n",
      "Epoch 17. Loss: 0.07343136479496234, Train_acc 0.9815963273195877\n",
      "\n",
      "Epoch 17. Loss: 0.07550563851033992, Train_acc 0.9814503205128206\n",
      "\n",
      "Epoch 17. Loss: 0.07874074821801794, Train_acc 0.98132\n",
      "\n",
      "Epoch 18. Loss: 0.07287667575596403, Train_acc 1.0\n",
      "\n",
      "Epoch 18. Loss: 0.06996791183756558, Train_acc 0.9921875\n",
      "\n",
      "Epoch 18. Loss: 0.07193540441817137, Train_acc 0.984375\n",
      "\n",
      "Epoch 18. Loss: 0.07470938704454386, Train_acc 0.98046875\n",
      "\n",
      "Epoch 18. Loss: 0.07121559955516592, Train_acc 0.98125\n",
      "\n",
      "Epoch 18. Loss: 0.07144301141356649, Train_acc 0.9791666666666666\n",
      "\n",
      "Epoch 18. Loss: 0.06925837178577682, Train_acc 0.9799107142857143\n",
      "\n",
      "Epoch 18. Loss: 0.06534321215346188, Train_acc 0.98046875\n",
      "\n",
      "Epoch 18. Loss: 0.06860127991373596, Train_acc 0.9782986111111112\n",
      "\n",
      "Epoch 18. Loss: 0.0724193888539248, Train_acc 0.97734375\n",
      "\n",
      "Epoch 18. Loss: 0.06910440438695312, Train_acc 0.9786931818181818\n",
      "\n",
      "Epoch 18. Loss: 0.06671038855946862, Train_acc 0.9798177083333334\n",
      "\n",
      "Epoch 18. Loss: 0.06533727353665356, Train_acc 0.9795673076923077\n",
      "\n",
      "Epoch 18. Loss: 0.06300742117333225, Train_acc 0.9799107142857143\n",
      "\n",
      "Epoch 18. Loss: 0.06254532654077838, Train_acc 0.9796875\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18. Loss: 0.06967631625227061, Train_acc 0.9794921875\n",
      "\n",
      "Epoch 18. Loss: 0.07181100827835733, Train_acc 0.9784007352941176\n",
      "\n",
      "Epoch 18. Loss: 0.07487091376527609, Train_acc 0.9774305555555556\n",
      "\n",
      "Epoch 18. Loss: 0.06995807304958518, Train_acc 0.9782072368421053\n",
      "\n",
      "Epoch 18. Loss: 0.06786270259302869, Train_acc 0.977734375\n",
      "\n",
      "Epoch 18. Loss: 0.0698588019771756, Train_acc 0.9769345238095238\n",
      "\n",
      "Epoch 18. Loss: 0.07119064713985156, Train_acc 0.9769176136363636\n",
      "\n",
      "Epoch 18. Loss: 0.06785010190728692, Train_acc 0.9775815217391305\n",
      "\n",
      "Epoch 18. Loss: 0.06540004141858269, Train_acc 0.9778645833333334\n",
      "\n",
      "Epoch 18. Loss: 0.06552950645444736, Train_acc 0.978125\n",
      "\n",
      "Epoch 18. Loss: 0.06711384151838373, Train_acc 0.9780649038461539\n",
      "\n",
      "Epoch 18. Loss: 0.0647915832203223, Train_acc 0.9782986111111112\n",
      "\n",
      "Epoch 18. Loss: 0.0664549468757147, Train_acc 0.9776785714285714\n",
      "\n",
      "Epoch 18. Loss: 0.06905581940425345, Train_acc 0.9773706896551724\n",
      "\n",
      "Epoch 18. Loss: 0.06707935681235411, Train_acc 0.9776041666666667\n",
      "\n",
      "Epoch 18. Loss: 0.06610942319296258, Train_acc 0.977570564516129\n",
      "\n",
      "Epoch 18. Loss: 0.0622664948725324, Train_acc 0.97802734375\n",
      "\n",
      "Epoch 18. Loss: 0.05994522441240738, Train_acc 0.978219696969697\n",
      "\n",
      "Epoch 18. Loss: 0.05848692463766864, Train_acc 0.9779411764705882\n",
      "\n",
      "Epoch 18. Loss: 0.05700923002002834, Train_acc 0.9783482142857143\n",
      "\n",
      "Epoch 18. Loss: 0.05735146288190662, Train_acc 0.978515625\n",
      "\n",
      "Epoch 18. Loss: 0.055912766538092906, Train_acc 0.9786739864864865\n",
      "\n",
      "Epoch 18. Loss: 0.061406277431871964, Train_acc 0.9782072368421053\n",
      "\n",
      "Epoch 18. Loss: 0.06047730064138157, Train_acc 0.9781650641025641\n",
      "\n",
      "Epoch 18. Loss: 0.0636920384980236, Train_acc 0.9775390625\n",
      "\n",
      "Epoch 18. Loss: 0.06086106880757164, Train_acc 0.9777057926829268\n",
      "\n",
      "Epoch 18. Loss: 0.06031861298608438, Train_acc 0.9776785714285714\n",
      "\n",
      "Epoch 18. Loss: 0.06749025338883093, Train_acc 0.9769258720930233\n",
      "\n",
      "Epoch 18. Loss: 0.06576707642371854, Train_acc 0.9767400568181818\n",
      "\n",
      "Epoch 18. Loss: 0.06480419946696223, Train_acc 0.9765625\n",
      "\n",
      "Epoch 18. Loss: 0.0638881398408341, Train_acc 0.9767323369565217\n",
      "\n",
      "Epoch 18. Loss: 0.07328318117577381, Train_acc 0.9763962765957447\n",
      "\n",
      "Epoch 18. Loss: 0.07237106613980425, Train_acc 0.97607421875\n",
      "\n",
      "Epoch 18. Loss: 0.07396709817051911, Train_acc 0.9759247448979592\n",
      "\n",
      "Epoch 18. Loss: 0.07219078337311766, Train_acc 0.97578125\n",
      "\n",
      "Epoch 18. Loss: 0.06720528330051918, Train_acc 0.9761029411764706\n",
      "\n",
      "Epoch 18. Loss: 0.06299249169061201, Train_acc 0.9762620192307693\n",
      "\n",
      "Epoch 18. Loss: 0.06032077747729078, Train_acc 0.9764150943396226\n",
      "\n",
      "Epoch 18. Loss: 0.06066945667397966, Train_acc 0.9765625\n",
      "\n",
      "Epoch 18. Loss: 0.05863085218070736, Train_acc 0.9768465909090909\n",
      "\n",
      "Epoch 18. Loss: 0.06031734416900984, Train_acc 0.9767020089285714\n",
      "\n",
      "Epoch 18. Loss: 0.057176746271719744, Train_acc 0.9768366228070176\n",
      "\n",
      "Epoch 18. Loss: 0.054547760122421574, Train_acc 0.9771012931034483\n",
      "\n",
      "Epoch 18. Loss: 0.05828296533233213, Train_acc 0.9769597457627118\n",
      "\n",
      "Epoch 18. Loss: 0.055403506526407194, Train_acc 0.9770833333333333\n",
      "\n",
      "Epoch 18. Loss: 0.05243628950630718, Train_acc 0.977202868852459\n",
      "\n",
      "Epoch 18. Loss: 0.05222993104203129, Train_acc 0.9771925403225806\n",
      "\n",
      "Epoch 18. Loss: 0.04933463230917082, Train_acc 0.9774305555555556\n",
      "\n",
      "Epoch 18. Loss: 0.053698446856640804, Train_acc 0.977294921875\n",
      "\n",
      "Epoch 18. Loss: 0.05216274619701775, Train_acc 0.9774038461538461\n",
      "\n",
      "Epoch 18. Loss: 0.05233026148918216, Train_acc 0.9772727272727273\n",
      "\n",
      "Epoch 18. Loss: 0.05489358546176206, Train_acc 0.9770289179104478\n",
      "\n",
      "Epoch 18. Loss: 0.05619044296597228, Train_acc 0.9769071691176471\n",
      "\n",
      "Epoch 18. Loss: 0.05310118556906091, Train_acc 0.9772418478260869\n",
      "\n",
      "Epoch 18. Loss: 0.050867206290864705, Train_acc 0.9774553571428571\n",
      "\n",
      "Epoch 18. Loss: 0.051392480896863726, Train_acc 0.9774427816901409\n",
      "\n",
      "Epoch 18. Loss: 0.056803266108292394, Train_acc 0.9771050347222222\n",
      "\n",
      "Epoch 18. Loss: 0.05491769453906243, Train_acc 0.9772046232876712\n",
      "\n",
      "Epoch 18. Loss: 0.05637363917550348, Train_acc 0.9770903716216216\n",
      "\n",
      "Epoch 18. Loss: 0.05358552368212554, Train_acc 0.9772916666666667\n",
      "\n",
      "Epoch 18. Loss: 0.05910418568607104, Train_acc 0.9770764802631579\n",
      "\n",
      "Epoch 18. Loss: 0.058417080091440074, Train_acc 0.9771712662337663\n",
      "\n",
      "Epoch 18. Loss: 0.05836594693094795, Train_acc 0.9770633012820513\n",
      "\n",
      "Epoch 18. Loss: 0.05773693256584082, Train_acc 0.9770569620253164\n",
      "\n",
      "Epoch 18. Loss: 0.062148109969561764, Train_acc 0.976953125\n",
      "\n",
      "Epoch 18. Loss: 0.06193601643776786, Train_acc 0.9769483024691358\n",
      "\n",
      "Epoch 18. Loss: 0.06531448414089583, Train_acc 0.9768483231707317\n",
      "\n",
      "Epoch 18. Loss: 0.07503585741068991, Train_acc 0.9764683734939759\n",
      "\n",
      "Epoch 18. Loss: 0.07158182986211245, Train_acc 0.9764694940476191\n",
      "\n",
      "Epoch 18. Loss: 0.06888543935982704, Train_acc 0.9766544117647059\n",
      "\n",
      "Epoch 18. Loss: 0.07032648955912875, Train_acc 0.9763808139534884\n",
      "\n",
      "Epoch 18. Loss: 0.07317095385609407, Train_acc 0.9762033045977011\n",
      "\n",
      "Epoch 18. Loss: 0.07039849880294508, Train_acc 0.9762073863636364\n",
      "\n",
      "Epoch 18. Loss: 0.06675186013838505, Train_acc 0.9762991573033708\n",
      "\n",
      "Epoch 18. Loss: 0.07159918179208805, Train_acc 0.9760416666666667\n",
      "\n",
      "Epoch 18. Loss: 0.07113231685842368, Train_acc 0.9760473901098901\n",
      "\n",
      "Epoch 18. Loss: 0.0757475306131121, Train_acc 0.9758831521739131\n",
      "\n",
      "Epoch 18. Loss: 0.07412628095188824, Train_acc 0.9759744623655914\n",
      "\n",
      "Epoch 18. Loss: 0.07308791811024327, Train_acc 0.976063829787234\n",
      "\n",
      "Epoch 18. Loss: 0.07953836978753072, Train_acc 0.9755756578947369\n",
      "\n",
      "Epoch 18. Loss: 0.07500578502964671, Train_acc 0.9756673177083334\n",
      "\n",
      "Epoch 18. Loss: 0.07182460574941363, Train_acc 0.9757570876288659\n",
      "\n",
      "Epoch 18. Loss: 0.07246583445641273, Train_acc 0.9756855867346939\n",
      "\n",
      "Epoch 18. Loss: 0.06999897466992921, Train_acc 0.9757733585858586\n",
      "\n",
      "Epoch 18. Loss: 0.06711383058335411, Train_acc 0.975859375\n",
      "\n",
      "[Epoch 18 Batch 100] Loss: 0.06598805205857183 Training: accuracy=0.975866\n",
      "Epoch 18. Loss: 0.06598805205857183, Train_acc 0.9758663366336634\n",
      "\n",
      "Epoch 18. Loss: 0.06647862181218349, Train_acc 0.9758731617647058\n",
      "\n",
      "Epoch 18. Loss: 0.0634068963839282, Train_acc 0.9760315533980582\n",
      "\n",
      "Epoch 18. Loss: 0.06802760224762583, Train_acc 0.9757361778846154\n",
      "\n",
      "Epoch 18. Loss: 0.06305559570690714, Train_acc 0.9758928571428571\n",
      "\n",
      "Epoch 18. Loss: 0.07139302577168395, Train_acc 0.9757517688679245\n",
      "\n",
      "Epoch 18. Loss: 0.06911016548207984, Train_acc 0.9757593457943925\n",
      "\n",
      "Epoch 18. Loss: 0.06601894239662515, Train_acc 0.9759114583333334\n",
      "\n",
      "Epoch 18. Loss: 0.06868815204571271, Train_acc 0.9759174311926605\n",
      "\n",
      "Epoch 18. Loss: 0.07172226337555573, Train_acc 0.9757102272727273\n",
      "\n",
      "Epoch 18. Loss: 0.07240681136813933, Train_acc 0.9757179054054054\n",
      "\n",
      "Epoch 18. Loss: 0.07210710899681307, Train_acc 0.9756556919642857\n",
      "\n",
      "Epoch 18. Loss: 0.06963467790171912, Train_acc 0.9756637168141593\n",
      "\n",
      "Epoch 18. Loss: 0.06830436983840535, Train_acc 0.9758086622807017\n",
      "\n",
      "Epoch 18. Loss: 0.06928007303896729, Train_acc 0.9756114130434783\n",
      "\n",
      "Epoch 18. Loss: 0.0709945395519422, Train_acc 0.9755522629310345\n",
      "\n",
      "Epoch 18. Loss: 0.06634914237380801, Train_acc 0.975761217948718\n",
      "\n",
      "Epoch 18. Loss: 0.06479538254249792, Train_acc 0.9757680084745762\n",
      "\n",
      "Epoch 18. Loss: 0.06544024964250952, Train_acc 0.9757090336134454\n",
      "\n",
      "Epoch 18. Loss: 0.06325156848202196, Train_acc 0.9758463541666667\n",
      "\n",
      "Epoch 18. Loss: 0.062309839074939914, Train_acc 0.9758522727272727\n",
      "\n",
      "Epoch 18. Loss: 0.0610601062284086, Train_acc 0.975922131147541\n",
      "\n",
      "Epoch 18. Loss: 0.061879712763980674, Train_acc 0.9759908536585366\n",
      "\n",
      "Epoch 18. Loss: 0.05670596108456461, Train_acc 0.9761844758064516\n",
      "\n",
      "Epoch 18. Loss: 0.05716583009618528, Train_acc 0.976125\n",
      "\n",
      "Epoch 18. Loss: 0.05475900993697054, Train_acc 0.9761904761904762\n",
      "\n",
      "Epoch 18. Loss: 0.05968146257953829, Train_acc 0.9761318897637795\n",
      "\n",
      "Epoch 18. Loss: 0.05669442847392249, Train_acc 0.9761962890625\n",
      "\n",
      "Epoch 18. Loss: 0.054214448794912884, Train_acc 0.9763202519379846\n",
      "\n",
      "Epoch 18. Loss: 0.05085752515362941, Train_acc 0.9765024038461538\n",
      "\n",
      "Epoch 18. Loss: 0.05301752336353579, Train_acc 0.9765028625954199\n",
      "\n",
      "Epoch 18. Loss: 0.04971189351407158, Train_acc 0.9766216856060606\n",
      "\n",
      "Epoch 18. Loss: 0.045275187021739494, Train_acc 0.9767974624060151\n",
      "\n",
      "Epoch 18. Loss: 0.041886521135640634, Train_acc 0.9769706156716418\n",
      "\n",
      "Epoch 18. Loss: 0.04058470506656691, Train_acc 0.9771412037037037\n",
      "\n",
      "Epoch 18. Loss: 0.03751157179494373, Train_acc 0.9773092830882353\n",
      "\n",
      "Epoch 18. Loss: 0.03576851707714503, Train_acc 0.9774178832116789\n",
      "\n",
      "Epoch 18. Loss: 0.03481472906784152, Train_acc 0.9775249094202898\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18. Loss: 0.03948177883609475, Train_acc 0.9774055755395683\n",
      "\n",
      "Epoch 18. Loss: 0.038272574264565186, Train_acc 0.9775111607142857\n",
      "\n",
      "Epoch 18. Loss: 0.036860950598501335, Train_acc 0.9776152482269503\n",
      "\n",
      "Epoch 18. Loss: 0.03863367465977356, Train_acc 0.977662852112676\n",
      "\n",
      "Epoch 18. Loss: 0.04301171029667097, Train_acc 0.9776005244755245\n",
      "\n",
      "Epoch 18. Loss: 0.04145792074555192, Train_acc 0.9777018229166666\n",
      "\n",
      "Epoch 18. Loss: 0.041917495705670424, Train_acc 0.9776939655172414\n",
      "\n",
      "Epoch 18. Loss: 0.039779810483443416, Train_acc 0.9777932363013698\n",
      "\n",
      "Epoch 18. Loss: 0.039895015992392015, Train_acc 0.9777848639455783\n",
      "\n",
      "Epoch 18. Loss: 0.04229309979468785, Train_acc 0.9777766047297297\n",
      "\n",
      "Epoch 18. Loss: 0.045771801382811686, Train_acc 0.9777160234899329\n",
      "\n",
      "Epoch 18. Loss: 0.047035007694821204, Train_acc 0.97765625\n",
      "\n",
      "Epoch 18. Loss: 0.048096268119925845, Train_acc 0.9776490066225165\n",
      "\n",
      "Epoch 18. Loss: 0.049047562100751334, Train_acc 0.9776932565789473\n",
      "\n",
      "Epoch 18. Loss: 0.048533748941060724, Train_acc 0.977685866013072\n",
      "\n",
      "Epoch 18. Loss: 0.051555615386161345, Train_acc 0.9775771103896104\n",
      "\n",
      "Epoch 18. Loss: 0.049152889709883754, Train_acc 0.9776713709677419\n",
      "\n",
      "Epoch 18. Loss: 0.05371587696183964, Train_acc 0.9775641025641025\n",
      "\n",
      "Epoch 18. Loss: 0.057473478220485846, Train_acc 0.9775079617834395\n",
      "\n",
      "Epoch 18. Loss: 0.05796488672725845, Train_acc 0.9775019778481012\n",
      "\n",
      "Epoch 18. Loss: 0.058448066266469555, Train_acc 0.9775452044025157\n",
      "\n",
      "Epoch 18. Loss: 0.05488136592694437, Train_acc 0.97763671875\n",
      "\n",
      "Epoch 18. Loss: 0.06027693465222403, Train_acc 0.97753299689441\n",
      "\n",
      "Epoch 18. Loss: 0.05986567212524549, Train_acc 0.9775270061728395\n",
      "\n",
      "Epoch 18. Loss: 0.05621353051110389, Train_acc 0.9776169478527608\n",
      "\n",
      "Epoch 18. Loss: 0.053677307913103246, Train_acc 0.977610518292683\n",
      "\n",
      "Epoch 18. Loss: 0.051801291718541274, Train_acc 0.9776515151515152\n",
      "\n",
      "Epoch 18. Loss: 0.05218729722302439, Train_acc 0.9775978915662651\n",
      "\n",
      "Epoch 18. Loss: 0.05214043496073439, Train_acc 0.9776384730538922\n",
      "\n",
      "Epoch 18. Loss: 0.05307690721471149, Train_acc 0.9775855654761905\n",
      "\n",
      "Epoch 18. Loss: 0.049219285183123095, Train_acc 0.9777181952662722\n",
      "\n",
      "Epoch 18. Loss: 0.050189043342743524, Train_acc 0.9777113970588235\n",
      "\n",
      "Epoch 18. Loss: 0.05184801989168603, Train_acc 0.9777046783625731\n",
      "\n",
      "Epoch 18. Loss: 0.04952246724102508, Train_acc 0.9777888808139535\n",
      "\n",
      "Epoch 18. Loss: 0.047749232010843856, Train_acc 0.9778269508670521\n",
      "\n",
      "Epoch 18. Loss: 0.04644729413700328, Train_acc 0.9779094827586207\n",
      "\n",
      "Epoch 18. Loss: 0.045860895229389305, Train_acc 0.9779910714285714\n",
      "\n",
      "Epoch 18. Loss: 0.05459612194866839, Train_acc 0.9777610085227273\n",
      "\n",
      "Epoch 18. Loss: 0.052143388062753405, Train_acc 0.9778425141242938\n",
      "\n",
      "Epoch 18. Loss: 0.05816717124286723, Train_acc 0.9777036516853933\n",
      "\n",
      "Epoch 18. Loss: 0.06429889061722248, Train_acc 0.9775226955307262\n",
      "\n",
      "Epoch 18. Loss: 0.06069256186789056, Train_acc 0.9775607638888889\n",
      "\n",
      "Epoch 18. Loss: 0.061060138675324144, Train_acc 0.9774689226519337\n",
      "\n",
      "Epoch 18. Loss: 0.057500414743499775, Train_acc 0.9775927197802198\n",
      "\n",
      "Epoch 18. Loss: 0.06008066179854586, Train_acc 0.9774590163934426\n",
      "\n",
      "Epoch 18. Loss: 0.06076441355797274, Train_acc 0.9774116847826086\n",
      "\n",
      "Epoch 18. Loss: 0.05679701550232729, Train_acc 0.9775337837837837\n",
      "\n",
      "Epoch 18. Loss: 0.056018015296107775, Train_acc 0.977570564516129\n",
      "\n",
      "Epoch 18. Loss: 0.054556027174752574, Train_acc 0.9776069518716578\n",
      "\n",
      "Epoch 18. Loss: 0.05544297780462648, Train_acc 0.9776429521276596\n",
      "\n",
      "Epoch 18. Loss: 0.058876835279481524, Train_acc 0.9775545634920635\n",
      "\n",
      "Epoch 18. Loss: 0.055733860893085824, Train_acc 0.9776315789473684\n",
      "\n",
      "Epoch 18. Loss: 0.055643805217476396, Train_acc 0.9776259816753927\n",
      "\n",
      "Epoch 18. Loss: 0.05391716511702392, Train_acc 0.9776611328125\n",
      "\n",
      "Epoch 18. Loss: 0.053892986565731646, Train_acc 0.9776149611398963\n",
      "\n",
      "Epoch 18. Loss: 0.05097700629970671, Train_acc 0.9776900773195877\n",
      "\n",
      "Epoch 18. Loss: 0.0481265035957805, Train_acc 0.9777644230769231\n",
      "\n",
      "Epoch 18. Loss: 0.0464971842042248, Train_acc 0.9778\n",
      "\n",
      "Epoch 19. Loss: 0.043601760864702514, Train_acc 0.9921875\n",
      "\n",
      "Epoch 19. Loss: 0.040666040141535686, Train_acc 0.99609375\n",
      "\n",
      "Epoch 19. Loss: 0.0389711272947367, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 19. Loss: 0.039003321504507305, Train_acc 0.990234375\n",
      "\n",
      "Epoch 19. Loss: 0.04228693229786799, Train_acc 0.984375\n",
      "\n",
      "Epoch 19. Loss: 0.039631029064943604, Train_acc 0.9869791666666666\n",
      "\n",
      "Epoch 19. Loss: 0.0388838567693444, Train_acc 0.9866071428571429\n",
      "\n",
      "Epoch 19. Loss: 0.03997213855618941, Train_acc 0.984375\n",
      "\n",
      "Epoch 19. Loss: 0.04626067100675142, Train_acc 0.9826388888888888\n",
      "\n",
      "Epoch 19. Loss: 0.04488009991089615, Train_acc 0.9828125\n",
      "\n",
      "Epoch 19. Loss: 0.04583890541052919, Train_acc 0.9822443181818182\n",
      "\n",
      "Epoch 19. Loss: 0.044616991761232336, Train_acc 0.982421875\n",
      "\n",
      "Epoch 19. Loss: 0.04081056099719249, Train_acc 0.9837740384615384\n",
      "\n",
      "Epoch 19. Loss: 0.040223648383496194, Train_acc 0.9827008928571429\n",
      "\n",
      "Epoch 19. Loss: 0.040795185626397716, Train_acc 0.9822916666666667\n",
      "\n",
      "Epoch 19. Loss: 0.04063607614712434, Train_acc 0.98193359375\n",
      "\n",
      "Epoch 19. Loss: 0.03972224469312892, Train_acc 0.9820772058823529\n",
      "\n",
      "Epoch 19. Loss: 0.036615473612357965, Train_acc 0.9830729166666666\n",
      "\n",
      "Epoch 19. Loss: 0.040228594169804274, Train_acc 0.9827302631578947\n",
      "\n",
      "Epoch 19. Loss: 0.03832390482794239, Train_acc 0.98359375\n",
      "\n",
      "Epoch 19. Loss: 0.0373593860543161, Train_acc 0.9840029761904762\n",
      "\n",
      "Epoch 19. Loss: 0.03666860181180144, Train_acc 0.9840198863636364\n",
      "\n",
      "Epoch 19. Loss: 0.03477720399726187, Train_acc 0.9847146739130435\n",
      "\n",
      "Epoch 19. Loss: 0.037939996838826734, Train_acc 0.9850260416666666\n",
      "\n",
      "Epoch 19. Loss: 0.04086188121461165, Train_acc 0.9846875\n",
      "\n",
      "Epoch 19. Loss: 0.039367575739234315, Train_acc 0.9849759615384616\n",
      "\n",
      "Epoch 19. Loss: 0.03609774347639945, Train_acc 0.9855324074074074\n",
      "\n",
      "Epoch 19. Loss: 0.03391840740141452, Train_acc 0.9860491071428571\n",
      "\n",
      "Epoch 19. Loss: 0.03320171513346297, Train_acc 0.9859913793103449\n",
      "\n",
      "Epoch 19. Loss: 0.03201454742867466, Train_acc 0.9861979166666667\n",
      "\n",
      "Epoch 19. Loss: 0.033227080381978004, Train_acc 0.9861391129032258\n",
      "\n",
      "Epoch 19. Loss: 0.03414629335141341, Train_acc 0.986083984375\n",
      "\n",
      "Epoch 19. Loss: 0.031827938999409916, Train_acc 0.9865056818181818\n",
      "\n",
      "Epoch 19. Loss: 0.03158438014597485, Train_acc 0.9866727941176471\n",
      "\n",
      "Epoch 19. Loss: 0.031327612095571666, Train_acc 0.9868303571428572\n",
      "\n",
      "Epoch 19. Loss: 0.03439157588198523, Train_acc 0.9865451388888888\n",
      "\n",
      "Epoch 19. Loss: 0.0358550415150649, Train_acc 0.9864864864864865\n",
      "\n",
      "Epoch 19. Loss: 0.04238072252681791, Train_acc 0.9860197368421053\n",
      "\n",
      "Epoch 19. Loss: 0.04250064760217911, Train_acc 0.9857772435897436\n",
      "\n",
      "Epoch 19. Loss: 0.0397020300755189, Train_acc 0.9861328125\n",
      "\n",
      "Epoch 19. Loss: 0.03691770860069569, Train_acc 0.9862804878048781\n",
      "\n",
      "Epoch 19. Loss: 0.03658240828079202, Train_acc 0.9862351190476191\n",
      "\n",
      "Epoch 19. Loss: 0.036729886396189494, Train_acc 0.9861918604651163\n",
      "\n",
      "Epoch 19. Loss: 0.03496226528000232, Train_acc 0.986328125\n",
      "\n",
      "Epoch 19. Loss: 0.0350346284393495, Train_acc 0.9862847222222222\n",
      "\n",
      "Epoch 19. Loss: 0.03385212277925244, Train_acc 0.9864130434782609\n",
      "\n",
      "Epoch 19. Loss: 0.032839210939910095, Train_acc 0.9865359042553191\n",
      "\n",
      "Epoch 19. Loss: 0.03314869965240903, Train_acc 0.9866536458333334\n",
      "\n",
      "Epoch 19. Loss: 0.0350933472674389, Train_acc 0.9866071428571429\n",
      "\n",
      "Epoch 19. Loss: 0.03500821332883531, Train_acc 0.98671875\n",
      "\n",
      "Epoch 19. Loss: 0.03420275799112047, Train_acc 0.9868259803921569\n",
      "\n",
      "Epoch 19. Loss: 0.03298189302542679, Train_acc 0.9869290865384616\n",
      "\n",
      "Epoch 19. Loss: 0.03411722609632199, Train_acc 0.9868808962264151\n",
      "\n",
      "Epoch 19. Loss: 0.03142840119138049, Train_acc 0.9871238425925926\n",
      "\n",
      "Epoch 19. Loss: 0.03052701162041444, Train_acc 0.9873579545454545\n",
      "\n",
      "Epoch 19. Loss: 0.030008552432726786, Train_acc 0.9874441964285714\n",
      "\n",
      "Epoch 19. Loss: 0.030864744300250085, Train_acc 0.9875274122807017\n",
      "\n",
      "Epoch 19. Loss: 0.029419357290509825, Train_acc 0.9876077586206896\n",
      "\n",
      "Epoch 19. Loss: 0.028133588956871763, Train_acc 0.9878177966101694\n",
      "\n",
      "Epoch 19. Loss: 0.026646166583519402, Train_acc 0.987890625\n",
      "\n",
      "Epoch 19. Loss: 0.026026454157192607, Train_acc 0.9879610655737705\n",
      "\n",
      "Epoch 19. Loss: 0.028387513685130268, Train_acc 0.9879032258064516\n",
      "\n",
      "Epoch 19. Loss: 0.027136014449211827, Train_acc 0.9879712301587301\n",
      "\n",
      "Epoch 19. Loss: 0.030675973636757916, Train_acc 0.98779296875\n",
      "\n",
      "Epoch 19. Loss: 0.028424095918552505, Train_acc 0.9879807692307693\n",
      "\n",
      "Epoch 19. Loss: 0.027320084290042308, Train_acc 0.9880445075757576\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19. Loss: 0.02605425829410683, Train_acc 0.988106343283582\n",
      "\n",
      "Epoch 19. Loss: 0.02481084553647158, Train_acc 0.9881663602941176\n",
      "\n",
      "Epoch 19. Loss: 0.02525885560287342, Train_acc 0.9881114130434783\n",
      "\n",
      "Epoch 19. Loss: 0.028195603115916006, Train_acc 0.9879464285714286\n",
      "\n",
      "Epoch 19. Loss: 0.02823219009360053, Train_acc 0.988006161971831\n",
      "\n",
      "Epoch 19. Loss: 0.029182334391358894, Train_acc 0.9878472222222222\n",
      "\n",
      "Epoch 19. Loss: 0.026574724411740958, Train_acc 0.988013698630137\n",
      "\n",
      "Epoch 19. Loss: 0.02614324498543894, Train_acc 0.9880701013513513\n",
      "\n",
      "Epoch 19. Loss: 0.02784176804157873, Train_acc 0.988125\n",
      "\n",
      "Epoch 19. Loss: 0.02552660752117139, Train_acc 0.98828125\n",
      "\n",
      "Epoch 19. Loss: 0.027935617704208215, Train_acc 0.9881290584415584\n",
      "\n",
      "Epoch 19. Loss: 0.02648791428418355, Train_acc 0.98828125\n",
      "\n",
      "Epoch 19. Loss: 0.027588159272176595, Train_acc 0.9881329113924051\n",
      "\n",
      "Epoch 19. Loss: 0.028598947461637176, Train_acc 0.98798828125\n",
      "\n",
      "Epoch 19. Loss: 0.02947576698916464, Train_acc 0.9879436728395061\n",
      "\n",
      "Epoch 19. Loss: 0.028932019909536623, Train_acc 0.9880907012195121\n",
      "\n",
      "Epoch 19. Loss: 0.0320858559074841, Train_acc 0.9880459337349398\n",
      "\n",
      "Epoch 19. Loss: 0.03358275043036121, Train_acc 0.9880022321428571\n",
      "\n",
      "Epoch 19. Loss: 0.03346300360917072, Train_acc 0.9879595588235294\n",
      "\n",
      "Epoch 19. Loss: 0.036442137396565266, Train_acc 0.9880087209302325\n",
      "\n",
      "Epoch 19. Loss: 0.0382848851110618, Train_acc 0.9879669540229885\n",
      "\n",
      "Epoch 19. Loss: 0.037312997257061074, Train_acc 0.9879261363636364\n",
      "\n",
      "Epoch 19. Loss: 0.036886301227224416, Train_acc 0.9879740168539326\n",
      "\n",
      "Epoch 19. Loss: 0.03684259348018099, Train_acc 0.9880208333333333\n",
      "\n",
      "Epoch 19. Loss: 0.04174750649544415, Train_acc 0.9878949175824175\n",
      "\n",
      "Epoch 19. Loss: 0.04333641733479038, Train_acc 0.9877717391304348\n",
      "\n",
      "Epoch 19. Loss: 0.040236455961330554, Train_acc 0.9879032258064516\n",
      "\n",
      "Epoch 19. Loss: 0.04096060605132326, Train_acc 0.9876994680851063\n",
      "\n",
      "Epoch 19. Loss: 0.03893740891322862, Train_acc 0.9877467105263158\n",
      "\n",
      "Epoch 19. Loss: 0.050291954745996334, Train_acc 0.9872233072916666\n",
      "\n",
      "Epoch 19. Loss: 0.048070163372291634, Train_acc 0.987193943298969\n",
      "\n",
      "Epoch 19. Loss: 0.05015467853230254, Train_acc 0.9870057397959183\n",
      "\n",
      "Epoch 19. Loss: 0.05450540111257448, Train_acc 0.98666351010101\n",
      "\n",
      "Epoch 19. Loss: 0.055787532709185614, Train_acc 0.986640625\n",
      "\n",
      "[Epoch 19 Batch 100] Loss: 0.05393151567770035 Training: accuracy=0.986618\n",
      "Epoch 19. Loss: 0.05393151567770035, Train_acc 0.986618193069307\n",
      "\n",
      "Epoch 19. Loss: 0.051784607035455024, Train_acc 0.9866727941176471\n",
      "\n",
      "Epoch 19. Loss: 0.05450822615254246, Train_acc 0.9866504854368932\n",
      "\n",
      "Epoch 19. Loss: 0.05346609051789334, Train_acc 0.9867037259615384\n",
      "\n",
      "Epoch 19. Loss: 0.05064472239403865, Train_acc 0.9867559523809524\n",
      "\n",
      "Epoch 19. Loss: 0.0490213924454654, Train_acc 0.9867334905660378\n",
      "\n",
      "Epoch 19. Loss: 0.049981188965470026, Train_acc 0.9867114485981309\n",
      "\n",
      "Epoch 19. Loss: 0.048574921959010156, Train_acc 0.9866174768518519\n",
      "\n",
      "Epoch 19. Loss: 0.04483227140683001, Train_acc 0.986740252293578\n",
      "\n",
      "Epoch 19. Loss: 0.045144808652800905, Train_acc 0.9865767045454545\n",
      "\n",
      "Epoch 19. Loss: 0.04639772127223246, Train_acc 0.9865568693693694\n",
      "\n",
      "Epoch 19. Loss: 0.04454105466740339, Train_acc 0.9865373883928571\n",
      "\n",
      "Epoch 19. Loss: 0.047761784077915634, Train_acc 0.9864491150442478\n",
      "\n",
      "Epoch 19. Loss: 0.04537494130244829, Train_acc 0.9865679824561403\n",
      "\n",
      "Epoch 19. Loss: 0.04464495164732019, Train_acc 0.9865489130434782\n",
      "\n",
      "Epoch 19. Loss: 0.044181725227056864, Train_acc 0.9865301724137931\n",
      "\n",
      "Epoch 19. Loss: 0.047353388377921815, Train_acc 0.9863782051282052\n",
      "\n",
      "Epoch 19. Loss: 0.04588083275457951, Train_acc 0.9863612288135594\n",
      "\n",
      "Epoch 19. Loss: 0.042347922123677134, Train_acc 0.9864758403361344\n",
      "\n",
      "Epoch 19. Loss: 0.04878841343272322, Train_acc 0.9864583333333333\n",
      "\n",
      "Epoch 19. Loss: 0.04703635352327162, Train_acc 0.9864411157024794\n",
      "\n",
      "Epoch 19. Loss: 0.047144081465665115, Train_acc 0.9863601434426229\n",
      "\n",
      "Epoch 19. Loss: 0.044589834307667865, Train_acc 0.9864710365853658\n",
      "\n",
      "Epoch 19. Loss: 0.050169367547366554, Train_acc 0.9862021169354839\n",
      "\n",
      "Epoch 19. Loss: 0.0559148235221507, Train_acc 0.9860625\n",
      "\n",
      "Epoch 19. Loss: 0.05590584067402499, Train_acc 0.9859871031746031\n",
      "\n",
      "Epoch 19. Loss: 0.051300896894021786, Train_acc 0.9860974409448819\n",
      "\n",
      "Epoch 19. Loss: 0.049078226036802494, Train_acc 0.98614501953125\n",
      "\n",
      "Epoch 19. Loss: 0.04895696262744864, Train_acc 0.9861312984496124\n",
      "\n",
      "Epoch 19. Loss: 0.051704501094470626, Train_acc 0.9860576923076924\n",
      "\n",
      "Epoch 19. Loss: 0.04945002625022847, Train_acc 0.9860448473282443\n",
      "\n",
      "Epoch 19. Loss: 0.04913307916791307, Train_acc 0.986032196969697\n",
      "\n",
      "Epoch 19. Loss: 0.05214055947963357, Train_acc 0.9859022556390977\n",
      "\n",
      "Epoch 19. Loss: 0.05010852766785586, Train_acc 0.9858908582089553\n",
      "\n",
      "Epoch 19. Loss: 0.04754472589719502, Train_acc 0.9859375\n",
      "\n",
      "Epoch 19. Loss: 0.04578277397508808, Train_acc 0.9859260110294118\n",
      "\n",
      "Epoch 19. Loss: 0.04453023384531189, Train_acc 0.9859146897810219\n",
      "\n",
      "Epoch 19. Loss: 0.04247079776692256, Train_acc 0.9859601449275363\n",
      "\n",
      "Epoch 19. Loss: 0.0415714650181043, Train_acc 0.9858925359712231\n",
      "\n",
      "Epoch 19. Loss: 0.0409127978676952, Train_acc 0.9858816964285714\n",
      "\n",
      "Epoch 19. Loss: 0.039543834316229556, Train_acc 0.9859264184397163\n",
      "\n",
      "Epoch 19. Loss: 0.039403669077899224, Train_acc 0.9859154929577465\n",
      "\n",
      "Epoch 19. Loss: 0.03645187761373475, Train_acc 0.986013986013986\n",
      "\n",
      "Epoch 19. Loss: 0.03464070726323565, Train_acc 0.9860568576388888\n",
      "\n",
      "Epoch 19. Loss: 0.044303403218583226, Train_acc 0.9858836206896552\n",
      "\n",
      "Epoch 19. Loss: 0.04599305250048276, Train_acc 0.9858197773972602\n",
      "\n",
      "Epoch 19. Loss: 0.047356938640472024, Train_acc 0.9858630952380952\n",
      "\n",
      "Epoch 19. Loss: 0.05457268385904735, Train_acc 0.9856946790540541\n",
      "\n",
      "Epoch 19. Loss: 0.052665803392091745, Train_acc 0.985685822147651\n",
      "\n",
      "Epoch 19. Loss: 0.049442320891641994, Train_acc 0.98578125\n",
      "\n",
      "Epoch 19. Loss: 0.046417111377498585, Train_acc 0.9858236754966887\n",
      "\n",
      "Epoch 19. Loss: 0.04614841272286869, Train_acc 0.9857627467105263\n",
      "\n",
      "Epoch 19. Loss: 0.047545612944832116, Train_acc 0.985702614379085\n",
      "\n",
      "Epoch 19. Loss: 0.046846770727936034, Train_acc 0.985744724025974\n",
      "\n",
      "Epoch 19. Loss: 0.045721161127957946, Train_acc 0.9856854838709678\n",
      "\n",
      "Epoch 19. Loss: 0.04252007030922763, Train_acc 0.9857772435897436\n",
      "\n",
      "Epoch 19. Loss: 0.04152133545409375, Train_acc 0.9858180732484076\n",
      "\n",
      "Epoch 19. Loss: 0.04225808104393542, Train_acc 0.9858089398734177\n",
      "\n",
      "Epoch 19. Loss: 0.044613449011900966, Train_acc 0.9857016509433962\n",
      "\n",
      "Epoch 19. Loss: 0.041842183382504235, Train_acc 0.985791015625\n",
      "\n",
      "Epoch 19. Loss: 0.04043334189313029, Train_acc 0.9858792701863354\n",
      "\n",
      "Epoch 19. Loss: 0.04326479700139799, Train_acc 0.9857735339506173\n",
      "\n",
      "Epoch 19. Loss: 0.04853215500949298, Train_acc 0.985573236196319\n",
      "\n",
      "Epoch 19. Loss: 0.04846012124632426, Train_acc 0.9855659298780488\n",
      "\n",
      "Epoch 19. Loss: 0.04445431677667464, Train_acc 0.985653409090909\n",
      "\n",
      "Epoch 19. Loss: 0.04265494426937251, Train_acc 0.9857398343373494\n",
      "\n",
      "Epoch 19. Loss: 0.04795320061610355, Train_acc 0.9856380988023952\n",
      "\n",
      "Epoch 19. Loss: 0.04464804398506475, Train_acc 0.9856770833333334\n",
      "\n",
      "Epoch 19. Loss: 0.04535162501772874, Train_acc 0.9857156065088757\n",
      "\n",
      "Epoch 19. Loss: 0.047003980829482976, Train_acc 0.9856617647058824\n",
      "\n",
      "Epoch 19. Loss: 0.0458607868291429, Train_acc 0.9856542397660819\n",
      "\n",
      "Epoch 19. Loss: 0.043783720033242525, Train_acc 0.9856468023255814\n",
      "\n",
      "Epoch 19. Loss: 0.043804985162801346, Train_acc 0.9856846098265896\n",
      "\n",
      "Epoch 19. Loss: 0.04372137915538562, Train_acc 0.9857219827586207\n",
      "\n",
      "Epoch 19. Loss: 0.04240530884069335, Train_acc 0.9857142857142858\n",
      "\n",
      "Epoch 19. Loss: 0.04096668036254166, Train_acc 0.9857066761363636\n",
      "\n",
      "Epoch 19. Loss: 0.042364842338608974, Train_acc 0.9856550141242938\n",
      "\n",
      "Epoch 19. Loss: 0.0431739263027137, Train_acc 0.9855161516853933\n",
      "\n",
      "Epoch 19. Loss: 0.04411099379860391, Train_acc 0.9854661312849162\n",
      "\n",
      "Epoch 19. Loss: 0.048138895859745415, Train_acc 0.9854166666666667\n",
      "\n",
      "Epoch 19. Loss: 0.05113852029779012, Train_acc 0.9852814226519337\n",
      "\n",
      "Epoch 19. Loss: 0.04899170366589834, Train_acc 0.9852764423076923\n",
      "\n",
      "Epoch 19. Loss: 0.045961447367053716, Train_acc 0.9853568989071039\n",
      "\n",
      "Epoch 19. Loss: 0.04294606716988816, Train_acc 0.9854364809782609\n",
      "\n",
      "Epoch 19. Loss: 0.043850870846733454, Train_acc 0.9853462837837837\n",
      "\n",
      "Epoch 19. Loss: 0.042837786155067385, Train_acc 0.985341061827957\n",
      "\n",
      "Epoch 19. Loss: 0.04508248640041575, Train_acc 0.9853358957219251\n",
      "\n",
      "Epoch 19. Loss: 0.04208390727660976, Train_acc 0.9854138962765957\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19. Loss: 0.04381436577458908, Train_acc 0.9854497354497355\n",
      "\n",
      "Epoch 19. Loss: 0.0483854626508331, Train_acc 0.9853207236842105\n",
      "\n",
      "Epoch 19. Loss: 0.04818509428725622, Train_acc 0.985315772251309\n",
      "\n",
      "Epoch 19. Loss: 0.04961583756529672, Train_acc 0.9852294921875\n",
      "\n",
      "Epoch 19. Loss: 0.05493995466640637, Train_acc 0.9850631476683938\n",
      "\n",
      "Epoch 19. Loss: 0.050848704036871, Train_acc 0.9851401417525774\n",
      "\n",
      "Epoch 19. Loss: 0.04882735758882708, Train_acc 0.985176282051282\n",
      "\n",
      "Epoch 19. Loss: 0.04605067223187041, Train_acc 0.98516\n",
      "\n",
      "Epoch 20. Loss: 0.04862590089329259, Train_acc 0.96875\n",
      "\n",
      "Epoch 20. Loss: 0.045278102687491564, Train_acc 0.984375\n",
      "\n",
      "Epoch 20. Loss: 0.043482482908511394, Train_acc 0.9869791666666666\n",
      "\n",
      "Epoch 20. Loss: 0.04557240275592586, Train_acc 0.984375\n",
      "\n",
      "Epoch 20. Loss: 0.04662699305758757, Train_acc 0.9828125\n",
      "\n",
      "Epoch 20. Loss: 0.05295297849547162, Train_acc 0.98046875\n",
      "\n",
      "Epoch 20. Loss: 0.0509516799304303, Train_acc 0.9799107142857143\n",
      "\n",
      "Epoch 20. Loss: 0.04762781762511282, Train_acc 0.9814453125\n",
      "\n",
      "Epoch 20. Loss: 0.044765024811900395, Train_acc 0.9835069444444444\n",
      "\n",
      "Epoch 20. Loss: 0.045042216268965665, Train_acc 0.9828125\n",
      "\n",
      "Epoch 20. Loss: 0.04366699150603032, Train_acc 0.9829545454545454\n",
      "\n",
      "Epoch 20. Loss: 0.04089637920022919, Train_acc 0.984375\n",
      "\n",
      "Epoch 20. Loss: 0.038119264708556956, Train_acc 0.9855769230769231\n",
      "\n",
      "Epoch 20. Loss: 0.03651598276191791, Train_acc 0.9866071428571429\n",
      "\n",
      "Epoch 20. Loss: 0.03623847080612636, Train_acc 0.9864583333333333\n",
      "\n",
      "Epoch 20. Loss: 0.03852713030586651, Train_acc 0.986328125\n",
      "\n",
      "Epoch 20. Loss: 0.03576995101878057, Train_acc 0.9871323529411765\n",
      "\n",
      "Epoch 20. Loss: 0.03540261053123185, Train_acc 0.9869791666666666\n",
      "\n",
      "Epoch 20. Loss: 0.032534706821245936, Train_acc 0.9876644736842105\n",
      "\n",
      "Epoch 20. Loss: 0.03909645816403894, Train_acc 0.9859375\n",
      "\n",
      "Epoch 20. Loss: 0.037748018531962656, Train_acc 0.9862351190476191\n",
      "\n",
      "Epoch 20. Loss: 0.03616142649557986, Train_acc 0.9861505681818182\n",
      "\n",
      "Epoch 20. Loss: 0.035577531195641734, Train_acc 0.9860733695652174\n",
      "\n",
      "Epoch 20. Loss: 0.03659441519107924, Train_acc 0.9860026041666666\n",
      "\n",
      "Epoch 20. Loss: 0.03541245563322162, Train_acc 0.98625\n",
      "\n",
      "Epoch 20. Loss: 0.03240677372882238, Train_acc 0.9867788461538461\n",
      "\n",
      "Epoch 20. Loss: 0.03768964177014951, Train_acc 0.9869791666666666\n",
      "\n",
      "Epoch 20. Loss: 0.03762850820102564, Train_acc 0.9866071428571429\n",
      "\n",
      "Epoch 20. Loss: 0.03775411092410927, Train_acc 0.9865301724137931\n",
      "\n",
      "Epoch 20. Loss: 0.03725422540161411, Train_acc 0.98671875\n",
      "\n",
      "Epoch 20. Loss: 0.03415759535598815, Train_acc 0.9871471774193549\n",
      "\n",
      "Epoch 20. Loss: 0.03282835117251927, Train_acc 0.9873046875\n",
      "\n",
      "Epoch 20. Loss: 0.033187877666395194, Train_acc 0.9874526515151515\n",
      "\n",
      "Epoch 20. Loss: 0.03091024427691813, Train_acc 0.9878216911764706\n",
      "\n",
      "Epoch 20. Loss: 0.030347156769749962, Train_acc 0.9881696428571428\n",
      "\n",
      "Epoch 20. Loss: 0.02920091684614191, Train_acc 0.98828125\n",
      "\n",
      "Epoch 20. Loss: 0.031286318549107635, Train_acc 0.9881756756756757\n",
      "\n",
      "Epoch 20. Loss: 0.029010725645951443, Train_acc 0.9884868421052632\n",
      "\n",
      "Epoch 20. Loss: 0.02758091913869859, Train_acc 0.9887820512820513\n",
      "\n",
      "Epoch 20. Loss: 0.0264421369705577, Train_acc 0.9888671875\n",
      "\n",
      "Epoch 20. Loss: 0.025155757594017326, Train_acc 0.9891387195121951\n",
      "\n",
      "Epoch 20. Loss: 0.02477795774004591, Train_acc 0.9890252976190477\n",
      "\n",
      "Epoch 20. Loss: 0.024456678689376107, Train_acc 0.9890988372093024\n",
      "\n",
      "Epoch 20. Loss: 0.02345158905388915, Train_acc 0.9893465909090909\n",
      "\n",
      "Epoch 20. Loss: 0.023265138646382126, Train_acc 0.9894097222222222\n",
      "\n",
      "Epoch 20. Loss: 0.022832700950281056, Train_acc 0.9894701086956522\n",
      "\n",
      "Epoch 20. Loss: 0.021675287623592825, Train_acc 0.9896941489361702\n",
      "\n",
      "Epoch 20. Loss: 0.021290446242143463, Train_acc 0.98974609375\n",
      "\n",
      "Epoch 20. Loss: 0.019538193450897707, Train_acc 0.9899553571428571\n",
      "\n",
      "Epoch 20. Loss: 0.02233963043081442, Train_acc 0.99\n",
      "\n",
      "Epoch 20. Loss: 0.02170860429633569, Train_acc 0.9901960784313726\n",
      "\n",
      "Epoch 20. Loss: 0.023222859516998335, Train_acc 0.9900841346153846\n",
      "\n",
      "Epoch 20. Loss: 0.027033064498239938, Train_acc 0.9895341981132075\n",
      "\n",
      "Epoch 20. Loss: 0.027540477723241613, Train_acc 0.9894386574074074\n",
      "\n",
      "Epoch 20. Loss: 0.0284654662999756, Train_acc 0.9893465909090909\n",
      "\n",
      "Epoch 20. Loss: 0.02771162421940984, Train_acc 0.9892578125\n",
      "\n",
      "Epoch 20. Loss: 0.026611553264610965, Train_acc 0.9894462719298246\n",
      "\n",
      "Epoch 20. Loss: 0.024323161079208254, Train_acc 0.9896282327586207\n",
      "\n",
      "Epoch 20. Loss: 0.022611857865351616, Train_acc 0.9898040254237288\n",
      "\n",
      "Epoch 20. Loss: 0.021662176826535026, Train_acc 0.9899739583333333\n",
      "\n",
      "Epoch 20. Loss: 0.023819784384016718, Train_acc 0.9898821721311475\n",
      "\n",
      "Epoch 20. Loss: 0.023998088444213146, Train_acc 0.9899193548387096\n",
      "\n",
      "Epoch 20. Loss: 0.023773792137152024, Train_acc 0.9899553571428571\n",
      "\n",
      "Epoch 20. Loss: 0.02317215710828847, Train_acc 0.9898681640625\n",
      "\n",
      "Epoch 20. Loss: 0.02180593601942193, Train_acc 0.9900240384615384\n",
      "\n",
      "Epoch 20. Loss: 0.022244399752439248, Train_acc 0.9900568181818182\n",
      "\n",
      "Epoch 20. Loss: 0.022970949418444502, Train_acc 0.9899720149253731\n",
      "\n",
      "Epoch 20. Loss: 0.021984141147523287, Train_acc 0.9901194852941176\n",
      "\n",
      "Epoch 20. Loss: 0.022955780693640557, Train_acc 0.9901494565217391\n",
      "\n",
      "Epoch 20. Loss: 0.021223343489691834, Train_acc 0.9902901785714285\n",
      "\n",
      "Epoch 20. Loss: 0.021540758754126924, Train_acc 0.9903169014084507\n",
      "\n",
      "Epoch 20. Loss: 0.02014750329358521, Train_acc 0.9904513888888888\n",
      "\n",
      "Epoch 20. Loss: 0.020675675237504926, Train_acc 0.9904751712328768\n",
      "\n",
      "Epoch 20. Loss: 0.01991347243800308, Train_acc 0.9904983108108109\n",
      "\n",
      "Epoch 20. Loss: 0.020604214441012257, Train_acc 0.9904166666666666\n",
      "\n",
      "Epoch 20. Loss: 0.019833720025030598, Train_acc 0.9904399671052632\n",
      "\n",
      "Epoch 20. Loss: 0.01836003730515345, Train_acc 0.9905641233766234\n",
      "\n",
      "Epoch 20. Loss: 0.017082642438140845, Train_acc 0.9906850961538461\n",
      "\n",
      "Epoch 20. Loss: 0.01695547242205799, Train_acc 0.9908030063291139\n",
      "\n",
      "Epoch 20. Loss: 0.016928952836168947, Train_acc 0.9908203125\n",
      "\n",
      "Epoch 20. Loss: 0.016908739718651603, Train_acc 0.9908371913580247\n",
      "\n",
      "Epoch 20. Loss: 0.016902493987550584, Train_acc 0.9908536585365854\n",
      "\n",
      "Epoch 20. Loss: 0.016258884455922468, Train_acc 0.9909638554216867\n",
      "\n",
      "Epoch 20. Loss: 0.017282658281472227, Train_acc 0.9908854166666666\n",
      "\n",
      "Epoch 20. Loss: 0.015974261913490505, Train_acc 0.9909926470588235\n",
      "\n",
      "Epoch 20. Loss: 0.015132653817199658, Train_acc 0.9910973837209303\n",
      "\n",
      "Epoch 20. Loss: 0.015809744392034104, Train_acc 0.9911099137931034\n",
      "\n",
      "Epoch 20. Loss: 0.014624644631919285, Train_acc 0.9912109375\n",
      "\n",
      "Epoch 20. Loss: 0.014056924490431269, Train_acc 0.991309691011236\n",
      "\n",
      "Epoch 20. Loss: 0.013976817548244582, Train_acc 0.99140625\n",
      "\n",
      "Epoch 20. Loss: 0.014783455255600262, Train_acc 0.9914148351648352\n",
      "\n",
      "Epoch 20. Loss: 0.015734023591553375, Train_acc 0.9914232336956522\n",
      "\n",
      "Epoch 20. Loss: 0.015057146335996871, Train_acc 0.9915154569892473\n",
      "\n",
      "Epoch 20. Loss: 0.015335647197387534, Train_acc 0.991439494680851\n",
      "\n",
      "Epoch 20. Loss: 0.019865000634034204, Train_acc 0.9913651315789473\n",
      "\n",
      "Epoch 20. Loss: 0.020108903770422692, Train_acc 0.9913736979166666\n",
      "\n",
      "Epoch 20. Loss: 0.019441748235174198, Train_acc 0.9913820876288659\n",
      "\n",
      "Epoch 20. Loss: 0.01969020216782228, Train_acc 0.9913105867346939\n",
      "\n",
      "Epoch 20. Loss: 0.019173599622720507, Train_acc 0.9913194444444444\n",
      "\n",
      "Epoch 20. Loss: 0.01922756903654995, Train_acc 0.991328125\n",
      "\n",
      "[Epoch 20 Batch 100] Loss: 0.01928897625166174 Training: accuracy=0.991337\n",
      "Epoch 20. Loss: 0.01928897625166174, Train_acc 0.9913366336633663\n",
      "\n",
      "Epoch 20. Loss: 0.020610294574123587, Train_acc 0.9912683823529411\n",
      "\n",
      "Epoch 20. Loss: 0.02107157573129711, Train_acc 0.9912014563106796\n",
      "\n",
      "Epoch 20. Loss: 0.020037383627378738, Train_acc 0.9912109375\n",
      "\n",
      "Epoch 20. Loss: 0.019346793424174606, Train_acc 0.9912946428571429\n",
      "\n",
      "Epoch 20. Loss: 0.018814732817785815, Train_acc 0.9913030660377359\n",
      "\n",
      "Epoch 20. Loss: 0.017854550183245728, Train_acc 0.9913843457943925\n",
      "\n",
      "Epoch 20. Loss: 0.02237084242739903, Train_acc 0.9913917824074074\n",
      "\n",
      "Epoch 20. Loss: 0.022557492775070315, Train_acc 0.9913990825688074\n",
      "\n",
      "Epoch 20. Loss: 0.02340863113613216, Train_acc 0.9913352272727273\n",
      "\n",
      "Epoch 20. Loss: 0.021921362787586045, Train_acc 0.9914132882882883\n",
      "\n",
      "Epoch 20. Loss: 0.02281464827963852, Train_acc 0.9913504464285714\n",
      "\n",
      "Epoch 20. Loss: 0.02633486674346754, Train_acc 0.9912195796460177\n",
      "\n",
      "Epoch 20. Loss: 0.02480546950058546, Train_acc 0.991296600877193\n",
      "\n",
      "Epoch 20. Loss: 0.024601294342485723, Train_acc 0.9912364130434783\n",
      "\n",
      "Epoch 20. Loss: 0.024743216106719663, Train_acc 0.9912446120689655\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20. Loss: 0.02413827552893182, Train_acc 0.9912526709401709\n",
      "\n",
      "Epoch 20. Loss: 0.024794302503750504, Train_acc 0.991260593220339\n",
      "\n",
      "Epoch 20. Loss: 0.027202274683552193, Train_acc 0.9911370798319328\n",
      "\n",
      "Epoch 20. Loss: 0.03591011206814993, Train_acc 0.9908203125\n",
      "\n",
      "Epoch 20. Loss: 0.03479417181470408, Train_acc 0.9908316115702479\n",
      "\n",
      "Epoch 20. Loss: 0.034752823559568054, Train_acc 0.9907146516393442\n",
      "\n",
      "Epoch 20. Loss: 0.03666046275030887, Train_acc 0.9906631097560976\n",
      "\n",
      "Epoch 20. Loss: 0.035485933095198714, Train_acc 0.9906754032258065\n",
      "\n",
      "Epoch 20. Loss: 0.03503331493137644, Train_acc 0.9906875\n",
      "\n",
      "Epoch 20. Loss: 0.03600968674539059, Train_acc 0.9906994047619048\n",
      "\n",
      "Epoch 20. Loss: 0.05855331202493783, Train_acc 0.9899729330708661\n",
      "\n",
      "Epoch 20. Loss: 0.057205868930935946, Train_acc 0.9898681640625\n",
      "\n",
      "Epoch 20. Loss: 0.05627915919243105, Train_acc 0.9898255813953488\n",
      "\n",
      "Epoch 20. Loss: 0.06129659334199555, Train_acc 0.9896634615384615\n",
      "\n",
      "Epoch 20. Loss: 0.06606833519974585, Train_acc 0.9893845419847328\n",
      "\n",
      "Epoch 20. Loss: 0.06243007972037109, Train_acc 0.9894649621212122\n",
      "\n",
      "Epoch 20. Loss: 0.06260476345594507, Train_acc 0.9894266917293233\n",
      "\n",
      "Epoch 20. Loss: 0.06198242755033775, Train_acc 0.9893889925373134\n",
      "\n",
      "Epoch 20. Loss: 0.058356026124640144, Train_acc 0.9894675925925925\n",
      "\n",
      "Epoch 20. Loss: 0.0594786093935524, Train_acc 0.9893152573529411\n",
      "\n",
      "Epoch 20. Loss: 0.059201520202024696, Train_acc 0.989279197080292\n",
      "\n",
      "Epoch 20. Loss: 0.056186873891172336, Train_acc 0.9892436594202898\n",
      "\n",
      "Epoch 20. Loss: 0.06425284222801106, Train_acc 0.9890400179856115\n",
      "\n",
      "Epoch 20. Loss: 0.07213799544608214, Train_acc 0.9887834821428572\n",
      "\n",
      "Epoch 20. Loss: 0.06975540791543382, Train_acc 0.9887522163120568\n",
      "\n",
      "Epoch 20. Loss: 0.06577680710338406, Train_acc 0.9887213908450704\n",
      "\n",
      "Epoch 20. Loss: 0.06207956779047417, Train_acc 0.9886909965034965\n",
      "\n",
      "Epoch 20. Loss: 0.057640309927265945, Train_acc 0.9887152777777778\n",
      "\n",
      "Epoch 20. Loss: 0.06151975241071085, Train_acc 0.9885775862068965\n",
      "\n",
      "Epoch 20. Loss: 0.060458796144420804, Train_acc 0.988548801369863\n",
      "\n",
      "Epoch 20. Loss: 0.06625343807419679, Train_acc 0.9883078231292517\n",
      "\n",
      "Epoch 20. Loss: 0.06773724509370811, Train_acc 0.9882284628378378\n",
      "\n",
      "Epoch 20. Loss: 0.06795109230064589, Train_acc 0.9880453020134228\n",
      "\n",
      "Epoch 20. Loss: 0.070796862999647, Train_acc 0.9878125\n",
      "\n",
      "Epoch 20. Loss: 0.07069764726762398, Train_acc 0.9877379966887417\n",
      "\n",
      "Epoch 20. Loss: 0.06483313092652938, Train_acc 0.9878186677631579\n",
      "\n",
      "Epoch 20. Loss: 0.060365401423549486, Train_acc 0.9878982843137255\n",
      "\n",
      "Epoch 20. Loss: 0.059625790834345674, Train_acc 0.9878754058441559\n",
      "\n",
      "Epoch 20. Loss: 0.062385584849046105, Train_acc 0.9877520161290323\n",
      "\n",
      "Epoch 20. Loss: 0.06093265721612552, Train_acc 0.9877303685897436\n",
      "\n",
      "Epoch 20. Loss: 0.057710276404738844, Train_acc 0.9877587579617835\n",
      "\n",
      "Epoch 20. Loss: 0.05468960917120018, Train_acc 0.9877867879746836\n",
      "\n",
      "Epoch 20. Loss: 0.05379550292603527, Train_acc 0.9877161949685535\n",
      "\n",
      "Epoch 20. Loss: 0.050424286621919466, Train_acc 0.987744140625\n",
      "\n",
      "Epoch 20. Loss: 0.048229558153251875, Train_acc 0.9877232142857143\n",
      "\n",
      "Epoch 20. Loss: 0.048802935674756825, Train_acc 0.9876060956790124\n",
      "\n",
      "Epoch 20. Loss: 0.050485914434465824, Train_acc 0.9874904141104295\n",
      "\n",
      "Epoch 20. Loss: 0.04951321451557254, Train_acc 0.9874714176829268\n",
      "\n",
      "Epoch 20. Loss: 0.04856843383931436, Train_acc 0.987405303030303\n",
      "\n",
      "Epoch 20. Loss: 0.0457320972024499, Train_acc 0.9873870481927711\n",
      "\n",
      "Epoch 20. Loss: 0.05276493031434107, Train_acc 0.9873222305389222\n",
      "\n",
      "Epoch 20. Loss: 0.0519081157325377, Train_acc 0.9873046875\n",
      "\n",
      "Epoch 20. Loss: 0.05471616776692897, Train_acc 0.987241124260355\n",
      "\n",
      "Epoch 20. Loss: 0.05385864488996294, Train_acc 0.9872242647058823\n",
      "\n",
      "Epoch 20. Loss: 0.051717946345066074, Train_acc 0.9872532894736842\n",
      "\n",
      "Epoch 20. Loss: 0.05430187828641091, Train_acc 0.9872365552325582\n",
      "\n",
      "Epoch 20. Loss: 0.054162695681759306, Train_acc 0.987220014450867\n",
      "\n",
      "Epoch 20. Loss: 0.05209168241236382, Train_acc 0.9872036637931034\n",
      "\n",
      "Epoch 20. Loss: 0.0540593805534879, Train_acc 0.9870535714285714\n",
      "\n",
      "Epoch 20. Loss: 0.0515392132958686, Train_acc 0.9870827414772727\n",
      "\n",
      "Epoch 20. Loss: 0.05437003672369561, Train_acc 0.9870233050847458\n",
      "\n",
      "Epoch 20. Loss: 0.05037197169138409, Train_acc 0.9870523174157303\n",
      "\n",
      "Epoch 20. Loss: 0.04761395052647666, Train_acc 0.9870810055865922\n",
      "\n",
      "Epoch 20. Loss: 0.044818238054896084, Train_acc 0.987109375\n",
      "\n",
      "Epoch 20. Loss: 0.04574657400117936, Train_acc 0.9870942679558011\n",
      "\n",
      "Epoch 20. Loss: 0.04349689802974423, Train_acc 0.9870793269230769\n",
      "\n",
      "Epoch 20. Loss: 0.04222411379769409, Train_acc 0.9871072404371585\n",
      "\n",
      "Epoch 20. Loss: 0.046584148397043036, Train_acc 0.9869650135869565\n",
      "\n",
      "Epoch 20. Loss: 0.044215588665003795, Train_acc 0.9869510135135136\n",
      "\n",
      "Epoch 20. Loss: 0.04442006921410133, Train_acc 0.9869791666666666\n",
      "\n",
      "Epoch 20. Loss: 0.04358322725271794, Train_acc 0.9869652406417112\n",
      "\n",
      "Epoch 20. Loss: 0.044004152839561814, Train_acc 0.9869514627659575\n",
      "\n",
      "Epoch 20. Loss: 0.0447521274910991, Train_acc 0.9868964947089947\n",
      "\n",
      "Epoch 20. Loss: 0.04387774607181173, Train_acc 0.9868832236842106\n",
      "\n",
      "Epoch 20. Loss: 0.04795847347950598, Train_acc 0.9867882853403142\n",
      "\n",
      "Epoch 20. Loss: 0.04732762660004789, Train_acc 0.9867350260416666\n",
      "\n",
      "Epoch 20. Loss: 0.052178501803440705, Train_acc 0.9866418393782384\n",
      "\n",
      "Epoch 20. Loss: 0.05660368924030321, Train_acc 0.9865093427835051\n",
      "\n",
      "Epoch 20. Loss: 0.053511607718664325, Train_acc 0.9864983974358974\n",
      "\n",
      "Epoch 20. Loss: 0.07032319134968333, Train_acc 0.9864\n",
      "\n",
      "Epoch 21. Loss: 0.06914400362817477, Train_acc 0.9609375\n",
      "\n",
      "Epoch 21. Loss: 0.07560640100104836, Train_acc 0.95703125\n",
      "\n",
      "Epoch 21. Loss: 0.07068852616962695, Train_acc 0.9635416666666666\n",
      "\n",
      "Epoch 21. Loss: 0.06913182541981552, Train_acc 0.96484375\n",
      "\n",
      "Epoch 21. Loss: 0.06386806116481317, Train_acc 0.971875\n",
      "\n",
      "Epoch 21. Loss: 0.0626029689250561, Train_acc 0.97265625\n",
      "\n",
      "Epoch 21. Loss: 0.07529741100712171, Train_acc 0.9698660714285714\n",
      "\n",
      "Epoch 21. Loss: 0.07156415422776537, Train_acc 0.9716796875\n",
      "\n",
      "Epoch 21. Loss: 0.07574583044665334, Train_acc 0.9713541666666666\n",
      "\n",
      "Epoch 21. Loss: 0.07445556328610131, Train_acc 0.971875\n",
      "\n",
      "Epoch 21. Loss: 0.06774454461111619, Train_acc 0.9744318181818182\n",
      "\n",
      "Epoch 21. Loss: 0.06308538281089658, Train_acc 0.9759114583333334\n",
      "\n",
      "Epoch 21. Loss: 0.059342476917802645, Train_acc 0.9771634615384616\n",
      "\n",
      "Epoch 21. Loss: 0.072966384762674, Train_acc 0.9737723214285714\n",
      "\n",
      "Epoch 21. Loss: 0.07500350732280263, Train_acc 0.9734375\n",
      "\n",
      "Epoch 21. Loss: 0.07415173210507733, Train_acc 0.97265625\n",
      "\n",
      "Epoch 21. Loss: 0.07603649056976529, Train_acc 0.9719669117647058\n",
      "\n",
      "Epoch 21. Loss: 0.07883722192369842, Train_acc 0.9709201388888888\n",
      "\n",
      "Epoch 21. Loss: 0.07579303963175069, Train_acc 0.9716282894736842\n",
      "\n",
      "Epoch 21. Loss: 0.07227802291384922, Train_acc 0.971875\n",
      "\n",
      "Epoch 21. Loss: 0.06830020448450672, Train_acc 0.9728422619047619\n",
      "\n",
      "Epoch 21. Loss: 0.06728288412884856, Train_acc 0.9730113636363636\n",
      "\n",
      "Epoch 21. Loss: 0.06575835091587291, Train_acc 0.9731657608695652\n",
      "\n",
      "Epoch 21. Loss: 0.0640898943786298, Train_acc 0.9736328125\n",
      "\n",
      "Epoch 21. Loss: 0.06222340546647979, Train_acc 0.9740625\n",
      "\n",
      "Epoch 21. Loss: 0.06252718641698604, Train_acc 0.9741586538461539\n",
      "\n",
      "Epoch 21. Loss: 0.06291498846715908, Train_acc 0.9742476851851852\n",
      "\n",
      "Epoch 21. Loss: 0.0588122843078335, Train_acc 0.9748883928571429\n",
      "\n",
      "Epoch 21. Loss: 0.057294892970165004, Train_acc 0.9752155172413793\n",
      "\n",
      "Epoch 21. Loss: 0.0544722109989289, Train_acc 0.9755208333333333\n",
      "\n",
      "Epoch 21. Loss: 0.050646547671195585, Train_acc 0.9760584677419355\n",
      "\n",
      "Epoch 21. Loss: 0.053977217551502636, Train_acc 0.9755859375\n",
      "\n",
      "Epoch 21. Loss: 0.05766952151933287, Train_acc 0.974905303030303\n",
      "\n",
      "Epoch 21. Loss: 0.05687650656591929, Train_acc 0.9751838235294118\n",
      "\n",
      "Epoch 21. Loss: 0.05349821626446614, Train_acc 0.9754464285714286\n",
      "\n",
      "Epoch 21. Loss: 0.05093898296477171, Train_acc 0.9756944444444444\n",
      "\n",
      "Epoch 21. Loss: 0.05019825141240751, Train_acc 0.9757179054054054\n",
      "\n",
      "Epoch 21. Loss: 0.05039101189919945, Train_acc 0.9759457236842105\n",
      "\n",
      "Epoch 21. Loss: 0.047165935977238144, Train_acc 0.9763621794871795\n",
      "\n",
      "Epoch 21. Loss: 0.05011782861704027, Train_acc 0.9759765625\n",
      "\n",
      "Epoch 21. Loss: 0.05210154339928384, Train_acc 0.975609756097561\n",
      "\n",
      "Epoch 21. Loss: 0.05041246602170726, Train_acc 0.9760044642857143\n",
      "\n",
      "Epoch 21. Loss: 0.05260616084247584, Train_acc 0.9760174418604651\n",
      "\n",
      "Epoch 21. Loss: 0.057191199424652055, Train_acc 0.9756747159090909\n",
      "\n",
      "Epoch 21. Loss: 0.053045425851155334, Train_acc 0.9760416666666667\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21. Loss: 0.048603965414174506, Train_acc 0.9765625\n",
      "\n",
      "Epoch 21. Loss: 0.04759687281186114, Train_acc 0.9768949468085106\n",
      "\n",
      "Epoch 21. Loss: 0.05081180718423185, Train_acc 0.9762369791666666\n",
      "\n",
      "Epoch 21. Loss: 0.046301450835596836, Train_acc 0.9767219387755102\n",
      "\n",
      "Epoch 21. Loss: 0.04318455732115923, Train_acc 0.9771875\n",
      "\n",
      "Epoch 21. Loss: 0.04689884820206897, Train_acc 0.9767156862745098\n",
      "\n",
      "Epoch 21. Loss: 0.04468766556194965, Train_acc 0.9771634615384616\n",
      "\n",
      "Epoch 21. Loss: 0.042932515570624566, Train_acc 0.9775943396226415\n",
      "\n",
      "Epoch 21. Loss: 0.04026399312535277, Train_acc 0.9780092592592593\n",
      "\n",
      "Epoch 21. Loss: 0.040040027422779956, Train_acc 0.978125\n",
      "\n",
      "Epoch 21. Loss: 0.03819606198943331, Train_acc 0.9783761160714286\n",
      "\n",
      "Epoch 21. Loss: 0.035712832345753974, Train_acc 0.9787554824561403\n",
      "\n",
      "Epoch 21. Loss: 0.035774355725219906, Train_acc 0.9789870689655172\n",
      "\n",
      "Epoch 21. Loss: 0.035937272544894566, Train_acc 0.9790783898305084\n",
      "\n",
      "Epoch 21. Loss: 0.03549924578028377, Train_acc 0.9791666666666666\n",
      "\n",
      "Epoch 21. Loss: 0.034000541291452545, Train_acc 0.9795081967213115\n",
      "\n",
      "Epoch 21. Loss: 0.03458127314312795, Train_acc 0.9797127016129032\n",
      "\n",
      "Epoch 21. Loss: 0.03170644130636936, Train_acc 0.9800347222222222\n",
      "\n",
      "Epoch 21. Loss: 0.03217540132698136, Train_acc 0.980224609375\n",
      "\n",
      "Epoch 21. Loss: 0.03510522423115418, Train_acc 0.9800480769230769\n",
      "\n",
      "Epoch 21. Loss: 0.035042758982721384, Train_acc 0.9799952651515151\n",
      "\n",
      "Epoch 21. Loss: 0.037206358791598754, Train_acc 0.9800606343283582\n",
      "\n",
      "Epoch 21. Loss: 0.03843847587514735, Train_acc 0.9802389705882353\n",
      "\n",
      "Epoch 21. Loss: 0.03834164596923128, Train_acc 0.9802989130434783\n",
      "\n",
      "Epoch 21. Loss: 0.03577059972132386, Train_acc 0.98046875\n",
      "\n",
      "Epoch 21. Loss: 0.0389740628109438, Train_acc 0.9805237676056338\n",
      "\n",
      "Epoch 21. Loss: 0.03971045199984874, Train_acc 0.9805772569444444\n",
      "\n",
      "Epoch 21. Loss: 0.041198092183064514, Train_acc 0.9806292808219178\n",
      "\n",
      "Epoch 21. Loss: 0.0399071942841331, Train_acc 0.9806798986486487\n",
      "\n",
      "Epoch 21. Loss: 0.04216591978746532, Train_acc 0.9804166666666667\n",
      "\n",
      "Epoch 21. Loss: 0.040797616970639335, Train_acc 0.98046875\n",
      "\n",
      "Epoch 21. Loss: 0.03766027232149324, Train_acc 0.9807224025974026\n",
      "\n",
      "Epoch 21. Loss: 0.03801681450133695, Train_acc 0.9806690705128205\n",
      "\n",
      "Epoch 21. Loss: 0.03710531906299448, Train_acc 0.9809137658227848\n",
      "\n",
      "Epoch 21. Loss: 0.034301723422223235, Train_acc 0.98115234375\n",
      "\n",
      "Epoch 21. Loss: 0.03883195702577881, Train_acc 0.9810956790123457\n",
      "\n",
      "Epoch 21. Loss: 0.036931851999568215, Train_acc 0.9812309451219512\n",
      "\n",
      "Epoch 21. Loss: 0.03389913720706755, Train_acc 0.981457078313253\n",
      "\n",
      "Epoch 21. Loss: 0.03517225726979662, Train_acc 0.9814918154761905\n",
      "\n",
      "Epoch 21. Loss: 0.03678314323309978, Train_acc 0.9814338235294118\n",
      "\n",
      "Epoch 21. Loss: 0.037239555434142826, Train_acc 0.981468023255814\n",
      "\n",
      "Epoch 21. Loss: 0.034639172311057405, Train_acc 0.9816810344827587\n",
      "\n",
      "Epoch 21. Loss: 0.03218721947931924, Train_acc 0.9818004261363636\n",
      "\n",
      "Epoch 21. Loss: 0.0347455834763975, Train_acc 0.9819171348314607\n",
      "\n",
      "Epoch 21. Loss: 0.033463100120520395, Train_acc 0.98203125\n",
      "\n",
      "Epoch 21. Loss: 0.03363135414579135, Train_acc 0.9820570054945055\n",
      "\n",
      "Epoch 21. Loss: 0.03306845835380515, Train_acc 0.9821671195652174\n",
      "\n",
      "Epoch 21. Loss: 0.030738282027388455, Train_acc 0.9823588709677419\n",
      "\n",
      "Epoch 21. Loss: 0.030558187430392066, Train_acc 0.9824634308510638\n",
      "\n",
      "Epoch 21. Loss: 0.029774162283799376, Train_acc 0.9825657894736842\n",
      "\n",
      "Epoch 21. Loss: 0.03036289306991815, Train_acc 0.982666015625\n",
      "\n",
      "Epoch 21. Loss: 0.02987392914307284, Train_acc 0.982764175257732\n",
      "\n",
      "Epoch 21. Loss: 0.03232432832132728, Train_acc 0.9827008928571429\n",
      "\n",
      "Epoch 21. Loss: 0.03080332179198519, Train_acc 0.9828756313131313\n",
      "\n",
      "Epoch 21. Loss: 0.028980820284752747, Train_acc 0.983046875\n",
      "\n",
      "[Epoch 21 Batch 100] Loss: 0.029784365138234528 Training: accuracy=0.983137\n",
      "Epoch 21. Loss: 0.029784365138234528, Train_acc 0.9831373762376238\n",
      "\n",
      "Epoch 21. Loss: 0.03066562143637702, Train_acc 0.9831495098039216\n",
      "\n",
      "Epoch 21. Loss: 0.030699751028483796, Train_acc 0.9831614077669902\n",
      "\n",
      "Epoch 21. Loss: 0.028180119068457802, Train_acc 0.9833233173076923\n",
      "\n",
      "Epoch 21. Loss: 0.026562450271279323, Train_acc 0.9834077380952381\n",
      "\n",
      "Epoch 21. Loss: 0.024668647045058643, Train_acc 0.9835642688679245\n",
      "\n",
      "Epoch 21. Loss: 0.022734345930066083, Train_acc 0.9837178738317757\n",
      "\n",
      "Epoch 21. Loss: 0.02346138307802055, Train_acc 0.9837239583333334\n",
      "\n",
      "Epoch 21. Loss: 0.025413128951360348, Train_acc 0.9836582568807339\n",
      "\n",
      "Epoch 21. Loss: 0.028730391236397233, Train_acc 0.9835227272727273\n",
      "\n",
      "Epoch 21. Loss: 0.027387206462549513, Train_acc 0.9836007882882883\n",
      "\n",
      "Epoch 21. Loss: 0.025653215795034778, Train_acc 0.9837472098214286\n",
      "\n",
      "Epoch 21. Loss: 0.02811205801302905, Train_acc 0.983683628318584\n",
      "\n",
      "Epoch 21. Loss: 0.026051039530498223, Train_acc 0.9838267543859649\n",
      "\n",
      "Epoch 21. Loss: 0.025813841291066203, Train_acc 0.9838994565217392\n",
      "\n",
      "Epoch 21. Loss: 0.024689047158774312, Train_acc 0.9840382543103449\n",
      "\n",
      "Epoch 21. Loss: 0.025376562286332168, Train_acc 0.9840411324786325\n",
      "\n",
      "Epoch 21. Loss: 0.02530716662160896, Train_acc 0.9841101694915254\n",
      "\n",
      "Epoch 21. Loss: 0.024596792388430325, Train_acc 0.9841780462184874\n",
      "\n",
      "Epoch 21. Loss: 0.023044845509652277, Train_acc 0.9843098958333333\n",
      "\n",
      "Epoch 21. Loss: 0.02176029049437402, Train_acc 0.9844395661157025\n",
      "\n",
      "Epoch 21. Loss: 0.022525676158796176, Train_acc 0.984375\n",
      "\n",
      "Epoch 21. Loss: 0.022325914301929255, Train_acc 0.9844385162601627\n",
      "\n",
      "Epoch 21. Loss: 0.020838174596912305, Train_acc 0.9845640120967742\n",
      "\n",
      "Epoch 21. Loss: 0.023111618347901083, Train_acc 0.9845\n",
      "\n",
      "Epoch 21. Loss: 0.02174307202586947, Train_acc 0.9846230158730159\n",
      "\n",
      "Epoch 21. Loss: 0.020846917140091223, Train_acc 0.9846825787401575\n",
      "\n",
      "Epoch 21. Loss: 0.024132110691909278, Train_acc 0.98455810546875\n",
      "\n",
      "Epoch 21. Loss: 0.024971328020254632, Train_acc 0.9846172480620154\n",
      "\n",
      "Epoch 21. Loss: 0.02660771065070617, Train_acc 0.9846754807692307\n",
      "\n",
      "Epoch 21. Loss: 0.02836313861412753, Train_acc 0.9846731870229007\n",
      "\n",
      "Epoch 21. Loss: 0.029668983603742264, Train_acc 0.9846117424242424\n",
      "\n",
      "Epoch 21. Loss: 0.03126104074885834, Train_acc 0.9846099624060151\n",
      "\n",
      "Epoch 21. Loss: 0.030758037625286477, Train_acc 0.9846665111940298\n",
      "\n",
      "Epoch 21. Loss: 0.02992714483308807, Train_acc 0.9847222222222223\n",
      "\n",
      "Epoch 21. Loss: 0.027891743343484536, Train_acc 0.9848345588235294\n",
      "\n",
      "Epoch 21. Loss: 0.02996168344743145, Train_acc 0.9847741788321168\n",
      "\n",
      "Epoch 21. Loss: 0.038393977816645136, Train_acc 0.9847146739130435\n",
      "\n",
      "Epoch 21. Loss: 0.03557122954569206, Train_acc 0.9848246402877698\n",
      "\n",
      "Epoch 21. Loss: 0.03384277150489639, Train_acc 0.9848772321428572\n",
      "\n",
      "Epoch 21. Loss: 0.03322903316877261, Train_acc 0.9849290780141844\n",
      "\n",
      "Epoch 21. Loss: 0.03325950951870062, Train_acc 0.9848151408450704\n",
      "\n",
      "Epoch 21. Loss: 0.030849600000641745, Train_acc 0.9849213286713286\n",
      "\n",
      "Epoch 21. Loss: 0.02933338842999518, Train_acc 0.9849717881944444\n",
      "\n",
      "Epoch 21. Loss: 0.02738326703871709, Train_acc 0.9850754310344828\n",
      "\n",
      "Epoch 21. Loss: 0.028079302597332795, Train_acc 0.9850171232876712\n",
      "\n",
      "Epoch 21. Loss: 0.030348691557307957, Train_acc 0.9850127551020408\n",
      "\n",
      "Epoch 21. Loss: 0.03442510057788484, Train_acc 0.9849556587837838\n",
      "\n",
      "Epoch 21. Loss: 0.032039962576044134, Train_acc 0.9850566275167785\n",
      "\n",
      "Epoch 21. Loss: 0.030874636090885876, Train_acc 0.98515625\n",
      "\n",
      "Epoch 21. Loss: 0.03188029272892291, Train_acc 0.9850993377483444\n",
      "\n",
      "Epoch 21. Loss: 0.03153360290263488, Train_acc 0.985094572368421\n",
      "\n",
      "Epoch 21. Loss: 0.029435221262434665, Train_acc 0.985140931372549\n",
      "\n",
      "Epoch 21. Loss: 0.02803424014835913, Train_acc 0.9851866883116883\n",
      "\n",
      "Epoch 21. Loss: 0.03085277465751194, Train_acc 0.9851310483870968\n",
      "\n",
      "Epoch 21. Loss: 0.030859805161688535, Train_acc 0.985176282051282\n",
      "\n",
      "Epoch 21. Loss: 0.029745296700239607, Train_acc 0.9852209394904459\n",
      "\n",
      "Epoch 21. Loss: 0.02758628076026478, Train_acc 0.9853144778481012\n",
      "\n",
      "Epoch 21. Loss: 0.02575512014218842, Train_acc 0.9854068396226415\n",
      "\n",
      "Epoch 21. Loss: 0.025441950476664383, Train_acc 0.98544921875\n",
      "\n",
      "Epoch 21. Loss: 0.024963319189695785, Train_acc 0.9854425465838509\n",
      "\n",
      "Epoch 21. Loss: 0.023319151896847728, Train_acc 0.9855324074074074\n",
      "\n",
      "Epoch 21. Loss: 0.023524970396113495, Train_acc 0.9855253067484663\n",
      "\n",
      "Epoch 21. Loss: 0.021933737639712188, Train_acc 0.9856135670731707\n",
      "\n",
      "Epoch 21. Loss: 0.021089238034898247, Train_acc 0.9857007575757576\n",
      "\n",
      "Epoch 21. Loss: 0.023217667288077656, Train_acc 0.9856457078313253\n",
      "\n",
      "Epoch 21. Loss: 0.023341478575610627, Train_acc 0.9856380988023952\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21. Loss: 0.022120446434775152, Train_acc 0.9857235863095238\n",
      "\n",
      "Epoch 21. Loss: 0.020907501925074304, Train_acc 0.9858080621301775\n",
      "\n",
      "Epoch 21. Loss: 0.02135935847375683, Train_acc 0.9858455882352941\n",
      "\n",
      "Epoch 21. Loss: 0.020043243071412076, Train_acc 0.9859283625730995\n",
      "\n",
      "Epoch 21. Loss: 0.020533793733395665, Train_acc 0.9859193313953488\n",
      "\n",
      "Epoch 21. Loss: 0.020735705851803003, Train_acc 0.9859104046242775\n",
      "\n",
      "Epoch 21. Loss: 0.020326972902676266, Train_acc 0.9859464798850575\n",
      "\n",
      "Epoch 21. Loss: 0.018675819123002115, Train_acc 0.9860267857142857\n",
      "\n",
      "Epoch 21. Loss: 0.01811794450585147, Train_acc 0.9861061789772727\n",
      "\n",
      "Epoch 21. Loss: 0.019453470877147615, Train_acc 0.9860963983050848\n",
      "\n",
      "Epoch 21. Loss: 0.01958489527225813, Train_acc 0.9861306179775281\n",
      "\n",
      "Epoch 21. Loss: 0.017982427687603122, Train_acc 0.9862081005586593\n",
      "\n",
      "Epoch 21. Loss: 0.016568297389626105, Train_acc 0.9862847222222222\n",
      "\n",
      "Epoch 21. Loss: 0.01666588100953066, Train_acc 0.9863173342541437\n",
      "\n",
      "Epoch 21. Loss: 0.015363662272101616, Train_acc 0.9863925137362637\n",
      "\n",
      "Epoch 21. Loss: 0.015026203427677728, Train_acc 0.9864668715846995\n",
      "\n",
      "Epoch 21. Loss: 0.01397285505068187, Train_acc 0.9865404211956522\n",
      "\n",
      "Epoch 21. Loss: 0.01331734087480799, Train_acc 0.9866131756756756\n",
      "\n",
      "Epoch 21. Loss: 0.014639977452877425, Train_acc 0.9866431451612904\n",
      "\n",
      "Epoch 21. Loss: 0.013899547498872813, Train_acc 0.9867145721925134\n",
      "\n",
      "Epoch 21. Loss: 0.013496993142918589, Train_acc 0.9867852393617021\n",
      "\n",
      "Epoch 21. Loss: 0.012884724728962042, Train_acc 0.9868551587301587\n",
      "\n",
      "Epoch 21. Loss: 0.014078720145851605, Train_acc 0.9868832236842106\n",
      "\n",
      "Epoch 21. Loss: 0.01313468356066665, Train_acc 0.9869518979057592\n",
      "\n",
      "Epoch 21. Loss: 0.01457849440694202, Train_acc 0.9869384765625\n",
      "\n",
      "Epoch 21. Loss: 0.01619146136391475, Train_acc 0.9869656735751295\n",
      "\n",
      "Epoch 21. Loss: 0.017433865677848288, Train_acc 0.9869925902061856\n",
      "\n",
      "Epoch 21. Loss: 0.017178331184269334, Train_acc 0.9870192307692308\n",
      "\n",
      "Epoch 21. Loss: 0.01585942683104993, Train_acc 0.98704\n",
      "\n",
      "Epoch 22. Loss: 0.014953843600907813, Train_acc 1.0\n",
      "\n",
      "Epoch 22. Loss: 0.013817769078039131, Train_acc 1.0\n",
      "\n",
      "Epoch 22. Loss: 0.013045798862462939, Train_acc 1.0\n",
      "\n",
      "Epoch 22. Loss: 0.01294020701153788, Train_acc 0.998046875\n",
      "\n",
      "Epoch 22. Loss: 0.01331617155257207, Train_acc 0.996875\n",
      "\n",
      "Epoch 22. Loss: 0.013803421052545384, Train_acc 0.99609375\n",
      "\n",
      "Epoch 22. Loss: 0.013538221780732343, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 22. Loss: 0.013678176751084688, Train_acc 0.99609375\n",
      "\n",
      "Epoch 22. Loss: 0.012856937486989108, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 22. Loss: 0.014181884338613874, Train_acc 0.99609375\n",
      "\n",
      "Epoch 22. Loss: 0.014108261672547334, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 22. Loss: 0.015221666507027335, Train_acc 0.9954427083333334\n",
      "\n",
      "Epoch 22. Loss: 0.01478218786755364, Train_acc 0.9957932692307693\n",
      "\n",
      "Epoch 22. Loss: 0.015834577965788493, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 22. Loss: 0.015076976608978911, Train_acc 0.9958333333333333\n",
      "\n",
      "Epoch 22. Loss: 0.014053199512956027, Train_acc 0.99609375\n",
      "\n",
      "Epoch 22. Loss: 0.013680599509058134, Train_acc 0.9963235294117647\n",
      "\n",
      "Epoch 22. Loss: 0.013431078459362152, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 22. Loss: 0.013435884951537814, Train_acc 0.9962993421052632\n",
      "\n",
      "Epoch 22. Loss: 0.013442208853947491, Train_acc 0.996484375\n",
      "\n",
      "Epoch 22. Loss: 0.014758166361678277, Train_acc 0.9962797619047619\n",
      "\n",
      "Epoch 22. Loss: 0.013814532543789119, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 22. Loss: 0.0199991818835474, Train_acc 0.9955842391304348\n",
      "\n",
      "Epoch 22. Loss: 0.018654710083020058, Train_acc 0.9957682291666666\n",
      "\n",
      "Epoch 22. Loss: 0.017883040278833206, Train_acc 0.995625\n",
      "\n",
      "Epoch 22. Loss: 0.016264513189805534, Train_acc 0.9957932692307693\n",
      "\n",
      "Epoch 22. Loss: 0.01584092253167598, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 22. Loss: 0.01462063528383525, Train_acc 0.9958147321428571\n",
      "\n",
      "Epoch 22. Loss: 0.013911311503437924, Train_acc 0.9959590517241379\n",
      "\n",
      "Epoch 22. Loss: 0.013016659290660412, Train_acc 0.99609375\n",
      "\n",
      "Epoch 22. Loss: 0.01351875508225172, Train_acc 0.9959677419354839\n",
      "\n",
      "Epoch 22. Loss: 0.0122664714382995, Train_acc 0.99609375\n",
      "\n",
      "Epoch 22. Loss: 0.013067446532271102, Train_acc 0.9959753787878788\n",
      "\n",
      "Epoch 22. Loss: 0.01290421847917598, Train_acc 0.99609375\n",
      "\n",
      "Epoch 22. Loss: 0.013142957145732298, Train_acc 0.9959821428571428\n",
      "\n",
      "Epoch 22. Loss: 0.015510795731629421, Train_acc 0.9954427083333334\n",
      "\n",
      "Epoch 22. Loss: 0.014351720773162387, Train_acc 0.9955658783783784\n",
      "\n",
      "Epoch 22. Loss: 0.013496340211911746, Train_acc 0.9956825657894737\n",
      "\n",
      "Epoch 22. Loss: 0.012563993419349564, Train_acc 0.9957932692307693\n",
      "\n",
      "Epoch 22. Loss: 0.014215486766523457, Train_acc 0.995703125\n",
      "\n",
      "Epoch 22. Loss: 0.014199721832537357, Train_acc 0.9956173780487805\n",
      "\n",
      "Epoch 22. Loss: 0.013019435967956815, Train_acc 0.9957217261904762\n",
      "\n",
      "Epoch 22. Loss: 0.015221059724052103, Train_acc 0.9954578488372093\n",
      "\n",
      "Epoch 22. Loss: 0.016000604618513006, Train_acc 0.9952059659090909\n",
      "\n",
      "Epoch 22. Loss: 0.018403561924925524, Train_acc 0.9951388888888889\n",
      "\n",
      "Epoch 22. Loss: 0.017248751348284852, Train_acc 0.9952445652173914\n",
      "\n",
      "Epoch 22. Loss: 0.019066984915162302, Train_acc 0.9950132978723404\n",
      "\n",
      "Epoch 22. Loss: 0.017550573283702294, Train_acc 0.9951171875\n",
      "\n",
      "Epoch 22. Loss: 0.01690428705224707, Train_acc 0.9952168367346939\n",
      "\n",
      "Epoch 22. Loss: 0.016375798090928623, Train_acc 0.9953125\n",
      "\n",
      "Epoch 22. Loss: 0.016336368564933982, Train_acc 0.9952512254901961\n",
      "\n",
      "Epoch 22. Loss: 0.015537825191769404, Train_acc 0.9953425480769231\n",
      "\n",
      "Epoch 22. Loss: 0.01719845112987167, Train_acc 0.9951356132075472\n",
      "\n",
      "Epoch 22. Loss: 0.01767119323606318, Train_acc 0.9949363425925926\n",
      "\n",
      "Epoch 22. Loss: 0.016771387710973855, Train_acc 0.9950284090909091\n",
      "\n",
      "Epoch 22. Loss: 0.015576581180666599, Train_acc 0.9951171875\n",
      "\n",
      "Epoch 22. Loss: 0.017804907280720515, Train_acc 0.9950657894736842\n",
      "\n",
      "Epoch 22. Loss: 0.01737692622260801, Train_acc 0.9951508620689655\n",
      "\n",
      "Epoch 22. Loss: 0.016340262128039167, Train_acc 0.9952330508474576\n",
      "\n",
      "Epoch 22. Loss: 0.01663492990266439, Train_acc 0.9950520833333333\n",
      "\n",
      "Epoch 22. Loss: 0.01697294281629762, Train_acc 0.9950051229508197\n",
      "\n",
      "Epoch 22. Loss: 0.016878412031007182, Train_acc 0.9949596774193549\n",
      "\n",
      "Epoch 22. Loss: 0.016078965857957934, Train_acc 0.9950396825396826\n",
      "\n",
      "Epoch 22. Loss: 0.015756576150210325, Train_acc 0.9949951171875\n",
      "\n",
      "Epoch 22. Loss: 0.016087268417672777, Train_acc 0.9950721153846154\n",
      "\n",
      "Epoch 22. Loss: 0.01703807994776648, Train_acc 0.9949100378787878\n",
      "\n",
      "Epoch 22. Loss: 0.018678514227751034, Train_acc 0.9948694029850746\n",
      "\n",
      "Epoch 22. Loss: 0.01733906342914683, Train_acc 0.9949448529411765\n",
      "\n",
      "Epoch 22. Loss: 0.017835881406047784, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 22. Loss: 0.016441602353211203, Train_acc 0.9948660714285714\n",
      "\n",
      "Epoch 22. Loss: 0.016081803189774715, Train_acc 0.9949383802816901\n",
      "\n",
      "Epoch 22. Loss: 0.01697948297595414, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 22. Loss: 0.0209007316446492, Train_acc 0.9945419520547946\n",
      "\n",
      "Epoch 22. Loss: 0.019918229102300608, Train_acc 0.9945101351351351\n",
      "\n",
      "Epoch 22. Loss: 0.025464356767422265, Train_acc 0.9941666666666666\n",
      "\n",
      "Epoch 22. Loss: 0.02451304830070106, Train_acc 0.994140625\n",
      "\n",
      "Epoch 22. Loss: 0.023275865125260663, Train_acc 0.9942167207792207\n",
      "\n",
      "Epoch 22. Loss: 0.027534849650503915, Train_acc 0.9939903846153846\n",
      "\n",
      "Epoch 22. Loss: 0.025275726400844804, Train_acc 0.9940664556962026\n",
      "\n",
      "Epoch 22. Loss: 0.02790204930278589, Train_acc 0.99384765625\n",
      "\n",
      "Epoch 22. Loss: 0.02831924816643831, Train_acc 0.9937307098765432\n",
      "\n",
      "Epoch 22. Loss: 0.033506931608995524, Train_acc 0.9933307926829268\n",
      "\n",
      "Epoch 22. Loss: 0.03124147623426979, Train_acc 0.9933170180722891\n",
      "\n",
      "Epoch 22. Loss: 0.03773431750816642, Train_acc 0.9930245535714286\n",
      "\n",
      "Epoch 22. Loss: 0.04394003769173509, Train_acc 0.9927389705882353\n",
      "\n",
      "Epoch 22. Loss: 0.03983038181530046, Train_acc 0.9928234011627907\n",
      "\n",
      "Epoch 22. Loss: 0.037242130505740115, Train_acc 0.992816091954023\n",
      "\n",
      "Epoch 22. Loss: 0.04262160232755495, Train_acc 0.9924538352272727\n",
      "\n",
      "Epoch 22. Loss: 0.04736855078720706, Train_acc 0.9920997191011236\n",
      "\n",
      "Epoch 22. Loss: 0.04501387654826335, Train_acc 0.9920138888888889\n",
      "\n",
      "Epoch 22. Loss: 0.04334168650137149, Train_acc 0.9920157967032966\n",
      "\n",
      "Epoch 22. Loss: 0.04224733353340712, Train_acc 0.9919327445652174\n",
      "\n",
      "Epoch 22. Loss: 0.044350075787461585, Train_acc 0.9917674731182796\n",
      "\n",
      "Epoch 22. Loss: 0.04370869597747038, Train_acc 0.991688829787234\n",
      "\n",
      "Epoch 22. Loss: 0.043249244102425366, Train_acc 0.9916940789473684\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22. Loss: 0.046865938998985585, Train_acc 0.9913736979166666\n",
      "\n",
      "Epoch 22. Loss: 0.0446828346157625, Train_acc 0.9913820876288659\n",
      "\n",
      "Epoch 22. Loss: 0.042893252621998314, Train_acc 0.9913105867346939\n",
      "\n",
      "Epoch 22. Loss: 0.03988963959447437, Train_acc 0.9913194444444444\n",
      "\n",
      "Epoch 22. Loss: 0.037727637718605045, Train_acc 0.991328125\n",
      "\n",
      "[Epoch 22 Batch 100] Loss: 0.04008660976334248 Training: accuracy=0.991337\n",
      "Epoch 22. Loss: 0.04008660976334248, Train_acc 0.9913366336633663\n",
      "\n",
      "Epoch 22. Loss: 0.041384182997737835, Train_acc 0.9911917892156863\n",
      "\n",
      "Epoch 22. Loss: 0.03845863148855672, Train_acc 0.9912014563106796\n",
      "\n",
      "Epoch 22. Loss: 0.03751146682608878, Train_acc 0.9912109375\n",
      "\n",
      "Epoch 22. Loss: 0.03742055085458239, Train_acc 0.9911458333333333\n",
      "\n",
      "Epoch 22. Loss: 0.038245006535868764, Train_acc 0.9910082547169812\n",
      "\n",
      "Epoch 22. Loss: 0.035462692816782826, Train_acc 0.9910192757009346\n",
      "\n",
      "Epoch 22. Loss: 0.03927031571244791, Train_acc 0.9909577546296297\n",
      "\n",
      "Epoch 22. Loss: 0.038652152549406245, Train_acc 0.9908973623853211\n",
      "\n",
      "Epoch 22. Loss: 0.04363968288705977, Train_acc 0.9907670454545454\n",
      "\n",
      "Epoch 22. Loss: 0.041001022822912625, Train_acc 0.9907798423423423\n",
      "\n",
      "Epoch 22. Loss: 0.04514294204168567, Train_acc 0.9905133928571429\n",
      "\n",
      "Epoch 22. Loss: 0.04658513966548188, Train_acc 0.990320796460177\n",
      "\n",
      "Epoch 22. Loss: 0.046587518185505966, Train_acc 0.9902686403508771\n",
      "\n",
      "Epoch 22. Loss: 0.049246937480684844, Train_acc 0.9900815217391304\n",
      "\n",
      "Epoch 22. Loss: 0.05015827382843202, Train_acc 0.9899649784482759\n",
      "\n",
      "Epoch 22. Loss: 0.046811661670272106, Train_acc 0.9899839743589743\n",
      "\n",
      "Epoch 22. Loss: 0.04865462918549587, Train_acc 0.9898040254237288\n",
      "\n",
      "Epoch 22. Loss: 0.049914759452371095, Train_acc 0.9896927521008403\n",
      "\n",
      "Epoch 22. Loss: 0.05686340739300397, Train_acc 0.9893880208333333\n",
      "\n",
      "Epoch 22. Loss: 0.052929189331566213, Train_acc 0.9894111570247934\n",
      "\n",
      "Epoch 22. Loss: 0.05236903230300687, Train_acc 0.9893698770491803\n",
      "\n",
      "Epoch 22. Loss: 0.05374431520656772, Train_acc 0.9892657520325203\n",
      "\n",
      "Epoch 22. Loss: 0.05096801289876724, Train_acc 0.989226310483871\n",
      "\n",
      "Epoch 22. Loss: 0.047326186226699575, Train_acc 0.9893125\n",
      "\n",
      "Epoch 22. Loss: 0.046961701446974716, Train_acc 0.9892113095238095\n",
      "\n",
      "Epoch 22. Loss: 0.049861625463549296, Train_acc 0.9891117125984252\n",
      "\n",
      "Epoch 22. Loss: 0.05294493046175003, Train_acc 0.989013671875\n",
      "\n",
      "Epoch 22. Loss: 0.04990295077208185, Train_acc 0.9890382751937985\n",
      "\n",
      "Epoch 22. Loss: 0.05156043995776925, Train_acc 0.9888221153846154\n",
      "\n",
      "Epoch 22. Loss: 0.05085588503801066, Train_acc 0.9887881679389313\n",
      "\n",
      "Epoch 22. Loss: 0.04865710706046139, Train_acc 0.9887547348484849\n",
      "\n",
      "Epoch 22. Loss: 0.06490775290606243, Train_acc 0.988545582706767\n",
      "\n",
      "Epoch 22. Loss: 0.06377714955935916, Train_acc 0.9885144589552238\n",
      "\n",
      "Epoch 22. Loss: 0.0591856421974007, Train_acc 0.9885416666666667\n",
      "\n",
      "Epoch 22. Loss: 0.06040221365809772, Train_acc 0.9883386948529411\n",
      "\n",
      "Epoch 22. Loss: 0.05914441268909276, Train_acc 0.9883097627737226\n",
      "\n",
      "Epoch 22. Loss: 0.05541956331969768, Train_acc 0.9883378623188406\n",
      "\n",
      "Epoch 22. Loss: 0.0506482011673582, Train_acc 0.9884217625899281\n",
      "\n",
      "Epoch 22. Loss: 0.051113653474843423, Train_acc 0.9883370535714285\n",
      "\n",
      "Epoch 22. Loss: 0.04857020896118515, Train_acc 0.9883643617021277\n",
      "\n",
      "Epoch 22. Loss: 0.052945575011744794, Train_acc 0.9882262323943662\n",
      "\n",
      "Epoch 22. Loss: 0.051932879590667516, Train_acc 0.9881993006993007\n",
      "\n",
      "Epoch 22. Loss: 0.05519673449129811, Train_acc 0.9880642361111112\n",
      "\n",
      "Epoch 22. Loss: 0.055061409747579254, Train_acc 0.9879849137931035\n",
      "\n",
      "Epoch 22. Loss: 0.05440523166296949, Train_acc 0.9879066780821918\n",
      "\n",
      "Epoch 22. Loss: 0.0584857979909009, Train_acc 0.9878826530612245\n",
      "\n",
      "Epoch 22. Loss: 0.05675057794112798, Train_acc 0.9877533783783784\n",
      "\n",
      "Epoch 22. Loss: 0.0543131345551506, Train_acc 0.9877307046979866\n",
      "\n",
      "Epoch 22. Loss: 0.052836162734743536, Train_acc 0.98765625\n",
      "\n",
      "Epoch 22. Loss: 0.048870663692399785, Train_acc 0.9876862582781457\n",
      "\n",
      "Epoch 22. Loss: 0.04652424120889151, Train_acc 0.9877158717105263\n",
      "\n",
      "Epoch 22. Loss: 0.04442988397019545, Train_acc 0.9877450980392157\n",
      "\n",
      "Epoch 22. Loss: 0.041092166107929706, Train_acc 0.9878246753246753\n",
      "\n",
      "Epoch 22. Loss: 0.04164790776554074, Train_acc 0.9877520161290323\n",
      "\n",
      "Epoch 22. Loss: 0.04323348328933113, Train_acc 0.9877303685897436\n",
      "\n",
      "Epoch 22. Loss: 0.04142066564826661, Train_acc 0.9877587579617835\n",
      "\n",
      "Epoch 22. Loss: 0.04190312156082834, Train_acc 0.9877373417721519\n",
      "\n",
      "Epoch 22. Loss: 0.04094705503286401, Train_acc 0.9877653301886793\n",
      "\n",
      "Epoch 22. Loss: 0.04720811862738263, Train_acc 0.987548828125\n",
      "\n",
      "Epoch 22. Loss: 0.04354298716626762, Train_acc 0.9875776397515528\n",
      "\n",
      "Epoch 22. Loss: 0.04113799614467203, Train_acc 0.9876543209876543\n",
      "\n",
      "Epoch 22. Loss: 0.040303599754792266, Train_acc 0.9876342024539877\n",
      "\n",
      "Epoch 22. Loss: 0.036985952866290646, Train_acc 0.9877096036585366\n",
      "\n",
      "Epoch 22. Loss: 0.035254040214909285, Train_acc 0.9877367424242425\n",
      "\n",
      "Epoch 22. Loss: 0.03667726227953419, Train_acc 0.9877164909638554\n",
      "\n",
      "Epoch 22. Loss: 0.03573654652518975, Train_acc 0.9876964820359282\n",
      "\n",
      "Epoch 22. Loss: 0.04129540378644717, Train_acc 0.9876302083333334\n",
      "\n",
      "Epoch 22. Loss: 0.040786299822878715, Train_acc 0.9876109467455622\n",
      "\n",
      "Epoch 22. Loss: 0.04040386934711207, Train_acc 0.9875919117647058\n",
      "\n",
      "Epoch 22. Loss: 0.04135553383499684, Train_acc 0.9874817251461988\n",
      "\n",
      "Epoch 22. Loss: 0.04205591576102646, Train_acc 0.9874182412790697\n",
      "\n",
      "Epoch 22. Loss: 0.04550148484232967, Train_acc 0.9872651734104047\n",
      "\n",
      "Epoch 22. Loss: 0.04220669995656263, Train_acc 0.9873383620689655\n",
      "\n",
      "Epoch 22. Loss: 0.0398584953478931, Train_acc 0.9873660714285715\n",
      "\n",
      "Epoch 22. Loss: 0.038695077548798196, Train_acc 0.9873490767045454\n",
      "\n",
      "Epoch 22. Loss: 0.036329402897843366, Train_acc 0.9873764124293786\n",
      "\n",
      "Epoch 22. Loss: 0.03754878844984351, Train_acc 0.9873156601123596\n",
      "\n",
      "Epoch 22. Loss: 0.03648402834237795, Train_acc 0.9872992318435754\n",
      "\n",
      "Epoch 22. Loss: 0.04057217130930288, Train_acc 0.9871961805555556\n",
      "\n",
      "Epoch 22. Loss: 0.03984845457855817, Train_acc 0.9871805939226519\n",
      "\n",
      "Epoch 22. Loss: 0.037822504409110155, Train_acc 0.9872081043956044\n",
      "\n",
      "Epoch 22. Loss: 0.03838952368613088, Train_acc 0.9871499316939891\n",
      "\n",
      "Epoch 22. Loss: 0.0349592528927267, Train_acc 0.9872197690217391\n",
      "\n",
      "Epoch 22. Loss: 0.03226743877869311, Train_acc 0.9872888513513514\n",
      "\n",
      "Epoch 22. Loss: 0.029850950476748916, Train_acc 0.987357190860215\n",
      "\n",
      "Epoch 22. Loss: 0.03778313902368233, Train_acc 0.9872994652406417\n",
      "\n",
      "Epoch 22. Loss: 0.04225850231066422, Train_acc 0.9872007978723404\n",
      "\n",
      "Epoch 22. Loss: 0.039651648342148155, Train_acc 0.9871858465608465\n",
      "\n",
      "Epoch 22. Loss: 0.03720451723221155, Train_acc 0.9872532894736842\n",
      "\n",
      "Epoch 22. Loss: 0.03437164609745036, Train_acc 0.9873200261780105\n",
      "\n",
      "Epoch 22. Loss: 0.03707571269674501, Train_acc 0.9873046875\n",
      "\n",
      "Epoch 22. Loss: 0.04174695111754598, Train_acc 0.9871680699481865\n",
      "\n",
      "Epoch 22. Loss: 0.04216852774420138, Train_acc 0.9871134020618557\n",
      "\n",
      "Epoch 22. Loss: 0.03911226643799623, Train_acc 0.9871794871794872\n",
      "\n",
      "Epoch 22. Loss: 0.047896706941833025, Train_acc 0.98704\n",
      "\n",
      "Epoch 23. Loss: 0.04558451746384197, Train_acc 0.9921875\n",
      "\n",
      "Epoch 23. Loss: 0.041932356576441766, Train_acc 0.99609375\n",
      "\n",
      "Epoch 23. Loss: 0.04699183006911192, Train_acc 0.9895833333333334\n",
      "\n",
      "Epoch 23. Loss: 0.05520835667695446, Train_acc 0.978515625\n",
      "\n",
      "Epoch 23. Loss: 0.06081082135301093, Train_acc 0.978125\n",
      "\n",
      "Epoch 23. Loss: 0.061883011846494015, Train_acc 0.9765625\n",
      "\n",
      "Epoch 23. Loss: 0.0659148501355213, Train_acc 0.9732142857142857\n",
      "\n",
      "Epoch 23. Loss: 0.0663594296871509, Train_acc 0.97265625\n",
      "\n",
      "Epoch 23. Loss: 0.06385834064771705, Train_acc 0.9748263888888888\n",
      "\n",
      "Epoch 23. Loss: 0.061883085265964026, Train_acc 0.97578125\n",
      "\n",
      "Epoch 23. Loss: 0.059029394354113716, Train_acc 0.9779829545454546\n",
      "\n",
      "Epoch 23. Loss: 0.061493415205796466, Train_acc 0.9765625\n",
      "\n",
      "Epoch 23. Loss: 0.059448694276022826, Train_acc 0.9765625\n",
      "\n",
      "Epoch 23. Loss: 0.05586605005312674, Train_acc 0.9776785714285714\n",
      "\n",
      "Epoch 23. Loss: 0.05362105838521164, Train_acc 0.9786458333333333\n",
      "\n",
      "Epoch 23. Loss: 0.05050249614921667, Train_acc 0.97998046875\n",
      "\n",
      "Epoch 23. Loss: 0.05079372869677058, Train_acc 0.9797794117647058\n",
      "\n",
      "Epoch 23. Loss: 0.04879871216487924, Train_acc 0.9796006944444444\n",
      "\n",
      "Epoch 23. Loss: 0.04614946021502054, Train_acc 0.9798519736842105\n",
      "\n",
      "Epoch 23. Loss: 0.04432459029285463, Train_acc 0.98046875\n",
      "\n",
      "Epoch 23. Loss: 0.044244662845686254, Train_acc 0.9802827380952381\n",
      "\n",
      "Epoch 23. Loss: 0.042167264304657434, Train_acc 0.9808238636363636\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23. Loss: 0.044320560767143656, Train_acc 0.9806385869565217\n",
      "\n",
      "Epoch 23. Loss: 0.043949460036059936, Train_acc 0.98046875\n",
      "\n",
      "Epoch 23. Loss: 0.04671691362246935, Train_acc 0.98\n",
      "\n",
      "Epoch 23. Loss: 0.04285903809608577, Train_acc 0.9807692307692307\n",
      "\n",
      "Epoch 23. Loss: 0.04063253027029239, Train_acc 0.9811921296296297\n",
      "\n",
      "Epoch 23. Loss: 0.04308338244403068, Train_acc 0.9807477678571429\n",
      "\n",
      "Epoch 23. Loss: 0.041182346348267763, Train_acc 0.9811422413793104\n",
      "\n",
      "Epoch 23. Loss: 0.04231022420910177, Train_acc 0.9809895833333333\n",
      "\n",
      "Epoch 23. Loss: 0.04096918514419059, Train_acc 0.9808467741935484\n",
      "\n",
      "Epoch 23. Loss: 0.03764564024849349, Train_acc 0.9814453125\n",
      "\n",
      "Epoch 23. Loss: 0.03545036891797436, Train_acc 0.9817708333333334\n",
      "\n",
      "Epoch 23. Loss: 0.03464170340924787, Train_acc 0.9820772058823529\n",
      "\n",
      "Epoch 23. Loss: 0.032016578153335994, Train_acc 0.9825892857142857\n",
      "\n",
      "Epoch 23. Loss: 0.032488191427794647, Train_acc 0.9826388888888888\n",
      "\n",
      "Epoch 23. Loss: 0.02986793716431339, Train_acc 0.9831081081081081\n",
      "\n",
      "Epoch 23. Loss: 0.028028364197290056, Train_acc 0.9835526315789473\n",
      "\n",
      "Epoch 23. Loss: 0.03543903846968065, Train_acc 0.9829727564102564\n",
      "\n",
      "Epoch 23. Loss: 0.033302787716050594, Train_acc 0.9833984375\n",
      "\n",
      "Epoch 23. Loss: 0.032905718892687244, Train_acc 0.983422256097561\n",
      "\n",
      "Epoch 23. Loss: 0.03143604245174558, Train_acc 0.9836309523809523\n",
      "\n",
      "Epoch 23. Loss: 0.03192636315275995, Train_acc 0.9838299418604651\n",
      "\n",
      "Epoch 23. Loss: 0.033422783636299684, Train_acc 0.9838423295454546\n",
      "\n",
      "Epoch 23. Loss: 0.03231711182586662, Train_acc 0.9838541666666667\n",
      "\n",
      "Epoch 23. Loss: 0.035755867453744816, Train_acc 0.9840353260869565\n",
      "\n",
      "Epoch 23. Loss: 0.03915186198860181, Train_acc 0.983876329787234\n",
      "\n",
      "Epoch 23. Loss: 0.03653204146230017, Train_acc 0.9842122395833334\n",
      "\n",
      "Epoch 23. Loss: 0.037604134111438356, Train_acc 0.984375\n",
      "\n",
      "Epoch 23. Loss: 0.037753231074363736, Train_acc 0.98421875\n",
      "\n",
      "Epoch 23. Loss: 0.04042069472010501, Train_acc 0.9840686274509803\n",
      "\n",
      "Epoch 23. Loss: 0.03957793771149726, Train_acc 0.9842247596153846\n",
      "\n",
      "Epoch 23. Loss: 0.036249837163511024, Train_acc 0.9845224056603774\n",
      "\n",
      "Epoch 23. Loss: 0.03518235278137604, Train_acc 0.9845196759259259\n",
      "\n",
      "Epoch 23. Loss: 0.03285897419161868, Train_acc 0.9848011363636363\n",
      "\n",
      "Epoch 23. Loss: 0.03161355647719447, Train_acc 0.9850725446428571\n",
      "\n",
      "Epoch 23. Loss: 0.031489188052206143, Train_acc 0.9850603070175439\n",
      "\n",
      "Epoch 23. Loss: 0.037736503401686765, Train_acc 0.9845096982758621\n",
      "\n",
      "Epoch 23. Loss: 0.03575505483385028, Train_acc 0.9847722457627118\n",
      "\n",
      "Epoch 23. Loss: 0.03341409602674337, Train_acc 0.9848958333333333\n",
      "\n",
      "Epoch 23. Loss: 0.037102300276569945, Train_acc 0.9847592213114754\n",
      "\n",
      "Epoch 23. Loss: 0.04171264024097838, Train_acc 0.984375\n",
      "\n",
      "Epoch 23. Loss: 0.03878682085739778, Train_acc 0.9846230158730159\n",
      "\n",
      "Epoch 23. Loss: 0.0360108830007959, Train_acc 0.98486328125\n",
      "\n",
      "Epoch 23. Loss: 0.03578548662123519, Train_acc 0.9849759615384616\n",
      "\n",
      "Epoch 23. Loss: 0.0365614122801194, Train_acc 0.9849668560606061\n",
      "\n",
      "Epoch 23. Loss: 0.034078935215905555, Train_acc 0.9851912313432836\n",
      "\n",
      "Epoch 23. Loss: 0.032624140803547426, Train_acc 0.9852941176470589\n",
      "\n",
      "Epoch 23. Loss: 0.030980853557168, Train_acc 0.9853940217391305\n",
      "\n",
      "Epoch 23. Loss: 0.028853545139353173, Train_acc 0.9856026785714286\n",
      "\n",
      "Epoch 23. Loss: 0.02808526397507253, Train_acc 0.9856954225352113\n",
      "\n",
      "Epoch 23. Loss: 0.03085570364380654, Train_acc 0.9854600694444444\n",
      "\n",
      "Epoch 23. Loss: 0.03695712234841087, Train_acc 0.9850171232876712\n",
      "\n",
      "Epoch 23. Loss: 0.03552765340000062, Train_acc 0.9851140202702703\n",
      "\n",
      "Epoch 23. Loss: 0.033677825171259064, Train_acc 0.9852083333333334\n",
      "\n",
      "Epoch 23. Loss: 0.030727704507267792, Train_acc 0.9854029605263158\n",
      "\n",
      "Epoch 23. Loss: 0.033743087329408214, Train_acc 0.9851866883116883\n",
      "\n",
      "Epoch 23. Loss: 0.033999787757939715, Train_acc 0.985176282051282\n",
      "\n",
      "Epoch 23. Loss: 0.031859266488385156, Train_acc 0.9852650316455697\n",
      "\n",
      "Epoch 23. Loss: 0.03041923103806253, Train_acc 0.9853515625\n",
      "\n",
      "Epoch 23. Loss: 0.02881481606283971, Train_acc 0.9855324074074074\n",
      "\n",
      "Epoch 23. Loss: 0.026979474389724627, Train_acc 0.9856135670731707\n",
      "\n",
      "Epoch 23. Loss: 0.025753389147674468, Train_acc 0.9857868975903614\n",
      "\n",
      "Epoch 23. Loss: 0.027856161011238778, Train_acc 0.9857700892857143\n",
      "\n",
      "Epoch 23. Loss: 0.025962501131427184, Train_acc 0.9859375\n",
      "\n",
      "Epoch 23. Loss: 0.025065466378270295, Train_acc 0.9860101744186046\n",
      "\n",
      "Epoch 23. Loss: 0.023289447445024883, Train_acc 0.9861709770114943\n",
      "\n",
      "Epoch 23. Loss: 0.024033256994202588, Train_acc 0.9861505681818182\n",
      "\n",
      "Epoch 23. Loss: 0.023059790471060444, Train_acc 0.9863061797752809\n",
      "\n",
      "Epoch 23. Loss: 0.02331915361183587, Train_acc 0.9863715277777778\n",
      "\n",
      "Epoch 23. Loss: 0.023569121286252468, Train_acc 0.9864354395604396\n",
      "\n",
      "Epoch 23. Loss: 0.022519794993084073, Train_acc 0.9864979619565217\n",
      "\n",
      "Epoch 23. Loss: 0.022508149386180697, Train_acc 0.9865591397849462\n",
      "\n",
      "Epoch 23. Loss: 0.02257522739386552, Train_acc 0.9866190159574468\n",
      "\n",
      "Epoch 23. Loss: 0.021564224227511825, Train_acc 0.9867598684210527\n",
      "\n",
      "Epoch 23. Loss: 0.021108101596752353, Train_acc 0.98681640625\n",
      "\n",
      "Epoch 23. Loss: 0.020774585715221953, Train_acc 0.9867912371134021\n",
      "\n",
      "Epoch 23. Loss: 0.019573094325918788, Train_acc 0.9869260204081632\n",
      "\n",
      "Epoch 23. Loss: 0.018794035355143696, Train_acc 0.9870580808080808\n",
      "\n",
      "Epoch 23. Loss: 0.017873795444422618, Train_acc 0.9871875\n",
      "\n",
      "[Epoch 23 Batch 100] Loss: 0.017188565386522105 Training: accuracy=0.987237\n",
      "Epoch 23. Loss: 0.017188565386522105, Train_acc 0.987237004950495\n",
      "\n",
      "Epoch 23. Loss: 0.017330163153876327, Train_acc 0.9872855392156863\n",
      "\n",
      "Epoch 23. Loss: 0.01656683338392031, Train_acc 0.9874089805825242\n",
      "\n",
      "Epoch 23. Loss: 0.01605298379994856, Train_acc 0.9875300480769231\n",
      "\n",
      "Epoch 23. Loss: 0.015435754596627592, Train_acc 0.9876488095238095\n",
      "\n",
      "Epoch 23. Loss: 0.01757258602032379, Train_acc 0.9876179245283019\n",
      "\n",
      "Epoch 23. Loss: 0.018501813811504682, Train_acc 0.9875876168224299\n",
      "\n",
      "Epoch 23. Loss: 0.01755291957254157, Train_acc 0.9877025462962963\n",
      "\n",
      "Epoch 23. Loss: 0.016111647445253542, Train_acc 0.9878153669724771\n",
      "\n",
      "Epoch 23. Loss: 0.015157641930468688, Train_acc 0.9879261363636364\n",
      "\n",
      "Epoch 23. Loss: 0.014281812947768995, Train_acc 0.9880349099099099\n",
      "\n",
      "Epoch 23. Loss: 0.023862364418905106, Train_acc 0.98779296875\n",
      "\n",
      "Epoch 23. Loss: 0.024587699236811214, Train_acc 0.9878318584070797\n",
      "\n",
      "Epoch 23. Loss: 0.027030421163744642, Train_acc 0.9878015350877193\n",
      "\n",
      "Epoch 23. Loss: 0.03410337004015468, Train_acc 0.9875679347826087\n",
      "\n",
      "Epoch 23. Loss: 0.03606647520914336, Train_acc 0.9874730603448276\n",
      "\n",
      "Epoch 23. Loss: 0.033190006100279036, Train_acc 0.9875801282051282\n",
      "\n",
      "Epoch 23. Loss: 0.030466440478168676, Train_acc 0.9876853813559322\n",
      "\n",
      "Epoch 23. Loss: 0.02894422722313054, Train_acc 0.9877888655462185\n",
      "\n",
      "Epoch 23. Loss: 0.037721027992247774, Train_acc 0.9875\n",
      "\n",
      "Epoch 23. Loss: 0.03697960494048527, Train_acc 0.987474173553719\n",
      "\n",
      "Epoch 23. Loss: 0.03761072756129919, Train_acc 0.9874487704918032\n",
      "\n",
      "Epoch 23. Loss: 0.03790033580015676, Train_acc 0.9874237804878049\n",
      "\n",
      "Epoch 23. Loss: 0.0353959012059919, Train_acc 0.9875252016129032\n",
      "\n",
      "Epoch 23. Loss: 0.036392307999302625, Train_acc 0.9874375\n",
      "\n",
      "Epoch 23. Loss: 0.03492459957829387, Train_acc 0.9874751984126984\n",
      "\n",
      "Epoch 23. Loss: 0.03713575203744714, Train_acc 0.9874507874015748\n",
      "\n",
      "Epoch 23. Loss: 0.03614253356630931, Train_acc 0.98748779296875\n",
      "\n",
      "Epoch 23. Loss: 0.033587981317120756, Train_acc 0.9875847868217055\n",
      "\n",
      "Epoch 23. Loss: 0.038517074930976, Train_acc 0.9874399038461539\n",
      "\n",
      "Epoch 23. Loss: 0.03846639959363059, Train_acc 0.9874165076335878\n",
      "\n",
      "Epoch 23. Loss: 0.04028498107207938, Train_acc 0.9872750946969697\n",
      "\n",
      "Epoch 23. Loss: 0.0396144007803183, Train_acc 0.987312030075188\n",
      "\n",
      "Epoch 23. Loss: 0.03908464857886861, Train_acc 0.9873484141791045\n",
      "\n",
      "Epoch 23. Loss: 0.03613215523765055, Train_acc 0.9874421296296296\n",
      "\n",
      "Epoch 23. Loss: 0.033856460212667895, Train_acc 0.9874770220588235\n",
      "\n",
      "Epoch 23. Loss: 0.032576559119522674, Train_acc 0.9875114051094891\n",
      "\n",
      "Epoch 23. Loss: 0.03255383838692317, Train_acc 0.9874886775362319\n",
      "\n",
      "Epoch 23. Loss: 0.03359644490014621, Train_acc 0.9874662769784173\n",
      "\n",
      "Epoch 23. Loss: 0.03459664548216261, Train_acc 0.9874441964285714\n",
      "\n",
      "Epoch 23. Loss: 0.03734805463055966, Train_acc 0.9874224290780141\n",
      "\n",
      "Epoch 23. Loss: 0.035150397076906544, Train_acc 0.9875110035211268\n",
      "\n",
      "Epoch 23. Loss: 0.03197131976439963, Train_acc 0.9875983391608392\n",
      "\n",
      "Epoch 23. Loss: 0.030308668203244304, Train_acc 0.9876302083333334\n",
      "\n",
      "Epoch 23. Loss: 0.03154587504603538, Train_acc 0.9875538793103448\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23. Loss: 0.03279987356666988, Train_acc 0.9875321061643836\n",
      "\n",
      "Epoch 23. Loss: 0.030697728938796513, Train_acc 0.9876169217687075\n",
      "\n",
      "Epoch 23. Loss: 0.03186733789468264, Train_acc 0.9875950168918919\n",
      "\n",
      "Epoch 23. Loss: 0.03308578409753253, Train_acc 0.9875734060402684\n",
      "\n",
      "Epoch 23. Loss: 0.030371531423944324, Train_acc 0.98765625\n",
      "\n",
      "Epoch 23. Loss: 0.027845076838449917, Train_acc 0.9877379966887417\n",
      "\n",
      "Epoch 23. Loss: 0.02659195273606445, Train_acc 0.9877672697368421\n",
      "\n",
      "Epoch 23. Loss: 0.033601375158027996, Train_acc 0.9875919117647058\n",
      "\n",
      "Epoch 23. Loss: 0.03364207191949742, Train_acc 0.9876217532467533\n",
      "\n",
      "Epoch 23. Loss: 0.03241220069991639, Train_acc 0.9876512096774194\n",
      "\n",
      "Epoch 23. Loss: 0.034992875484231925, Train_acc 0.9875300480769231\n",
      "\n",
      "Epoch 23. Loss: 0.03479202404106004, Train_acc 0.9875099522292994\n",
      "\n",
      "Epoch 23. Loss: 0.034149821865418636, Train_acc 0.9874901107594937\n",
      "\n",
      "Epoch 23. Loss: 0.0329053949724368, Train_acc 0.9875687893081762\n",
      "\n",
      "Epoch 23. Loss: 0.031345227859383686, Train_acc 0.98759765625\n",
      "\n",
      "Epoch 23. Loss: 0.034262381793826104, Train_acc 0.9874805900621118\n",
      "\n",
      "Epoch 23. Loss: 0.037294559450539305, Train_acc 0.9873649691358025\n",
      "\n",
      "Epoch 23. Loss: 0.03546180823885711, Train_acc 0.987394555214724\n",
      "\n",
      "Epoch 23. Loss: 0.03410265407958608, Train_acc 0.987376143292683\n",
      "\n",
      "Epoch 23. Loss: 0.03559133689402623, Train_acc 0.987310606060606\n",
      "\n",
      "Epoch 23. Loss: 0.03742433031617775, Train_acc 0.987292921686747\n",
      "\n",
      "Epoch 23. Loss: 0.03515979361357547, Train_acc 0.9873222305389222\n",
      "\n",
      "Epoch 23. Loss: 0.03347334157069556, Train_acc 0.9873511904761905\n",
      "\n",
      "Epoch 23. Loss: 0.03480321890687971, Train_acc 0.9873335798816568\n",
      "\n",
      "Epoch 23. Loss: 0.03251952098228957, Train_acc 0.9873621323529411\n",
      "\n",
      "Epoch 23. Loss: 0.0341562375404098, Train_acc 0.98734466374269\n",
      "\n",
      "Epoch 23. Loss: 0.031911512294649336, Train_acc 0.9874182412790697\n",
      "\n",
      "Epoch 23. Loss: 0.029317667080154347, Train_acc 0.9874909682080925\n",
      "\n",
      "Epoch 23. Loss: 0.02800215929137796, Train_acc 0.9875628591954023\n",
      "\n",
      "Epoch 23. Loss: 0.028315584765855637, Train_acc 0.9875892857142857\n",
      "\n",
      "Epoch 23. Loss: 0.028564506089971214, Train_acc 0.9875710227272727\n",
      "\n",
      "Epoch 23. Loss: 0.028466751783745664, Train_acc 0.987597104519774\n",
      "\n",
      "Epoch 23. Loss: 0.029031351753762823, Train_acc 0.9875790028089888\n",
      "\n",
      "Epoch 23. Loss: 0.02676378402555716, Train_acc 0.9876483938547486\n",
      "\n",
      "Epoch 23. Loss: 0.02552670813078939, Train_acc 0.9877170138888889\n",
      "\n",
      "Epoch 23. Loss: 0.02358117395468288, Train_acc 0.9877848756906077\n",
      "\n",
      "Epoch 23. Loss: 0.02284309348160982, Train_acc 0.9877661401098901\n",
      "\n",
      "Epoch 23. Loss: 0.021001058327659607, Train_acc 0.9878329918032787\n",
      "\n",
      "Epoch 23. Loss: 0.019557229855288242, Train_acc 0.987899116847826\n",
      "\n",
      "Epoch 23. Loss: 0.02072827563759313, Train_acc 0.9879222972972973\n",
      "\n",
      "Epoch 23. Loss: 0.021914289931147926, Train_acc 0.9879032258064516\n",
      "\n",
      "Epoch 23. Loss: 0.02227156616570619, Train_acc 0.9878843582887701\n",
      "\n",
      "Epoch 23. Loss: 0.023489501392740614, Train_acc 0.9879072473404256\n",
      "\n",
      "Epoch 23. Loss: 0.02145614676481361, Train_acc 0.9879712301587301\n",
      "\n",
      "Epoch 23. Loss: 0.020952308687322212, Train_acc 0.9879934210526315\n",
      "\n",
      "Epoch 23. Loss: 0.019160732237848227, Train_acc 0.9880562827225131\n",
      "\n",
      "Epoch 23. Loss: 0.01808398172633581, Train_acc 0.9881184895833334\n",
      "\n",
      "Epoch 23. Loss: 0.023682502258211967, Train_acc 0.9880586139896373\n",
      "\n",
      "Epoch 23. Loss: 0.029752325876108345, Train_acc 0.9880798969072165\n",
      "\n",
      "Epoch 23. Loss: 0.02753181381990153, Train_acc 0.9881410256410257\n",
      "\n",
      "Epoch 23. Loss: 0.025595041168954717, Train_acc 0.98816\n",
      "\n",
      "Epoch 24. Loss: 0.025847000974321438, Train_acc 0.9921875\n",
      "\n",
      "Epoch 24. Loss: 0.025611964588973586, Train_acc 0.9921875\n",
      "\n",
      "Epoch 24. Loss: 0.02642256637717515, Train_acc 0.9921875\n",
      "\n",
      "Epoch 24. Loss: 0.025995507421838312, Train_acc 0.990234375\n",
      "\n",
      "Epoch 24. Loss: 0.0254338433960799, Train_acc 0.990625\n",
      "\n",
      "Epoch 24. Loss: 0.031244643833016478, Train_acc 0.9856770833333334\n",
      "\n",
      "Epoch 24. Loss: 0.028622919482685735, Train_acc 0.9877232142857143\n",
      "\n",
      "Epoch 24. Loss: 0.026828956972984323, Train_acc 0.9892578125\n",
      "\n",
      "Epoch 24. Loss: 0.028761637095893487, Train_acc 0.9878472222222222\n",
      "\n",
      "Epoch 24. Loss: 0.03106801156784749, Train_acc 0.9859375\n",
      "\n",
      "Epoch 24. Loss: 0.030945224005749727, Train_acc 0.9865056818181818\n",
      "\n",
      "Epoch 24. Loss: 0.031021270101163602, Train_acc 0.986328125\n",
      "\n",
      "Epoch 24. Loss: 0.02997594031235023, Train_acc 0.9873798076923077\n",
      "\n",
      "Epoch 24. Loss: 0.03433334635979334, Train_acc 0.9854910714285714\n",
      "\n",
      "Epoch 24. Loss: 0.034185882424888604, Train_acc 0.9854166666666667\n",
      "\n",
      "Epoch 24. Loss: 0.03407097400627517, Train_acc 0.9853515625\n",
      "\n",
      "Epoch 24. Loss: 0.03168072169409976, Train_acc 0.9857536764705882\n",
      "\n",
      "Epoch 24. Loss: 0.03311233102130996, Train_acc 0.9861111111111112\n",
      "\n",
      "Epoch 24. Loss: 0.03229435313208199, Train_acc 0.9864309210526315\n",
      "\n",
      "Epoch 24. Loss: 0.030740679309934047, Train_acc 0.98671875\n",
      "\n",
      "Epoch 24. Loss: 0.034549328094276494, Train_acc 0.9862351190476191\n",
      "\n",
      "Epoch 24. Loss: 0.03196310169001166, Train_acc 0.9868607954545454\n",
      "\n",
      "Epoch 24. Loss: 0.030118795855341055, Train_acc 0.9870923913043478\n",
      "\n",
      "Epoch 24. Loss: 0.0276367429351041, Train_acc 0.9876302083333334\n",
      "\n",
      "Epoch 24. Loss: 0.03277936847107672, Train_acc 0.9871875\n",
      "\n",
      "Epoch 24. Loss: 0.03144189659741876, Train_acc 0.9873798076923077\n",
      "\n",
      "Epoch 24. Loss: 0.03156173439908645, Train_acc 0.9872685185185185\n",
      "\n",
      "Epoch 24. Loss: 0.033832635019021826, Train_acc 0.9871651785714286\n",
      "\n",
      "Epoch 24. Loss: 0.03349335800152802, Train_acc 0.9870689655172413\n",
      "\n",
      "Epoch 24. Loss: 0.0326338993210356, Train_acc 0.9869791666666666\n",
      "\n",
      "Epoch 24. Loss: 0.03245193280566579, Train_acc 0.9866431451612904\n",
      "\n",
      "Epoch 24. Loss: 0.03161997922768157, Train_acc 0.98681640625\n",
      "\n",
      "Epoch 24. Loss: 0.029604543888657936, Train_acc 0.9872159090909091\n",
      "\n",
      "Epoch 24. Loss: 0.028721319193324133, Train_acc 0.9873621323529411\n",
      "\n",
      "Epoch 24. Loss: 0.03162927096010508, Train_acc 0.9870535714285714\n",
      "\n",
      "Epoch 24. Loss: 0.030548877067159967, Train_acc 0.9871961805555556\n",
      "\n",
      "Epoch 24. Loss: 0.030038174879662413, Train_acc 0.9871199324324325\n",
      "\n",
      "Epoch 24. Loss: 0.02772170222962995, Train_acc 0.9874588815789473\n",
      "\n",
      "Epoch 24. Loss: 0.02717812732307702, Train_acc 0.9875801282051282\n",
      "\n",
      "Epoch 24. Loss: 0.028730379421549348, Train_acc 0.9875\n",
      "\n",
      "Epoch 24. Loss: 0.026822963919374918, Train_acc 0.9876143292682927\n",
      "\n",
      "Epoch 24. Loss: 0.024827940886363604, Train_acc 0.9879092261904762\n",
      "\n",
      "Epoch 24. Loss: 0.023855169192086356, Train_acc 0.9880087209302325\n",
      "\n",
      "Epoch 24. Loss: 0.022613722637412577, Train_acc 0.98828125\n",
      "\n",
      "Epoch 24. Loss: 0.02135858779113081, Train_acc 0.9885416666666667\n",
      "\n",
      "Epoch 24. Loss: 0.019902542849650266, Train_acc 0.9887907608695652\n",
      "\n",
      "Epoch 24. Loss: 0.019463589410725488, Train_acc 0.989029255319149\n",
      "\n",
      "Epoch 24. Loss: 0.01997561212248497, Train_acc 0.9890950520833334\n",
      "\n",
      "Epoch 24. Loss: 0.01832264957606995, Train_acc 0.9893176020408163\n",
      "\n",
      "Epoch 24. Loss: 0.018275076578082475, Train_acc 0.989375\n",
      "\n",
      "Epoch 24. Loss: 0.018587160532196015, Train_acc 0.9894301470588235\n",
      "\n",
      "Epoch 24. Loss: 0.018212508584874554, Train_acc 0.9894831730769231\n",
      "\n",
      "Epoch 24. Loss: 0.018087821238473967, Train_acc 0.9895341981132075\n",
      "\n",
      "Epoch 24. Loss: 0.016627650360489712, Train_acc 0.9897280092592593\n",
      "\n",
      "Epoch 24. Loss: 0.01664146488925054, Train_acc 0.9896306818181818\n",
      "\n",
      "Epoch 24. Loss: 0.016215846666874596, Train_acc 0.9896763392857143\n",
      "\n",
      "Epoch 24. Loss: 0.020637651439769963, Train_acc 0.9895833333333334\n",
      "\n",
      "Epoch 24. Loss: 0.019526996230719, Train_acc 0.9897629310344828\n",
      "\n",
      "Epoch 24. Loss: 0.01894785454032199, Train_acc 0.9899364406779662\n",
      "\n",
      "Epoch 24. Loss: 0.020104678259706882, Train_acc 0.9899739583333333\n",
      "\n",
      "Epoch 24. Loss: 0.018449408970735718, Train_acc 0.9901383196721312\n",
      "\n",
      "Epoch 24. Loss: 0.020025417428429948, Train_acc 0.9900453629032258\n",
      "\n",
      "Epoch 24. Loss: 0.02009246797521355, Train_acc 0.9900793650793651\n",
      "\n",
      "Epoch 24. Loss: 0.019750895436043525, Train_acc 0.9901123046875\n",
      "\n",
      "Epoch 24. Loss: 0.019512827174754426, Train_acc 0.9901442307692307\n",
      "\n",
      "Epoch 24. Loss: 0.017845377957276837, Train_acc 0.9902935606060606\n",
      "\n",
      "Epoch 24. Loss: 0.016442146813528836, Train_acc 0.9904384328358209\n",
      "\n",
      "Epoch 24. Loss: 0.016401881015888242, Train_acc 0.9904641544117647\n",
      "\n",
      "Epoch 24. Loss: 0.015599355916611603, Train_acc 0.9906023550724637\n",
      "\n",
      "Epoch 24. Loss: 0.014240517735122667, Train_acc 0.9907366071428572\n",
      "\n",
      "Epoch 24. Loss: 0.012967521326014274, Train_acc 0.9908670774647887\n",
      "\n",
      "Epoch 24. Loss: 0.015688683279993124, Train_acc 0.9908854166666666\n",
      "\n",
      "Epoch 24. Loss: 0.014667749275543082, Train_acc 0.9910102739726028\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24. Loss: 0.01488366301635902, Train_acc 0.9910261824324325\n",
      "\n",
      "Epoch 24. Loss: 0.015033202178299435, Train_acc 0.9910416666666667\n",
      "\n",
      "Epoch 24. Loss: 0.014512128787803657, Train_acc 0.9911595394736842\n",
      "\n",
      "Epoch 24. Loss: 0.013430483216666884, Train_acc 0.9912743506493507\n",
      "\n",
      "Epoch 24. Loss: 0.012306613444014229, Train_acc 0.991386217948718\n",
      "\n",
      "Epoch 24. Loss: 0.013340303869894599, Train_acc 0.9912974683544303\n",
      "\n",
      "Epoch 24. Loss: 0.015149820585714091, Train_acc 0.99111328125\n",
      "\n",
      "Epoch 24. Loss: 0.016572098052203336, Train_acc 0.9911265432098766\n",
      "\n",
      "Epoch 24. Loss: 0.015415514829635333, Train_acc 0.991234756097561\n",
      "\n",
      "Epoch 24. Loss: 0.01523213024247859, Train_acc 0.991246234939759\n",
      "\n",
      "Epoch 24. Loss: 0.02219990210511542, Train_acc 0.9910714285714286\n",
      "\n",
      "Epoch 24. Loss: 0.020581983813151034, Train_acc 0.9911764705882353\n",
      "\n",
      "Epoch 24. Loss: 0.021033270989511296, Train_acc 0.9910973837209303\n",
      "\n",
      "Epoch 24. Loss: 0.020117279124695554, Train_acc 0.9911997126436781\n",
      "\n",
      "Epoch 24. Loss: 0.018429201639388645, Train_acc 0.9912997159090909\n",
      "\n",
      "Epoch 24. Loss: 0.01783953516262291, Train_acc 0.991309691011236\n",
      "\n",
      "Epoch 24. Loss: 0.017708388271130783, Train_acc 0.9913194444444444\n",
      "\n",
      "Epoch 24. Loss: 0.018497594455359277, Train_acc 0.9913289835164835\n",
      "\n",
      "Epoch 24. Loss: 0.01953231443567088, Train_acc 0.9913383152173914\n",
      "\n",
      "Epoch 24. Loss: 0.01908578810858438, Train_acc 0.9913474462365591\n",
      "\n",
      "Epoch 24. Loss: 0.01782727711142042, Train_acc 0.991439494680851\n",
      "\n",
      "Epoch 24. Loss: 0.016225571709976544, Train_acc 0.9915296052631579\n",
      "\n",
      "Epoch 24. Loss: 0.01616826771477397, Train_acc 0.9916178385416666\n",
      "\n",
      "Epoch 24. Loss: 0.015395373422916553, Train_acc 0.9917042525773195\n",
      "\n",
      "Epoch 24. Loss: 0.023694438027455647, Train_acc 0.9913105867346939\n",
      "\n",
      "Epoch 24. Loss: 0.0224852940026947, Train_acc 0.9913983585858586\n",
      "\n",
      "Epoch 24. Loss: 0.025569268442752494, Train_acc 0.99125\n",
      "\n",
      "[Epoch 24 Batch 100] Loss: 0.024174325766470314 Training: accuracy=0.991259\n",
      "Epoch 24. Loss: 0.024174325766470314, Train_acc 0.9912592821782178\n",
      "\n",
      "Epoch 24. Loss: 0.028263000937378064, Train_acc 0.9910386029411765\n",
      "\n",
      "Epoch 24. Loss: 0.028265671581395556, Train_acc 0.9910497572815534\n",
      "\n",
      "Epoch 24. Loss: 0.025964842349619946, Train_acc 0.9911358173076923\n",
      "\n",
      "Epoch 24. Loss: 0.023742324920294836, Train_acc 0.9912202380952381\n",
      "\n",
      "Epoch 24. Loss: 0.024638890232263344, Train_acc 0.9912293632075472\n",
      "\n",
      "Epoch 24. Loss: 0.02849398464466781, Train_acc 0.9911653037383178\n",
      "\n",
      "Epoch 24. Loss: 0.029777380023947215, Train_acc 0.9911024305555556\n",
      "\n",
      "Epoch 24. Loss: 0.028034047509328298, Train_acc 0.9911123853211009\n",
      "\n",
      "Epoch 24. Loss: 0.02701406346270064, Train_acc 0.9911221590909091\n",
      "\n",
      "Epoch 24. Loss: 0.026648304423766905, Train_acc 0.9911317567567568\n",
      "\n",
      "Epoch 24. Loss: 0.027593172247181153, Train_acc 0.9910714285714286\n",
      "\n",
      "Epoch 24. Loss: 0.027008518566164208, Train_acc 0.9911504424778761\n",
      "\n",
      "Epoch 24. Loss: 0.02666634003621891, Train_acc 0.9910910087719298\n",
      "\n",
      "Epoch 24. Loss: 0.025964761274777842, Train_acc 0.9911005434782608\n",
      "\n",
      "Epoch 24. Loss: 0.024866630432954128, Train_acc 0.9911772629310345\n",
      "\n",
      "Epoch 24. Loss: 0.02527853791232469, Train_acc 0.9910523504273504\n",
      "\n",
      "Epoch 24. Loss: 0.02787399428470936, Train_acc 0.9909957627118644\n",
      "\n",
      "Epoch 24. Loss: 0.025614366325444043, Train_acc 0.9910714285714286\n",
      "\n",
      "Epoch 24. Loss: 0.023568369845857674, Train_acc 0.9911458333333333\n",
      "\n",
      "Epoch 24. Loss: 0.023341129333058406, Train_acc 0.9911544421487604\n",
      "\n",
      "Epoch 24. Loss: 0.021304214890923566, Train_acc 0.9912269467213115\n",
      "\n",
      "Epoch 24. Loss: 0.020179649908357678, Train_acc 0.9912982723577236\n",
      "\n",
      "Epoch 24. Loss: 0.019224087978017765, Train_acc 0.9913684475806451\n",
      "\n",
      "Epoch 24. Loss: 0.01745339615617687, Train_acc 0.9914375\n",
      "\n",
      "Epoch 24. Loss: 0.018395510205398452, Train_acc 0.9913194444444444\n",
      "\n",
      "Epoch 24. Loss: 0.01934552771339159, Train_acc 0.991326279527559\n",
      "\n",
      "Epoch 24. Loss: 0.021440592773163385, Train_acc 0.9912109375\n",
      "\n",
      "Epoch 24. Loss: 0.022220788405004802, Train_acc 0.991218507751938\n",
      "\n",
      "Epoch 24. Loss: 0.021058692024496492, Train_acc 0.9912860576923077\n",
      "\n",
      "Epoch 24. Loss: 0.0207320432615405, Train_acc 0.9912929389312977\n",
      "\n",
      "Epoch 24. Loss: 0.02929624445010355, Train_acc 0.9912405303030303\n",
      "\n",
      "Epoch 24. Loss: 0.028797228501163105, Train_acc 0.9912476503759399\n",
      "\n",
      "Epoch 24. Loss: 0.028299869961370988, Train_acc 0.9912546641791045\n",
      "\n",
      "Epoch 24. Loss: 0.026753839843121137, Train_acc 0.9913194444444444\n",
      "\n",
      "Epoch 24. Loss: 0.024219837994725525, Train_acc 0.9913832720588235\n",
      "\n",
      "Epoch 24. Loss: 0.024095898981110173, Train_acc 0.9913891423357665\n",
      "\n",
      "Epoch 24. Loss: 0.023175048148825095, Train_acc 0.9913949275362319\n",
      "\n",
      "Epoch 24. Loss: 0.02794737575906008, Train_acc 0.9912882194244604\n",
      "\n",
      "Epoch 24. Loss: 0.02623627781978985, Train_acc 0.9913504464285714\n",
      "\n",
      "Epoch 24. Loss: 0.02865366220574147, Train_acc 0.991300975177305\n",
      "\n",
      "Epoch 24. Loss: 0.028502323822086152, Train_acc 0.9912522007042254\n",
      "\n",
      "Epoch 24. Loss: 0.026792040422622947, Train_acc 0.9913133741258742\n",
      "\n",
      "Epoch 24. Loss: 0.026824287061451006, Train_acc 0.9913194444444444\n",
      "\n",
      "Epoch 24. Loss: 0.025012959470204824, Train_acc 0.9913793103448276\n",
      "\n",
      "Epoch 24. Loss: 0.02321330406950621, Train_acc 0.9914383561643836\n",
      "\n",
      "Epoch 24. Loss: 0.02318416042941846, Train_acc 0.9914434523809523\n",
      "\n",
      "Epoch 24. Loss: 0.02547961104349528, Train_acc 0.9914484797297297\n",
      "\n",
      "Epoch 24. Loss: 0.024654056162562082, Train_acc 0.9915058724832215\n",
      "\n",
      "Epoch 24. Loss: 0.02409622698062013, Train_acc 0.9915625\n",
      "\n",
      "Epoch 24. Loss: 0.02268393397212044, Train_acc 0.9916183774834437\n",
      "\n",
      "Epoch 24. Loss: 0.020690003665954013, Train_acc 0.9916735197368421\n",
      "\n",
      "Epoch 24. Loss: 0.02098883581102205, Train_acc 0.9916768790849673\n",
      "\n",
      "Epoch 24. Loss: 0.023856685089531357, Train_acc 0.9916294642857143\n",
      "\n",
      "Epoch 24. Loss: 0.025155288452621834, Train_acc 0.9915826612903226\n",
      "\n",
      "Epoch 24. Loss: 0.023260425381109003, Train_acc 0.9916366185897436\n",
      "\n",
      "Epoch 24. Loss: 0.021292681589867073, Train_acc 0.9916898885350318\n",
      "\n",
      "Epoch 24. Loss: 0.020136420606951772, Train_acc 0.9917424841772152\n",
      "\n",
      "Epoch 24. Loss: 0.019209404748124652, Train_acc 0.9917944182389937\n",
      "\n",
      "Epoch 24. Loss: 0.023650995607473947, Train_acc 0.99169921875\n",
      "\n",
      "Epoch 24. Loss: 0.02516998839256033, Train_acc 0.991702251552795\n",
      "\n",
      "Epoch 24. Loss: 0.024423610905202012, Train_acc 0.9917052469135802\n",
      "\n",
      "Epoch 24. Loss: 0.023966192332856462, Train_acc 0.9916602760736196\n",
      "\n",
      "Epoch 24. Loss: 0.02419832065965468, Train_acc 0.9916158536585366\n",
      "\n",
      "Epoch 24. Loss: 0.0219806166752717, Train_acc 0.9916666666666667\n",
      "\n",
      "Epoch 24. Loss: 0.021118567043352823, Train_acc 0.9917168674698795\n",
      "\n",
      "Epoch 24. Loss: 0.019313178260490626, Train_acc 0.9917664670658682\n",
      "\n",
      "Epoch 24. Loss: 0.017586538267685768, Train_acc 0.9918154761904762\n",
      "\n",
      "Epoch 24. Loss: 0.01630274915103954, Train_acc 0.9918639053254438\n",
      "\n",
      "Epoch 24. Loss: 0.01534770764288165, Train_acc 0.9919117647058824\n",
      "\n",
      "Epoch 24. Loss: 0.015643378010781327, Train_acc 0.9919133771929824\n",
      "\n",
      "Epoch 24. Loss: 0.01619024157052492, Train_acc 0.9918695494186046\n",
      "\n",
      "Epoch 24. Loss: 0.020622567053365008, Train_acc 0.9918262283236994\n",
      "\n",
      "Epoch 24. Loss: 0.01978855960732159, Train_acc 0.9918283045977011\n",
      "\n",
      "Epoch 24. Loss: 0.018731077647198353, Train_acc 0.991875\n",
      "\n",
      "Epoch 24. Loss: 0.021305362256755632, Train_acc 0.9917879971590909\n",
      "\n",
      "Epoch 24. Loss: 0.022848926370492757, Train_acc 0.991746115819209\n",
      "\n",
      "Epoch 24. Loss: 0.02423368384106563, Train_acc 0.991748595505618\n",
      "\n",
      "Epoch 24. Loss: 0.027893644478889763, Train_acc 0.9917074022346368\n",
      "\n",
      "Epoch 24. Loss: 0.028668040252005277, Train_acc 0.9916666666666667\n",
      "\n",
      "Epoch 24. Loss: 0.028953160017378826, Train_acc 0.9916263812154696\n",
      "\n",
      "Epoch 24. Loss: 0.027299868001473875, Train_acc 0.9916723901098901\n",
      "\n",
      "Epoch 24. Loss: 0.026365585491597295, Train_acc 0.9916752049180327\n",
      "\n",
      "Epoch 24. Loss: 0.025646660170441545, Train_acc 0.9916779891304348\n",
      "\n",
      "Epoch 24. Loss: 0.025077984951274702, Train_acc 0.9916807432432433\n",
      "\n",
      "Epoch 24. Loss: 0.02347996260360221, Train_acc 0.9917254704301075\n",
      "\n",
      "Epoch 24. Loss: 0.022211450418549834, Train_acc 0.9917279411764706\n",
      "\n",
      "Epoch 24. Loss: 0.020852540580080205, Train_acc 0.9917719414893617\n",
      "\n",
      "Epoch 24. Loss: 0.02460998786775433, Train_acc 0.9917328042328042\n",
      "\n",
      "Epoch 24. Loss: 0.02256077447493222, Train_acc 0.9917763157894737\n",
      "\n",
      "Epoch 24. Loss: 0.023624520769351842, Train_acc 0.9917375654450262\n",
      "\n",
      "Epoch 24. Loss: 0.023552547413677682, Train_acc 0.9917399088541666\n",
      "\n",
      "Epoch 24. Loss: 0.025650107579145473, Train_acc 0.9916612694300518\n",
      "\n",
      "Epoch 24. Loss: 0.02382056994181601, Train_acc 0.9917042525773195\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24. Loss: 0.024919551979974457, Train_acc 0.9917067307692308\n",
      "\n",
      "Epoch 24. Loss: 0.02927988979650338, Train_acc 0.99168\n",
      "\n",
      "Epoch 25. Loss: 0.028175727882380482, Train_acc 0.9921875\n",
      "\n",
      "Epoch 25. Loss: 0.028024893537219046, Train_acc 0.98828125\n",
      "\n",
      "Epoch 25. Loss: 0.027221786299397657, Train_acc 0.9895833333333334\n",
      "\n",
      "Epoch 25. Loss: 0.02499363336366425, Train_acc 0.9921875\n",
      "\n",
      "Epoch 25. Loss: 0.026087466747182698, Train_acc 0.9890625\n",
      "\n",
      "Epoch 25. Loss: 0.02380171256679424, Train_acc 0.9908854166666666\n",
      "\n",
      "Epoch 25. Loss: 0.025496894157690957, Train_acc 0.9910714285714286\n",
      "\n",
      "Epoch 25. Loss: 0.02538911744513794, Train_acc 0.9912109375\n",
      "\n",
      "Epoch 25. Loss: 0.025061959352123894, Train_acc 0.9913194444444444\n",
      "\n",
      "Epoch 25. Loss: 0.023248061773355148, Train_acc 0.9921875\n",
      "\n",
      "Epoch 25. Loss: 0.0220198571939844, Train_acc 0.9928977272727273\n",
      "\n",
      "Epoch 25. Loss: 0.030171867334208916, Train_acc 0.9921875\n",
      "\n",
      "Epoch 25. Loss: 0.027921815010185865, Train_acc 0.9927884615384616\n",
      "\n",
      "Epoch 25. Loss: 0.026149237454482162, Train_acc 0.9933035714285714\n",
      "\n",
      "Epoch 25. Loss: 0.026071927816165907, Train_acc 0.9927083333333333\n",
      "\n",
      "Epoch 25. Loss: 0.026951436135614, Train_acc 0.99267578125\n",
      "\n",
      "Epoch 25. Loss: 0.026192723006109073, Train_acc 0.9926470588235294\n",
      "\n",
      "Epoch 25. Loss: 0.030391395053356595, Train_acc 0.9917534722222222\n",
      "\n",
      "Epoch 25. Loss: 0.03287265818812523, Train_acc 0.990953947368421\n",
      "\n",
      "Epoch 25. Loss: 0.030844894858432476, Train_acc 0.99140625\n",
      "\n",
      "Epoch 25. Loss: 0.030586481373518108, Train_acc 0.9914434523809523\n",
      "\n",
      "Epoch 25. Loss: 0.030946552259632408, Train_acc 0.9914772727272727\n",
      "\n",
      "Epoch 25. Loss: 0.02971700422725838, Train_acc 0.9915081521739131\n",
      "\n",
      "Epoch 25. Loss: 0.03614891850437309, Train_acc 0.9905598958333334\n",
      "\n",
      "Epoch 25. Loss: 0.033764570971449484, Train_acc 0.9909375\n",
      "\n",
      "Epoch 25. Loss: 0.035913911479819066, Train_acc 0.9906850961538461\n",
      "\n",
      "Epoch 25. Loss: 0.03383548924455784, Train_acc 0.9907407407407407\n",
      "\n",
      "Epoch 25. Loss: 0.034742319158879605, Train_acc 0.9899553571428571\n",
      "\n",
      "Epoch 25. Loss: 0.03392012215152474, Train_acc 0.9897629310344828\n",
      "\n",
      "Epoch 25. Loss: 0.03174381763334655, Train_acc 0.98984375\n",
      "\n",
      "Epoch 25. Loss: 0.038115146552880855, Train_acc 0.9889112903225806\n",
      "\n",
      "Epoch 25. Loss: 0.0400369166243317, Train_acc 0.989013671875\n",
      "\n",
      "Epoch 25. Loss: 0.0371789423704066, Train_acc 0.9893465909090909\n",
      "\n",
      "Epoch 25. Loss: 0.042600162751667336, Train_acc 0.9892003676470589\n",
      "\n",
      "Epoch 25. Loss: 0.04330212288545904, Train_acc 0.9888392857142857\n",
      "\n",
      "Epoch 25. Loss: 0.04014019180936221, Train_acc 0.9891493055555556\n",
      "\n",
      "Epoch 25. Loss: 0.03791345776262227, Train_acc 0.989231418918919\n",
      "\n",
      "Epoch 25. Loss: 0.03677030090518901, Train_acc 0.9891036184210527\n",
      "\n",
      "Epoch 25. Loss: 0.04362856686736443, Train_acc 0.9889823717948718\n",
      "\n",
      "Epoch 25. Loss: 0.04061073984019725, Train_acc 0.9890625\n",
      "\n",
      "Epoch 25. Loss: 0.03814607009571286, Train_acc 0.9891387195121951\n",
      "\n",
      "Epoch 25. Loss: 0.03912187907351397, Train_acc 0.9890252976190477\n",
      "\n",
      "Epoch 25. Loss: 0.04041086734759816, Train_acc 0.9889171511627907\n",
      "\n",
      "Epoch 25. Loss: 0.03786302225078352, Train_acc 0.9891690340909091\n",
      "\n",
      "Epoch 25. Loss: 0.03653494074599631, Train_acc 0.9892361111111111\n",
      "\n",
      "Epoch 25. Loss: 0.0337959964058401, Train_acc 0.9894701086956522\n",
      "\n",
      "Epoch 25. Loss: 0.03154389731794016, Train_acc 0.9896941489361702\n",
      "\n",
      "Epoch 25. Loss: 0.03214215045609549, Train_acc 0.9892578125\n",
      "\n",
      "Epoch 25. Loss: 0.030494264077590188, Train_acc 0.9893176020408163\n",
      "\n",
      "Epoch 25. Loss: 0.030099947805505647, Train_acc 0.98921875\n",
      "\n",
      "Epoch 25. Loss: 0.028933507924051572, Train_acc 0.9892769607843137\n",
      "\n",
      "Epoch 25. Loss: 0.031449467889760274, Train_acc 0.9891826923076923\n",
      "\n",
      "Epoch 25. Loss: 0.030033173890973038, Train_acc 0.9892393867924528\n",
      "\n",
      "Epoch 25. Loss: 0.031069262533245896, Train_acc 0.9892939814814815\n",
      "\n",
      "Epoch 25. Loss: 0.02874429091858126, Train_acc 0.9894886363636364\n",
      "\n",
      "Epoch 25. Loss: 0.027700383611445938, Train_acc 0.9895368303571429\n",
      "\n",
      "Epoch 25. Loss: 0.02596093777754186, Train_acc 0.9897203947368421\n",
      "\n",
      "Epoch 25. Loss: 0.0254055166745628, Train_acc 0.9896282327586207\n",
      "\n",
      "Epoch 25. Loss: 0.025676025666693907, Train_acc 0.9898040254237288\n",
      "\n",
      "Epoch 25. Loss: 0.025214767054826077, Train_acc 0.98984375\n",
      "\n",
      "Epoch 25. Loss: 0.024717393677929092, Train_acc 0.9898821721311475\n",
      "\n",
      "Epoch 25. Loss: 0.02445288247898136, Train_acc 0.9899193548387096\n",
      "\n",
      "Epoch 25. Loss: 0.0258038233700536, Train_acc 0.9898313492063492\n",
      "\n",
      "Epoch 25. Loss: 0.02341870212404212, Train_acc 0.989990234375\n",
      "\n",
      "Epoch 25. Loss: 0.022746829261019355, Train_acc 0.9900240384615384\n",
      "\n",
      "Epoch 25. Loss: 0.021431862047732942, Train_acc 0.9901751893939394\n",
      "\n",
      "Epoch 25. Loss: 0.01948580800757206, Train_acc 0.9903218283582089\n",
      "\n",
      "Epoch 25. Loss: 0.02123964981077966, Train_acc 0.990234375\n",
      "\n",
      "Epoch 25. Loss: 0.022006508238662993, Train_acc 0.9901494565217391\n",
      "\n",
      "Epoch 25. Loss: 0.023120608056381088, Train_acc 0.9901785714285715\n",
      "\n",
      "Epoch 25. Loss: 0.021726301014239856, Train_acc 0.9902068661971831\n",
      "\n",
      "Epoch 25. Loss: 0.022334432668818772, Train_acc 0.9901258680555556\n",
      "\n",
      "Epoch 25. Loss: 0.020512603898197777, Train_acc 0.9902611301369864\n",
      "\n",
      "Epoch 25. Loss: 0.019529976930633516, Train_acc 0.9902871621621622\n",
      "\n",
      "Epoch 25. Loss: 0.018228296606763002, Train_acc 0.9904166666666666\n",
      "\n",
      "Epoch 25. Loss: 0.017491722109041034, Train_acc 0.9905427631578947\n",
      "\n",
      "Epoch 25. Loss: 0.01729321390580066, Train_acc 0.9906655844155844\n",
      "\n",
      "Epoch 25. Loss: 0.01617121439225311, Train_acc 0.9907852564102564\n",
      "\n",
      "Epoch 25. Loss: 0.0182239296976939, Train_acc 0.9907041139240507\n",
      "\n",
      "Epoch 25. Loss: 0.018356792780239745, Train_acc 0.99072265625\n",
      "\n",
      "Epoch 25. Loss: 0.017351522339862015, Train_acc 0.9908371913580247\n",
      "\n",
      "Epoch 25. Loss: 0.02041783642186054, Train_acc 0.9905678353658537\n",
      "\n",
      "Epoch 25. Loss: 0.01981751185801621, Train_acc 0.9905873493975904\n",
      "\n",
      "Epoch 25. Loss: 0.018585216902765593, Train_acc 0.9906994047619048\n",
      "\n",
      "Epoch 25. Loss: 0.018476036216085817, Train_acc 0.9907169117647059\n",
      "\n",
      "Epoch 25. Loss: 0.02164471330517441, Train_acc 0.9906431686046512\n",
      "\n",
      "Epoch 25. Loss: 0.020174435665672213, Train_acc 0.9907507183908046\n",
      "\n",
      "Epoch 25. Loss: 0.025664737275658718, Train_acc 0.9907670454545454\n",
      "\n",
      "Epoch 25. Loss: 0.02638408135004521, Train_acc 0.9906952247191011\n",
      "\n",
      "Epoch 25. Loss: 0.024440293777758006, Train_acc 0.9907986111111111\n",
      "\n",
      "Epoch 25. Loss: 0.022950132897145262, Train_acc 0.9908997252747253\n",
      "\n",
      "Epoch 25. Loss: 0.023602363655549328, Train_acc 0.9909137228260869\n",
      "\n",
      "Epoch 25. Loss: 0.025225688239558376, Train_acc 0.9907594086021505\n",
      "\n",
      "Epoch 25. Loss: 0.023960795953682515, Train_acc 0.9907746010638298\n",
      "\n",
      "Epoch 25. Loss: 0.02425485018325876, Train_acc 0.9907072368421053\n",
      "\n",
      "Epoch 25. Loss: 0.022477509145584978, Train_acc 0.9908040364583334\n",
      "\n",
      "Epoch 25. Loss: 0.021088154895288296, Train_acc 0.9908988402061856\n",
      "\n",
      "Epoch 25. Loss: 0.02394460859881271, Train_acc 0.9907525510204082\n",
      "\n",
      "Epoch 25. Loss: 0.0274944809644201, Train_acc 0.9906092171717171\n",
      "\n",
      "Epoch 25. Loss: 0.03082382523138332, Train_acc 0.990546875\n",
      "\n",
      "[Epoch 25 Batch 100] Loss: 0.03560471543478079 Training: accuracy=0.990486\n",
      "Epoch 25. Loss: 0.03560471543478079, Train_acc 0.9904857673267327\n",
      "\n",
      "Epoch 25. Loss: 0.03685026139444507, Train_acc 0.9903492647058824\n",
      "\n",
      "Epoch 25. Loss: 0.035309354212222074, Train_acc 0.9903671116504854\n",
      "\n",
      "Epoch 25. Loss: 0.03474413413226984, Train_acc 0.9903094951923077\n",
      "\n",
      "Epoch 25. Loss: 0.033916931749168475, Train_acc 0.9902529761904761\n",
      "\n",
      "Epoch 25. Loss: 0.03421122035454223, Train_acc 0.9901238207547169\n",
      "\n",
      "Epoch 25. Loss: 0.03229770709786275, Train_acc 0.9901431074766355\n",
      "\n",
      "Epoch 25. Loss: 0.03013069893908613, Train_acc 0.990234375\n",
      "\n",
      "Epoch 25. Loss: 0.030729118430543954, Train_acc 0.9902522935779816\n",
      "\n",
      "Epoch 25. Loss: 0.030463204072948412, Train_acc 0.9901988636363637\n",
      "\n",
      "Epoch 25. Loss: 0.028606708790692194, Train_acc 0.9902871621621622\n",
      "\n",
      "Epoch 25. Loss: 0.031562318380921335, Train_acc 0.9903041294642857\n",
      "\n",
      "Epoch 25. Loss: 0.029436944497003483, Train_acc 0.9903899336283186\n",
      "\n",
      "Epoch 25. Loss: 0.029255968918538985, Train_acc 0.9903371710526315\n",
      "\n",
      "Epoch 25. Loss: 0.027901252812269534, Train_acc 0.9904211956521739\n",
      "\n",
      "Epoch 25. Loss: 0.0275038319433837, Train_acc 0.9904364224137931\n",
      "\n",
      "Epoch 25. Loss: 0.027749508256176905, Train_acc 0.9903846153846154\n",
      "\n",
      "Epoch 25. Loss: 0.026952972867601926, Train_acc 0.9903998940677966\n",
      "\n",
      "Epoch 25. Loss: 0.026077229179603294, Train_acc 0.9904149159663865\n",
      "\n",
      "Epoch 25. Loss: 0.024184858297701867, Train_acc 0.9904947916666667\n",
      "\n",
      "Epoch 25. Loss: 0.024729088764246877, Train_acc 0.9904442148760331\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25. Loss: 0.02619829921798996, Train_acc 0.9904585040983607\n",
      "\n",
      "Epoch 25. Loss: 0.02569254006186508, Train_acc 0.9904725609756098\n",
      "\n",
      "Epoch 25. Loss: 0.023793265406319944, Train_acc 0.9905493951612904\n",
      "\n",
      "Epoch 25. Loss: 0.02356090077820073, Train_acc 0.9905\n",
      "\n",
      "Epoch 25. Loss: 0.023001819587313985, Train_acc 0.9905133928571429\n",
      "\n",
      "Epoch 25. Loss: 0.021982597137895694, Train_acc 0.9905265748031497\n",
      "\n",
      "Epoch 25. Loss: 0.0221510920230217, Train_acc 0.99053955078125\n",
      "\n",
      "Epoch 25. Loss: 0.021513672691911512, Train_acc 0.9906128875968992\n",
      "\n",
      "Epoch 25. Loss: 0.02040098071232145, Train_acc 0.990625\n",
      "\n",
      "Epoch 25. Loss: 0.01967054262505208, Train_acc 0.9906965648854962\n",
      "\n",
      "Epoch 25. Loss: 0.019849667219038913, Train_acc 0.9907078598484849\n",
      "\n",
      "Epoch 25. Loss: 0.022387179822667934, Train_acc 0.9906015037593985\n",
      "\n",
      "Epoch 25. Loss: 0.02100041300738856, Train_acc 0.9906716417910447\n",
      "\n",
      "Epoch 25. Loss: 0.01923961650168155, Train_acc 0.9907407407407407\n",
      "\n",
      "Epoch 25. Loss: 0.017672038380073796, Train_acc 0.9908088235294118\n",
      "\n",
      "Epoch 25. Loss: 0.01762717855313476, Train_acc 0.9908188868613139\n",
      "\n",
      "Epoch 25. Loss: 0.017101039985618495, Train_acc 0.990828804347826\n",
      "\n",
      "Epoch 25. Loss: 0.016380635537029658, Train_acc 0.9908947841726619\n",
      "\n",
      "Epoch 25. Loss: 0.02037980419753911, Train_acc 0.9908482142857142\n",
      "\n",
      "Epoch 25. Loss: 0.018581341922884482, Train_acc 0.9909131205673759\n",
      "\n",
      "Epoch 25. Loss: 0.01936418113464591, Train_acc 0.9908670774647887\n",
      "\n",
      "Epoch 25. Loss: 0.017792373806799745, Train_acc 0.9909309440559441\n",
      "\n",
      "Epoch 25. Loss: 0.016166335147938398, Train_acc 0.9909939236111112\n",
      "\n",
      "Epoch 25. Loss: 0.01562398967354411, Train_acc 0.9910560344827586\n",
      "\n",
      "Epoch 25. Loss: 0.014700216383864708, Train_acc 0.991117294520548\n",
      "\n",
      "Epoch 25. Loss: 0.015133628470716084, Train_acc 0.991124574829932\n",
      "\n",
      "Epoch 25. Loss: 0.015000245956793909, Train_acc 0.9911317567567568\n",
      "\n",
      "Epoch 25. Loss: 0.019338755597068803, Train_acc 0.9910864093959731\n",
      "\n",
      "Epoch 25. Loss: 0.01918229948526079, Train_acc 0.9910416666666667\n",
      "\n",
      "Epoch 25. Loss: 0.01826860049184073, Train_acc 0.9910492549668874\n",
      "\n",
      "Epoch 25. Loss: 0.01670314529690214, Train_acc 0.9911081414473685\n",
      "\n",
      "Epoch 25. Loss: 0.02370601066189767, Train_acc 0.9910130718954249\n",
      "\n",
      "Epoch 25. Loss: 0.02386928127620603, Train_acc 0.9909699675324676\n",
      "\n",
      "Epoch 25. Loss: 0.021920932832708826, Train_acc 0.9910282258064517\n",
      "\n",
      "Epoch 25. Loss: 0.026118052902833408, Train_acc 0.9909354967948718\n",
      "\n",
      "Epoch 25. Loss: 0.032105207058503435, Train_acc 0.990843949044586\n",
      "\n",
      "Epoch 25. Loss: 0.030563507255358287, Train_acc 0.9909018987341772\n",
      "\n",
      "Epoch 25. Loss: 0.02951194590459119, Train_acc 0.9908608490566038\n",
      "\n",
      "Epoch 25. Loss: 0.03026469532665477, Train_acc 0.9908203125\n",
      "\n",
      "Epoch 25. Loss: 0.03024651617422878, Train_acc 0.9907802795031055\n",
      "\n",
      "Epoch 25. Loss: 0.030492931699292476, Train_acc 0.9906925154320988\n",
      "\n",
      "Epoch 25. Loss: 0.029451180148604466, Train_acc 0.9906537576687117\n",
      "\n",
      "Epoch 25. Loss: 0.027133060249074956, Train_acc 0.9907107469512195\n",
      "\n",
      "Epoch 25. Loss: 0.02733650490854799, Train_acc 0.990719696969697\n",
      "\n",
      "Epoch 25. Loss: 0.029793360995184953, Train_acc 0.9905873493975904\n",
      "\n",
      "Epoch 25. Loss: 0.02742480970942817, Train_acc 0.9906437125748503\n",
      "\n",
      "Epoch 25. Loss: 0.031441777833019276, Train_acc 0.9905598958333334\n",
      "\n",
      "Epoch 25. Loss: 0.03936820914242975, Train_acc 0.9905232988165681\n",
      "\n",
      "Epoch 25. Loss: 0.036770453604855945, Train_acc 0.9905330882352941\n",
      "\n",
      "Epoch 25. Loss: 0.0356974008778919, Train_acc 0.9904970760233918\n",
      "\n",
      "Epoch 25. Loss: 0.0324508295837959, Train_acc 0.9905523255813954\n",
      "\n",
      "Epoch 25. Loss: 0.0301923504591513, Train_acc 0.990606936416185\n",
      "\n",
      "Epoch 25. Loss: 0.028350451130020174, Train_acc 0.9906609195402298\n",
      "\n",
      "Epoch 25. Loss: 0.02987683284730991, Train_acc 0.9905803571428572\n",
      "\n",
      "Epoch 25. Loss: 0.03038221941993785, Train_acc 0.9905450994318182\n",
      "\n",
      "Epoch 25. Loss: 0.03020883400684135, Train_acc 0.9905102401129944\n",
      "\n",
      "Epoch 25. Loss: 0.02960120148461047, Train_acc 0.9905196629213483\n",
      "\n",
      "Epoch 25. Loss: 0.027673076342055052, Train_acc 0.9905289804469274\n",
      "\n",
      "Epoch 25. Loss: 0.027402464412607717, Train_acc 0.9904947916666667\n",
      "\n",
      "Epoch 25. Loss: 0.02803759100701627, Train_acc 0.9904609806629834\n",
      "\n",
      "Epoch 25. Loss: 0.02676194021254376, Train_acc 0.990470467032967\n",
      "\n",
      "Epoch 25. Loss: 0.02534932703509565, Train_acc 0.9905225409836066\n",
      "\n",
      "Epoch 25. Loss: 0.024786644785713876, Train_acc 0.9905315896739131\n",
      "\n",
      "Epoch 25. Loss: 0.02734747926215386, Train_acc 0.9905405405405405\n",
      "\n",
      "Epoch 25. Loss: 0.02553560159939577, Train_acc 0.9905913978494624\n",
      "\n",
      "Epoch 25. Loss: 0.026886042854232045, Train_acc 0.9905581550802139\n",
      "\n",
      "Epoch 25. Loss: 0.028592837066390323, Train_acc 0.9905252659574468\n",
      "\n",
      "Epoch 25. Loss: 0.027767426634673662, Train_acc 0.9905340608465608\n",
      "\n",
      "Epoch 25. Loss: 0.026215353878448356, Train_acc 0.9905427631578947\n",
      "\n",
      "Epoch 25. Loss: 0.02510558115432556, Train_acc 0.9905513743455497\n",
      "\n",
      "Epoch 25. Loss: 0.023803381296901963, Train_acc 0.9906005859375\n",
      "\n",
      "Epoch 25. Loss: 0.022485029367723224, Train_acc 0.9906492875647669\n",
      "\n",
      "Epoch 25. Loss: 0.02345417924355104, Train_acc 0.9906169458762887\n",
      "\n",
      "Epoch 25. Loss: 0.02278243329492779, Train_acc 0.990625\n",
      "\n",
      "Epoch 25. Loss: 0.028610995349594097, Train_acc 0.99056\n",
      "\n",
      "Epoch 26. Loss: 0.02674564672616852, Train_acc 1.0\n",
      "\n",
      "Epoch 26. Loss: 0.0307876269797182, Train_acc 0.98828125\n",
      "\n",
      "Epoch 26. Loss: 0.030622179875942703, Train_acc 0.9895833333333334\n",
      "\n",
      "Epoch 26. Loss: 0.03369770846084294, Train_acc 0.986328125\n",
      "\n",
      "Epoch 26. Loss: 0.03422538847907368, Train_acc 0.984375\n",
      "\n",
      "Epoch 26. Loss: 0.037786780993795246, Train_acc 0.9817708333333334\n",
      "\n",
      "Epoch 26. Loss: 0.04310593533574568, Train_acc 0.9810267857142857\n",
      "\n",
      "Epoch 26. Loss: 0.04813050503783548, Train_acc 0.9794921875\n",
      "\n",
      "Epoch 26. Loss: 0.046405390503285446, Train_acc 0.9800347222222222\n",
      "\n",
      "Epoch 26. Loss: 0.052120572867046105, Train_acc 0.9796875\n",
      "\n",
      "Epoch 26. Loss: 0.05525450248305527, Train_acc 0.9794034090909091\n",
      "\n",
      "Epoch 26. Loss: 0.05111753805757637, Train_acc 0.9811197916666666\n",
      "\n",
      "Epoch 26. Loss: 0.0483079562867976, Train_acc 0.9819711538461539\n",
      "\n",
      "Epoch 26. Loss: 0.0459421604754296, Train_acc 0.9827008928571429\n",
      "\n",
      "Epoch 26. Loss: 0.04265472597316805, Train_acc 0.9833333333333333\n",
      "\n",
      "Epoch 26. Loss: 0.05058734988959941, Train_acc 0.982421875\n",
      "\n",
      "Epoch 26. Loss: 0.04844993241839689, Train_acc 0.9825367647058824\n",
      "\n",
      "Epoch 26. Loss: 0.047289704277036326, Train_acc 0.9830729166666666\n",
      "\n",
      "Epoch 26. Loss: 0.04806718453221119, Train_acc 0.9835526315789473\n",
      "\n",
      "Epoch 26. Loss: 0.04453893159958062, Train_acc 0.984375\n",
      "\n",
      "Epoch 26. Loss: 0.04390150074779097, Train_acc 0.9847470238095238\n",
      "\n",
      "Epoch 26. Loss: 0.0456895665641347, Train_acc 0.984375\n",
      "\n",
      "Epoch 26. Loss: 0.044851991055821126, Train_acc 0.9847146739130435\n",
      "\n",
      "Epoch 26. Loss: 0.04205474575765259, Train_acc 0.9853515625\n",
      "\n",
      "Epoch 26. Loss: 0.049539376679724405, Train_acc 0.984375\n",
      "\n",
      "Epoch 26. Loss: 0.04895879384905036, Train_acc 0.9846754807692307\n",
      "\n",
      "Epoch 26. Loss: 0.045317517451464555, Train_acc 0.9852430555555556\n",
      "\n",
      "Epoch 26. Loss: 0.042801656446176256, Train_acc 0.9854910714285714\n",
      "\n",
      "Epoch 26. Loss: 0.04071010928271784, Train_acc 0.9857219827586207\n",
      "\n",
      "Epoch 26. Loss: 0.03911944692658103, Train_acc 0.9856770833333334\n",
      "\n",
      "Epoch 26. Loss: 0.03819971351617619, Train_acc 0.9856350806451613\n",
      "\n",
      "Epoch 26. Loss: 0.041894506533092665, Train_acc 0.984619140625\n",
      "\n",
      "Epoch 26. Loss: 0.03969465575588919, Train_acc 0.9850852272727273\n",
      "\n",
      "Epoch 26. Loss: 0.036990686754642524, Train_acc 0.9855238970588235\n",
      "\n",
      "Epoch 26. Loss: 0.033963427618377146, Train_acc 0.9859375\n",
      "\n",
      "Epoch 26. Loss: 0.03484911606481618, Train_acc 0.9858940972222222\n",
      "\n",
      "Epoch 26. Loss: 0.03378592850957167, Train_acc 0.9860641891891891\n",
      "\n",
      "Epoch 26. Loss: 0.035671171595399245, Train_acc 0.9858141447368421\n",
      "\n",
      "Epoch 26. Loss: 0.032760343251521586, Train_acc 0.9861778846153846\n",
      "\n",
      "Epoch 26. Loss: 0.034977990059162856, Train_acc 0.9861328125\n",
      "\n",
      "Epoch 26. Loss: 0.03772851280996711, Train_acc 0.9860899390243902\n",
      "\n",
      "Epoch 26. Loss: 0.03616828838851611, Train_acc 0.9862351190476191\n",
      "\n",
      "Epoch 26. Loss: 0.041715819715260505, Train_acc 0.9854651162790697\n",
      "\n",
      "Epoch 26. Loss: 0.041283994089483356, Train_acc 0.9852627840909091\n",
      "\n",
      "Epoch 26. Loss: 0.03801846821241302, Train_acc 0.9855902777777777\n",
      "\n",
      "Epoch 26. Loss: 0.03755489463328769, Train_acc 0.985733695652174\n",
      "\n",
      "Epoch 26. Loss: 0.041164944839949466, Train_acc 0.9853723404255319\n",
      "\n",
      "Epoch 26. Loss: 0.04191054539901769, Train_acc 0.9851888020833334\n",
      "\n",
      "Epoch 26. Loss: 0.05255034539421877, Train_acc 0.9850127551020408\n",
      "\n",
      "Epoch 26. Loss: 0.04964683609444333, Train_acc 0.985\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26. Loss: 0.04720282471691161, Train_acc 0.985140931372549\n",
      "\n",
      "Epoch 26. Loss: 0.04746338873965672, Train_acc 0.9849759615384616\n",
      "\n",
      "Epoch 26. Loss: 0.04754381984349905, Train_acc 0.9848172169811321\n",
      "\n",
      "Epoch 26. Loss: 0.044989670305342844, Train_acc 0.9849537037037037\n",
      "\n",
      "Epoch 26. Loss: 0.0438544347782952, Train_acc 0.9850852272727273\n",
      "\n",
      "Epoch 26. Loss: 0.0404853467926403, Train_acc 0.9853515625\n",
      "\n",
      "Epoch 26. Loss: 0.038231862056406156, Train_acc 0.985608552631579\n",
      "\n",
      "Epoch 26. Loss: 0.03639748317136033, Train_acc 0.9858566810344828\n",
      "\n",
      "Epoch 26. Loss: 0.03423175557747779, Train_acc 0.9859639830508474\n",
      "\n",
      "Epoch 26. Loss: 0.0323449808221635, Train_acc 0.9860677083333333\n",
      "\n",
      "Epoch 26. Loss: 0.02958643579363019, Train_acc 0.9862961065573771\n",
      "\n",
      "Epoch 26. Loss: 0.028733258676938926, Train_acc 0.9865171370967742\n",
      "\n",
      "Epoch 26. Loss: 0.02727592366106455, Train_acc 0.9867311507936508\n",
      "\n",
      "Epoch 26. Loss: 0.027961320076887113, Train_acc 0.98681640625\n",
      "\n",
      "Epoch 26. Loss: 0.029456829781387122, Train_acc 0.9867788461538461\n",
      "\n",
      "Epoch 26. Loss: 0.02808522388790894, Train_acc 0.9868607954545454\n",
      "\n",
      "Epoch 26. Loss: 0.026172888905151324, Train_acc 0.9870569029850746\n",
      "\n",
      "Epoch 26. Loss: 0.023920358414882693, Train_acc 0.9872472426470589\n",
      "\n",
      "Epoch 26. Loss: 0.025536875005454665, Train_acc 0.9872056159420289\n",
      "\n",
      "Epoch 26. Loss: 0.02371332954881267, Train_acc 0.9873883928571429\n",
      "\n",
      "Epoch 26. Loss: 0.022787872283318723, Train_acc 0.9875660211267606\n",
      "\n",
      "Epoch 26. Loss: 0.027344019706838505, Train_acc 0.9875217013888888\n",
      "\n",
      "Epoch 26. Loss: 0.026403271999174218, Train_acc 0.9875856164383562\n",
      "\n",
      "Epoch 26. Loss: 0.027235194381666657, Train_acc 0.9875422297297297\n",
      "\n",
      "Epoch 26. Loss: 0.026243194344573447, Train_acc 0.9876041666666666\n",
      "\n",
      "Epoch 26. Loss: 0.02468007703015199, Train_acc 0.9877672697368421\n",
      "\n",
      "Epoch 26. Loss: 0.02365947536577872, Train_acc 0.9879261363636364\n",
      "\n",
      "Epoch 26. Loss: 0.025409486713559252, Train_acc 0.9879807692307693\n",
      "\n",
      "Epoch 26. Loss: 0.024873767187491794, Train_acc 0.9880340189873418\n",
      "\n",
      "Epoch 26. Loss: 0.022995252101387746, Train_acc 0.98818359375\n",
      "\n",
      "Epoch 26. Loss: 0.022473218982308658, Train_acc 0.988233024691358\n",
      "\n",
      "Epoch 26. Loss: 0.02222435104390045, Train_acc 0.98828125\n",
      "\n",
      "Epoch 26. Loss: 0.021283858552933275, Train_acc 0.9884224397590361\n",
      "\n",
      "Epoch 26. Loss: 0.021871880995059496, Train_acc 0.9884672619047619\n",
      "\n",
      "Epoch 26. Loss: 0.023883771574638328, Train_acc 0.9882352941176471\n",
      "\n",
      "Epoch 26. Loss: 0.030733966090806166, Train_acc 0.9880087209302325\n",
      "\n",
      "Epoch 26. Loss: 0.0354011147545527, Train_acc 0.9879669540229885\n",
      "\n",
      "Epoch 26. Loss: 0.0322335763605014, Train_acc 0.9881036931818182\n",
      "\n",
      "Epoch 26. Loss: 0.037666531249723634, Train_acc 0.9877984550561798\n",
      "\n",
      "Epoch 26. Loss: 0.03709165320829314, Train_acc 0.9877604166666667\n",
      "\n",
      "Epoch 26. Loss: 0.03534882481577184, Train_acc 0.9878090659340659\n",
      "\n",
      "Epoch 26. Loss: 0.0329450641484456, Train_acc 0.9879415760869565\n",
      "\n",
      "Epoch 26. Loss: 0.031058497581159774, Train_acc 0.9879872311827957\n",
      "\n",
      "Epoch 26. Loss: 0.03184371763760659, Train_acc 0.9879488031914894\n",
      "\n",
      "Epoch 26. Loss: 0.0308935192536844, Train_acc 0.9879934210526315\n",
      "\n",
      "Epoch 26. Loss: 0.02963266236885189, Train_acc 0.988037109375\n",
      "\n",
      "Epoch 26. Loss: 0.03032531183931648, Train_acc 0.9879993556701031\n",
      "\n",
      "Epoch 26. Loss: 0.027817610262841755, Train_acc 0.9881218112244898\n",
      "\n",
      "Epoch 26. Loss: 0.03528197782547245, Train_acc 0.9879261363636364\n",
      "\n",
      "Epoch 26. Loss: 0.0333210191709784, Train_acc 0.98796875\n",
      "\n",
      "[Epoch 26 Batch 100] Loss: 0.03059010185484475 Training: accuracy=0.988088\n",
      "Epoch 26. Loss: 0.03059010185484475, Train_acc 0.9880878712871287\n",
      "\n",
      "Epoch 26. Loss: 0.0318385789038335, Train_acc 0.9879748774509803\n",
      "\n",
      "Epoch 26. Loss: 0.03037522491737557, Train_acc 0.9880157766990292\n",
      "\n",
      "Epoch 26. Loss: 0.029697654085675054, Train_acc 0.9880558894230769\n",
      "\n",
      "Epoch 26. Loss: 0.02891951309500859, Train_acc 0.9880952380952381\n",
      "\n",
      "Epoch 26. Loss: 0.028695879565406375, Train_acc 0.9881338443396226\n",
      "\n",
      "Epoch 26. Loss: 0.02651576237684059, Train_acc 0.9882447429906542\n",
      "\n",
      "Epoch 26. Loss: 0.02506427807112546, Train_acc 0.9883535879629629\n",
      "\n",
      "Epoch 26. Loss: 0.02417708382755528, Train_acc 0.9884604357798165\n",
      "\n",
      "Epoch 26. Loss: 0.02237374268397698, Train_acc 0.9885653409090909\n",
      "\n",
      "Epoch 26. Loss: 0.02092567361079165, Train_acc 0.9886683558558559\n",
      "\n",
      "Epoch 26. Loss: 0.023652516171477813, Train_acc 0.9886997767857143\n",
      "\n",
      "Epoch 26. Loss: 0.026214220999308747, Train_acc 0.9886615044247787\n",
      "\n",
      "Epoch 26. Loss: 0.027609486620391897, Train_acc 0.9886239035087719\n",
      "\n",
      "Epoch 26. Loss: 0.02511011424580111, Train_acc 0.9887228260869565\n",
      "\n",
      "Epoch 26. Loss: 0.025389674197902327, Train_acc 0.9887526939655172\n",
      "\n",
      "Epoch 26. Loss: 0.024217533483746688, Train_acc 0.9888488247863247\n",
      "\n",
      "Epoch 26. Loss: 0.027235118223407604, Train_acc 0.9887447033898306\n",
      "\n",
      "Epoch 26. Loss: 0.03010425694869048, Train_acc 0.9886423319327731\n",
      "\n",
      "Epoch 26. Loss: 0.0346694869824, Train_acc 0.9885416666666667\n",
      "\n",
      "Epoch 26. Loss: 0.037803200605012285, Train_acc 0.9885072314049587\n",
      "\n",
      "Epoch 26. Loss: 0.04424630199894069, Train_acc 0.9883452868852459\n",
      "\n",
      "Epoch 26. Loss: 0.04419229525349819, Train_acc 0.9883130081300813\n",
      "\n",
      "Epoch 26. Loss: 0.04131237579604045, Train_acc 0.9883442540322581\n",
      "\n",
      "Epoch 26. Loss: 0.04255611073869517, Train_acc 0.98825\n",
      "\n",
      "Epoch 26. Loss: 0.04305364561287806, Train_acc 0.9881572420634921\n",
      "\n",
      "Epoch 26. Loss: 0.04105323066301565, Train_acc 0.9882504921259843\n",
      "\n",
      "Epoch 26. Loss: 0.03894553454209049, Train_acc 0.98828125\n",
      "\n",
      "Epoch 26. Loss: 0.03566045106043231, Train_acc 0.9883720930232558\n",
      "\n",
      "Epoch 26. Loss: 0.036203158264665115, Train_acc 0.9884014423076923\n",
      "\n",
      "Epoch 26. Loss: 0.033935119836308036, Train_acc 0.9884899809160306\n",
      "\n",
      "Epoch 26. Loss: 0.03250882357696665, Train_acc 0.9885179924242424\n",
      "\n",
      "Epoch 26. Loss: 0.029943015585899107, Train_acc 0.988545582706767\n",
      "\n",
      "Epoch 26. Loss: 0.02764009368059911, Train_acc 0.9886310634328358\n",
      "\n",
      "Epoch 26. Loss: 0.026759142376225092, Train_acc 0.9886574074074074\n",
      "\n",
      "Epoch 26. Loss: 0.025141294216132967, Train_acc 0.9887408088235294\n",
      "\n",
      "Epoch 26. Loss: 0.0292632680371554, Train_acc 0.9886519160583942\n",
      "\n",
      "Epoch 26. Loss: 0.026675076706870016, Train_acc 0.9887341485507246\n",
      "\n",
      "Epoch 26. Loss: 0.028408582663831367, Train_acc 0.9887027877697842\n",
      "\n",
      "Epoch 26. Loss: 0.02932189687159412, Train_acc 0.988671875\n",
      "\n",
      "Epoch 26. Loss: 0.03386349857509213, Train_acc 0.9886414007092199\n",
      "\n",
      "Epoch 26. Loss: 0.0310760967939503, Train_acc 0.9887213908450704\n",
      "\n",
      "Epoch 26. Loss: 0.031825815112239746, Train_acc 0.9887456293706294\n",
      "\n",
      "Epoch 26. Loss: 0.030058477252733674, Train_acc 0.98876953125\n",
      "\n",
      "Epoch 26. Loss: 0.034219353434454175, Train_acc 0.9886853448275862\n",
      "\n",
      "Epoch 26. Loss: 0.03416663769216309, Train_acc 0.9887093321917808\n",
      "\n",
      "Epoch 26. Loss: 0.03358055398611102, Train_acc 0.9887329931972789\n",
      "\n",
      "Epoch 26. Loss: 0.033843097425233185, Train_acc 0.9886507601351351\n",
      "\n",
      "Epoch 26. Loss: 0.03221542001074331, Train_acc 0.9887269295302014\n",
      "\n",
      "Epoch 26. Loss: 0.03915971988712946, Train_acc 0.98859375\n",
      "\n",
      "Epoch 26. Loss: 0.03718306902148009, Train_acc 0.9886175496688742\n",
      "\n",
      "Epoch 26. Loss: 0.03523107200650287, Train_acc 0.9886924342105263\n",
      "\n",
      "Epoch 26. Loss: 0.03412111957181614, Train_acc 0.9887152777777778\n",
      "\n",
      "Epoch 26. Loss: 0.03279682868101407, Train_acc 0.9887378246753247\n",
      "\n",
      "Epoch 26. Loss: 0.03395392148236819, Train_acc 0.9887600806451613\n",
      "\n",
      "Epoch 26. Loss: 0.03200928962415804, Train_acc 0.9888321314102564\n",
      "\n",
      "Epoch 26. Loss: 0.031529727879342585, Train_acc 0.9888535031847133\n",
      "\n",
      "Epoch 26. Loss: 0.03042024594829424, Train_acc 0.9888746044303798\n",
      "\n",
      "Epoch 26. Loss: 0.029781558861904835, Train_acc 0.9888954402515723\n",
      "\n",
      "Epoch 26. Loss: 0.02879000566951051, Train_acc 0.988916015625\n",
      "\n",
      "Epoch 26. Loss: 0.02675821704836143, Train_acc 0.9889848602484472\n",
      "\n",
      "Epoch 26. Loss: 0.026676586179478046, Train_acc 0.9889564043209876\n",
      "\n",
      "Epoch 26. Loss: 0.031637156821974884, Train_acc 0.9888803680981595\n",
      "\n",
      "Epoch 26. Loss: 0.029337457404454443, Train_acc 0.9889481707317073\n",
      "\n",
      "Epoch 26. Loss: 0.026995260149690416, Train_acc 0.9890151515151515\n",
      "\n",
      "Epoch 26. Loss: 0.029321934175896264, Train_acc 0.9889871987951807\n",
      "\n",
      "Epoch 26. Loss: 0.028259864800340786, Train_acc 0.9890063622754491\n",
      "\n",
      "Epoch 26. Loss: 0.02585252337068336, Train_acc 0.9890718005952381\n",
      "\n",
      "Epoch 26. Loss: 0.02636128481397048, Train_acc 0.9890902366863905\n",
      "\n",
      "Epoch 26. Loss: 0.025137394047549503, Train_acc 0.989108455882353\n",
      "\n",
      "Epoch 26. Loss: 0.02795766908833784, Train_acc 0.9890350877192983\n",
      "\n",
      "Epoch 26. Loss: 0.031134891455555577, Train_acc 0.9890534156976745\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26. Loss: 0.030883040677176076, Train_acc 0.9890715317919075\n",
      "\n",
      "Epoch 26. Loss: 0.030114597254097007, Train_acc 0.9890894396551724\n",
      "\n",
      "Epoch 26. Loss: 0.028686669400125334, Train_acc 0.9891071428571429\n",
      "\n",
      "Epoch 26. Loss: 0.02753497031848692, Train_acc 0.9891246448863636\n",
      "\n",
      "Epoch 26. Loss: 0.02612049666065928, Train_acc 0.9891419491525424\n",
      "\n",
      "Epoch 26. Loss: 0.023837774717604728, Train_acc 0.9892029494382022\n",
      "\n",
      "Epoch 26. Loss: 0.02287627079975213, Train_acc 0.989219622905028\n",
      "\n",
      "Epoch 26. Loss: 0.021853395329191734, Train_acc 0.9892361111111111\n",
      "\n",
      "Epoch 26. Loss: 0.020480966759122417, Train_acc 0.9892955801104972\n",
      "\n",
      "Epoch 26. Loss: 0.018639686954860693, Train_acc 0.9893543956043956\n",
      "\n",
      "Epoch 26. Loss: 0.019112181219021803, Train_acc 0.9893698770491803\n",
      "\n",
      "Epoch 26. Loss: 0.01879391660025149, Train_acc 0.9893851902173914\n",
      "\n",
      "Epoch 26. Loss: 0.01932188054678228, Train_acc 0.9894003378378379\n",
      "\n",
      "Epoch 26. Loss: 0.017774220658718524, Train_acc 0.9894573252688172\n",
      "\n",
      "Epoch 26. Loss: 0.022978251892369073, Train_acc 0.9893465909090909\n",
      "\n",
      "Epoch 26. Loss: 0.022389951245225442, Train_acc 0.9893617021276596\n",
      "\n",
      "Epoch 26. Loss: 0.02407627364656655, Train_acc 0.9893353174603174\n",
      "\n",
      "Epoch 26. Loss: 0.02320409918422694, Train_acc 0.9893503289473684\n",
      "\n",
      "Epoch 26. Loss: 0.022372834202008203, Train_acc 0.9893651832460733\n",
      "\n",
      "Epoch 26. Loss: 0.024432893678268872, Train_acc 0.9893798828125\n",
      "\n",
      "Epoch 26. Loss: 0.0223774529447148, Train_acc 0.9894349093264249\n",
      "\n",
      "Epoch 26. Loss: 0.021093208926915206, Train_acc 0.989489368556701\n",
      "\n",
      "Epoch 26. Loss: 0.026143298451303615, Train_acc 0.989423076923077\n",
      "\n",
      "Epoch 26. Loss: 0.028367389056860662, Train_acc 0.9894\n",
      "\n",
      "Epoch 27. Loss: 0.026084458233069707, Train_acc 1.0\n",
      "\n",
      "Epoch 27. Loss: 0.024024343988956212, Train_acc 1.0\n",
      "\n",
      "Epoch 27. Loss: 0.022081433368469357, Train_acc 1.0\n",
      "\n",
      "Epoch 27. Loss: 0.023537485196660532, Train_acc 0.994140625\n",
      "\n",
      "Epoch 27. Loss: 0.02171363533352665, Train_acc 0.9953125\n",
      "\n",
      "Epoch 27. Loss: 0.019999243987558948, Train_acc 0.99609375\n",
      "\n",
      "Epoch 27. Loss: 0.018530267519913914, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 27. Loss: 0.018124046941694144, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 27. Loss: 0.016787271294084066, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 27. Loss: 0.015856258449483105, Train_acc 0.99765625\n",
      "\n",
      "Epoch 27. Loss: 0.021279913077528648, Train_acc 0.9943181818181818\n",
      "\n",
      "Epoch 27. Loss: 0.021016753664411938, Train_acc 0.994140625\n",
      "\n",
      "Epoch 27. Loss: 0.020643129640040846, Train_acc 0.9939903846153846\n",
      "\n",
      "Epoch 27. Loss: 0.019016530742393182, Train_acc 0.9944196428571429\n",
      "\n",
      "Epoch 27. Loss: 0.017838093652334432, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 27. Loss: 0.017128290509289462, Train_acc 0.9951171875\n",
      "\n",
      "Epoch 27. Loss: 0.015689627224674187, Train_acc 0.9954044117647058\n",
      "\n",
      "Epoch 27. Loss: 0.015075731984052387, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 27. Loss: 0.01572205867881178, Train_acc 0.9954769736842105\n",
      "\n",
      "Epoch 27. Loss: 0.01621098403496682, Train_acc 0.9953125\n",
      "\n",
      "Epoch 27. Loss: 0.01572793285351818, Train_acc 0.9951636904761905\n",
      "\n",
      "Epoch 27. Loss: 0.01576764805139743, Train_acc 0.9950284090909091\n",
      "\n",
      "Epoch 27. Loss: 0.014465866760358001, Train_acc 0.9952445652173914\n",
      "\n",
      "Epoch 27. Loss: 0.013308098954061973, Train_acc 0.9954427083333334\n",
      "\n",
      "Epoch 27. Loss: 0.013235655241102255, Train_acc 0.9953125\n",
      "\n",
      "Epoch 27. Loss: 0.01232368959148849, Train_acc 0.9954927884615384\n",
      "\n",
      "Epoch 27. Loss: 0.01268208236092441, Train_acc 0.9953703703703703\n",
      "\n",
      "Epoch 27. Loss: 0.014411936348027999, Train_acc 0.9952566964285714\n",
      "\n",
      "Epoch 27. Loss: 0.014993989970100239, Train_acc 0.9948814655172413\n",
      "\n",
      "Epoch 27. Loss: 0.014199491334687753, Train_acc 0.9950520833333333\n",
      "\n",
      "Epoch 27. Loss: 0.014032639612464086, Train_acc 0.9949596774193549\n",
      "\n",
      "Epoch 27. Loss: 0.012888361697755434, Train_acc 0.9951171875\n",
      "\n",
      "Epoch 27. Loss: 0.016795375289346735, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 27. Loss: 0.0182512067334288, Train_acc 0.9947150735294118\n",
      "\n",
      "Epoch 27. Loss: 0.01707766494465771, Train_acc 0.9948660714285714\n",
      "\n",
      "Epoch 27. Loss: 0.015645806441645944, Train_acc 0.9950086805555556\n",
      "\n",
      "Epoch 27. Loss: 0.01503738097096186, Train_acc 0.995143581081081\n",
      "\n",
      "Epoch 27. Loss: 0.018607011423212597, Train_acc 0.994860197368421\n",
      "\n",
      "Epoch 27. Loss: 0.01696263330175934, Train_acc 0.9949919871794872\n",
      "\n",
      "Epoch 27. Loss: 0.015551164875875037, Train_acc 0.9951171875\n",
      "\n",
      "Epoch 27. Loss: 0.014977191412106265, Train_acc 0.995045731707317\n",
      "\n",
      "Epoch 27. Loss: 0.013629412865460763, Train_acc 0.9951636904761905\n",
      "\n",
      "Epoch 27. Loss: 0.013562358512718245, Train_acc 0.995094476744186\n",
      "\n",
      "Epoch 27. Loss: 0.016599264378165092, Train_acc 0.9948508522727273\n",
      "\n",
      "Epoch 27. Loss: 0.0161971591128244, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 27. Loss: 0.015608532403111516, Train_acc 0.994735054347826\n",
      "\n",
      "Epoch 27. Loss: 0.015016317504674248, Train_acc 0.9948470744680851\n",
      "\n",
      "Epoch 27. Loss: 0.01811992165866201, Train_acc 0.9944661458333334\n",
      "\n",
      "Epoch 27. Loss: 0.017250606193447454, Train_acc 0.9945790816326531\n",
      "\n",
      "Epoch 27. Loss: 0.02238432580915482, Train_acc 0.99421875\n",
      "\n",
      "Epoch 27. Loss: 0.02043403495661817, Train_acc 0.9943321078431373\n",
      "\n",
      "Epoch 27. Loss: 0.01912997371461155, Train_acc 0.9944411057692307\n",
      "\n",
      "Epoch 27. Loss: 0.01934812272196557, Train_acc 0.9943985849056604\n",
      "\n",
      "Epoch 27. Loss: 0.01768462103718262, Train_acc 0.9945023148148148\n",
      "\n",
      "Epoch 27. Loss: 0.01716832977187998, Train_acc 0.9944602272727273\n",
      "\n",
      "Epoch 27. Loss: 0.0157019592838946, Train_acc 0.9945591517857143\n",
      "\n",
      "Epoch 27. Loss: 0.014428572577123018, Train_acc 0.9946546052631579\n",
      "\n",
      "Epoch 27. Loss: 0.013535257524818932, Train_acc 0.9947467672413793\n",
      "\n",
      "Epoch 27. Loss: 0.012503386142391642, Train_acc 0.9948358050847458\n",
      "\n",
      "Epoch 27. Loss: 0.01260014099854709, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 27. Loss: 0.012709065750793946, Train_acc 0.9947489754098361\n",
      "\n",
      "Epoch 27. Loss: 0.014824345611533224, Train_acc 0.9945816532258065\n",
      "\n",
      "Epoch 27. Loss: 0.015430418874025971, Train_acc 0.9945436507936508\n",
      "\n",
      "Epoch 27. Loss: 0.014026408313021628, Train_acc 0.99462890625\n",
      "\n",
      "Epoch 27. Loss: 0.0138043775424113, Train_acc 0.9947115384615385\n",
      "\n",
      "Epoch 27. Loss: 0.013533493102915597, Train_acc 0.9946732954545454\n",
      "\n",
      "Epoch 27. Loss: 0.016074282873863737, Train_acc 0.9945195895522388\n",
      "\n",
      "Epoch 27. Loss: 0.0147971357509745, Train_acc 0.9946001838235294\n",
      "\n",
      "Epoch 27. Loss: 0.013415473434705543, Train_acc 0.9946784420289855\n",
      "\n",
      "Epoch 27. Loss: 0.013185952253680534, Train_acc 0.9947544642857142\n",
      "\n",
      "Epoch 27. Loss: 0.01826643346030215, Train_acc 0.9940580985915493\n",
      "\n",
      "Epoch 27. Loss: 0.017047657513502533, Train_acc 0.994140625\n",
      "\n",
      "Epoch 27. Loss: 0.01701836882729825, Train_acc 0.9941138698630136\n",
      "\n",
      "Epoch 27. Loss: 0.016035619701738626, Train_acc 0.9941934121621622\n",
      "\n",
      "Epoch 27. Loss: 0.016311515302177195, Train_acc 0.9941666666666666\n",
      "\n",
      "Epoch 27. Loss: 0.01502850355905228, Train_acc 0.9942434210526315\n",
      "\n",
      "Epoch 27. Loss: 0.01546741252871096, Train_acc 0.9942167207792207\n",
      "\n",
      "Epoch 27. Loss: 0.017245755127654135, Train_acc 0.9940905448717948\n",
      "\n",
      "Epoch 27. Loss: 0.016364860358016785, Train_acc 0.9941653481012658\n",
      "\n",
      "Epoch 27. Loss: 0.015429131648773338, Train_acc 0.99423828125\n",
      "\n",
      "Epoch 27. Loss: 0.015864412824959505, Train_acc 0.9942129629629629\n",
      "\n",
      "Epoch 27. Loss: 0.014845007571414963, Train_acc 0.9942835365853658\n",
      "\n",
      "Epoch 27. Loss: 0.01423834893509971, Train_acc 0.9943524096385542\n",
      "\n",
      "Epoch 27. Loss: 0.013155212212065401, Train_acc 0.9944196428571429\n",
      "\n",
      "Epoch 27. Loss: 0.012845529522859642, Train_acc 0.9944852941176471\n",
      "\n",
      "Epoch 27. Loss: 0.015510614281621805, Train_acc 0.9944585755813954\n",
      "\n",
      "Epoch 27. Loss: 0.014959704729819803, Train_acc 0.9945222701149425\n",
      "\n",
      "Epoch 27. Loss: 0.01623550781867311, Train_acc 0.9944957386363636\n",
      "\n",
      "Epoch 27. Loss: 0.019010086172176057, Train_acc 0.9944698033707865\n",
      "\n",
      "Epoch 27. Loss: 0.018672819566743958, Train_acc 0.9944444444444445\n",
      "\n",
      "Epoch 27. Loss: 0.022250479652301123, Train_acc 0.9944196428571429\n",
      "\n",
      "Epoch 27. Loss: 0.022253387929930375, Train_acc 0.9943104619565217\n",
      "\n",
      "Epoch 27. Loss: 0.02070466607013412, Train_acc 0.9943716397849462\n",
      "\n",
      "Epoch 27. Loss: 0.01910135715297521, Train_acc 0.9944315159574468\n",
      "\n",
      "Epoch 27. Loss: 0.022024493909701657, Train_acc 0.9943256578947368\n",
      "\n",
      "Epoch 27. Loss: 0.02164308692976083, Train_acc 0.9942220052083334\n",
      "\n",
      "Epoch 27. Loss: 0.024310685389914325, Train_acc 0.9942010309278351\n",
      "\n",
      "Epoch 27. Loss: 0.024412134388397524, Train_acc 0.9941007653061225\n",
      "\n",
      "Epoch 27. Loss: 0.02661820979354715, Train_acc 0.9940025252525253\n",
      "\n",
      "Epoch 27. Loss: 0.029105238077979705, Train_acc 0.993984375\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 27 Batch 100] Loss: 0.033885550014324264 Training: accuracy=0.993812\n",
      "Epoch 27. Loss: 0.033885550014324264, Train_acc 0.9938118811881188\n",
      "\n",
      "Epoch 27. Loss: 0.030916559790877055, Train_acc 0.9938725490196079\n",
      "\n",
      "Epoch 27. Loss: 0.02817312550870259, Train_acc 0.9939320388349514\n",
      "\n",
      "Epoch 27. Loss: 0.0263204931787641, Train_acc 0.9939903846153846\n",
      "\n",
      "Epoch 27. Loss: 0.028854796773671313, Train_acc 0.9938988095238095\n",
      "\n",
      "Epoch 27. Loss: 0.030328091147374395, Train_acc 0.9937352594339622\n",
      "\n",
      "Epoch 27. Loss: 0.03215421728446896, Train_acc 0.9935017523364486\n",
      "\n",
      "Epoch 27. Loss: 0.03428799502987995, Train_acc 0.9934172453703703\n",
      "\n",
      "Epoch 27. Loss: 0.032830443132871395, Train_acc 0.9933342889908257\n",
      "\n",
      "Epoch 27. Loss: 0.03431514678801954, Train_acc 0.9933238636363636\n",
      "\n",
      "Epoch 27. Loss: 0.03408873106604094, Train_acc 0.9931728603603603\n",
      "\n",
      "Epoch 27. Loss: 0.032671747957753614, Train_acc 0.9931640625\n",
      "\n",
      "Epoch 27. Loss: 0.031657709014493954, Train_acc 0.9931554203539823\n",
      "\n",
      "Epoch 27. Loss: 0.03336604572720414, Train_acc 0.993078399122807\n",
      "\n",
      "Epoch 27. Loss: 0.033861166722063, Train_acc 0.9929347826086956\n",
      "\n",
      "Epoch 27. Loss: 0.032217318217292824, Train_acc 0.9929956896551724\n",
      "\n",
      "Epoch 27. Loss: 0.034845769986810146, Train_acc 0.9928552350427351\n",
      "\n",
      "Epoch 27. Loss: 0.03480577409443425, Train_acc 0.9928495762711864\n",
      "\n",
      "Epoch 27. Loss: 0.03330927996495814, Train_acc 0.9928440126050421\n",
      "\n",
      "Epoch 27. Loss: 0.03183863006823764, Train_acc 0.9928385416666666\n",
      "\n",
      "Epoch 27. Loss: 0.02979701585212504, Train_acc 0.9928977272727273\n",
      "\n",
      "Epoch 27. Loss: 0.027949894346050816, Train_acc 0.9928919057377049\n",
      "\n",
      "Epoch 27. Loss: 0.03270170081608212, Train_acc 0.9928861788617886\n",
      "\n",
      "Epoch 27. Loss: 0.032607238268429484, Train_acc 0.9928175403225806\n",
      "\n",
      "Epoch 27. Loss: 0.03245744066736798, Train_acc 0.99275\n",
      "\n",
      "Epoch 27. Loss: 0.031559664001778065, Train_acc 0.9927455357142857\n",
      "\n",
      "Epoch 27. Loss: 0.02953797585432109, Train_acc 0.9928026574803149\n",
      "\n",
      "Epoch 27. Loss: 0.043584314048269776, Train_acc 0.99237060546875\n",
      "\n",
      "Epoch 27. Loss: 0.04022021533696001, Train_acc 0.9923691860465116\n",
      "\n",
      "Epoch 27. Loss: 0.036566906086934914, Train_acc 0.9924278846153847\n",
      "\n",
      "Epoch 27. Loss: 0.040209325026571735, Train_acc 0.9923067748091603\n",
      "\n",
      "Epoch 27. Loss: 0.04487814101973175, Train_acc 0.9920099431818182\n",
      "\n",
      "Epoch 27. Loss: 0.0420167419096738, Train_acc 0.9920112781954887\n",
      "\n",
      "Epoch 27. Loss: 0.038851078680686046, Train_acc 0.992070895522388\n",
      "\n",
      "Epoch 27. Loss: 0.04316509261566272, Train_acc 0.9918981481481481\n",
      "\n",
      "Epoch 27. Loss: 0.05160527224693778, Train_acc 0.9916130514705882\n",
      "\n",
      "Epoch 27. Loss: 0.04950700461435989, Train_acc 0.9915602189781022\n",
      "\n",
      "Epoch 27. Loss: 0.04630876750858434, Train_acc 0.9915647644927537\n",
      "\n",
      "Epoch 27. Loss: 0.06092589352528878, Train_acc 0.9911196043165468\n",
      "\n",
      "Epoch 27. Loss: 0.056184393110131875, Train_acc 0.9911830357142857\n",
      "\n",
      "Epoch 27. Loss: 0.05458318354987114, Train_acc 0.9910239361702128\n",
      "\n",
      "Epoch 27. Loss: 0.05028317361893961, Train_acc 0.991087147887324\n",
      "\n",
      "Epoch 27. Loss: 0.05146087324460783, Train_acc 0.9909855769230769\n",
      "\n",
      "Epoch 27. Loss: 0.04819095517701302, Train_acc 0.9909939236111112\n",
      "\n",
      "Epoch 27. Loss: 0.04511974854475016, Train_acc 0.9910021551724137\n",
      "\n",
      "Epoch 27. Loss: 0.044804768441966965, Train_acc 0.9909032534246576\n",
      "\n",
      "Epoch 27. Loss: 0.049678507458137094, Train_acc 0.9906994047619048\n",
      "\n",
      "Epoch 27. Loss: 0.04728647125002738, Train_acc 0.9906566722972973\n",
      "\n",
      "Epoch 27. Loss: 0.04900417598101791, Train_acc 0.9905096476510067\n",
      "\n",
      "Epoch 27. Loss: 0.04788270478260484, Train_acc 0.99046875\n",
      "\n",
      "Epoch 27. Loss: 0.04531209701131553, Train_acc 0.9904801324503312\n",
      "\n",
      "Epoch 27. Loss: 0.04424983777550552, Train_acc 0.990491365131579\n",
      "\n",
      "Epoch 27. Loss: 0.04128540779677952, Train_acc 0.9905024509803921\n",
      "\n",
      "Epoch 27. Loss: 0.038209278849016946, Train_acc 0.9905641233766234\n",
      "\n",
      "Epoch 27. Loss: 0.03744513475202142, Train_acc 0.9905745967741936\n",
      "\n",
      "Epoch 27. Loss: 0.03471551598953562, Train_acc 0.9906350160256411\n",
      "\n",
      "Epoch 27. Loss: 0.03632293391389273, Train_acc 0.9905453821656051\n",
      "\n",
      "Epoch 27. Loss: 0.036633486284279426, Train_acc 0.9905557753164557\n",
      "\n",
      "Epoch 27. Loss: 0.03427129969384993, Train_acc 0.9905660377358491\n",
      "\n",
      "Epoch 27. Loss: 0.035918302330852074, Train_acc 0.9904296875\n",
      "\n",
      "Epoch 27. Loss: 0.034360564606023304, Train_acc 0.9903920807453416\n",
      "\n",
      "Epoch 27. Loss: 0.03230590203997416, Train_acc 0.9904513888888888\n",
      "\n",
      "Epoch 27. Loss: 0.03497200679418674, Train_acc 0.9904141104294478\n",
      "\n",
      "Epoch 27. Loss: 0.03436341521117595, Train_acc 0.9903772865853658\n",
      "\n",
      "Epoch 27. Loss: 0.03260245482897914, Train_acc 0.9904356060606061\n",
      "\n",
      "Epoch 27. Loss: 0.03085405284860274, Train_acc 0.9904461596385542\n",
      "\n",
      "Epoch 27. Loss: 0.028370074075745412, Train_acc 0.9905033682634731\n",
      "\n",
      "Epoch 27. Loss: 0.028921649955767577, Train_acc 0.9904668898809523\n",
      "\n",
      "Epoch 27. Loss: 0.02701667357137041, Train_acc 0.9905232988165681\n",
      "\n",
      "Epoch 27. Loss: 0.02573225053310606, Train_acc 0.9905330882352941\n",
      "\n",
      "Epoch 27. Loss: 0.024974096064211845, Train_acc 0.9905427631578947\n",
      "\n",
      "Epoch 27. Loss: 0.024689256692923833, Train_acc 0.9905523255813954\n",
      "\n",
      "Epoch 27. Loss: 0.023275833542642947, Train_acc 0.990606936416185\n",
      "\n",
      "Epoch 27. Loss: 0.021909865799246392, Train_acc 0.9906609195402298\n",
      "\n",
      "Epoch 27. Loss: 0.02064435066672995, Train_acc 0.9907142857142858\n",
      "\n",
      "Epoch 27. Loss: 0.019301480954672406, Train_acc 0.9907670454545454\n",
      "\n",
      "Epoch 27. Loss: 0.02152805945794479, Train_acc 0.990775070621469\n",
      "\n",
      "Epoch 27. Loss: 0.02014926704261329, Train_acc 0.9908268960674157\n",
      "\n",
      "Epoch 27. Loss: 0.02091598349803948, Train_acc 0.9907908519553073\n",
      "\n",
      "Epoch 27. Loss: 0.02163375545734999, Train_acc 0.9907552083333333\n",
      "\n",
      "Epoch 27. Loss: 0.019777564066714087, Train_acc 0.9908062845303868\n",
      "\n",
      "Epoch 27. Loss: 0.0200176445243353, Train_acc 0.9908138736263736\n",
      "\n",
      "Epoch 27. Loss: 0.018979479213588925, Train_acc 0.9908640710382514\n",
      "\n",
      "Epoch 27. Loss: 0.01739408272917583, Train_acc 0.9909137228260869\n",
      "\n",
      "Epoch 27. Loss: 0.015925083244022857, Train_acc 0.9909628378378378\n",
      "\n",
      "Epoch 27. Loss: 0.01734092937485319, Train_acc 0.9909274193548387\n",
      "\n",
      "Epoch 27. Loss: 0.01630354400084265, Train_acc 0.990975935828877\n",
      "\n",
      "Epoch 27. Loss: 0.014896285315804312, Train_acc 0.9910239361702128\n",
      "\n",
      "Epoch 27. Loss: 0.0172141836110824, Train_acc 0.9910300925925926\n",
      "\n",
      "Epoch 27. Loss: 0.01580886337283167, Train_acc 0.9910773026315789\n",
      "\n",
      "Epoch 27. Loss: 0.017201456068064985, Train_acc 0.9910422120418848\n",
      "\n",
      "Epoch 27. Loss: 0.01734050412902792, Train_acc 0.9910888671875\n",
      "\n",
      "Epoch 27. Loss: 0.016104260999079585, Train_acc 0.9911350388601037\n",
      "\n",
      "Epoch 27. Loss: 0.016256691069706713, Train_acc 0.9911404639175257\n",
      "\n",
      "Epoch 27. Loss: 0.014805000994123758, Train_acc 0.9911858974358975\n",
      "\n",
      "Epoch 27. Loss: 0.015749821341202626, Train_acc 0.9912\n",
      "\n",
      "Epoch 28. Loss: 0.014326533237583311, Train_acc 1.0\n",
      "\n",
      "Epoch 28. Loss: 0.014633336790937368, Train_acc 0.99609375\n",
      "\n",
      "Epoch 28. Loss: 0.014152909781221912, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 28. Loss: 0.01455368702025804, Train_acc 0.99609375\n",
      "\n",
      "Epoch 28. Loss: 0.01324905287693375, Train_acc 0.996875\n",
      "\n",
      "Epoch 28. Loss: 0.0121195424647221, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 28. Loss: 0.012109959469087932, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 28. Loss: 0.012079868532730353, Train_acc 0.99609375\n",
      "\n",
      "Epoch 28. Loss: 0.011947674644005191, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 28. Loss: 0.013870069727610254, Train_acc 0.99609375\n",
      "\n",
      "Epoch 28. Loss: 0.012915152610743674, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 28. Loss: 0.011821030470867126, Train_acc 0.9967447916666666\n",
      "\n",
      "Epoch 28. Loss: 0.011306253669237348, Train_acc 0.9969951923076923\n",
      "\n",
      "Epoch 28. Loss: 0.01058736559345596, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 28. Loss: 0.009950275178351458, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 28. Loss: 0.0094379937810586, Train_acc 0.99755859375\n",
      "\n",
      "Epoch 28. Loss: 0.009068361708556363, Train_acc 0.9977022058823529\n",
      "\n",
      "Epoch 28. Loss: 0.00966574886578448, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 28. Loss: 0.009146879087878413, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 28. Loss: 0.009669022608691288, Train_acc 0.997265625\n",
      "\n",
      "Epoch 28. Loss: 0.010010257991904466, Train_acc 0.9970238095238095\n",
      "\n",
      "Epoch 28. Loss: 0.013914692222554492, Train_acc 0.99609375\n",
      "\n",
      "Epoch 28. Loss: 0.014353561687003677, Train_acc 0.9959239130434783\n",
      "\n",
      "Epoch 28. Loss: 0.01356189344639877, Train_acc 0.99609375\n",
      "\n",
      "Epoch 28. Loss: 0.013395232134896216, Train_acc 0.99625\n",
      "\n",
      "Epoch 28. Loss: 0.012917754880044787, Train_acc 0.9963942307692307\n",
      "\n",
      "Epoch 28. Loss: 0.011726108303475912, Train_acc 0.9965277777777778\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28. Loss: 0.011177021662123683, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 28. Loss: 0.020177851676697448, Train_acc 0.9951508620689655\n",
      "\n",
      "Epoch 28. Loss: 0.019058743433435187, Train_acc 0.9953125\n",
      "\n",
      "Epoch 28. Loss: 0.02856924770737835, Train_acc 0.9947076612903226\n",
      "\n",
      "Epoch 28. Loss: 0.028236431935117975, Train_acc 0.99462890625\n",
      "\n",
      "Epoch 28. Loss: 0.02709321578623623, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 28. Loss: 0.027746044697896575, Train_acc 0.9947150735294118\n",
      "\n",
      "Epoch 28. Loss: 0.025684988478603305, Train_acc 0.9948660714285714\n",
      "\n",
      "Epoch 28. Loss: 0.02480941204409213, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 28. Loss: 0.032029672904435494, Train_acc 0.9940878378378378\n",
      "\n",
      "Epoch 28. Loss: 0.03476858201052877, Train_acc 0.9936266447368421\n",
      "\n",
      "Epoch 28. Loss: 0.03227873509683728, Train_acc 0.9937900641025641\n",
      "\n",
      "Epoch 28. Loss: 0.037459585358725664, Train_acc 0.9931640625\n",
      "\n",
      "Epoch 28. Loss: 0.03542398322227003, Train_acc 0.993140243902439\n",
      "\n",
      "Epoch 28. Loss: 0.03265474920401634, Train_acc 0.9933035714285714\n",
      "\n",
      "Epoch 28. Loss: 0.029981503845494938, Train_acc 0.9934593023255814\n",
      "\n",
      "Epoch 28. Loss: 0.027348401595644906, Train_acc 0.9936079545454546\n",
      "\n",
      "Epoch 28. Loss: 0.025369427401118954, Train_acc 0.99375\n",
      "\n",
      "Epoch 28. Loss: 0.02355819207277311, Train_acc 0.9938858695652174\n",
      "\n",
      "Epoch 28. Loss: 0.02317951220434677, Train_acc 0.9936835106382979\n",
      "\n",
      "Epoch 28. Loss: 0.025120287521139727, Train_acc 0.9934895833333334\n",
      "\n",
      "Epoch 28. Loss: 0.024852675393333388, Train_acc 0.9936224489795918\n",
      "\n",
      "Epoch 28. Loss: 0.024182438577810245, Train_acc 0.99359375\n",
      "\n",
      "Epoch 28. Loss: 0.02219199150481759, Train_acc 0.9937193627450981\n",
      "\n",
      "Epoch 28. Loss: 0.02133351852457767, Train_acc 0.9938401442307693\n",
      "\n",
      "Epoch 28. Loss: 0.023899740710506247, Train_acc 0.9935141509433962\n",
      "\n",
      "Epoch 28. Loss: 0.02288725018991477, Train_acc 0.9933449074074074\n",
      "\n",
      "Epoch 28. Loss: 0.022729103070438923, Train_acc 0.9931818181818182\n",
      "\n",
      "Epoch 28. Loss: 0.021284886011726577, Train_acc 0.9933035714285714\n",
      "\n",
      "Epoch 28. Loss: 0.0209506872080984, Train_acc 0.9932839912280702\n",
      "\n",
      "Epoch 28. Loss: 0.02013006665482124, Train_acc 0.9932650862068966\n",
      "\n",
      "Epoch 28. Loss: 0.019286915416336065, Train_acc 0.9932468220338984\n",
      "\n",
      "Epoch 28. Loss: 0.01777183531282783, Train_acc 0.993359375\n",
      "\n",
      "Epoch 28. Loss: 0.020839885788188343, Train_acc 0.9933401639344263\n",
      "\n",
      "Epoch 28. Loss: 0.019569311458938685, Train_acc 0.9934475806451613\n",
      "\n",
      "Epoch 28. Loss: 0.018984131666189463, Train_acc 0.9935515873015873\n",
      "\n",
      "Epoch 28. Loss: 0.01740254598770234, Train_acc 0.99365234375\n",
      "\n",
      "Epoch 28. Loss: 0.01704642448944175, Train_acc 0.9936298076923077\n",
      "\n",
      "Epoch 28. Loss: 0.019389119959971224, Train_acc 0.9934895833333334\n",
      "\n",
      "Epoch 28. Loss: 0.018938979812354668, Train_acc 0.9934701492537313\n",
      "\n",
      "Epoch 28. Loss: 0.017630873951665304, Train_acc 0.9935661764705882\n",
      "\n",
      "Epoch 28. Loss: 0.020741339102403885, Train_acc 0.9933197463768116\n",
      "\n",
      "Epoch 28. Loss: 0.019077131805956275, Train_acc 0.9934151785714286\n",
      "\n",
      "Epoch 28. Loss: 0.020218177206641357, Train_acc 0.9933978873239436\n",
      "\n",
      "Epoch 28. Loss: 0.025403510988348057, Train_acc 0.9932725694444444\n",
      "\n",
      "Epoch 28. Loss: 0.02992483061009049, Train_acc 0.9931506849315068\n",
      "\n",
      "Epoch 28. Loss: 0.027278140286870894, Train_acc 0.9932432432432432\n",
      "\n",
      "Epoch 28. Loss: 0.024894761383773174, Train_acc 0.9933333333333333\n",
      "\n",
      "Epoch 28. Loss: 0.022869198719627816, Train_acc 0.993421052631579\n",
      "\n",
      "Epoch 28. Loss: 0.021237578272790155, Train_acc 0.9935064935064936\n",
      "\n",
      "Epoch 28. Loss: 0.021665926863226687, Train_acc 0.9934895833333334\n",
      "\n",
      "Epoch 28. Loss: 0.019903918677842674, Train_acc 0.9935719936708861\n",
      "\n",
      "Epoch 28. Loss: 0.018324798113950543, Train_acc 0.99365234375\n",
      "\n",
      "Epoch 28. Loss: 0.020893568486137798, Train_acc 0.9935378086419753\n",
      "\n",
      "Epoch 28. Loss: 0.0221553747566017, Train_acc 0.9934260670731707\n",
      "\n",
      "Epoch 28. Loss: 0.02815720481081061, Train_acc 0.9929405120481928\n",
      "\n",
      "Epoch 28. Loss: 0.036943167827158445, Train_acc 0.9928385416666666\n",
      "\n",
      "Epoch 28. Loss: 0.03363945224915082, Train_acc 0.9929227941176471\n",
      "\n",
      "Epoch 28. Loss: 0.03110484437525989, Train_acc 0.9930050872093024\n",
      "\n",
      "Epoch 28. Loss: 0.031740691420859585, Train_acc 0.9929058908045977\n",
      "\n",
      "Epoch 28. Loss: 0.0350354786134599, Train_acc 0.9928089488636364\n",
      "\n",
      "Epoch 28. Loss: 0.034296827428058244, Train_acc 0.9928019662921348\n",
      "\n",
      "Epoch 28. Loss: 0.03466746642814469, Train_acc 0.9926215277777778\n",
      "\n",
      "Epoch 28. Loss: 0.03526569769942514, Train_acc 0.9925309065934066\n",
      "\n",
      "Epoch 28. Loss: 0.03391274578419702, Train_acc 0.9925271739130435\n",
      "\n",
      "Epoch 28. Loss: 0.03516324289483467, Train_acc 0.9925235215053764\n",
      "\n",
      "Epoch 28. Loss: 0.03260211684488629, Train_acc 0.9926030585106383\n",
      "\n",
      "Epoch 28. Loss: 0.03190222416684069, Train_acc 0.992516447368421\n",
      "\n",
      "Epoch 28. Loss: 0.032636566022321914, Train_acc 0.9925130208333334\n",
      "\n",
      "Epoch 28. Loss: 0.03420027879710674, Train_acc 0.9924291237113402\n",
      "\n",
      "Epoch 28. Loss: 0.030952797609588623, Train_acc 0.9925063775510204\n",
      "\n",
      "Epoch 28. Loss: 0.029490376102645207, Train_acc 0.9925031565656566\n",
      "\n",
      "Epoch 28. Loss: 0.027392383855032034, Train_acc 0.9925\n",
      "\n",
      "[Epoch 28 Batch 100] Loss: 0.027905469558936753 Training: accuracy=0.992497\n",
      "Epoch 28. Loss: 0.027905469558936753, Train_acc 0.992496905940594\n",
      "\n",
      "Epoch 28. Loss: 0.02931224667039728, Train_acc 0.9924938725490197\n",
      "\n",
      "Epoch 28. Loss: 0.030471256640617988, Train_acc 0.9924150485436893\n",
      "\n",
      "Epoch 28. Loss: 0.02812920726498807, Train_acc 0.9924879807692307\n",
      "\n",
      "Epoch 28. Loss: 0.026570393503405256, Train_acc 0.992485119047619\n",
      "\n",
      "Epoch 28. Loss: 0.029754311317829137, Train_acc 0.9922612028301887\n",
      "\n",
      "Epoch 28. Loss: 0.02834984553572045, Train_acc 0.9922605140186916\n",
      "\n",
      "Epoch 28. Loss: 0.02895342574462151, Train_acc 0.9921875\n",
      "\n",
      "Epoch 28. Loss: 0.02971341400693228, Train_acc 0.9921158256880734\n",
      "\n",
      "Epoch 28. Loss: 0.02736093636393878, Train_acc 0.9921875\n",
      "\n",
      "Epoch 28. Loss: 0.02509826640224755, Train_acc 0.9922578828828829\n",
      "\n",
      "Epoch 28. Loss: 0.024607011407044233, Train_acc 0.9921875\n",
      "\n",
      "Epoch 28. Loss: 0.02320126237370971, Train_acc 0.9922566371681416\n",
      "\n",
      "Epoch 28. Loss: 0.022548743339464696, Train_acc 0.9923245614035088\n",
      "\n",
      "Epoch 28. Loss: 0.02131612777896431, Train_acc 0.9923913043478261\n",
      "\n",
      "Epoch 28. Loss: 0.024497949452886348, Train_acc 0.9923221982758621\n",
      "\n",
      "Epoch 28. Loss: 0.023178926703354148, Train_acc 0.9923210470085471\n",
      "\n",
      "Epoch 28. Loss: 0.023320954789537576, Train_acc 0.9923199152542372\n",
      "\n",
      "Epoch 28. Loss: 0.022307318150834785, Train_acc 0.9923188025210085\n",
      "\n",
      "Epoch 28. Loss: 0.021765533491822968, Train_acc 0.9923177083333333\n",
      "\n",
      "Epoch 28. Loss: 0.0214935694529291, Train_acc 0.992316632231405\n",
      "\n",
      "Epoch 28. Loss: 0.020077680816681032, Train_acc 0.9923796106557377\n",
      "\n",
      "Epoch 28. Loss: 0.01834853511267678, Train_acc 0.9924415650406504\n",
      "\n",
      "Epoch 28. Loss: 0.017885149553094292, Train_acc 0.9924395161290323\n",
      "\n",
      "Epoch 28. Loss: 0.01861233561605869, Train_acc 0.992375\n",
      "\n",
      "Epoch 28. Loss: 0.02104944034848206, Train_acc 0.9923735119047619\n",
      "\n",
      "Epoch 28. Loss: 0.020558597358467514, Train_acc 0.992433562992126\n",
      "\n",
      "Epoch 28. Loss: 0.019614249881269634, Train_acc 0.992431640625\n",
      "\n",
      "Epoch 28. Loss: 0.01915611186950991, Train_acc 0.9924297480620154\n",
      "\n",
      "Epoch 28. Loss: 0.018467567441579007, Train_acc 0.9924879807692307\n",
      "\n",
      "Epoch 28. Loss: 0.02127832285557655, Train_acc 0.9924260496183206\n",
      "\n",
      "Epoch 28. Loss: 0.02150950774098457, Train_acc 0.9923650568181818\n",
      "\n",
      "Epoch 28. Loss: 0.020187605142250844, Train_acc 0.9924224624060151\n",
      "\n",
      "Epoch 28. Loss: 0.019058512776036728, Train_acc 0.9924790111940298\n",
      "\n",
      "Epoch 28. Loss: 0.026735571440106333, Train_acc 0.9922453703703704\n",
      "\n",
      "Epoch 28. Loss: 0.024821095326360197, Train_acc 0.9923023897058824\n",
      "\n",
      "Epoch 28. Loss: 0.023994913094177363, Train_acc 0.9923015510948905\n",
      "\n",
      "Epoch 28. Loss: 0.02522456271314727, Train_acc 0.9923007246376812\n",
      "\n",
      "Epoch 28. Loss: 0.025050994734741212, Train_acc 0.9922999100719424\n",
      "\n",
      "Epoch 28. Loss: 0.024506298733452225, Train_acc 0.9922991071428572\n",
      "\n",
      "Epoch 28. Loss: 0.022417361393003998, Train_acc 0.9923537234042553\n",
      "\n",
      "Epoch 28. Loss: 0.022442577276613716, Train_acc 0.9923525528169014\n",
      "\n",
      "Epoch 28. Loss: 0.02446990020035482, Train_acc 0.9922967657342657\n",
      "\n",
      "Epoch 28. Loss: 0.02419040440284112, Train_acc 0.9923502604166666\n",
      "\n",
      "Epoch 28. Loss: 0.022894476216401748, Train_acc 0.9923491379310345\n",
      "\n",
      "Epoch 28. Loss: 0.02184378522160598, Train_acc 0.9924015410958904\n",
      "\n",
      "Epoch 28. Loss: 0.02058737790977611, Train_acc 0.9924532312925171\n",
      "\n",
      "Epoch 28. Loss: 0.01977841634061027, Train_acc 0.9924514358108109\n",
      "\n",
      "Epoch 28. Loss: 0.018999720694179132, Train_acc 0.9925020973154363\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28. Loss: 0.018291344007749673, Train_acc 0.9925\n",
      "\n",
      "Epoch 28. Loss: 0.01873904240360795, Train_acc 0.9924979304635762\n",
      "\n",
      "Epoch 28. Loss: 0.02137827222553735, Train_acc 0.9923930921052632\n",
      "\n",
      "Epoch 28. Loss: 0.01962626661367278, Train_acc 0.9924428104575164\n",
      "\n",
      "Epoch 28. Loss: 0.019079973251435702, Train_acc 0.9924411525974026\n",
      "\n",
      "Epoch 28. Loss: 0.019402897500229072, Train_acc 0.9924395161290323\n",
      "\n",
      "Epoch 28. Loss: 0.017650960569738323, Train_acc 0.9924879807692307\n",
      "\n",
      "Epoch 28. Loss: 0.018469474779211556, Train_acc 0.9924363057324841\n",
      "\n",
      "Epoch 28. Loss: 0.020374842345693478, Train_acc 0.9923852848101266\n",
      "\n",
      "Epoch 28. Loss: 0.019961526566724872, Train_acc 0.9923840408805031\n",
      "\n",
      "Epoch 28. Loss: 0.02022719583569249, Train_acc 0.9923828125\n",
      "\n",
      "Epoch 28. Loss: 0.020013021618052847, Train_acc 0.992381599378882\n",
      "\n",
      "Epoch 28. Loss: 0.02310617687397408, Train_acc 0.9923321759259259\n",
      "\n",
      "Epoch 28. Loss: 0.02571315658473856, Train_acc 0.9922833588957055\n",
      "\n",
      "Epoch 28. Loss: 0.023536040388872206, Train_acc 0.9923304115853658\n",
      "\n",
      "Epoch 28. Loss: 0.021796095597740994, Train_acc 0.992376893939394\n",
      "\n",
      "Epoch 28. Loss: 0.02157447403192251, Train_acc 0.9923757530120482\n",
      "\n",
      "Epoch 28. Loss: 0.025950969745395146, Train_acc 0.9922342814371258\n",
      "\n",
      "Epoch 28. Loss: 0.02344034135350069, Train_acc 0.9922805059523809\n",
      "\n",
      "Epoch 28. Loss: 0.02410467135913802, Train_acc 0.9922337278106509\n",
      "\n",
      "Epoch 28. Loss: 0.022989625030079182, Train_acc 0.9922334558823529\n",
      "\n",
      "Epoch 28. Loss: 0.02949012827275875, Train_acc 0.9921875\n",
      "\n",
      "Epoch 28. Loss: 0.029834334654200222, Train_acc 0.9921420784883721\n",
      "\n",
      "Epoch 28. Loss: 0.02706499311000539, Train_acc 0.9921875\n",
      "\n",
      "Epoch 28. Loss: 0.02921839129332095, Train_acc 0.9921426005747126\n",
      "\n",
      "Epoch 28. Loss: 0.029180359174937512, Train_acc 0.9921428571428571\n",
      "\n",
      "Epoch 28. Loss: 0.02669196257081375, Train_acc 0.9921875\n",
      "\n",
      "Epoch 28. Loss: 0.024533380120278107, Train_acc 0.992231638418079\n",
      "\n",
      "Epoch 28. Loss: 0.023072969622266928, Train_acc 0.9922313904494382\n",
      "\n",
      "Epoch 28. Loss: 0.021279334080013014, Train_acc 0.9922747905027933\n",
      "\n",
      "Epoch 28. Loss: 0.021263905884437898, Train_acc 0.9922309027777778\n",
      "\n",
      "Epoch 28. Loss: 0.02272797802532894, Train_acc 0.9922306629834254\n",
      "\n",
      "Epoch 28. Loss: 0.0213853560599254, Train_acc 0.9922733516483516\n",
      "\n",
      "Epoch 28. Loss: 0.02017514370419679, Train_acc 0.9923155737704918\n",
      "\n",
      "Epoch 28. Loss: 0.01884310347062139, Train_acc 0.9923573369565217\n",
      "\n",
      "Epoch 28. Loss: 0.025177314748362795, Train_acc 0.9923141891891892\n",
      "\n",
      "Epoch 28. Loss: 0.02598056558072218, Train_acc 0.9923135080645161\n",
      "\n",
      "Epoch 28. Loss: 0.02441906033798738, Train_acc 0.9923128342245989\n",
      "\n",
      "Epoch 28. Loss: 0.0279381142453374, Train_acc 0.9923121675531915\n",
      "\n",
      "Epoch 28. Loss: 0.026787323853017825, Train_acc 0.9923115079365079\n",
      "\n",
      "Epoch 28. Loss: 0.026078339830614868, Train_acc 0.9923108552631579\n",
      "\n",
      "Epoch 28. Loss: 0.02689271658561624, Train_acc 0.9922284031413613\n",
      "\n",
      "Epoch 28. Loss: 0.025091808757799837, Train_acc 0.9922688802083334\n",
      "\n",
      "Epoch 28. Loss: 0.024300788205818512, Train_acc 0.9922684585492227\n",
      "\n",
      "Epoch 28. Loss: 0.023673141736051003, Train_acc 0.9922680412371134\n",
      "\n",
      "Epoch 28. Loss: 0.02320940322124412, Train_acc 0.9922676282051283\n",
      "\n",
      "Epoch 28. Loss: 0.021193910836109078, Train_acc 0.99228\n",
      "\n",
      "Epoch 29. Loss: 0.01977572518491318, Train_acc 1.0\n",
      "\n",
      "Epoch 29. Loss: 0.01836134740884814, Train_acc 1.0\n",
      "\n",
      "Epoch 29. Loss: 0.019583419703028022, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 29. Loss: 0.01824851908057757, Train_acc 0.998046875\n",
      "\n",
      "Epoch 29. Loss: 0.01806240654232944, Train_acc 0.996875\n",
      "\n",
      "Epoch 29. Loss: 0.018200169887329743, Train_acc 0.99609375\n",
      "\n",
      "Epoch 29. Loss: 0.019490238326357847, Train_acc 0.9944196428571429\n",
      "\n",
      "Epoch 29. Loss: 0.018973885984778744, Train_acc 0.994140625\n",
      "\n",
      "Epoch 29. Loss: 0.017456275621520287, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 29. Loss: 0.01595865190354002, Train_acc 0.9953125\n",
      "\n",
      "Epoch 29. Loss: 0.016338497589472048, Train_acc 0.9943181818181818\n",
      "\n",
      "Epoch 29. Loss: 0.014959363530227344, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 29. Loss: 0.013819016753270151, Train_acc 0.9951923076923077\n",
      "\n",
      "Epoch 29. Loss: 0.013138995579526355, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 29. Loss: 0.012266095793973383, Train_acc 0.9958333333333333\n",
      "\n",
      "Epoch 29. Loss: 0.011674181478155533, Train_acc 0.99609375\n",
      "\n",
      "Epoch 29. Loss: 0.010976850122823905, Train_acc 0.9963235294117647\n",
      "\n",
      "Epoch 29. Loss: 0.01152650990094059, Train_acc 0.99609375\n",
      "\n",
      "Epoch 29. Loss: 0.01129550336753112, Train_acc 0.9962993421052632\n",
      "\n",
      "Epoch 29. Loss: 0.010492225922612387, Train_acc 0.996484375\n",
      "\n",
      "Epoch 29. Loss: 0.010743868555845056, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 29. Loss: 0.009988935494769723, Train_acc 0.9968039772727273\n",
      "\n",
      "Epoch 29. Loss: 0.009823205821379225, Train_acc 0.9969429347826086\n",
      "\n",
      "Epoch 29. Loss: 0.012957512440679251, Train_acc 0.9967447916666666\n",
      "\n",
      "Epoch 29. Loss: 0.013065143896547955, Train_acc 0.9965625\n",
      "\n",
      "Epoch 29. Loss: 0.01282157757735968, Train_acc 0.9963942307692307\n",
      "\n",
      "Epoch 29. Loss: 0.013083665338367703, Train_acc 0.9962384259259259\n",
      "\n",
      "Epoch 29. Loss: 0.012197335452327564, Train_acc 0.9963727678571429\n",
      "\n",
      "Epoch 29. Loss: 0.011146499910270663, Train_acc 0.9964978448275862\n",
      "\n",
      "Epoch 29. Loss: 0.010321287373437427, Train_acc 0.9966145833333333\n",
      "\n",
      "Epoch 29. Loss: 0.00937525745233948, Train_acc 0.9967237903225806\n",
      "\n",
      "Epoch 29. Loss: 0.008852965602288142, Train_acc 0.996826171875\n",
      "\n",
      "Epoch 29. Loss: 0.00921622793213382, Train_acc 0.9969223484848485\n",
      "\n",
      "Epoch 29. Loss: 0.008956643614195478, Train_acc 0.9970128676470589\n",
      "\n",
      "Epoch 29. Loss: 0.009375955412259124, Train_acc 0.996875\n",
      "\n",
      "Epoch 29. Loss: 0.008703785524230083, Train_acc 0.9969618055555556\n",
      "\n",
      "Epoch 29. Loss: 0.008279549507463766, Train_acc 0.997043918918919\n",
      "\n",
      "Epoch 29. Loss: 0.0077981720269082126, Train_acc 0.9971217105263158\n",
      "\n",
      "Epoch 29. Loss: 0.007478169501232338, Train_acc 0.9971955128205128\n",
      "\n",
      "Epoch 29. Loss: 0.0071266722161238485, Train_acc 0.997265625\n",
      "\n",
      "Epoch 29. Loss: 0.0070362882427422785, Train_acc 0.9973323170731707\n",
      "\n",
      "Epoch 29. Loss: 0.008038276876096302, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 29. Loss: 0.007492678419017232, Train_acc 0.9972747093023255\n",
      "\n",
      "Epoch 29. Loss: 0.007027764570017252, Train_acc 0.9973366477272727\n",
      "\n",
      "Epoch 29. Loss: 0.008941587128907079, Train_acc 0.9972222222222222\n",
      "\n",
      "Epoch 29. Loss: 0.008230820126759679, Train_acc 0.9972826086956522\n",
      "\n",
      "Epoch 29. Loss: 0.007932404646957818, Train_acc 0.9973404255319149\n",
      "\n",
      "Epoch 29. Loss: 0.009932054179625126, Train_acc 0.9969075520833334\n",
      "\n",
      "Epoch 29. Loss: 0.009007407939115312, Train_acc 0.9969706632653061\n",
      "\n",
      "Epoch 29. Loss: 0.008196001015186291, Train_acc 0.99703125\n",
      "\n",
      "Epoch 29. Loss: 0.008618614796173556, Train_acc 0.9969362745098039\n",
      "\n",
      "Epoch 29. Loss: 0.00815832508209823, Train_acc 0.9969951923076923\n",
      "\n",
      "Epoch 29. Loss: 0.009993246168823348, Train_acc 0.9967570754716981\n",
      "\n",
      "Epoch 29. Loss: 0.009894002538261986, Train_acc 0.9968171296296297\n",
      "\n",
      "Epoch 29. Loss: 0.009028800226640562, Train_acc 0.996875\n",
      "\n",
      "Epoch 29. Loss: 0.008333641878791325, Train_acc 0.9969308035714286\n",
      "\n",
      "Epoch 29. Loss: 0.00781552134859056, Train_acc 0.996984649122807\n",
      "\n",
      "Epoch 29. Loss: 0.007380841098271227, Train_acc 0.9970366379310345\n",
      "\n",
      "Epoch 29. Loss: 0.007581389420815483, Train_acc 0.9969544491525424\n",
      "\n",
      "Epoch 29. Loss: 0.007378660202626743, Train_acc 0.9970052083333333\n",
      "\n",
      "Epoch 29. Loss: 0.007563997114245019, Train_acc 0.9969262295081968\n",
      "\n",
      "Epoch 29. Loss: 0.007875354171136549, Train_acc 0.9968497983870968\n",
      "\n",
      "Epoch 29. Loss: 0.008521646388923703, Train_acc 0.9968998015873016\n",
      "\n",
      "Epoch 29. Loss: 0.008034720270348112, Train_acc 0.9969482421875\n",
      "\n",
      "Epoch 29. Loss: 0.00948216661677884, Train_acc 0.996875\n",
      "\n",
      "Epoch 29. Loss: 0.008786838330062868, Train_acc 0.9969223484848485\n",
      "\n",
      "Epoch 29. Loss: 0.007942554470867232, Train_acc 0.9969682835820896\n",
      "\n",
      "Epoch 29. Loss: 0.007769050851735754, Train_acc 0.9970128676470589\n",
      "\n",
      "Epoch 29. Loss: 0.007388440984359339, Train_acc 0.9970561594202898\n",
      "\n",
      "Epoch 29. Loss: 0.00669974711645033, Train_acc 0.9970982142857143\n",
      "\n",
      "Epoch 29. Loss: 0.006177635346763307, Train_acc 0.9971390845070423\n",
      "\n",
      "Epoch 29. Loss: 0.006193045248013414, Train_acc 0.9971788194444444\n",
      "\n",
      "Epoch 29. Loss: 0.005836577276368448, Train_acc 0.9972174657534246\n",
      "\n",
      "Epoch 29. Loss: 0.005774431831743874, Train_acc 0.9972550675675675\n",
      "\n",
      "Epoch 29. Loss: 0.005472813193520806, Train_acc 0.9972916666666667\n",
      "\n",
      "Epoch 29. Loss: 0.005067434083893957, Train_acc 0.997327302631579\n",
      "\n",
      "Epoch 29. Loss: 0.010611496423013563, Train_acc 0.997260551948052\n",
      "\n",
      "Epoch 29. Loss: 0.009783923925975761, Train_acc 0.9972956730769231\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29. Loss: 0.00887999755441119, Train_acc 0.9973299050632911\n",
      "\n",
      "Epoch 29. Loss: 0.008188765863021938, Train_acc 0.99736328125\n",
      "\n",
      "Epoch 29. Loss: 0.008634715205676014, Train_acc 0.9972993827160493\n",
      "\n",
      "Epoch 29. Loss: 0.008066801372167457, Train_acc 0.9973323170731707\n",
      "\n",
      "Epoch 29. Loss: 0.009320056827065637, Train_acc 0.9972703313253012\n",
      "\n",
      "Epoch 29. Loss: 0.008439241860107891, Train_acc 0.9973028273809523\n",
      "\n",
      "Epoch 29. Loss: 0.008373846163269562, Train_acc 0.9973345588235294\n",
      "\n",
      "Epoch 29. Loss: 0.01187541966132821, Train_acc 0.997093023255814\n",
      "\n",
      "Epoch 29. Loss: 0.0113043360329494, Train_acc 0.9971264367816092\n",
      "\n",
      "Epoch 29. Loss: 0.010393865780919056, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 29. Loss: 0.013541679048737224, Train_acc 0.9971032303370787\n",
      "\n",
      "Epoch 29. Loss: 0.016942823720753494, Train_acc 0.996875\n",
      "\n",
      "Epoch 29. Loss: 0.01683567985991863, Train_acc 0.996823489010989\n",
      "\n",
      "Epoch 29. Loss: 0.016262586639227517, Train_acc 0.9967730978260869\n",
      "\n",
      "Epoch 29. Loss: 0.014844874103428763, Train_acc 0.9968077956989247\n",
      "\n",
      "Epoch 29. Loss: 0.014013803729023196, Train_acc 0.996841755319149\n",
      "\n",
      "Epoch 29. Loss: 0.01468850752288609, Train_acc 0.9967927631578948\n",
      "\n",
      "Epoch 29. Loss: 0.013774534709300184, Train_acc 0.996826171875\n",
      "\n",
      "Epoch 29. Loss: 0.01299723249037169, Train_acc 0.9968588917525774\n",
      "\n",
      "Epoch 29. Loss: 0.012687910915396535, Train_acc 0.9968909438775511\n",
      "\n",
      "Epoch 29. Loss: 0.011622612316294245, Train_acc 0.9969223484848485\n",
      "\n",
      "Epoch 29. Loss: 0.012905001317456723, Train_acc 0.996796875\n",
      "\n",
      "[Epoch 29 Batch 100] Loss: 0.012194246647875334 Training: accuracy=0.996829\n",
      "Epoch 29. Loss: 0.012194246647875334, Train_acc 0.9968285891089109\n",
      "\n",
      "Epoch 29. Loss: 0.012581610096801065, Train_acc 0.9967830882352942\n",
      "\n",
      "Epoch 29. Loss: 0.014273924079515407, Train_acc 0.9966626213592233\n",
      "\n",
      "Epoch 29. Loss: 0.014564059999863389, Train_acc 0.9966195913461539\n",
      "\n",
      "Epoch 29. Loss: 0.013568969410088732, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 29. Loss: 0.012874844267750152, Train_acc 0.9966833726415094\n",
      "\n",
      "Epoch 29. Loss: 0.012140261839137407, Train_acc 0.9967143691588785\n",
      "\n",
      "Epoch 29. Loss: 0.011096153410052597, Train_acc 0.9967447916666666\n",
      "\n",
      "Epoch 29. Loss: 0.010241673632249539, Train_acc 0.9967746559633027\n",
      "\n",
      "Epoch 29. Loss: 0.010423549165980792, Train_acc 0.9967329545454545\n",
      "\n",
      "Epoch 29. Loss: 0.010434476867905357, Train_acc 0.9967623873873874\n",
      "\n",
      "Epoch 29. Loss: 0.009808062018982558, Train_acc 0.9967912946428571\n",
      "\n",
      "Epoch 29. Loss: 0.010743364470033635, Train_acc 0.9967505530973452\n",
      "\n",
      "Epoch 29. Loss: 0.00991176575027, Train_acc 0.9967790570175439\n",
      "\n",
      "Epoch 29. Loss: 0.015931814994830706, Train_acc 0.9966032608695652\n",
      "\n",
      "Epoch 29. Loss: 0.017976450624840396, Train_acc 0.9964304956896551\n",
      "\n",
      "Epoch 29. Loss: 0.01643835925000334, Train_acc 0.9964610042735043\n",
      "\n",
      "Epoch 29. Loss: 0.015196963222882966, Train_acc 0.9964909957627118\n",
      "\n",
      "Epoch 29. Loss: 0.01441374179830714, Train_acc 0.9965204831932774\n",
      "\n",
      "Epoch 29. Loss: 0.014010462321584498, Train_acc 0.9965494791666667\n",
      "\n",
      "Epoch 29. Loss: 0.013684100314448841, Train_acc 0.9965134297520661\n",
      "\n",
      "Epoch 29. Loss: 0.01383483637896529, Train_acc 0.9964779713114754\n",
      "\n",
      "Epoch 29. Loss: 0.013932135052478473, Train_acc 0.9964430894308943\n",
      "\n",
      "Epoch 29. Loss: 0.013103319511857175, Train_acc 0.9964717741935484\n",
      "\n",
      "Epoch 29. Loss: 0.01239915329385985, Train_acc 0.9965\n",
      "\n",
      "Epoch 29. Loss: 0.01126066229904463, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 29. Loss: 0.011754185770435067, Train_acc 0.9964936023622047\n",
      "\n",
      "Epoch 29. Loss: 0.010838266258969545, Train_acc 0.99652099609375\n",
      "\n",
      "Epoch 29. Loss: 0.011824880357564665, Train_acc 0.9964268410852714\n",
      "\n",
      "Epoch 29. Loss: 0.01146665890081034, Train_acc 0.9964543269230769\n",
      "\n",
      "Epoch 29. Loss: 0.011680889613002295, Train_acc 0.9964217557251909\n",
      "\n",
      "Epoch 29. Loss: 0.012782520751568455, Train_acc 0.996389678030303\n",
      "\n",
      "Epoch 29. Loss: 0.012356412347775203, Train_acc 0.9964168233082706\n",
      "\n",
      "Epoch 29. Loss: 0.01583114327784315, Train_acc 0.9963269589552238\n",
      "\n",
      "Epoch 29. Loss: 0.01479966793511154, Train_acc 0.9963541666666667\n",
      "\n",
      "Epoch 29. Loss: 0.015750855206434503, Train_acc 0.9963235294117647\n",
      "\n",
      "Epoch 29. Loss: 0.014657717756019152, Train_acc 0.9963503649635036\n",
      "\n",
      "Epoch 29. Loss: 0.013782648732068643, Train_acc 0.9963768115942029\n",
      "\n",
      "Epoch 29. Loss: 0.014413790544690943, Train_acc 0.9963466726618705\n",
      "\n",
      "Epoch 29. Loss: 0.014610603987415663, Train_acc 0.9963169642857143\n",
      "\n",
      "Epoch 29. Loss: 0.013947582726991205, Train_acc 0.996343085106383\n",
      "\n",
      "Epoch 29. Loss: 0.013206611597820547, Train_acc 0.996368838028169\n",
      "\n",
      "Epoch 29. Loss: 0.01421494325931468, Train_acc 0.9963395979020979\n",
      "\n",
      "Epoch 29. Loss: 0.014988618523796782, Train_acc 0.9963107638888888\n",
      "\n",
      "Epoch 29. Loss: 0.01480827027343546, Train_acc 0.9963362068965518\n",
      "\n",
      "Epoch 29. Loss: 0.023185290042604518, Train_acc 0.9962007705479452\n",
      "\n",
      "Epoch 29. Loss: 0.020958499152477543, Train_acc 0.9962266156462585\n",
      "\n",
      "Epoch 29. Loss: 0.019230017715557778, Train_acc 0.9962521114864865\n",
      "\n",
      "Epoch 29. Loss: 0.01794765253338012, Train_acc 0.9962772651006712\n",
      "\n",
      "Epoch 29. Loss: 0.018870345736796794, Train_acc 0.9961979166666667\n",
      "\n",
      "Epoch 29. Loss: 0.02023652745955152, Train_acc 0.996171357615894\n",
      "\n",
      "Epoch 29. Loss: 0.018587552886698805, Train_acc 0.9961965460526315\n",
      "\n",
      "Epoch 29. Loss: 0.019503928950274734, Train_acc 0.9961703431372549\n",
      "\n",
      "Epoch 29. Loss: 0.01985867099986501, Train_acc 0.99609375\n",
      "\n",
      "Epoch 29. Loss: 0.023262068870896345, Train_acc 0.9959677419354839\n",
      "\n",
      "Epoch 29. Loss: 0.026698131331712824, Train_acc 0.9958433493589743\n",
      "\n",
      "Epoch 29. Loss: 0.030151851298431297, Train_acc 0.9957205414012739\n",
      "\n",
      "Epoch 29. Loss: 0.02755119738088823, Train_acc 0.9957476265822784\n",
      "\n",
      "Epoch 29. Loss: 0.026166309356899054, Train_acc 0.9957252358490566\n",
      "\n",
      "Epoch 29. Loss: 0.02431280097235232, Train_acc 0.995751953125\n",
      "\n",
      "Epoch 29. Loss: 0.024602091066858078, Train_acc 0.9956812888198758\n",
      "\n",
      "Epoch 29. Loss: 0.023028103283334586, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 29. Loss: 0.02124227826524271, Train_acc 0.9956863496932515\n",
      "\n",
      "Epoch 29. Loss: 0.020885211740986943, Train_acc 0.9956650152439024\n",
      "\n",
      "Epoch 29. Loss: 0.02159146332596818, Train_acc 0.9955965909090909\n",
      "\n",
      "Epoch 29. Loss: 0.020481261977002736, Train_acc 0.9955760542168675\n",
      "\n",
      "Epoch 29. Loss: 0.02052885222594057, Train_acc 0.9955089820359282\n",
      "\n",
      "Epoch 29. Loss: 0.021505345506907532, Train_acc 0.9954892113095238\n",
      "\n",
      "Epoch 29. Loss: 0.019458689209356336, Train_acc 0.9955159023668639\n",
      "\n",
      "Epoch 29. Loss: 0.019451217539490247, Train_acc 0.9954503676470589\n",
      "\n",
      "Epoch 29. Loss: 0.019354924950642272, Train_acc 0.9954312865497076\n",
      "\n",
      "Epoch 29. Loss: 0.02215459381965657, Train_acc 0.9952761627906976\n",
      "\n",
      "Epoch 29. Loss: 0.022172201033781706, Train_acc 0.9952131502890174\n",
      "\n",
      "Epoch 29. Loss: 0.02597402783306009, Train_acc 0.9951059626436781\n",
      "\n",
      "Epoch 29. Loss: 0.028483126331015525, Train_acc 0.995\n",
      "\n",
      "Epoch 29. Loss: 0.026611438223997443, Train_acc 0.9949840198863636\n",
      "\n",
      "Epoch 29. Loss: 0.02463810806731554, Train_acc 0.9950123587570622\n",
      "\n",
      "Epoch 29. Loss: 0.023345840802879683, Train_acc 0.9950403792134831\n",
      "\n",
      "Epoch 29. Loss: 0.021305037609159843, Train_acc 0.9950680865921788\n",
      "\n",
      "Epoch 29. Loss: 0.020772706669348384, Train_acc 0.9950520833333333\n",
      "\n",
      "Epoch 29. Loss: 0.02109643849889449, Train_acc 0.9950362569060773\n",
      "\n",
      "Epoch 29. Loss: 0.02092607535266887, Train_acc 0.9950206043956044\n",
      "\n",
      "Epoch 29. Loss: 0.020187928608155346, Train_acc 0.9950478142076503\n",
      "\n",
      "Epoch 29. Loss: 0.022177469132330502, Train_acc 0.9949048913043478\n",
      "\n",
      "Epoch 29. Loss: 0.020325352407122986, Train_acc 0.9949324324324325\n",
      "\n",
      "Epoch 29. Loss: 0.01930263887193084, Train_acc 0.9949596774193549\n",
      "\n",
      "Epoch 29. Loss: 0.018302733454223993, Train_acc 0.9949866310160428\n",
      "\n",
      "Epoch 29. Loss: 0.016649952356696, Train_acc 0.9950132978723404\n",
      "\n",
      "Epoch 29. Loss: 0.015219178625096268, Train_acc 0.9950396825396826\n",
      "\n",
      "Epoch 29. Loss: 0.014759930740132378, Train_acc 0.9950657894736842\n",
      "\n",
      "Epoch 29. Loss: 0.014896106030345958, Train_acc 0.9950507198952879\n",
      "\n",
      "Epoch 29. Loss: 0.016288096135080758, Train_acc 0.9949951171875\n",
      "\n",
      "Epoch 29. Loss: 0.014816069473244311, Train_acc 0.9950210492227979\n",
      "\n",
      "Epoch 29. Loss: 0.0232010928118982, Train_acc 0.9948453608247423\n",
      "\n",
      "Epoch 29. Loss: 0.021301813044749925, Train_acc 0.9948717948717949\n",
      "\n",
      "Epoch 29. Loss: 0.019309580555520116, Train_acc 0.99488\n",
      "\n",
      "Epoch 30. Loss: 0.024233182726170116, Train_acc 0.9921875\n",
      "\n",
      "Epoch 30. Loss: 0.024128297380684758, Train_acc 0.98828125\n",
      "\n",
      "Epoch 30. Loss: 0.025668504681061754, Train_acc 0.9895833333333334\n",
      "\n",
      "Epoch 30. Loss: 0.024057868152890547, Train_acc 0.990234375\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30. Loss: 0.02317523836049492, Train_acc 0.990625\n",
      "\n",
      "Epoch 30. Loss: 0.021647601051208866, Train_acc 0.9921875\n",
      "\n",
      "Epoch 30. Loss: 0.024992535239229344, Train_acc 0.9910714285714286\n",
      "\n",
      "Epoch 30. Loss: 0.02306122056836165, Train_acc 0.9921875\n",
      "\n",
      "Epoch 30. Loss: 0.0215294819633151, Train_acc 0.9930555555555556\n",
      "\n",
      "Epoch 30. Loss: 0.01957018655702337, Train_acc 0.99375\n",
      "\n",
      "Epoch 30. Loss: 0.02163893601743756, Train_acc 0.9928977272727273\n",
      "\n",
      "Epoch 30. Loss: 0.02091723220972757, Train_acc 0.9928385416666666\n",
      "\n",
      "Epoch 30. Loss: 0.022860582507507863, Train_acc 0.9921875\n",
      "\n",
      "Epoch 30. Loss: 0.021686606112292586, Train_acc 0.9921875\n",
      "\n",
      "Epoch 30. Loss: 0.02232958451196955, Train_acc 0.9921875\n",
      "\n",
      "Epoch 30. Loss: 0.026062803643513377, Train_acc 0.99169921875\n",
      "\n",
      "Epoch 30. Loss: 0.0249425796703118, Train_acc 0.9917279411764706\n",
      "\n",
      "Epoch 30. Loss: 0.025235955874826126, Train_acc 0.9917534722222222\n",
      "\n",
      "Epoch 30. Loss: 0.024377274664377224, Train_acc 0.9917763157894737\n",
      "\n",
      "Epoch 30. Loss: 0.02404978501242553, Train_acc 0.991796875\n",
      "\n",
      "Epoch 30. Loss: 0.02222153211333294, Train_acc 0.9921875\n",
      "\n",
      "Epoch 30. Loss: 0.023022120800893955, Train_acc 0.9921875\n",
      "\n",
      "Epoch 30. Loss: 0.026029181278301585, Train_acc 0.9915081521739131\n",
      "\n",
      "Epoch 30. Loss: 0.024438279703903176, Train_acc 0.9915364583333334\n",
      "\n",
      "Epoch 30. Loss: 0.022332122849507315, Train_acc 0.991875\n",
      "\n",
      "Epoch 30. Loss: 0.020945684881880745, Train_acc 0.9921875\n",
      "\n",
      "Epoch 30. Loss: 0.021179033909924205, Train_acc 0.9918981481481481\n",
      "\n",
      "Epoch 30. Loss: 0.023583914200682083, Train_acc 0.9916294642857143\n",
      "\n",
      "Epoch 30. Loss: 0.021438273830162263, Train_acc 0.9919181034482759\n",
      "\n",
      "Epoch 30. Loss: 0.026480120905888176, Train_acc 0.9916666666666667\n",
      "\n",
      "Epoch 30. Loss: 0.02729413024066576, Train_acc 0.9916834677419355\n",
      "\n",
      "Epoch 30. Loss: 0.02616779065709134, Train_acc 0.99169921875\n",
      "\n",
      "Epoch 30. Loss: 0.025199857301242534, Train_acc 0.9914772727272727\n",
      "\n",
      "Epoch 30. Loss: 0.025291763123924182, Train_acc 0.9914981617647058\n",
      "\n",
      "Epoch 30. Loss: 0.028559711093057376, Train_acc 0.9910714285714286\n",
      "\n",
      "Epoch 30. Loss: 0.02768823155553566, Train_acc 0.9911024305555556\n",
      "\n",
      "Epoch 30. Loss: 0.026319577850771783, Train_acc 0.9911317567567568\n",
      "\n",
      "Epoch 30. Loss: 0.02462583731446222, Train_acc 0.9913651315789473\n",
      "\n",
      "Epoch 30. Loss: 0.027435016192497812, Train_acc 0.9911858974358975\n",
      "\n",
      "Epoch 30. Loss: 0.025435485500099064, Train_acc 0.99140625\n",
      "\n",
      "Epoch 30. Loss: 0.025364492959977808, Train_acc 0.9914253048780488\n",
      "\n",
      "Epoch 30. Loss: 0.02468424499231722, Train_acc 0.9914434523809523\n",
      "\n",
      "Epoch 30. Loss: 0.026172737421376817, Train_acc 0.9914607558139535\n",
      "\n",
      "Epoch 30. Loss: 0.0300805957392901, Train_acc 0.9909446022727273\n",
      "\n",
      "Epoch 30. Loss: 0.02832611199701278, Train_acc 0.9909722222222223\n",
      "\n",
      "Epoch 30. Loss: 0.027858743487159447, Train_acc 0.9909986413043478\n",
      "\n",
      "Epoch 30. Loss: 0.027340315879905253, Train_acc 0.9910239361702128\n",
      "\n",
      "Epoch 30. Loss: 0.02586924822764757, Train_acc 0.9912109375\n",
      "\n",
      "Epoch 30. Loss: 0.02547365315232124, Train_acc 0.9912308673469388\n",
      "\n",
      "Epoch 30. Loss: 0.025622354373098427, Train_acc 0.99109375\n",
      "\n",
      "Epoch 30. Loss: 0.025552845716262772, Train_acc 0.9911151960784313\n",
      "\n",
      "Epoch 30. Loss: 0.026411277103231774, Train_acc 0.9909855769230769\n",
      "\n",
      "Epoch 30. Loss: 0.024122483414499248, Train_acc 0.9911556603773585\n",
      "\n",
      "Epoch 30. Loss: 0.02303525508083846, Train_acc 0.9913194444444444\n",
      "\n",
      "Epoch 30. Loss: 0.02330099206988167, Train_acc 0.9913352272727273\n",
      "\n",
      "Epoch 30. Loss: 0.02365559316567318, Train_acc 0.9913504464285714\n",
      "\n",
      "Epoch 30. Loss: 0.023649722317383316, Train_acc 0.9913651315789473\n",
      "\n",
      "Epoch 30. Loss: 0.027519952487521437, Train_acc 0.9912446120689655\n",
      "\n",
      "Epoch 30. Loss: 0.02792357428214526, Train_acc 0.9911281779661016\n",
      "\n",
      "Epoch 30. Loss: 0.02856492085762241, Train_acc 0.9911458333333333\n",
      "\n",
      "Epoch 30. Loss: 0.029570766539938023, Train_acc 0.9910348360655737\n",
      "\n",
      "Epoch 30. Loss: 0.037076751814693304, Train_acc 0.9905493951612904\n",
      "\n",
      "Epoch 30. Loss: 0.03480944792679855, Train_acc 0.9906994047619048\n",
      "\n",
      "Epoch 30. Loss: 0.0360619255326859, Train_acc 0.9906005859375\n",
      "\n",
      "Epoch 30. Loss: 0.03378567186051653, Train_acc 0.990625\n",
      "\n",
      "Epoch 30. Loss: 0.0317311110307638, Train_acc 0.9906486742424242\n",
      "\n",
      "Epoch 30. Loss: 0.030265942525255454, Train_acc 0.9906716417910447\n",
      "\n",
      "Epoch 30. Loss: 0.030838027129817997, Train_acc 0.9905790441176471\n",
      "\n",
      "Epoch 30. Loss: 0.03664338546715587, Train_acc 0.9901494565217391\n",
      "\n",
      "Epoch 30. Loss: 0.03435212550138601, Train_acc 0.9902901785714285\n",
      "\n",
      "Epoch 30. Loss: 0.03264672263033839, Train_acc 0.9903169014084507\n",
      "\n",
      "Epoch 30. Loss: 0.03014341961056875, Train_acc 0.9904513888888888\n",
      "\n",
      "Epoch 30. Loss: 0.027402257494464996, Train_acc 0.990582191780822\n",
      "\n",
      "Epoch 30. Loss: 0.026466111605467333, Train_acc 0.9906038851351351\n",
      "\n",
      "Epoch 30. Loss: 0.025014767474027217, Train_acc 0.9907291666666667\n",
      "\n",
      "Epoch 30. Loss: 0.025228138872467047, Train_acc 0.9906455592105263\n",
      "\n",
      "Epoch 30. Loss: 0.02488269849134913, Train_acc 0.9906655844155844\n",
      "\n",
      "Epoch 30. Loss: 0.025582292170942704, Train_acc 0.9906850961538461\n",
      "\n",
      "Epoch 30. Loss: 0.0253336827754565, Train_acc 0.9907041139240507\n",
      "\n",
      "Epoch 30. Loss: 0.023318044819645993, Train_acc 0.9908203125\n",
      "\n",
      "Epoch 30. Loss: 0.026046911607575038, Train_acc 0.9907407407407407\n",
      "\n",
      "Epoch 30. Loss: 0.024723468666128772, Train_acc 0.9908536585365854\n",
      "\n",
      "Epoch 30. Loss: 0.02576813894050043, Train_acc 0.9907756024096386\n",
      "\n",
      "Epoch 30. Loss: 0.02871592385354687, Train_acc 0.9906994047619048\n",
      "\n",
      "Epoch 30. Loss: 0.03151821942135438, Train_acc 0.9905330882352941\n",
      "\n",
      "Epoch 30. Loss: 0.033924823784870606, Train_acc 0.9903706395348837\n",
      "\n",
      "Epoch 30. Loss: 0.03180266921658161, Train_acc 0.9903915229885057\n",
      "\n",
      "Epoch 30. Loss: 0.029433598506648926, Train_acc 0.9905007102272727\n",
      "\n",
      "Epoch 30. Loss: 0.02678308924443238, Train_acc 0.9906074438202247\n",
      "\n",
      "Epoch 30. Loss: 0.024931125704110085, Train_acc 0.9907118055555556\n",
      "\n",
      "Epoch 30. Loss: 0.025240938504332677, Train_acc 0.990728021978022\n",
      "\n",
      "Epoch 30. Loss: 0.023084203516321816, Train_acc 0.990828804347826\n",
      "\n",
      "Epoch 30. Loss: 0.029898143662402725, Train_acc 0.9904233870967742\n",
      "\n",
      "Epoch 30. Loss: 0.02854984642868313, Train_acc 0.9904421542553191\n",
      "\n",
      "Epoch 30. Loss: 0.03555352069561249, Train_acc 0.9903782894736842\n",
      "\n",
      "Epoch 30. Loss: 0.03232598229795306, Train_acc 0.990478515625\n",
      "\n",
      "Epoch 30. Loss: 0.03212370432510623, Train_acc 0.9904155927835051\n",
      "\n",
      "Epoch 30. Loss: 0.029353569949146945, Train_acc 0.9905133928571429\n",
      "\n",
      "Epoch 30. Loss: 0.0299790570179911, Train_acc 0.9903724747474747\n",
      "\n",
      "Epoch 30. Loss: 0.0342403495943807, Train_acc 0.990234375\n",
      "\n",
      "[Epoch 30 Batch 100] Loss: 0.03183132380720339 Training: accuracy=0.990331\n",
      "Epoch 30. Loss: 0.03183132380720339, Train_acc 0.9903310643564357\n",
      "\n",
      "Epoch 30. Loss: 0.033746761564699065, Train_acc 0.9903492647058824\n",
      "\n",
      "Epoch 30. Loss: 0.03162013533051662, Train_acc 0.9903671116504854\n",
      "\n",
      "Epoch 30. Loss: 0.029245299851916904, Train_acc 0.9904597355769231\n",
      "\n",
      "Epoch 30. Loss: 0.027327641142328985, Train_acc 0.9905505952380952\n",
      "\n",
      "Epoch 30. Loss: 0.026910495684671767, Train_acc 0.9904923349056604\n",
      "\n",
      "Epoch 30. Loss: 0.024476987448598473, Train_acc 0.990581191588785\n",
      "\n",
      "Epoch 30. Loss: 0.022816781824617563, Train_acc 0.9906684027777778\n",
      "\n",
      "Epoch 30. Loss: 0.025372508206178826, Train_acc 0.9905389908256881\n",
      "\n",
      "Epoch 30. Loss: 0.025809953470417934, Train_acc 0.9904829545454545\n",
      "\n",
      "Epoch 30. Loss: 0.024011112251331578, Train_acc 0.9905686936936937\n",
      "\n",
      "Epoch 30. Loss: 0.022419394849345242, Train_acc 0.9906529017857143\n",
      "\n",
      "Epoch 30. Loss: 0.027165407805387815, Train_acc 0.9905973451327433\n",
      "\n",
      "Epoch 30. Loss: 0.03310569587535677, Train_acc 0.9904057017543859\n",
      "\n",
      "Epoch 30. Loss: 0.031398519358220855, Train_acc 0.9904891304347826\n",
      "\n",
      "Epoch 30. Loss: 0.029107672164156877, Train_acc 0.9905711206896551\n",
      "\n",
      "Epoch 30. Loss: 0.031184008439762753, Train_acc 0.9905849358974359\n",
      "\n",
      "Epoch 30. Loss: 0.029299303322628166, Train_acc 0.9906647245762712\n",
      "\n",
      "Epoch 30. Loss: 0.028600825231905307, Train_acc 0.9906118697478992\n",
      "\n",
      "Epoch 30. Loss: 0.03010683844533759, Train_acc 0.9905598958333334\n",
      "\n",
      "Epoch 30. Loss: 0.03192034779531239, Train_acc 0.990573347107438\n",
      "\n",
      "Epoch 30. Loss: 0.03015792650916408, Train_acc 0.9905865778688525\n",
      "\n",
      "Epoch 30. Loss: 0.027890674133046543, Train_acc 0.9906631097560976\n",
      "\n",
      "Epoch 30. Loss: 0.026272407346019815, Train_acc 0.9907384072580645\n",
      "\n",
      "Epoch 30. Loss: 0.024971798552319114, Train_acc 0.99075\n",
      "\n",
      "Epoch 30. Loss: 0.02434028375289861, Train_acc 0.9907614087301587\n",
      "\n",
      "Epoch 30. Loss: 0.023572145221907113, Train_acc 0.9907726377952756\n",
      "\n",
      "Epoch 30. Loss: 0.025111351148734883, Train_acc 0.99066162109375\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30. Loss: 0.026775145146057364, Train_acc 0.9906128875968992\n",
      "\n",
      "Epoch 30. Loss: 0.025104596343164465, Train_acc 0.9906850961538461\n",
      "\n",
      "Epoch 30. Loss: 0.023209637926392097, Train_acc 0.9907562022900763\n",
      "\n",
      "Epoch 30. Loss: 0.021634678836276237, Train_acc 0.9908262310606061\n",
      "\n",
      "Epoch 30. Loss: 0.022520344298133346, Train_acc 0.9907777255639098\n",
      "\n",
      "Epoch 30. Loss: 0.021877775161906265, Train_acc 0.9907882462686567\n",
      "\n",
      "Epoch 30. Loss: 0.020546097668508453, Train_acc 0.9908564814814815\n",
      "\n",
      "Epoch 30. Loss: 0.021338907208293463, Train_acc 0.9908088235294118\n",
      "\n",
      "Epoch 30. Loss: 0.02272123865149896, Train_acc 0.9908188868613139\n",
      "\n",
      "Epoch 30. Loss: 0.0209378286822511, Train_acc 0.9908854166666666\n",
      "\n",
      "Epoch 30. Loss: 0.022979236509550208, Train_acc 0.9907823741007195\n",
      "\n",
      "Epoch 30. Loss: 0.021162830331830914, Train_acc 0.9908482142857142\n",
      "\n",
      "Epoch 30. Loss: 0.02178022864959425, Train_acc 0.990802304964539\n",
      "\n",
      "Epoch 30. Loss: 0.020065398182363386, Train_acc 0.9908670774647887\n",
      "\n",
      "Epoch 30. Loss: 0.021220485790870557, Train_acc 0.9908216783216783\n",
      "\n",
      "Epoch 30. Loss: 0.019431698794783923, Train_acc 0.9908854166666666\n",
      "\n",
      "Epoch 30. Loss: 0.018074253049303688, Train_acc 0.990948275862069\n",
      "\n",
      "Epoch 30. Loss: 0.016614084172004103, Train_acc 0.9910102739726028\n",
      "\n",
      "Epoch 30. Loss: 0.016632641981023825, Train_acc 0.9910182823129252\n",
      "\n",
      "Epoch 30. Loss: 0.01683010049609388, Train_acc 0.9910261824324325\n",
      "\n",
      "Epoch 30. Loss: 0.022524822246563835, Train_acc 0.990876677852349\n",
      "\n",
      "Epoch 30. Loss: 0.022935645796238545, Train_acc 0.9908333333333333\n",
      "\n",
      "Epoch 30. Loss: 0.0212418650152944, Train_acc 0.9908940397350994\n",
      "\n",
      "Epoch 30. Loss: 0.02429462689721547, Train_acc 0.9908511513157895\n",
      "\n",
      "Epoch 30. Loss: 0.025304570513045452, Train_acc 0.990859885620915\n",
      "\n",
      "Epoch 30. Loss: 0.02617904891110271, Train_acc 0.9908685064935064\n",
      "\n",
      "Epoch 30. Loss: 0.02370761286518851, Train_acc 0.9909274193548387\n",
      "\n",
      "Epoch 30. Loss: 0.028126523208336945, Train_acc 0.9908854166666666\n",
      "\n",
      "Epoch 30. Loss: 0.028552559669360742, Train_acc 0.990843949044586\n",
      "\n",
      "Epoch 30. Loss: 0.025930239399264955, Train_acc 0.9909018987341772\n",
      "\n",
      "Epoch 30. Loss: 0.02364109907708231, Train_acc 0.9909591194968553\n",
      "\n",
      "Epoch 30. Loss: 0.023623129315629574, Train_acc 0.99091796875\n",
      "\n",
      "Epoch 30. Loss: 0.021556171322201167, Train_acc 0.9909743788819876\n",
      "\n",
      "Epoch 30. Loss: 0.022259287016988823, Train_acc 0.9909818672839507\n",
      "\n",
      "Epoch 30. Loss: 0.023208092058361496, Train_acc 0.990989263803681\n",
      "\n",
      "Epoch 30. Loss: 0.023817883234912983, Train_acc 0.9909489329268293\n",
      "\n",
      "Epoch 30. Loss: 0.021940752165044694, Train_acc 0.9910037878787878\n",
      "\n",
      "Epoch 30. Loss: 0.020231986208506244, Train_acc 0.9910579819277109\n",
      "\n",
      "Epoch 30. Loss: 0.024413483587277966, Train_acc 0.9909711826347305\n",
      "\n",
      "Epoch 30. Loss: 0.022741014750188325, Train_acc 0.9910249255952381\n",
      "\n",
      "Epoch 30. Loss: 0.0211197910753361, Train_acc 0.9910780325443787\n",
      "\n",
      "Epoch 30. Loss: 0.021793662284088577, Train_acc 0.9910845588235294\n",
      "\n",
      "Epoch 30. Loss: 0.020488436541800898, Train_acc 0.9910910087719298\n",
      "\n",
      "Epoch 30. Loss: 0.019425363001387003, Train_acc 0.9911428052325582\n",
      "\n",
      "Epoch 30. Loss: 0.019042112613911047, Train_acc 0.9911488439306358\n",
      "\n",
      "Epoch 30. Loss: 0.01860467070507522, Train_acc 0.9911548132183908\n",
      "\n",
      "Epoch 30. Loss: 0.018562865398831806, Train_acc 0.9911607142857143\n",
      "\n",
      "Epoch 30. Loss: 0.01897236765996305, Train_acc 0.9911665482954546\n",
      "\n",
      "Epoch 30. Loss: 0.020245066835662913, Train_acc 0.9911281779661016\n",
      "\n",
      "Epoch 30. Loss: 0.020342050578458185, Train_acc 0.9911341292134831\n",
      "\n",
      "Epoch 30. Loss: 0.0187886634774623, Train_acc 0.9911836592178771\n",
      "\n",
      "Epoch 30. Loss: 0.021619918582524447, Train_acc 0.9911892361111111\n",
      "\n",
      "Epoch 30. Loss: 0.020206644974814884, Train_acc 0.9912379143646409\n",
      "\n",
      "Epoch 30. Loss: 0.018333077441398383, Train_acc 0.9912860576923077\n",
      "\n",
      "Epoch 30. Loss: 0.016798306545535397, Train_acc 0.991333674863388\n",
      "\n",
      "Epoch 30. Loss: 0.016669279224502745, Train_acc 0.9913383152173914\n",
      "\n",
      "Epoch 30. Loss: 0.01624189545526597, Train_acc 0.9913851351351352\n",
      "\n",
      "Epoch 30. Loss: 0.01634054743332708, Train_acc 0.9913894489247311\n",
      "\n",
      "Epoch 30. Loss: 0.015562961609658994, Train_acc 0.9914354946524064\n",
      "\n",
      "Epoch 30. Loss: 0.01726011867359048, Train_acc 0.9913979388297872\n",
      "\n",
      "Epoch 30. Loss: 0.01906848864288419, Train_acc 0.9914021164021164\n",
      "\n",
      "Epoch 30. Loss: 0.01821113116918167, Train_acc 0.9914473684210526\n",
      "\n",
      "Epoch 30. Loss: 0.01724348345662499, Train_acc 0.9914921465968587\n",
      "\n",
      "Epoch 30. Loss: 0.018550391347098454, Train_acc 0.991455078125\n",
      "\n",
      "Epoch 30. Loss: 0.020389271841247177, Train_acc 0.9914588730569949\n",
      "\n",
      "Epoch 30. Loss: 0.018685138801268604, Train_acc 0.9915028994845361\n",
      "\n",
      "Epoch 30. Loss: 0.016985593518568754, Train_acc 0.9915464743589744\n",
      "\n",
      "Epoch 30. Loss: 0.01957721891786487, Train_acc 0.99152\n",
      "\n",
      "Epoch 31. Loss: 0.017864173208124917, Train_acc 1.0\n",
      "\n",
      "Epoch 31. Loss: 0.016678958881897465, Train_acc 1.0\n",
      "\n",
      "Epoch 31. Loss: 0.015146846670231435, Train_acc 1.0\n",
      "\n",
      "Epoch 31. Loss: 0.015257207392145287, Train_acc 0.998046875\n",
      "\n",
      "Epoch 31. Loss: 0.013816884125070207, Train_acc 0.9984375\n",
      "\n",
      "Epoch 31. Loss: 0.01394593969565311, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 31. Loss: 0.014732528714075795, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 31. Loss: 0.01437391650697748, Train_acc 0.99609375\n",
      "\n",
      "Epoch 31. Loss: 0.02083496506829107, Train_acc 0.9939236111111112\n",
      "\n",
      "Epoch 31. Loss: 0.02141420473890642, Train_acc 0.99375\n",
      "\n",
      "Epoch 31. Loss: 0.02037810592937893, Train_acc 0.9943181818181818\n",
      "\n",
      "Epoch 31. Loss: 0.02146005217661047, Train_acc 0.994140625\n",
      "\n",
      "Epoch 31. Loss: 0.019390363855542624, Train_acc 0.9945913461538461\n",
      "\n",
      "Epoch 31. Loss: 0.019947477047188775, Train_acc 0.9944196428571429\n",
      "\n",
      "Epoch 31. Loss: 0.01921420102004143, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 31. Loss: 0.01743531340031489, Train_acc 0.9951171875\n",
      "\n",
      "Epoch 31. Loss: 0.017669284242409447, Train_acc 0.9944852941176471\n",
      "\n",
      "Epoch 31. Loss: 0.020255464075223786, Train_acc 0.9943576388888888\n",
      "\n",
      "Epoch 31. Loss: 0.019275399528339076, Train_acc 0.9942434210526315\n",
      "\n",
      "Epoch 31. Loss: 0.018664140331650883, Train_acc 0.994140625\n",
      "\n",
      "Epoch 31. Loss: 0.017230877722416917, Train_acc 0.9944196428571429\n",
      "\n",
      "Epoch 31. Loss: 0.016767766389353216, Train_acc 0.9943181818181818\n",
      "\n",
      "Epoch 31. Loss: 0.01817718153873367, Train_acc 0.9942255434782609\n",
      "\n",
      "Epoch 31. Loss: 0.017688647615277317, Train_acc 0.994140625\n",
      "\n",
      "Epoch 31. Loss: 0.01693998219358642, Train_acc 0.994375\n",
      "\n",
      "Epoch 31. Loss: 0.016498467643896217, Train_acc 0.9942908653846154\n",
      "\n",
      "Epoch 31. Loss: 0.015949498738204965, Train_acc 0.9945023148148148\n",
      "\n",
      "Epoch 31. Loss: 0.020170361437221344, Train_acc 0.9944196428571429\n",
      "\n",
      "Epoch 31. Loss: 0.02190797870262263, Train_acc 0.9943426724137931\n",
      "\n",
      "Epoch 31. Loss: 0.02025412643428562, Train_acc 0.99453125\n",
      "\n",
      "Epoch 31. Loss: 0.018926776475244027, Train_acc 0.9947076612903226\n",
      "\n",
      "Epoch 31. Loss: 0.017934048683822094, Train_acc 0.994873046875\n",
      "\n",
      "Epoch 31. Loss: 0.018988243053597156, Train_acc 0.9945549242424242\n",
      "\n",
      "Epoch 31. Loss: 0.021341394686915233, Train_acc 0.9944852941176471\n",
      "\n",
      "Epoch 31. Loss: 0.02174768881131806, Train_acc 0.9944196428571429\n",
      "\n",
      "Epoch 31. Loss: 0.020168262577470522, Train_acc 0.9945746527777778\n",
      "\n",
      "Epoch 31. Loss: 0.01977720292486225, Train_acc 0.9945101351351351\n",
      "\n",
      "Epoch 31. Loss: 0.018734066698647807, Train_acc 0.9946546052631579\n",
      "\n",
      "Epoch 31. Loss: 0.021954858911362833, Train_acc 0.9945913461538461\n",
      "\n",
      "Epoch 31. Loss: 0.020906879220003675, Train_acc 0.99453125\n",
      "\n",
      "Epoch 31. Loss: 0.02034129795157444, Train_acc 0.9944740853658537\n",
      "\n",
      "Epoch 31. Loss: 0.02039230291596232, Train_acc 0.9944196428571429\n",
      "\n",
      "Epoch 31. Loss: 0.019761852990548414, Train_acc 0.9941860465116279\n",
      "\n",
      "Epoch 31. Loss: 0.023312811244392932, Train_acc 0.9937855113636364\n",
      "\n",
      "Epoch 31. Loss: 0.021602988682044633, Train_acc 0.9939236111111112\n",
      "\n",
      "Epoch 31. Loss: 0.01985538343356826, Train_acc 0.9940557065217391\n",
      "\n",
      "Epoch 31. Loss: 0.01851549158968131, Train_acc 0.9941821808510638\n",
      "\n",
      "Epoch 31. Loss: 0.017010669680857064, Train_acc 0.9943033854166666\n",
      "\n",
      "Epoch 31. Loss: 0.015608524150705398, Train_acc 0.9944196428571429\n",
      "\n",
      "Epoch 31. Loss: 0.01611293020879274, Train_acc 0.994375\n",
      "\n",
      "Epoch 31. Loss: 0.015217335303441097, Train_acc 0.9944852941176471\n",
      "\n",
      "Epoch 31. Loss: 0.017986426901652287, Train_acc 0.9942908653846154\n",
      "\n",
      "Epoch 31. Loss: 0.016931079836339243, Train_acc 0.9943985849056604\n",
      "\n",
      "Epoch 31. Loss: 0.01875625447480424, Train_acc 0.9942129629629629\n",
      "\n",
      "Epoch 31. Loss: 0.019793266059892272, Train_acc 0.9941761363636363\n",
      "\n",
      "Epoch 31. Loss: 0.018239943628999795, Train_acc 0.9942801339285714\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31. Loss: 0.01747806091576207, Train_acc 0.9943804824561403\n",
      "\n",
      "Epoch 31. Loss: 0.01784973750534107, Train_acc 0.994207974137931\n",
      "\n",
      "Epoch 31. Loss: 0.016948519494585243, Train_acc 0.9943061440677966\n",
      "\n",
      "Epoch 31. Loss: 0.015777496213646575, Train_acc 0.9944010416666667\n",
      "\n",
      "Epoch 31. Loss: 0.015271799272237877, Train_acc 0.9944928278688525\n",
      "\n",
      "Epoch 31. Loss: 0.020558646922652718, Train_acc 0.9940776209677419\n",
      "\n",
      "Epoch 31. Loss: 0.019254237637977123, Train_acc 0.994171626984127\n",
      "\n",
      "Epoch 31. Loss: 0.018188292362743903, Train_acc 0.9942626953125\n",
      "\n",
      "Epoch 31. Loss: 0.023935447256375215, Train_acc 0.9939903846153846\n",
      "\n",
      "Epoch 31. Loss: 0.0235571623926838, Train_acc 0.9939630681818182\n",
      "\n",
      "Epoch 31. Loss: 0.021398369142977575, Train_acc 0.9940531716417911\n",
      "\n",
      "Epoch 31. Loss: 0.019922821151824158, Train_acc 0.994140625\n",
      "\n",
      "Epoch 31. Loss: 0.018470181283081796, Train_acc 0.9942255434782609\n",
      "\n",
      "Epoch 31. Loss: 0.01857688904409876, Train_acc 0.9941964285714285\n",
      "\n",
      "Epoch 31. Loss: 0.017727580996053847, Train_acc 0.9942781690140845\n",
      "\n",
      "Epoch 31. Loss: 0.01874231494816908, Train_acc 0.9942491319444444\n",
      "\n",
      "Epoch 31. Loss: 0.01753822145479413, Train_acc 0.9943279109589042\n",
      "\n",
      "Epoch 31. Loss: 0.015995895820788968, Train_acc 0.9944045608108109\n",
      "\n",
      "Epoch 31. Loss: 0.014510428900472012, Train_acc 0.9944791666666667\n",
      "\n",
      "Epoch 31. Loss: 0.015377329993204791, Train_acc 0.9943462171052632\n",
      "\n",
      "Epoch 31. Loss: 0.015136915277352798, Train_acc 0.9943181818181818\n",
      "\n",
      "Epoch 31. Loss: 0.01671463597349304, Train_acc 0.9941907051282052\n",
      "\n",
      "Epoch 31. Loss: 0.017947361009108827, Train_acc 0.9941653481012658\n",
      "\n",
      "Epoch 31. Loss: 0.017717669095207278, Train_acc 0.994140625\n",
      "\n",
      "Epoch 31. Loss: 0.01733512477780195, Train_acc 0.994116512345679\n",
      "\n",
      "Epoch 31. Loss: 0.016420682005925287, Train_acc 0.9940929878048781\n",
      "\n",
      "Epoch 31. Loss: 0.016124970320174077, Train_acc 0.9940700301204819\n",
      "\n",
      "Epoch 31. Loss: 0.021831481847145243, Train_acc 0.9938616071428571\n",
      "\n",
      "Epoch 31. Loss: 0.0197935815204484, Train_acc 0.9939338235294117\n",
      "\n",
      "Epoch 31. Loss: 0.01879119602286542, Train_acc 0.9939135174418605\n",
      "\n",
      "Epoch 31. Loss: 0.017378899299967807, Train_acc 0.9939834770114943\n",
      "\n",
      "Epoch 31. Loss: 0.016432797471167316, Train_acc 0.9940518465909091\n",
      "\n",
      "Epoch 31. Loss: 0.017300124966634814, Train_acc 0.9939431179775281\n",
      "\n",
      "Epoch 31. Loss: 0.01679193504470602, Train_acc 0.9940104166666667\n",
      "\n",
      "Epoch 31. Loss: 0.015370311673779924, Train_acc 0.9940762362637363\n",
      "\n",
      "Epoch 31. Loss: 0.014986881281107341, Train_acc 0.994140625\n",
      "\n",
      "Epoch 31. Loss: 0.013744399807008811, Train_acc 0.9942036290322581\n",
      "\n",
      "Epoch 31. Loss: 0.013380470803665556, Train_acc 0.9941821808510638\n",
      "\n",
      "Epoch 31. Loss: 0.012745039923150037, Train_acc 0.9941611842105263\n",
      "\n",
      "Epoch 31. Loss: 0.011859670116223717, Train_acc 0.9942220052083334\n",
      "\n",
      "Epoch 31. Loss: 0.013799220174894773, Train_acc 0.9941204896907216\n",
      "\n",
      "Epoch 31. Loss: 0.013466895331006685, Train_acc 0.9941007653061225\n",
      "\n",
      "Epoch 31. Loss: 0.013247548212016916, Train_acc 0.9941603535353535\n",
      "\n",
      "Epoch 31. Loss: 0.012944313066666093, Train_acc 0.99421875\n",
      "\n",
      "[Epoch 31 Batch 100] Loss: 0.012761341026393862 Training: accuracy=0.994199\n",
      "Epoch 31. Loss: 0.012761341026393862, Train_acc 0.9941986386138614\n",
      "\n",
      "Epoch 31. Loss: 0.011989341332884094, Train_acc 0.9942555147058824\n",
      "\n",
      "Epoch 31. Loss: 0.011933839328770157, Train_acc 0.9942354368932039\n",
      "\n",
      "Epoch 31. Loss: 0.011033583774582429, Train_acc 0.9942908653846154\n",
      "\n",
      "Epoch 31. Loss: 0.010669339802711503, Train_acc 0.9943452380952381\n",
      "\n",
      "Epoch 31. Loss: 0.010460738784238068, Train_acc 0.9943985849056604\n",
      "\n",
      "Epoch 31. Loss: 0.009942722430748672, Train_acc 0.9944509345794392\n",
      "\n",
      "Epoch 31. Loss: 0.009973998951246975, Train_acc 0.9945023148148148\n",
      "\n",
      "Epoch 31. Loss: 0.010601127374765847, Train_acc 0.9944094036697247\n",
      "\n",
      "Epoch 31. Loss: 0.010069118216124988, Train_acc 0.9944602272727273\n",
      "\n",
      "Epoch 31. Loss: 0.010844397939283684, Train_acc 0.9943693693693694\n",
      "\n",
      "Epoch 31. Loss: 0.012764663119947048, Train_acc 0.9943498883928571\n",
      "\n",
      "Epoch 31. Loss: 0.012165770255999384, Train_acc 0.9943998893805309\n",
      "\n",
      "Epoch 31. Loss: 0.012298351256677465, Train_acc 0.9943119517543859\n",
      "\n",
      "Epoch 31. Loss: 0.012535351607467791, Train_acc 0.9942934782608696\n",
      "\n",
      "Epoch 31. Loss: 0.012348487758576328, Train_acc 0.9942753232758621\n",
      "\n",
      "Epoch 31. Loss: 0.011573421575670949, Train_acc 0.9943242521367521\n",
      "\n",
      "Epoch 31. Loss: 0.014755500213544527, Train_acc 0.994239936440678\n",
      "\n",
      "Epoch 31. Loss: 0.017348015626884365, Train_acc 0.9942226890756303\n",
      "\n",
      "Epoch 31. Loss: 0.015847236987009822, Train_acc 0.9942708333333333\n",
      "\n",
      "Epoch 31. Loss: 0.01693903732394145, Train_acc 0.9942536157024794\n",
      "\n",
      "Epoch 31. Loss: 0.01907432409907847, Train_acc 0.9942366803278688\n",
      "\n",
      "Epoch 31. Loss: 0.017830326077286626, Train_acc 0.9942200203252033\n",
      "\n",
      "Epoch 31. Loss: 0.01657905295516034, Train_acc 0.9942666330645161\n",
      "\n",
      "Epoch 31. Loss: 0.016074625965431154, Train_acc 0.99425\n",
      "\n",
      "Epoch 31. Loss: 0.014536105779759424, Train_acc 0.9942956349206349\n",
      "\n",
      "Epoch 31. Loss: 0.013595546139808599, Train_acc 0.9943405511811023\n",
      "\n",
      "Epoch 31. Loss: 0.013466637078105304, Train_acc 0.99432373046875\n",
      "\n",
      "Epoch 31. Loss: 0.012545524829488003, Train_acc 0.9943677325581395\n",
      "\n",
      "Epoch 31. Loss: 0.012077688464994137, Train_acc 0.9944110576923076\n",
      "\n",
      "Epoch 31. Loss: 0.01112362266787878, Train_acc 0.9944537213740458\n",
      "\n",
      "Epoch 31. Loss: 0.01076474273913197, Train_acc 0.994436553030303\n",
      "\n",
      "Epoch 31. Loss: 0.011651014213679065, Train_acc 0.9944196428571429\n",
      "\n",
      "Epoch 31. Loss: 0.01355349843196675, Train_acc 0.9944029850746269\n",
      "\n",
      "Epoch 31. Loss: 0.01419834635698144, Train_acc 0.9943287037037037\n",
      "\n",
      "Epoch 31. Loss: 0.01320019199849675, Train_acc 0.9943704044117647\n",
      "\n",
      "Epoch 31. Loss: 0.012064708429625719, Train_acc 0.994411496350365\n",
      "\n",
      "Epoch 31. Loss: 0.011384935054675718, Train_acc 0.9944519927536232\n",
      "\n",
      "Epoch 31. Loss: 0.011588743271824103, Train_acc 0.994435701438849\n",
      "\n",
      "Epoch 31. Loss: 0.011374953300413234, Train_acc 0.9944196428571429\n",
      "\n",
      "Epoch 31. Loss: 0.010736865638038585, Train_acc 0.994459219858156\n",
      "\n",
      "Epoch 31. Loss: 0.009765504440113369, Train_acc 0.9944982394366197\n",
      "\n",
      "Epoch 31. Loss: 0.011059617898265539, Train_acc 0.9943728146853147\n",
      "\n",
      "Epoch 31. Loss: 0.010556743634253758, Train_acc 0.9944118923611112\n",
      "\n",
      "Epoch 31. Loss: 0.01566726327762903, Train_acc 0.9943426724137931\n",
      "\n",
      "Epoch 31. Loss: 0.015262062534623456, Train_acc 0.9943279109589042\n",
      "\n",
      "Epoch 31. Loss: 0.014002067248835962, Train_acc 0.9943664965986394\n",
      "\n",
      "Epoch 31. Loss: 0.012921846103651645, Train_acc 0.9944045608108109\n",
      "\n",
      "Epoch 31. Loss: 0.012358868908420195, Train_acc 0.9944421140939598\n",
      "\n",
      "Epoch 31. Loss: 0.011419228487530343, Train_acc 0.9944791666666667\n",
      "\n",
      "Epoch 31. Loss: 0.01062019926252424, Train_acc 0.9945157284768212\n",
      "\n",
      "Epoch 31. Loss: 0.012026915060959393, Train_acc 0.9945004111842105\n",
      "\n",
      "Epoch 31. Loss: 0.011256961564703705, Train_acc 0.9945363562091504\n",
      "\n",
      "Epoch 31. Loss: 0.013536099529699018, Train_acc 0.9945211038961039\n",
      "\n",
      "Epoch 31. Loss: 0.016250220480354606, Train_acc 0.9944556451612904\n",
      "\n",
      "Epoch 31. Loss: 0.016794134342186434, Train_acc 0.9943910256410257\n",
      "\n",
      "Epoch 31. Loss: 0.018319611993592486, Train_acc 0.994327229299363\n",
      "\n",
      "Epoch 31. Loss: 0.02123514435931579, Train_acc 0.9943136867088608\n",
      "\n",
      "Epoch 31. Loss: 0.01938052493943604, Train_acc 0.9943494496855346\n",
      "\n",
      "Epoch 31. Loss: 0.017526886266370105, Train_acc 0.994384765625\n",
      "\n",
      "Epoch 31. Loss: 0.01963226510754182, Train_acc 0.9942740683229814\n",
      "\n",
      "Epoch 31. Loss: 0.020297108340301698, Train_acc 0.994164737654321\n",
      "\n",
      "Epoch 31. Loss: 0.021898627204929518, Train_acc 0.9941046779141104\n",
      "\n",
      "Epoch 31. Loss: 0.022616530699939782, Train_acc 0.9940453506097561\n",
      "\n",
      "Epoch 31. Loss: 0.02143986759118252, Train_acc 0.9940814393939394\n",
      "\n",
      "Epoch 31. Loss: 0.021820926554787276, Train_acc 0.9940229668674698\n",
      "\n",
      "Epoch 31. Loss: 0.02311088566880356, Train_acc 0.9940119760479041\n",
      "\n",
      "Epoch 31. Loss: 0.024114150255032756, Train_acc 0.9939546130952381\n",
      "\n",
      "Epoch 31. Loss: 0.024630734055437187, Train_acc 0.9938979289940828\n",
      "\n",
      "Epoch 31. Loss: 0.02557630015539903, Train_acc 0.9937959558823529\n",
      "\n",
      "Epoch 31. Loss: 0.02378086812051635, Train_acc 0.9938322368421053\n",
      "\n",
      "Epoch 31. Loss: 0.023811772317461677, Train_acc 0.9937772529069767\n",
      "\n",
      "Epoch 31. Loss: 0.026410452888106565, Train_acc 0.9936777456647399\n",
      "\n",
      "Epoch 31. Loss: 0.02607938299986296, Train_acc 0.9935793821839081\n",
      "\n",
      "Epoch 31. Loss: 0.024443651776724216, Train_acc 0.9935714285714285\n",
      "\n",
      "Epoch 31. Loss: 0.030602806545388543, Train_acc 0.9934303977272727\n",
      "\n",
      "Epoch 31. Loss: 0.03630010521747933, Train_acc 0.9933350988700564\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31. Loss: 0.03643575708274484, Train_acc 0.9933286516853933\n",
      "\n",
      "Epoch 31. Loss: 0.036681819559971456, Train_acc 0.9933222765363129\n",
      "\n",
      "Epoch 31. Loss: 0.03595754639968869, Train_acc 0.9932725694444444\n",
      "\n",
      "Epoch 31. Loss: 0.034684098988761874, Train_acc 0.9932665745856354\n",
      "\n",
      "Epoch 31. Loss: 0.03716392045914266, Train_acc 0.9932606456043956\n",
      "\n",
      "Epoch 31. Loss: 0.03469796401142299, Train_acc 0.9932974726775956\n",
      "\n",
      "Epoch 31. Loss: 0.03236274854283828, Train_acc 0.9932914402173914\n",
      "\n",
      "Epoch 31. Loss: 0.030409461804699583, Train_acc 0.9933277027027027\n",
      "\n",
      "Epoch 31. Loss: 0.0323390587107584, Train_acc 0.9932375672043011\n",
      "\n",
      "Epoch 31. Loss: 0.033798997754118904, Train_acc 0.9931901737967914\n",
      "\n",
      "Epoch 31. Loss: 0.036122656378980336, Train_acc 0.9931432845744681\n",
      "\n",
      "Epoch 31. Loss: 0.040635403854104156, Train_acc 0.9930142195767195\n",
      "\n",
      "Epoch 31. Loss: 0.037312277441801676, Train_acc 0.9930509868421052\n",
      "\n",
      "Epoch 31. Loss: 0.03589212554894273, Train_acc 0.9930464659685864\n",
      "\n",
      "Epoch 31. Loss: 0.0362340643245195, Train_acc 0.9930419921875\n",
      "\n",
      "Epoch 31. Loss: 0.036275898001034375, Train_acc 0.9929566062176166\n",
      "\n",
      "Epoch 31. Loss: 0.03382846638390957, Train_acc 0.9929526417525774\n",
      "\n",
      "Epoch 31. Loss: 0.03381187289800828, Train_acc 0.992948717948718\n",
      "\n",
      "Epoch 31. Loss: 0.039937341837703456, Train_acc 0.99288\n",
      "\n",
      "Epoch 32. Loss: 0.038921855430560655, Train_acc 0.9921875\n",
      "\n",
      "Epoch 32. Loss: 0.03846808005043031, Train_acc 0.984375\n",
      "\n",
      "Epoch 32. Loss: 0.03863000552655602, Train_acc 0.9817708333333334\n",
      "\n",
      "Epoch 32. Loss: 0.03853460860968839, Train_acc 0.982421875\n",
      "\n",
      "Epoch 32. Loss: 0.042246158832799294, Train_acc 0.9828125\n",
      "\n",
      "Epoch 32. Loss: 0.038570065310142246, Train_acc 0.9856770833333334\n",
      "\n",
      "Epoch 32. Loss: 0.03548143794771297, Train_acc 0.9877232142857143\n",
      "\n",
      "Epoch 32. Loss: 0.03699598415764806, Train_acc 0.9873046875\n",
      "\n",
      "Epoch 32. Loss: 0.034644896405839655, Train_acc 0.9878472222222222\n",
      "\n",
      "Epoch 32. Loss: 0.03519568111113047, Train_acc 0.98671875\n",
      "\n",
      "Epoch 32. Loss: 0.03483273922453525, Train_acc 0.9865056818181818\n",
      "\n",
      "Epoch 32. Loss: 0.0514439121399838, Train_acc 0.984375\n",
      "\n",
      "Epoch 32. Loss: 0.0469926329789625, Train_acc 0.9855769230769231\n",
      "\n",
      "Epoch 32. Loss: 0.04407274304372666, Train_acc 0.9860491071428571\n",
      "\n",
      "Epoch 32. Loss: 0.04002854084038077, Train_acc 0.9869791666666666\n",
      "\n",
      "Epoch 32. Loss: 0.04020449166056519, Train_acc 0.98681640625\n",
      "\n",
      "Epoch 32. Loss: 0.04356995726725762, Train_acc 0.9848345588235294\n",
      "\n",
      "Epoch 32. Loss: 0.04141729627640222, Train_acc 0.9848090277777778\n",
      "\n",
      "Epoch 32. Loss: 0.04704054642848231, Train_acc 0.9847861842105263\n",
      "\n",
      "Epoch 32. Loss: 0.04345433387129358, Train_acc 0.98515625\n",
      "\n",
      "Epoch 32. Loss: 0.03956988913985059, Train_acc 0.9858630952380952\n",
      "\n",
      "Epoch 32. Loss: 0.03696947698150843, Train_acc 0.9865056818181818\n",
      "\n",
      "Epoch 32. Loss: 0.03652699653227422, Train_acc 0.9860733695652174\n",
      "\n",
      "Epoch 32. Loss: 0.034723679249757174, Train_acc 0.986328125\n",
      "\n",
      "Epoch 32. Loss: 0.03510595562333492, Train_acc 0.9859375\n",
      "\n",
      "Epoch 32. Loss: 0.0333919276872989, Train_acc 0.9861778846153846\n",
      "\n",
      "Epoch 32. Loss: 0.03186988831279127, Train_acc 0.9864004629629629\n",
      "\n",
      "Epoch 32. Loss: 0.030519985786534382, Train_acc 0.9866071428571429\n",
      "\n",
      "Epoch 32. Loss: 0.028620953286251753, Train_acc 0.9870689655172413\n",
      "\n",
      "Epoch 32. Loss: 0.03540068262031197, Train_acc 0.9869791666666666\n",
      "\n",
      "Epoch 32. Loss: 0.033177201240156766, Train_acc 0.9871471774193549\n",
      "\n",
      "Epoch 32. Loss: 0.03470468457540394, Train_acc 0.987060546875\n",
      "\n",
      "Epoch 32. Loss: 0.035594333136086356, Train_acc 0.9865056818181818\n",
      "\n",
      "Epoch 32. Loss: 0.03871237688422623, Train_acc 0.9855238970588235\n",
      "\n",
      "Epoch 32. Loss: 0.03634955850461503, Train_acc 0.9859375\n",
      "\n",
      "Epoch 32. Loss: 0.036816434120113074, Train_acc 0.9858940972222222\n",
      "\n",
      "Epoch 32. Loss: 0.03905253504661419, Train_acc 0.9856418918918919\n",
      "\n",
      "Epoch 32. Loss: 0.03741836584312646, Train_acc 0.985608552631579\n",
      "\n",
      "Epoch 32. Loss: 0.03556688460740085, Train_acc 0.9857772435897436\n",
      "\n",
      "Epoch 32. Loss: 0.03292750213026376, Train_acc 0.9861328125\n",
      "\n",
      "Epoch 32. Loss: 0.03602637702357207, Train_acc 0.9855182926829268\n",
      "\n",
      "Epoch 32. Loss: 0.03679490070758552, Train_acc 0.9853050595238095\n",
      "\n",
      "Epoch 32. Loss: 0.0346909068708267, Train_acc 0.9854651162790697\n",
      "\n",
      "Epoch 32. Loss: 0.033421012254176694, Train_acc 0.9856178977272727\n",
      "\n",
      "Epoch 32. Loss: 0.03900260477508738, Train_acc 0.9852430555555556\n",
      "\n",
      "Epoch 32. Loss: 0.03644571657549412, Train_acc 0.9853940217391305\n",
      "\n",
      "Epoch 32. Loss: 0.03574532491479282, Train_acc 0.9853723404255319\n",
      "\n",
      "Epoch 32. Loss: 0.03669182857138483, Train_acc 0.9851888020833334\n",
      "\n",
      "Epoch 32. Loss: 0.03622245140608461, Train_acc 0.9851721938775511\n",
      "\n",
      "Epoch 32. Loss: 0.03451495257976334, Train_acc 0.9853125\n",
      "\n",
      "Epoch 32. Loss: 0.032535625085646044, Train_acc 0.9856004901960784\n",
      "\n",
      "Epoch 32. Loss: 0.032399508060885186, Train_acc 0.9857271634615384\n",
      "\n",
      "Epoch 32. Loss: 0.03253962229359691, Train_acc 0.9857016509433962\n",
      "\n",
      "Epoch 32. Loss: 0.03523182911278496, Train_acc 0.9856770833333334\n",
      "\n",
      "Epoch 32. Loss: 0.035003932201281396, Train_acc 0.985653409090909\n",
      "\n",
      "Epoch 32. Loss: 0.035461010977699055, Train_acc 0.9857700892857143\n",
      "\n",
      "Epoch 32. Loss: 0.03980606118894252, Train_acc 0.9857456140350878\n",
      "\n",
      "Epoch 32. Loss: 0.04060889396122067, Train_acc 0.9857219827586207\n",
      "\n",
      "Epoch 32. Loss: 0.03882416047648462, Train_acc 0.9856991525423728\n",
      "\n",
      "Epoch 32. Loss: 0.03564833756234532, Train_acc 0.9859375\n",
      "\n",
      "Epoch 32. Loss: 0.0344744569594826, Train_acc 0.9859118852459017\n",
      "\n",
      "Epoch 32. Loss: 0.03367973702715329, Train_acc 0.9860131048387096\n",
      "\n",
      "Epoch 32. Loss: 0.031023421502335294, Train_acc 0.9862351190476191\n",
      "\n",
      "Epoch 32. Loss: 0.03944941933413454, Train_acc 0.9862060546875\n",
      "\n",
      "Epoch 32. Loss: 0.037436814722062124, Train_acc 0.9862980769230769\n",
      "\n",
      "Epoch 32. Loss: 0.03529157987979738, Train_acc 0.9863873106060606\n",
      "\n",
      "Epoch 32. Loss: 0.031912835039457126, Train_acc 0.9865904850746269\n",
      "\n",
      "Epoch 32. Loss: 0.030319131290400425, Train_acc 0.9867876838235294\n",
      "\n",
      "Epoch 32. Loss: 0.028761692904368995, Train_acc 0.9869791666666666\n",
      "\n",
      "Epoch 32. Loss: 0.026685258970054353, Train_acc 0.9871651785714286\n",
      "\n",
      "Epoch 32. Loss: 0.024991789251916738, Train_acc 0.9873459507042254\n",
      "\n",
      "Epoch 32. Loss: 0.022798494239094674, Train_acc 0.9875217013888888\n",
      "\n",
      "Epoch 32. Loss: 0.021533935060598988, Train_acc 0.9876926369863014\n",
      "\n",
      "Epoch 32. Loss: 0.021799945867507345, Train_acc 0.9876478040540541\n",
      "\n",
      "Epoch 32. Loss: 0.021935167047186514, Train_acc 0.9877083333333333\n",
      "\n",
      "Epoch 32. Loss: 0.021678453541818698, Train_acc 0.9877672697368421\n",
      "\n",
      "Epoch 32. Loss: 0.019885759589022493, Train_acc 0.9879261363636364\n",
      "\n",
      "Epoch 32. Loss: 0.019268826949846236, Train_acc 0.9880809294871795\n",
      "\n",
      "Epoch 32. Loss: 0.019103918462918538, Train_acc 0.9881329113924051\n",
      "\n",
      "Epoch 32. Loss: 0.01804157945358128, Train_acc 0.98828125\n",
      "\n",
      "Epoch 32. Loss: 0.016854807256996965, Train_acc 0.9884259259259259\n",
      "\n",
      "Epoch 32. Loss: 0.017068875337547362, Train_acc 0.9884717987804879\n",
      "\n",
      "Epoch 32. Loss: 0.017212210227465302, Train_acc 0.9885165662650602\n",
      "\n",
      "Epoch 32. Loss: 0.015654915458745363, Train_acc 0.9886532738095238\n",
      "\n",
      "Epoch 32. Loss: 0.014907123643267099, Train_acc 0.9887867647058823\n",
      "\n",
      "Epoch 32. Loss: 0.013737158633939574, Train_acc 0.9889171511627907\n",
      "\n",
      "Epoch 32. Loss: 0.013091765429233447, Train_acc 0.9890445402298851\n",
      "\n",
      "Epoch 32. Loss: 0.012071463332724514, Train_acc 0.9891690340909091\n",
      "\n",
      "Epoch 32. Loss: 0.01651988807274575, Train_acc 0.9892029494382022\n",
      "\n",
      "Epoch 32. Loss: 0.0167112349312336, Train_acc 0.9891493055555556\n",
      "\n",
      "Epoch 32. Loss: 0.015401078237890966, Train_acc 0.9892685439560439\n",
      "\n",
      "Epoch 32. Loss: 0.01397591007859239, Train_acc 0.9893851902173914\n",
      "\n",
      "Epoch 32. Loss: 0.014864666817582212, Train_acc 0.9894153225806451\n",
      "\n",
      "Epoch 32. Loss: 0.013620489617508556, Train_acc 0.9895279255319149\n",
      "\n",
      "Epoch 32. Loss: 0.012772780451093828, Train_acc 0.9896381578947369\n",
      "\n",
      "Epoch 32. Loss: 0.01293922580890183, Train_acc 0.9896647135416666\n",
      "\n",
      "Epoch 32. Loss: 0.017996494033446827, Train_acc 0.9896907216494846\n",
      "\n",
      "Epoch 32. Loss: 0.016521120812902676, Train_acc 0.9897959183673469\n",
      "\n",
      "Epoch 32. Loss: 0.015425872017213548, Train_acc 0.98989898989899\n",
      "\n",
      "Epoch 32. Loss: 0.01510610353285269, Train_acc 0.989921875\n",
      "\n",
      "[Epoch 32 Batch 100] Loss: 0.01410584053472456 Training: accuracy=0.990022\n",
      "Epoch 32. Loss: 0.01410584053472456, Train_acc 0.9900216584158416\n",
      "\n",
      "Epoch 32. Loss: 0.013748639682612807, Train_acc 0.9900428921568627\n",
      "\n",
      "Epoch 32. Loss: 0.013060890515609375, Train_acc 0.9901395631067961\n",
      "\n",
      "Epoch 32. Loss: 0.013485077363220266, Train_acc 0.9901592548076923\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32. Loss: 0.01644274742183156, Train_acc 0.9899553571428571\n",
      "\n",
      "Epoch 32. Loss: 0.016176470413300996, Train_acc 0.9899764150943396\n",
      "\n",
      "Epoch 32. Loss: 0.014678846078658348, Train_acc 0.990070093457944\n",
      "\n",
      "Epoch 32. Loss: 0.013375498253332894, Train_acc 0.9901620370370371\n",
      "\n",
      "Epoch 32. Loss: 0.012653719449693549, Train_acc 0.9902522935779816\n",
      "\n",
      "Epoch 32. Loss: 0.01508532298921459, Train_acc 0.9902698863636363\n",
      "\n",
      "Epoch 32. Loss: 0.015405675582458794, Train_acc 0.9902871621621622\n",
      "\n",
      "Epoch 32. Loss: 0.014491964066285092, Train_acc 0.9903738839285714\n",
      "\n",
      "Epoch 32. Loss: 0.013698182429082571, Train_acc 0.9904590707964602\n",
      "\n",
      "Epoch 32. Loss: 0.01414784346539442, Train_acc 0.9904057017543859\n",
      "\n",
      "Epoch 32. Loss: 0.014275970797407606, Train_acc 0.9904211956521739\n",
      "\n",
      "Epoch 32. Loss: 0.014695192157329302, Train_acc 0.9904364224137931\n",
      "\n",
      "Epoch 32. Loss: 0.016560587089450223, Train_acc 0.9904513888888888\n",
      "\n",
      "Epoch 32. Loss: 0.015893559613398667, Train_acc 0.9905323093220338\n",
      "\n",
      "Epoch 32. Loss: 0.014429625212428233, Train_acc 0.9906118697478992\n",
      "\n",
      "Epoch 32. Loss: 0.013775792052695687, Train_acc 0.9906901041666667\n",
      "\n",
      "Epoch 32. Loss: 0.012580744505054833, Train_acc 0.9907670454545454\n",
      "\n",
      "Epoch 32. Loss: 0.011444967446776104, Train_acc 0.9908427254098361\n",
      "\n",
      "Epoch 32. Loss: 0.011194219626234656, Train_acc 0.990917174796748\n",
      "\n",
      "Epoch 32. Loss: 0.010658456636366265, Train_acc 0.9909904233870968\n",
      "\n",
      "Epoch 32. Loss: 0.010439620728400665, Train_acc 0.991\n",
      "\n",
      "Epoch 32. Loss: 0.009695542615375504, Train_acc 0.9910714285714286\n",
      "\n",
      "Epoch 32. Loss: 0.009875372472454536, Train_acc 0.9910802165354331\n",
      "\n",
      "Epoch 32. Loss: 0.009818265779062594, Train_acc 0.99114990234375\n",
      "\n",
      "Epoch 32. Loss: 0.010951032625059323, Train_acc 0.9911579457364341\n",
      "\n",
      "Epoch 32. Loss: 0.011103511388379369, Train_acc 0.9911658653846154\n",
      "\n",
      "Epoch 32. Loss: 0.010264668207491666, Train_acc 0.9912333015267175\n",
      "\n",
      "Epoch 32. Loss: 0.010043845146410373, Train_acc 0.9912997159090909\n",
      "\n",
      "Epoch 32. Loss: 0.010340472633701003, Train_acc 0.9913063909774437\n",
      "\n",
      "Epoch 32. Loss: 0.009808410892317983, Train_acc 0.9913712686567164\n",
      "\n",
      "Epoch 32. Loss: 0.01100639002570238, Train_acc 0.9913194444444444\n",
      "\n",
      "Epoch 32. Loss: 0.01035605088962966, Train_acc 0.9913832720588235\n",
      "\n",
      "Epoch 32. Loss: 0.009447832707782274, Train_acc 0.9914461678832117\n",
      "\n",
      "Epoch 32. Loss: 0.009561222057836966, Train_acc 0.9915081521739131\n",
      "\n",
      "Epoch 32. Loss: 0.008841882213806555, Train_acc 0.9915692446043165\n",
      "\n",
      "Epoch 32. Loss: 0.008007390371999917, Train_acc 0.9916294642857143\n",
      "\n",
      "Epoch 32. Loss: 0.00744204963479201, Train_acc 0.991688829787234\n",
      "\n",
      "Epoch 32. Loss: 0.006954079521115959, Train_acc 0.9917473591549296\n",
      "\n",
      "Epoch 32. Loss: 0.006435116218700713, Train_acc 0.9918050699300699\n",
      "\n",
      "Epoch 32. Loss: 0.006056921401701605, Train_acc 0.9918619791666666\n",
      "\n",
      "Epoch 32. Loss: 0.0059831976427873095, Train_acc 0.9919181034482759\n",
      "\n",
      "Epoch 32. Loss: 0.005913993804982912, Train_acc 0.9919734589041096\n",
      "\n",
      "Epoch 32. Loss: 0.006575922151802431, Train_acc 0.9919749149659864\n",
      "\n",
      "Epoch 32. Loss: 0.008757766691206502, Train_acc 0.9919763513513513\n",
      "\n",
      "Epoch 32. Loss: 0.008346835936479516, Train_acc 0.9920302013422819\n",
      "\n",
      "Epoch 32. Loss: 0.008013167100732995, Train_acc 0.9920833333333333\n",
      "\n",
      "Epoch 32. Loss: 0.007527438125463253, Train_acc 0.992135761589404\n",
      "\n",
      "Epoch 32. Loss: 0.009743144948588543, Train_acc 0.9920847039473685\n",
      "\n",
      "Epoch 32. Loss: 0.009031639905399144, Train_acc 0.9921364379084967\n",
      "\n",
      "Epoch 32. Loss: 0.008638600125127488, Train_acc 0.9921875\n",
      "\n",
      "Epoch 32. Loss: 0.007991603230726826, Train_acc 0.9922379032258064\n",
      "\n",
      "Epoch 32. Loss: 0.0074765561769534125, Train_acc 0.9922876602564102\n",
      "\n",
      "Epoch 32. Loss: 0.0073788916319724, Train_acc 0.9923367834394905\n",
      "\n",
      "Epoch 32. Loss: 0.007049791378910787, Train_acc 0.9923852848101266\n",
      "\n",
      "Epoch 32. Loss: 0.00701214332935403, Train_acc 0.992433176100629\n",
      "\n",
      "Epoch 32. Loss: 0.006452866025966617, Train_acc 0.99248046875\n",
      "\n",
      "Epoch 32. Loss: 0.00642079433712561, Train_acc 0.9925271739130435\n",
      "\n",
      "Epoch 32. Loss: 0.006304091104089014, Train_acc 0.9925733024691358\n",
      "\n",
      "Epoch 32. Loss: 0.006179598069461101, Train_acc 0.9926188650306749\n",
      "\n",
      "Epoch 32. Loss: 0.006229297828321379, Train_acc 0.9926638719512195\n",
      "\n",
      "Epoch 32. Loss: 0.010918360809962203, Train_acc 0.9926609848484849\n",
      "\n",
      "Epoch 32. Loss: 0.010370193595123514, Train_acc 0.9927051957831325\n",
      "\n",
      "Epoch 32. Loss: 0.0094854595860978, Train_acc 0.992748877245509\n",
      "\n",
      "Epoch 32. Loss: 0.010635720202428702, Train_acc 0.9927455357142857\n",
      "\n",
      "Epoch 32. Loss: 0.010302724036144557, Train_acc 0.9927422337278107\n",
      "\n",
      "Epoch 32. Loss: 0.011682502300352463, Train_acc 0.9927389705882353\n",
      "\n",
      "Epoch 32. Loss: 0.01125944591684098, Train_acc 0.992781432748538\n",
      "\n",
      "Epoch 32. Loss: 0.013041655715909197, Train_acc 0.9927779796511628\n",
      "\n",
      "Epoch 32. Loss: 0.012364253752624925, Train_acc 0.992819725433526\n",
      "\n",
      "Epoch 32. Loss: 0.01170057201671237, Train_acc 0.9928609913793104\n",
      "\n",
      "Epoch 32. Loss: 0.01073773180615277, Train_acc 0.9929017857142857\n",
      "\n",
      "Epoch 32. Loss: 0.0107203281127337, Train_acc 0.9929421164772727\n",
      "\n",
      "Epoch 32. Loss: 0.01161677632059962, Train_acc 0.9928937146892656\n",
      "\n",
      "Epoch 32. Loss: 0.010806293539640103, Train_acc 0.9929336376404494\n",
      "\n",
      "Epoch 32. Loss: 0.010132747704479212, Train_acc 0.9929731145251397\n",
      "\n",
      "Epoch 32. Loss: 0.01160275927009563, Train_acc 0.9929253472222223\n",
      "\n",
      "Epoch 32. Loss: 0.011122026631510679, Train_acc 0.9929644337016574\n",
      "\n",
      "Epoch 32. Loss: 0.01126589751402416, Train_acc 0.9929601648351648\n",
      "\n",
      "Epoch 32. Loss: 0.010251212409823044, Train_acc 0.9929986338797814\n",
      "\n",
      "Epoch 32. Loss: 0.010028370991369103, Train_acc 0.9929942255434783\n",
      "\n",
      "Epoch 32. Loss: 0.009112558501324816, Train_acc 0.9930320945945946\n",
      "\n",
      "Epoch 32. Loss: 0.00984466454746881, Train_acc 0.9930275537634409\n",
      "\n",
      "Epoch 32. Loss: 0.010310559776686658, Train_acc 0.9930230614973262\n",
      "\n",
      "Epoch 32. Loss: 0.014230099446114627, Train_acc 0.9929770611702128\n",
      "\n",
      "Epoch 32. Loss: 0.013085170431505198, Train_acc 0.9930142195767195\n",
      "\n",
      "Epoch 32. Loss: 0.011993401185448964, Train_acc 0.9930509868421052\n",
      "\n",
      "Epoch 32. Loss: 0.011642861197092532, Train_acc 0.9930464659685864\n",
      "\n",
      "Epoch 32. Loss: 0.011024345659194945, Train_acc 0.9930826822916666\n",
      "\n",
      "Epoch 32. Loss: 0.012189843985121154, Train_acc 0.9930780440414507\n",
      "\n",
      "Epoch 32. Loss: 0.011564010692176852, Train_acc 0.9931137242268041\n",
      "\n",
      "Epoch 32. Loss: 0.011046154927495987, Train_acc 0.9931490384615385\n",
      "\n",
      "Epoch 32. Loss: 0.011548791533366328, Train_acc 0.99316\n",
      "\n",
      "Epoch 33. Loss: 0.011304589023282068, Train_acc 0.9921875\n",
      "\n",
      "Epoch 33. Loss: 0.010618734111717288, Train_acc 0.99609375\n",
      "\n",
      "Epoch 33. Loss: 0.01097712045565034, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 33. Loss: 0.014258701732648479, Train_acc 0.9921875\n",
      "\n",
      "Epoch 33. Loss: 0.01574618682792163, Train_acc 0.9921875\n",
      "\n",
      "Epoch 33. Loss: 0.015530151994052912, Train_acc 0.9921875\n",
      "\n",
      "Epoch 33. Loss: 0.014159997360485094, Train_acc 0.9933035714285714\n",
      "\n",
      "Epoch 33. Loss: 0.01300822501472589, Train_acc 0.994140625\n",
      "\n",
      "Epoch 33. Loss: 0.01435056787811479, Train_acc 0.9930555555555556\n",
      "\n",
      "Epoch 33. Loss: 0.01390526326000179, Train_acc 0.99296875\n",
      "\n",
      "Epoch 33. Loss: 0.015225694200391934, Train_acc 0.9928977272727273\n",
      "\n",
      "Epoch 33. Loss: 0.014384418349857956, Train_acc 0.9934895833333334\n",
      "\n",
      "Epoch 33. Loss: 0.013045054894443598, Train_acc 0.9939903846153846\n",
      "\n",
      "Epoch 33. Loss: 0.012674652536293489, Train_acc 0.9944196428571429\n",
      "\n",
      "Epoch 33. Loss: 0.017596606239301524, Train_acc 0.99375\n",
      "\n",
      "Epoch 33. Loss: 0.022518092088063865, Train_acc 0.9931640625\n",
      "\n",
      "Epoch 33. Loss: 0.020794721268558778, Train_acc 0.9935661764705882\n",
      "\n",
      "Epoch 33. Loss: 0.020724838739285715, Train_acc 0.9930555555555556\n",
      "\n",
      "Epoch 33. Loss: 0.03240189471749948, Train_acc 0.990953947368421\n",
      "\n",
      "Epoch 33. Loss: 0.029864150594474254, Train_acc 0.99140625\n",
      "\n",
      "Epoch 33. Loss: 0.028648975098849574, Train_acc 0.9914434523809523\n",
      "\n",
      "Epoch 33. Loss: 0.026211355114851512, Train_acc 0.9918323863636364\n",
      "\n",
      "Epoch 33. Loss: 0.02440477006647657, Train_acc 0.9921875\n",
      "\n",
      "Epoch 33. Loss: 0.022430977218720352, Train_acc 0.9925130208333334\n",
      "\n",
      "Epoch 33. Loss: 0.02186326845887873, Train_acc 0.9925\n",
      "\n",
      "Epoch 33. Loss: 0.025349347645672322, Train_acc 0.9915865384615384\n",
      "\n",
      "Epoch 33. Loss: 0.025304120500056888, Train_acc 0.9913194444444444\n",
      "\n",
      "Epoch 33. Loss: 0.02332518533840979, Train_acc 0.9916294642857143\n",
      "\n",
      "Epoch 33. Loss: 0.021559205460699248, Train_acc 0.9919181034482759\n",
      "\n",
      "Epoch 33. Loss: 0.020682834960358006, Train_acc 0.9921875\n",
      "\n",
      "Epoch 33. Loss: 0.024038667271140214, Train_acc 0.9919354838709677\n",
      "\n",
      "Epoch 33. Loss: 0.023012365492078364, Train_acc 0.991943359375\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33. Loss: 0.023474795900487334, Train_acc 0.9919507575757576\n",
      "\n",
      "Epoch 33. Loss: 0.022262577760401456, Train_acc 0.9919577205882353\n",
      "\n",
      "Epoch 33. Loss: 0.020627757270127316, Train_acc 0.9921875\n",
      "\n",
      "Epoch 33. Loss: 0.02071043136029522, Train_acc 0.9921875\n",
      "\n",
      "Epoch 33. Loss: 0.022448705425641657, Train_acc 0.9919763513513513\n",
      "\n",
      "Epoch 33. Loss: 0.020694449096126902, Train_acc 0.9921875\n",
      "\n",
      "Epoch 33. Loss: 0.018961679835091724, Train_acc 0.9923878205128205\n",
      "\n",
      "Epoch 33. Loss: 0.018268194071028258, Train_acc 0.992578125\n",
      "\n",
      "Epoch 33. Loss: 0.022144763936019208, Train_acc 0.9923780487804879\n",
      "\n",
      "Epoch 33. Loss: 0.021887726801111933, Train_acc 0.9923735119047619\n",
      "\n",
      "Epoch 33. Loss: 0.02030935774443266, Train_acc 0.9925508720930233\n",
      "\n",
      "Epoch 33. Loss: 0.021986829252818682, Train_acc 0.9923650568181818\n",
      "\n",
      "Epoch 33. Loss: 0.020641260995816698, Train_acc 0.9925347222222223\n",
      "\n",
      "Epoch 33. Loss: 0.018689470908769826, Train_acc 0.9926970108695652\n",
      "\n",
      "Epoch 33. Loss: 0.017337270290460165, Train_acc 0.9928523936170213\n",
      "\n",
      "Epoch 33. Loss: 0.015879314022486785, Train_acc 0.9930013020833334\n",
      "\n",
      "Epoch 33. Loss: 0.01533735985135321, Train_acc 0.9931441326530612\n",
      "\n",
      "Epoch 33. Loss: 0.015586027938800612, Train_acc 0.993125\n",
      "\n",
      "Epoch 33. Loss: 0.016903057006309233, Train_acc 0.9931066176470589\n",
      "\n",
      "Epoch 33. Loss: 0.015467599136771086, Train_acc 0.9932391826923077\n",
      "\n",
      "Epoch 33. Loss: 0.017036545741386404, Train_acc 0.9930719339622641\n",
      "\n",
      "Epoch 33. Loss: 0.016878880587512725, Train_acc 0.9932002314814815\n",
      "\n",
      "Epoch 33. Loss: 0.01566137580778701, Train_acc 0.9933238636363636\n",
      "\n",
      "Epoch 33. Loss: 0.014533082818223563, Train_acc 0.9934430803571429\n",
      "\n",
      "Epoch 33. Loss: 0.013342308549419219, Train_acc 0.9935581140350878\n",
      "\n",
      "Epoch 33. Loss: 0.012490135195107915, Train_acc 0.9936691810344828\n",
      "\n",
      "Epoch 33. Loss: 0.012770949948357039, Train_acc 0.9937764830508474\n",
      "\n",
      "Epoch 33. Loss: 0.012686860452020015, Train_acc 0.99375\n",
      "\n",
      "Epoch 33. Loss: 0.012551537541977029, Train_acc 0.9938524590163934\n",
      "\n",
      "Epoch 33. Loss: 0.011769468088535781, Train_acc 0.9939516129032258\n",
      "\n",
      "Epoch 33. Loss: 0.010854325135801717, Train_acc 0.9940476190476191\n",
      "\n",
      "Epoch 33. Loss: 0.010904439336289004, Train_acc 0.9940185546875\n",
      "\n",
      "Epoch 33. Loss: 0.011803860333170626, Train_acc 0.9938701923076924\n",
      "\n",
      "Epoch 33. Loss: 0.010887336471995234, Train_acc 0.9939630681818182\n",
      "\n",
      "Epoch 33. Loss: 0.011088156392562854, Train_acc 0.9939365671641791\n",
      "\n",
      "Epoch 33. Loss: 0.010720933175434292, Train_acc 0.9940257352941176\n",
      "\n",
      "Epoch 33. Loss: 0.010779252376868982, Train_acc 0.9939990942028986\n",
      "\n",
      "Epoch 33. Loss: 0.011879562491221421, Train_acc 0.9939732142857143\n",
      "\n",
      "Epoch 33. Loss: 0.010809098359086984, Train_acc 0.9940580985915493\n",
      "\n",
      "Epoch 33. Loss: 0.011405665137891955, Train_acc 0.9939236111111112\n",
      "\n",
      "Epoch 33. Loss: 0.010314924236325535, Train_acc 0.9940068493150684\n",
      "\n",
      "Epoch 33. Loss: 0.010508265353311402, Train_acc 0.9939822635135135\n",
      "\n",
      "Epoch 33. Loss: 0.011534902832272025, Train_acc 0.9939583333333334\n",
      "\n",
      "Epoch 33. Loss: 0.011452601427312827, Train_acc 0.9939350328947368\n",
      "\n",
      "Epoch 33. Loss: 0.010536042886317792, Train_acc 0.9940137987012987\n",
      "\n",
      "Epoch 33. Loss: 0.010785263325876912, Train_acc 0.9939903846153846\n",
      "\n",
      "Epoch 33. Loss: 0.010026645645743836, Train_acc 0.9940664556962026\n",
      "\n",
      "Epoch 33. Loss: 0.009808330336433257, Train_acc 0.99404296875\n",
      "\n",
      "Epoch 33. Loss: 0.009423332526583915, Train_acc 0.994116512345679\n",
      "\n",
      "Epoch 33. Loss: 0.009138922048478822, Train_acc 0.9941882621951219\n",
      "\n",
      "Epoch 33. Loss: 0.008312789091611953, Train_acc 0.9942582831325302\n",
      "\n",
      "Epoch 33. Loss: 0.00831487624866818, Train_acc 0.9943266369047619\n",
      "\n",
      "Epoch 33. Loss: 0.008247106383201969, Train_acc 0.9943933823529412\n",
      "\n",
      "Epoch 33. Loss: 0.007627320052645349, Train_acc 0.9944585755813954\n",
      "\n",
      "Epoch 33. Loss: 0.007022291017699311, Train_acc 0.9945222701149425\n",
      "\n",
      "Epoch 33. Loss: 0.008294738465364042, Train_acc 0.9944957386363636\n",
      "\n",
      "Epoch 33. Loss: 0.008356124394072828, Train_acc 0.9945575842696629\n",
      "\n",
      "Epoch 33. Loss: 0.009701817318439845, Train_acc 0.99453125\n",
      "\n",
      "Epoch 33. Loss: 0.00881336544058728, Train_acc 0.9945913461538461\n",
      "\n",
      "Epoch 33. Loss: 0.008071450656633148, Train_acc 0.9946501358695652\n",
      "\n",
      "Epoch 33. Loss: 0.0075075747774367655, Train_acc 0.9947076612903226\n",
      "\n",
      "Epoch 33. Loss: 0.008600961912243825, Train_acc 0.9946808510638298\n",
      "\n",
      "Epoch 33. Loss: 0.009978420174332793, Train_acc 0.9946546052631579\n",
      "\n",
      "Epoch 33. Loss: 0.009616240319575968, Train_acc 0.9947102864583334\n",
      "\n",
      "Epoch 33. Loss: 0.009169967871799562, Train_acc 0.9947648195876289\n",
      "\n",
      "Epoch 33. Loss: 0.008423541440459634, Train_acc 0.9948182397959183\n",
      "\n",
      "Epoch 33. Loss: 0.008583867434167157, Train_acc 0.9948705808080808\n",
      "\n",
      "Epoch 33. Loss: 0.008105907918105983, Train_acc 0.994921875\n",
      "\n",
      "[Epoch 33 Batch 100] Loss: 0.009166139473995982 Training: accuracy=0.994895\n",
      "Epoch 33. Loss: 0.009166139473995982, Train_acc 0.994894801980198\n",
      "\n",
      "Epoch 33. Loss: 0.011377386922074632, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 33. Loss: 0.0124662548000514, Train_acc 0.9947663834951457\n",
      "\n",
      "Epoch 33. Loss: 0.011977911089277222, Train_acc 0.9947415865384616\n",
      "\n",
      "Epoch 33. Loss: 0.011078636618926486, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 33. Loss: 0.011208139957464659, Train_acc 0.9947670990566038\n",
      "\n",
      "Epoch 33. Loss: 0.01094007070867144, Train_acc 0.9948160046728972\n",
      "\n",
      "Epoch 33. Loss: 0.01411088773019245, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 33. Loss: 0.012913408732701517, Train_acc 0.9948394495412844\n",
      "\n",
      "Epoch 33. Loss: 0.012510870249976973, Train_acc 0.994815340909091\n",
      "\n",
      "Epoch 33. Loss: 0.011636210026064749, Train_acc 0.9948620495495496\n",
      "\n",
      "Epoch 33. Loss: 0.011824511215137752, Train_acc 0.9948381696428571\n",
      "\n",
      "Epoch 33. Loss: 0.011334491862026433, Train_acc 0.9948838495575221\n",
      "\n",
      "Epoch 33. Loss: 0.011126903322935922, Train_acc 0.994860197368421\n",
      "\n",
      "Epoch 33. Loss: 0.010661706349343797, Train_acc 0.9949048913043478\n",
      "\n",
      "Epoch 33. Loss: 0.010250814464173382, Train_acc 0.9949488146551724\n",
      "\n",
      "Epoch 33. Loss: 0.009467311457937956, Train_acc 0.9949919871794872\n",
      "\n",
      "Epoch 33. Loss: 0.008790171189140678, Train_acc 0.9950344279661016\n",
      "\n",
      "Epoch 33. Loss: 0.008253128432026269, Train_acc 0.9950761554621849\n",
      "\n",
      "Epoch 33. Loss: 0.007595820756330278, Train_acc 0.9951171875\n",
      "\n",
      "Epoch 33. Loss: 0.007325497540003824, Train_acc 0.995157541322314\n",
      "\n",
      "Epoch 33. Loss: 0.008837753703147263, Train_acc 0.9951331967213115\n",
      "\n",
      "Epoch 33. Loss: 0.009155471439614973, Train_acc 0.9951092479674797\n",
      "\n",
      "Epoch 33. Loss: 0.008378123718161955, Train_acc 0.995148689516129\n",
      "\n",
      "Epoch 33. Loss: 0.00830643387376628, Train_acc 0.9951875\n",
      "\n",
      "Epoch 33. Loss: 0.00764195286920096, Train_acc 0.9952256944444444\n",
      "\n",
      "Epoch 33. Loss: 0.00732700747570776, Train_acc 0.9952632874015748\n",
      "\n",
      "Epoch 33. Loss: 0.006764886955996302, Train_acc 0.99530029296875\n",
      "\n",
      "Epoch 33. Loss: 0.006293800103810383, Train_acc 0.9953367248062015\n",
      "\n",
      "Epoch 33. Loss: 0.005995895120334881, Train_acc 0.9953725961538461\n",
      "\n",
      "Epoch 33. Loss: 0.009228459211735957, Train_acc 0.9952886450381679\n",
      "\n",
      "Epoch 33. Loss: 0.012296520140065877, Train_acc 0.9952059659090909\n",
      "\n",
      "Epoch 33. Loss: 0.0114779275540657, Train_acc 0.9952420112781954\n",
      "\n",
      "Epoch 33. Loss: 0.011073255614264055, Train_acc 0.9952775186567164\n",
      "\n",
      "Epoch 33. Loss: 0.015065648325523656, Train_acc 0.9950231481481482\n",
      "\n",
      "Epoch 33. Loss: 0.014881763832188477, Train_acc 0.9950022977941176\n",
      "\n",
      "Epoch 33. Loss: 0.018621625208631302, Train_acc 0.9949247262773723\n",
      "\n",
      "Epoch 33. Loss: 0.0168547424004638, Train_acc 0.9949615036231884\n",
      "\n",
      "Epoch 33. Loss: 0.01720891470397983, Train_acc 0.99494154676259\n",
      "\n",
      "Epoch 33. Loss: 0.017043662552703686, Train_acc 0.994921875\n",
      "\n",
      "Epoch 33. Loss: 0.015715684192518235, Train_acc 0.994957890070922\n",
      "\n",
      "Epoch 33. Loss: 0.01775449762982712, Train_acc 0.9949383802816901\n",
      "\n",
      "Epoch 33. Loss: 0.016272774922967723, Train_acc 0.9949737762237763\n",
      "\n",
      "Epoch 33. Loss: 0.014981371396776234, Train_acc 0.9950086805555556\n",
      "\n",
      "Epoch 33. Loss: 0.016066962615248138, Train_acc 0.9949353448275862\n",
      "\n",
      "Epoch 33. Loss: 0.014590895055022753, Train_acc 0.9949700342465754\n",
      "\n",
      "Epoch 33. Loss: 0.014315884041744694, Train_acc 0.9950042517006803\n",
      "\n",
      "Epoch 33. Loss: 0.013208872102051876, Train_acc 0.9950380067567568\n",
      "\n",
      "Epoch 33. Loss: 0.012604317517444404, Train_acc 0.9950713087248322\n",
      "\n",
      "Epoch 33. Loss: 0.011457094054958145, Train_acc 0.9951041666666667\n",
      "\n",
      "Epoch 33. Loss: 0.01164393011618339, Train_acc 0.9950331125827815\n",
      "\n",
      "Epoch 33. Loss: 0.014286476825672535, Train_acc 0.9949629934210527\n",
      "\n",
      "Epoch 33. Loss: 0.019852528084812894, Train_acc 0.9948427287581699\n",
      "\n",
      "Epoch 33. Loss: 0.019117036503849924, Train_acc 0.994825487012987\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33. Loss: 0.01728336812169902, Train_acc 0.994858870967742\n",
      "\n",
      "Epoch 33. Loss: 0.016253026566161684, Train_acc 0.9948918269230769\n",
      "\n",
      "Epoch 33. Loss: 0.015468864842880342, Train_acc 0.994874601910828\n",
      "\n",
      "Epoch 33. Loss: 0.015813909132446565, Train_acc 0.9948575949367089\n",
      "\n",
      "Epoch 33. Loss: 0.016853860274701465, Train_acc 0.9948408018867925\n",
      "\n",
      "Epoch 33. Loss: 0.01542858719408436, Train_acc 0.994873046875\n",
      "\n",
      "Epoch 33. Loss: 0.014668713342367919, Train_acc 0.9948563664596274\n",
      "\n",
      "Epoch 33. Loss: 0.013423993268954139, Train_acc 0.9948881172839507\n",
      "\n",
      "Epoch 33. Loss: 0.01635942190529172, Train_acc 0.9948236196319018\n",
      "\n",
      "Epoch 33. Loss: 0.015173524119477847, Train_acc 0.9948551829268293\n",
      "\n",
      "Epoch 33. Loss: 0.01773676641108517, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 33. Loss: 0.02134241119612984, Train_acc 0.9946818524096386\n",
      "\n",
      "Epoch 33. Loss: 0.023141793509629954, Train_acc 0.9945733532934131\n",
      "\n",
      "Epoch 33. Loss: 0.021071056594415834, Train_acc 0.9946056547619048\n",
      "\n",
      "Epoch 33. Loss: 0.020441710638968047, Train_acc 0.9945913461538461\n",
      "\n",
      "Epoch 33. Loss: 0.019316695537836458, Train_acc 0.9946231617647059\n",
      "\n",
      "Epoch 33. Loss: 0.017601944795254863, Train_acc 0.9946546052631579\n",
      "\n",
      "Epoch 33. Loss: 0.017017419430766106, Train_acc 0.994640261627907\n",
      "\n",
      "Epoch 33. Loss: 0.015421185590259226, Train_acc 0.9946712427745664\n",
      "\n",
      "Epoch 33. Loss: 0.02191803338894128, Train_acc 0.9945222701149425\n",
      "\n",
      "Epoch 33. Loss: 0.022083205016871207, Train_acc 0.9945089285714286\n",
      "\n",
      "Epoch 33. Loss: 0.021168952575999423, Train_acc 0.9945401278409091\n",
      "\n",
      "Epoch 33. Loss: 0.026128140442083413, Train_acc 0.9944385593220338\n",
      "\n",
      "Epoch 33. Loss: 0.030925769227007155, Train_acc 0.9943381320224719\n",
      "\n",
      "Epoch 33. Loss: 0.029908210106723718, Train_acc 0.9943261173184358\n",
      "\n",
      "Epoch 33. Loss: 0.027822127999097, Train_acc 0.9943576388888888\n",
      "\n",
      "Epoch 33. Loss: 0.025837747583892845, Train_acc 0.9943888121546961\n",
      "\n",
      "Epoch 33. Loss: 0.0304431021184685, Train_acc 0.9942479395604396\n",
      "\n",
      "Epoch 33. Loss: 0.027924697517615154, Train_acc 0.9942793715846995\n",
      "\n",
      "Epoch 33. Loss: 0.02573283573844575, Train_acc 0.9943104619565217\n",
      "\n",
      "Epoch 33. Loss: 0.024253806550281136, Train_acc 0.9943412162162162\n",
      "\n",
      "Epoch 33. Loss: 0.02609113141504844, Train_acc 0.9943296370967742\n",
      "\n",
      "Epoch 33. Loss: 0.03159533322997022, Train_acc 0.9942764037433155\n",
      "\n",
      "Epoch 33. Loss: 0.029691197964374378, Train_acc 0.9942652925531915\n",
      "\n",
      "Epoch 33. Loss: 0.02701758910260274, Train_acc 0.9942956349206349\n",
      "\n",
      "Epoch 33. Loss: 0.0254360391411931, Train_acc 0.9943256578947368\n",
      "\n",
      "Epoch 33. Loss: 0.03015087354604161, Train_acc 0.9942326570680629\n",
      "\n",
      "Epoch 33. Loss: 0.031591750086162294, Train_acc 0.9941813151041666\n",
      "\n",
      "Epoch 33. Loss: 0.030884626717102952, Train_acc 0.9941305051813472\n",
      "\n",
      "Epoch 33. Loss: 0.036633035430967, Train_acc 0.9940399484536082\n",
      "\n",
      "Epoch 33. Loss: 0.03876533029048966, Train_acc 0.9939102564102564\n",
      "\n",
      "Epoch 33. Loss: 0.0449969805857777, Train_acc 0.99384\n",
      "\n",
      "Epoch 34. Loss: 0.04093396846000011, Train_acc 1.0\n",
      "\n",
      "Epoch 34. Loss: 0.04255089998433281, Train_acc 0.98828125\n",
      "\n",
      "Epoch 34. Loss: 0.04939482665231189, Train_acc 0.9739583333333334\n",
      "\n",
      "Epoch 34. Loss: 0.050916581358048565, Train_acc 0.97265625\n",
      "\n",
      "Epoch 34. Loss: 0.04915176205831759, Train_acc 0.975\n",
      "\n",
      "Epoch 34. Loss: 0.05663233732877368, Train_acc 0.9713541666666666\n",
      "\n",
      "Epoch 34. Loss: 0.06397875907151276, Train_acc 0.96875\n",
      "\n",
      "Epoch 34. Loss: 0.06292400780732967, Train_acc 0.9716796875\n",
      "\n",
      "Epoch 34. Loss: 0.05954663066639486, Train_acc 0.9739583333333334\n",
      "\n",
      "Epoch 34. Loss: 0.05695345573342427, Train_acc 0.97578125\n",
      "\n",
      "Epoch 34. Loss: 0.05726587166830824, Train_acc 0.9758522727272727\n",
      "\n",
      "Epoch 34. Loss: 0.05254575568090313, Train_acc 0.9778645833333334\n",
      "\n",
      "Epoch 34. Loss: 0.05465554929659158, Train_acc 0.9777644230769231\n",
      "\n",
      "Epoch 34. Loss: 0.05186868745284131, Train_acc 0.9787946428571429\n",
      "\n",
      "Epoch 34. Loss: 0.048765880397232036, Train_acc 0.9796875\n",
      "\n",
      "Epoch 34. Loss: 0.04783529195005148, Train_acc 0.97998046875\n",
      "\n",
      "Epoch 34. Loss: 0.04877730074060961, Train_acc 0.9797794117647058\n",
      "\n",
      "Epoch 34. Loss: 0.04467604223668281, Train_acc 0.9809027777777778\n",
      "\n",
      "Epoch 34. Loss: 0.04352467281025384, Train_acc 0.9814967105263158\n",
      "\n",
      "Epoch 34. Loss: 0.04115124644251228, Train_acc 0.98203125\n",
      "\n",
      "Epoch 34. Loss: 0.038456873384817486, Train_acc 0.9825148809523809\n",
      "\n",
      "Epoch 34. Loss: 0.03891900110635523, Train_acc 0.9829545454545454\n",
      "\n",
      "Epoch 34. Loss: 0.036480399326026716, Train_acc 0.9833559782608695\n",
      "\n",
      "Epoch 34. Loss: 0.04326343448955442, Train_acc 0.982421875\n",
      "\n",
      "Epoch 34. Loss: 0.04368368159531319, Train_acc 0.9825\n",
      "\n",
      "Epoch 34. Loss: 0.04168190300433723, Train_acc 0.9825721153846154\n",
      "\n",
      "Epoch 34. Loss: 0.04435823252769311, Train_acc 0.9823495370370371\n",
      "\n",
      "Epoch 34. Loss: 0.042622010180103774, Train_acc 0.9827008928571429\n",
      "\n",
      "Epoch 34. Loss: 0.039778715984894034, Train_acc 0.9830280172413793\n",
      "\n",
      "Epoch 34. Loss: 0.036693179749137037, Train_acc 0.98359375\n",
      "\n",
      "Epoch 34. Loss: 0.03529480693580437, Train_acc 0.9838709677419355\n",
      "\n",
      "Epoch 34. Loss: 0.03367139300264473, Train_acc 0.984130859375\n",
      "\n",
      "Epoch 34. Loss: 0.031146196318187318, Train_acc 0.9846117424242424\n",
      "\n",
      "Epoch 34. Loss: 0.0292844052247864, Train_acc 0.9850643382352942\n",
      "\n",
      "Epoch 34. Loss: 0.028704014804899276, Train_acc 0.9850446428571429\n",
      "\n",
      "Epoch 34. Loss: 0.026595450464135032, Train_acc 0.9854600694444444\n",
      "\n",
      "Epoch 34. Loss: 0.026199049635153075, Train_acc 0.9854307432432432\n",
      "\n",
      "Epoch 34. Loss: 0.026153433702964538, Train_acc 0.985608552631579\n",
      "\n",
      "Epoch 34. Loss: 0.024218946087430974, Train_acc 0.9859775641025641\n",
      "\n",
      "Epoch 34. Loss: 0.02312811111337339, Train_acc 0.986328125\n",
      "\n",
      "Epoch 34. Loss: 0.022764012395677522, Train_acc 0.9866615853658537\n",
      "\n",
      "Epoch 34. Loss: 0.023525706838969193, Train_acc 0.9867931547619048\n",
      "\n",
      "Epoch 34. Loss: 0.02175391794643146, Train_acc 0.9871002906976745\n",
      "\n",
      "Epoch 34. Loss: 0.022045785730195125, Train_acc 0.9872159090909091\n",
      "\n",
      "Epoch 34. Loss: 0.019978972257401417, Train_acc 0.9875\n",
      "\n",
      "Epoch 34. Loss: 0.02124293847193647, Train_acc 0.9874320652173914\n",
      "\n",
      "Epoch 34. Loss: 0.02101130499670203, Train_acc 0.987533244680851\n",
      "\n",
      "Epoch 34. Loss: 0.020054229122215172, Train_acc 0.9876302083333334\n",
      "\n",
      "Epoch 34. Loss: 0.023971350212526613, Train_acc 0.9874043367346939\n",
      "\n",
      "Epoch 34. Loss: 0.022031634180664086, Train_acc 0.98765625\n",
      "\n",
      "Epoch 34. Loss: 0.021269818175362703, Train_acc 0.9877450980392157\n",
      "\n",
      "Epoch 34. Loss: 0.020128386958861787, Train_acc 0.9879807692307693\n",
      "\n",
      "Epoch 34. Loss: 0.01873208548375169, Train_acc 0.9882075471698113\n",
      "\n",
      "Epoch 34. Loss: 0.022565827957524653, Train_acc 0.98828125\n",
      "\n",
      "Epoch 34. Loss: 0.020490846311733542, Train_acc 0.9884943181818182\n",
      "\n",
      "Epoch 34. Loss: 0.0186812087191809, Train_acc 0.9886997767857143\n",
      "\n",
      "Epoch 34. Loss: 0.017535490600571225, Train_acc 0.9888980263157895\n",
      "\n",
      "Epoch 34. Loss: 0.017379430584584347, Train_acc 0.9889547413793104\n",
      "\n",
      "Epoch 34. Loss: 0.016111673783860806, Train_acc 0.9891419491525424\n",
      "\n",
      "Epoch 34. Loss: 0.01757652777874667, Train_acc 0.9891927083333333\n",
      "\n",
      "Epoch 34. Loss: 0.019256842971839296, Train_acc 0.9892418032786885\n",
      "\n",
      "Epoch 34. Loss: 0.020666994086800027, Train_acc 0.989289314516129\n",
      "\n",
      "Epoch 34. Loss: 0.02013890802359403, Train_acc 0.9893353174603174\n",
      "\n",
      "Epoch 34. Loss: 0.01853958736281831, Train_acc 0.989501953125\n",
      "\n",
      "Epoch 34. Loss: 0.016930279895704142, Train_acc 0.9896634615384615\n",
      "\n",
      "Epoch 34. Loss: 0.016033294847644406, Train_acc 0.9898200757575758\n",
      "\n",
      "Epoch 34. Loss: 0.014822074146005842, Train_acc 0.9899720149253731\n",
      "\n",
      "Epoch 34. Loss: 0.01353804698316008, Train_acc 0.9901194852941176\n",
      "\n",
      "Epoch 34. Loss: 0.015589067838142068, Train_acc 0.990036231884058\n",
      "\n",
      "Epoch 34. Loss: 0.014126058088371307, Train_acc 0.9901785714285715\n",
      "\n",
      "Epoch 34. Loss: 0.01327527131881936, Train_acc 0.9903169014084507\n",
      "\n",
      "Epoch 34. Loss: 0.012425391130119177, Train_acc 0.9904513888888888\n",
      "\n",
      "Epoch 34. Loss: 0.011837200329053056, Train_acc 0.990582191780822\n",
      "\n",
      "Epoch 34. Loss: 0.010873815966894613, Train_acc 0.9907094594594594\n",
      "\n",
      "Epoch 34. Loss: 0.010534264651239264, Train_acc 0.9908333333333333\n",
      "\n",
      "Epoch 34. Loss: 0.010756216651767802, Train_acc 0.990953947368421\n",
      "\n",
      "Epoch 34. Loss: 0.010752912348422686, Train_acc 0.9909699675324676\n",
      "\n",
      "Epoch 34. Loss: 0.01283502480618353, Train_acc 0.9908854166666666\n",
      "\n",
      "Epoch 34. Loss: 0.012353333785970765, Train_acc 0.9910007911392406\n",
      "\n",
      "Epoch 34. Loss: 0.01139439985775032, Train_acc 0.99111328125\n",
      "\n",
      "Epoch 34. Loss: 0.01051983702274184, Train_acc 0.9912229938271605\n",
      "\n",
      "Epoch 34. Loss: 0.00999051639221925, Train_acc 0.9913300304878049\n",
      "\n",
      "Epoch 34. Loss: 0.009720700200940536, Train_acc 0.9914344879518072\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34. Loss: 0.01259312529851082, Train_acc 0.9914434523809523\n",
      "\n",
      "Epoch 34. Loss: 0.011964663206688313, Train_acc 0.9915441176470589\n",
      "\n",
      "Epoch 34. Loss: 0.01107270760981895, Train_acc 0.9916424418604651\n",
      "\n",
      "Epoch 34. Loss: 0.010774138419914163, Train_acc 0.9916487068965517\n",
      "\n",
      "Epoch 34. Loss: 0.010791836339164898, Train_acc 0.9916548295454546\n",
      "\n",
      "Epoch 34. Loss: 0.009995539865095132, Train_acc 0.991748595505618\n",
      "\n",
      "Epoch 34. Loss: 0.01062344451057796, Train_acc 0.9916666666666667\n",
      "\n",
      "Epoch 34. Loss: 0.009645922224601441, Train_acc 0.9917582417582418\n",
      "\n",
      "Epoch 34. Loss: 0.009212476165262162, Train_acc 0.9918478260869565\n",
      "\n",
      "Epoch 34. Loss: 0.01493870510265288, Train_acc 0.9917674731182796\n",
      "\n",
      "Epoch 34. Loss: 0.014219142839879309, Train_acc 0.9918550531914894\n",
      "\n",
      "Epoch 34. Loss: 0.014830968465421064, Train_acc 0.991858552631579\n",
      "\n",
      "Epoch 34. Loss: 0.013902448554125544, Train_acc 0.991943359375\n",
      "\n",
      "Epoch 34. Loss: 0.012670713962722227, Train_acc 0.9920264175257731\n",
      "\n",
      "Epoch 34. Loss: 0.011606303667225006, Train_acc 0.9921077806122449\n",
      "\n",
      "Epoch 34. Loss: 0.010793133501512614, Train_acc 0.9921875\n",
      "\n",
      "Epoch 34. Loss: 0.01837502845314396, Train_acc 0.99203125\n",
      "\n",
      "[Epoch 34 Batch 100] Loss: 0.017050387161409133 Training: accuracy=0.992110\n",
      "Epoch 34. Loss: 0.017050387161409133, Train_acc 0.9921101485148515\n",
      "\n",
      "Epoch 34. Loss: 0.015606830925250299, Train_acc 0.9921875\n",
      "\n",
      "Epoch 34. Loss: 0.017159310909066423, Train_acc 0.9921116504854369\n",
      "\n",
      "Epoch 34. Loss: 0.018192111155647478, Train_acc 0.9921123798076923\n",
      "\n",
      "Epoch 34. Loss: 0.02049737233036021, Train_acc 0.9920386904761904\n",
      "\n",
      "Epoch 34. Loss: 0.02474516086083585, Train_acc 0.991966391509434\n",
      "\n",
      "Epoch 34. Loss: 0.02450444543929637, Train_acc 0.9919684579439252\n",
      "\n",
      "Epoch 34. Loss: 0.02942678923522002, Train_acc 0.9918258101851852\n",
      "\n",
      "Epoch 34. Loss: 0.02920790269328266, Train_acc 0.9917574541284404\n",
      "\n",
      "Epoch 34. Loss: 0.027515176163790612, Train_acc 0.9918323863636364\n",
      "\n",
      "Epoch 34. Loss: 0.027993940466652503, Train_acc 0.9917652027027027\n",
      "\n",
      "Epoch 34. Loss: 0.026233337100455337, Train_acc 0.9917689732142857\n",
      "\n",
      "Epoch 34. Loss: 0.027617798098423338, Train_acc 0.9917035398230089\n",
      "\n",
      "Epoch 34. Loss: 0.030638877688495745, Train_acc 0.9915707236842105\n",
      "\n",
      "Epoch 34. Loss: 0.027985315651728297, Train_acc 0.9916440217391305\n",
      "\n",
      "Epoch 34. Loss: 0.027428199803263175, Train_acc 0.9916487068965517\n",
      "\n",
      "Epoch 34. Loss: 0.02875162880608162, Train_acc 0.9915865384615384\n",
      "\n",
      "Epoch 34. Loss: 0.027517740541595705, Train_acc 0.9915916313559322\n",
      "\n",
      "Epoch 34. Loss: 0.025090098385086794, Train_acc 0.9916622899159664\n",
      "\n",
      "Epoch 34. Loss: 0.02541111559039754, Train_acc 0.9916666666666667\n",
      "\n",
      "Epoch 34. Loss: 0.023303371242729447, Train_acc 0.9917355371900827\n",
      "\n",
      "Epoch 34. Loss: 0.021045669095279385, Train_acc 0.9918032786885246\n",
      "\n",
      "Epoch 34. Loss: 0.01908885243767793, Train_acc 0.991869918699187\n",
      "\n",
      "Epoch 34. Loss: 0.02423186647803451, Train_acc 0.9918724798387096\n",
      "\n",
      "Epoch 34. Loss: 0.022773697283067097, Train_acc 0.9919375\n",
      "\n",
      "Epoch 34. Loss: 0.020979262221557906, Train_acc 0.9920014880952381\n",
      "\n",
      "Epoch 34. Loss: 0.019401851953524063, Train_acc 0.992064468503937\n",
      "\n",
      "Epoch 34. Loss: 0.01966445456724558, Train_acc 0.9920654296875\n",
      "\n",
      "Epoch 34. Loss: 0.01848865298880214, Train_acc 0.9921269379844961\n",
      "\n",
      "Epoch 34. Loss: 0.01822571864831216, Train_acc 0.9921875\n",
      "\n",
      "Epoch 34. Loss: 0.017050671714017692, Train_acc 0.9922471374045801\n",
      "\n",
      "Epoch 34. Loss: 0.017333794582608256, Train_acc 0.9922466856060606\n",
      "\n",
      "Epoch 34. Loss: 0.015966265477029604, Train_acc 0.9923049812030075\n",
      "\n",
      "Epoch 34. Loss: 0.015425666621137967, Train_acc 0.992304104477612\n",
      "\n",
      "Epoch 34. Loss: 0.014245286605113127, Train_acc 0.9923611111111111\n",
      "\n",
      "Epoch 34. Loss: 0.015808282811659614, Train_acc 0.9923598345588235\n",
      "\n",
      "Epoch 34. Loss: 0.014781472998158372, Train_acc 0.992415602189781\n",
      "\n",
      "Epoch 34. Loss: 0.013918950688656782, Train_acc 0.9924705615942029\n",
      "\n",
      "Epoch 34. Loss: 0.01282165055213864, Train_acc 0.9925247302158273\n",
      "\n",
      "Epoch 34. Loss: 0.012515062005715033, Train_acc 0.992578125\n",
      "\n",
      "Epoch 34. Loss: 0.011706547024604493, Train_acc 0.9926307624113475\n",
      "\n",
      "Epoch 34. Loss: 0.010786835839456452, Train_acc 0.9926826584507042\n",
      "\n",
      "Epoch 34. Loss: 0.01038815659517598, Train_acc 0.9927338286713286\n",
      "\n",
      "Epoch 34. Loss: 0.01632598563046353, Train_acc 0.99267578125\n",
      "\n",
      "Epoch 34. Loss: 0.015556770405272516, Train_acc 0.9927262931034483\n",
      "\n",
      "Epoch 34. Loss: 0.014812044545501356, Train_acc 0.9927761130136986\n",
      "\n",
      "Epoch 34. Loss: 0.0161410856570213, Train_acc 0.9927721088435374\n",
      "\n",
      "Epoch 34. Loss: 0.01566695364121279, Train_acc 0.9927681587837838\n",
      "\n",
      "Epoch 34. Loss: 0.017675842196974285, Train_acc 0.9927642617449665\n",
      "\n",
      "Epoch 34. Loss: 0.018195214064031653, Train_acc 0.9927083333333333\n",
      "\n",
      "Epoch 34. Loss: 0.01653238996254785, Train_acc 0.9927566225165563\n",
      "\n",
      "Epoch 34. Loss: 0.015011515443323997, Train_acc 0.9928042763157895\n",
      "\n",
      "Epoch 34. Loss: 0.014275141689746631, Train_acc 0.9928002450980392\n",
      "\n",
      "Epoch 34. Loss: 0.016958256632300363, Train_acc 0.9926440746753247\n",
      "\n",
      "Epoch 34. Loss: 0.015582668890621196, Train_acc 0.9926915322580645\n",
      "\n",
      "Epoch 34. Loss: 0.014418164254783926, Train_acc 0.9927383814102564\n",
      "\n",
      "Epoch 34. Loss: 0.013942652276807431, Train_acc 0.9927846337579618\n",
      "\n",
      "Epoch 34. Loss: 0.013975543247896497, Train_acc 0.9927808544303798\n",
      "\n",
      "Epoch 34. Loss: 0.013472336873923003, Train_acc 0.9927771226415094\n",
      "\n",
      "Epoch 34. Loss: 0.012536399915529125, Train_acc 0.992822265625\n",
      "\n",
      "Epoch 34. Loss: 0.011421786605403125, Train_acc 0.9928668478260869\n",
      "\n",
      "Epoch 34. Loss: 0.010496118394398957, Train_acc 0.9929108796296297\n",
      "\n",
      "Epoch 34. Loss: 0.010138749032048228, Train_acc 0.9929064417177914\n",
      "\n",
      "Epoch 34. Loss: 0.009241899816202678, Train_acc 0.9929496951219512\n",
      "\n",
      "Epoch 34. Loss: 0.010306622953421673, Train_acc 0.9929450757575757\n",
      "\n",
      "Epoch 34. Loss: 0.010734374836421133, Train_acc 0.9929405120481928\n",
      "\n",
      "Epoch 34. Loss: 0.013058108924629799, Train_acc 0.9928892215568862\n",
      "\n",
      "Epoch 34. Loss: 0.011901481962064664, Train_acc 0.9929315476190477\n",
      "\n",
      "Epoch 34. Loss: 0.012192778154486205, Train_acc 0.9929271449704142\n",
      "\n",
      "Epoch 34. Loss: 0.012102285464948822, Train_acc 0.9929227941176471\n",
      "\n",
      "Epoch 34. Loss: 0.011144671950240203, Train_acc 0.9929641812865497\n",
      "\n",
      "Epoch 34. Loss: 0.010726889966949166, Train_acc 0.9930050872093024\n",
      "\n",
      "Epoch 34. Loss: 0.010410988385848113, Train_acc 0.9930455202312138\n",
      "\n",
      "Epoch 34. Loss: 0.009445646526903875, Train_acc 0.9930854885057471\n",
      "\n",
      "Epoch 34. Loss: 0.009097013303629428, Train_acc 0.993125\n",
      "\n",
      "Epoch 34. Loss: 0.00908915651201475, Train_acc 0.9931640625\n",
      "\n",
      "Epoch 34. Loss: 0.008346565968961432, Train_acc 0.9932026836158192\n",
      "\n",
      "Epoch 34. Loss: 0.007670857334401531, Train_acc 0.9932408707865169\n",
      "\n",
      "Epoch 34. Loss: 0.007416019692361048, Train_acc 0.9932786312849162\n",
      "\n",
      "Epoch 34. Loss: 0.009577618595367394, Train_acc 0.9932291666666667\n",
      "\n",
      "Epoch 34. Loss: 0.009396813152497163, Train_acc 0.9932665745856354\n",
      "\n",
      "Epoch 34. Loss: 0.008851603572009639, Train_acc 0.9933035714285714\n",
      "\n",
      "Epoch 34. Loss: 0.00906331033283946, Train_acc 0.9932974726775956\n",
      "\n",
      "Epoch 34. Loss: 0.008325141208651457, Train_acc 0.9933338994565217\n",
      "\n",
      "Epoch 34. Loss: 0.00817190853486907, Train_acc 0.9933277027027027\n",
      "\n",
      "Epoch 34. Loss: 0.007653943475533588, Train_acc 0.9933635752688172\n",
      "\n",
      "Epoch 34. Loss: 0.007353927945151088, Train_acc 0.993399064171123\n",
      "\n",
      "Epoch 34. Loss: 0.007768732220727942, Train_acc 0.993392619680851\n",
      "\n",
      "Epoch 34. Loss: 0.007118248412727185, Train_acc 0.9934275793650794\n",
      "\n",
      "Epoch 34. Loss: 0.006514681334076555, Train_acc 0.9934621710526316\n",
      "\n",
      "Epoch 34. Loss: 0.005958852229255347, Train_acc 0.9934964005235603\n",
      "\n",
      "Epoch 34. Loss: 0.006251533585999527, Train_acc 0.9934895833333334\n",
      "\n",
      "Epoch 34. Loss: 0.008632919721198784, Train_acc 0.9934423575129534\n",
      "\n",
      "Epoch 34. Loss: 0.007995570051574146, Train_acc 0.9934761597938144\n",
      "\n",
      "Epoch 34. Loss: 0.007724646594363543, Train_acc 0.9935096153846154\n",
      "\n",
      "Epoch 34. Loss: 0.007266076571856224, Train_acc 0.99352\n",
      "\n",
      "Epoch 35. Loss: 0.006606048501962527, Train_acc 1.0\n",
      "\n",
      "Epoch 35. Loss: 0.006312626727052723, Train_acc 1.0\n",
      "\n",
      "Epoch 35. Loss: 0.00803898126121896, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 35. Loss: 0.007897613162426986, Train_acc 0.998046875\n",
      "\n",
      "Epoch 35. Loss: 0.007529785396571909, Train_acc 0.9984375\n",
      "\n",
      "Epoch 35. Loss: 0.006904589506275315, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 35. Loss: 0.0065487840002359686, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 35. Loss: 0.006763018434546745, Train_acc 0.998046875\n",
      "\n",
      "Epoch 35. Loss: 0.006911470903726539, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 35. Loss: 0.00920115507880341, Train_acc 0.996875\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35. Loss: 0.008958157835061768, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 35. Loss: 0.008091780017269033, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 35. Loss: 0.007497788846152167, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 35. Loss: 0.007746530347010916, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 35. Loss: 0.007958215160317503, Train_acc 0.996875\n",
      "\n",
      "Epoch 35. Loss: 0.007330721212384656, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 35. Loss: 0.0075713462841131285, Train_acc 0.9972426470588235\n",
      "\n",
      "Epoch 35. Loss: 0.009076045129741847, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 35. Loss: 0.008424513393159765, Train_acc 0.9967105263157895\n",
      "\n",
      "Epoch 35. Loss: 0.007622448176262356, Train_acc 0.996875\n",
      "\n",
      "Epoch 35. Loss: 0.00697469041199691, Train_acc 0.9970238095238095\n",
      "\n",
      "Epoch 35. Loss: 0.006444795522216322, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 35. Loss: 0.007446748623064187, Train_acc 0.9969429347826086\n",
      "\n",
      "Epoch 35. Loss: 0.008709876709113443, Train_acc 0.9967447916666666\n",
      "\n",
      "Epoch 35. Loss: 0.007967434720148079, Train_acc 0.996875\n",
      "\n",
      "Epoch 35. Loss: 0.008599210716887802, Train_acc 0.9966947115384616\n",
      "\n",
      "Epoch 35. Loss: 0.008995991554204663, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 35. Loss: 0.008750287575731314, Train_acc 0.9963727678571429\n",
      "\n",
      "Epoch 35. Loss: 0.00895417162019876, Train_acc 0.9964978448275862\n",
      "\n",
      "Epoch 35. Loss: 0.00830737791125954, Train_acc 0.9966145833333333\n",
      "\n",
      "Epoch 35. Loss: 0.008186622383057899, Train_acc 0.9964717741935484\n",
      "\n",
      "Epoch 35. Loss: 0.008992243898087586, Train_acc 0.996337890625\n",
      "\n",
      "Epoch 35. Loss: 0.008200702470249394, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 35. Loss: 0.009941604273056799, Train_acc 0.99609375\n",
      "\n",
      "Epoch 35. Loss: 0.00946120645392163, Train_acc 0.9962053571428572\n",
      "\n",
      "Epoch 35. Loss: 0.008774536631598084, Train_acc 0.9963107638888888\n",
      "\n",
      "Epoch 35. Loss: 0.00954851086326898, Train_acc 0.9961993243243243\n",
      "\n",
      "Epoch 35. Loss: 0.010986370149747678, Train_acc 0.99609375\n",
      "\n",
      "Epoch 35. Loss: 0.01019888090561731, Train_acc 0.9961939102564102\n",
      "\n",
      "Epoch 35. Loss: 0.009676312038414807, Train_acc 0.9962890625\n",
      "\n",
      "Epoch 35. Loss: 0.009351245820474445, Train_acc 0.9963795731707317\n",
      "\n",
      "Epoch 35. Loss: 0.009000642755584555, Train_acc 0.9964657738095238\n",
      "\n",
      "Epoch 35. Loss: 0.012406696670314642, Train_acc 0.9960029069767442\n",
      "\n",
      "Epoch 35. Loss: 0.011468651472906148, Train_acc 0.99609375\n",
      "\n",
      "Epoch 35. Loss: 0.011923779804450163, Train_acc 0.9960069444444445\n",
      "\n",
      "Epoch 35. Loss: 0.012054993741758366, Train_acc 0.9959239130434783\n",
      "\n",
      "Epoch 35. Loss: 0.01537561628196928, Train_acc 0.9956781914893617\n",
      "\n",
      "Epoch 35. Loss: 0.014626740333208082, Train_acc 0.9957682291666666\n",
      "\n",
      "Epoch 35. Loss: 0.01364486395390508, Train_acc 0.9958545918367347\n",
      "\n",
      "Epoch 35. Loss: 0.01234222538684318, Train_acc 0.9959375\n",
      "\n",
      "Epoch 35. Loss: 0.011444997125472214, Train_acc 0.9960171568627451\n",
      "\n",
      "Epoch 35. Loss: 0.012765681073312987, Train_acc 0.9959435096153846\n",
      "\n",
      "Epoch 35. Loss: 0.011815361480447676, Train_acc 0.9960200471698113\n",
      "\n",
      "Epoch 35. Loss: 0.01333541684645387, Train_acc 0.9959490740740741\n",
      "\n",
      "Epoch 35. Loss: 0.012302321756873779, Train_acc 0.9960227272727272\n",
      "\n",
      "Epoch 35. Loss: 0.0112497903289222, Train_acc 0.99609375\n",
      "\n",
      "Epoch 35. Loss: 0.013671314482255871, Train_acc 0.9958881578947368\n",
      "\n",
      "Epoch 35. Loss: 0.01248325967117169, Train_acc 0.9959590517241379\n",
      "\n",
      "Epoch 35. Loss: 0.01185747357822077, Train_acc 0.9960275423728814\n",
      "\n",
      "Epoch 35. Loss: 0.010776574166602939, Train_acc 0.99609375\n",
      "\n",
      "Epoch 35. Loss: 0.010404121374625309, Train_acc 0.9960297131147541\n",
      "\n",
      "Epoch 35. Loss: 0.010363687235598275, Train_acc 0.9959677419354839\n",
      "\n",
      "Epoch 35. Loss: 0.011136790357665278, Train_acc 0.9959077380952381\n",
      "\n",
      "Epoch 35. Loss: 0.01298441089031344, Train_acc 0.9957275390625\n",
      "\n",
      "Epoch 35. Loss: 0.014149985583161521, Train_acc 0.9956730769230769\n",
      "\n",
      "Epoch 35. Loss: 0.012860123553940839, Train_acc 0.9957386363636364\n",
      "\n",
      "Epoch 35. Loss: 0.014393816580536234, Train_acc 0.9955690298507462\n",
      "\n",
      "Epoch 35. Loss: 0.013765642682608008, Train_acc 0.9956341911764706\n",
      "\n",
      "Epoch 35. Loss: 0.013115461500641143, Train_acc 0.995697463768116\n",
      "\n",
      "Epoch 35. Loss: 0.012637851386210116, Train_acc 0.9957589285714286\n",
      "\n",
      "Epoch 35. Loss: 0.012329639251328222, Train_acc 0.9957086267605634\n",
      "\n",
      "Epoch 35. Loss: 0.011482337727290433, Train_acc 0.9957682291666666\n",
      "\n",
      "Epoch 35. Loss: 0.011153805376567282, Train_acc 0.995826198630137\n",
      "\n",
      "Epoch 35. Loss: 0.011906125765870069, Train_acc 0.995777027027027\n",
      "\n",
      "Epoch 35. Loss: 0.012622536231723477, Train_acc 0.9957291666666667\n",
      "\n",
      "Epoch 35. Loss: 0.013386912429017173, Train_acc 0.9956825657894737\n",
      "\n",
      "Epoch 35. Loss: 0.014887639314248276, Train_acc 0.9956371753246753\n",
      "\n",
      "Epoch 35. Loss: 0.013609827885498804, Train_acc 0.9956931089743589\n",
      "\n",
      "Epoch 35. Loss: 0.014953420382264437, Train_acc 0.9956487341772152\n",
      "\n",
      "Epoch 35. Loss: 0.014240406163653596, Train_acc 0.995703125\n",
      "\n",
      "Epoch 35. Loss: 0.017769602797735512, Train_acc 0.9955632716049383\n",
      "\n",
      "Epoch 35. Loss: 0.016767459081314905, Train_acc 0.9956173780487805\n",
      "\n",
      "Epoch 35. Loss: 0.01649270810935161, Train_acc 0.9956701807228916\n",
      "\n",
      "Epoch 35. Loss: 0.015376440006523683, Train_acc 0.9957217261904762\n",
      "\n",
      "Epoch 35. Loss: 0.015624563829329032, Train_acc 0.9955882352941177\n",
      "\n",
      "Epoch 35. Loss: 0.01511705219631769, Train_acc 0.9955486918604651\n",
      "\n",
      "Epoch 35. Loss: 0.014478609784412783, Train_acc 0.9955998563218391\n",
      "\n",
      "Epoch 35. Loss: 0.014887059471578958, Train_acc 0.9955610795454546\n",
      "\n",
      "Epoch 35. Loss: 0.014632207296703663, Train_acc 0.9955231741573034\n",
      "\n",
      "Epoch 35. Loss: 0.0151917640648017, Train_acc 0.9953993055555556\n",
      "\n",
      "Epoch 35. Loss: 0.015301014120733411, Train_acc 0.995364010989011\n",
      "\n",
      "Epoch 35. Loss: 0.014045305601266626, Train_acc 0.9954144021739131\n",
      "\n",
      "Epoch 35. Loss: 0.01324678063341165, Train_acc 0.9954637096774194\n",
      "\n",
      "Epoch 35. Loss: 0.017062568813099126, Train_acc 0.995345744680851\n",
      "\n",
      "Epoch 35. Loss: 0.015460043501623269, Train_acc 0.9953947368421052\n",
      "\n",
      "Epoch 35. Loss: 0.01407539722528037, Train_acc 0.9954427083333334\n",
      "\n",
      "Epoch 35. Loss: 0.018685891498976738, Train_acc 0.9954091494845361\n",
      "\n",
      "Epoch 35. Loss: 0.01757596069859307, Train_acc 0.9954559948979592\n",
      "\n",
      "Epoch 35. Loss: 0.0158575983325985, Train_acc 0.9955018939393939\n",
      "\n",
      "Epoch 35. Loss: 0.014326904570556532, Train_acc 0.995546875\n",
      "\n",
      "[Epoch 35 Batch 100] Loss: 0.013593199552294778 Training: accuracy=0.995591\n",
      "Epoch 35. Loss: 0.013593199552294778, Train_acc 0.9955909653465347\n",
      "\n",
      "Epoch 35. Loss: 0.014475330331501812, Train_acc 0.9955575980392157\n",
      "\n",
      "Epoch 35. Loss: 0.013462448850119815, Train_acc 0.9956007281553398\n",
      "\n",
      "Epoch 35. Loss: 0.012638103585178886, Train_acc 0.9956430288461539\n",
      "\n",
      "Epoch 35. Loss: 0.01160619119732252, Train_acc 0.9956845238095238\n",
      "\n",
      "Epoch 35. Loss: 0.014529650300103468, Train_acc 0.9955041273584906\n",
      "\n",
      "Epoch 35. Loss: 0.013182353082842864, Train_acc 0.9955461448598131\n",
      "\n",
      "Epoch 35. Loss: 0.012074727503960344, Train_acc 0.9955873842592593\n",
      "\n",
      "Epoch 35. Loss: 0.01095757743782812, Train_acc 0.9956278669724771\n",
      "\n",
      "Epoch 35. Loss: 0.010674947189393762, Train_acc 0.9955965909090909\n",
      "\n",
      "Epoch 35. Loss: 0.010614445004257372, Train_acc 0.9955658783783784\n",
      "\n",
      "Epoch 35. Loss: 0.011154708997958432, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 35. Loss: 0.010315865955400644, Train_acc 0.995575221238938\n",
      "\n",
      "Epoch 35. Loss: 0.01125492831168906, Train_acc 0.9955455043859649\n",
      "\n",
      "Epoch 35. Loss: 0.012449521691486266, Train_acc 0.9955163043478261\n",
      "\n",
      "Epoch 35. Loss: 0.011723216731147491, Train_acc 0.9955549568965517\n",
      "\n",
      "Epoch 35. Loss: 0.012288987361308805, Train_acc 0.9955261752136753\n",
      "\n",
      "Epoch 35. Loss: 0.013191538615152423, Train_acc 0.9954978813559322\n",
      "\n",
      "Epoch 35. Loss: 0.013941077758185729, Train_acc 0.9954700630252101\n",
      "\n",
      "Epoch 35. Loss: 0.01629735756156981, Train_acc 0.9954427083333334\n",
      "\n",
      "Epoch 35. Loss: 0.017221366792066158, Train_acc 0.9953512396694215\n",
      "\n",
      "Epoch 35. Loss: 0.016014210751259264, Train_acc 0.9953893442622951\n",
      "\n",
      "Epoch 35. Loss: 0.02063510033840293, Train_acc 0.9953633130081301\n",
      "\n",
      "Epoch 35. Loss: 0.01863168501127679, Train_acc 0.9954007056451613\n",
      "\n",
      "Epoch 35. Loss: 0.01734602451639401, Train_acc 0.9954375\n",
      "\n",
      "Epoch 35. Loss: 0.016372214912477378, Train_acc 0.9954737103174603\n",
      "\n",
      "Epoch 35. Loss: 0.017696104303690712, Train_acc 0.9953863188976378\n",
      "\n",
      "Epoch 35. Loss: 0.01676929703118764, Train_acc 0.995361328125\n",
      "\n",
      "Epoch 35. Loss: 0.015208951906132218, Train_acc 0.9953972868217055\n",
      "\n",
      "Epoch 35. Loss: 0.014302571150229142, Train_acc 0.9954326923076923\n",
      "\n",
      "Epoch 35. Loss: 0.013246217883437066, Train_acc 0.9954675572519084\n",
      "\n",
      "Epoch 35. Loss: 0.013812880903609862, Train_acc 0.9954427083333334\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35. Loss: 0.01282317595791364, Train_acc 0.9954769736842105\n",
      "\n",
      "Epoch 35. Loss: 0.020956569079561928, Train_acc 0.9953941231343284\n",
      "\n",
      "Epoch 35. Loss: 0.01908460360713652, Train_acc 0.9954282407407408\n",
      "\n",
      "Epoch 35. Loss: 0.018050846903304916, Train_acc 0.9954618566176471\n",
      "\n",
      "Epoch 35. Loss: 0.01710680150504171, Train_acc 0.9954949817518248\n",
      "\n",
      "Epoch 35. Loss: 0.018019344867902333, Train_acc 0.9954144021739131\n",
      "\n",
      "Epoch 35. Loss: 0.016308698742112, Train_acc 0.9954473920863309\n",
      "\n",
      "Epoch 35. Loss: 0.017597269398141338, Train_acc 0.9954241071428571\n",
      "\n",
      "Epoch 35. Loss: 0.01728388697549859, Train_acc 0.9954011524822695\n",
      "\n",
      "Epoch 35. Loss: 0.021146190440462464, Train_acc 0.9953235035211268\n",
      "\n",
      "Epoch 35. Loss: 0.019964073863601474, Train_acc 0.9953562062937062\n",
      "\n",
      "Epoch 35. Loss: 0.02273867183951359, Train_acc 0.9953342013888888\n",
      "\n",
      "Epoch 35. Loss: 0.02251602474475939, Train_acc 0.9953125\n",
      "\n",
      "Epoch 35. Loss: 0.02207143859081005, Train_acc 0.995291095890411\n",
      "\n",
      "Epoch 35. Loss: 0.020743489971123946, Train_acc 0.9953231292517006\n",
      "\n",
      "Epoch 35. Loss: 0.020190756192382704, Train_acc 0.9952491554054054\n",
      "\n",
      "Epoch 35. Loss: 0.0220629247312932, Train_acc 0.9952286073825504\n",
      "\n",
      "Epoch 35. Loss: 0.021234236973689986, Train_acc 0.9952083333333334\n",
      "\n",
      "Epoch 35. Loss: 0.02060538894072204, Train_acc 0.9952400662251656\n",
      "\n",
      "Epoch 35. Loss: 0.020445231641546154, Train_acc 0.9952199835526315\n",
      "\n",
      "Epoch 35. Loss: 0.018499055629043516, Train_acc 0.9952512254901961\n",
      "\n",
      "Epoch 35. Loss: 0.019827308841111127, Train_acc 0.9951806006493507\n",
      "\n",
      "Epoch 35. Loss: 0.02293954722961354, Train_acc 0.9951612903225806\n",
      "\n",
      "Epoch 35. Loss: 0.02659130036426098, Train_acc 0.9950420673076923\n",
      "\n",
      "Epoch 35. Loss: 0.02879092080526809, Train_acc 0.9949741242038217\n",
      "\n",
      "Epoch 35. Loss: 0.026573363261371198, Train_acc 0.9950059335443038\n",
      "\n",
      "Epoch 35. Loss: 0.024300760621457702, Train_acc 0.9950373427672956\n",
      "\n",
      "Epoch 35. Loss: 0.02497421217229611, Train_acc 0.99501953125\n",
      "\n",
      "Epoch 35. Loss: 0.023886656405180513, Train_acc 0.9950019409937888\n",
      "\n",
      "Epoch 35. Loss: 0.026904689721748073, Train_acc 0.9949845679012346\n",
      "\n",
      "Epoch 35. Loss: 0.024501712251813565, Train_acc 0.9950153374233128\n",
      "\n",
      "Epoch 35. Loss: 0.022257951958055515, Train_acc 0.995045731707317\n",
      "\n",
      "Epoch 35. Loss: 0.0267022987274008, Train_acc 0.9949337121212121\n",
      "\n",
      "Epoch 35. Loss: 0.025116280695886346, Train_acc 0.9949642319277109\n",
      "\n",
      "Epoch 35. Loss: 0.025774127004525898, Train_acc 0.9949476047904192\n",
      "\n",
      "Epoch 35. Loss: 0.02696732909200952, Train_acc 0.9948846726190477\n",
      "\n",
      "Epoch 35. Loss: 0.024940198208108832, Train_acc 0.9949149408284024\n",
      "\n",
      "Epoch 35. Loss: 0.023570683527185284, Train_acc 0.9948988970588235\n",
      "\n",
      "Epoch 35. Loss: 0.02227812339651027, Train_acc 0.9948830409356725\n",
      "\n",
      "Epoch 35. Loss: 0.021218591896779288, Train_acc 0.9948673691860465\n",
      "\n",
      "Epoch 35. Loss: 0.025566515894013896, Train_acc 0.9948067196531792\n",
      "\n",
      "Epoch 35. Loss: 0.02479940398449742, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 35. Loss: 0.024225367737546948, Train_acc 0.9947767857142857\n",
      "\n",
      "Epoch 35. Loss: 0.023460927128257203, Train_acc 0.9947620738636364\n",
      "\n",
      "Epoch 35. Loss: 0.02282866762828396, Train_acc 0.9947475282485876\n",
      "\n",
      "Epoch 35. Loss: 0.02120152725541502, Train_acc 0.9947770365168539\n",
      "\n",
      "Epoch 35. Loss: 0.020299872003620056, Train_acc 0.9948062150837989\n",
      "\n",
      "Epoch 35. Loss: 0.019738247648738494, Train_acc 0.9948350694444444\n",
      "\n",
      "Epoch 35. Loss: 0.018996441857542998, Train_acc 0.9948204419889503\n",
      "\n",
      "Epoch 35. Loss: 0.01899464793192721, Train_acc 0.9948059752747253\n",
      "\n",
      "Epoch 35. Loss: 0.017962588113731533, Train_acc 0.9948343579234973\n",
      "\n",
      "Epoch 35. Loss: 0.01848229105817055, Train_acc 0.9948199728260869\n",
      "\n",
      "Epoch 35. Loss: 0.016980953860328576, Train_acc 0.994847972972973\n",
      "\n",
      "Epoch 35. Loss: 0.015980816291760784, Train_acc 0.9948756720430108\n",
      "\n",
      "Epoch 35. Loss: 0.01559188622116272, Train_acc 0.9948612967914439\n",
      "\n",
      "Epoch 35. Loss: 0.0166829071153333, Train_acc 0.9948470744680851\n",
      "\n",
      "Epoch 35. Loss: 0.015140552938987034, Train_acc 0.9948743386243386\n",
      "\n",
      "Epoch 35. Loss: 0.014197724858456152, Train_acc 0.9949013157894737\n",
      "\n",
      "Epoch 35. Loss: 0.01376022713962194, Train_acc 0.994887107329843\n",
      "\n",
      "Epoch 35. Loss: 0.013066023726758332, Train_acc 0.9949137369791666\n",
      "\n",
      "Epoch 35. Loss: 0.012474051708278332, Train_acc 0.9949400906735751\n",
      "\n",
      "Epoch 35. Loss: 0.011723760124785251, Train_acc 0.9949661726804123\n",
      "\n",
      "Epoch 35. Loss: 0.011244378772073281, Train_acc 0.9949919871794872\n",
      "\n",
      "Epoch 35. Loss: 0.01699754427673813, Train_acc 0.99496\n",
      "\n",
      "Epoch 36. Loss: 0.022297532833836044, Train_acc 0.96875\n",
      "\n",
      "Epoch 36. Loss: 0.022511744329829424, Train_acc 0.9765625\n",
      "\n",
      "Epoch 36. Loss: 0.021939200047701068, Train_acc 0.9817708333333334\n",
      "\n",
      "Epoch 36. Loss: 0.0208793929858948, Train_acc 0.984375\n",
      "\n",
      "Epoch 36. Loss: 0.020237559972162117, Train_acc 0.9859375\n",
      "\n",
      "Epoch 36. Loss: 0.01871670000444806, Train_acc 0.98828125\n",
      "\n",
      "Epoch 36. Loss: 0.02062950696966907, Train_acc 0.9877232142857143\n",
      "\n",
      "Epoch 36. Loss: 0.03311430215616698, Train_acc 0.9853515625\n",
      "\n",
      "Epoch 36. Loss: 0.03298585459392972, Train_acc 0.9861111111111112\n",
      "\n",
      "Epoch 36. Loss: 0.03368632505656815, Train_acc 0.9859375\n",
      "\n",
      "Epoch 36. Loss: 0.03480694377709809, Train_acc 0.9850852272727273\n",
      "\n",
      "Epoch 36. Loss: 0.033873108745718444, Train_acc 0.9856770833333334\n",
      "\n",
      "Epoch 36. Loss: 0.03122500899458329, Train_acc 0.9867788461538461\n",
      "\n",
      "Epoch 36. Loss: 0.033244829905251266, Train_acc 0.9860491071428571\n",
      "\n",
      "Epoch 36. Loss: 0.03336078810592258, Train_acc 0.9854166666666667\n",
      "\n",
      "Epoch 36. Loss: 0.03493404697984246, Train_acc 0.98486328125\n",
      "\n",
      "Epoch 36. Loss: 0.03185632907920886, Train_acc 0.9857536764705882\n",
      "\n",
      "Epoch 36. Loss: 0.029267381413195806, Train_acc 0.9865451388888888\n",
      "\n",
      "Epoch 36. Loss: 0.029241076067162405, Train_acc 0.9868421052631579\n",
      "\n",
      "Epoch 36. Loss: 0.028521551114385892, Train_acc 0.98671875\n",
      "\n",
      "Epoch 36. Loss: 0.029658212219535324, Train_acc 0.9866071428571429\n",
      "\n",
      "Epoch 36. Loss: 0.03410741891401322, Train_acc 0.9865056818181818\n",
      "\n",
      "Epoch 36. Loss: 0.031141055353915495, Train_acc 0.9870923913043478\n",
      "\n",
      "Epoch 36. Loss: 0.02863704484822077, Train_acc 0.9876302083333334\n",
      "\n",
      "Epoch 36. Loss: 0.027315555785194536, Train_acc 0.9878125\n",
      "\n",
      "Epoch 36. Loss: 0.027681732013012914, Train_acc 0.9876802884615384\n",
      "\n",
      "Epoch 36. Loss: 0.027715543919073896, Train_acc 0.9878472222222222\n",
      "\n",
      "Epoch 36. Loss: 0.03087631092661681, Train_acc 0.9877232142857143\n",
      "\n",
      "Epoch 36. Loss: 0.03201683477634843, Train_acc 0.9878771551724138\n",
      "\n",
      "Epoch 36. Loss: 0.03110909938282957, Train_acc 0.9880208333333333\n",
      "\n",
      "Epoch 36. Loss: 0.02899675015628806, Train_acc 0.9884072580645161\n",
      "\n",
      "Epoch 36. Loss: 0.027004511526410025, Train_acc 0.98876953125\n",
      "\n",
      "Epoch 36. Loss: 0.025229300108120658, Train_acc 0.9891098484848485\n",
      "\n",
      "Epoch 36. Loss: 0.025395076949804262, Train_acc 0.9889705882352942\n",
      "\n",
      "Epoch 36. Loss: 0.026526261326142463, Train_acc 0.9888392857142857\n",
      "\n",
      "Epoch 36. Loss: 0.026869276164294763, Train_acc 0.9889322916666666\n",
      "\n",
      "Epoch 36. Loss: 0.02476321266814007, Train_acc 0.989231418918919\n",
      "\n",
      "Epoch 36. Loss: 0.02267950365743578, Train_acc 0.989514802631579\n",
      "\n",
      "Epoch 36. Loss: 0.020695647771558526, Train_acc 0.9897836538461539\n",
      "\n",
      "Epoch 36. Loss: 0.01964923723450425, Train_acc 0.9900390625\n",
      "\n",
      "Epoch 36. Loss: 0.018409821433524393, Train_acc 0.9902820121951219\n",
      "\n",
      "Epoch 36. Loss: 0.01987821806314597, Train_acc 0.9903273809523809\n",
      "\n",
      "Epoch 36. Loss: 0.020897775803592887, Train_acc 0.9900072674418605\n",
      "\n",
      "Epoch 36. Loss: 0.02049101099185981, Train_acc 0.9898792613636364\n",
      "\n",
      "Epoch 36. Loss: 0.021110678432698586, Train_acc 0.9899305555555555\n",
      "\n",
      "Epoch 36. Loss: 0.02039077955259282, Train_acc 0.9899796195652174\n",
      "\n",
      "Epoch 36. Loss: 0.020375702107906925, Train_acc 0.9900265957446809\n",
      "\n",
      "Epoch 36. Loss: 0.019884319223428298, Train_acc 0.9900716145833334\n",
      "\n",
      "Epoch 36. Loss: 0.01842836036604452, Train_acc 0.9902742346938775\n",
      "\n",
      "Epoch 36. Loss: 0.01801229253922529, Train_acc 0.9903125\n",
      "\n",
      "Epoch 36. Loss: 0.016590964944046382, Train_acc 0.9905024509803921\n",
      "\n",
      "Epoch 36. Loss: 0.018133971155478042, Train_acc 0.9905348557692307\n",
      "\n",
      "Epoch 36. Loss: 0.02059166444312943, Train_acc 0.9904186320754716\n",
      "\n",
      "Epoch 36. Loss: 0.023440265845996858, Train_acc 0.9901620370370371\n",
      "\n",
      "Epoch 36. Loss: 0.023837483137913992, Train_acc 0.9901988636363637\n",
      "\n",
      "Epoch 36. Loss: 0.021938231691406775, Train_acc 0.9903738839285714\n",
      "\n",
      "Epoch 36. Loss: 0.020400977433192677, Train_acc 0.9905427631578947\n",
      "\n",
      "Epoch 36. Loss: 0.019391927354456138, Train_acc 0.9905711206896551\n",
      "\n",
      "Epoch 36. Loss: 0.018817677817870217, Train_acc 0.9907309322033898\n",
      "\n",
      "Epoch 36. Loss: 0.021063751851435636, Train_acc 0.990625\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36. Loss: 0.019386832229718088, Train_acc 0.9907786885245902\n",
      "\n",
      "Epoch 36. Loss: 0.02006076773621844, Train_acc 0.9908014112903226\n",
      "\n",
      "Epoch 36. Loss: 0.026336877053542797, Train_acc 0.9905753968253969\n",
      "\n",
      "Epoch 36. Loss: 0.025219563828167795, Train_acc 0.9906005859375\n",
      "\n",
      "Epoch 36. Loss: 0.02454765664302481, Train_acc 0.990625\n",
      "\n",
      "Epoch 36. Loss: 0.02276585754652178, Train_acc 0.9907670454545454\n",
      "\n",
      "Epoch 36. Loss: 0.021408015178734262, Train_acc 0.9907882462686567\n",
      "\n",
      "Epoch 36. Loss: 0.020840383451069176, Train_acc 0.9909237132352942\n",
      "\n",
      "Epoch 36. Loss: 0.024615490628079873, Train_acc 0.990828804347826\n",
      "\n",
      "Epoch 36. Loss: 0.03290328460287717, Train_acc 0.9901785714285715\n",
      "\n",
      "Epoch 36. Loss: 0.030703100136086348, Train_acc 0.9902068661971831\n",
      "\n",
      "Epoch 36. Loss: 0.02924894212588519, Train_acc 0.990234375\n",
      "\n",
      "Epoch 36. Loss: 0.03306617738817499, Train_acc 0.990154109589041\n",
      "\n",
      "Epoch 36. Loss: 0.03039094592382937, Train_acc 0.9902871621621622\n",
      "\n",
      "Epoch 36. Loss: 0.027584242996204756, Train_acc 0.9904166666666666\n",
      "\n",
      "Epoch 36. Loss: 0.026389323034848745, Train_acc 0.9905427631578947\n",
      "\n",
      "Epoch 36. Loss: 0.025685930312245468, Train_acc 0.9905641233766234\n",
      "\n",
      "Epoch 36. Loss: 0.024666181763770625, Train_acc 0.9905849358974359\n",
      "\n",
      "Epoch 36. Loss: 0.02250223802247266, Train_acc 0.9907041139240507\n",
      "\n",
      "Epoch 36. Loss: 0.020407698269466642, Train_acc 0.9908203125\n",
      "\n",
      "Epoch 36. Loss: 0.021045571982067898, Train_acc 0.9908371913580247\n",
      "\n",
      "Epoch 36. Loss: 0.01924352586496062, Train_acc 0.9909489329268293\n",
      "\n",
      "Epoch 36. Loss: 0.017579636216341142, Train_acc 0.9910579819277109\n",
      "\n",
      "Epoch 36. Loss: 0.018165019890825765, Train_acc 0.9910714285714286\n",
      "\n",
      "Epoch 36. Loss: 0.021925411216462392, Train_acc 0.9909926470588235\n",
      "\n",
      "Epoch 36. Loss: 0.025242650814692444, Train_acc 0.9909156976744186\n",
      "\n",
      "Epoch 36. Loss: 0.023214512258327248, Train_acc 0.9910201149425287\n",
      "\n",
      "Epoch 36. Loss: 0.02154764273387752, Train_acc 0.9911221590909091\n",
      "\n",
      "Epoch 36. Loss: 0.01964619291552957, Train_acc 0.9912219101123596\n",
      "\n",
      "Epoch 36. Loss: 0.018531139487585925, Train_acc 0.9913194444444444\n",
      "\n",
      "Epoch 36. Loss: 0.02207632620146409, Train_acc 0.9912431318681318\n",
      "\n",
      "Epoch 36. Loss: 0.02061069010431053, Train_acc 0.9913383152173914\n",
      "\n",
      "Epoch 36. Loss: 0.019064610998938813, Train_acc 0.9914314516129032\n",
      "\n",
      "Epoch 36. Loss: 0.017493464256698194, Train_acc 0.9915226063829787\n",
      "\n",
      "Epoch 36. Loss: 0.015960312818325436, Train_acc 0.9916118421052632\n",
      "\n",
      "Epoch 36. Loss: 0.014590253920707294, Train_acc 0.99169921875\n",
      "\n",
      "Epoch 36. Loss: 0.017205526374000184, Train_acc 0.9917042525773195\n",
      "\n",
      "Epoch 36. Loss: 0.015688315331497376, Train_acc 0.9917889030612245\n",
      "\n",
      "Epoch 36. Loss: 0.014286601264100746, Train_acc 0.9918718434343434\n",
      "\n",
      "Epoch 36. Loss: 0.013520569512684473, Train_acc 0.991953125\n",
      "\n",
      "[Epoch 36 Batch 100] Loss: 0.012257050988787557 Training: accuracy=0.992033\n",
      "Epoch 36. Loss: 0.012257050988787557, Train_acc 0.9920327970297029\n",
      "\n",
      "Epoch 36. Loss: 0.013065053016883862, Train_acc 0.9920343137254902\n",
      "\n",
      "Epoch 36. Loss: 0.013803665406354726, Train_acc 0.9920358009708737\n",
      "\n",
      "Epoch 36. Loss: 0.01260566322288897, Train_acc 0.9921123798076923\n",
      "\n",
      "Epoch 36. Loss: 0.01297017898364651, Train_acc 0.9921130952380952\n",
      "\n",
      "Epoch 36. Loss: 0.012054809625778685, Train_acc 0.9921875\n",
      "\n",
      "Epoch 36. Loss: 0.012473424661905251, Train_acc 0.9921875\n",
      "\n",
      "Epoch 36. Loss: 0.0120109440509236, Train_acc 0.9922598379629629\n",
      "\n",
      "Epoch 36. Loss: 0.01266016911331619, Train_acc 0.9922591743119266\n",
      "\n",
      "Epoch 36. Loss: 0.01219554577795093, Train_acc 0.9923295454545454\n",
      "\n",
      "Epoch 36. Loss: 0.013088611524052246, Train_acc 0.9922578828828829\n",
      "\n",
      "Epoch 36. Loss: 0.013218835601878308, Train_acc 0.9922572544642857\n",
      "\n",
      "Epoch 36. Loss: 0.01212311916545523, Train_acc 0.9923257743362832\n",
      "\n",
      "Epoch 36. Loss: 0.011759245094616646, Train_acc 0.9923930921052632\n",
      "\n",
      "Epoch 36. Loss: 0.016675587323569746, Train_acc 0.9923233695652174\n",
      "\n",
      "Epoch 36. Loss: 0.015293420030896506, Train_acc 0.9923895474137931\n",
      "\n",
      "Epoch 36. Loss: 0.015954954034886934, Train_acc 0.9923210470085471\n",
      "\n",
      "Epoch 36. Loss: 0.014877558688195507, Train_acc 0.992386122881356\n",
      "\n",
      "Epoch 36. Loss: 0.014720967320983375, Train_acc 0.9923844537815126\n",
      "\n",
      "Epoch 36. Loss: 0.013937134549067705, Train_acc 0.9924479166666667\n",
      "\n",
      "Epoch 36. Loss: 0.014206775133353135, Train_acc 0.99244576446281\n",
      "\n",
      "Epoch 36. Loss: 0.01307614564929157, Train_acc 0.9925076844262295\n",
      "\n",
      "Epoch 36. Loss: 0.012211057434160259, Train_acc 0.9925685975609756\n",
      "\n",
      "Epoch 36. Loss: 0.012181363789450003, Train_acc 0.9926285282258065\n",
      "\n",
      "Epoch 36. Loss: 0.011294863230253046, Train_acc 0.9926875\n",
      "\n",
      "Epoch 36. Loss: 0.011010168066261516, Train_acc 0.9927455357142857\n",
      "\n",
      "Epoch 36. Loss: 0.01227022181061355, Train_acc 0.992679625984252\n",
      "\n",
      "Epoch 36. Loss: 0.011816554342425893, Train_acc 0.99273681640625\n",
      "\n",
      "Epoch 36. Loss: 0.011334855902687041, Train_acc 0.9927931201550387\n",
      "\n",
      "Epoch 36. Loss: 0.010579678291972275, Train_acc 0.9928485576923077\n",
      "\n",
      "Epoch 36. Loss: 0.01000218247985464, Train_acc 0.9929031488549618\n",
      "\n",
      "Epoch 36. Loss: 0.013316950103184177, Train_acc 0.9928977272727273\n",
      "\n",
      "Epoch 36. Loss: 0.01263223804023021, Train_acc 0.9929511278195489\n",
      "\n",
      "Epoch 36. Loss: 0.011536548771492275, Train_acc 0.9930037313432836\n",
      "\n",
      "Epoch 36. Loss: 0.011004760422287851, Train_acc 0.9930555555555556\n",
      "\n",
      "Epoch 36. Loss: 0.011141668423693005, Train_acc 0.9930491727941176\n",
      "\n",
      "Epoch 36. Loss: 0.010874885356140694, Train_acc 0.9930999087591241\n",
      "\n",
      "Epoch 36. Loss: 0.01374808187995484, Train_acc 0.9930932971014492\n",
      "\n",
      "Epoch 36. Loss: 0.012717313820361769, Train_acc 0.9931429856115108\n",
      "\n",
      "Epoch 36. Loss: 0.014998750913953491, Train_acc 0.9930803571428571\n",
      "\n",
      "Epoch 36. Loss: 0.013682677664480246, Train_acc 0.9931294326241135\n",
      "\n",
      "Epoch 36. Loss: 0.013066275832612786, Train_acc 0.9931778169014085\n",
      "\n",
      "Epoch 36. Loss: 0.014980212003790861, Train_acc 0.9930616258741258\n",
      "\n",
      "Epoch 36. Loss: 0.014244390227618987, Train_acc 0.9931098090277778\n",
      "\n",
      "Epoch 36. Loss: 0.013627368016442515, Train_acc 0.9931573275862069\n",
      "\n",
      "Epoch 36. Loss: 0.012917431528926663, Train_acc 0.9932041952054794\n",
      "\n",
      "Epoch 36. Loss: 0.011716247907270065, Train_acc 0.993250425170068\n",
      "\n",
      "Epoch 36. Loss: 0.013050423430790667, Train_acc 0.9932432432432432\n",
      "\n",
      "Epoch 36. Loss: 0.012464813201403765, Train_acc 0.9932361577181208\n",
      "\n",
      "Epoch 36. Loss: 0.012365396075346603, Train_acc 0.9932291666666667\n",
      "\n",
      "Epoch 36. Loss: 0.011467076272501231, Train_acc 0.9932740066225165\n",
      "\n",
      "Epoch 36. Loss: 0.01106436201697619, Train_acc 0.9933182565789473\n",
      "\n",
      "Epoch 36. Loss: 0.010131015072720033, Train_acc 0.9933619281045751\n",
      "\n",
      "Epoch 36. Loss: 0.00924950865361701, Train_acc 0.9934050324675324\n",
      "\n",
      "Epoch 36. Loss: 0.009728880472066496, Train_acc 0.9933971774193548\n",
      "\n",
      "Epoch 36. Loss: 0.009611720570548618, Train_acc 0.9934395032051282\n",
      "\n",
      "Epoch 36. Loss: 0.0097095464723923, Train_acc 0.9934812898089171\n",
      "\n",
      "Epoch 36. Loss: 0.009169496992166477, Train_acc 0.9935225474683544\n",
      "\n",
      "Epoch 36. Loss: 0.008904914914610063, Train_acc 0.993563286163522\n",
      "\n",
      "Epoch 36. Loss: 0.00829742194589264, Train_acc 0.993603515625\n",
      "\n",
      "Epoch 36. Loss: 0.00770689367988366, Train_acc 0.9936432453416149\n",
      "\n",
      "Epoch 36. Loss: 0.00755777905647747, Train_acc 0.9936824845679012\n",
      "\n",
      "Epoch 36. Loss: 0.006900422517249366, Train_acc 0.9937212423312883\n",
      "\n",
      "Epoch 36. Loss: 0.008093453230371517, Train_acc 0.9937118902439024\n",
      "\n",
      "Epoch 36. Loss: 0.007416371557055065, Train_acc 0.99375\n",
      "\n",
      "Epoch 36. Loss: 0.007446042206902637, Train_acc 0.9937405873493976\n",
      "\n",
      "Epoch 36. Loss: 0.0070611993519017115, Train_acc 0.9937780688622755\n",
      "\n",
      "Epoch 36. Loss: 0.0071816171189441405, Train_acc 0.9938151041666666\n",
      "\n",
      "Epoch 36. Loss: 0.009915172306921552, Train_acc 0.993805473372781\n",
      "\n",
      "Epoch 36. Loss: 0.009747676717394415, Train_acc 0.9937959558823529\n",
      "\n",
      "Epoch 36. Loss: 0.009828571379620276, Train_acc 0.9937865497076024\n",
      "\n",
      "Epoch 36. Loss: 0.0088806006830846, Train_acc 0.9938226744186046\n",
      "\n",
      "Epoch 36. Loss: 0.008075653244139454, Train_acc 0.9938583815028902\n",
      "\n",
      "Epoch 36. Loss: 0.007377236294484169, Train_acc 0.9938936781609196\n",
      "\n",
      "Epoch 36. Loss: 0.011386375910999804, Train_acc 0.9937946428571428\n",
      "\n",
      "Epoch 36. Loss: 0.010354484837021616, Train_acc 0.9938299005681818\n",
      "\n",
      "Epoch 36. Loss: 0.009732369651957918, Train_acc 0.9938647598870056\n",
      "\n",
      "Epoch 36. Loss: 0.009133561777641984, Train_acc 0.9938992275280899\n",
      "\n",
      "Epoch 36. Loss: 0.008458069622952294, Train_acc 0.9939333100558659\n",
      "\n",
      "Epoch 36. Loss: 0.008119589177911179, Train_acc 0.9939670138888889\n",
      "\n",
      "Epoch 36. Loss: 0.007578599960188296, Train_acc 0.9940003453038674\n",
      "\n",
      "Epoch 36. Loss: 0.007529643010494316, Train_acc 0.9940333104395604\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36. Loss: 0.007038599446547513, Train_acc 0.9940659153005464\n",
      "\n",
      "Epoch 36. Loss: 0.006496307903274135, Train_acc 0.9940981657608695\n",
      "\n",
      "Epoch 36. Loss: 0.006153983434284541, Train_acc 0.9941300675675676\n",
      "\n",
      "Epoch 36. Loss: 0.005622225884892997, Train_acc 0.994161626344086\n",
      "\n",
      "Epoch 36. Loss: 0.007027900935082249, Train_acc 0.9941510695187166\n",
      "\n",
      "Epoch 36. Loss: 0.006906918205352377, Train_acc 0.9941821808510638\n",
      "\n",
      "Epoch 36. Loss: 0.006269309251178505, Train_acc 0.9942129629629629\n",
      "\n",
      "Epoch 36. Loss: 0.006110872370677473, Train_acc 0.9942434210526315\n",
      "\n",
      "Epoch 36. Loss: 0.008783254512557938, Train_acc 0.9941917539267016\n",
      "\n",
      "Epoch 36. Loss: 0.008329890946739513, Train_acc 0.9942220052083334\n",
      "\n",
      "Epoch 36. Loss: 0.007838550693342326, Train_acc 0.9942519430051814\n",
      "\n",
      "Epoch 36. Loss: 0.0084079537047886, Train_acc 0.9942413015463918\n",
      "\n",
      "Epoch 36. Loss: 0.008133227836693211, Train_acc 0.9942708333333333\n",
      "\n",
      "Epoch 36. Loss: 0.0074274389218917936, Train_acc 0.99428\n",
      "\n",
      "Epoch 37. Loss: 0.007438517114218901, Train_acc 1.0\n",
      "\n",
      "Epoch 37. Loss: 0.007124748770770577, Train_acc 1.0\n",
      "\n",
      "Epoch 37. Loss: 0.008908900121787619, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 37. Loss: 0.00891542527819225, Train_acc 0.99609375\n",
      "\n",
      "Epoch 37. Loss: 0.008471035258795757, Train_acc 0.996875\n",
      "\n",
      "Epoch 37. Loss: 0.009473444861316032, Train_acc 0.99609375\n",
      "\n",
      "Epoch 37. Loss: 0.00979651135248841, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 37. Loss: 0.010015980686630916, Train_acc 0.9951171875\n",
      "\n",
      "Epoch 37. Loss: 0.009066425092239554, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 37. Loss: 0.008430666438425518, Train_acc 0.99609375\n",
      "\n",
      "Epoch 37. Loss: 0.007684388197462577, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 37. Loss: 0.007431080378145711, Train_acc 0.9967447916666666\n",
      "\n",
      "Epoch 37. Loss: 0.00829564558301932, Train_acc 0.9963942307692307\n",
      "\n",
      "Epoch 37. Loss: 0.007501680218951624, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 37. Loss: 0.007109162766696562, Train_acc 0.996875\n",
      "\n",
      "Epoch 37. Loss: 0.006427298151867546, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 37. Loss: 0.0060005813668298335, Train_acc 0.9972426470588235\n",
      "\n",
      "Epoch 37. Loss: 0.00573381680407771, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 37. Loss: 0.0052667028012899925, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 37. Loss: 0.0049220844196069275, Train_acc 0.99765625\n",
      "\n",
      "Epoch 37. Loss: 0.007202722609351996, Train_acc 0.9970238095238095\n",
      "\n",
      "Epoch 37. Loss: 0.007032071529979339, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 37. Loss: 0.006385791306373326, Train_acc 0.9972826086956522\n",
      "\n",
      "Epoch 37. Loss: 0.006520134941199584, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 37. Loss: 0.006018607575484362, Train_acc 0.9975\n",
      "\n",
      "Epoch 37. Loss: 0.006007399278168303, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 37. Loss: 0.006220718075142285, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 37. Loss: 0.005626134014766423, Train_acc 0.9974888392857143\n",
      "\n",
      "Epoch 37. Loss: 0.005572745352215477, Train_acc 0.9975754310344828\n",
      "\n",
      "Epoch 37. Loss: 0.00508564599627427, Train_acc 0.99765625\n",
      "\n",
      "Epoch 37. Loss: 0.004627206883097113, Train_acc 0.9977318548387096\n",
      "\n",
      "Epoch 37. Loss: 0.004490066881118197, Train_acc 0.997802734375\n",
      "\n",
      "Epoch 37. Loss: 0.004211972251099031, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 37. Loss: 0.006236886876429631, Train_acc 0.9977022058823529\n",
      "\n",
      "Epoch 37. Loss: 0.00588543208940075, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 37. Loss: 0.005468983764789219, Train_acc 0.9978298611111112\n",
      "\n",
      "Epoch 37. Loss: 0.005925719386644705, Train_acc 0.9976773648648649\n",
      "\n",
      "Epoch 37. Loss: 0.005683739547110389, Train_acc 0.9977384868421053\n",
      "\n",
      "Epoch 37. Loss: 0.005280890030888579, Train_acc 0.9977964743589743\n",
      "\n",
      "Epoch 37. Loss: 0.00603871377622592, Train_acc 0.99765625\n",
      "\n",
      "Epoch 37. Loss: 0.0054754602340784594, Train_acc 0.9977134146341463\n",
      "\n",
      "Epoch 37. Loss: 0.005000237322487854, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 37. Loss: 0.005619204369162104, Train_acc 0.9976380813953488\n",
      "\n",
      "Epoch 37. Loss: 0.00510403491104543, Train_acc 0.9976917613636364\n",
      "\n",
      "Epoch 37. Loss: 0.006791986319824158, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 37. Loss: 0.006751300489220708, Train_acc 0.997452445652174\n",
      "\n",
      "Epoch 37. Loss: 0.006218073592987975, Train_acc 0.9975066489361702\n",
      "\n",
      "Epoch 37. Loss: 0.006003004837176788, Train_acc 0.99755859375\n",
      "\n",
      "Epoch 37. Loss: 0.005754164165832032, Train_acc 0.9976084183673469\n",
      "\n",
      "Epoch 37. Loss: 0.005302302846046474, Train_acc 0.99765625\n",
      "\n",
      "Epoch 37. Loss: 0.004816205790390166, Train_acc 0.9977022058823529\n",
      "\n",
      "Epoch 37. Loss: 0.004507432441338532, Train_acc 0.9977463942307693\n",
      "\n",
      "Epoch 37. Loss: 0.005515375228605837, Train_acc 0.9976415094339622\n",
      "\n",
      "Epoch 37. Loss: 0.005308580097935054, Train_acc 0.9976851851851852\n",
      "\n",
      "Epoch 37. Loss: 0.009587445882601846, Train_acc 0.9975852272727272\n",
      "\n",
      "Epoch 37. Loss: 0.00898812803582994, Train_acc 0.9976283482142857\n",
      "\n",
      "Epoch 37. Loss: 0.010115074638634751, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 37. Loss: 0.009143259543362479, Train_acc 0.9974407327586207\n",
      "\n",
      "Epoch 37. Loss: 0.009719121606513757, Train_acc 0.9973516949152542\n",
      "\n",
      "Epoch 37. Loss: 0.008857862244183478, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 37. Loss: 0.008063116119270465, Train_acc 0.9974385245901639\n",
      "\n",
      "Epoch 37. Loss: 0.007366969234427758, Train_acc 0.9974798387096774\n",
      "\n",
      "Epoch 37. Loss: 0.008212987412525071, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 37. Loss: 0.00851937353269415, Train_acc 0.997314453125\n",
      "\n",
      "Epoch 37. Loss: 0.00772599024576983, Train_acc 0.9973557692307692\n",
      "\n",
      "Epoch 37. Loss: 0.007056093528242033, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 37. Loss: 0.0064473012688535045, Train_acc 0.9974347014925373\n",
      "\n",
      "Epoch 37. Loss: 0.008074966186533356, Train_acc 0.9973575367647058\n",
      "\n",
      "Epoch 37. Loss: 0.01033023579947649, Train_acc 0.9971693840579711\n",
      "\n",
      "Epoch 37. Loss: 0.012479212886385607, Train_acc 0.9970982142857143\n",
      "\n",
      "Epoch 37. Loss: 0.011297331419578557, Train_acc 0.9971390845070423\n",
      "\n",
      "Epoch 37. Loss: 0.010624680966429143, Train_acc 0.9971788194444444\n",
      "\n",
      "Epoch 37. Loss: 0.022220449790619816, Train_acc 0.996896404109589\n",
      "\n",
      "Epoch 37. Loss: 0.02005850597932235, Train_acc 0.9969383445945946\n",
      "\n",
      "Epoch 37. Loss: 0.01878254587506618, Train_acc 0.9969791666666666\n",
      "\n",
      "Epoch 37. Loss: 0.024101480618614248, Train_acc 0.9965049342105263\n",
      "\n",
      "Epoch 37. Loss: 0.023446502708344127, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 37. Loss: 0.023258298752857866, Train_acc 0.9962940705128205\n",
      "\n",
      "Epoch 37. Loss: 0.02183915601431157, Train_acc 0.9963409810126582\n",
      "\n",
      "Epoch 37. Loss: 0.020613900378425355, Train_acc 0.99638671875\n",
      "\n",
      "Epoch 37. Loss: 0.019459740717780085, Train_acc 0.9964313271604939\n",
      "\n",
      "Epoch 37. Loss: 0.025995417445514944, Train_acc 0.9961890243902439\n",
      "\n",
      "Epoch 37. Loss: 0.0237639804363528, Train_acc 0.9962349397590361\n",
      "\n",
      "Epoch 37. Loss: 0.021570144236839187, Train_acc 0.9962797619047619\n",
      "\n",
      "Epoch 37. Loss: 0.023888862333377933, Train_acc 0.9961397058823529\n",
      "\n",
      "Epoch 37. Loss: 0.02503190595061845, Train_acc 0.9960029069767442\n",
      "\n",
      "Epoch 37. Loss: 0.022908617247130867, Train_acc 0.9960488505747126\n",
      "\n",
      "Epoch 37. Loss: 0.021320277053329107, Train_acc 0.99609375\n",
      "\n",
      "Epoch 37. Loss: 0.01952417458340921, Train_acc 0.9961376404494382\n",
      "\n",
      "Epoch 37. Loss: 0.022679833086538894, Train_acc 0.99609375\n",
      "\n",
      "Epoch 37. Loss: 0.024264389287419842, Train_acc 0.9960508241758241\n",
      "\n",
      "Epoch 37. Loss: 0.02270453372089958, Train_acc 0.99609375\n",
      "\n",
      "Epoch 37. Loss: 0.0217763936198255, Train_acc 0.996051747311828\n",
      "\n",
      "Epoch 37. Loss: 0.021037322604045325, Train_acc 0.99609375\n",
      "\n",
      "Epoch 37. Loss: 0.024739124840544212, Train_acc 0.9960526315789474\n",
      "\n",
      "Epoch 37. Loss: 0.030976784347933425, Train_acc 0.9959309895833334\n",
      "\n",
      "Epoch 37. Loss: 0.030731371822454237, Train_acc 0.9958923969072165\n",
      "\n",
      "Epoch 37. Loss: 0.0291955939598361, Train_acc 0.9959343112244898\n",
      "\n",
      "Epoch 37. Loss: 0.0265065522678923, Train_acc 0.9959753787878788\n",
      "\n",
      "Epoch 37. Loss: 0.0293230272848813, Train_acc 0.995859375\n",
      "\n",
      "[Epoch 37 Batch 100] Loss: 0.0266490003297694 Training: accuracy=0.995900\n",
      "Epoch 37. Loss: 0.0266490003297694, Train_acc 0.9959003712871287\n",
      "\n",
      "Epoch 37. Loss: 0.024385485797819566, Train_acc 0.9959405637254902\n",
      "\n",
      "Epoch 37. Loss: 0.022062076558088128, Train_acc 0.9959799757281553\n",
      "\n",
      "Epoch 37. Loss: 0.020525701942144214, Train_acc 0.9960186298076923\n",
      "\n",
      "Epoch 37. Loss: 0.024827728213755826, Train_acc 0.9958333333333333\n",
      "\n",
      "Epoch 37. Loss: 0.025628673620720393, Train_acc 0.9957252358490566\n",
      "\n",
      "Epoch 37. Loss: 0.024882507216363866, Train_acc 0.9956921728971962\n",
      "\n",
      "Epoch 37. Loss: 0.02339013518371855, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 37. Loss: 0.02186920836027272, Train_acc 0.9956995412844036\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37. Loss: 0.0216010862093193, Train_acc 0.9955965909090909\n",
      "\n",
      "Epoch 37. Loss: 0.02277830274412239, Train_acc 0.9954251126126126\n",
      "\n",
      "Epoch 37. Loss: 0.020923241276748817, Train_acc 0.9954659598214286\n",
      "\n",
      "Epoch 37. Loss: 0.01924663924355016, Train_acc 0.9955060840707964\n",
      "\n",
      "Epoch 37. Loss: 0.01783883569251334, Train_acc 0.9955455043859649\n",
      "\n",
      "Epoch 37. Loss: 0.01838466709206255, Train_acc 0.9955163043478261\n",
      "\n",
      "Epoch 37. Loss: 0.018090894054023192, Train_acc 0.9954876077586207\n",
      "\n",
      "Epoch 37. Loss: 0.017273377460820465, Train_acc 0.9955261752136753\n",
      "\n",
      "Epoch 37. Loss: 0.0167304672666636, Train_acc 0.9954978813559322\n",
      "\n",
      "Epoch 37. Loss: 0.019677170547984263, Train_acc 0.9954044117647058\n",
      "\n",
      "Epoch 37. Loss: 0.019382214821704227, Train_acc 0.9953776041666667\n",
      "\n",
      "Epoch 37. Loss: 0.021268341342206003, Train_acc 0.995286673553719\n",
      "\n",
      "Epoch 37. Loss: 0.019642541803057672, Train_acc 0.9953253073770492\n",
      "\n",
      "Epoch 37. Loss: 0.018124669368611887, Train_acc 0.9953633130081301\n",
      "\n",
      "Epoch 37. Loss: 0.021394675590587064, Train_acc 0.9952116935483871\n",
      "\n",
      "Epoch 37. Loss: 0.021605078124695188, Train_acc 0.9951875\n",
      "\n",
      "Epoch 37. Loss: 0.02050543920504436, Train_acc 0.9951636904761905\n",
      "\n",
      "Epoch 37. Loss: 0.020745116029447782, Train_acc 0.9951402559055118\n",
      "\n",
      "Epoch 37. Loss: 0.019910343784928144, Train_acc 0.99517822265625\n",
      "\n",
      "Epoch 37. Loss: 0.018121441585837145, Train_acc 0.9952156007751938\n",
      "\n",
      "Epoch 37. Loss: 0.016868418797568983, Train_acc 0.9952524038461539\n",
      "\n",
      "Epoch 37. Loss: 0.015403366825476146, Train_acc 0.9952886450381679\n",
      "\n",
      "Epoch 37. Loss: 0.013997634823280446, Train_acc 0.9953243371212122\n",
      "\n",
      "Epoch 37. Loss: 0.01311306408806849, Train_acc 0.995359492481203\n",
      "\n",
      "Epoch 37. Loss: 0.012527138243370132, Train_acc 0.9953358208955224\n",
      "\n",
      "Epoch 37. Loss: 0.013704273142146655, Train_acc 0.9953125\n",
      "\n",
      "Epoch 37. Loss: 0.013225004464591374, Train_acc 0.9953469669117647\n",
      "\n",
      "Epoch 37. Loss: 0.012135634198409167, Train_acc 0.9953809306569343\n",
      "\n",
      "Epoch 37. Loss: 0.011327181802724464, Train_acc 0.9954144021739131\n",
      "\n",
      "Epoch 37. Loss: 0.011705518946678636, Train_acc 0.9953911870503597\n",
      "\n",
      "Epoch 37. Loss: 0.011396961881039619, Train_acc 0.9954241071428571\n",
      "\n",
      "Epoch 37. Loss: 0.011262680938826274, Train_acc 0.9954011524822695\n",
      "\n",
      "Epoch 37. Loss: 0.0101594739242078, Train_acc 0.9954335387323944\n",
      "\n",
      "Epoch 37. Loss: 0.009531799569757086, Train_acc 0.995465472027972\n",
      "\n",
      "Epoch 37. Loss: 0.011525546824960084, Train_acc 0.9953884548611112\n",
      "\n",
      "Epoch 37. Loss: 0.011277377887989437, Train_acc 0.9953663793103448\n",
      "\n",
      "Epoch 37. Loss: 0.010428193815097532, Train_acc 0.9953981164383562\n",
      "\n",
      "Epoch 37. Loss: 0.009575854347314228, Train_acc 0.9954294217687075\n",
      "\n",
      "Epoch 37. Loss: 0.009335507342516591, Train_acc 0.9954075168918919\n",
      "\n",
      "Epoch 37. Loss: 0.010675646563737878, Train_acc 0.9953859060402684\n",
      "\n",
      "Epoch 37. Loss: 0.009960151875721773, Train_acc 0.9954166666666666\n",
      "\n",
      "Epoch 37. Loss: 0.009139772391057635, Train_acc 0.9954470198675497\n",
      "\n",
      "Epoch 37. Loss: 0.008481617262873017, Train_acc 0.9954769736842105\n",
      "\n",
      "Epoch 37. Loss: 0.007788505110681472, Train_acc 0.9955065359477124\n",
      "\n",
      "Epoch 37. Loss: 0.007052116043422186, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 37. Loss: 0.006782795162099805, Train_acc 0.9955645161290323\n",
      "\n",
      "Epoch 37. Loss: 0.00625210249727059, Train_acc 0.9955929487179487\n",
      "\n",
      "Epoch 37. Loss: 0.005802575378053683, Train_acc 0.9956210191082803\n",
      "\n",
      "Epoch 37. Loss: 0.00525581714654897, Train_acc 0.9956487341772152\n",
      "\n",
      "Epoch 37. Loss: 0.0048154008184479275, Train_acc 0.9956761006289309\n",
      "\n",
      "Epoch 37. Loss: 0.004724362848589414, Train_acc 0.995703125\n",
      "\n",
      "Epoch 37. Loss: 0.004383852853490049, Train_acc 0.9957298136645962\n",
      "\n",
      "Epoch 37. Loss: 0.004404538490947903, Train_acc 0.9957561728395061\n",
      "\n",
      "Epoch 37. Loss: 0.004035717212905873, Train_acc 0.995782208588957\n",
      "\n",
      "Epoch 37. Loss: 0.00445940319933032, Train_acc 0.9958079268292683\n",
      "\n",
      "Epoch 37. Loss: 0.004614344660826341, Train_acc 0.9958333333333333\n",
      "\n",
      "Epoch 37. Loss: 0.005352958168287113, Train_acc 0.9958113704819277\n",
      "\n",
      "Epoch 37. Loss: 0.004923923731009544, Train_acc 0.9958364520958084\n",
      "\n",
      "Epoch 37. Loss: 0.0061463199214581085, Train_acc 0.9958147321428571\n",
      "\n",
      "Epoch 37. Loss: 0.006509638565609762, Train_acc 0.9957932692307693\n",
      "\n",
      "Epoch 37. Loss: 0.005979345686097362, Train_acc 0.9958180147058824\n",
      "\n",
      "Epoch 37. Loss: 0.005505349395317064, Train_acc 0.9958424707602339\n",
      "\n",
      "Epoch 37. Loss: 0.005845033387966955, Train_acc 0.9958212209302325\n",
      "\n",
      "Epoch 37. Loss: 0.005403173789570931, Train_acc 0.9958453757225434\n",
      "\n",
      "Epoch 37. Loss: 0.004894422460051807, Train_acc 0.9958692528735632\n",
      "\n",
      "Epoch 37. Loss: 0.004539333460586458, Train_acc 0.9958928571428571\n",
      "\n",
      "Epoch 37. Loss: 0.004604791869169942, Train_acc 0.9959161931818182\n",
      "\n",
      "Epoch 37. Loss: 0.004205523555789714, Train_acc 0.9959392655367232\n",
      "\n",
      "Epoch 37. Loss: 0.004491085727048806, Train_acc 0.9959181882022472\n",
      "\n",
      "Epoch 37. Loss: 0.004143443235449099, Train_acc 0.9959409916201117\n",
      "\n",
      "Epoch 37. Loss: 0.0037690764922131033, Train_acc 0.9959635416666667\n",
      "\n",
      "Epoch 37. Loss: 0.0035997522396873476, Train_acc 0.9959858425414365\n",
      "\n",
      "Epoch 37. Loss: 0.0034466407096115687, Train_acc 0.9960078983516484\n",
      "\n",
      "Epoch 37. Loss: 0.0031488892135581766, Train_acc 0.9960297131147541\n",
      "\n",
      "Epoch 37. Loss: 0.0030854178527052454, Train_acc 0.9960512907608695\n",
      "\n",
      "Epoch 37. Loss: 0.003071637310711019, Train_acc 0.9960726351351351\n",
      "\n",
      "Epoch 37. Loss: 0.0028063335753300916, Train_acc 0.99609375\n",
      "\n",
      "Epoch 37. Loss: 0.0026225885632304817, Train_acc 0.9961146390374331\n",
      "\n",
      "Epoch 37. Loss: 0.0024413212025409313, Train_acc 0.9961353058510638\n",
      "\n",
      "Epoch 37. Loss: 0.0029743027993361986, Train_acc 0.996114417989418\n",
      "\n",
      "Epoch 37. Loss: 0.002715264904288389, Train_acc 0.9961348684210526\n",
      "\n",
      "Epoch 37. Loss: 0.002991898117471878, Train_acc 0.9961551047120419\n",
      "\n",
      "Epoch 37. Loss: 0.0027553106450371244, Train_acc 0.9961751302083334\n",
      "\n",
      "Epoch 37. Loss: 0.0026136281782946553, Train_acc 0.9961949481865285\n",
      "\n",
      "Epoch 37. Loss: 0.004707081521561286, Train_acc 0.9961742912371134\n",
      "\n",
      "Epoch 37. Loss: 0.005169322312632687, Train_acc 0.9961939102564102\n",
      "\n",
      "Epoch 37. Loss: 0.011526702541791934, Train_acc 0.99616\n",
      "\n",
      "Epoch 38. Loss: 0.010750268493533319, Train_acc 1.0\n",
      "\n",
      "Epoch 38. Loss: 0.021072499091422725, Train_acc 0.98828125\n",
      "\n",
      "Epoch 38. Loss: 0.030706153483685408, Train_acc 0.9791666666666666\n",
      "\n",
      "Epoch 38. Loss: 0.028215806116011637, Train_acc 0.984375\n",
      "\n",
      "Epoch 38. Loss: 0.055471945192826, Train_acc 0.9703125\n",
      "\n",
      "Epoch 38. Loss: 0.061971670436631626, Train_acc 0.9661458333333334\n",
      "\n",
      "Epoch 38. Loss: 0.058425994036588956, Train_acc 0.9698660714285714\n",
      "\n",
      "Epoch 38. Loss: 0.08591586171209266, Train_acc 0.9638671875\n",
      "\n",
      "Epoch 38. Loss: 0.09475213872152075, Train_acc 0.9609375\n",
      "\n",
      "Epoch 38. Loss: 0.08841942477307473, Train_acc 0.9640625\n",
      "\n",
      "Epoch 38. Loss: 0.09113463069273608, Train_acc 0.9644886363636364\n",
      "\n",
      "Epoch 38. Loss: 0.09843038891500454, Train_acc 0.9622395833333334\n",
      "\n",
      "Epoch 38. Loss: 0.10084271766018468, Train_acc 0.9621394230769231\n",
      "\n",
      "Epoch 38. Loss: 0.09791515547577977, Train_acc 0.9631696428571429\n",
      "\n",
      "Epoch 38. Loss: 0.09599085848222172, Train_acc 0.9630208333333333\n",
      "\n",
      "Epoch 38. Loss: 0.10460514158627388, Train_acc 0.96142578125\n",
      "\n",
      "Epoch 38. Loss: 0.10067448241073786, Train_acc 0.9613970588235294\n",
      "\n",
      "Epoch 38. Loss: 0.10545841356419533, Train_acc 0.9618055555555556\n",
      "\n",
      "Epoch 38. Loss: 0.1042122080949218, Train_acc 0.962171052631579\n",
      "\n",
      "Epoch 38. Loss: 0.10419103816395439, Train_acc 0.962890625\n",
      "\n",
      "Epoch 38. Loss: 0.09648125826041792, Train_acc 0.9642857142857143\n",
      "\n",
      "Epoch 38. Loss: 0.08876931928444709, Train_acc 0.9659090909090909\n",
      "\n",
      "Epoch 38. Loss: 0.08620146077438122, Train_acc 0.9663722826086957\n",
      "\n",
      "Epoch 38. Loss: 0.08253180827108555, Train_acc 0.9671223958333334\n",
      "\n",
      "Epoch 38. Loss: 0.08737654398746074, Train_acc 0.96625\n",
      "\n",
      "Epoch 38. Loss: 0.08170832539379698, Train_acc 0.9672475961538461\n",
      "\n",
      "Epoch 38. Loss: 0.07791074971658082, Train_acc 0.9675925925925926\n",
      "\n",
      "Epoch 38. Loss: 0.0715655227740296, Train_acc 0.9684709821428571\n",
      "\n",
      "Epoch 38. Loss: 0.07159178616759374, Train_acc 0.96875\n",
      "\n",
      "Epoch 38. Loss: 0.07151679243585939, Train_acc 0.9690104166666667\n",
      "\n",
      "Epoch 38. Loss: 0.07056158933885223, Train_acc 0.9695060483870968\n",
      "\n",
      "Epoch 38. Loss: 0.0653596560255944, Train_acc 0.97021484375\n",
      "\n",
      "Epoch 38. Loss: 0.0602212248828643, Train_acc 0.9708806818181818\n",
      "\n",
      "Epoch 38. Loss: 0.05784861954331101, Train_acc 0.9712775735294118\n",
      "\n",
      "Epoch 38. Loss: 0.054064736736831376, Train_acc 0.9720982142857143\n",
      "\n",
      "Epoch 38. Loss: 0.05221853454978821, Train_acc 0.9724392361111112\n",
      "\n",
      "Epoch 38. Loss: 0.0483593484206935, Train_acc 0.9731841216216216\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38. Loss: 0.045316921810264005, Train_acc 0.973889802631579\n",
      "\n",
      "Epoch 38. Loss: 0.04192699115197773, Train_acc 0.9745592948717948\n",
      "\n",
      "Epoch 38. Loss: 0.038984680230655516, Train_acc 0.9751953125\n",
      "\n",
      "Epoch 38. Loss: 0.0360782904485508, Train_acc 0.9758003048780488\n",
      "\n",
      "Epoch 38. Loss: 0.034145087612537525, Train_acc 0.9761904761904762\n",
      "\n",
      "Epoch 38. Loss: 0.03113439417290805, Train_acc 0.9767441860465116\n",
      "\n",
      "Epoch 38. Loss: 0.03184787022836314, Train_acc 0.9769176136363636\n",
      "\n",
      "Epoch 38. Loss: 0.031347583273952956, Train_acc 0.9772569444444444\n",
      "\n",
      "Epoch 38. Loss: 0.03463667232385792, Train_acc 0.9774116847826086\n",
      "\n",
      "Epoch 38. Loss: 0.03198197963319586, Train_acc 0.9778922872340425\n",
      "\n",
      "Epoch 38. Loss: 0.031361700624069865, Train_acc 0.9781901041666666\n",
      "\n",
      "Epoch 38. Loss: 0.03058096959129688, Train_acc 0.9784757653061225\n",
      "\n",
      "Epoch 38. Loss: 0.028786190470478385, Train_acc 0.97875\n",
      "\n",
      "Epoch 38. Loss: 0.028302576761324513, Train_acc 0.9790134803921569\n",
      "\n",
      "Epoch 38. Loss: 0.02595753432814417, Train_acc 0.9794170673076923\n",
      "\n",
      "Epoch 38. Loss: 0.025924039287902156, Train_acc 0.9796580188679245\n",
      "\n",
      "Epoch 38. Loss: 0.026091499912921107, Train_acc 0.9798900462962963\n",
      "\n",
      "Epoch 38. Loss: 0.023994224971771404, Train_acc 0.9802556818181818\n",
      "\n",
      "Epoch 38. Loss: 0.022425509801125672, Train_acc 0.9806082589285714\n",
      "\n",
      "Epoch 38. Loss: 0.021653480844750536, Train_acc 0.9806743421052632\n",
      "\n",
      "Epoch 38. Loss: 0.022410244696189047, Train_acc 0.9807381465517241\n",
      "\n",
      "Epoch 38. Loss: 0.020776473744525684, Train_acc 0.9810646186440678\n",
      "\n",
      "Epoch 38. Loss: 0.020791193408203876, Train_acc 0.98125\n",
      "\n",
      "Epoch 38. Loss: 0.018989459858215832, Train_acc 0.9815573770491803\n",
      "\n",
      "Epoch 38. Loss: 0.017587714538389726, Train_acc 0.9818548387096774\n",
      "\n",
      "Epoch 38. Loss: 0.017920584622395888, Train_acc 0.9818948412698413\n",
      "\n",
      "Epoch 38. Loss: 0.017850170002913047, Train_acc 0.9820556640625\n",
      "\n",
      "Epoch 38. Loss: 0.01654519363108477, Train_acc 0.9823317307692307\n",
      "\n",
      "Epoch 38. Loss: 0.015109271927817473, Train_acc 0.9825994318181818\n",
      "\n",
      "Epoch 38. Loss: 0.015085941068062611, Train_acc 0.9828591417910447\n",
      "\n",
      "Epoch 38. Loss: 0.014190119077693906, Train_acc 0.9831112132352942\n",
      "\n",
      "Epoch 38. Loss: 0.013622272486923475, Train_acc 0.9833559782608695\n",
      "\n",
      "Epoch 38. Loss: 0.014907220505569882, Train_acc 0.9833705357142857\n",
      "\n",
      "Epoch 38. Loss: 0.013527250951415605, Train_acc 0.9836047535211268\n",
      "\n",
      "Epoch 38. Loss: 0.01234372195252297, Train_acc 0.9838324652777778\n",
      "\n",
      "Epoch 38. Loss: 0.012389662556187968, Train_acc 0.9839469178082192\n",
      "\n",
      "Epoch 38. Loss: 0.011850143349397178, Train_acc 0.9841638513513513\n",
      "\n",
      "Epoch 38. Loss: 0.011694475245828624, Train_acc 0.9842708333333333\n",
      "\n",
      "Epoch 38. Loss: 0.010747839778718528, Train_acc 0.9844777960526315\n",
      "\n",
      "Epoch 38. Loss: 0.010295904175615767, Train_acc 0.9846793831168831\n",
      "\n",
      "Epoch 38. Loss: 0.009684889378332907, Train_acc 0.9848758012820513\n",
      "\n",
      "Epoch 38. Loss: 0.009641903739139868, Train_acc 0.9849683544303798\n",
      "\n",
      "Epoch 38. Loss: 0.008746568179388358, Train_acc 0.98515625\n",
      "\n",
      "Epoch 38. Loss: 0.009377228341632647, Train_acc 0.9852430555555556\n",
      "\n",
      "Epoch 38. Loss: 0.008811710437059608, Train_acc 0.985423018292683\n",
      "\n",
      "Epoch 38. Loss: 0.008634695348817294, Train_acc 0.9855986445783133\n",
      "\n",
      "Epoch 38. Loss: 0.008129167491729424, Train_acc 0.9857700892857143\n",
      "\n",
      "Epoch 38. Loss: 0.007472067947642833, Train_acc 0.9859375\n",
      "\n",
      "Epoch 38. Loss: 0.008171489444038418, Train_acc 0.9860101744186046\n",
      "\n",
      "Epoch 38. Loss: 0.00812208897657199, Train_acc 0.9861709770114943\n",
      "\n",
      "Epoch 38. Loss: 0.009810207382920414, Train_acc 0.9862393465909091\n",
      "\n",
      "Epoch 38. Loss: 0.009113658985346284, Train_acc 0.9863939606741573\n",
      "\n",
      "Epoch 38. Loss: 0.00867489235477125, Train_acc 0.9865451388888888\n",
      "\n",
      "Epoch 38. Loss: 0.00845861683228441, Train_acc 0.9866929945054945\n",
      "\n",
      "Epoch 38. Loss: 0.008419688883621943, Train_acc 0.9868376358695652\n",
      "\n",
      "Epoch 38. Loss: 0.00776848665156539, Train_acc 0.9869791666666666\n",
      "\n",
      "Epoch 38. Loss: 0.010320338350044868, Train_acc 0.9869514627659575\n",
      "\n",
      "Epoch 38. Loss: 0.009742159845164878, Train_acc 0.9870888157894737\n",
      "\n",
      "Epoch 38. Loss: 0.00930359967394006, Train_acc 0.9872233072916666\n",
      "\n",
      "Epoch 38. Loss: 0.014795186440736042, Train_acc 0.9871134020618557\n",
      "\n",
      "Epoch 38. Loss: 0.01670051871590911, Train_acc 0.9870854591836735\n",
      "\n",
      "Epoch 38. Loss: 0.01559541112276702, Train_acc 0.9872159090909091\n",
      "\n",
      "Epoch 38. Loss: 0.014786245363290212, Train_acc 0.98734375\n",
      "\n",
      "[Epoch 38 Batch 100] Loss: 0.01400414883144358 Training: accuracy=0.987469\n",
      "Epoch 38. Loss: 0.01400414883144358, Train_acc 0.9874690594059405\n",
      "\n",
      "Epoch 38. Loss: 0.01557155929399424, Train_acc 0.987515318627451\n",
      "\n",
      "Epoch 38. Loss: 0.01502008366489017, Train_acc 0.9876365291262136\n",
      "\n",
      "Epoch 38. Loss: 0.014242441512527503, Train_acc 0.9877554086538461\n",
      "\n",
      "Epoch 38. Loss: 0.013864464792504106, Train_acc 0.9877976190476191\n",
      "\n",
      "Epoch 38. Loss: 0.01285741975864249, Train_acc 0.9879127358490566\n",
      "\n",
      "Epoch 38. Loss: 0.011874817832578518, Train_acc 0.9880257009345794\n",
      "\n",
      "Epoch 38. Loss: 0.011494049526097743, Train_acc 0.9881365740740741\n",
      "\n",
      "Epoch 38. Loss: 0.011184999377437563, Train_acc 0.9882454128440367\n",
      "\n",
      "Epoch 38. Loss: 0.011651129712976336, Train_acc 0.98828125\n",
      "\n",
      "Epoch 38. Loss: 0.013882789334938514, Train_acc 0.9882460585585585\n",
      "\n",
      "Epoch 38. Loss: 0.015363234270768394, Train_acc 0.98828125\n",
      "\n",
      "Epoch 38. Loss: 0.014278532815715997, Train_acc 0.9883849557522124\n",
      "\n",
      "Epoch 38. Loss: 0.013607677335507865, Train_acc 0.9884868421052632\n",
      "\n",
      "Epoch 38. Loss: 0.012646450711757417, Train_acc 0.9885869565217391\n",
      "\n",
      "Epoch 38. Loss: 0.013252980587009022, Train_acc 0.9886179956896551\n",
      "\n",
      "Epoch 38. Loss: 0.012595050683280911, Train_acc 0.9887152777777778\n",
      "\n",
      "Epoch 38. Loss: 0.012650300399060028, Train_acc 0.9887447033898306\n",
      "\n",
      "Epoch 38. Loss: 0.011820324754501859, Train_acc 0.9888392857142857\n",
      "\n",
      "Epoch 38. Loss: 0.010954272030809951, Train_acc 0.9889322916666666\n",
      "\n",
      "Epoch 38. Loss: 0.013375717054920883, Train_acc 0.9888946280991735\n",
      "\n",
      "Epoch 38. Loss: 0.012531599584103367, Train_acc 0.9889856557377049\n",
      "\n",
      "Epoch 38. Loss: 0.01157163424470044, Train_acc 0.9890752032520326\n",
      "\n",
      "Epoch 38. Loss: 0.010806966754150542, Train_acc 0.9891633064516129\n",
      "\n",
      "Epoch 38. Loss: 0.009817344445090801, Train_acc 0.98925\n",
      "\n",
      "Epoch 38. Loss: 0.009410941878498773, Train_acc 0.9893353174603174\n",
      "\n",
      "Epoch 38. Loss: 0.012903143566436633, Train_acc 0.9892962598425197\n",
      "\n",
      "Epoch 38. Loss: 0.011816846549067256, Train_acc 0.9893798828125\n",
      "\n",
      "Epoch 38. Loss: 0.011056188802021763, Train_acc 0.9894622093023255\n",
      "\n",
      "Epoch 38. Loss: 0.010152700587822219, Train_acc 0.9895432692307692\n",
      "\n",
      "Epoch 38. Loss: 0.012936215217155118, Train_acc 0.989444179389313\n",
      "\n",
      "Epoch 38. Loss: 0.014555804795243054, Train_acc 0.9894649621212122\n",
      "\n",
      "Epoch 38. Loss: 0.016919542803958992, Train_acc 0.9894854323308271\n",
      "\n",
      "Epoch 38. Loss: 0.016171197664376444, Train_acc 0.9895055970149254\n",
      "\n",
      "Epoch 38. Loss: 0.014771707960191083, Train_acc 0.9895833333333334\n",
      "\n",
      "Epoch 38. Loss: 0.014866329900821488, Train_acc 0.9896024816176471\n",
      "\n",
      "Epoch 38. Loss: 0.013590896376878417, Train_acc 0.9896783759124088\n",
      "\n",
      "Epoch 38. Loss: 0.012592247690962611, Train_acc 0.9897531702898551\n",
      "\n",
      "Epoch 38. Loss: 0.01292680809605735, Train_acc 0.9897706834532374\n",
      "\n",
      "Epoch 38. Loss: 0.0132457810018237, Train_acc 0.9897321428571428\n",
      "\n",
      "Epoch 38. Loss: 0.012035077296087942, Train_acc 0.9898049645390071\n",
      "\n",
      "Epoch 38. Loss: 0.011586315197026551, Train_acc 0.9898767605633803\n",
      "\n",
      "Epoch 38. Loss: 0.011790332004227478, Train_acc 0.9898929195804196\n",
      "\n",
      "Epoch 38. Loss: 0.01151299973261199, Train_acc 0.9899631076388888\n",
      "\n",
      "Epoch 38. Loss: 0.010592154599116816, Train_acc 0.9900323275862069\n",
      "\n",
      "Epoch 38. Loss: 0.009701471935874886, Train_acc 0.9901005993150684\n",
      "\n",
      "Epoch 38. Loss: 0.01131499275073409, Train_acc 0.9901147959183674\n",
      "\n",
      "Epoch 38. Loss: 0.010874591636702418, Train_acc 0.9901815878378378\n",
      "\n",
      "Epoch 38. Loss: 0.010316386468078196, Train_acc 0.9902474832214765\n",
      "\n",
      "Epoch 38. Loss: 0.011090301034032257, Train_acc 0.9902604166666666\n",
      "\n",
      "Epoch 38. Loss: 0.011814403212528484, Train_acc 0.9902731788079471\n",
      "\n",
      "Epoch 38. Loss: 0.01216538322102522, Train_acc 0.9902857730263158\n",
      "\n",
      "Epoch 38. Loss: 0.011721352015121238, Train_acc 0.9903492647058824\n",
      "\n",
      "Epoch 38. Loss: 0.01078740798702102, Train_acc 0.9904119318181818\n",
      "\n",
      "Epoch 38. Loss: 0.015806042044790934, Train_acc 0.9903729838709677\n",
      "\n",
      "Epoch 38. Loss: 0.01469814849445136, Train_acc 0.9904346955128205\n",
      "\n",
      "Epoch 38. Loss: 0.0137010191068701, Train_acc 0.9904956210191083\n",
      "\n",
      "Epoch 38. Loss: 0.016092793943195228, Train_acc 0.9904568829113924\n",
      "\n",
      "Epoch 38. Loss: 0.014532453233506843, Train_acc 0.9905169025157232\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38. Loss: 0.016344700900769144, Train_acc 0.99052734375\n",
      "\n",
      "Epoch 38. Loss: 0.014930402638515153, Train_acc 0.9905861801242236\n",
      "\n",
      "Epoch 38. Loss: 0.014725119514316605, Train_acc 0.9905960648148148\n",
      "\n",
      "Epoch 38. Loss: 0.017159059846148152, Train_acc 0.9906058282208589\n",
      "\n",
      "Epoch 38. Loss: 0.01656151981614106, Train_acc 0.9906154725609756\n",
      "\n",
      "Epoch 38. Loss: 0.015567962123114525, Train_acc 0.990625\n",
      "\n",
      "Epoch 38. Loss: 0.014099213059695729, Train_acc 0.9906814759036144\n",
      "\n",
      "Epoch 38. Loss: 0.01610516949828163, Train_acc 0.9906904940119761\n",
      "\n",
      "Epoch 38. Loss: 0.01596099973248567, Train_acc 0.9906994047619048\n",
      "\n",
      "Epoch 38. Loss: 0.015319233172629407, Train_acc 0.9907544378698225\n",
      "\n",
      "Epoch 38. Loss: 0.01428196852296066, Train_acc 0.9908088235294118\n",
      "\n",
      "Epoch 38. Loss: 0.013389612398053453, Train_acc 0.9908625730994152\n",
      "\n",
      "Epoch 38. Loss: 0.013567647854839486, Train_acc 0.9908702761627907\n",
      "\n",
      "Epoch 38. Loss: 0.013452576528806735, Train_acc 0.9908778901734104\n",
      "\n",
      "Epoch 38. Loss: 0.013100382642435356, Train_acc 0.9908854166666666\n",
      "\n",
      "Epoch 38. Loss: 0.012335952257949702, Train_acc 0.9909375\n",
      "\n",
      "Epoch 38. Loss: 0.012634284599130088, Train_acc 0.9909889914772727\n",
      "\n",
      "Epoch 38. Loss: 0.01243893942922777, Train_acc 0.9909957627118644\n",
      "\n",
      "Epoch 38. Loss: 0.011868776390541428, Train_acc 0.9910463483146067\n",
      "\n",
      "Epoch 38. Loss: 0.013309246906270535, Train_acc 0.9910527234636871\n",
      "\n",
      "Epoch 38. Loss: 0.012398452213299231, Train_acc 0.9911024305555556\n",
      "\n",
      "Epoch 38. Loss: 0.012251148116641006, Train_acc 0.9911084254143646\n",
      "\n",
      "Epoch 38. Loss: 0.011798867315399135, Train_acc 0.9911572802197802\n",
      "\n",
      "Epoch 38. Loss: 0.016139112767887848, Train_acc 0.9911202185792349\n",
      "\n",
      "Epoch 38. Loss: 0.015780840947311584, Train_acc 0.9911684782608695\n",
      "\n",
      "Epoch 38. Loss: 0.015086180762125371, Train_acc 0.9912162162162163\n",
      "\n",
      "Epoch 38. Loss: 0.01469439065442084, Train_acc 0.991221438172043\n",
      "\n",
      "Epoch 38. Loss: 0.015586649478843202, Train_acc 0.9912683823529411\n",
      "\n",
      "Epoch 38. Loss: 0.01522868918004965, Train_acc 0.9913148271276596\n",
      "\n",
      "Epoch 38. Loss: 0.01411456926500799, Train_acc 0.9913607804232805\n",
      "\n",
      "Epoch 38. Loss: 0.013412384467968361, Train_acc 0.99140625\n",
      "\n",
      "Epoch 38. Loss: 0.014517076263709978, Train_acc 0.9913694371727748\n",
      "\n",
      "Epoch 38. Loss: 0.013487559791550741, Train_acc 0.9914143880208334\n",
      "\n",
      "Epoch 38. Loss: 0.01349146184204135, Train_acc 0.9914183937823834\n",
      "\n",
      "Epoch 38. Loss: 0.012550374271375956, Train_acc 0.9914626288659794\n",
      "\n",
      "Epoch 38. Loss: 0.012046414321127257, Train_acc 0.9915064102564103\n",
      "\n",
      "Epoch 38. Loss: 0.01820814404379969, Train_acc 0.99148\n",
      "\n",
      "Epoch 39. Loss: 0.016706013649254847, Train_acc 1.0\n",
      "\n",
      "Epoch 39. Loss: 0.017766562114253467, Train_acc 0.9921875\n",
      "\n",
      "Epoch 39. Loss: 0.018862724052454375, Train_acc 0.9921875\n",
      "\n",
      "Epoch 39. Loss: 0.02405585325949074, Train_acc 0.98828125\n",
      "\n",
      "Epoch 39. Loss: 0.03230576271289004, Train_acc 0.984375\n",
      "\n",
      "Epoch 39. Loss: 0.03163026694482636, Train_acc 0.9856770833333334\n",
      "\n",
      "Epoch 39. Loss: 0.03873622051500743, Train_acc 0.984375\n",
      "\n",
      "Epoch 39. Loss: 0.047443423851938234, Train_acc 0.98046875\n",
      "\n",
      "Epoch 39. Loss: 0.043919757024596204, Train_acc 0.9817708333333334\n",
      "\n",
      "Epoch 39. Loss: 0.04160753489984578, Train_acc 0.9828125\n",
      "\n",
      "Epoch 39. Loss: 0.040364873571278215, Train_acc 0.9829545454545454\n",
      "\n",
      "Epoch 39. Loss: 0.04591459229267975, Train_acc 0.9817708333333334\n",
      "\n",
      "Epoch 39. Loss: 0.043041785311794346, Train_acc 0.9819711538461539\n",
      "\n",
      "Epoch 39. Loss: 0.04165427737125403, Train_acc 0.9821428571428571\n",
      "\n",
      "Epoch 39. Loss: 0.041750812703567564, Train_acc 0.9817708333333334\n",
      "\n",
      "Epoch 39. Loss: 0.04486378133970304, Train_acc 0.9814453125\n",
      "\n",
      "Epoch 39. Loss: 0.04665412620315972, Train_acc 0.9802389705882353\n",
      "\n",
      "Epoch 39. Loss: 0.04517792454907319, Train_acc 0.9809027777777778\n",
      "\n",
      "Epoch 39. Loss: 0.04190262816741187, Train_acc 0.9819078947368421\n",
      "\n",
      "Epoch 39. Loss: 0.05024881210083472, Train_acc 0.98125\n",
      "\n",
      "Epoch 39. Loss: 0.06156684052486456, Train_acc 0.9795386904761905\n",
      "\n",
      "Epoch 39. Loss: 0.056107824369125696, Train_acc 0.98046875\n",
      "\n",
      "Epoch 39. Loss: 0.05196439811112267, Train_acc 0.9809782608695652\n",
      "\n",
      "Epoch 39. Loss: 0.04994026501645251, Train_acc 0.9811197916666666\n",
      "\n",
      "Epoch 39. Loss: 0.050964544457223454, Train_acc 0.9815625\n",
      "\n",
      "Epoch 39. Loss: 0.051809417672776976, Train_acc 0.9810697115384616\n",
      "\n",
      "Epoch 39. Loss: 0.04825957898899061, Train_acc 0.9814814814814815\n",
      "\n",
      "Epoch 39. Loss: 0.044466271095163906, Train_acc 0.9821428571428571\n",
      "\n",
      "Epoch 39. Loss: 0.04209545471610482, Train_acc 0.982489224137931\n",
      "\n",
      "Epoch 39. Loss: 0.04114020885534753, Train_acc 0.9828125\n",
      "\n",
      "Epoch 39. Loss: 0.04429669175899926, Train_acc 0.9826108870967742\n",
      "\n",
      "Epoch 39. Loss: 0.04527798625251862, Train_acc 0.982177734375\n",
      "\n",
      "Epoch 39. Loss: 0.04221231638569724, Train_acc 0.982717803030303\n",
      "\n",
      "Epoch 39. Loss: 0.03845029611337863, Train_acc 0.9832261029411765\n",
      "\n",
      "Epoch 39. Loss: 0.039376445835369964, Train_acc 0.9834821428571429\n",
      "\n",
      "Epoch 39. Loss: 0.039264558531825075, Train_acc 0.9832899305555556\n",
      "\n",
      "Epoch 39. Loss: 0.03724830525635272, Train_acc 0.9837415540540541\n",
      "\n",
      "Epoch 39. Loss: 0.036107904933559205, Train_acc 0.9839638157894737\n",
      "\n",
      "Epoch 39. Loss: 0.03345897023916301, Train_acc 0.984375\n",
      "\n",
      "Epoch 39. Loss: 0.030890432522059, Train_acc 0.984765625\n",
      "\n",
      "Epoch 39. Loss: 0.028486041654223665, Train_acc 0.9851371951219512\n",
      "\n",
      "Epoch 39. Loss: 0.027309028703636943, Train_acc 0.9853050595238095\n",
      "\n",
      "Epoch 39. Loss: 0.02538611158981951, Train_acc 0.9856468023255814\n",
      "\n",
      "Epoch 39. Loss: 0.0241760621652457, Train_acc 0.9857954545454546\n",
      "\n",
      "Epoch 39. Loss: 0.022418555224131307, Train_acc 0.9861111111111112\n",
      "\n",
      "Epoch 39. Loss: 0.022285351287595116, Train_acc 0.9862432065217391\n",
      "\n",
      "Epoch 39. Loss: 0.022930901838485913, Train_acc 0.9863696808510638\n",
      "\n",
      "Epoch 39. Loss: 0.020895496829802858, Train_acc 0.9866536458333334\n",
      "\n",
      "Epoch 39. Loss: 0.019375366057713388, Train_acc 0.9869260204081632\n",
      "\n",
      "Epoch 39. Loss: 0.018714459615134797, Train_acc 0.9871875\n",
      "\n",
      "Epoch 39. Loss: 0.018549504691824557, Train_acc 0.9872855392156863\n",
      "\n",
      "Epoch 39. Loss: 0.018407684473215263, Train_acc 0.9873798076923077\n",
      "\n",
      "Epoch 39. Loss: 0.01702273435117488, Train_acc 0.9876179245283019\n",
      "\n",
      "Epoch 39. Loss: 0.016485103078678412, Train_acc 0.9878472222222222\n",
      "\n",
      "Epoch 39. Loss: 0.01521814030937418, Train_acc 0.9880681818181818\n",
      "\n",
      "Epoch 39. Loss: 0.015345637090790851, Train_acc 0.98828125\n",
      "\n",
      "Epoch 39. Loss: 0.01572595213006906, Train_acc 0.9884868421052632\n",
      "\n",
      "Epoch 39. Loss: 0.015353575229504458, Train_acc 0.9885506465517241\n",
      "\n",
      "Epoch 39. Loss: 0.01433415858509429, Train_acc 0.9887447033898306\n",
      "\n",
      "Epoch 39. Loss: 0.013607171015998313, Train_acc 0.9889322916666666\n",
      "\n",
      "Epoch 39. Loss: 0.012620419462749888, Train_acc 0.9891137295081968\n",
      "\n",
      "Epoch 39. Loss: 0.011645444475319561, Train_acc 0.989289314516129\n",
      "\n",
      "Epoch 39. Loss: 0.011282090202903668, Train_acc 0.9894593253968254\n",
      "\n",
      "Epoch 39. Loss: 0.010554161017479824, Train_acc 0.9896240234375\n",
      "\n",
      "Epoch 39. Loss: 0.011918271977015431, Train_acc 0.9896634615384615\n",
      "\n",
      "Epoch 39. Loss: 0.011171917461208788, Train_acc 0.9898200757575758\n",
      "\n",
      "Epoch 39. Loss: 0.01059691391805019, Train_acc 0.9899720149253731\n",
      "\n",
      "Epoch 39. Loss: 0.010196294087194257, Train_acc 0.9901194852941176\n",
      "\n",
      "Epoch 39. Loss: 0.011022915570160318, Train_acc 0.9901494565217391\n",
      "\n",
      "Epoch 39. Loss: 0.010013506187211484, Train_acc 0.9902901785714285\n",
      "\n",
      "Epoch 39. Loss: 0.009372557660827945, Train_acc 0.9904269366197183\n",
      "\n",
      "Epoch 39. Loss: 0.009013284316709558, Train_acc 0.9905598958333334\n",
      "\n",
      "Epoch 39. Loss: 0.009007986642614828, Train_acc 0.9906892123287672\n",
      "\n",
      "Epoch 39. Loss: 0.00867662500346824, Train_acc 0.9908150337837838\n",
      "\n",
      "Epoch 39. Loss: 0.007912983202048758, Train_acc 0.9909375\n",
      "\n",
      "Epoch 39. Loss: 0.007219832916729408, Train_acc 0.9910567434210527\n",
      "\n",
      "Epoch 39. Loss: 0.006784696978038035, Train_acc 0.9911728896103896\n",
      "\n",
      "Epoch 39. Loss: 0.006508356907998457, Train_acc 0.9912860576923077\n",
      "\n",
      "Epoch 39. Loss: 0.0062963442093446256, Train_acc 0.9913963607594937\n",
      "\n",
      "Epoch 39. Loss: 0.006785087291417814, Train_acc 0.99140625\n",
      "\n",
      "Epoch 39. Loss: 0.007154838371889261, Train_acc 0.9914158950617284\n",
      "\n",
      "Epoch 39. Loss: 0.008315734456732692, Train_acc 0.9914253048780488\n",
      "\n",
      "Epoch 39. Loss: 0.007681964286719104, Train_acc 0.9915286144578314\n",
      "\n",
      "Epoch 39. Loss: 0.007341911793325251, Train_acc 0.9916294642857143\n",
      "\n",
      "Epoch 39. Loss: 0.006748432465410745, Train_acc 0.9917279411764706\n",
      "\n",
      "Epoch 39. Loss: 0.0075594764818398795, Train_acc 0.9917332848837209\n",
      "\n",
      "Epoch 39. Loss: 0.006959913621643809, Train_acc 0.9918283045977011\n",
      "\n",
      "Epoch 39. Loss: 0.007131410401582385, Train_acc 0.9918323863636364\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39. Loss: 0.006536904467324613, Train_acc 0.9919241573033708\n",
      "\n",
      "Epoch 39. Loss: 0.006442006261509834, Train_acc 0.9920138888888889\n",
      "\n",
      "Epoch 39. Loss: 0.0060538773872961206, Train_acc 0.9921016483516484\n",
      "\n",
      "Epoch 39. Loss: 0.007551141840682292, Train_acc 0.9920176630434783\n",
      "\n",
      "Epoch 39. Loss: 0.007052252983643887, Train_acc 0.9921034946236559\n",
      "\n",
      "Epoch 39. Loss: 0.006694048721129547, Train_acc 0.9921875\n",
      "\n",
      "Epoch 39. Loss: 0.006690214551420376, Train_acc 0.9922697368421053\n",
      "\n",
      "Epoch 39. Loss: 0.0062075493581165665, Train_acc 0.9923502604166666\n",
      "\n",
      "Epoch 39. Loss: 0.006218253712466639, Train_acc 0.9924291237113402\n",
      "\n",
      "Epoch 39. Loss: 0.006563335447559906, Train_acc 0.9924266581632653\n",
      "\n",
      "Epoch 39. Loss: 0.006128051362455028, Train_acc 0.9925031565656566\n",
      "\n",
      "Epoch 39. Loss: 0.005557132365870599, Train_acc 0.992578125\n",
      "\n",
      "[Epoch 39 Batch 100] Loss: 0.005793941112668625 Training: accuracy=0.992574\n",
      "Epoch 39. Loss: 0.005793941112668625, Train_acc 0.9925742574257426\n",
      "\n",
      "Epoch 39. Loss: 0.005252165169100146, Train_acc 0.9926470588235294\n",
      "\n",
      "Epoch 39. Loss: 0.005364501679089827, Train_acc 0.9927184466019418\n",
      "\n",
      "Epoch 39. Loss: 0.005183759272081103, Train_acc 0.9927884615384616\n",
      "\n",
      "Epoch 39. Loss: 0.004897367672420245, Train_acc 0.9928571428571429\n",
      "\n",
      "Epoch 39. Loss: 0.00445744234965633, Train_acc 0.9929245283018868\n",
      "\n",
      "Epoch 39. Loss: 0.004068848800151935, Train_acc 0.9929906542056075\n",
      "\n",
      "Epoch 39. Loss: 0.004454800876816563, Train_acc 0.9930555555555556\n",
      "\n",
      "Epoch 39. Loss: 0.0049045529376034016, Train_acc 0.9930475917431193\n",
      "\n",
      "Epoch 39. Loss: 0.004848738718232281, Train_acc 0.9931107954545455\n",
      "\n",
      "Epoch 39. Loss: 0.004385105735736654, Train_acc 0.9931728603603603\n",
      "\n",
      "Epoch 39. Loss: 0.006517273083338946, Train_acc 0.9930943080357143\n",
      "\n",
      "Epoch 39. Loss: 0.0061448327211750834, Train_acc 0.9931554203539823\n",
      "\n",
      "Epoch 39. Loss: 0.005724975657452341, Train_acc 0.9932154605263158\n",
      "\n",
      "Epoch 39. Loss: 0.00528216394531506, Train_acc 0.9932744565217392\n",
      "\n",
      "Epoch 39. Loss: 0.004845831114220121, Train_acc 0.9933324353448276\n",
      "\n",
      "Epoch 39. Loss: 0.004435125096180289, Train_acc 0.9933894230769231\n",
      "\n",
      "Epoch 39. Loss: 0.0042207132833047955, Train_acc 0.9934454449152542\n",
      "\n",
      "Epoch 39. Loss: 0.004476748166100167, Train_acc 0.993500525210084\n",
      "\n",
      "Epoch 39. Loss: 0.004068383459640986, Train_acc 0.9935546875\n",
      "\n",
      "Epoch 39. Loss: 0.00412877581922124, Train_acc 0.9936079545454546\n",
      "\n",
      "Epoch 39. Loss: 0.003951766203265579, Train_acc 0.9936603483606558\n",
      "\n",
      "Epoch 39. Loss: 0.0036786054363514703, Train_acc 0.9937118902439024\n",
      "\n",
      "Epoch 39. Loss: 0.004110047742634927, Train_acc 0.9936995967741935\n",
      "\n",
      "Epoch 39. Loss: 0.0059865671618967485, Train_acc 0.993625\n",
      "\n",
      "Epoch 39. Loss: 0.005509479241000643, Train_acc 0.9936755952380952\n",
      "\n",
      "Epoch 39. Loss: 0.005692008054414718, Train_acc 0.9937253937007874\n",
      "\n",
      "Epoch 39. Loss: 0.005287044867419596, Train_acc 0.9937744140625\n",
      "\n",
      "Epoch 39. Loss: 0.00503245196730053, Train_acc 0.9938226744186046\n",
      "\n",
      "Epoch 39. Loss: 0.004568143365071615, Train_acc 0.9938701923076924\n",
      "\n",
      "Epoch 39. Loss: 0.0043794653426808714, Train_acc 0.9939169847328244\n",
      "\n",
      "Epoch 39. Loss: 0.004512363434466952, Train_acc 0.9939630681818182\n",
      "\n",
      "Epoch 39. Loss: 0.004161631581567139, Train_acc 0.9940084586466166\n",
      "\n",
      "Epoch 39. Loss: 0.005932449080689917, Train_acc 0.9939948694029851\n",
      "\n",
      "Epoch 39. Loss: 0.005569504505971822, Train_acc 0.9940393518518519\n",
      "\n",
      "Epoch 39. Loss: 0.00665250842861511, Train_acc 0.9940257352941176\n",
      "\n",
      "Epoch 39. Loss: 0.006298621958945791, Train_acc 0.9940693430656934\n",
      "\n",
      "Epoch 39. Loss: 0.005815344371643305, Train_acc 0.9941123188405797\n",
      "\n",
      "Epoch 39. Loss: 0.005277506571045866, Train_acc 0.9941546762589928\n",
      "\n",
      "Epoch 39. Loss: 0.004824531436748893, Train_acc 0.9941964285714285\n",
      "\n",
      "Epoch 39. Loss: 0.007580087954510085, Train_acc 0.9941821808510638\n",
      "\n",
      "Epoch 39. Loss: 0.007026666723862736, Train_acc 0.9942231514084507\n",
      "\n",
      "Epoch 39. Loss: 0.006809661956735357, Train_acc 0.994263548951049\n",
      "\n",
      "Epoch 39. Loss: 0.008656021361447486, Train_acc 0.9941948784722222\n",
      "\n",
      "Epoch 39. Loss: 0.00813287768857668, Train_acc 0.9942349137931035\n",
      "\n",
      "Epoch 39. Loss: 0.00738225009416333, Train_acc 0.9942744006849316\n",
      "\n",
      "Epoch 39. Loss: 0.00717016739137284, Train_acc 0.994313350340136\n",
      "\n",
      "Epoch 39. Loss: 0.007015844249984433, Train_acc 0.9943517736486487\n",
      "\n",
      "Epoch 39. Loss: 0.009641300571794041, Train_acc 0.9943372483221476\n",
      "\n",
      "Epoch 39. Loss: 0.009872447136343773, Train_acc 0.994375\n",
      "\n",
      "Epoch 39. Loss: 0.009097031625890364, Train_acc 0.9944122516556292\n",
      "\n",
      "Epoch 39. Loss: 0.008338292604659018, Train_acc 0.9944490131578947\n",
      "\n",
      "Epoch 39. Loss: 0.007754007246657327, Train_acc 0.9944852941176471\n",
      "\n",
      "Epoch 39. Loss: 0.012567349985150203, Train_acc 0.9944703733766234\n",
      "\n",
      "Epoch 39. Loss: 0.011771976264483666, Train_acc 0.9945060483870968\n",
      "\n",
      "Epoch 39. Loss: 0.014603273700624943, Train_acc 0.9944411057692307\n",
      "\n",
      "Epoch 39. Loss: 0.015576728028908589, Train_acc 0.9944267515923567\n",
      "\n",
      "Epoch 39. Loss: 0.014147348007318572, Train_acc 0.9944620253164557\n",
      "\n",
      "Epoch 39. Loss: 0.012958135948262091, Train_acc 0.9944968553459119\n",
      "\n",
      "Epoch 39. Loss: 0.018630610477043518, Train_acc 0.9943359375\n",
      "\n",
      "Epoch 39. Loss: 0.018549583021801708, Train_acc 0.9943225931677019\n",
      "\n",
      "Epoch 39. Loss: 0.018772927669288515, Train_acc 0.9943094135802469\n",
      "\n",
      "Epoch 39. Loss: 0.01776404030406636, Train_acc 0.9943443251533742\n",
      "\n",
      "Epoch 39. Loss: 0.017766903279282112, Train_acc 0.9942835365853658\n",
      "\n",
      "Epoch 39. Loss: 0.02414832452361953, Train_acc 0.9941761363636363\n",
      "\n",
      "Epoch 39. Loss: 0.02717757357143019, Train_acc 0.994117093373494\n",
      "\n",
      "Epoch 39. Loss: 0.025357792784118545, Train_acc 0.9941523203592815\n",
      "\n",
      "Epoch 39. Loss: 0.023468686741748953, Train_acc 0.9941871279761905\n",
      "\n",
      "Epoch 39. Loss: 0.02548931041552976, Train_acc 0.9941752958579881\n",
      "\n",
      "Epoch 39. Loss: 0.023240703174160618, Train_acc 0.9942095588235295\n",
      "\n",
      "Epoch 39. Loss: 0.02417508802892569, Train_acc 0.9941977339181286\n",
      "\n",
      "Epoch 39. Loss: 0.022356151327477126, Train_acc 0.9942314680232558\n",
      "\n",
      "Epoch 39. Loss: 0.020376726201350597, Train_acc 0.9942648121387283\n",
      "\n",
      "Epoch 39. Loss: 0.024463137651540436, Train_acc 0.9942528735632183\n",
      "\n",
      "Epoch 39. Loss: 0.022811084742150545, Train_acc 0.9942857142857143\n",
      "\n",
      "Epoch 39. Loss: 0.02212946579289601, Train_acc 0.9942737926136364\n",
      "\n",
      "Epoch 39. Loss: 0.0209156433755055, Train_acc 0.9943061440677966\n",
      "\n",
      "Epoch 39. Loss: 0.019772940838089132, Train_acc 0.9942942415730337\n",
      "\n",
      "Epoch 39. Loss: 0.018275825032219778, Train_acc 0.9943261173184358\n",
      "\n",
      "Epoch 39. Loss: 0.01819940054293766, Train_acc 0.9943142361111111\n",
      "\n",
      "Epoch 39. Loss: 0.017258673050638686, Train_acc 0.9943456491712708\n",
      "\n",
      "Epoch 39. Loss: 0.015684108411046848, Train_acc 0.994376717032967\n",
      "\n",
      "Epoch 39. Loss: 0.014238702860457884, Train_acc 0.9944074453551912\n",
      "\n",
      "Epoch 39. Loss: 0.013423378674968947, Train_acc 0.9944378396739131\n",
      "\n",
      "Epoch 39. Loss: 0.013489149690078082, Train_acc 0.9944256756756756\n",
      "\n",
      "Epoch 39. Loss: 0.014531293113893017, Train_acc 0.9944136424731183\n",
      "\n",
      "Epoch 39. Loss: 0.013864184968053472, Train_acc 0.9944435160427807\n",
      "\n",
      "Epoch 39. Loss: 0.012918321630250668, Train_acc 0.9944730718085106\n",
      "\n",
      "Epoch 39. Loss: 0.01354739238252454, Train_acc 0.9944196428571429\n",
      "\n",
      "Epoch 39. Loss: 0.015500165919335602, Train_acc 0.9943667763157895\n",
      "\n",
      "Epoch 39. Loss: 0.01634391153592341, Train_acc 0.9943553664921466\n",
      "\n",
      "Epoch 39. Loss: 0.015438014357806498, Train_acc 0.994384765625\n",
      "\n",
      "Epoch 39. Loss: 0.014370114752967286, Train_acc 0.994413860103627\n",
      "\n",
      "Epoch 39. Loss: 0.013168667096967216, Train_acc 0.9944426546391752\n",
      "\n",
      "Epoch 39. Loss: 0.013207811271317049, Train_acc 0.9944310897435897\n",
      "\n",
      "Epoch 39. Loss: 0.011941810910553257, Train_acc 0.99444\n",
      "\n",
      "Epoch 40. Loss: 0.011184549747094976, Train_acc 1.0\n",
      "\n",
      "Epoch 40. Loss: 0.010168507729152263, Train_acc 1.0\n",
      "\n",
      "Epoch 40. Loss: 0.010446354032319267, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 40. Loss: 0.010055119832540881, Train_acc 0.998046875\n",
      "\n",
      "Epoch 40. Loss: 0.00936624816486418, Train_acc 0.9984375\n",
      "\n",
      "Epoch 40. Loss: 0.008840517652891695, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 40. Loss: 0.009075206885811048, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 40. Loss: 0.008779413695701682, Train_acc 0.998046875\n",
      "\n",
      "Epoch 40. Loss: 0.0111852471788842, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 40. Loss: 0.010180404560613797, Train_acc 0.996875\n",
      "\n",
      "Epoch 40. Loss: 0.012995126792950779, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 40. Loss: 0.012313039955866351, Train_acc 0.9967447916666666\n",
      "\n",
      "Epoch 40. Loss: 0.01238846050861956, Train_acc 0.9963942307692307\n",
      "\n",
      "Epoch 40. Loss: 0.011226188411022929, Train_acc 0.9966517857142857\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40. Loss: 0.010693103232344127, Train_acc 0.996875\n",
      "\n",
      "Epoch 40. Loss: 0.011062859699154024, Train_acc 0.99658203125\n",
      "\n",
      "Epoch 40. Loss: 0.010894464549443834, Train_acc 0.9967830882352942\n",
      "\n",
      "Epoch 40. Loss: 0.011604774569292408, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 40. Loss: 0.013101517438727207, Train_acc 0.9962993421052632\n",
      "\n",
      "Epoch 40. Loss: 0.012774123538885343, Train_acc 0.99609375\n",
      "\n",
      "Epoch 40. Loss: 0.011655049096122081, Train_acc 0.9962797619047619\n",
      "\n",
      "Epoch 40. Loss: 0.010587836774300512, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 40. Loss: 0.009828149390617887, Train_acc 0.9966032608695652\n",
      "\n",
      "Epoch 40. Loss: 0.010153242152094732, Train_acc 0.9964192708333334\n",
      "\n",
      "Epoch 40. Loss: 0.012380122647726439, Train_acc 0.99625\n",
      "\n",
      "Epoch 40. Loss: 0.011793744494954262, Train_acc 0.9963942307692307\n",
      "\n",
      "Epoch 40. Loss: 0.010658296643031698, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 40. Loss: 0.009683761637797338, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 40. Loss: 0.00913534396862124, Train_acc 0.9967672413793104\n",
      "\n",
      "Epoch 40. Loss: 0.008910962898434412, Train_acc 0.996875\n",
      "\n",
      "Epoch 40. Loss: 0.009405346587808025, Train_acc 0.9967237903225806\n",
      "\n",
      "Epoch 40. Loss: 0.00874487520241239, Train_acc 0.996826171875\n",
      "\n",
      "Epoch 40. Loss: 0.010251090326757714, Train_acc 0.9966856060606061\n",
      "\n",
      "Epoch 40. Loss: 0.009275444226011098, Train_acc 0.9967830882352942\n",
      "\n",
      "Epoch 40. Loss: 0.00893204278450709, Train_acc 0.996875\n",
      "\n",
      "Epoch 40. Loss: 0.008324647224819674, Train_acc 0.9969618055555556\n",
      "\n",
      "Epoch 40. Loss: 0.008071771316044939, Train_acc 0.997043918918919\n",
      "\n",
      "Epoch 40. Loss: 0.007324966006186675, Train_acc 0.9971217105263158\n",
      "\n",
      "Epoch 40. Loss: 0.006678541399723652, Train_acc 0.9971955128205128\n",
      "\n",
      "Epoch 40. Loss: 0.0060663291153301565, Train_acc 0.997265625\n",
      "\n",
      "Epoch 40. Loss: 0.006548375692545453, Train_acc 0.997141768292683\n",
      "\n",
      "Epoch 40. Loss: 0.0062115248984805456, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 40. Loss: 0.0057810282491932855, Train_acc 0.9972747093023255\n",
      "\n",
      "Epoch 40. Loss: 0.006997342999275674, Train_acc 0.9969815340909091\n",
      "\n",
      "Epoch 40. Loss: 0.00718440613865508, Train_acc 0.9970486111111111\n",
      "\n",
      "Epoch 40. Loss: 0.0074386845496563925, Train_acc 0.9969429347826086\n",
      "\n",
      "Epoch 40. Loss: 0.01001928117578645, Train_acc 0.9966755319148937\n",
      "\n",
      "Epoch 40. Loss: 0.009302472761247332, Train_acc 0.9967447916666666\n",
      "\n",
      "Epoch 40. Loss: 0.009117238655066886, Train_acc 0.9968112244897959\n",
      "\n",
      "Epoch 40. Loss: 0.012772151471116898, Train_acc 0.99671875\n",
      "\n",
      "Epoch 40. Loss: 0.012303699828033528, Train_acc 0.9966299019607843\n",
      "\n",
      "Epoch 40. Loss: 0.011110250091432674, Train_acc 0.9966947115384616\n",
      "\n",
      "Epoch 40. Loss: 0.010365405844937989, Train_acc 0.9967570754716981\n",
      "\n",
      "Epoch 40. Loss: 0.009444919555075076, Train_acc 0.9968171296296297\n",
      "\n",
      "Epoch 40. Loss: 0.008652179954144752, Train_acc 0.996875\n",
      "\n",
      "Epoch 40. Loss: 0.007919371732962933, Train_acc 0.9969308035714286\n",
      "\n",
      "Epoch 40. Loss: 0.007784027778112417, Train_acc 0.996984649122807\n",
      "\n",
      "Epoch 40. Loss: 0.00762093594864326, Train_acc 0.9970366379310345\n",
      "\n",
      "Epoch 40. Loss: 0.00799899036015854, Train_acc 0.9969544491525424\n",
      "\n",
      "Epoch 40. Loss: 0.014810486742786637, Train_acc 0.9966145833333333\n",
      "\n",
      "Epoch 40. Loss: 0.013489431836246317, Train_acc 0.9966700819672131\n",
      "\n",
      "Epoch 40. Loss: 0.017117569996153294, Train_acc 0.9964717741935484\n",
      "\n",
      "Epoch 40. Loss: 0.02994829727998523, Train_acc 0.9957837301587301\n",
      "\n",
      "Epoch 40. Loss: 0.027344378188620344, Train_acc 0.995849609375\n",
      "\n",
      "Epoch 40. Loss: 0.030148201679024402, Train_acc 0.9957932692307693\n",
      "\n",
      "Epoch 40. Loss: 0.035402281726747725, Train_acc 0.9953835227272727\n",
      "\n",
      "Epoch 40. Loss: 0.035964392032042124, Train_acc 0.9952192164179104\n",
      "\n",
      "Epoch 40. Loss: 0.032442528612057105, Train_acc 0.9952895220588235\n",
      "\n",
      "Epoch 40. Loss: 0.029309388901921123, Train_acc 0.9953577898550725\n",
      "\n",
      "Epoch 40. Loss: 0.027315438287227163, Train_acc 0.9954241071428571\n",
      "\n",
      "Epoch 40. Loss: 0.02467934944610862, Train_acc 0.9954885563380281\n",
      "\n",
      "Epoch 40. Loss: 0.022515307176353645, Train_acc 0.9955512152777778\n",
      "\n",
      "Epoch 40. Loss: 0.020802101023413642, Train_acc 0.9956121575342466\n",
      "\n",
      "Epoch 40. Loss: 0.018791175301951533, Train_acc 0.9956714527027027\n",
      "\n",
      "Epoch 40. Loss: 0.017334501500650377, Train_acc 0.9957291666666667\n",
      "\n",
      "Epoch 40. Loss: 0.015764655029396682, Train_acc 0.9957853618421053\n",
      "\n",
      "Epoch 40. Loss: 0.01906311744954032, Train_acc 0.9957386363636364\n",
      "\n",
      "Epoch 40. Loss: 0.019251017133943817, Train_acc 0.9956931089743589\n",
      "\n",
      "Epoch 40. Loss: 0.018179027387993856, Train_acc 0.9956487341772152\n",
      "\n",
      "Epoch 40. Loss: 0.016865838247833245, Train_acc 0.995703125\n",
      "\n",
      "Epoch 40. Loss: 0.018151894333926673, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 40. Loss: 0.016509180719078632, Train_acc 0.9957126524390244\n",
      "\n",
      "Epoch 40. Loss: 0.014956330890994714, Train_acc 0.9957643072289156\n",
      "\n",
      "Epoch 40. Loss: 0.014222379317618711, Train_acc 0.9958147321428571\n",
      "\n",
      "Epoch 40. Loss: 0.0137087477921581, Train_acc 0.9958639705882353\n",
      "\n",
      "Epoch 40. Loss: 0.012950186173615074, Train_acc 0.9959120639534884\n",
      "\n",
      "Epoch 40. Loss: 0.011926877029125883, Train_acc 0.9959590517241379\n",
      "\n",
      "Epoch 40. Loss: 0.011163552269609266, Train_acc 0.9960049715909091\n",
      "\n",
      "Epoch 40. Loss: 0.01034752307800635, Train_acc 0.9960498595505618\n",
      "\n",
      "Epoch 40. Loss: 0.009396830967901804, Train_acc 0.99609375\n",
      "\n",
      "Epoch 40. Loss: 0.008891900750775925, Train_acc 0.9961366758241759\n",
      "\n",
      "Epoch 40. Loss: 0.008048729146009872, Train_acc 0.9961786684782609\n",
      "\n",
      "Epoch 40. Loss: 0.00775906560263293, Train_acc 0.9962197580645161\n",
      "\n",
      "Epoch 40. Loss: 0.007090246621459785, Train_acc 0.9962599734042553\n",
      "\n",
      "Epoch 40. Loss: 0.006693904270364401, Train_acc 0.9962993421052632\n",
      "\n",
      "Epoch 40. Loss: 0.006948117709577284, Train_acc 0.9962565104166666\n",
      "\n",
      "Epoch 40. Loss: 0.006588084064017417, Train_acc 0.9962951030927835\n",
      "\n",
      "Epoch 40. Loss: 0.007858053836605563, Train_acc 0.9962531887755102\n",
      "\n",
      "Epoch 40. Loss: 0.007598003282813681, Train_acc 0.9962910353535354\n",
      "\n",
      "Epoch 40. Loss: 0.007311043341906476, Train_acc 0.996328125\n",
      "\n",
      "[Epoch 40 Batch 100] Loss: 0.006617804360067047 Training: accuracy=0.996364\n",
      "Epoch 40. Loss: 0.006617804360067047, Train_acc 0.9963644801980198\n",
      "\n",
      "Epoch 40. Loss: 0.006049616278156815, Train_acc 0.9964001225490197\n",
      "\n",
      "Epoch 40. Loss: 0.005484887998022485, Train_acc 0.996435072815534\n",
      "\n",
      "Epoch 40. Loss: 0.005820078197018368, Train_acc 0.9963942307692307\n",
      "\n",
      "Epoch 40. Loss: 0.005515847137365696, Train_acc 0.9964285714285714\n",
      "\n",
      "Epoch 40. Loss: 0.005768842054123244, Train_acc 0.9964622641509434\n",
      "\n",
      "Epoch 40. Loss: 0.005600882266281153, Train_acc 0.9964953271028038\n",
      "\n",
      "Epoch 40. Loss: 0.005307186661796069, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 40. Loss: 0.005131278520348337, Train_acc 0.9965596330275229\n",
      "\n",
      "Epoch 40. Loss: 0.006330147685577869, Train_acc 0.9965198863636363\n",
      "\n",
      "Epoch 40. Loss: 0.006664704522017001, Train_acc 0.9964808558558559\n",
      "\n",
      "Epoch 40. Loss: 0.007484381171783828, Train_acc 0.9964425223214286\n",
      "\n",
      "Epoch 40. Loss: 0.009333119896996936, Train_acc 0.9964048672566371\n",
      "\n",
      "Epoch 40. Loss: 0.008474966733372738, Train_acc 0.9964364035087719\n",
      "\n",
      "Epoch 40. Loss: 0.007869440587021288, Train_acc 0.9964673913043478\n",
      "\n",
      "Epoch 40. Loss: 0.0072927681876263405, Train_acc 0.9964978448275862\n",
      "\n",
      "Epoch 40. Loss: 0.006791937275987093, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 40. Loss: 0.0062202868818219525, Train_acc 0.9965572033898306\n",
      "\n",
      "Epoch 40. Loss: 0.006746038015989306, Train_acc 0.9965204831932774\n",
      "\n",
      "Epoch 40. Loss: 0.006559518163702943, Train_acc 0.9965494791666667\n",
      "\n",
      "Epoch 40. Loss: 0.006034978104652814, Train_acc 0.9965779958677686\n",
      "\n",
      "Epoch 40. Loss: 0.00574642266901301, Train_acc 0.9966060450819673\n",
      "\n",
      "Epoch 40. Loss: 0.008290395627069175, Train_acc 0.9965701219512195\n",
      "\n",
      "Epoch 40. Loss: 0.00927000350324604, Train_acc 0.9965347782258065\n",
      "\n",
      "Epoch 40. Loss: 0.009918435125663518, Train_acc 0.9964375\n",
      "\n",
      "Epoch 40. Loss: 0.009462464191718077, Train_acc 0.9964657738095238\n",
      "\n",
      "Epoch 40. Loss: 0.008680029892991343, Train_acc 0.9964936023622047\n",
      "\n",
      "Epoch 40. Loss: 0.00829220397091242, Train_acc 0.99652099609375\n",
      "\n",
      "Epoch 40. Loss: 0.007485966940037244, Train_acc 0.9965479651162791\n",
      "\n",
      "Epoch 40. Loss: 0.0081000934512721, Train_acc 0.9965144230769231\n",
      "\n",
      "Epoch 40. Loss: 0.007450861686603561, Train_acc 0.9965410305343512\n",
      "\n",
      "Epoch 40. Loss: 0.0067599224319876, Train_acc 0.9965672348484849\n",
      "\n",
      "Epoch 40. Loss: 0.00633763698674626, Train_acc 0.9965930451127819\n",
      "\n",
      "Epoch 40. Loss: 0.006315630588865759, Train_acc 0.9966184701492538\n",
      "\n",
      "Epoch 40. Loss: 0.006212373112681343, Train_acc 0.9966435185185185\n",
      "\n",
      "Epoch 40. Loss: 0.011136342914440782, Train_acc 0.9965533088235294\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40. Loss: 0.012405966630463498, Train_acc 0.9964644160583942\n",
      "\n",
      "Epoch 40. Loss: 0.012890888670877843, Train_acc 0.9964334239130435\n",
      "\n",
      "Epoch 40. Loss: 0.012296851941388454, Train_acc 0.9964590827338129\n",
      "\n",
      "Epoch 40. Loss: 0.013361492203272825, Train_acc 0.9964285714285714\n",
      "\n",
      "Epoch 40. Loss: 0.012714407694277863, Train_acc 0.9963984929078015\n",
      "\n",
      "Epoch 40. Loss: 0.014663837643210024, Train_acc 0.996368838028169\n",
      "\n",
      "Epoch 40. Loss: 0.013272854825550852, Train_acc 0.9963942307692307\n",
      "\n",
      "Epoch 40. Loss: 0.012681924891720299, Train_acc 0.9964192708333334\n",
      "\n",
      "Epoch 40. Loss: 0.013496416479870753, Train_acc 0.9963900862068965\n",
      "\n",
      "Epoch 40. Loss: 0.014851278405360945, Train_acc 0.996361301369863\n",
      "\n",
      "Epoch 40. Loss: 0.014796080894147665, Train_acc 0.9963329081632653\n",
      "\n",
      "Epoch 40. Loss: 0.014315384066291433, Train_acc 0.9963576858108109\n",
      "\n",
      "Epoch 40. Loss: 0.01851257266359429, Train_acc 0.9962248322147651\n",
      "\n",
      "Epoch 40. Loss: 0.017545469277413787, Train_acc 0.9961979166666667\n",
      "\n",
      "Epoch 40. Loss: 0.01628669129347393, Train_acc 0.9962230960264901\n",
      "\n",
      "Epoch 40. Loss: 0.014760593911392294, Train_acc 0.9962479440789473\n",
      "\n",
      "Epoch 40. Loss: 0.020809927887066725, Train_acc 0.9962214052287581\n",
      "\n",
      "Epoch 40. Loss: 0.019579543298194876, Train_acc 0.996195211038961\n",
      "\n",
      "Epoch 40. Loss: 0.017966361931228702, Train_acc 0.9962197580645161\n",
      "\n",
      "Epoch 40. Loss: 0.025929826132593214, Train_acc 0.99609375\n",
      "\n",
      "Epoch 40. Loss: 0.024583440299008184, Train_acc 0.9960688694267515\n",
      "\n",
      "Epoch 40. Loss: 0.026970317982292675, Train_acc 0.9960443037974683\n",
      "\n",
      "Epoch 40. Loss: 0.029800292273750757, Train_acc 0.995872641509434\n",
      "\n",
      "Epoch 40. Loss: 0.02752017519769745, Train_acc 0.9958984375\n",
      "\n",
      "Epoch 40. Loss: 0.0251364043003113, Train_acc 0.9959239130434783\n",
      "\n",
      "Epoch 40. Loss: 0.023012712916355517, Train_acc 0.9959490740740741\n",
      "\n",
      "Epoch 40. Loss: 0.021167283512462248, Train_acc 0.9959739263803681\n",
      "\n",
      "Epoch 40. Loss: 0.0226326058125279, Train_acc 0.9959032012195121\n",
      "\n",
      "Epoch 40. Loss: 0.021512646509627847, Train_acc 0.9959280303030303\n",
      "\n",
      "Epoch 40. Loss: 0.020363630328405217, Train_acc 0.9959054969879518\n",
      "\n",
      "Epoch 40. Loss: 0.026027917689527558, Train_acc 0.9958364520958084\n",
      "\n",
      "Epoch 40. Loss: 0.03780142202357544, Train_acc 0.9957217261904762\n",
      "\n",
      "Epoch 40. Loss: 0.03428265703846598, Train_acc 0.9957470414201184\n",
      "\n",
      "Epoch 40. Loss: 0.031005687131587426, Train_acc 0.9957720588235294\n",
      "\n",
      "Epoch 40. Loss: 0.030669118044469142, Train_acc 0.9957054093567251\n",
      "\n",
      "Epoch 40. Loss: 0.02980925149711375, Train_acc 0.9956395348837209\n",
      "\n",
      "Epoch 40. Loss: 0.0394992724686182, Train_acc 0.9955292630057804\n",
      "\n",
      "Epoch 40. Loss: 0.041576121356724186, Train_acc 0.995465158045977\n",
      "\n",
      "Epoch 40. Loss: 0.04994391421077116, Train_acc 0.9952678571428571\n",
      "\n",
      "Epoch 40. Loss: 0.05889601724979994, Train_acc 0.9951615767045454\n",
      "\n",
      "Epoch 40. Loss: 0.053242425144950006, Train_acc 0.9951889124293786\n",
      "\n",
      "Epoch 40. Loss: 0.048297388311838614, Train_acc 0.995215941011236\n",
      "\n",
      "Epoch 40. Loss: 0.05650826807911591, Train_acc 0.9949807960893855\n",
      "\n",
      "Epoch 40. Loss: 0.06024133502926287, Train_acc 0.9947482638888889\n",
      "\n",
      "Epoch 40. Loss: 0.05789460768836013, Train_acc 0.994690953038674\n",
      "\n",
      "Epoch 40. Loss: 0.05641453665975277, Train_acc 0.9946771978021978\n",
      "\n",
      "Epoch 40. Loss: 0.06821053805187534, Train_acc 0.9944074453551912\n",
      "\n",
      "Epoch 40. Loss: 0.0756412319740819, Train_acc 0.9940981657608695\n",
      "\n",
      "Epoch 40. Loss: 0.07288857898722592, Train_acc 0.9940033783783784\n",
      "\n",
      "Epoch 40. Loss: 0.08079659582624289, Train_acc 0.9937415994623656\n",
      "\n",
      "Epoch 40. Loss: 0.08939620531901228, Train_acc 0.9933572860962567\n",
      "\n",
      "Epoch 40. Loss: 0.08091936423641004, Train_acc 0.993392619680851\n",
      "\n",
      "Epoch 40. Loss: 0.07685061691041194, Train_acc 0.9933449074074074\n",
      "\n",
      "Epoch 40. Loss: 0.07301342917533579, Train_acc 0.9932565789473684\n",
      "\n",
      "Epoch 40. Loss: 0.07406402170406458, Train_acc 0.993128272251309\n",
      "\n",
      "Epoch 40. Loss: 0.0703397791661025, Train_acc 0.9930826822916666\n",
      "\n",
      "Epoch 40. Loss: 0.07624181369637259, Train_acc 0.9929161269430051\n",
      "\n",
      "Epoch 40. Loss: 0.07348512233520872, Train_acc 0.9928318298969072\n",
      "\n",
      "Epoch 40. Loss: 0.07083948959015603, Train_acc 0.9928285256410256\n",
      "\n",
      "Epoch 40. Loss: 0.06449840514677282, Train_acc 0.99284\n",
      "\n",
      "Epoch 41. Loss: 0.06489173292056485, Train_acc 0.984375\n",
      "\n",
      "Epoch 41. Loss: 0.0599307854676464, Train_acc 0.98828125\n",
      "\n",
      "Epoch 41. Loss: 0.055733486834545626, Train_acc 0.9921875\n",
      "\n",
      "Epoch 41. Loss: 0.055293943575066055, Train_acc 0.98828125\n",
      "\n",
      "Epoch 41. Loss: 0.053640578172542204, Train_acc 0.9859375\n",
      "\n",
      "Epoch 41. Loss: 0.049032527415696574, Train_acc 0.98828125\n",
      "\n",
      "Epoch 41. Loss: 0.04944781128353816, Train_acc 0.9866071428571429\n",
      "\n",
      "Epoch 41. Loss: 0.04672241357374437, Train_acc 0.986328125\n",
      "\n",
      "Epoch 41. Loss: 0.04661334586806518, Train_acc 0.9861111111111112\n",
      "\n",
      "Epoch 41. Loss: 0.044229905599362455, Train_acc 0.9859375\n",
      "\n",
      "Epoch 41. Loss: 0.043889506871110325, Train_acc 0.9850852272727273\n",
      "\n",
      "Epoch 41. Loss: 0.041551687052493805, Train_acc 0.9856770833333334\n",
      "\n",
      "Epoch 41. Loss: 0.037849527244846984, Train_acc 0.9867788461538461\n",
      "\n",
      "Epoch 41. Loss: 0.03753107150949326, Train_acc 0.9866071428571429\n",
      "\n",
      "Epoch 41. Loss: 0.03676752528301436, Train_acc 0.9869791666666666\n",
      "\n",
      "Epoch 41. Loss: 0.0339368457861384, Train_acc 0.98779296875\n",
      "\n",
      "Epoch 41. Loss: 0.03125901918457212, Train_acc 0.9885110294117647\n",
      "\n",
      "Epoch 41. Loss: 0.028649730280157288, Train_acc 0.9891493055555556\n",
      "\n",
      "Epoch 41. Loss: 0.027969746741756524, Train_acc 0.9893092105263158\n",
      "\n",
      "Epoch 41. Loss: 0.027775935637746507, Train_acc 0.989453125\n",
      "\n",
      "Epoch 41. Loss: 0.026069478984440196, Train_acc 0.9899553571428571\n",
      "\n",
      "Epoch 41. Loss: 0.026570449326126126, Train_acc 0.9897017045454546\n",
      "\n",
      "Epoch 41. Loss: 0.02595606320681126, Train_acc 0.9898097826086957\n",
      "\n",
      "Epoch 41. Loss: 0.026217651168244642, Train_acc 0.9899088541666666\n",
      "\n",
      "Epoch 41. Loss: 0.024051464002344813, Train_acc 0.9903125\n",
      "\n",
      "Epoch 41. Loss: 0.022537515633714623, Train_acc 0.9903846153846154\n",
      "\n",
      "Epoch 41. Loss: 0.02088631897277751, Train_acc 0.9907407407407407\n",
      "\n",
      "Epoch 41. Loss: 0.0190579666359614, Train_acc 0.9910714285714286\n",
      "\n",
      "Epoch 41. Loss: 0.023126353203957437, Train_acc 0.9905711206896551\n",
      "\n",
      "Epoch 41. Loss: 0.0266845585820423, Train_acc 0.9903645833333333\n",
      "\n",
      "Epoch 41. Loss: 0.02436108928552387, Train_acc 0.9906754032258065\n",
      "\n",
      "Epoch 41. Loss: 0.02310116384146617, Train_acc 0.99072265625\n",
      "\n",
      "Epoch 41. Loss: 0.022768600862187204, Train_acc 0.9907670454545454\n",
      "\n",
      "Epoch 41. Loss: 0.021350558956827574, Train_acc 0.9910386029411765\n",
      "\n",
      "Epoch 41. Loss: 0.02553393813404368, Train_acc 0.9901785714285715\n",
      "\n",
      "Epoch 41. Loss: 0.024789874418970285, Train_acc 0.990234375\n",
      "\n",
      "Epoch 41. Loss: 0.023753664063122577, Train_acc 0.9902871621621622\n",
      "\n",
      "Epoch 41. Loss: 0.022147953808343446, Train_acc 0.9905427631578947\n",
      "\n",
      "Epoch 41. Loss: 0.023356173828276428, Train_acc 0.9903846153846154\n",
      "\n",
      "Epoch 41. Loss: 0.022388477082579523, Train_acc 0.990625\n",
      "\n",
      "Epoch 41. Loss: 0.02199728395539152, Train_acc 0.9906631097560976\n",
      "\n",
      "Epoch 41. Loss: 0.021284551282950884, Train_acc 0.9906994047619048\n",
      "\n",
      "Epoch 41. Loss: 0.019729766972194893, Train_acc 0.9909156976744186\n",
      "\n",
      "Epoch 41. Loss: 0.01862173897981416, Train_acc 0.9911221590909091\n",
      "\n",
      "Epoch 41. Loss: 0.018915608507035112, Train_acc 0.9911458333333333\n",
      "\n",
      "Epoch 41. Loss: 0.020083224384460988, Train_acc 0.9911684782608695\n",
      "\n",
      "Epoch 41. Loss: 0.01938711701346112, Train_acc 0.9913563829787234\n",
      "\n",
      "Epoch 41. Loss: 0.018679393591100033, Train_acc 0.9913736979166666\n",
      "\n",
      "Epoch 41. Loss: 0.017862270708335095, Train_acc 0.9915497448979592\n",
      "\n",
      "Epoch 41. Loss: 0.0171820788812214, Train_acc 0.9915625\n",
      "\n",
      "Epoch 41. Loss: 0.01631736536159282, Train_acc 0.9915747549019608\n",
      "\n",
      "Epoch 41. Loss: 0.015555946977443978, Train_acc 0.9917367788461539\n",
      "\n",
      "Epoch 41. Loss: 0.016366408572948712, Train_acc 0.9915978773584906\n",
      "\n",
      "Epoch 41. Loss: 0.017214695973417227, Train_acc 0.9914641203703703\n",
      "\n",
      "Epoch 41. Loss: 0.016197749179501293, Train_acc 0.9916193181818181\n",
      "\n",
      "Epoch 41. Loss: 0.015445179002194666, Train_acc 0.9917689732142857\n",
      "\n",
      "Epoch 41. Loss: 0.014969215548076387, Train_acc 0.9917763157894737\n",
      "\n",
      "Epoch 41. Loss: 0.014879496699009677, Train_acc 0.9919181034482759\n",
      "\n",
      "Epoch 41. Loss: 0.013734636323728568, Train_acc 0.9920550847457628\n",
      "\n",
      "Epoch 41. Loss: 0.012492993869721209, Train_acc 0.9921875\n",
      "\n",
      "Epoch 41. Loss: 0.012391211951529368, Train_acc 0.9921875\n",
      "\n",
      "Epoch 41. Loss: 0.011317743810513215, Train_acc 0.9923135080645161\n",
      "\n",
      "Epoch 41. Loss: 0.010940321110560236, Train_acc 0.9924355158730159\n",
      "\n",
      "Epoch 41. Loss: 0.010817365450746182, Train_acc 0.9925537109375\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41. Loss: 0.010556331965106455, Train_acc 0.9926682692307692\n",
      "\n",
      "Epoch 41. Loss: 0.011309595243136045, Train_acc 0.9926609848484849\n",
      "\n",
      "Epoch 41. Loss: 0.010349134549088737, Train_acc 0.9927705223880597\n",
      "\n",
      "Epoch 41. Loss: 0.009886000069607015, Train_acc 0.9928768382352942\n",
      "\n",
      "Epoch 41. Loss: 0.00965006828505878, Train_acc 0.9929800724637681\n",
      "\n",
      "Epoch 41. Loss: 0.00876854231339992, Train_acc 0.9930803571428571\n",
      "\n",
      "Epoch 41. Loss: 0.008304013643106527, Train_acc 0.9931778169014085\n",
      "\n",
      "Epoch 41. Loss: 0.007775014131425954, Train_acc 0.9932725694444444\n",
      "\n",
      "Epoch 41. Loss: 0.007521186275028411, Train_acc 0.9933647260273972\n",
      "\n",
      "Epoch 41. Loss: 0.0069933292853026595, Train_acc 0.9934543918918919\n",
      "\n",
      "Epoch 41. Loss: 0.007479915794329852, Train_acc 0.9934375\n",
      "\n",
      "Epoch 41. Loss: 0.007582448968229005, Train_acc 0.9935238486842105\n",
      "\n",
      "Epoch 41. Loss: 0.009530102579835633, Train_acc 0.9934050324675324\n",
      "\n",
      "Epoch 41. Loss: 0.008791373674088937, Train_acc 0.9934895833333334\n",
      "\n",
      "Epoch 41. Loss: 0.008091094676734557, Train_acc 0.9935719936708861\n",
      "\n",
      "Epoch 41. Loss: 0.007391539919859067, Train_acc 0.99365234375\n",
      "\n",
      "Epoch 41. Loss: 0.006922906427780594, Train_acc 0.9937307098765432\n",
      "\n",
      "Epoch 41. Loss: 0.006543809997506266, Train_acc 0.9938071646341463\n",
      "\n",
      "Epoch 41. Loss: 0.0059929403098007965, Train_acc 0.9938817771084337\n",
      "\n",
      "Epoch 41. Loss: 0.00594435487262138, Train_acc 0.9939546130952381\n",
      "\n",
      "Epoch 41. Loss: 0.006509312986478761, Train_acc 0.9940257352941176\n",
      "\n",
      "Epoch 41. Loss: 0.006021044241897514, Train_acc 0.9940952034883721\n",
      "\n",
      "Epoch 41. Loss: 0.00625603732095264, Train_acc 0.994073275862069\n",
      "\n",
      "Epoch 41. Loss: 0.010632532864446365, Train_acc 0.9940518465909091\n",
      "\n",
      "Epoch 41. Loss: 0.012458415616722337, Train_acc 0.9940308988764045\n",
      "\n",
      "Epoch 41. Loss: 0.012571256344769684, Train_acc 0.9940104166666667\n",
      "\n",
      "Epoch 41. Loss: 0.011863878272328633, Train_acc 0.9940762362637363\n",
      "\n",
      "Epoch 41. Loss: 0.011706193132567875, Train_acc 0.9940557065217391\n",
      "\n",
      "Epoch 41. Loss: 0.011357363452793782, Train_acc 0.9940356182795699\n",
      "\n",
      "Epoch 41. Loss: 0.01026709164462086, Train_acc 0.9940990691489362\n",
      "\n",
      "Epoch 41. Loss: 0.00937731677079883, Train_acc 0.9941611842105263\n",
      "\n",
      "Epoch 41. Loss: 0.00879506523938197, Train_acc 0.9942220052083334\n",
      "\n",
      "Epoch 41. Loss: 0.008056666052993102, Train_acc 0.9942815721649485\n",
      "\n",
      "Epoch 41. Loss: 0.007572196049419906, Train_acc 0.9943399234693877\n",
      "\n",
      "Epoch 41. Loss: 0.006953812169852435, Train_acc 0.9943970959595959\n",
      "\n",
      "Epoch 41. Loss: 0.00637009056909911, Train_acc 0.994453125\n",
      "\n",
      "[Epoch 41 Batch 100] Loss: 0.006096653547174026 Training: accuracy=0.994508\n",
      "Epoch 41. Loss: 0.006096653547174026, Train_acc 0.9945080445544554\n",
      "\n",
      "Epoch 41. Loss: 0.006274446295606753, Train_acc 0.9945618872549019\n",
      "\n",
      "Epoch 41. Loss: 0.006805186876125033, Train_acc 0.9945388349514563\n",
      "\n",
      "Epoch 41. Loss: 0.006632394103452768, Train_acc 0.9945913461538461\n",
      "\n",
      "Epoch 41. Loss: 0.00614442819302473, Train_acc 0.9946428571428572\n",
      "\n",
      "Epoch 41. Loss: 0.005742227408917489, Train_acc 0.9946933962264151\n",
      "\n",
      "Epoch 41. Loss: 0.005527077576784857, Train_acc 0.9947429906542056\n",
      "\n",
      "Epoch 41. Loss: 0.0059091690208928896, Train_acc 0.9947193287037037\n",
      "\n",
      "Epoch 41. Loss: 0.005879141046233515, Train_acc 0.9947677752293578\n",
      "\n",
      "Epoch 41. Loss: 0.005849122225756234, Train_acc 0.994815340909091\n",
      "\n",
      "Epoch 41. Loss: 0.005294797232592659, Train_acc 0.9948620495495496\n",
      "\n",
      "Epoch 41. Loss: 0.004831330293706408, Train_acc 0.9949079241071429\n",
      "\n",
      "Epoch 41. Loss: 0.004922006429843323, Train_acc 0.9949529867256637\n",
      "\n",
      "Epoch 41. Loss: 0.0047090761787702586, Train_acc 0.9949972587719298\n",
      "\n",
      "Epoch 41. Loss: 0.004340087602374101, Train_acc 0.9950407608695652\n",
      "\n",
      "Epoch 41. Loss: 0.004125819327909182, Train_acc 0.9950835129310345\n",
      "\n",
      "Epoch 41. Loss: 0.004386456770430592, Train_acc 0.9950587606837606\n",
      "\n",
      "Epoch 41. Loss: 0.004054183172268201, Train_acc 0.9951006355932204\n",
      "\n",
      "Epoch 41. Loss: 0.003831627050693359, Train_acc 0.995141806722689\n",
      "\n",
      "Epoch 41. Loss: 0.004272612367262417, Train_acc 0.9951822916666667\n",
      "\n",
      "Epoch 41. Loss: 0.003940741210777662, Train_acc 0.9952221074380165\n",
      "\n",
      "Epoch 41. Loss: 0.0036256739660307184, Train_acc 0.9952612704918032\n",
      "\n",
      "Epoch 41. Loss: 0.0034317199371416344, Train_acc 0.9952997967479674\n",
      "\n",
      "Epoch 41. Loss: 0.0031545500990816035, Train_acc 0.9953377016129032\n",
      "\n",
      "Epoch 41. Loss: 0.003298267386442549, Train_acc 0.995375\n",
      "\n",
      "Epoch 41. Loss: 0.0029872777615465988, Train_acc 0.9954117063492064\n",
      "\n",
      "Epoch 41. Loss: 0.0027814736731629013, Train_acc 0.9954478346456693\n",
      "\n",
      "Epoch 41. Loss: 0.0025650231493235774, Train_acc 0.9954833984375\n",
      "\n",
      "Epoch 41. Loss: 0.0023357726076722427, Train_acc 0.9955184108527132\n",
      "\n",
      "Epoch 41. Loss: 0.0022274618886319055, Train_acc 0.9955528846153846\n",
      "\n",
      "Epoch 41. Loss: 0.002112189242216848, Train_acc 0.9955868320610687\n",
      "\n",
      "Epoch 41. Loss: 0.0019879658232573295, Train_acc 0.9956202651515151\n",
      "\n",
      "Epoch 41. Loss: 0.001905863458945032, Train_acc 0.9956531954887218\n",
      "\n",
      "Epoch 41. Loss: 0.0019002868221442487, Train_acc 0.9956856343283582\n",
      "\n",
      "Epoch 41. Loss: 0.0017363647909873132, Train_acc 0.9957175925925926\n",
      "\n",
      "Epoch 41. Loss: 0.0016084263781306213, Train_acc 0.9957490808823529\n",
      "\n",
      "Epoch 41. Loss: 0.0014610382927081717, Train_acc 0.995780109489051\n",
      "\n",
      "Epoch 41. Loss: 0.0014501409993615806, Train_acc 0.9958106884057971\n",
      "\n",
      "Epoch 41. Loss: 0.001449639559761172, Train_acc 0.9958408273381295\n",
      "\n",
      "Epoch 41. Loss: 0.0013423967670290415, Train_acc 0.9958705357142857\n",
      "\n",
      "Epoch 41. Loss: 0.002164043297847099, Train_acc 0.995844414893617\n",
      "\n",
      "Epoch 41. Loss: 0.001960989043522428, Train_acc 0.9958736795774648\n",
      "\n",
      "Epoch 41. Loss: 0.002003194305293456, Train_acc 0.995902534965035\n",
      "\n",
      "Epoch 41. Loss: 0.0018430820202669014, Train_acc 0.9959309895833334\n",
      "\n",
      "Epoch 41. Loss: 0.0019504657249904136, Train_acc 0.9959590517241379\n",
      "\n",
      "Epoch 41. Loss: 0.0018147001510305518, Train_acc 0.9959867294520548\n",
      "\n",
      "Epoch 41. Loss: 0.0016772543273750305, Train_acc 0.9960140306122449\n",
      "\n",
      "Epoch 41. Loss: 0.001761529742468896, Train_acc 0.9960409628378378\n",
      "\n",
      "Epoch 41. Loss: 0.003270943223347815, Train_acc 0.996015100671141\n",
      "\n",
      "Epoch 41. Loss: 0.004308922112504142, Train_acc 0.9959895833333333\n",
      "\n",
      "Epoch 41. Loss: 0.003929056087228207, Train_acc 0.996016142384106\n",
      "\n",
      "Epoch 41. Loss: 0.0036145747194335294, Train_acc 0.9960423519736842\n",
      "\n",
      "Epoch 41. Loss: 0.0033314234025366247, Train_acc 0.9960682189542484\n",
      "\n",
      "Epoch 41. Loss: 0.0034464689685780236, Train_acc 0.99609375\n",
      "\n",
      "Epoch 41. Loss: 0.003325794696819344, Train_acc 0.9961189516129032\n",
      "\n",
      "Epoch 41. Loss: 0.0030582111294950327, Train_acc 0.9961438301282052\n",
      "\n",
      "Epoch 41. Loss: 0.0039036464660661173, Train_acc 0.9961186305732485\n",
      "\n",
      "Epoch 41. Loss: 0.004063455787536211, Train_acc 0.9961431962025317\n",
      "\n",
      "Epoch 41. Loss: 0.003875318994882739, Train_acc 0.9961674528301887\n",
      "\n",
      "Epoch 41. Loss: 0.00501364933097038, Train_acc 0.996142578125\n",
      "\n",
      "Epoch 41. Loss: 0.005489233210477292, Train_acc 0.9961180124223602\n",
      "\n",
      "Epoch 41. Loss: 0.004981768004876876, Train_acc 0.996141975308642\n",
      "\n",
      "Epoch 41. Loss: 0.004600958908322457, Train_acc 0.9961656441717791\n",
      "\n",
      "Epoch 41. Loss: 0.00417534351577897, Train_acc 0.9961890243902439\n",
      "\n",
      "Epoch 41. Loss: 0.0038381283904548504, Train_acc 0.9962121212121212\n",
      "\n",
      "Epoch 41. Loss: 0.004836856835374477, Train_acc 0.9961878765060241\n",
      "\n",
      "Epoch 41. Loss: 0.004468868971110949, Train_acc 0.9962107035928144\n",
      "\n",
      "Epoch 41. Loss: 0.0041525578179693835, Train_acc 0.9962332589285714\n",
      "\n",
      "Epoch 41. Loss: 0.0038161657449404854, Train_acc 0.9962555473372781\n",
      "\n",
      "Epoch 41. Loss: 0.003959475728583376, Train_acc 0.9962775735294118\n",
      "\n",
      "Epoch 41. Loss: 0.003660118710765205, Train_acc 0.9962993421052632\n",
      "\n",
      "Epoch 41. Loss: 0.0036240446022694967, Train_acc 0.9963208575581395\n",
      "\n",
      "Epoch 41. Loss: 0.003296354469236344, Train_acc 0.9963421242774566\n",
      "\n",
      "Epoch 41. Loss: 0.003069414926519194, Train_acc 0.9963631465517241\n",
      "\n",
      "Epoch 41. Loss: 0.00290724507172796, Train_acc 0.9963839285714285\n",
      "\n",
      "Epoch 41. Loss: 0.0026883277585906646, Train_acc 0.9964044744318182\n",
      "\n",
      "Epoch 41. Loss: 0.0025254000964733537, Train_acc 0.9964247881355932\n",
      "\n",
      "Epoch 41. Loss: 0.0023235013630011746, Train_acc 0.9964448735955056\n",
      "\n",
      "Epoch 41. Loss: 0.002189654398167348, Train_acc 0.9964647346368715\n",
      "\n",
      "Epoch 41. Loss: 0.0031457509442009476, Train_acc 0.9964409722222223\n",
      "\n",
      "Epoch 41. Loss: 0.0033938278174106434, Train_acc 0.996460635359116\n",
      "\n",
      "Epoch 41. Loss: 0.003191908713344111, Train_acc 0.9964800824175825\n",
      "\n",
      "Epoch 41. Loss: 0.003917926825133002, Train_acc 0.9964566256830601\n",
      "\n",
      "Epoch 41. Loss: 0.003710473124836716, Train_acc 0.996475883152174\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41. Loss: 0.003825338522781283, Train_acc 0.9964949324324325\n",
      "\n",
      "Epoch 41. Loss: 0.003480893156101719, Train_acc 0.9965137768817204\n",
      "\n",
      "Epoch 41. Loss: 0.003189852499564736, Train_acc 0.9965324197860963\n",
      "\n",
      "Epoch 41. Loss: 0.0028853396502614387, Train_acc 0.9965508643617021\n",
      "\n",
      "Epoch 41. Loss: 0.0026421749043866205, Train_acc 0.9965691137566137\n",
      "\n",
      "Epoch 41. Loss: 0.0025431064479488914, Train_acc 0.9965871710526316\n",
      "\n",
      "Epoch 41. Loss: 0.002671581767911206, Train_acc 0.9966050392670157\n",
      "\n",
      "Epoch 41. Loss: 0.002475601601086474, Train_acc 0.9966227213541666\n",
      "\n",
      "Epoch 41. Loss: 0.0023282306788332016, Train_acc 0.9966402202072538\n",
      "\n",
      "Epoch 41. Loss: 0.0023312163913667278, Train_acc 0.9966575386597938\n",
      "\n",
      "Epoch 41. Loss: 0.002256774028003521, Train_acc 0.9966746794871795\n",
      "\n",
      "Epoch 41. Loss: 0.002168413060778654, Train_acc 0.99668\n",
      "\n",
      "Epoch 42. Loss: 0.002004932440406927, Train_acc 1.0\n",
      "\n",
      "Epoch 42. Loss: 0.002058531794700189, Train_acc 1.0\n",
      "\n",
      "Epoch 42. Loss: 0.0019072793860482398, Train_acc 1.0\n",
      "\n",
      "Epoch 42. Loss: 0.0018010287030299505, Train_acc 1.0\n",
      "\n",
      "Epoch 42. Loss: 0.0038540619054818156, Train_acc 0.996875\n",
      "\n",
      "Epoch 42. Loss: 0.003496827701857187, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 42. Loss: 0.0031682862902644815, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 42. Loss: 0.0029293167290617714, Train_acc 0.998046875\n",
      "\n",
      "Epoch 42. Loss: 0.002803578319924744, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 42. Loss: 0.004489960865179603, Train_acc 0.99765625\n",
      "\n",
      "Epoch 42. Loss: 0.004248721657469783, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 42. Loss: 0.004757424283720476, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 42. Loss: 0.004571070321974834, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 42. Loss: 0.004212290452918571, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 42. Loss: 0.0038941953710477013, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 42. Loss: 0.003883826682948511, Train_acc 0.998046875\n",
      "\n",
      "Epoch 42. Loss: 0.0037259925920368206, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 42. Loss: 0.003431152906302077, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 42. Loss: 0.003491263223841902, Train_acc 0.9983552631578947\n",
      "\n",
      "Epoch 42. Loss: 0.0032699525196374507, Train_acc 0.9984375\n",
      "\n",
      "Epoch 42. Loss: 0.004135958388956283, Train_acc 0.9985119047619048\n",
      "\n",
      "Epoch 42. Loss: 0.0037404834971217615, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 42. Loss: 0.0036841296270091806, Train_acc 0.998641304347826\n",
      "\n",
      "Epoch 42. Loss: 0.003793727149257017, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 42. Loss: 0.003947341077124136, Train_acc 0.99875\n",
      "\n",
      "Epoch 42. Loss: 0.0036251049486838794, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 42. Loss: 0.003287440655810879, Train_acc 0.9988425925925926\n",
      "\n",
      "Epoch 42. Loss: 0.003304097939707261, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 42. Loss: 0.0034872453972793413, Train_acc 0.9989224137931034\n",
      "\n",
      "Epoch 42. Loss: 0.0035501837825861688, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 42. Loss: 0.012266677924640815, Train_acc 0.9982358870967742\n",
      "\n",
      "Epoch 42. Loss: 0.011094187814790688, Train_acc 0.998291015625\n",
      "\n",
      "Epoch 42. Loss: 0.010083379132251009, Train_acc 0.998342803030303\n",
      "\n",
      "Epoch 42. Loss: 0.009263355481803475, Train_acc 0.9983915441176471\n",
      "\n",
      "Epoch 42. Loss: 0.01956520657078629, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 42. Loss: 0.01806660018044298, Train_acc 0.9978298611111112\n",
      "\n",
      "Epoch 42. Loss: 0.01636016920265259, Train_acc 0.9978885135135135\n",
      "\n",
      "Epoch 42. Loss: 0.014853701767087295, Train_acc 0.9979440789473685\n",
      "\n",
      "Epoch 42. Loss: 0.013623091923715455, Train_acc 0.9979967948717948\n",
      "\n",
      "Epoch 42. Loss: 0.013288680104185746, Train_acc 0.9978515625\n",
      "\n",
      "Epoch 42. Loss: 0.01827460681298638, Train_acc 0.997141768292683\n",
      "\n",
      "Epoch 42. Loss: 0.01714329071066616, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 42. Loss: 0.015493641515103771, Train_acc 0.9972747093023255\n",
      "\n",
      "Epoch 42. Loss: 0.015182760088468607, Train_acc 0.9973366477272727\n",
      "\n",
      "Epoch 42. Loss: 0.013767468391146526, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 42. Loss: 0.012474797442513346, Train_acc 0.997452445652174\n",
      "\n",
      "Epoch 42. Loss: 0.014514357022903239, Train_acc 0.9971742021276596\n",
      "\n",
      "Epoch 42. Loss: 0.013395953588712402, Train_acc 0.9972330729166666\n",
      "\n",
      "Epoch 42. Loss: 0.012097263622802739, Train_acc 0.9972895408163265\n",
      "\n",
      "Epoch 42. Loss: 0.011195395925996224, Train_acc 0.99734375\n",
      "\n",
      "Epoch 42. Loss: 0.010343310965954531, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 42. Loss: 0.009662766684316934, Train_acc 0.9974459134615384\n",
      "\n",
      "Epoch 42. Loss: 0.010528585735759146, Train_acc 0.9973466981132075\n",
      "\n",
      "Epoch 42. Loss: 0.010381911291600175, Train_acc 0.9972511574074074\n",
      "\n",
      "Epoch 42. Loss: 0.010630720043707706, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 42. Loss: 0.010242671805571452, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 42. Loss: 0.009567614571594538, Train_acc 0.9972587719298246\n",
      "\n",
      "Epoch 42. Loss: 0.008698402401562416, Train_acc 0.9973060344827587\n",
      "\n",
      "Epoch 42. Loss: 0.011101212179740565, Train_acc 0.9969544491525424\n",
      "\n",
      "Epoch 42. Loss: 0.011215967995149165, Train_acc 0.996875\n",
      "\n",
      "Epoch 42. Loss: 0.010775870773692967, Train_acc 0.9969262295081968\n",
      "\n",
      "Epoch 42. Loss: 0.02032755988255147, Train_acc 0.9967237903225806\n",
      "\n",
      "Epoch 42. Loss: 0.018768637956291474, Train_acc 0.9967757936507936\n",
      "\n",
      "Epoch 42. Loss: 0.01743521489935521, Train_acc 0.996826171875\n",
      "\n",
      "Epoch 42. Loss: 0.015847746867760155, Train_acc 0.996875\n",
      "\n",
      "Epoch 42. Loss: 0.014551843344486476, Train_acc 0.9969223484848485\n",
      "\n",
      "Epoch 42. Loss: 0.013240722458571243, Train_acc 0.9969682835820896\n",
      "\n",
      "Epoch 42. Loss: 0.013909452534624979, Train_acc 0.9968979779411765\n",
      "\n",
      "Epoch 42. Loss: 0.0128038648207045, Train_acc 0.9969429347826086\n",
      "\n",
      "Epoch 42. Loss: 0.012664558226381815, Train_acc 0.9969866071428571\n",
      "\n",
      "Epoch 42. Loss: 0.011570105308326403, Train_acc 0.9970290492957746\n",
      "\n",
      "Epoch 42. Loss: 0.012877086344986249, Train_acc 0.9969618055555556\n",
      "\n",
      "Epoch 42. Loss: 0.011773665330264648, Train_acc 0.9970034246575342\n",
      "\n",
      "Epoch 42. Loss: 0.010625279634907408, Train_acc 0.997043918918919\n",
      "\n",
      "Epoch 42. Loss: 0.010784875808401016, Train_acc 0.9969791666666666\n",
      "\n",
      "Epoch 42. Loss: 0.009844291536056794, Train_acc 0.9970189144736842\n",
      "\n",
      "Epoch 42. Loss: 0.00895103408365701, Train_acc 0.9970576298701299\n",
      "\n",
      "Epoch 42. Loss: 0.008601712945201288, Train_acc 0.9970953525641025\n",
      "\n",
      "Epoch 42. Loss: 0.008585392360179089, Train_acc 0.9971321202531646\n",
      "\n",
      "Epoch 42. Loss: 0.008040173507590707, Train_acc 0.99716796875\n",
      "\n",
      "Epoch 42. Loss: 0.007359429179304495, Train_acc 0.9972029320987654\n",
      "\n",
      "Epoch 42. Loss: 0.006642003043812428, Train_acc 0.9972370426829268\n",
      "\n",
      "Epoch 42. Loss: 0.007060460389544291, Train_acc 0.9971762048192772\n",
      "\n",
      "Epoch 42. Loss: 0.00710471356776928, Train_acc 0.9971168154761905\n",
      "\n",
      "Epoch 42. Loss: 0.006959627889775411, Train_acc 0.9971507352941177\n",
      "\n",
      "Epoch 42. Loss: 0.007984165093168476, Train_acc 0.997093023255814\n",
      "\n",
      "Epoch 42. Loss: 0.008311879440425211, Train_acc 0.9970366379310345\n",
      "\n",
      "Epoch 42. Loss: 0.007691997785221077, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 42. Loss: 0.007026604757547859, Train_acc 0.9971032303370787\n",
      "\n",
      "Epoch 42. Loss: 0.006586036684929267, Train_acc 0.9971354166666667\n",
      "\n",
      "Epoch 42. Loss: 0.008004076721804382, Train_acc 0.9969951923076923\n",
      "\n",
      "Epoch 42. Loss: 0.009926288151029087, Train_acc 0.9969429347826086\n",
      "\n",
      "Epoch 42. Loss: 0.009006284760871907, Train_acc 0.9969758064516129\n",
      "\n",
      "Epoch 42. Loss: 0.008330387006459576, Train_acc 0.9970079787234043\n",
      "\n",
      "Epoch 42. Loss: 0.009932043259076425, Train_acc 0.9969572368421052\n",
      "\n",
      "Epoch 42. Loss: 0.00912930795042111, Train_acc 0.9969889322916666\n",
      "\n",
      "Epoch 42. Loss: 0.008756101544470133, Train_acc 0.9970199742268041\n",
      "\n",
      "Epoch 42. Loss: 0.0079277855627143, Train_acc 0.9970503826530612\n",
      "\n",
      "Epoch 42. Loss: 0.0073432436560753244, Train_acc 0.9970801767676768\n",
      "\n",
      "Epoch 42. Loss: 0.006682612185707011, Train_acc 0.997109375\n",
      "\n",
      "[Epoch 42 Batch 100] Loss: 0.006502031514075682 Training: accuracy=0.997138\n",
      "Epoch 42. Loss: 0.006502031514075682, Train_acc 0.997137995049505\n",
      "\n",
      "Epoch 42. Loss: 0.006400336008394318, Train_acc 0.9971660539215687\n",
      "\n",
      "Epoch 42. Loss: 0.0058691222466338185, Train_acc 0.9971935679611651\n",
      "\n",
      "Epoch 42. Loss: 0.005534145677221582, Train_acc 0.9972205528846154\n",
      "\n",
      "Epoch 42. Loss: 0.006271750392734497, Train_acc 0.997172619047619\n",
      "\n",
      "Epoch 42. Loss: 0.0057296168566501795, Train_acc 0.9971992924528302\n",
      "\n",
      "Epoch 42. Loss: 0.005269961179264485, Train_acc 0.9972254672897196\n",
      "\n",
      "Epoch 42. Loss: 0.004789782900367282, Train_acc 0.9972511574074074\n",
      "\n",
      "Epoch 42. Loss: 0.004759149491045567, Train_acc 0.997276376146789\n",
      "\n",
      "Epoch 42. Loss: 0.004927501007619822, Train_acc 0.9973011363636364\n",
      "\n",
      "Epoch 42. Loss: 0.004587292336127899, Train_acc 0.9973254504504504\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42. Loss: 0.004333762499684163, Train_acc 0.9973493303571429\n",
      "\n",
      "Epoch 42. Loss: 0.004267107295872928, Train_acc 0.9973727876106194\n",
      "\n",
      "Epoch 42. Loss: 0.0039083775030140525, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 42. Loss: 0.0036334607285169766, Train_acc 0.9974184782608696\n",
      "\n",
      "Epoch 42. Loss: 0.003351827210339875, Train_acc 0.9974407327586207\n",
      "\n",
      "Epoch 42. Loss: 0.003255189076351795, Train_acc 0.9974626068376068\n",
      "\n",
      "Epoch 42. Loss: 0.004476507558185763, Train_acc 0.9974179025423728\n",
      "\n",
      "Epoch 42. Loss: 0.005197339739285922, Train_acc 0.9973739495798319\n",
      "\n",
      "Epoch 42. Loss: 0.005065320405594721, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 42. Loss: 0.0048234329645549185, Train_acc 0.9974173553719008\n",
      "\n",
      "Epoch 42. Loss: 0.004366916040538469, Train_acc 0.9974385245901639\n",
      "\n",
      "Epoch 42. Loss: 0.004004814061485576, Train_acc 0.9974593495934959\n",
      "\n",
      "Epoch 42. Loss: 0.0036938944665196667, Train_acc 0.9974798387096774\n",
      "\n",
      "Epoch 42. Loss: 0.004784065190637392, Train_acc 0.9974375\n",
      "\n",
      "Epoch 42. Loss: 0.0048009383916267296, Train_acc 0.9974578373015873\n",
      "\n",
      "Epoch 42. Loss: 0.0043458101732965744, Train_acc 0.9974778543307087\n",
      "\n",
      "Epoch 42. Loss: 0.0039556693604773825, Train_acc 0.99749755859375\n",
      "\n",
      "Epoch 42. Loss: 0.0035896588019876823, Train_acc 0.9975169573643411\n",
      "\n",
      "Epoch 42. Loss: 0.0032609354978199285, Train_acc 0.9975360576923077\n",
      "\n",
      "Epoch 42. Loss: 0.002949788150319798, Train_acc 0.9975548664122137\n",
      "\n",
      "Epoch 42. Loss: 0.0029302263567635503, Train_acc 0.9975733901515151\n",
      "\n",
      "Epoch 42. Loss: 0.0027468282228705963, Train_acc 0.9975916353383458\n",
      "\n",
      "Epoch 42. Loss: 0.004261681727707179, Train_acc 0.9975513059701493\n",
      "\n",
      "Epoch 42. Loss: 0.0038550997809080408, Train_acc 0.9975694444444444\n",
      "\n",
      "Epoch 42. Loss: 0.00405452557225598, Train_acc 0.9975873161764706\n",
      "\n",
      "Epoch 42. Loss: 0.004648229866351841, Train_acc 0.9975479014598541\n",
      "\n",
      "Epoch 42. Loss: 0.004409211998396658, Train_acc 0.9975656702898551\n",
      "\n",
      "Epoch 42. Loss: 0.004154315963578411, Train_acc 0.9975831834532374\n",
      "\n",
      "Epoch 42. Loss: 0.008159881942145992, Train_acc 0.9975446428571428\n",
      "\n",
      "Epoch 42. Loss: 0.007395863352032425, Train_acc 0.9975620567375887\n",
      "\n",
      "Epoch 42. Loss: 0.006744838442047541, Train_acc 0.9975792253521126\n",
      "\n",
      "Epoch 42. Loss: 0.006267531791901683, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 42. Loss: 0.006334936820336666, Train_acc 0.9976128472222222\n",
      "\n",
      "Epoch 42. Loss: 0.005955797065751392, Train_acc 0.9976293103448276\n",
      "\n",
      "Epoch 42. Loss: 0.005378449974724439, Train_acc 0.9976455479452054\n",
      "\n",
      "Epoch 42. Loss: 0.008019997940899838, Train_acc 0.9976084183673469\n",
      "\n",
      "Epoch 42. Loss: 0.008075845330752649, Train_acc 0.9975717905405406\n",
      "\n",
      "Epoch 42. Loss: 0.00732668610867654, Train_acc 0.9975880872483222\n",
      "\n",
      "Epoch 42. Loss: 0.006987095042676878, Train_acc 0.9976041666666666\n",
      "\n",
      "Epoch 42. Loss: 0.00678691613304122, Train_acc 0.9976200331125827\n",
      "\n",
      "Epoch 42. Loss: 0.008571211376436088, Train_acc 0.9975842927631579\n",
      "\n",
      "Epoch 42. Loss: 0.007932037090418518, Train_acc 0.9976000816993464\n",
      "\n",
      "Epoch 42. Loss: 0.008403149504355592, Train_acc 0.9976156655844156\n",
      "\n",
      "Epoch 42. Loss: 0.007967458962031009, Train_acc 0.9976310483870968\n",
      "\n",
      "Epoch 42. Loss: 0.007749399847055497, Train_acc 0.9976462339743589\n",
      "\n",
      "Epoch 42. Loss: 0.009548341346918066, Train_acc 0.9976114649681529\n",
      "\n",
      "Epoch 42. Loss: 0.01089138659519421, Train_acc 0.9975771360759493\n",
      "\n",
      "Epoch 42. Loss: 0.00990926315100089, Train_acc 0.9975923742138365\n",
      "\n",
      "Epoch 42. Loss: 0.009364390616516132, Train_acc 0.997607421875\n",
      "\n",
      "Epoch 42. Loss: 0.008583756210379176, Train_acc 0.9976222826086957\n",
      "\n",
      "Epoch 42. Loss: 0.00796901208357278, Train_acc 0.9976369598765432\n",
      "\n",
      "Epoch 42. Loss: 0.0074446770717242075, Train_acc 0.9976514570552147\n",
      "\n",
      "Epoch 42. Loss: 0.006776012712415043, Train_acc 0.9976657774390244\n",
      "\n",
      "Epoch 42. Loss: 0.008166490517880903, Train_acc 0.9976325757575758\n",
      "\n",
      "Epoch 42. Loss: 0.007651064085693407, Train_acc 0.9976468373493976\n",
      "\n",
      "Epoch 42. Loss: 0.00880005877113156, Train_acc 0.9976141467065869\n",
      "\n",
      "Epoch 42. Loss: 0.011166237332485429, Train_acc 0.9975818452380952\n",
      "\n",
      "Epoch 42. Loss: 0.011372885887082499, Train_acc 0.997549926035503\n",
      "\n",
      "Epoch 42. Loss: 0.011140400835206583, Train_acc 0.9975643382352941\n",
      "\n",
      "Epoch 42. Loss: 0.010097902739976771, Train_acc 0.9975785818713451\n",
      "\n",
      "Epoch 42. Loss: 0.011781053669692511, Train_acc 0.9975018168604651\n",
      "\n",
      "Epoch 42. Loss: 0.010866374639183076, Train_acc 0.9975162572254336\n",
      "\n",
      "Epoch 42. Loss: 0.01618290025071185, Train_acc 0.9974407327586207\n",
      "\n",
      "Epoch 42. Loss: 0.01477409615137471, Train_acc 0.9974553571428572\n",
      "\n",
      "Epoch 42. Loss: 0.01688913261012697, Train_acc 0.9973810369318182\n",
      "\n",
      "Epoch 42. Loss: 0.015861816191224433, Train_acc 0.9973516949152542\n",
      "\n",
      "Epoch 42. Loss: 0.014482563691405811, Train_acc 0.9973665730337079\n",
      "\n",
      "Epoch 42. Loss: 0.01699263837075385, Train_acc 0.9973376396648045\n",
      "\n",
      "Epoch 42. Loss: 0.01546666399054887, Train_acc 0.9973524305555556\n",
      "\n",
      "Epoch 42. Loss: 0.01709296442937698, Train_acc 0.9972807320441989\n",
      "\n",
      "Epoch 42. Loss: 0.015562154956692572, Train_acc 0.9972956730769231\n",
      "\n",
      "Epoch 42. Loss: 0.014411241266608938, Train_acc 0.9973104508196722\n",
      "\n",
      "Epoch 42. Loss: 0.01837147142304245, Train_acc 0.9972826086956522\n",
      "\n",
      "Epoch 42. Loss: 0.018232058465301362, Train_acc 0.9972550675675675\n",
      "\n",
      "Epoch 42. Loss: 0.02153824729903284, Train_acc 0.9971438172043011\n",
      "\n",
      "Epoch 42. Loss: 0.019631369944255742, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 42. Loss: 0.017747734981270084, Train_acc 0.9971742021276596\n",
      "\n",
      "Epoch 42. Loss: 0.017568880503617032, Train_acc 0.9971478174603174\n",
      "\n",
      "Epoch 42. Loss: 0.01811967307499853, Train_acc 0.9970805921052631\n",
      "\n",
      "Epoch 42. Loss: 0.016413206803658372, Train_acc 0.9970958769633508\n",
      "\n",
      "Epoch 42. Loss: 0.01629906170996317, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 42. Loss: 0.01529566899402996, Train_acc 0.9970854922279793\n",
      "\n",
      "Epoch 42. Loss: 0.01583958377358967, Train_acc 0.9970199742268041\n",
      "\n",
      "Epoch 42. Loss: 0.015099604814508442, Train_acc 0.9970352564102564\n",
      "\n",
      "Epoch 42. Loss: 0.01433679735631545, Train_acc 0.99704\n",
      "\n",
      "Epoch 43. Loss: 0.015641141170002218, Train_acc 0.984375\n",
      "\n",
      "Epoch 43. Loss: 0.015795415178302404, Train_acc 0.98828125\n",
      "\n",
      "Epoch 43. Loss: 0.014318796877236048, Train_acc 0.9921875\n",
      "\n",
      "Epoch 43. Loss: 0.013582271867249203, Train_acc 0.9921875\n",
      "\n",
      "Epoch 43. Loss: 0.012535719463530593, Train_acc 0.99375\n",
      "\n",
      "Epoch 43. Loss: 0.014515511369082404, Train_acc 0.9921875\n",
      "\n",
      "Epoch 43. Loss: 0.014611949574535852, Train_acc 0.9921875\n",
      "\n",
      "Epoch 43. Loss: 0.013265007605796993, Train_acc 0.9931640625\n",
      "\n",
      "Epoch 43. Loss: 0.01235495602322752, Train_acc 0.9939236111111112\n",
      "\n",
      "Epoch 43. Loss: 0.015093588190374981, Train_acc 0.99296875\n",
      "\n",
      "Epoch 43. Loss: 0.014934613763181757, Train_acc 0.9928977272727273\n",
      "\n",
      "Epoch 43. Loss: 0.01371371700012391, Train_acc 0.9934895833333334\n",
      "\n",
      "Epoch 43. Loss: 0.013044406431708084, Train_acc 0.9939903846153846\n",
      "\n",
      "Epoch 43. Loss: 0.012246984783077251, Train_acc 0.9944196428571429\n",
      "\n",
      "Epoch 43. Loss: 0.012276596204874526, Train_acc 0.9942708333333333\n",
      "\n",
      "Epoch 43. Loss: 0.01248920943716551, Train_acc 0.994140625\n",
      "\n",
      "Epoch 43. Loss: 0.011763312266433703, Train_acc 0.9944852941176471\n",
      "\n",
      "Epoch 43. Loss: 0.0107541751417498, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 43. Loss: 0.009752509225240073, Train_acc 0.9950657894736842\n",
      "\n",
      "Epoch 43. Loss: 0.008789813529283267, Train_acc 0.9953125\n",
      "\n",
      "Epoch 43. Loss: 0.012218541065600927, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 43. Loss: 0.011724721745920852, Train_acc 0.9946732954545454\n",
      "\n",
      "Epoch 43. Loss: 0.011014835305532225, Train_acc 0.9949048913043478\n",
      "\n",
      "Epoch 43. Loss: 0.011805700153875717, Train_acc 0.9944661458333334\n",
      "\n",
      "Epoch 43. Loss: 0.01474014801451716, Train_acc 0.9940625\n",
      "\n",
      "Epoch 43. Loss: 0.019610178911708177, Train_acc 0.9936899038461539\n",
      "\n",
      "Epoch 43. Loss: 0.017721813564432306, Train_acc 0.9939236111111112\n",
      "\n",
      "Epoch 43. Loss: 0.01647908368998704, Train_acc 0.994140625\n",
      "\n",
      "Epoch 43. Loss: 0.015179702491706054, Train_acc 0.9943426724137931\n",
      "\n",
      "Epoch 43. Loss: 0.015477348768245079, Train_acc 0.9942708333333333\n",
      "\n",
      "Epoch 43. Loss: 0.01401779911470568, Train_acc 0.9944556451612904\n",
      "\n",
      "Epoch 43. Loss: 0.012673528727284349, Train_acc 0.99462890625\n",
      "\n",
      "Epoch 43. Loss: 0.012442173498622726, Train_acc 0.9945549242424242\n",
      "\n",
      "Epoch 43. Loss: 0.011546093188451664, Train_acc 0.9947150735294118\n",
      "\n",
      "Epoch 43. Loss: 0.011379733722859862, Train_acc 0.9946428571428572\n",
      "\n",
      "Epoch 43. Loss: 0.01363172050546489, Train_acc 0.994140625\n",
      "\n",
      "Epoch 43. Loss: 0.012932520076461571, Train_acc 0.9942989864864865\n",
      "\n",
      "Epoch 43. Loss: 0.013990008203531449, Train_acc 0.9942434210526315\n",
      "\n",
      "Epoch 43. Loss: 0.014134478227804732, Train_acc 0.9941907051282052\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43. Loss: 0.01529885734454748, Train_acc 0.994140625\n",
      "\n",
      "Epoch 43. Loss: 0.015624086643778894, Train_acc 0.9940929878048781\n",
      "\n",
      "Epoch 43. Loss: 0.014425792253671837, Train_acc 0.9942336309523809\n",
      "\n",
      "Epoch 43. Loss: 0.013126823574670035, Train_acc 0.9943677325581395\n",
      "\n",
      "Epoch 43. Loss: 0.012432265225381742, Train_acc 0.9944957386363636\n",
      "\n",
      "Epoch 43. Loss: 0.011698065535722158, Train_acc 0.9946180555555556\n",
      "\n",
      "Epoch 43. Loss: 0.011597409288434371, Train_acc 0.9945652173913043\n",
      "\n",
      "Epoch 43. Loss: 0.010630579036878661, Train_acc 0.9946808510638298\n",
      "\n",
      "Epoch 43. Loss: 0.010340541501260207, Train_acc 0.99462890625\n",
      "\n",
      "Epoch 43. Loss: 0.009521500955745344, Train_acc 0.9947385204081632\n",
      "\n",
      "Epoch 43. Loss: 0.008741681974470405, Train_acc 0.99484375\n",
      "\n",
      "Epoch 43. Loss: 0.008041685533976366, Train_acc 0.9949448529411765\n",
      "\n",
      "Epoch 43. Loss: 0.007275325298153402, Train_acc 0.9950420673076923\n",
      "\n",
      "Epoch 43. Loss: 0.007003907300764061, Train_acc 0.9951356132075472\n",
      "\n",
      "Epoch 43. Loss: 0.007359312828839186, Train_acc 0.9950810185185185\n",
      "\n",
      "Epoch 43. Loss: 0.00861773526501092, Train_acc 0.9950284090909091\n",
      "\n",
      "Epoch 43. Loss: 0.008284222757426794, Train_acc 0.9951171875\n",
      "\n",
      "Epoch 43. Loss: 0.007750969248436, Train_acc 0.995202850877193\n",
      "\n",
      "Epoch 43. Loss: 0.00709532582920531, Train_acc 0.9952855603448276\n",
      "\n",
      "Epoch 43. Loss: 0.006484333181709703, Train_acc 0.995365466101695\n",
      "\n",
      "Epoch 43. Loss: 0.006007401739859423, Train_acc 0.9954427083333334\n",
      "\n",
      "Epoch 43. Loss: 0.00569007699516759, Train_acc 0.9955174180327869\n",
      "\n",
      "Epoch 43. Loss: 0.005200121172324307, Train_acc 0.9955897177419355\n",
      "\n",
      "Epoch 43. Loss: 0.005808298227687616, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 43. Loss: 0.0053550845570861745, Train_acc 0.99560546875\n",
      "\n",
      "Epoch 43. Loss: 0.005993587834760498, Train_acc 0.9955528846153846\n",
      "\n",
      "Epoch 43. Loss: 0.005570597693417177, Train_acc 0.9956202651515151\n",
      "\n",
      "Epoch 43. Loss: 0.005053149113352371, Train_acc 0.9956856343283582\n",
      "\n",
      "Epoch 43. Loss: 0.005687263879294937, Train_acc 0.9956341911764706\n",
      "\n",
      "Epoch 43. Loss: 0.007230606286033165, Train_acc 0.9955842391304348\n",
      "\n",
      "Epoch 43. Loss: 0.006893341423917566, Train_acc 0.9956473214285714\n",
      "\n",
      "Epoch 43. Loss: 0.006378174882451821, Train_acc 0.9957086267605634\n",
      "\n",
      "Epoch 43. Loss: 0.006137475668329116, Train_acc 0.9957682291666666\n",
      "\n",
      "Epoch 43. Loss: 0.005621103790570601, Train_acc 0.995826198630137\n",
      "\n",
      "Epoch 43. Loss: 0.00511682144206253, Train_acc 0.9958826013513513\n",
      "\n",
      "Epoch 43. Loss: 0.007410657656802124, Train_acc 0.9957291666666667\n",
      "\n",
      "Epoch 43. Loss: 0.0067454639473081114, Train_acc 0.9957853618421053\n",
      "\n",
      "Epoch 43. Loss: 0.00679077579291348, Train_acc 0.9958400974025974\n",
      "\n",
      "Epoch 43. Loss: 0.0064275892801882424, Train_acc 0.9958934294871795\n",
      "\n",
      "Epoch 43. Loss: 0.008042018761736297, Train_acc 0.9958465189873418\n",
      "\n",
      "Epoch 43. Loss: 0.007976830941142569, Train_acc 0.9958984375\n",
      "\n",
      "Epoch 43. Loss: 0.011739832259746133, Train_acc 0.9958526234567902\n",
      "\n",
      "Epoch 43. Loss: 0.01466867626982785, Train_acc 0.9958079268292683\n",
      "\n",
      "Epoch 43. Loss: 0.01321634256317506, Train_acc 0.9958584337349398\n",
      "\n",
      "Epoch 43. Loss: 0.012633007991456596, Train_acc 0.9959077380952381\n",
      "\n",
      "Epoch 43. Loss: 0.011743039464594669, Train_acc 0.9959558823529412\n",
      "\n",
      "Epoch 43. Loss: 0.013137795731999052, Train_acc 0.9959120639534884\n",
      "\n",
      "Epoch 43. Loss: 0.016407177483061766, Train_acc 0.9957794540229885\n",
      "\n",
      "Epoch 43. Loss: 0.014989230697619751, Train_acc 0.9958274147727273\n",
      "\n",
      "Epoch 43. Loss: 0.013843504310266229, Train_acc 0.995874297752809\n",
      "\n",
      "Epoch 43. Loss: 0.01427748670037036, Train_acc 0.9958333333333333\n",
      "\n",
      "Epoch 43. Loss: 0.014294959279347463, Train_acc 0.9957932692307693\n",
      "\n",
      "Epoch 43. Loss: 0.01737835489730448, Train_acc 0.9957540760869565\n",
      "\n",
      "Epoch 43. Loss: 0.015744314074512517, Train_acc 0.9957997311827957\n",
      "\n",
      "Epoch 43. Loss: 0.019595855531093057, Train_acc 0.9956781914893617\n",
      "\n",
      "Epoch 43. Loss: 0.020795268094834604, Train_acc 0.9956414473684211\n",
      "\n",
      "Epoch 43. Loss: 0.018911357256812082, Train_acc 0.9956868489583334\n",
      "\n",
      "Epoch 43. Loss: 0.017276659339406097, Train_acc 0.9957313144329897\n",
      "\n",
      "Epoch 43. Loss: 0.01566828190400124, Train_acc 0.9957748724489796\n",
      "\n",
      "Epoch 43. Loss: 0.014730408584227448, Train_acc 0.9958175505050505\n",
      "\n",
      "Epoch 43. Loss: 0.014220619204774755, Train_acc 0.99578125\n",
      "\n",
      "[Epoch 43 Batch 100] Loss: 0.01399191817549043 Training: accuracy=0.995746\n",
      "Epoch 43. Loss: 0.01399191817549043, Train_acc 0.9957456683168316\n",
      "\n",
      "Epoch 43. Loss: 0.013021462195281741, Train_acc 0.9957873774509803\n",
      "\n",
      "Epoch 43. Loss: 0.013984094291774534, Train_acc 0.995752427184466\n",
      "\n",
      "Epoch 43. Loss: 0.017256903108818625, Train_acc 0.9956430288461539\n",
      "\n",
      "Epoch 43. Loss: 0.015865565867711567, Train_acc 0.9956845238095238\n",
      "\n",
      "Epoch 43. Loss: 0.018604716910263417, Train_acc 0.9956515330188679\n",
      "\n",
      "Epoch 43. Loss: 0.017068524801365004, Train_acc 0.9956921728971962\n",
      "\n",
      "Epoch 43. Loss: 0.015788664489878534, Train_acc 0.9957320601851852\n",
      "\n",
      "Epoch 43. Loss: 0.016160363393926607, Train_acc 0.9956995412844036\n",
      "\n",
      "Epoch 43. Loss: 0.018214873467001902, Train_acc 0.9955255681818181\n",
      "\n",
      "Epoch 43. Loss: 0.017066318275732028, Train_acc 0.9955658783783784\n",
      "\n",
      "Epoch 43. Loss: 0.01567996620937636, Train_acc 0.99560546875\n",
      "\n",
      "Epoch 43. Loss: 0.014333901615927671, Train_acc 0.9956443584070797\n",
      "\n",
      "Epoch 43. Loss: 0.014511858950844458, Train_acc 0.9956140350877193\n",
      "\n",
      "Epoch 43. Loss: 0.014549619713387835, Train_acc 0.9955842391304348\n",
      "\n",
      "Epoch 43. Loss: 0.013231810276492936, Train_acc 0.9956223060344828\n",
      "\n",
      "Epoch 43. Loss: 0.011963711903424117, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 43. Loss: 0.011046977277746247, Train_acc 0.9956965042372882\n",
      "\n",
      "Epoch 43. Loss: 0.015578972342148823, Train_acc 0.9956670168067226\n",
      "\n",
      "Epoch 43. Loss: 0.015909104944052163, Train_acc 0.9956380208333333\n",
      "\n",
      "Epoch 43. Loss: 0.014820141182048795, Train_acc 0.9956740702479339\n",
      "\n",
      "Epoch 43. Loss: 0.01390225741292865, Train_acc 0.9957095286885246\n",
      "\n",
      "Epoch 43. Loss: 0.01412085900925843, Train_acc 0.9956808943089431\n",
      "\n",
      "Epoch 43. Loss: 0.013146455230324698, Train_acc 0.9957157258064516\n",
      "\n",
      "Epoch 43. Loss: 0.01290758767754665, Train_acc 0.9956875\n",
      "\n",
      "Epoch 43. Loss: 0.012394606659837047, Train_acc 0.9957217261904762\n",
      "\n",
      "Epoch 43. Loss: 0.013101278623963129, Train_acc 0.9956938976377953\n",
      "\n",
      "Epoch 43. Loss: 0.016557029379330335, Train_acc 0.99560546875\n",
      "\n",
      "Epoch 43. Loss: 0.017260805734624497, Train_acc 0.9955184108527132\n",
      "\n",
      "Epoch 43. Loss: 0.018272437089946896, Train_acc 0.9954927884615384\n",
      "\n",
      "Epoch 43. Loss: 0.016826444898635474, Train_acc 0.9955271946564885\n",
      "\n",
      "Epoch 43. Loss: 0.017873117582133703, Train_acc 0.9955018939393939\n",
      "\n",
      "Epoch 43. Loss: 0.0219336111898404, Train_acc 0.995359492481203\n",
      "\n",
      "Epoch 43. Loss: 0.02132320955144003, Train_acc 0.9953358208955224\n",
      "\n",
      "Epoch 43. Loss: 0.019528554520167125, Train_acc 0.9953703703703703\n",
      "\n",
      "Epoch 43. Loss: 0.018474385585180414, Train_acc 0.9954044117647058\n",
      "\n",
      "Epoch 43. Loss: 0.021230091553144002, Train_acc 0.9953239051094891\n",
      "\n",
      "Epoch 43. Loss: 0.019421586538817596, Train_acc 0.9953577898550725\n",
      "\n",
      "Epoch 43. Loss: 0.01771688003060172, Train_acc 0.9953911870503597\n",
      "\n",
      "Epoch 43. Loss: 0.01681985414743677, Train_acc 0.9954241071428571\n",
      "\n",
      "Epoch 43. Loss: 0.01519670184074384, Train_acc 0.9954565602836879\n",
      "\n",
      "Epoch 43. Loss: 0.01631138205336221, Train_acc 0.9954335387323944\n",
      "\n",
      "Epoch 43. Loss: 0.025218164740264608, Train_acc 0.9952469405594405\n",
      "\n",
      "Epoch 43. Loss: 0.02399174867712873, Train_acc 0.9952256944444444\n",
      "\n",
      "Epoch 43. Loss: 0.026289870205313724, Train_acc 0.9952047413793104\n",
      "\n",
      "Epoch 43. Loss: 0.025384265620521394, Train_acc 0.9951840753424658\n",
      "\n",
      "Epoch 43. Loss: 0.028146988247941457, Train_acc 0.9950042517006803\n",
      "\n",
      "Epoch 43. Loss: 0.02552956487173783, Train_acc 0.9950380067567568\n",
      "\n",
      "Epoch 43. Loss: 0.026361457068636542, Train_acc 0.9950188758389261\n",
      "\n",
      "Epoch 43. Loss: 0.031854297869427076, Train_acc 0.9948958333333333\n",
      "\n",
      "Epoch 43. Loss: 0.036189676361998685, Train_acc 0.9947744205298014\n",
      "\n",
      "Epoch 43. Loss: 0.034276058148790096, Train_acc 0.9947060032894737\n",
      "\n",
      "Epoch 43. Loss: 0.034154043231709626, Train_acc 0.9946895424836601\n",
      "\n",
      "Epoch 43. Loss: 0.03347718846884712, Train_acc 0.994622564935065\n",
      "\n",
      "Epoch 43. Loss: 0.03526702194291959, Train_acc 0.9945564516129032\n",
      "\n",
      "Epoch 43. Loss: 0.03674572037647912, Train_acc 0.9944911858974359\n",
      "\n",
      "Epoch 43. Loss: 0.0344953093110688, Train_acc 0.9944765127388535\n",
      "\n",
      "Epoch 43. Loss: 0.03558329260461039, Train_acc 0.994412579113924\n",
      "\n",
      "Epoch 43. Loss: 0.03459883719187236, Train_acc 0.9943494496855346\n",
      "\n",
      "Epoch 43. Loss: 0.03848322918565204, Train_acc 0.99423828125\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43. Loss: 0.0437964299966496, Train_acc 0.9941284937888198\n",
      "\n",
      "Epoch 43. Loss: 0.039679125432261986, Train_acc 0.994164737654321\n",
      "\n",
      "Epoch 43. Loss: 0.036629553013225645, Train_acc 0.9942005368098159\n",
      "\n",
      "Epoch 43. Loss: 0.039702462738615496, Train_acc 0.9940929878048781\n",
      "\n",
      "Epoch 43. Loss: 0.03939496994244655, Train_acc 0.9940340909090909\n",
      "\n",
      "Epoch 43. Loss: 0.04000714141333938, Train_acc 0.9939759036144579\n",
      "\n",
      "Epoch 43. Loss: 0.03792872903381145, Train_acc 0.9939651946107785\n",
      "\n",
      "Epoch 43. Loss: 0.03491101085701009, Train_acc 0.9940011160714286\n",
      "\n",
      "Epoch 43. Loss: 0.03361391502223987, Train_acc 0.9939441568047337\n",
      "\n",
      "Epoch 43. Loss: 0.034652884849332974, Train_acc 0.9938878676470588\n",
      "\n",
      "Epoch 43. Loss: 0.031547529582387095, Train_acc 0.9939236111111112\n",
      "\n",
      "Epoch 43. Loss: 0.02871643901880612, Train_acc 0.9939589389534884\n",
      "\n",
      "Epoch 43. Loss: 0.027754745865011483, Train_acc 0.9939486994219653\n",
      "\n",
      "Epoch 43. Loss: 0.025978202470371966, Train_acc 0.9939385775862069\n",
      "\n",
      "Epoch 43. Loss: 0.025659666819777945, Train_acc 0.9939285714285714\n",
      "\n",
      "Epoch 43. Loss: 0.023245467952332073, Train_acc 0.9939630681818182\n",
      "\n",
      "Epoch 43. Loss: 0.022150561067260363, Train_acc 0.9939530367231638\n",
      "\n",
      "Epoch 43. Loss: 0.024021432417151684, Train_acc 0.9939431179775281\n",
      "\n",
      "Epoch 43. Loss: 0.02270299353899123, Train_acc 0.9939769553072626\n",
      "\n",
      "Epoch 43. Loss: 0.02166793842197861, Train_acc 0.9940104166666667\n",
      "\n",
      "Epoch 43. Loss: 0.020213381155563048, Train_acc 0.9940435082872928\n",
      "\n",
      "Epoch 43. Loss: 0.02225675198814212, Train_acc 0.9940333104395604\n",
      "\n",
      "Epoch 43. Loss: 0.020862366471865224, Train_acc 0.9940659153005464\n",
      "\n",
      "Epoch 43. Loss: 0.01956167759896378, Train_acc 0.9940981657608695\n",
      "\n",
      "Epoch 43. Loss: 0.02096870713592524, Train_acc 0.9940033783783784\n",
      "\n",
      "Epoch 43. Loss: 0.021901475509950113, Train_acc 0.9939936155913979\n",
      "\n",
      "Epoch 43. Loss: 0.02033562030281001, Train_acc 0.9940257352941176\n",
      "\n",
      "Epoch 43. Loss: 0.02198436617152727, Train_acc 0.9939744015957447\n",
      "\n",
      "Epoch 43. Loss: 0.020648400754900303, Train_acc 0.9939649470899471\n",
      "\n",
      "Epoch 43. Loss: 0.02019705431566077, Train_acc 0.9939555921052632\n",
      "\n",
      "Epoch 43. Loss: 0.019465867379952408, Train_acc 0.993946335078534\n",
      "\n",
      "Epoch 43. Loss: 0.017913319404854418, Train_acc 0.9939778645833334\n",
      "\n",
      "Epoch 43. Loss: 0.01762357701221172, Train_acc 0.9939685880829016\n",
      "\n",
      "Epoch 43. Loss: 0.017813686983517384, Train_acc 0.9939594072164949\n",
      "\n",
      "Epoch 43. Loss: 0.020268453171907282, Train_acc 0.9939102564102564\n",
      "\n",
      "Epoch 43. Loss: 0.01833796110294394, Train_acc 0.99392\n",
      "\n",
      "Epoch 44. Loss: 0.01660396471647962, Train_acc 1.0\n",
      "\n",
      "Epoch 44. Loss: 0.015117228752257326, Train_acc 1.0\n",
      "\n",
      "Epoch 44. Loss: 0.01370629359441495, Train_acc 1.0\n",
      "\n",
      "Epoch 44. Loss: 0.012761315811343456, Train_acc 1.0\n",
      "\n",
      "Epoch 44. Loss: 0.012838180050552605, Train_acc 0.9984375\n",
      "\n",
      "Epoch 44. Loss: 0.012971569390863823, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 44. Loss: 0.011780152744706554, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 44. Loss: 0.01080840239356257, Train_acc 0.998046875\n",
      "\n",
      "Epoch 44. Loss: 0.010267665917548217, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 44. Loss: 0.01004543658111037, Train_acc 0.9984375\n",
      "\n",
      "Epoch 44. Loss: 0.009357207322241734, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 44. Loss: 0.008856824619655495, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 44. Loss: 0.008347096079738155, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 44. Loss: 0.008201050854087961, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 44. Loss: 0.007883167520637297, Train_acc 0.9984375\n",
      "\n",
      "Epoch 44. Loss: 0.007286583916522548, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 44. Loss: 0.006726214803969847, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 44. Loss: 0.0074636575179242975, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 44. Loss: 0.007269370288873663, Train_acc 0.9983552631578947\n",
      "\n",
      "Epoch 44. Loss: 0.0073730127159282125, Train_acc 0.9984375\n",
      "\n",
      "Epoch 44. Loss: 0.008135987547951152, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 44. Loss: 0.007492998078279684, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 44. Loss: 0.006834449444590575, Train_acc 0.9979619565217391\n",
      "\n",
      "Epoch 44. Loss: 0.008419035180847556, Train_acc 0.9977213541666666\n",
      "\n",
      "Epoch 44. Loss: 0.010563672680652777, Train_acc 0.9975\n",
      "\n",
      "Epoch 44. Loss: 0.01206125938802657, Train_acc 0.9972956730769231\n",
      "\n",
      "Epoch 44. Loss: 0.01100020857018707, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 44. Loss: 0.010512313445173007, Train_acc 0.9974888392857143\n",
      "\n",
      "Epoch 44. Loss: 0.010205551517914803, Train_acc 0.9975754310344828\n",
      "\n",
      "Epoch 44. Loss: 0.009735573783139353, Train_acc 0.99765625\n",
      "\n",
      "Epoch 44. Loss: 0.008914336121115057, Train_acc 0.9977318548387096\n",
      "\n",
      "Epoch 44. Loss: 0.00880629883500901, Train_acc 0.997802734375\n",
      "\n",
      "Epoch 44. Loss: 0.008576150086161203, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 44. Loss: 0.007803735027807987, Train_acc 0.9979319852941176\n",
      "\n",
      "Epoch 44. Loss: 0.007110134752694624, Train_acc 0.9979910714285715\n",
      "\n",
      "Epoch 44. Loss: 0.007956002515200249, Train_acc 0.9978298611111112\n",
      "\n",
      "Epoch 44. Loss: 0.009507947961965326, Train_acc 0.9976773648648649\n",
      "\n",
      "Epoch 44. Loss: 0.008622136012148075, Train_acc 0.9977384868421053\n",
      "\n",
      "Epoch 44. Loss: 0.00801650843919624, Train_acc 0.9977964743589743\n",
      "\n",
      "Epoch 44. Loss: 0.009053226331484102, Train_acc 0.99765625\n",
      "\n",
      "Epoch 44. Loss: 0.008208277743614567, Train_acc 0.9977134146341463\n",
      "\n",
      "Epoch 44. Loss: 0.007507887661638278, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 44. Loss: 0.0069635163694388436, Train_acc 0.9978197674418605\n",
      "\n",
      "Epoch 44. Loss: 0.006335405822543064, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 44. Loss: 0.006551661419970774, Train_acc 0.9977430555555555\n",
      "\n",
      "Epoch 44. Loss: 0.0063075150316384285, Train_acc 0.9977921195652174\n",
      "\n",
      "Epoch 44. Loss: 0.005759395740908549, Train_acc 0.9978390957446809\n",
      "\n",
      "Epoch 44. Loss: 0.006425440664573461, Train_acc 0.9977213541666666\n",
      "\n",
      "Epoch 44. Loss: 0.006248302982435182, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 44. Loss: 0.0058526741966029, Train_acc 0.9978125\n",
      "\n",
      "Epoch 44. Loss: 0.00592142772900343, Train_acc 0.9977022058823529\n",
      "\n",
      "Epoch 44. Loss: 0.006040891771560431, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 44. Loss: 0.005459295203100145, Train_acc 0.9976415094339622\n",
      "\n",
      "Epoch 44. Loss: 0.00707812665981993, Train_acc 0.9975405092592593\n",
      "\n",
      "Epoch 44. Loss: 0.006409496343993835, Train_acc 0.9975852272727272\n",
      "\n",
      "Epoch 44. Loss: 0.006590921958712064, Train_acc 0.9974888392857143\n",
      "\n",
      "Epoch 44. Loss: 0.006242560417587152, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 44. Loss: 0.006224465731800727, Train_acc 0.9975754310344828\n",
      "\n",
      "Epoch 44. Loss: 0.005845495308246731, Train_acc 0.9976165254237288\n",
      "\n",
      "Epoch 44. Loss: 0.005486417668884861, Train_acc 0.99765625\n",
      "\n",
      "Epoch 44. Loss: 0.005035914681863816, Train_acc 0.9976946721311475\n",
      "\n",
      "Epoch 44. Loss: 0.00746511108652833, Train_acc 0.9976058467741935\n",
      "\n",
      "Epoch 44. Loss: 0.007109445608193423, Train_acc 0.9976438492063492\n",
      "\n",
      "Epoch 44. Loss: 0.006574462014691305, Train_acc 0.9976806640625\n",
      "\n",
      "Epoch 44. Loss: 0.006898315485497956, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 44. Loss: 0.0062517420369977315, Train_acc 0.9976325757575758\n",
      "\n",
      "Epoch 44. Loss: 0.006010053454139342, Train_acc 0.9976679104477612\n",
      "\n",
      "Epoch 44. Loss: 0.007971831022171834, Train_acc 0.9974724264705882\n",
      "\n",
      "Epoch 44. Loss: 0.007737776957573288, Train_acc 0.9975090579710145\n",
      "\n",
      "Epoch 44. Loss: 0.00751398892115515, Train_acc 0.9975446428571428\n",
      "\n",
      "Epoch 44. Loss: 0.0068552013803229025, Train_acc 0.9975792253521126\n",
      "\n",
      "Epoch 44. Loss: 0.007053456074181673, Train_acc 0.9976128472222222\n",
      "\n",
      "Epoch 44. Loss: 0.007351050257250795, Train_acc 0.9975385273972602\n",
      "\n",
      "Epoch 44. Loss: 0.0067835197903984455, Train_acc 0.9975717905405406\n",
      "\n",
      "Epoch 44. Loss: 0.01568965727611843, Train_acc 0.9971875\n",
      "\n",
      "Epoch 44. Loss: 0.01568055674381074, Train_acc 0.9971217105263158\n",
      "\n",
      "Epoch 44. Loss: 0.014339484590563327, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 44. Loss: 0.013516074889844493, Train_acc 0.9971955128205128\n",
      "\n",
      "Epoch 44. Loss: 0.01268677526618168, Train_acc 0.9972310126582279\n",
      "\n",
      "Epoch 44. Loss: 0.013622303207860516, Train_acc 0.99716796875\n",
      "\n",
      "Epoch 44. Loss: 0.012531917005908007, Train_acc 0.9972029320987654\n",
      "\n",
      "Epoch 44. Loss: 0.011371807958210125, Train_acc 0.9972370426829268\n",
      "\n",
      "Epoch 44. Loss: 0.012466220964960409, Train_acc 0.9971762048192772\n",
      "\n",
      "Epoch 44. Loss: 0.011447398414437907, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 44. Loss: 0.011564871862731817, Train_acc 0.9971507352941177\n",
      "\n",
      "Epoch 44. Loss: 0.010683730544889667, Train_acc 0.9971838662790697\n",
      "\n",
      "Epoch 44. Loss: 0.012127561951200395, Train_acc 0.9970366379310345\n",
      "\n",
      "Epoch 44. Loss: 0.011111922507304159, Train_acc 0.9970703125\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44. Loss: 0.010188547763531541, Train_acc 0.9971032303370787\n",
      "\n",
      "Epoch 44. Loss: 0.009240361528771866, Train_acc 0.9971354166666667\n",
      "\n",
      "Epoch 44. Loss: 0.008776613630438818, Train_acc 0.9971668956043956\n",
      "\n",
      "Epoch 44. Loss: 0.011336224354134478, Train_acc 0.9971127717391305\n",
      "\n",
      "Epoch 44. Loss: 0.010994479426884482, Train_acc 0.997059811827957\n",
      "\n",
      "Epoch 44. Loss: 0.010037828834613858, Train_acc 0.9970910904255319\n",
      "\n",
      "Epoch 44. Loss: 0.00918510410952407, Train_acc 0.9971217105263158\n",
      "\n",
      "Epoch 44. Loss: 0.009239792913357954, Train_acc 0.9971516927083334\n",
      "\n",
      "Epoch 44. Loss: 0.00860002691536594, Train_acc 0.997181056701031\n",
      "\n",
      "Epoch 44. Loss: 0.008770814936513738, Train_acc 0.9971301020408163\n",
      "\n",
      "Epoch 44. Loss: 0.008937939764101836, Train_acc 0.9970801767676768\n",
      "\n",
      "Epoch 44. Loss: 0.00892033574227053, Train_acc 0.997109375\n",
      "\n",
      "[Epoch 44 Batch 100] Loss: 0.010047737894149643 Training: accuracy=0.996983\n",
      "Epoch 44. Loss: 0.010047737894149643, Train_acc 0.9969832920792079\n",
      "\n",
      "Epoch 44. Loss: 0.013176706779919882, Train_acc 0.9969362745098039\n",
      "\n",
      "Epoch 44. Loss: 0.012177857202446003, Train_acc 0.9969660194174758\n",
      "\n",
      "Epoch 44. Loss: 0.012470591482212131, Train_acc 0.9969200721153846\n",
      "\n",
      "Epoch 44. Loss: 0.011504680551609383, Train_acc 0.9969494047619047\n",
      "\n",
      "Epoch 44. Loss: 0.011000005539525437, Train_acc 0.9969781839622641\n",
      "\n",
      "Epoch 44. Loss: 0.011648778813721734, Train_acc 0.9969334112149533\n",
      "\n",
      "Epoch 44. Loss: 0.010915474230177998, Train_acc 0.9969618055555556\n",
      "\n",
      "Epoch 44. Loss: 0.009843624797661498, Train_acc 0.9969896788990825\n",
      "\n",
      "Epoch 44. Loss: 0.009108034316926654, Train_acc 0.9970170454545455\n",
      "\n",
      "Epoch 44. Loss: 0.012313869635071865, Train_acc 0.9969031531531531\n",
      "\n",
      "Epoch 44. Loss: 0.012241157757317881, Train_acc 0.9968610491071429\n",
      "\n",
      "Epoch 44. Loss: 0.011133546815153982, Train_acc 0.9968888274336283\n",
      "\n",
      "Epoch 44. Loss: 0.01007005826421412, Train_acc 0.9969161184210527\n",
      "\n",
      "Epoch 44. Loss: 0.01657724758196919, Train_acc 0.9968070652173913\n",
      "\n",
      "Epoch 44. Loss: 0.016177079593769152, Train_acc 0.9967672413793104\n",
      "\n",
      "Epoch 44. Loss: 0.0153561327187402, Train_acc 0.9967948717948718\n",
      "\n",
      "Epoch 44. Loss: 0.017569426223175193, Train_acc 0.9965572033898306\n",
      "\n",
      "Epoch 44. Loss: 0.01605429752595258, Train_acc 0.9965861344537815\n",
      "\n",
      "Epoch 44. Loss: 0.014579651167336394, Train_acc 0.9966145833333333\n",
      "\n",
      "Epoch 44. Loss: 0.014167258342662414, Train_acc 0.9965779958677686\n",
      "\n",
      "Epoch 44. Loss: 0.01373179343765285, Train_acc 0.9965420081967213\n",
      "\n",
      "Epoch 44. Loss: 0.013558105415928124, Train_acc 0.9965701219512195\n",
      "\n",
      "Epoch 44. Loss: 0.012294418707354598, Train_acc 0.9965977822580645\n",
      "\n",
      "Epoch 44. Loss: 0.014752266193804504, Train_acc 0.9965625\n",
      "\n",
      "Epoch 44. Loss: 0.013865623893181111, Train_acc 0.9965897817460317\n",
      "\n",
      "Epoch 44. Loss: 0.012570767225433179, Train_acc 0.9966166338582677\n",
      "\n",
      "Epoch 44. Loss: 0.01193298788438033, Train_acc 0.99664306640625\n",
      "\n",
      "Epoch 44. Loss: 0.012929721324769775, Train_acc 0.9965479651162791\n",
      "\n",
      "Epoch 44. Loss: 0.014362963198835958, Train_acc 0.9964543269230769\n",
      "\n",
      "Epoch 44. Loss: 0.013987617914422133, Train_acc 0.9964217557251909\n",
      "\n",
      "Epoch 44. Loss: 0.015047153770515721, Train_acc 0.996389678030303\n",
      "\n",
      "Epoch 44. Loss: 0.015152309743692936, Train_acc 0.9962993421052632\n",
      "\n",
      "Epoch 44. Loss: 0.016381026089010056, Train_acc 0.996268656716418\n",
      "\n",
      "Epoch 44. Loss: 0.01625387160910733, Train_acc 0.9962384259259259\n",
      "\n",
      "Epoch 44. Loss: 0.014739810883777446, Train_acc 0.9962660845588235\n",
      "\n",
      "Epoch 44. Loss: 0.013488976477073528, Train_acc 0.9962933394160584\n",
      "\n",
      "Epoch 44. Loss: 0.012447643383170871, Train_acc 0.9963201992753623\n",
      "\n",
      "Epoch 44. Loss: 0.011848827618800737, Train_acc 0.9963466726618705\n",
      "\n",
      "Epoch 44. Loss: 0.010801661877618557, Train_acc 0.9963727678571429\n",
      "\n",
      "Epoch 44. Loss: 0.009903016862491959, Train_acc 0.9963984929078015\n",
      "\n",
      "Epoch 44. Loss: 0.009976687794673617, Train_acc 0.9964238556338029\n",
      "\n",
      "Epoch 44. Loss: 0.010175193804426351, Train_acc 0.9963942307692307\n",
      "\n",
      "Epoch 44. Loss: 0.013359883091977262, Train_acc 0.9963107638888888\n",
      "\n",
      "Epoch 44. Loss: 0.013390898998496851, Train_acc 0.9962823275862069\n",
      "\n",
      "Epoch 44. Loss: 0.012145126549602677, Train_acc 0.9963077910958904\n",
      "\n",
      "Epoch 44. Loss: 0.011997376476110037, Train_acc 0.9963329081632653\n",
      "\n",
      "Epoch 44. Loss: 0.016259574154956057, Train_acc 0.9961993243243243\n",
      "\n",
      "Epoch 44. Loss: 0.016263879397460445, Train_acc 0.996172399328859\n",
      "\n",
      "Epoch 44. Loss: 0.01468902501076523, Train_acc 0.9961979166666667\n",
      "\n",
      "Epoch 44. Loss: 0.014288657025486798, Train_acc 0.996171357615894\n",
      "\n",
      "Epoch 44. Loss: 0.013489759938186918, Train_acc 0.9961965460526315\n",
      "\n",
      "Epoch 44. Loss: 0.01245559220874296, Train_acc 0.9962214052287581\n",
      "\n",
      "Epoch 44. Loss: 0.01167393915121841, Train_acc 0.9962459415584416\n",
      "\n",
      "Epoch 44. Loss: 0.010541795877036492, Train_acc 0.9962701612903225\n",
      "\n",
      "Epoch 44. Loss: 0.010723800416961646, Train_acc 0.9962439903846154\n",
      "\n",
      "Epoch 44. Loss: 0.00969337332567975, Train_acc 0.9962679140127388\n",
      "\n",
      "Epoch 44. Loss: 0.008855025849664107, Train_acc 0.9962915348101266\n",
      "\n",
      "Epoch 44. Loss: 0.008171952186754849, Train_acc 0.996314858490566\n",
      "\n",
      "Epoch 44. Loss: 0.007794094376249469, Train_acc 0.996337890625\n",
      "\n",
      "Epoch 44. Loss: 0.010701109283402583, Train_acc 0.9962635869565217\n",
      "\n",
      "Epoch 44. Loss: 0.009824996549361963, Train_acc 0.9962866512345679\n",
      "\n",
      "Epoch 44. Loss: 0.009982072044289724, Train_acc 0.9962615030674846\n",
      "\n",
      "Epoch 44. Loss: 0.009051511164029642, Train_acc 0.9962842987804879\n",
      "\n",
      "Epoch 44. Loss: 0.008805647768545335, Train_acc 0.9962594696969697\n",
      "\n",
      "Epoch 44. Loss: 0.008955640966863798, Train_acc 0.9962820030120482\n",
      "\n",
      "Epoch 44. Loss: 0.008818941228244932, Train_acc 0.9962574850299402\n",
      "\n",
      "Epoch 44. Loss: 0.009846206788111536, Train_acc 0.9961867559523809\n",
      "\n",
      "Epoch 44. Loss: 0.008919188183530472, Train_acc 0.9962093195266272\n",
      "\n",
      "Epoch 44. Loss: 0.011465177358970912, Train_acc 0.99609375\n",
      "\n",
      "Epoch 44. Loss: 0.01135485545258451, Train_acc 0.9961165935672515\n",
      "\n",
      "Epoch 44. Loss: 0.011532172546184615, Train_acc 0.99609375\n",
      "\n",
      "Epoch 44. Loss: 0.02242895735984733, Train_acc 0.9959808526011561\n",
      "\n",
      "Epoch 44. Loss: 0.020499353858067306, Train_acc 0.9960039511494253\n",
      "\n",
      "Epoch 44. Loss: 0.02024128012558852, Train_acc 0.9959821428571428\n",
      "\n",
      "Epoch 44. Loss: 0.019262985641071508, Train_acc 0.9959605823863636\n",
      "\n",
      "Epoch 44. Loss: 0.02271624952939985, Train_acc 0.995850988700565\n",
      "\n",
      "Epoch 44. Loss: 0.021608764942477685, Train_acc 0.9958304073033708\n",
      "\n",
      "Epoch 44. Loss: 0.02077960578291763, Train_acc 0.9958100558659218\n",
      "\n",
      "Epoch 44. Loss: 0.02178413032909467, Train_acc 0.9957465277777777\n",
      "\n",
      "Epoch 44. Loss: 0.02040518359321565, Train_acc 0.9957700276243094\n",
      "\n",
      "Epoch 44. Loss: 0.02210214170198033, Train_acc 0.9957503434065934\n",
      "\n",
      "Epoch 44. Loss: 0.0456880369697248, Train_acc 0.9954320355191257\n",
      "\n",
      "Epoch 44. Loss: 0.04192440783210711, Train_acc 0.9954568614130435\n",
      "\n",
      "Epoch 44. Loss: 0.04790093146468505, Train_acc 0.9952702702702703\n",
      "\n",
      "Epoch 44. Loss: 0.04940719359551642, Train_acc 0.9952116935483871\n",
      "\n",
      "Epoch 44. Loss: 0.052168535024834636, Train_acc 0.9949866310160428\n",
      "\n",
      "Epoch 44. Loss: 0.047773806431960726, Train_acc 0.9950132978723404\n",
      "\n",
      "Epoch 44. Loss: 0.04417552850386947, Train_acc 0.9949983465608465\n",
      "\n",
      "Epoch 44. Loss: 0.042367735408915135, Train_acc 0.9949835526315789\n",
      "\n",
      "Epoch 44. Loss: 0.040066947738682974, Train_acc 0.9950098167539267\n",
      "\n",
      "Epoch 44. Loss: 0.04921767580540993, Train_acc 0.9949137369791666\n",
      "\n",
      "Epoch 44. Loss: 0.0478739359351875, Train_acc 0.9948591321243523\n",
      "\n",
      "Epoch 44. Loss: 0.04530909393336311, Train_acc 0.9948453608247423\n",
      "\n",
      "Epoch 44. Loss: 0.0410469685657108, Train_acc 0.9948717948717949\n",
      "\n",
      "Epoch 44. Loss: 0.037313638937357146, Train_acc 0.99488\n",
      "\n",
      "Epoch 45. Loss: 0.03678556574453391, Train_acc 0.984375\n",
      "\n",
      "Epoch 45. Loss: 0.03744804972174297, Train_acc 0.98046875\n",
      "\n",
      "Epoch 45. Loss: 0.034806188933663336, Train_acc 0.984375\n",
      "\n",
      "Epoch 45. Loss: 0.036842330091547464, Train_acc 0.984375\n",
      "\n",
      "Epoch 45. Loss: 0.0347543783873482, Train_acc 0.9859375\n",
      "\n",
      "Epoch 45. Loss: 0.032538148274138284, Train_acc 0.9869791666666666\n",
      "\n",
      "Epoch 45. Loss: 0.031052331449193993, Train_acc 0.9877232142857143\n",
      "\n",
      "Epoch 45. Loss: 0.02862935495445422, Train_acc 0.9892578125\n",
      "\n",
      "Epoch 45. Loss: 0.028801587808751687, Train_acc 0.9878472222222222\n",
      "\n",
      "Epoch 45. Loss: 0.028269796897730494, Train_acc 0.98828125\n",
      "\n",
      "Epoch 45. Loss: 0.026445328124399124, Train_acc 0.9886363636363636\n",
      "\n",
      "Epoch 45. Loss: 0.0252431956780271, Train_acc 0.9889322916666666\n",
      "\n",
      "Epoch 45. Loss: 0.02460358056595769, Train_acc 0.9891826923076923\n",
      "\n",
      "Epoch 45. Loss: 0.022850189289488017, Train_acc 0.9899553571428571\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45. Loss: 0.021207519558999795, Train_acc 0.990625\n",
      "\n",
      "Epoch 45. Loss: 0.02253662781828689, Train_acc 0.99072265625\n",
      "\n",
      "Epoch 45. Loss: 0.020915933441719835, Train_acc 0.9912683823529411\n",
      "\n",
      "Epoch 45. Loss: 0.019488965507538404, Train_acc 0.9917534722222222\n",
      "\n",
      "Epoch 45. Loss: 0.019225825401715593, Train_acc 0.9917763157894737\n",
      "\n",
      "Epoch 45. Loss: 0.01964549678496017, Train_acc 0.991796875\n",
      "\n",
      "Epoch 45. Loss: 0.018004677208273062, Train_acc 0.9921875\n",
      "\n",
      "Epoch 45. Loss: 0.016644280079312727, Train_acc 0.9925426136363636\n",
      "\n",
      "Epoch 45. Loss: 0.015051947469008436, Train_acc 0.9928668478260869\n",
      "\n",
      "Epoch 45. Loss: 0.014406643507175866, Train_acc 0.9928385416666666\n",
      "\n",
      "Epoch 45. Loss: 0.013861763392949006, Train_acc 0.993125\n",
      "\n",
      "Epoch 45. Loss: 0.012576380184349926, Train_acc 0.9933894230769231\n",
      "\n",
      "Epoch 45. Loss: 0.012138148917458218, Train_acc 0.9933449074074074\n",
      "\n",
      "Epoch 45. Loss: 0.016457112080188182, Train_acc 0.9930245535714286\n",
      "\n",
      "Epoch 45. Loss: 0.01501443603865646, Train_acc 0.9932650862068966\n",
      "\n",
      "Epoch 45. Loss: 0.014325921930959905, Train_acc 0.9934895833333334\n",
      "\n",
      "Epoch 45. Loss: 0.013387261135659592, Train_acc 0.9936995967741935\n",
      "\n",
      "Epoch 45. Loss: 0.012303870330705026, Train_acc 0.993896484375\n",
      "\n",
      "Epoch 45. Loss: 0.011402165381271045, Train_acc 0.9940814393939394\n",
      "\n",
      "Epoch 45. Loss: 0.011381725844584465, Train_acc 0.9940257352941176\n",
      "\n",
      "Epoch 45. Loss: 0.010548071504355275, Train_acc 0.9941964285714285\n",
      "\n",
      "Epoch 45. Loss: 0.010531795195389514, Train_acc 0.994140625\n",
      "\n",
      "Epoch 45. Loss: 0.009817334762572101, Train_acc 0.9942989864864865\n",
      "\n",
      "Epoch 45. Loss: 0.00961123364167707, Train_acc 0.9944490131578947\n",
      "\n",
      "Epoch 45. Loss: 0.011148943926369819, Train_acc 0.9941907051282052\n",
      "\n",
      "Epoch 45. Loss: 0.010426472638227647, Train_acc 0.9943359375\n",
      "\n",
      "Epoch 45. Loss: 0.00955969355871061, Train_acc 0.9944740853658537\n",
      "\n",
      "Epoch 45. Loss: 0.00918250774848264, Train_acc 0.9946056547619048\n",
      "\n",
      "Epoch 45. Loss: 0.009614881460438384, Train_acc 0.9945494186046512\n",
      "\n",
      "Epoch 45. Loss: 0.008986537620599758, Train_acc 0.9946732954545454\n",
      "\n",
      "Epoch 45. Loss: 0.009829382194735729, Train_acc 0.9946180555555556\n",
      "\n",
      "Epoch 45. Loss: 0.011037683943204394, Train_acc 0.9945652173913043\n",
      "\n",
      "Epoch 45. Loss: 0.011119634938352387, Train_acc 0.9945146276595744\n",
      "\n",
      "Epoch 45. Loss: 0.010074940163948162, Train_acc 0.99462890625\n",
      "\n",
      "Epoch 45. Loss: 0.010164596015117785, Train_acc 0.9945790816326531\n",
      "\n",
      "Epoch 45. Loss: 0.015444613135369618, Train_acc 0.99421875\n",
      "\n",
      "Epoch 45. Loss: 0.014293620568748116, Train_acc 0.9943321078431373\n",
      "\n",
      "Epoch 45. Loss: 0.013001876125527887, Train_acc 0.9944411057692307\n",
      "\n",
      "Epoch 45. Loss: 0.016022090583855036, Train_acc 0.9942511792452831\n",
      "\n",
      "Epoch 45. Loss: 0.02354711619300913, Train_acc 0.9937789351851852\n",
      "\n",
      "Epoch 45. Loss: 0.021802400976344387, Train_acc 0.9938920454545455\n",
      "\n",
      "Epoch 45. Loss: 0.02014642182060281, Train_acc 0.9940011160714286\n",
      "\n",
      "Epoch 45. Loss: 0.01838924255357563, Train_acc 0.9941063596491229\n",
      "\n",
      "Epoch 45. Loss: 0.01819915339100104, Train_acc 0.994073275862069\n",
      "\n",
      "Epoch 45. Loss: 0.020907774699459147, Train_acc 0.9937764830508474\n",
      "\n",
      "Epoch 45. Loss: 0.02088176508193881, Train_acc 0.99375\n",
      "\n",
      "Epoch 45. Loss: 0.02102922282617394, Train_acc 0.9935963114754098\n",
      "\n",
      "Epoch 45. Loss: 0.019230640881890984, Train_acc 0.9936995967741935\n",
      "\n",
      "Epoch 45. Loss: 0.017742783274026154, Train_acc 0.9937996031746031\n",
      "\n",
      "Epoch 45. Loss: 0.01769350974628756, Train_acc 0.99365234375\n",
      "\n",
      "Epoch 45. Loss: 0.017042877045596507, Train_acc 0.99375\n",
      "\n",
      "Epoch 45. Loss: 0.0163009913606866, Train_acc 0.993844696969697\n",
      "\n",
      "Epoch 45. Loss: 0.014937169735290749, Train_acc 0.9939365671641791\n",
      "\n",
      "Epoch 45. Loss: 0.014545855661175975, Train_acc 0.9940257352941176\n",
      "\n",
      "Epoch 45. Loss: 0.013622735468991693, Train_acc 0.9941123188405797\n",
      "\n",
      "Epoch 45. Loss: 0.013037662205575194, Train_acc 0.9941964285714285\n",
      "\n",
      "Epoch 45. Loss: 0.012985165023784297, Train_acc 0.9941681338028169\n",
      "\n",
      "Epoch 45. Loss: 0.012613365147096328, Train_acc 0.9942491319444444\n",
      "\n",
      "Epoch 45. Loss: 0.011594773623942504, Train_acc 0.9943279109589042\n",
      "\n",
      "Epoch 45. Loss: 0.011231705305963012, Train_acc 0.9942989864864865\n",
      "\n",
      "Epoch 45. Loss: 0.010266255487380253, Train_acc 0.994375\n",
      "\n",
      "Epoch 45. Loss: 0.010111043139735902, Train_acc 0.9943462171052632\n",
      "\n",
      "Epoch 45. Loss: 0.009838019416725675, Train_acc 0.9944196428571429\n",
      "\n",
      "Epoch 45. Loss: 0.010093496201332843, Train_acc 0.9943910256410257\n",
      "\n",
      "Epoch 45. Loss: 0.009850874561425837, Train_acc 0.9944620253164557\n",
      "\n",
      "Epoch 45. Loss: 0.008994819519689792, Train_acc 0.99453125\n",
      "\n",
      "Epoch 45. Loss: 0.009741164488587781, Train_acc 0.9945023148148148\n",
      "\n",
      "Epoch 45. Loss: 0.011454587945038681, Train_acc 0.9943788109756098\n",
      "\n",
      "Epoch 45. Loss: 0.01054441289785022, Train_acc 0.9944465361445783\n",
      "\n",
      "Epoch 45. Loss: 0.010666933678232264, Train_acc 0.9945126488095238\n",
      "\n",
      "Epoch 45. Loss: 0.009716991013136625, Train_acc 0.994577205882353\n",
      "\n",
      "Epoch 45. Loss: 0.00885810927843045, Train_acc 0.994640261627907\n",
      "\n",
      "Epoch 45. Loss: 0.008215181573696353, Train_acc 0.9947018678160919\n",
      "\n",
      "Epoch 45. Loss: 0.007498080090329723, Train_acc 0.9947620738636364\n",
      "\n",
      "Epoch 45. Loss: 0.009300462318044015, Train_acc 0.9946453651685393\n",
      "\n",
      "Epoch 45. Loss: 0.008507923605924346, Train_acc 0.9947048611111111\n",
      "\n",
      "Epoch 45. Loss: 0.007941434085341243, Train_acc 0.9947630494505495\n",
      "\n",
      "Epoch 45. Loss: 0.007402444237818076, Train_acc 0.9948199728260869\n",
      "\n",
      "Epoch 45. Loss: 0.007468789704307694, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 45. Loss: 0.008686213653681975, Train_acc 0.9947639627659575\n",
      "\n",
      "Epoch 45. Loss: 0.008155067221207887, Train_acc 0.9948190789473684\n",
      "\n",
      "Epoch 45. Loss: 0.007392406244900201, Train_acc 0.994873046875\n",
      "\n",
      "Epoch 45. Loss: 0.007000857324929274, Train_acc 0.9949259020618557\n",
      "\n",
      "Epoch 45. Loss: 0.01130891589659265, Train_acc 0.9948182397959183\n",
      "\n",
      "Epoch 45. Loss: 0.01047553679351042, Train_acc 0.9948705808080808\n",
      "\n",
      "Epoch 45. Loss: 0.009449132265302996, Train_acc 0.994921875\n",
      "\n",
      "[Epoch 45 Batch 100] Loss: 0.008786833251255862 Training: accuracy=0.994972\n",
      "Epoch 45. Loss: 0.008786833251255862, Train_acc 0.9949721534653465\n",
      "\n",
      "Epoch 45. Loss: 0.008333549579743844, Train_acc 0.9950214460784313\n",
      "\n",
      "Epoch 45. Loss: 0.007801146715445192, Train_acc 0.9950697815533981\n",
      "\n",
      "Epoch 45. Loss: 0.007407267860304896, Train_acc 0.9951171875\n",
      "\n",
      "Epoch 45. Loss: 0.009509313453791962, Train_acc 0.995014880952381\n",
      "\n",
      "Epoch 45. Loss: 0.009980893242709423, Train_acc 0.9949882075471698\n",
      "\n",
      "Epoch 45. Loss: 0.0103360197171741, Train_acc 0.9949620327102804\n",
      "\n",
      "Epoch 45. Loss: 0.009460144406293178, Train_acc 0.9950086805555556\n",
      "\n",
      "Epoch 45. Loss: 0.01077302623456807, Train_acc 0.9949827981651376\n",
      "\n",
      "Epoch 45. Loss: 0.010188755211601475, Train_acc 0.9950284090909091\n",
      "\n",
      "Epoch 45. Loss: 0.009214940400258663, Train_acc 0.9950731981981982\n",
      "\n",
      "Epoch 45. Loss: 0.010553511811497178, Train_acc 0.9950474330357143\n",
      "\n",
      "Epoch 45. Loss: 0.009628180374739944, Train_acc 0.9950912610619469\n",
      "\n",
      "Epoch 45. Loss: 0.009027247327972991, Train_acc 0.9951343201754386\n",
      "\n",
      "Epoch 45. Loss: 0.010805536164411494, Train_acc 0.9951086956521739\n",
      "\n",
      "Epoch 45. Loss: 0.009923718310357859, Train_acc 0.9951508620689655\n",
      "\n",
      "Epoch 45. Loss: 0.009246133462975975, Train_acc 0.9951923076923077\n",
      "\n",
      "Epoch 45. Loss: 0.009695191484442851, Train_acc 0.995166843220339\n",
      "\n",
      "Epoch 45. Loss: 0.009513163501100094, Train_acc 0.9952074579831933\n",
      "\n",
      "Epoch 45. Loss: 0.00862608535840483, Train_acc 0.9952473958333333\n",
      "\n",
      "Epoch 45. Loss: 0.01169200107831691, Train_acc 0.995157541322314\n",
      "\n",
      "Epoch 45. Loss: 0.01055147451827095, Train_acc 0.9951972336065574\n",
      "\n",
      "Epoch 45. Loss: 0.009790483252726492, Train_acc 0.9952362804878049\n",
      "\n",
      "Epoch 45. Loss: 0.010469214814772454, Train_acc 0.9952116935483871\n",
      "\n",
      "Epoch 45. Loss: 0.009521381421904488, Train_acc 0.99525\n",
      "\n",
      "Epoch 45. Loss: 0.009385385466236523, Train_acc 0.9952256944444444\n",
      "\n",
      "Epoch 45. Loss: 0.008658815844463097, Train_acc 0.9952632874015748\n",
      "\n",
      "Epoch 45. Loss: 0.009075824587291587, Train_acc 0.9952392578125\n",
      "\n",
      "Epoch 45. Loss: 0.0083286440134945, Train_acc 0.9952761627906976\n",
      "\n",
      "Epoch 45. Loss: 0.007936496495312674, Train_acc 0.9953125\n",
      "\n",
      "Epoch 45. Loss: 0.00720416512409409, Train_acc 0.9953482824427481\n",
      "\n",
      "Epoch 45. Loss: 0.008100660946842076, Train_acc 0.9953243371212122\n",
      "\n",
      "Epoch 45. Loss: 0.0075416425146171825, Train_acc 0.995359492481203\n",
      "\n",
      "Epoch 45. Loss: 0.006926114149988536, Train_acc 0.9953941231343284\n",
      "\n",
      "Epoch 45. Loss: 0.006312350628736253, Train_acc 0.9954282407407408\n",
      "\n",
      "Epoch 45. Loss: 0.006309787174727888, Train_acc 0.9954618566176471\n",
      "\n",
      "Epoch 45. Loss: 0.005713713880199675, Train_acc 0.9954949817518248\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45. Loss: 0.005486977968537943, Train_acc 0.9955276268115942\n",
      "\n",
      "Epoch 45. Loss: 0.005931073016456488, Train_acc 0.9955035971223022\n",
      "\n",
      "Epoch 45. Loss: 0.006349519400923005, Train_acc 0.9954799107142858\n",
      "\n",
      "Epoch 45. Loss: 0.005807934429043354, Train_acc 0.9955119680851063\n",
      "\n",
      "Epoch 45. Loss: 0.007871201165730198, Train_acc 0.9954335387323944\n",
      "\n",
      "Epoch 45. Loss: 0.00718450841455335, Train_acc 0.995465472027972\n",
      "\n",
      "Epoch 45. Loss: 0.008801793914872479, Train_acc 0.9954427083333334\n",
      "\n",
      "Epoch 45. Loss: 0.008417525773276155, Train_acc 0.9954741379310345\n",
      "\n",
      "Epoch 45. Loss: 0.008615592242803512, Train_acc 0.9954516267123288\n",
      "\n",
      "Epoch 45. Loss: 0.008284212003150288, Train_acc 0.9954825680272109\n",
      "\n",
      "Epoch 45. Loss: 0.007521882260682765, Train_acc 0.9955130912162162\n",
      "\n",
      "Epoch 45. Loss: 0.00926387572721474, Train_acc 0.9954383389261745\n",
      "\n",
      "Epoch 45. Loss: 0.009274796525560312, Train_acc 0.9954166666666666\n",
      "\n",
      "Epoch 45. Loss: 0.009911865968932952, Train_acc 0.9953952814569537\n",
      "\n",
      "Epoch 45. Loss: 0.009937891774115186, Train_acc 0.995374177631579\n",
      "\n",
      "Epoch 45. Loss: 0.00945489372706761, Train_acc 0.9954044117647058\n",
      "\n",
      "Epoch 45. Loss: 0.00875080486536488, Train_acc 0.9954342532467533\n",
      "\n",
      "Epoch 45. Loss: 0.00848305067964314, Train_acc 0.9954637096774194\n",
      "\n",
      "Epoch 45. Loss: 0.008987734353970753, Train_acc 0.9954427083333334\n",
      "\n",
      "Epoch 45. Loss: 0.008151021024420873, Train_acc 0.9954717356687898\n",
      "\n",
      "Epoch 45. Loss: 0.0074347289642334126, Train_acc 0.9955003955696202\n",
      "\n",
      "Epoch 45. Loss: 0.0068587591243921345, Train_acc 0.9955286949685535\n",
      "\n",
      "Epoch 45. Loss: 0.006311893560310181, Train_acc 0.995556640625\n",
      "\n",
      "Epoch 45. Loss: 0.01069937878652213, Train_acc 0.9954386645962733\n",
      "\n",
      "Epoch 45. Loss: 0.00994201953943489, Train_acc 0.9954668209876543\n",
      "\n",
      "Epoch 45. Loss: 0.009364430117481216, Train_acc 0.9954946319018405\n",
      "\n",
      "Epoch 45. Loss: 0.008740729044711527, Train_acc 0.9955221036585366\n",
      "\n",
      "Epoch 45. Loss: 0.01134269359782571, Train_acc 0.9955018939393939\n",
      "\n",
      "Epoch 45. Loss: 0.01117370497577102, Train_acc 0.9955289909638554\n",
      "\n",
      "Epoch 45. Loss: 0.010254134890036681, Train_acc 0.9955557634730539\n",
      "\n",
      "Epoch 45. Loss: 0.01389435580962619, Train_acc 0.9954892113095238\n",
      "\n",
      "Epoch 45. Loss: 0.012933802143949754, Train_acc 0.9955159023668639\n",
      "\n",
      "Epoch 45. Loss: 0.012047571711959082, Train_acc 0.9955422794117647\n",
      "\n",
      "Epoch 45. Loss: 0.011692444386233364, Train_acc 0.9955226608187134\n",
      "\n",
      "Epoch 45. Loss: 0.011297765519529112, Train_acc 0.9955032703488372\n",
      "\n",
      "Epoch 45. Loss: 0.010279587046669002, Train_acc 0.9955292630057804\n",
      "\n",
      "Epoch 45. Loss: 0.009385712110354967, Train_acc 0.9955549568965517\n",
      "\n",
      "Epoch 45. Loss: 0.008855420050043881, Train_acc 0.9955803571428572\n",
      "\n",
      "Epoch 45. Loss: 0.008924857330637295, Train_acc 0.9955610795454546\n",
      "\n",
      "Epoch 45. Loss: 0.009838665956840324, Train_acc 0.9955420197740112\n",
      "\n",
      "Epoch 45. Loss: 0.008974575279003002, Train_acc 0.9955670646067416\n",
      "\n",
      "Epoch 45. Loss: 0.008100384748698484, Train_acc 0.9955918296089385\n",
      "\n",
      "Epoch 45. Loss: 0.007580666063029657, Train_acc 0.9956163194444444\n",
      "\n",
      "Epoch 45. Loss: 0.007588077136396549, Train_acc 0.9956405386740331\n",
      "\n",
      "Epoch 45. Loss: 0.008706153376566633, Train_acc 0.9956215659340659\n",
      "\n",
      "Epoch 45. Loss: 0.008268468925655423, Train_acc 0.9956454918032787\n",
      "\n",
      "Epoch 45. Loss: 0.00847807947111178, Train_acc 0.9956266983695652\n",
      "\n",
      "Epoch 45. Loss: 0.01166699795405908, Train_acc 0.9956081081081081\n",
      "\n",
      "Epoch 45. Loss: 0.012584478871353062, Train_acc 0.9955477150537635\n",
      "\n",
      "Epoch 45. Loss: 0.013662943027610414, Train_acc 0.9954879679144385\n",
      "\n",
      "Epoch 45. Loss: 0.015689346595580727, Train_acc 0.9954288563829787\n",
      "\n",
      "Epoch 45. Loss: 0.015059810288079397, Train_acc 0.9954117063492064\n",
      "\n",
      "Epoch 45. Loss: 0.01406539231635137, Train_acc 0.9954358552631579\n",
      "\n",
      "Epoch 45. Loss: 0.012886562641646001, Train_acc 0.9954597513089005\n",
      "\n",
      "Epoch 45. Loss: 0.013279711406992854, Train_acc 0.9954427083333334\n",
      "\n",
      "Epoch 45. Loss: 0.014127169357151075, Train_acc 0.9954258419689119\n",
      "\n",
      "Epoch 45. Loss: 0.014416873952517166, Train_acc 0.9954091494845361\n",
      "\n",
      "Epoch 45. Loss: 0.013915644102486302, Train_acc 0.9954326923076923\n",
      "\n",
      "Epoch 45. Loss: 0.013500166286402044, Train_acc 0.99544\n",
      "\n",
      "Epoch 46. Loss: 0.012226020538153288, Train_acc 1.0\n",
      "\n",
      "Epoch 46. Loss: 0.011066702866096382, Train_acc 1.0\n",
      "\n",
      "Epoch 46. Loss: 0.009990816463481189, Train_acc 1.0\n",
      "\n",
      "Epoch 46. Loss: 0.015864618256197095, Train_acc 0.994140625\n",
      "\n",
      "Epoch 46. Loss: 0.01503184617415582, Train_acc 0.9953125\n",
      "\n",
      "Epoch 46. Loss: 0.013635661428526923, Train_acc 0.99609375\n",
      "\n",
      "Epoch 46. Loss: 0.014757502056976454, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 46. Loss: 0.014577093030053643, Train_acc 0.9951171875\n",
      "\n",
      "Epoch 46. Loss: 0.01323912796828592, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 46. Loss: 0.012647720586092271, Train_acc 0.99609375\n",
      "\n",
      "Epoch 46. Loss: 0.011568694260807482, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 46. Loss: 0.010477983999725415, Train_acc 0.9967447916666666\n",
      "\n",
      "Epoch 46. Loss: 0.009579716470592827, Train_acc 0.9969951923076923\n",
      "\n",
      "Epoch 46. Loss: 0.008685527346454064, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 46. Loss: 0.009151161441435216, Train_acc 0.996875\n",
      "\n",
      "Epoch 46. Loss: 0.008299108169796511, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 46. Loss: 0.007517241106302987, Train_acc 0.9972426470588235\n",
      "\n",
      "Epoch 46. Loss: 0.009108555092696653, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 46. Loss: 0.009037651497230804, Train_acc 0.9962993421052632\n",
      "\n",
      "Epoch 46. Loss: 0.008251131396257915, Train_acc 0.996484375\n",
      "\n",
      "Epoch 46. Loss: 0.007575192174812292, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 46. Loss: 0.006897827700376631, Train_acc 0.9968039772727273\n",
      "\n",
      "Epoch 46. Loss: 0.012231524555921663, Train_acc 0.9962635869565217\n",
      "\n",
      "Epoch 46. Loss: 0.011055223126456612, Train_acc 0.9964192708333334\n",
      "\n",
      "Epoch 46. Loss: 0.010993588622729904, Train_acc 0.99625\n",
      "\n",
      "Epoch 46. Loss: 0.012049145540285938, Train_acc 0.99609375\n",
      "\n",
      "Epoch 46. Loss: 0.012210219035913497, Train_acc 0.9959490740740741\n",
      "\n",
      "Epoch 46. Loss: 0.011267913480433777, Train_acc 0.99609375\n",
      "\n",
      "Epoch 46. Loss: 0.01050453498106416, Train_acc 0.9962284482758621\n",
      "\n",
      "Epoch 46. Loss: 0.011478361390303516, Train_acc 0.99609375\n",
      "\n",
      "Epoch 46. Loss: 0.01270766689086343, Train_acc 0.9957157258064516\n",
      "\n",
      "Epoch 46. Loss: 0.01356971010897504, Train_acc 0.99560546875\n",
      "\n",
      "Epoch 46. Loss: 0.01235308403168422, Train_acc 0.9957386363636364\n",
      "\n",
      "Epoch 46. Loss: 0.014769567066976148, Train_acc 0.9954044117647058\n",
      "\n",
      "Epoch 46. Loss: 0.014070023730366275, Train_acc 0.9953125\n",
      "\n",
      "Epoch 46. Loss: 0.01374824480113582, Train_acc 0.9952256944444444\n",
      "\n",
      "Epoch 46. Loss: 0.014342054263328281, Train_acc 0.995143581081081\n",
      "\n",
      "Epoch 46. Loss: 0.014142357608444782, Train_acc 0.9950657894736842\n",
      "\n",
      "Epoch 46. Loss: 0.012777819257449918, Train_acc 0.9951923076923077\n",
      "\n",
      "Epoch 46. Loss: 0.011711573820200693, Train_acc 0.9953125\n",
      "\n",
      "Epoch 46. Loss: 0.010822751579854309, Train_acc 0.9954268292682927\n",
      "\n",
      "Epoch 46. Loss: 0.009936171742013174, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 46. Loss: 0.010225288339761864, Train_acc 0.9954578488372093\n",
      "\n",
      "Epoch 46. Loss: 0.009782650393969985, Train_acc 0.9955610795454546\n",
      "\n",
      "Epoch 46. Loss: 0.00941248302331016, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 46. Loss: 0.008614933603290726, Train_acc 0.9957540760869565\n",
      "\n",
      "Epoch 46. Loss: 0.007858598901659856, Train_acc 0.995844414893617\n",
      "\n",
      "Epoch 46. Loss: 0.0077890959911769125, Train_acc 0.9957682291666666\n",
      "\n",
      "Epoch 46. Loss: 0.007928561533977882, Train_acc 0.9958545918367347\n",
      "\n",
      "Epoch 46. Loss: 0.010142651676079896, Train_acc 0.99578125\n",
      "\n",
      "Epoch 46. Loss: 0.01249555943513626, Train_acc 0.9957107843137255\n",
      "\n",
      "Epoch 46. Loss: 0.013586541732591816, Train_acc 0.9956430288461539\n",
      "\n",
      "Epoch 46. Loss: 0.016628132659592416, Train_acc 0.9954304245283019\n",
      "\n",
      "Epoch 46. Loss: 0.015021433080511409, Train_acc 0.9955150462962963\n",
      "\n",
      "Epoch 46. Loss: 0.014488620738932893, Train_acc 0.9954545454545455\n",
      "\n",
      "Epoch 46. Loss: 0.013578723188042109, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 46. Loss: 0.012753187122910736, Train_acc 0.9956140350877193\n",
      "\n",
      "Epoch 46. Loss: 0.016287801566394734, Train_acc 0.9955549568965517\n",
      "\n",
      "Epoch 46. Loss: 0.01816207839787534, Train_acc 0.9954978813559322\n",
      "\n",
      "Epoch 46. Loss: 0.021427578914825895, Train_acc 0.9951822916666667\n",
      "\n",
      "Epoch 46. Loss: 0.019844974205939274, Train_acc 0.9952612704918032\n",
      "\n",
      "Epoch 46. Loss: 0.01832114245836285, Train_acc 0.9953377016129032\n",
      "\n",
      "Epoch 46. Loss: 0.030047132846811538, Train_acc 0.9946676587301587\n",
      "\n",
      "Epoch 46. Loss: 0.028136909851818496, Train_acc 0.9947509765625\n",
      "\n",
      "Epoch 46. Loss: 0.026702280450066222, Train_acc 0.9947115384615385\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46. Loss: 0.024469717856377627, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 46. Loss: 0.02737766945314133, Train_acc 0.9944029850746269\n",
      "\n",
      "Epoch 46. Loss: 0.03084926257090322, Train_acc 0.994140625\n",
      "\n",
      "Epoch 46. Loss: 0.030745774056523012, Train_acc 0.9939990942028986\n",
      "\n",
      "Epoch 46. Loss: 0.029067736085661322, Train_acc 0.9939732142857143\n",
      "\n",
      "Epoch 46. Loss: 0.03786052425182587, Train_acc 0.9936179577464789\n",
      "\n",
      "Epoch 46. Loss: 0.03992196687588149, Train_acc 0.9931640625\n",
      "\n",
      "Epoch 46. Loss: 0.040919913517198446, Train_acc 0.9929366438356164\n",
      "\n",
      "Epoch 46. Loss: 0.040438213497485054, Train_acc 0.9927153716216216\n",
      "\n",
      "Epoch 46. Loss: 0.04458297435946942, Train_acc 0.9925\n",
      "\n",
      "Epoch 46. Loss: 0.041094656835565097, Train_acc 0.9925986842105263\n",
      "\n",
      "Epoch 46. Loss: 0.03830642300522547, Train_acc 0.9926948051948052\n",
      "\n",
      "Epoch 46. Loss: 0.03779667844780881, Train_acc 0.9926883012820513\n",
      "\n",
      "Epoch 46. Loss: 0.03482583147652685, Train_acc 0.9926819620253164\n",
      "\n",
      "Epoch 46. Loss: 0.033849620661447095, Train_acc 0.992578125\n",
      "\n",
      "Epoch 46. Loss: 0.03195418462870388, Train_acc 0.9925733024691358\n",
      "\n",
      "Epoch 46. Loss: 0.03160961404339554, Train_acc 0.9924733231707317\n",
      "\n",
      "Epoch 46. Loss: 0.02993064967449977, Train_acc 0.9924698795180723\n",
      "\n",
      "Epoch 46. Loss: 0.028179926553277435, Train_acc 0.9925595238095238\n",
      "\n",
      "Epoch 46. Loss: 0.025807577430970906, Train_acc 0.9926470588235294\n",
      "\n",
      "Epoch 46. Loss: 0.024299255048275684, Train_acc 0.9926417151162791\n",
      "\n",
      "Epoch 46. Loss: 0.03181099686179223, Train_acc 0.9925466954022989\n",
      "\n",
      "Epoch 46. Loss: 0.031082731684926115, Train_acc 0.9924538352272727\n",
      "\n",
      "Epoch 46. Loss: 0.03255169029612806, Train_acc 0.9924508426966292\n",
      "\n",
      "Epoch 46. Loss: 0.03645093606930495, Train_acc 0.9923611111111111\n",
      "\n",
      "Epoch 46. Loss: 0.034233443181409126, Train_acc 0.9923592032967034\n",
      "\n",
      "Epoch 46. Loss: 0.03126800470153423, Train_acc 0.9924422554347826\n",
      "\n",
      "Epoch 46. Loss: 0.038106113635897026, Train_acc 0.9922715053763441\n",
      "\n",
      "Epoch 46. Loss: 0.03487331044381802, Train_acc 0.9923537234042553\n",
      "\n",
      "Epoch 46. Loss: 0.03396413379197668, Train_acc 0.9923519736842106\n",
      "\n",
      "Epoch 46. Loss: 0.0311329513523163, Train_acc 0.992431640625\n",
      "\n",
      "Epoch 46. Loss: 0.031343805021034024, Train_acc 0.9923485824742269\n",
      "\n",
      "Epoch 46. Loss: 0.0287531195552525, Train_acc 0.9924266581632653\n",
      "\n",
      "Epoch 46. Loss: 0.02643880344298873, Train_acc 0.9925031565656566\n",
      "\n",
      "Epoch 46. Loss: 0.024108383855714444, Train_acc 0.992578125\n",
      "\n",
      "[Epoch 46 Batch 100] Loss: 0.02245938642829124 Training: accuracy=0.992652\n",
      "Epoch 46. Loss: 0.02245938642829124, Train_acc 0.9926516089108911\n",
      "\n",
      "Epoch 46. Loss: 0.02054282151580868, Train_acc 0.9927236519607843\n",
      "\n",
      "Epoch 46. Loss: 0.019225012958088677, Train_acc 0.9927942961165048\n",
      "\n",
      "Epoch 46. Loss: 0.019081372611259664, Train_acc 0.9927133413461539\n",
      "\n",
      "Epoch 46. Loss: 0.017390295536102576, Train_acc 0.9927827380952381\n",
      "\n",
      "Epoch 46. Loss: 0.019715377394063822, Train_acc 0.9927034198113207\n",
      "\n",
      "Epoch 46. Loss: 0.018134200601424472, Train_acc 0.9927716121495327\n",
      "\n",
      "Epoch 46. Loss: 0.017212807915639013, Train_acc 0.9928385416666666\n",
      "\n",
      "Epoch 46. Loss: 0.01765865719947022, Train_acc 0.9928325688073395\n",
      "\n",
      "Epoch 46. Loss: 0.01786836656897785, Train_acc 0.9928267045454545\n",
      "\n",
      "Epoch 46. Loss: 0.016537703071262136, Train_acc 0.9928913288288288\n",
      "\n",
      "Epoch 46. Loss: 0.015411672475241745, Train_acc 0.9929547991071429\n",
      "\n",
      "Epoch 46. Loss: 0.017304859294566325, Train_acc 0.9929480088495575\n",
      "\n",
      "Epoch 46. Loss: 0.01582401971305711, Train_acc 0.9930098684210527\n",
      "\n",
      "Epoch 46. Loss: 0.01537600840510699, Train_acc 0.993070652173913\n",
      "\n",
      "Epoch 46. Loss: 0.014187999516413564, Train_acc 0.9931303879310345\n",
      "\n",
      "Epoch 46. Loss: 0.012968302291537186, Train_acc 0.9931891025641025\n",
      "\n",
      "Epoch 46. Loss: 0.015057943110380941, Train_acc 0.9930481991525424\n",
      "\n",
      "Epoch 46. Loss: 0.014066309408215618, Train_acc 0.9931066176470589\n",
      "\n",
      "Epoch 46. Loss: 0.013222456070439162, Train_acc 0.9931640625\n",
      "\n",
      "Epoch 46. Loss: 0.012056019915221162, Train_acc 0.9932205578512396\n",
      "\n",
      "Epoch 46. Loss: 0.010930298258368769, Train_acc 0.9932761270491803\n",
      "\n",
      "Epoch 46. Loss: 0.01166803813532406, Train_acc 0.9932672764227642\n",
      "\n",
      "Epoch 46. Loss: 0.012020176830638175, Train_acc 0.9932585685483871\n",
      "\n",
      "Epoch 46. Loss: 0.011402813052235894, Train_acc 0.9933125\n",
      "\n",
      "Epoch 46. Loss: 0.010587687889947461, Train_acc 0.9933655753968254\n",
      "\n",
      "Epoch 46. Loss: 0.009886888788273008, Train_acc 0.99341781496063\n",
      "\n",
      "Epoch 46. Loss: 0.015069324337956373, Train_acc 0.993408203125\n",
      "\n",
      "Epoch 46. Loss: 0.01401106181645429, Train_acc 0.9934593023255814\n",
      "\n",
      "Epoch 46. Loss: 0.012900871889552794, Train_acc 0.9935096153846154\n",
      "\n",
      "Epoch 46. Loss: 0.01176920534809201, Train_acc 0.9935591603053435\n",
      "\n",
      "Epoch 46. Loss: 0.01586540082073005, Train_acc 0.9934895833333334\n",
      "\n",
      "Epoch 46. Loss: 0.018483272543333103, Train_acc 0.9934797932330827\n",
      "\n",
      "Epoch 46. Loss: 0.01681584814493623, Train_acc 0.9935284514925373\n",
      "\n",
      "Epoch 46. Loss: 0.015339748271113039, Train_acc 0.9935763888888889\n",
      "\n",
      "Epoch 46. Loss: 0.01596331871998793, Train_acc 0.9935661764705882\n",
      "\n",
      "Epoch 46. Loss: 0.015703539609484254, Train_acc 0.9935561131386861\n",
      "\n",
      "Epoch 46. Loss: 0.020837445312356095, Train_acc 0.9934895833333334\n",
      "\n",
      "Epoch 46. Loss: 0.019585311490549272, Train_acc 0.9934802158273381\n",
      "\n",
      "Epoch 46. Loss: 0.018994951225000882, Train_acc 0.9934709821428571\n",
      "\n",
      "Epoch 46. Loss: 0.01840191019476497, Train_acc 0.9935172872340425\n",
      "\n",
      "Epoch 46. Loss: 0.01804017755747775, Train_acc 0.9935079225352113\n",
      "\n",
      "Epoch 46. Loss: 0.019510841220864113, Train_acc 0.9933347902097902\n",
      "\n",
      "Epoch 46. Loss: 0.018857417829556876, Train_acc 0.9933810763888888\n",
      "\n",
      "Epoch 46. Loss: 0.01731975816154356, Train_acc 0.993426724137931\n",
      "\n",
      "Epoch 46. Loss: 0.017112632419591028, Train_acc 0.9934182363013698\n",
      "\n",
      "Epoch 46. Loss: 0.01580146326021094, Train_acc 0.9934630102040817\n",
      "\n",
      "Epoch 46. Loss: 0.014758831574208191, Train_acc 0.9935071790540541\n",
      "\n",
      "Epoch 46. Loss: 0.015104265940505254, Train_acc 0.993498322147651\n",
      "\n",
      "Epoch 46. Loss: 0.015023190300003876, Train_acc 0.9934895833333334\n",
      "\n",
      "Epoch 46. Loss: 0.014142170715632608, Train_acc 0.9935326986754967\n",
      "\n",
      "Epoch 46. Loss: 0.013272788945185455, Train_acc 0.9935752467105263\n",
      "\n",
      "Epoch 46. Loss: 0.015338171041024308, Train_acc 0.9935661764705882\n",
      "\n",
      "Epoch 46. Loss: 0.014157199790116471, Train_acc 0.9936079545454546\n",
      "\n",
      "Epoch 46. Loss: 0.014067720596524766, Train_acc 0.9935987903225807\n",
      "\n",
      "Epoch 46. Loss: 0.014015717967926881, Train_acc 0.9935897435897436\n",
      "\n",
      "Epoch 46. Loss: 0.013082897214215477, Train_acc 0.9936305732484076\n",
      "\n",
      "Epoch 46. Loss: 0.012508813176487218, Train_acc 0.9936708860759493\n",
      "\n",
      "Epoch 46. Loss: 0.0138923977395305, Train_acc 0.9936124213836478\n",
      "\n",
      "Epoch 46. Loss: 0.013453284781164733, Train_acc 0.99365234375\n",
      "\n",
      "Epoch 46. Loss: 0.012492530500280983, Train_acc 0.9936917701863354\n",
      "\n",
      "Epoch 46. Loss: 0.0114600397992624, Train_acc 0.9937307098765432\n",
      "\n",
      "Epoch 46. Loss: 0.01739573370055793, Train_acc 0.9937212423312883\n",
      "\n",
      "Epoch 46. Loss: 0.01706506120982562, Train_acc 0.9937118902439024\n",
      "\n",
      "Epoch 46. Loss: 0.018494752566422176, Train_acc 0.9936079545454546\n",
      "\n",
      "Epoch 46. Loss: 0.02109643371737464, Train_acc 0.9935993975903614\n",
      "\n",
      "Epoch 46. Loss: 0.01919732207677332, Train_acc 0.9936377245508982\n",
      "\n",
      "Epoch 46. Loss: 0.019028857592835135, Train_acc 0.9936290922619048\n",
      "\n",
      "Epoch 46. Loss: 0.01913542042889664, Train_acc 0.9936205621301775\n",
      "\n",
      "Epoch 46. Loss: 0.01838879251004877, Train_acc 0.9936580882352941\n",
      "\n",
      "Epoch 46. Loss: 0.021700650499954423, Train_acc 0.9936038011695907\n",
      "\n",
      "Epoch 46. Loss: 0.02291189510824794, Train_acc 0.9935955668604651\n",
      "\n",
      "Epoch 46. Loss: 0.02227879095854623, Train_acc 0.9935874277456648\n",
      "\n",
      "Epoch 46. Loss: 0.020961910650422542, Train_acc 0.9936242816091954\n",
      "\n",
      "Epoch 46. Loss: 0.01961414786863956, Train_acc 0.9936160714285714\n",
      "\n",
      "Epoch 46. Loss: 0.0224283857436952, Train_acc 0.9936079545454546\n",
      "\n",
      "Epoch 46. Loss: 0.020727299001095625, Train_acc 0.9936440677966102\n",
      "\n",
      "Epoch 46. Loss: 0.01954609290922695, Train_acc 0.9936358848314607\n",
      "\n",
      "Epoch 46. Loss: 0.018370620913043742, Train_acc 0.9936714385474861\n",
      "\n",
      "Epoch 46. Loss: 0.016653139196770004, Train_acc 0.9937065972222222\n",
      "\n",
      "Epoch 46. Loss: 0.015156355128455114, Train_acc 0.9937413674033149\n",
      "\n",
      "Epoch 46. Loss: 0.013863862385728615, Train_acc 0.9937757554945055\n",
      "\n",
      "Epoch 46. Loss: 0.013356896300952426, Train_acc 0.9937670765027322\n",
      "\n",
      "Epoch 46. Loss: 0.012430700918144695, Train_acc 0.9938009510869565\n",
      "\n",
      "Epoch 46. Loss: 0.011265284077685738, Train_acc 0.9938344594594595\n",
      "\n",
      "Epoch 46. Loss: 0.010243761824543772, Train_acc 0.9938676075268817\n",
      "\n",
      "Epoch 46. Loss: 0.010838196943976431, Train_acc 0.9938586229946524\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46. Loss: 0.010501972977022484, Train_acc 0.993891289893617\n",
      "\n",
      "Epoch 46. Loss: 0.009523792356906598, Train_acc 0.9939236111111112\n",
      "\n",
      "Epoch 46. Loss: 0.00881262781008327, Train_acc 0.9939555921052632\n",
      "\n",
      "Epoch 46. Loss: 0.008337091424622333, Train_acc 0.9939872382198953\n",
      "\n",
      "Epoch 46. Loss: 0.008619819374583539, Train_acc 0.9939778645833334\n",
      "\n",
      "Epoch 46. Loss: 0.008897026553781965, Train_acc 0.9939685880829016\n",
      "\n",
      "Epoch 46. Loss: 0.008874680165230159, Train_acc 0.9939594072164949\n",
      "\n",
      "Epoch 46. Loss: 0.008548799102406732, Train_acc 0.9939903846153846\n",
      "\n",
      "Epoch 46. Loss: 0.007711544231784055, Train_acc 0.994\n",
      "\n",
      "Epoch 47. Loss: 0.007433692563663462, Train_acc 1.0\n",
      "\n",
      "Epoch 47. Loss: 0.006939961017227655, Train_acc 1.0\n",
      "\n",
      "Epoch 47. Loss: 0.006621859442455904, Train_acc 1.0\n",
      "\n",
      "Epoch 47. Loss: 0.006232274642598632, Train_acc 1.0\n",
      "\n",
      "Epoch 47. Loss: 0.007056047625999454, Train_acc 0.9984375\n",
      "\n",
      "Epoch 47. Loss: 0.006501410660198304, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 47. Loss: 0.005961671878368532, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 47. Loss: 0.005439131234858224, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 47. Loss: 0.0056106455845598485, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 47. Loss: 0.005606960171279082, Train_acc 0.9984375\n",
      "\n",
      "Epoch 47. Loss: 0.005396761863738391, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 47. Loss: 0.004996005524450623, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 47. Loss: 0.009537277814079002, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 47. Loss: 0.009347139036725767, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 47. Loss: 0.00848667701392246, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 47. Loss: 0.007955743350056166, Train_acc 0.998046875\n",
      "\n",
      "Epoch 47. Loss: 0.0073106871925933846, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 47. Loss: 0.008896689620597097, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 47. Loss: 0.010007475285514832, Train_acc 0.9971217105263158\n",
      "\n",
      "Epoch 47. Loss: 0.009068503931661373, Train_acc 0.997265625\n",
      "\n",
      "Epoch 47. Loss: 0.008325317590292477, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 47. Loss: 0.007837870857028232, Train_acc 0.9975142045454546\n",
      "\n",
      "Epoch 47. Loss: 0.007190239732406794, Train_acc 0.9976222826086957\n",
      "\n",
      "Epoch 47. Loss: 0.007465697278030747, Train_acc 0.9977213541666666\n",
      "\n",
      "Epoch 47. Loss: 0.007113595140604407, Train_acc 0.9978125\n",
      "\n",
      "Epoch 47. Loss: 0.007237614932770935, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 47. Loss: 0.007353420810206599, Train_acc 0.9976851851851852\n",
      "\n",
      "Epoch 47. Loss: 0.007254906069535495, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 47. Loss: 0.006889198015859855, Train_acc 0.9978448275862069\n",
      "\n",
      "Epoch 47. Loss: 0.006320544601512968, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 47. Loss: 0.005989236063502448, Train_acc 0.9979838709677419\n",
      "\n",
      "Epoch 47. Loss: 0.006924597760357455, Train_acc 0.997802734375\n",
      "\n",
      "Epoch 47. Loss: 0.006977631670148369, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 47. Loss: 0.006304405855280113, Train_acc 0.9979319852941176\n",
      "\n",
      "Epoch 47. Loss: 0.006795196624525147, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 47. Loss: 0.006505649244646213, Train_acc 0.9978298611111112\n",
      "\n",
      "Epoch 47. Loss: 0.006193343217135949, Train_acc 0.9978885135135135\n",
      "\n",
      "Epoch 47. Loss: 0.006211134957487717, Train_acc 0.9979440789473685\n",
      "\n",
      "Epoch 47. Loss: 0.005780204586243929, Train_acc 0.9979967948717948\n",
      "\n",
      "Epoch 47. Loss: 0.0052169944295650805, Train_acc 0.998046875\n",
      "\n",
      "Epoch 47. Loss: 0.004821194338741847, Train_acc 0.9980945121951219\n",
      "\n",
      "Epoch 47. Loss: 0.004417061715224041, Train_acc 0.9981398809523809\n",
      "\n",
      "Epoch 47. Loss: 0.004021474032236922, Train_acc 0.9981831395348837\n",
      "\n",
      "Epoch 47. Loss: 0.003669305891998519, Train_acc 0.9982244318181818\n",
      "\n",
      "Epoch 47. Loss: 0.003415474406126508, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 47. Loss: 0.003282367481657894, Train_acc 0.9983016304347826\n",
      "\n",
      "Epoch 47. Loss: 0.0030473728928382235, Train_acc 0.9983377659574468\n",
      "\n",
      "Epoch 47. Loss: 0.002826795150086138, Train_acc 0.9983723958333334\n",
      "\n",
      "Epoch 47. Loss: 0.0030733805731637956, Train_acc 0.998405612244898\n",
      "\n",
      "Epoch 47. Loss: 0.003147475199054511, Train_acc 0.9984375\n",
      "\n",
      "Epoch 47. Loss: 0.0030353010959036633, Train_acc 0.9984681372549019\n",
      "\n",
      "Epoch 47. Loss: 0.0029189647050521512, Train_acc 0.9984975961538461\n",
      "\n",
      "Epoch 47. Loss: 0.0026911002820682595, Train_acc 0.9985259433962265\n",
      "\n",
      "Epoch 47. Loss: 0.0024554821910722172, Train_acc 0.9985532407407407\n",
      "\n",
      "Epoch 47. Loss: 0.002336290207670312, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 47. Loss: 0.002278196784276081, Train_acc 0.9986049107142857\n",
      "\n",
      "Epoch 47. Loss: 0.002305130850078147, Train_acc 0.9986293859649122\n",
      "\n",
      "Epoch 47. Loss: 0.002500633535133137, Train_acc 0.9986530172413793\n",
      "\n",
      "Epoch 47. Loss: 0.0022637280481075683, Train_acc 0.9986758474576272\n",
      "\n",
      "Epoch 47. Loss: 0.002437161593766401, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 47. Loss: 0.002246701520929238, Train_acc 0.998719262295082\n",
      "\n",
      "Epoch 47. Loss: 0.0020705388656673215, Train_acc 0.9987399193548387\n",
      "\n",
      "Epoch 47. Loss: 0.0018794345359374478, Train_acc 0.9987599206349206\n",
      "\n",
      "Epoch 47. Loss: 0.0017291381734287944, Train_acc 0.998779296875\n",
      "\n",
      "Epoch 47. Loss: 0.001741575255204845, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 47. Loss: 0.0016468771181918907, Train_acc 0.9988162878787878\n",
      "\n",
      "Epoch 47. Loss: 0.0030878386988417265, Train_acc 0.9986007462686567\n",
      "\n",
      "Epoch 47. Loss: 0.003057571175546285, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 47. Loss: 0.002812083899915966, Train_acc 0.998641304347826\n",
      "\n",
      "Epoch 47. Loss: 0.0025554651150881524, Train_acc 0.9986607142857142\n",
      "\n",
      "Epoch 47. Loss: 0.00234848729121388, Train_acc 0.9986795774647887\n",
      "\n",
      "Epoch 47. Loss: 0.002137927847740175, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 47. Loss: 0.002071079464751889, Train_acc 0.9987157534246576\n",
      "\n",
      "Epoch 47. Loss: 0.0019509951378390874, Train_acc 0.9987331081081081\n",
      "\n",
      "Epoch 47. Loss: 0.002602651314927848, Train_acc 0.9986458333333333\n",
      "\n",
      "Epoch 47. Loss: 0.0026990199118051336, Train_acc 0.9986636513157895\n",
      "\n",
      "Epoch 47. Loss: 0.0026411331554898683, Train_acc 0.9986810064935064\n",
      "\n",
      "Epoch 47. Loss: 0.0024416380793529655, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 47. Loss: 0.0024244031239162005, Train_acc 0.9987143987341772\n",
      "\n",
      "Epoch 47. Loss: 0.0022556785881953046, Train_acc 0.99873046875\n",
      "\n",
      "Epoch 47. Loss: 0.0020512132954731716, Train_acc 0.9987461419753086\n",
      "\n",
      "Epoch 47. Loss: 0.0020041143682459116, Train_acc 0.9987614329268293\n",
      "\n",
      "Epoch 47. Loss: 0.0018738533666250068, Train_acc 0.9987763554216867\n",
      "\n",
      "Epoch 47. Loss: 0.001703119251047846, Train_acc 0.9987909226190477\n",
      "\n",
      "Epoch 47. Loss: 0.0017103587361040203, Train_acc 0.9988051470588235\n",
      "\n",
      "Epoch 47. Loss: 0.0015599745229457494, Train_acc 0.9988190406976745\n",
      "\n",
      "Epoch 47. Loss: 0.0014213756519091958, Train_acc 0.9988326149425287\n",
      "\n",
      "Epoch 47. Loss: 0.0012913785531424471, Train_acc 0.9988458806818182\n",
      "\n",
      "Epoch 47. Loss: 0.0012914557445916227, Train_acc 0.9988588483146067\n",
      "\n",
      "Epoch 47. Loss: 0.0012482378442136368, Train_acc 0.9988715277777778\n",
      "\n",
      "Epoch 47. Loss: 0.0011421583905290816, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 47. Loss: 0.0011266899739291896, Train_acc 0.9988960597826086\n",
      "\n",
      "Epoch 47. Loss: 0.0011225097537229923, Train_acc 0.9989079301075269\n",
      "\n",
      "Epoch 47. Loss: 0.0018038069860807481, Train_acc 0.9988364361702128\n",
      "\n",
      "Epoch 47. Loss: 0.0016498086071018657, Train_acc 0.9988486842105263\n",
      "\n",
      "Epoch 47. Loss: 0.0016141646450724555, Train_acc 0.9988606770833334\n",
      "\n",
      "Epoch 47. Loss: 0.0014878828718445914, Train_acc 0.9988724226804123\n",
      "\n",
      "Epoch 47. Loss: 0.0013593928183815375, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 47. Loss: 0.0012626344460596735, Train_acc 0.998895202020202\n",
      "\n",
      "Epoch 47. Loss: 0.0011785853479212235, Train_acc 0.99890625\n",
      "\n",
      "[Epoch 47 Batch 100] Loss: 0.0011012417112662906 Training: accuracy=0.998917\n",
      "Epoch 47. Loss: 0.0011012417112662906, Train_acc 0.9989170792079208\n",
      "\n",
      "Epoch 47. Loss: 0.0010030874115512273, Train_acc 0.9989276960784313\n",
      "\n",
      "Epoch 47. Loss: 0.0009053049369037343, Train_acc 0.9989381067961165\n",
      "\n",
      "Epoch 47. Loss: 0.0008412265363656902, Train_acc 0.9989483173076923\n",
      "\n",
      "Epoch 47. Loss: 0.0007969468345391086, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 47. Loss: 0.0009088458567616938, Train_acc 0.9989681603773585\n",
      "\n",
      "Epoch 47. Loss: 0.0009411975645243465, Train_acc 0.9989778037383178\n",
      "\n",
      "Epoch 47. Loss: 0.0009050195763903266, Train_acc 0.9989872685185185\n",
      "\n",
      "Epoch 47. Loss: 0.0008227817190758893, Train_acc 0.9989965596330275\n",
      "\n",
      "Epoch 47. Loss: 0.0007818520197551333, Train_acc 0.9990056818181818\n",
      "\n",
      "Epoch 47. Loss: 0.0008143614324843183, Train_acc 0.9990146396396397\n",
      "\n",
      "Epoch 47. Loss: 0.0008026272285914684, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 47. Loss: 0.005802587589228416, Train_acc 0.9989629424778761\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47. Loss: 0.005262029115138663, Train_acc 0.9989720394736842\n",
      "\n",
      "Epoch 47. Loss: 0.004891568157847119, Train_acc 0.9989809782608695\n",
      "\n",
      "Epoch 47. Loss: 0.0044814533001504625, Train_acc 0.9989897629310345\n",
      "\n",
      "Epoch 47. Loss: 0.004050701836572903, Train_acc 0.9989983974358975\n",
      "\n",
      "Epoch 47. Loss: 0.004167748271146552, Train_acc 0.9990068855932204\n",
      "\n",
      "Epoch 47. Loss: 0.0038398396911289274, Train_acc 0.999015231092437\n",
      "\n",
      "Epoch 47. Loss: 0.0042738895178198195, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 47. Loss: 0.006284181339474861, Train_acc 0.9989023760330579\n",
      "\n",
      "Epoch 47. Loss: 0.00569999212204949, Train_acc 0.9989113729508197\n",
      "\n",
      "Epoch 47. Loss: 0.005565789895247245, Train_acc 0.9989202235772358\n",
      "\n",
      "Epoch 47. Loss: 0.005694744181550286, Train_acc 0.9989289314516129\n",
      "\n",
      "Epoch 47. Loss: 0.005250785503760048, Train_acc 0.9989375\n",
      "\n",
      "Epoch 47. Loss: 0.004984907925888957, Train_acc 0.9989459325396826\n",
      "\n",
      "Epoch 47. Loss: 0.0054688464067265945, Train_acc 0.9989542322834646\n",
      "\n",
      "Epoch 47. Loss: 0.0056579548905985565, Train_acc 0.99896240234375\n",
      "\n",
      "Epoch 47. Loss: 0.00785802688813481, Train_acc 0.9989098837209303\n",
      "\n",
      "Epoch 47. Loss: 0.007685635203045069, Train_acc 0.9989182692307692\n",
      "\n",
      "Epoch 47. Loss: 0.007033556062136405, Train_acc 0.9989265267175572\n",
      "\n",
      "Epoch 47. Loss: 0.006849703270781917, Train_acc 0.9989346590909091\n",
      "\n",
      "Epoch 47. Loss: 0.0064774461280976674, Train_acc 0.9989426691729323\n",
      "\n",
      "Epoch 47. Loss: 0.006624880468846107, Train_acc 0.9989505597014925\n",
      "\n",
      "Epoch 47. Loss: 0.0076058757627017, Train_acc 0.998900462962963\n",
      "\n",
      "Epoch 47. Loss: 0.0069544989365196265, Train_acc 0.9989085477941176\n",
      "\n",
      "Epoch 47. Loss: 0.006303293547401372, Train_acc 0.9989165145985401\n",
      "\n",
      "Epoch 47. Loss: 0.005753845646711776, Train_acc 0.9989243659420289\n",
      "\n",
      "Epoch 47. Loss: 0.0053979673401855725, Train_acc 0.9989321043165468\n",
      "\n",
      "Epoch 47. Loss: 0.0058180449232169956, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 47. Loss: 0.0055183831380420005, Train_acc 0.9988918439716312\n",
      "\n",
      "Epoch 47. Loss: 0.0049809804318285125, Train_acc 0.998899647887324\n",
      "\n",
      "Epoch 47. Loss: 0.004657335055770231, Train_acc 0.9989073426573427\n",
      "\n",
      "Epoch 47. Loss: 0.006544613553197759, Train_acc 0.9988064236111112\n",
      "\n",
      "Epoch 47. Loss: 0.006292481873731236, Train_acc 0.9988146551724137\n",
      "\n",
      "Epoch 47. Loss: 0.010274205792814869, Train_acc 0.9987157534246576\n",
      "\n",
      "Epoch 47. Loss: 0.00925634688267304, Train_acc 0.9987244897959183\n",
      "\n",
      "Epoch 47. Loss: 0.008368365839673444, Train_acc 0.9987331081081081\n",
      "\n",
      "Epoch 47. Loss: 0.0075476246765756325, Train_acc 0.9987416107382551\n",
      "\n",
      "Epoch 47. Loss: 0.007491485363230442, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 47. Loss: 0.015367576705800298, Train_acc 0.9986030629139073\n",
      "\n",
      "Epoch 47. Loss: 0.014929499903965119, Train_acc 0.9986122532894737\n",
      "\n",
      "Epoch 47. Loss: 0.013832202425657025, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 47. Loss: 0.012486800238807666, Train_acc 0.998630275974026\n",
      "\n",
      "Epoch 47. Loss: 0.011335014171578811, Train_acc 0.9986391129032258\n",
      "\n",
      "Epoch 47. Loss: 0.027818376303176573, Train_acc 0.9983974358974359\n",
      "\n",
      "Epoch 47. Loss: 0.025215504924992166, Train_acc 0.9984076433121019\n",
      "\n",
      "Epoch 47. Loss: 0.025327535743003587, Train_acc 0.9983682753164557\n",
      "\n",
      "Epoch 47. Loss: 0.023329055945860298, Train_acc 0.9983785377358491\n",
      "\n",
      "Epoch 47. Loss: 0.026310417032945413, Train_acc 0.998193359375\n",
      "\n",
      "Epoch 47. Loss: 0.024460220623426072, Train_acc 0.9982045807453416\n",
      "\n",
      "Epoch 47. Loss: 0.022672467554803878, Train_acc 0.9981674382716049\n",
      "\n",
      "Epoch 47. Loss: 0.02089160196500676, Train_acc 0.9981786809815951\n",
      "\n",
      "Epoch 47. Loss: 0.02047687333092979, Train_acc 0.9981421493902439\n",
      "\n",
      "Epoch 47. Loss: 0.01891344179227255, Train_acc 0.9981534090909091\n",
      "\n",
      "Epoch 47. Loss: 0.022330297286936363, Train_acc 0.998023343373494\n",
      "\n",
      "Epoch 47. Loss: 0.02079791075121944, Train_acc 0.9980351796407185\n",
      "\n",
      "Epoch 47. Loss: 0.018807387620083257, Train_acc 0.998046875\n",
      "\n",
      "Epoch 47. Loss: 0.019203342328851014, Train_acc 0.9980122041420119\n",
      "\n",
      "Epoch 47. Loss: 0.017745171894476944, Train_acc 0.9980238970588236\n",
      "\n",
      "Epoch 47. Loss: 0.01846087809042287, Train_acc 0.9979440789473685\n",
      "\n",
      "Epoch 47. Loss: 0.017862976921822, Train_acc 0.9979106104651163\n",
      "\n",
      "Epoch 47. Loss: 0.0184700249507058, Train_acc 0.9978323699421965\n",
      "\n",
      "Epoch 47. Loss: 0.017081971840846092, Train_acc 0.9978448275862069\n",
      "\n",
      "Epoch 47. Loss: 0.01855192970644315, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 47. Loss: 0.035126737279393194, Train_acc 0.9977361505681818\n",
      "\n",
      "Epoch 47. Loss: 0.03320854013952427, Train_acc 0.9977489406779662\n",
      "\n",
      "Epoch 47. Loss: 0.030424554008628243, Train_acc 0.9977615870786517\n",
      "\n",
      "Epoch 47. Loss: 0.029077628351794463, Train_acc 0.9977304469273743\n",
      "\n",
      "Epoch 47. Loss: 0.027820229654800997, Train_acc 0.9976996527777777\n",
      "\n",
      "Epoch 47. Loss: 0.025516339130960797, Train_acc 0.997712361878453\n",
      "\n",
      "Epoch 47. Loss: 0.023145922802623713, Train_acc 0.9977249313186813\n",
      "\n",
      "Epoch 47. Loss: 0.021009089221644347, Train_acc 0.9977373633879781\n",
      "\n",
      "Epoch 47. Loss: 0.020150956607688616, Train_acc 0.9977072010869565\n",
      "\n",
      "Epoch 47. Loss: 0.02175232359483464, Train_acc 0.9975929054054054\n",
      "\n",
      "Epoch 47. Loss: 0.023716606992911907, Train_acc 0.9974378360215054\n",
      "\n",
      "Epoch 47. Loss: 0.021950456515414964, Train_acc 0.9974515374331551\n",
      "\n",
      "Epoch 47. Loss: 0.02681956560802172, Train_acc 0.997298869680851\n",
      "\n",
      "Epoch 47. Loss: 0.024307348954361322, Train_acc 0.9973131613756614\n",
      "\n",
      "Epoch 47. Loss: 0.02213158554637281, Train_acc 0.997327302631579\n",
      "\n",
      "Epoch 47. Loss: 0.020106131191660596, Train_acc 0.9973412958115183\n",
      "\n",
      "Epoch 47. Loss: 0.018934042734452754, Train_acc 0.9973551432291666\n",
      "\n",
      "Epoch 47. Loss: 0.018331372573270204, Train_acc 0.9973283678756477\n",
      "\n",
      "Epoch 47. Loss: 0.02397272408094448, Train_acc 0.9972213273195877\n",
      "\n",
      "Epoch 47. Loss: 0.02219732146042385, Train_acc 0.997235576923077\n",
      "\n",
      "Epoch 47. Loss: 0.021968818632463798, Train_acc 0.99724\n",
      "\n",
      "Epoch 48. Loss: 0.023599697882861065, Train_acc 0.984375\n",
      "\n",
      "Epoch 48. Loss: 0.02354009522640422, Train_acc 0.984375\n",
      "\n",
      "Epoch 48. Loss: 0.022204034130070046, Train_acc 0.9869791666666666\n",
      "\n",
      "Epoch 48. Loss: 0.022171909265482518, Train_acc 0.98828125\n",
      "\n",
      "Epoch 48. Loss: 0.02081173487627276, Train_acc 0.990625\n",
      "\n",
      "Epoch 48. Loss: 0.01978542893192561, Train_acc 0.9921875\n",
      "\n",
      "Epoch 48. Loss: 0.020196163929057643, Train_acc 0.9921875\n",
      "\n",
      "Epoch 48. Loss: 0.0195704553327434, Train_acc 0.9931640625\n",
      "\n",
      "Epoch 48. Loss: 0.01847028198180849, Train_acc 0.9939236111111112\n",
      "\n",
      "Epoch 48. Loss: 0.020639411395832197, Train_acc 0.99375\n",
      "\n",
      "Epoch 48. Loss: 0.021734694870749978, Train_acc 0.9936079545454546\n",
      "\n",
      "Epoch 48. Loss: 0.019714480473792435, Train_acc 0.994140625\n",
      "\n",
      "Epoch 48. Loss: 0.01986035481172432, Train_acc 0.9933894230769231\n",
      "\n",
      "Epoch 48. Loss: 0.018128660452314878, Train_acc 0.9938616071428571\n",
      "\n",
      "Epoch 48. Loss: 0.017637539512171146, Train_acc 0.99375\n",
      "\n",
      "Epoch 48. Loss: 0.018002681305635388, Train_acc 0.99365234375\n",
      "\n",
      "Epoch 48. Loss: 0.020722338441576137, Train_acc 0.9931066176470589\n",
      "\n",
      "Epoch 48. Loss: 0.01903523051014445, Train_acc 0.9934895833333334\n",
      "\n",
      "Epoch 48. Loss: 0.01745901253577383, Train_acc 0.9938322368421053\n",
      "\n",
      "Epoch 48. Loss: 0.015965419373345183, Train_acc 0.994140625\n",
      "\n",
      "Epoch 48. Loss: 0.015656711968569582, Train_acc 0.9940476190476191\n",
      "\n",
      "Epoch 48. Loss: 0.01518578363608297, Train_acc 0.9943181818181818\n",
      "\n",
      "Epoch 48. Loss: 0.014069148263194945, Train_acc 0.9945652173913043\n",
      "\n",
      "Epoch 48. Loss: 0.012908105087861825, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 48. Loss: 0.011759332750255235, Train_acc 0.995\n",
      "\n",
      "Epoch 48. Loss: 0.012080447242272826, Train_acc 0.9948918269230769\n",
      "\n",
      "Epoch 48. Loss: 0.011527125128534078, Train_acc 0.9950810185185185\n",
      "\n",
      "Epoch 48. Loss: 0.012313562002861477, Train_acc 0.9946986607142857\n",
      "\n",
      "Epoch 48. Loss: 0.011358955057710984, Train_acc 0.9948814655172413\n",
      "\n",
      "Epoch 48. Loss: 0.01155733429841749, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 48. Loss: 0.010630699795805384, Train_acc 0.9949596774193549\n",
      "\n",
      "Epoch 48. Loss: 0.015521290423562798, Train_acc 0.99462890625\n",
      "\n",
      "Epoch 48. Loss: 0.014972000309458977, Train_acc 0.9945549242424242\n",
      "\n",
      "Epoch 48. Loss: 0.01798185839232648, Train_acc 0.9944852941176471\n",
      "\n",
      "Epoch 48. Loss: 0.016573304134586558, Train_acc 0.9946428571428572\n",
      "\n",
      "Epoch 48. Loss: 0.016124949725400604, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 48. Loss: 0.014771992538174567, Train_acc 0.9949324324324325\n",
      "\n",
      "Epoch 48. Loss: 0.01422142702233843, Train_acc 0.994860197368421\n",
      "\n",
      "Epoch 48. Loss: 0.012919928498346077, Train_acc 0.9949919871794872\n",
      "\n",
      "Epoch 48. Loss: 0.01208292779753667, Train_acc 0.9951171875\n",
      "\n",
      "Epoch 48. Loss: 0.011101121445492463, Train_acc 0.9952362804878049\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48. Loss: 0.010495618218924602, Train_acc 0.9953497023809523\n",
      "\n",
      "Epoch 48. Loss: 0.00949073295666013, Train_acc 0.9954578488372093\n",
      "\n",
      "Epoch 48. Loss: 0.009049951773493593, Train_acc 0.9955610795454546\n",
      "\n",
      "Epoch 48. Loss: 0.010865634448774848, Train_acc 0.9954861111111111\n",
      "\n",
      "Epoch 48. Loss: 0.01168236894230383, Train_acc 0.9954144021739131\n",
      "\n",
      "Epoch 48. Loss: 0.01081448469597403, Train_acc 0.9955119680851063\n",
      "\n",
      "Epoch 48. Loss: 0.010075210147320959, Train_acc 0.99560546875\n",
      "\n",
      "Epoch 48. Loss: 0.014252120506661893, Train_acc 0.9953762755102041\n",
      "\n",
      "Epoch 48. Loss: 0.013347801921723272, Train_acc 0.99546875\n",
      "\n",
      "Epoch 48. Loss: 0.014345638885758506, Train_acc 0.9954044117647058\n",
      "\n",
      "Epoch 48. Loss: 0.01453787015497284, Train_acc 0.9953425480769231\n",
      "\n",
      "Epoch 48. Loss: 0.015143606900747987, Train_acc 0.9951356132075472\n",
      "\n",
      "Epoch 48. Loss: 0.01436493809893105, Train_acc 0.9952256944444444\n",
      "\n",
      "Epoch 48. Loss: 0.013227220394084218, Train_acc 0.9953125\n",
      "\n",
      "Epoch 48. Loss: 0.01206902218019086, Train_acc 0.9953962053571429\n",
      "\n",
      "Epoch 48. Loss: 0.011083215173044364, Train_acc 0.9954769736842105\n",
      "\n",
      "Epoch 48. Loss: 0.010326571700275148, Train_acc 0.9955549568965517\n",
      "\n",
      "Epoch 48. Loss: 0.010568644050330108, Train_acc 0.9954978813559322\n",
      "\n",
      "Epoch 48. Loss: 0.009599791072148253, Train_acc 0.9955729166666667\n",
      "\n",
      "Epoch 48. Loss: 0.009744556674961598, Train_acc 0.9955174180327869\n",
      "\n",
      "Epoch 48. Loss: 0.009273731431383806, Train_acc 0.9955897177419355\n",
      "\n",
      "Epoch 48. Loss: 0.009668070517646298, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 48. Loss: 0.009497143612206304, Train_acc 0.99560546875\n",
      "\n",
      "Epoch 48. Loss: 0.009445239020943932, Train_acc 0.9956730769230769\n",
      "\n",
      "Epoch 48. Loss: 0.008838256315344833, Train_acc 0.9957386363636364\n",
      "\n",
      "Epoch 48. Loss: 0.008326009950894948, Train_acc 0.9958022388059702\n",
      "\n",
      "Epoch 48. Loss: 0.007555397239219847, Train_acc 0.9958639705882353\n",
      "\n",
      "Epoch 48. Loss: 0.00802471536343548, Train_acc 0.9958106884057971\n",
      "\n",
      "Epoch 48. Loss: 0.009882827718066454, Train_acc 0.9956473214285714\n",
      "\n",
      "Epoch 48. Loss: 0.00895550485164578, Train_acc 0.9957086267605634\n",
      "\n",
      "Epoch 48. Loss: 0.008178949812727319, Train_acc 0.9957682291666666\n",
      "\n",
      "Epoch 48. Loss: 0.007462626594388914, Train_acc 0.995826198630137\n",
      "\n",
      "Epoch 48. Loss: 0.006916917266474156, Train_acc 0.9958826013513513\n",
      "\n",
      "Epoch 48. Loss: 0.00870808886917769, Train_acc 0.9958333333333333\n",
      "\n",
      "Epoch 48. Loss: 0.008042496119952253, Train_acc 0.9958881578947368\n",
      "\n",
      "Epoch 48. Loss: 0.007360534423976587, Train_acc 0.9959415584415584\n",
      "\n",
      "Epoch 48. Loss: 0.006797394521733623, Train_acc 0.9959935897435898\n",
      "\n",
      "Epoch 48. Loss: 0.006234660209615232, Train_acc 0.9960443037974683\n",
      "\n",
      "Epoch 48. Loss: 0.005687149982380898, Train_acc 0.99609375\n",
      "\n",
      "Epoch 48. Loss: 0.005229256712737409, Train_acc 0.996141975308642\n",
      "\n",
      "Epoch 48. Loss: 0.005158746267491038, Train_acc 0.9961890243902439\n",
      "\n",
      "Epoch 48. Loss: 0.0060487326831818716, Train_acc 0.9960466867469879\n",
      "\n",
      "Epoch 48. Loss: 0.005913088133293489, Train_acc 0.99609375\n",
      "\n",
      "Epoch 48. Loss: 0.00602236542286703, Train_acc 0.9961397058823529\n",
      "\n",
      "Epoch 48. Loss: 0.007680326952179334, Train_acc 0.99609375\n",
      "\n",
      "Epoch 48. Loss: 0.007482316571748311, Train_acc 0.9961386494252874\n",
      "\n",
      "Epoch 48. Loss: 0.0068522926365444554, Train_acc 0.9961825284090909\n",
      "\n",
      "Epoch 48. Loss: 0.006469187116930738, Train_acc 0.9962254213483146\n",
      "\n",
      "Epoch 48. Loss: 0.006490344272234906, Train_acc 0.9962673611111111\n",
      "\n",
      "Epoch 48. Loss: 0.005883926310373204, Train_acc 0.9963083791208791\n",
      "\n",
      "Epoch 48. Loss: 0.00553888854747968, Train_acc 0.9963485054347826\n",
      "\n",
      "Epoch 48. Loss: 0.005004967467010197, Train_acc 0.9963877688172043\n",
      "\n",
      "Epoch 48. Loss: 0.0048239390201674495, Train_acc 0.9964261968085106\n",
      "\n",
      "Epoch 48. Loss: 0.007632157741246218, Train_acc 0.9963815789473685\n",
      "\n",
      "Epoch 48. Loss: 0.007110856498337622, Train_acc 0.9964192708333334\n",
      "\n",
      "Epoch 48. Loss: 0.006435121263195353, Train_acc 0.9964561855670103\n",
      "\n",
      "Epoch 48. Loss: 0.005911047531779954, Train_acc 0.9964923469387755\n",
      "\n",
      "Epoch 48. Loss: 0.005919724900901035, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 48. Loss: 0.005379543573506667, Train_acc 0.996484375\n",
      "\n",
      "[Epoch 48 Batch 100] Loss: 0.005000271460520173 Training: accuracy=0.996519\n",
      "Epoch 48. Loss: 0.005000271460520173, Train_acc 0.9965191831683168\n",
      "\n",
      "Epoch 48. Loss: 0.004630759254715095, Train_acc 0.9965533088235294\n",
      "\n",
      "Epoch 48. Loss: 0.004365323111225292, Train_acc 0.9965867718446602\n",
      "\n",
      "Epoch 48. Loss: 0.003963190060869567, Train_acc 0.9966195913461539\n",
      "\n",
      "Epoch 48. Loss: 0.0036188100998616633, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 48. Loss: 0.0033059934390257824, Train_acc 0.9966833726415094\n",
      "\n",
      "Epoch 48. Loss: 0.003057761264793965, Train_acc 0.9967143691588785\n",
      "\n",
      "Epoch 48. Loss: 0.0028190913303147787, Train_acc 0.9967447916666666\n",
      "\n",
      "Epoch 48. Loss: 0.0031657776239619588, Train_acc 0.9967029816513762\n",
      "\n",
      "Epoch 48. Loss: 0.0029653268459235967, Train_acc 0.9967329545454545\n",
      "\n",
      "Epoch 48. Loss: 0.002889280729618252, Train_acc 0.9967623873873874\n",
      "\n",
      "Epoch 48. Loss: 0.003255614642614049, Train_acc 0.9967215401785714\n",
      "\n",
      "Epoch 48. Loss: 0.002936859723195774, Train_acc 0.9967505530973452\n",
      "\n",
      "Epoch 48. Loss: 0.002680842701848344, Train_acc 0.9967790570175439\n",
      "\n",
      "Epoch 48. Loss: 0.0026094387884119117, Train_acc 0.9968070652173913\n",
      "\n",
      "Epoch 48. Loss: 0.0023955419150713648, Train_acc 0.9968345905172413\n",
      "\n",
      "Epoch 48. Loss: 0.002203150515743962, Train_acc 0.9968616452991453\n",
      "\n",
      "Epoch 48. Loss: 0.002003368260212537, Train_acc 0.9968882415254238\n",
      "\n",
      "Epoch 48. Loss: 0.0019681540651972263, Train_acc 0.9969143907563025\n",
      "\n",
      "Epoch 48. Loss: 0.0018678519197647425, Train_acc 0.9969401041666667\n",
      "\n",
      "Epoch 48. Loss: 0.0017573095784160183, Train_acc 0.9969653925619835\n",
      "\n",
      "Epoch 48. Loss: 0.0016022601168183403, Train_acc 0.9969902663934426\n",
      "\n",
      "Epoch 48. Loss: 0.0015297516938946024, Train_acc 0.9970147357723578\n",
      "\n",
      "Epoch 48. Loss: 0.001387710976944102, Train_acc 0.997038810483871\n",
      "\n",
      "Epoch 48. Loss: 0.004238709978770376, Train_acc 0.997\n",
      "\n",
      "Epoch 48. Loss: 0.003832244148348192, Train_acc 0.9970238095238095\n",
      "\n",
      "Epoch 48. Loss: 0.0037637428284386576, Train_acc 0.9970472440944882\n",
      "\n",
      "Epoch 48. Loss: 0.003421150624712165, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 48. Loss: 0.003118622932943014, Train_acc 0.997093023255814\n",
      "\n",
      "Epoch 48. Loss: 0.0028274761480841, Train_acc 0.9971153846153846\n",
      "\n",
      "Epoch 48. Loss: 0.004165129416533079, Train_acc 0.9970777671755725\n",
      "\n",
      "Epoch 48. Loss: 0.004215443638352543, Train_acc 0.9970999053030303\n",
      "\n",
      "Epoch 48. Loss: 0.0038770440054055957, Train_acc 0.9971217105263158\n",
      "\n",
      "Epoch 48. Loss: 0.0037678241700709082, Train_acc 0.9971431902985075\n",
      "\n",
      "Epoch 48. Loss: 0.003492326668645163, Train_acc 0.9971643518518518\n",
      "\n",
      "Epoch 48. Loss: 0.00316347638195186, Train_acc 0.9971852022058824\n",
      "\n",
      "Epoch 48. Loss: 0.0029128217468821632, Train_acc 0.9972057481751825\n",
      "\n",
      "Epoch 48. Loss: 0.002732872445542094, Train_acc 0.9972259963768116\n",
      "\n",
      "Epoch 48. Loss: 0.0034622305072770808, Train_acc 0.9971897482014388\n",
      "\n",
      "Epoch 48. Loss: 0.005070847952731814, Train_acc 0.9971540178571429\n",
      "\n",
      "Epoch 48. Loss: 0.004947449338616461, Train_acc 0.9971742021276596\n",
      "\n",
      "Epoch 48. Loss: 0.005707807605428872, Train_acc 0.9971390845070423\n",
      "\n",
      "Epoch 48. Loss: 0.0052874300972231125, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 48. Loss: 0.004799566735213956, Train_acc 0.9971788194444444\n",
      "\n",
      "Epoch 48. Loss: 0.004377533384003231, Train_acc 0.997198275862069\n",
      "\n",
      "Epoch 48. Loss: 0.003973899775719708, Train_acc 0.9972174657534246\n",
      "\n",
      "Epoch 48. Loss: 0.003743846462310313, Train_acc 0.9972363945578231\n",
      "\n",
      "Epoch 48. Loss: 0.004582329631126785, Train_acc 0.9972550675675675\n",
      "\n",
      "Epoch 48. Loss: 0.004415545872101364, Train_acc 0.9972734899328859\n",
      "\n",
      "Epoch 48. Loss: 0.0043084477081887515, Train_acc 0.9972916666666667\n",
      "\n",
      "Epoch 48. Loss: 0.004052112519945287, Train_acc 0.9973096026490066\n",
      "\n",
      "Epoch 48. Loss: 0.003681509782348164, Train_acc 0.997327302631579\n",
      "\n",
      "Epoch 48. Loss: 0.0036620776875830484, Train_acc 0.9973447712418301\n",
      "\n",
      "Epoch 48. Loss: 0.0033197385755419843, Train_acc 0.997362012987013\n",
      "\n",
      "Epoch 48. Loss: 0.003091468336503069, Train_acc 0.9973790322580646\n",
      "\n",
      "Epoch 48. Loss: 0.009217670341420497, Train_acc 0.9972956730769231\n",
      "\n",
      "Epoch 48. Loss: 0.008392595050516346, Train_acc 0.997312898089172\n",
      "\n",
      "Epoch 48. Loss: 0.008221112178518728, Train_acc 0.9973299050632911\n",
      "\n",
      "Epoch 48. Loss: 0.007973494881097398, Train_acc 0.9973466981132075\n",
      "\n",
      "Epoch 48. Loss: 0.011489041376445224, Train_acc 0.997265625\n",
      "\n",
      "Epoch 48. Loss: 0.012989619578421293, Train_acc 0.9972340838509317\n",
      "\n",
      "Epoch 48. Loss: 0.019780041312128464, Train_acc 0.9971547067901234\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48. Loss: 0.020983695493593957, Train_acc 0.9970763036809815\n",
      "\n",
      "Epoch 48. Loss: 0.018927137912783717, Train_acc 0.997094131097561\n",
      "\n",
      "Epoch 48. Loss: 0.017338551210253267, Train_acc 0.9971117424242424\n",
      "\n",
      "Epoch 48. Loss: 0.016603503508319403, Train_acc 0.997082078313253\n",
      "\n",
      "Epoch 48. Loss: 0.01512272538629542, Train_acc 0.9970995508982036\n",
      "\n",
      "Epoch 48. Loss: 0.013714495176560015, Train_acc 0.9971168154761905\n",
      "\n",
      "Epoch 48. Loss: 0.015228854082065521, Train_acc 0.9970876479289941\n",
      "\n",
      "Epoch 48. Loss: 0.013800115694577052, Train_acc 0.9971047794117647\n",
      "\n",
      "Epoch 48. Loss: 0.012862164301402468, Train_acc 0.9971217105263158\n",
      "\n",
      "Epoch 48. Loss: 0.013633981702679782, Train_acc 0.997093023255814\n",
      "\n",
      "Epoch 48. Loss: 0.017806345916945687, Train_acc 0.9970646676300579\n",
      "\n",
      "Epoch 48. Loss: 0.016836623390459077, Train_acc 0.9970815373563219\n",
      "\n",
      "Epoch 48. Loss: 0.01546746544851487, Train_acc 0.9970982142857143\n",
      "\n",
      "Epoch 48. Loss: 0.015447417280646789, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 48. Loss: 0.014069328253445888, Train_acc 0.9970868644067796\n",
      "\n",
      "Epoch 48. Loss: 0.012811426271850942, Train_acc 0.9971032303370787\n",
      "\n",
      "Epoch 48. Loss: 0.014059955060352455, Train_acc 0.997032122905028\n",
      "\n",
      "Epoch 48. Loss: 0.01295556259590647, Train_acc 0.9970486111111111\n",
      "\n",
      "Epoch 48. Loss: 0.011865645038343323, Train_acc 0.9970649171270718\n",
      "\n",
      "Epoch 48. Loss: 0.010772822447369415, Train_acc 0.9970810439560439\n",
      "\n",
      "Epoch 48. Loss: 0.010089643133655119, Train_acc 0.9970969945355191\n",
      "\n",
      "Epoch 48. Loss: 0.009119006853695894, Train_acc 0.9971127717391305\n",
      "\n",
      "Epoch 48. Loss: 0.009386751751359867, Train_acc 0.9970861486486486\n",
      "\n",
      "Epoch 48. Loss: 0.011401343859961539, Train_acc 0.997059811827957\n",
      "\n",
      "Epoch 48. Loss: 0.011311801594702221, Train_acc 0.997033756684492\n",
      "\n",
      "Epoch 48. Loss: 0.011263123554475145, Train_acc 0.9970079787234043\n",
      "\n",
      "Epoch 48. Loss: 0.010410548393975528, Train_acc 0.9970238095238095\n",
      "\n",
      "Epoch 48. Loss: 0.00952755600376874, Train_acc 0.9970394736842105\n",
      "\n",
      "Epoch 48. Loss: 0.009385740315144804, Train_acc 0.9970140706806283\n",
      "\n",
      "Epoch 48. Loss: 0.008917825792931511, Train_acc 0.9970296223958334\n",
      "\n",
      "Epoch 48. Loss: 0.008734928332003648, Train_acc 0.9970450129533679\n",
      "\n",
      "Epoch 48. Loss: 0.007964035628124502, Train_acc 0.9970602448453608\n",
      "\n",
      "Epoch 48. Loss: 0.008596204153792048, Train_acc 0.9970352564102564\n",
      "\n",
      "Epoch 48. Loss: 0.00796670651511489, Train_acc 0.99704\n",
      "\n",
      "Epoch 49. Loss: 0.0071869483977960716, Train_acc 1.0\n",
      "\n",
      "Epoch 49. Loss: 0.00660973470516418, Train_acc 1.0\n",
      "\n",
      "Epoch 49. Loss: 0.013289038966066372, Train_acc 0.9895833333333334\n",
      "\n",
      "Epoch 49. Loss: 0.012262421375855861, Train_acc 0.9921875\n",
      "\n",
      "Epoch 49. Loss: 0.011386631825278751, Train_acc 0.99375\n",
      "\n",
      "Epoch 49. Loss: 0.012191077827254431, Train_acc 0.9934895833333334\n",
      "\n",
      "Epoch 49. Loss: 0.019218424641048462, Train_acc 0.9910714285714286\n",
      "\n",
      "Epoch 49. Loss: 0.021176578566094235, Train_acc 0.9912109375\n",
      "\n",
      "Epoch 49. Loss: 0.01949098732888102, Train_acc 0.9921875\n",
      "\n",
      "Epoch 49. Loss: 0.017855591706434484, Train_acc 0.99296875\n",
      "\n",
      "Epoch 49. Loss: 0.017722091494798302, Train_acc 0.9928977272727273\n",
      "\n",
      "Epoch 49. Loss: 0.018175044061660445, Train_acc 0.9921875\n",
      "\n",
      "Epoch 49. Loss: 0.020483559431361865, Train_acc 0.9921875\n",
      "\n",
      "Epoch 49. Loss: 0.0243984995589206, Train_acc 0.9910714285714286\n",
      "\n",
      "Epoch 49. Loss: 0.029345784780879264, Train_acc 0.9911458333333333\n",
      "\n",
      "Epoch 49. Loss: 0.02989502738192628, Train_acc 0.99072265625\n",
      "\n",
      "Epoch 49. Loss: 0.03333553663141981, Train_acc 0.9903492647058824\n",
      "\n",
      "Epoch 49. Loss: 0.03896880067510118, Train_acc 0.9895833333333334\n",
      "\n",
      "Epoch 49. Loss: 0.043710867319608125, Train_acc 0.9893092105263158\n",
      "\n",
      "Epoch 49. Loss: 0.040730465914998404, Train_acc 0.989453125\n",
      "\n",
      "Epoch 49. Loss: 0.03714655441003497, Train_acc 0.9899553571428571\n",
      "\n",
      "Epoch 49. Loss: 0.03466749636343827, Train_acc 0.9900568181818182\n",
      "\n",
      "Epoch 49. Loss: 0.03290421543727854, Train_acc 0.9904891304347826\n",
      "\n",
      "Epoch 49. Loss: 0.03127723510453587, Train_acc 0.9908854166666666\n",
      "\n",
      "Epoch 49. Loss: 0.029069738670940568, Train_acc 0.99125\n",
      "\n",
      "Epoch 49. Loss: 0.026996948198755418, Train_acc 0.9915865384615384\n",
      "\n",
      "Epoch 49. Loss: 0.027434285321485848, Train_acc 0.9913194444444444\n",
      "\n",
      "Epoch 49. Loss: 0.025338007328199016, Train_acc 0.9916294642857143\n",
      "\n",
      "Epoch 49. Loss: 0.026339373350697755, Train_acc 0.9916487068965517\n",
      "\n",
      "Epoch 49. Loss: 0.027146390551827552, Train_acc 0.99140625\n",
      "\n",
      "Epoch 49. Loss: 0.028757528043838323, Train_acc 0.991179435483871\n",
      "\n",
      "Epoch 49. Loss: 0.030515586728202086, Train_acc 0.99072265625\n",
      "\n",
      "Epoch 49. Loss: 0.029525670948040587, Train_acc 0.990530303030303\n",
      "\n",
      "Epoch 49. Loss: 0.027991260868232344, Train_acc 0.9905790441176471\n",
      "\n",
      "Epoch 49. Loss: 0.0289184744941481, Train_acc 0.990625\n",
      "\n",
      "Epoch 49. Loss: 0.0316856820095141, Train_acc 0.990234375\n",
      "\n",
      "Epoch 49. Loss: 0.029099361035993032, Train_acc 0.9904983108108109\n",
      "\n",
      "Epoch 49. Loss: 0.026813665448147356, Train_acc 0.9907483552631579\n",
      "\n",
      "Epoch 49. Loss: 0.025094636661724717, Train_acc 0.9909855769230769\n",
      "\n",
      "Epoch 49. Loss: 0.02272094136346114, Train_acc 0.9912109375\n",
      "\n",
      "Epoch 49. Loss: 0.021031202813926928, Train_acc 0.9914253048780488\n",
      "\n",
      "Epoch 49. Loss: 0.019701741648191443, Train_acc 0.9916294642857143\n",
      "\n",
      "Epoch 49. Loss: 0.02267975510282001, Train_acc 0.9914607558139535\n",
      "\n",
      "Epoch 49. Loss: 0.020840829425284396, Train_acc 0.9916548295454546\n",
      "\n",
      "Epoch 49. Loss: 0.02158436363628131, Train_acc 0.9914930555555556\n",
      "\n",
      "Epoch 49. Loss: 0.019974264579480486, Train_acc 0.9916779891304348\n",
      "\n",
      "Epoch 49. Loss: 0.018236653534105956, Train_acc 0.9918550531914894\n",
      "\n",
      "Epoch 49. Loss: 0.019832147533474752, Train_acc 0.9918619791666666\n",
      "\n",
      "Epoch 49. Loss: 0.018312683272908678, Train_acc 0.9920280612244898\n",
      "\n",
      "Epoch 49. Loss: 0.01977927996386637, Train_acc 0.991875\n",
      "\n",
      "Epoch 49. Loss: 0.020898907753850962, Train_acc 0.9917279411764706\n",
      "\n",
      "Epoch 49. Loss: 0.020583630351447415, Train_acc 0.9917367788461539\n",
      "\n",
      "Epoch 49. Loss: 0.01881915844818057, Train_acc 0.9918926886792453\n",
      "\n",
      "Epoch 49. Loss: 0.020745760357440426, Train_acc 0.9918981481481481\n",
      "\n",
      "Epoch 49. Loss: 0.01906698514690481, Train_acc 0.9920454545454546\n",
      "\n",
      "Epoch 49. Loss: 0.017462941579368552, Train_acc 0.9921875\n",
      "\n",
      "Epoch 49. Loss: 0.016413658922028698, Train_acc 0.9923245614035088\n",
      "\n",
      "Epoch 49. Loss: 0.019684904871981285, Train_acc 0.9919181034482759\n",
      "\n",
      "Epoch 49. Loss: 0.01837335922406698, Train_acc 0.9919226694915254\n",
      "\n",
      "Epoch 49. Loss: 0.017229690469457964, Train_acc 0.9920572916666667\n",
      "\n",
      "Epoch 49. Loss: 0.01582045379976564, Train_acc 0.9921875\n",
      "\n",
      "Epoch 49. Loss: 0.017866365078390838, Train_acc 0.9920614919354839\n",
      "\n",
      "Epoch 49. Loss: 0.016758433808357596, Train_acc 0.9921875\n",
      "\n",
      "Epoch 49. Loss: 0.015528727421809208, Train_acc 0.9923095703125\n",
      "\n",
      "Epoch 49. Loss: 0.014144261421787565, Train_acc 0.9924278846153847\n",
      "\n",
      "Epoch 49. Loss: 0.013805458091522298, Train_acc 0.9924242424242424\n",
      "\n",
      "Epoch 49. Loss: 0.013925486222945191, Train_acc 0.9924207089552238\n",
      "\n",
      "Epoch 49. Loss: 0.01505783915463913, Train_acc 0.9924172794117647\n",
      "\n",
      "Epoch 49. Loss: 0.013704672419895187, Train_acc 0.9925271739130435\n",
      "\n",
      "Epoch 49. Loss: 0.01477014549571525, Train_acc 0.9925223214285714\n",
      "\n",
      "Epoch 49. Loss: 0.013419206690772633, Train_acc 0.9926276408450704\n",
      "\n",
      "Epoch 49. Loss: 0.012183775377371246, Train_acc 0.9927300347222222\n",
      "\n",
      "Epoch 49. Loss: 0.011037264131907748, Train_acc 0.9928296232876712\n",
      "\n",
      "Epoch 49. Loss: 0.011030560833279008, Train_acc 0.9928209459459459\n",
      "\n",
      "Epoch 49. Loss: 0.015675215663370833, Train_acc 0.9927083333333333\n",
      "\n",
      "Epoch 49. Loss: 0.015361856382510673, Train_acc 0.9927014802631579\n",
      "\n",
      "Epoch 49. Loss: 0.014611801712740907, Train_acc 0.9927962662337663\n",
      "\n",
      "Epoch 49. Loss: 0.01422167286339055, Train_acc 0.9927884615384616\n",
      "\n",
      "Epoch 49. Loss: 0.014752747178637837, Train_acc 0.9927808544303798\n",
      "\n",
      "Epoch 49. Loss: 0.014310621282217374, Train_acc 0.9927734375\n",
      "\n",
      "Epoch 49. Loss: 0.013463157451084975, Train_acc 0.9928626543209876\n",
      "\n",
      "Epoch 49. Loss: 0.012911010174541227, Train_acc 0.9929496951219512\n",
      "\n",
      "Epoch 49. Loss: 0.013517444071401851, Train_acc 0.9929405120481928\n",
      "\n",
      "Epoch 49. Loss: 0.014170943524446814, Train_acc 0.9929315476190477\n",
      "\n",
      "Epoch 49. Loss: 0.013134624690717514, Train_acc 0.993014705882353\n",
      "\n",
      "Epoch 49. Loss: 0.012366324277287176, Train_acc 0.9930959302325582\n",
      "\n",
      "Epoch 49. Loss: 0.011345083152039753, Train_acc 0.9931752873563219\n",
      "\n",
      "Epoch 49. Loss: 0.011410019872144378, Train_acc 0.9931640625\n",
      "\n",
      "Epoch 49. Loss: 0.011396482674827143, Train_acc 0.9931530898876404\n",
      "\n",
      "Epoch 49. Loss: 0.010548438536941974, Train_acc 0.9932291666666667\n",
      "\n",
      "Epoch 49. Loss: 0.02127681604726908, Train_acc 0.9930460164835165\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49. Loss: 0.021318864770565608, Train_acc 0.9929517663043478\n",
      "\n",
      "Epoch 49. Loss: 0.01977041463360266, Train_acc 0.9930275537634409\n",
      "\n",
      "Epoch 49. Loss: 0.018312705040842977, Train_acc 0.9931017287234043\n",
      "\n",
      "Epoch 49. Loss: 0.018923915533009785, Train_acc 0.9930921052631579\n",
      "\n",
      "Epoch 49. Loss: 0.017968707553550855, Train_acc 0.9931640625\n",
      "\n",
      "Epoch 49. Loss: 0.016510886760545004, Train_acc 0.9932345360824743\n",
      "\n",
      "Epoch 49. Loss: 0.016341700963221992, Train_acc 0.9932238520408163\n",
      "\n",
      "Epoch 49. Loss: 0.01557243943173558, Train_acc 0.9932133838383839\n",
      "\n",
      "Epoch 49. Loss: 0.01454754748158637, Train_acc 0.99328125\n",
      "\n",
      "[Epoch 49 Batch 100] Loss: 0.013192796789430679 Training: accuracy=0.993348\n",
      "Epoch 49. Loss: 0.013192796789430679, Train_acc 0.9933477722772277\n",
      "\n",
      "Epoch 49. Loss: 0.012432261481424957, Train_acc 0.9934129901960784\n",
      "\n",
      "Epoch 49. Loss: 0.014745349816567412, Train_acc 0.9933252427184466\n",
      "\n",
      "Epoch 49. Loss: 0.013472609968672732, Train_acc 0.9933894230769231\n",
      "\n",
      "Epoch 49. Loss: 0.01737537115963448, Train_acc 0.9933035714285714\n",
      "\n",
      "Epoch 49. Loss: 0.015736688929107626, Train_acc 0.9933667452830188\n",
      "\n",
      "Epoch 49. Loss: 0.01484222297278658, Train_acc 0.993428738317757\n",
      "\n",
      "Epoch 49. Loss: 0.013924695561000247, Train_acc 0.9934895833333334\n",
      "\n",
      "Epoch 49. Loss: 0.012718499425595439, Train_acc 0.9935493119266054\n",
      "\n",
      "Epoch 49. Loss: 0.011685728323276731, Train_acc 0.9936079545454546\n",
      "\n",
      "Epoch 49. Loss: 0.013866948075725936, Train_acc 0.9935951576576577\n",
      "\n",
      "Epoch 49. Loss: 0.016389401544005547, Train_acc 0.9935128348214286\n",
      "\n",
      "Epoch 49. Loss: 0.015035513292361087, Train_acc 0.9935702433628318\n",
      "\n",
      "Epoch 49. Loss: 0.015586347990282287, Train_acc 0.9935581140350878\n",
      "\n",
      "Epoch 49. Loss: 0.01783340158735029, Train_acc 0.993546195652174\n",
      "\n",
      "Epoch 49. Loss: 0.017727384747633145, Train_acc 0.9935344827586207\n",
      "\n",
      "Epoch 49. Loss: 0.016848802930029157, Train_acc 0.9935897435897436\n",
      "\n",
      "Epoch 49. Loss: 0.0163505341403889, Train_acc 0.9935778601694916\n",
      "\n",
      "Epoch 49. Loss: 0.017234963473070325, Train_acc 0.993500525210084\n",
      "\n",
      "Epoch 49. Loss: 0.016303151198228, Train_acc 0.9935546875\n",
      "\n",
      "Epoch 49. Loss: 0.01671557703435403, Train_acc 0.9935433884297521\n",
      "\n",
      "Epoch 49. Loss: 0.015657223208501773, Train_acc 0.9935963114754098\n",
      "\n",
      "Epoch 49. Loss: 0.01607858544774786, Train_acc 0.9935848577235772\n",
      "\n",
      "Epoch 49. Loss: 0.015076196006875651, Train_acc 0.9936365927419355\n",
      "\n",
      "Epoch 49. Loss: 0.016021266001708584, Train_acc 0.993625\n",
      "\n",
      "Epoch 49. Loss: 0.014517967348468849, Train_acc 0.9936755952380952\n",
      "\n",
      "Epoch 49. Loss: 0.013332121556033983, Train_acc 0.9937253937007874\n",
      "\n",
      "Epoch 49. Loss: 0.015103517533865834, Train_acc 0.99371337890625\n",
      "\n",
      "Epoch 49. Loss: 0.01531190203415805, Train_acc 0.9937015503875969\n",
      "\n",
      "Epoch 49. Loss: 0.016578025610334758, Train_acc 0.9936899038461539\n",
      "\n",
      "Epoch 49. Loss: 0.01618115940265693, Train_acc 0.9936784351145038\n",
      "\n",
      "Epoch 49. Loss: 0.0176079396626905, Train_acc 0.9936671401515151\n",
      "\n",
      "Epoch 49. Loss: 0.016160947177809956, Train_acc 0.9937147556390977\n",
      "\n",
      "Epoch 49. Loss: 0.017521182457210856, Train_acc 0.9937033582089553\n",
      "\n",
      "Epoch 49. Loss: 0.016062211821990226, Train_acc 0.99375\n",
      "\n",
      "Epoch 49. Loss: 0.01468178998427124, Train_acc 0.9937959558823529\n",
      "\n",
      "Epoch 49. Loss: 0.01337092401140062, Train_acc 0.9938412408759124\n",
      "\n",
      "Epoch 49. Loss: 0.012754802408544373, Train_acc 0.9938858695652174\n",
      "\n",
      "Epoch 49. Loss: 0.011613304037711606, Train_acc 0.9939298561151079\n",
      "\n",
      "Epoch 49. Loss: 0.01081496349918388, Train_acc 0.9939732142857143\n",
      "\n",
      "Epoch 49. Loss: 0.015483387159832204, Train_acc 0.9938497340425532\n",
      "\n",
      "Epoch 49. Loss: 0.018179225859815972, Train_acc 0.9937830105633803\n",
      "\n",
      "Epoch 49. Loss: 0.0164365366813858, Train_acc 0.993826486013986\n",
      "\n",
      "Epoch 49. Loss: 0.0189982037887561, Train_acc 0.9937065972222222\n",
      "\n",
      "Epoch 49. Loss: 0.017509687496327253, Train_acc 0.99375\n",
      "\n",
      "Epoch 49. Loss: 0.015910708169433078, Train_acc 0.993792808219178\n",
      "\n",
      "Epoch 49. Loss: 0.014490585103520096, Train_acc 0.9938350340136054\n",
      "\n",
      "Epoch 49. Loss: 0.01879206872721464, Train_acc 0.9937711148648649\n",
      "\n",
      "Epoch 49. Loss: 0.025235914380013505, Train_acc 0.9936031879194631\n",
      "\n",
      "Epoch 49. Loss: 0.02356612259804567, Train_acc 0.99359375\n",
      "\n",
      "Epoch 49. Loss: 0.021359444425189736, Train_acc 0.9936361754966887\n",
      "\n",
      "Epoch 49. Loss: 0.0233014776697912, Train_acc 0.9935752467105263\n",
      "\n",
      "Epoch 49. Loss: 0.022038512231364087, Train_acc 0.9936172385620915\n",
      "\n",
      "Epoch 49. Loss: 0.020229823644641848, Train_acc 0.993658685064935\n",
      "\n",
      "Epoch 49. Loss: 0.019843209316447806, Train_acc 0.9936491935483871\n",
      "\n",
      "Epoch 49. Loss: 0.018540491572498173, Train_acc 0.9936899038461539\n",
      "\n",
      "Epoch 49. Loss: 0.016908808648604653, Train_acc 0.9937300955414012\n",
      "\n",
      "Epoch 49. Loss: 0.016234712708757967, Train_acc 0.993720332278481\n",
      "\n",
      "Epoch 49. Loss: 0.016596290126830324, Train_acc 0.9937106918238994\n",
      "\n",
      "Epoch 49. Loss: 0.01564839351845382, Train_acc 0.99375\n",
      "\n",
      "Epoch 49. Loss: 0.017584633398109065, Train_acc 0.9937402950310559\n",
      "\n",
      "Epoch 49. Loss: 0.017920260974514532, Train_acc 0.9937307098765432\n",
      "\n",
      "Epoch 49. Loss: 0.017445651939882085, Train_acc 0.9937212423312883\n",
      "\n",
      "Epoch 49. Loss: 0.02181116260710947, Train_acc 0.9937118902439024\n",
      "\n",
      "Epoch 49. Loss: 0.020760406711312462, Train_acc 0.99375\n",
      "\n",
      "Epoch 49. Loss: 0.02035169254268318, Train_acc 0.9937405873493976\n",
      "\n",
      "Epoch 49. Loss: 0.018816339015067605, Train_acc 0.9937780688622755\n",
      "\n",
      "Epoch 49. Loss: 0.017160967465058855, Train_acc 0.9938151041666666\n",
      "\n",
      "Epoch 49. Loss: 0.015886265138893626, Train_acc 0.9938517011834319\n",
      "\n",
      "Epoch 49. Loss: 0.016530534975328418, Train_acc 0.9938419117647059\n",
      "\n",
      "Epoch 49. Loss: 0.01976166562968347, Train_acc 0.9936951754385965\n",
      "\n",
      "Epoch 49. Loss: 0.01823270382233429, Train_acc 0.9937318313953488\n",
      "\n",
      "Epoch 49. Loss: 0.016983347053435162, Train_acc 0.993768063583815\n",
      "\n",
      "Epoch 49. Loss: 0.0163310669721127, Train_acc 0.9937589798850575\n",
      "\n",
      "Epoch 49. Loss: 0.015011909743447047, Train_acc 0.9937946428571428\n",
      "\n",
      "Epoch 49. Loss: 0.01398306364630068, Train_acc 0.9938299005681818\n",
      "\n",
      "Epoch 49. Loss: 0.012969190686213118, Train_acc 0.9938647598870056\n",
      "\n",
      "Epoch 49. Loss: 0.013879089259446092, Train_acc 0.9938553370786517\n",
      "\n",
      "Epoch 49. Loss: 0.012936420324451114, Train_acc 0.9938896648044693\n",
      "\n",
      "Epoch 49. Loss: 0.013211316987579809, Train_acc 0.9938802083333333\n",
      "\n",
      "Epoch 49. Loss: 0.012516630571072471, Train_acc 0.9939140193370166\n",
      "\n",
      "Epoch 49. Loss: 0.011822173572839951, Train_acc 0.9939474587912088\n",
      "\n",
      "Epoch 49. Loss: 0.010984433157528927, Train_acc 0.9939805327868853\n",
      "\n",
      "Epoch 49. Loss: 0.011589645561533116, Train_acc 0.9939707880434783\n",
      "\n",
      "Epoch 49. Loss: 0.010672846388331303, Train_acc 0.9940033783783784\n",
      "\n",
      "Epoch 49. Loss: 0.011699786217371746, Train_acc 0.9939936155913979\n",
      "\n",
      "Epoch 49. Loss: 0.010798335507610552, Train_acc 0.9940257352941176\n",
      "\n",
      "Epoch 49. Loss: 0.010907204465656678, Train_acc 0.9940159574468085\n",
      "\n",
      "Epoch 49. Loss: 0.011585688456823708, Train_acc 0.994006283068783\n",
      "\n",
      "Epoch 49. Loss: 0.0127701489537331, Train_acc 0.9939967105263158\n",
      "\n",
      "Epoch 49. Loss: 0.012602492540422606, Train_acc 0.9940281413612565\n",
      "\n",
      "Epoch 49. Loss: 0.012866040127882535, Train_acc 0.9940592447916666\n",
      "\n",
      "Epoch 49. Loss: 0.01179687376610265, Train_acc 0.9940900259067358\n",
      "\n",
      "Epoch 49. Loss: 0.013523418530450694, Train_acc 0.9940802190721649\n",
      "\n",
      "Epoch 49. Loss: 0.012578054444530399, Train_acc 0.9941105769230769\n",
      "\n",
      "Epoch 49. Loss: 0.01138836497275833, Train_acc 0.99412\n",
      "\n",
      "Epoch 50. Loss: 0.01045090002045456, Train_acc 1.0\n",
      "\n",
      "Epoch 50. Loss: 0.012555686389435144, Train_acc 0.99609375\n",
      "\n",
      "Epoch 50. Loss: 0.011840320373724829, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 50. Loss: 0.010694184288470906, Train_acc 0.998046875\n",
      "\n",
      "Epoch 50. Loss: 0.012440086947461034, Train_acc 0.9953125\n",
      "\n",
      "Epoch 50. Loss: 0.012026609000486193, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 50. Loss: 0.010976616131370121, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 50. Loss: 0.010566954355333615, Train_acc 0.99609375\n",
      "\n",
      "Epoch 50. Loss: 0.010677665806616278, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 50. Loss: 0.009989686704550622, Train_acc 0.99609375\n",
      "\n",
      "Epoch 50. Loss: 0.01191699130553702, Train_acc 0.9950284090909091\n",
      "\n",
      "Epoch 50. Loss: 0.011840661785471732, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 50. Loss: 0.010973992575527693, Train_acc 0.9951923076923077\n",
      "\n",
      "Epoch 50. Loss: 0.011002987086911319, Train_acc 0.9949776785714286\n",
      "\n",
      "Epoch 50. Loss: 0.012112146878367053, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 50. Loss: 0.011975790572874595, Train_acc 0.99462890625\n",
      "\n",
      "Epoch 50. Loss: 0.011113871603463159, Train_acc 0.9949448529411765\n",
      "\n",
      "Epoch 50. Loss: 0.010400005374554454, Train_acc 0.9952256944444444\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50. Loss: 0.009962596852737956, Train_acc 0.9954769736842105\n",
      "\n",
      "Epoch 50. Loss: 0.00940498060061779, Train_acc 0.995703125\n",
      "\n",
      "Epoch 50. Loss: 0.008615777767088977, Train_acc 0.9959077380952381\n",
      "\n",
      "Epoch 50. Loss: 0.010359328837442668, Train_acc 0.9957386363636364\n",
      "\n",
      "Epoch 50. Loss: 0.009529341689495688, Train_acc 0.9959239130434783\n",
      "\n",
      "Epoch 50. Loss: 0.008934616487918894, Train_acc 0.99609375\n",
      "\n",
      "Epoch 50. Loss: 0.008485091164736688, Train_acc 0.99625\n",
      "\n",
      "Epoch 50. Loss: 0.008336494944642848, Train_acc 0.9963942307692307\n",
      "\n",
      "Epoch 50. Loss: 0.012360080106989324, Train_acc 0.9962384259259259\n",
      "\n",
      "Epoch 50. Loss: 0.011933590530397697, Train_acc 0.99609375\n",
      "\n",
      "Epoch 50. Loss: 0.010964368457608405, Train_acc 0.9962284482758621\n",
      "\n",
      "Epoch 50. Loss: 0.009941328014724388, Train_acc 0.9963541666666667\n",
      "\n",
      "Epoch 50. Loss: 0.009111959564463437, Train_acc 0.9964717741935484\n",
      "\n",
      "Epoch 50. Loss: 0.009709055325635797, Train_acc 0.996337890625\n",
      "\n",
      "Epoch 50. Loss: 0.008792842596022957, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 50. Loss: 0.008941193541957743, Train_acc 0.9965533088235294\n",
      "\n",
      "Epoch 50. Loss: 0.008587192805698937, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 50. Loss: 0.007752125780314923, Train_acc 0.9967447916666666\n",
      "\n",
      "Epoch 50. Loss: 0.007079201361825217, Train_acc 0.9968327702702703\n",
      "\n",
      "Epoch 50. Loss: 0.007290844269505276, Train_acc 0.9969161184210527\n",
      "\n",
      "Epoch 50. Loss: 0.00831265727243823, Train_acc 0.9967948717948718\n",
      "\n",
      "Epoch 50. Loss: 0.007553536937381347, Train_acc 0.996875\n",
      "\n",
      "Epoch 50. Loss: 0.00805289566136496, Train_acc 0.9967606707317073\n",
      "\n",
      "Epoch 50. Loss: 0.007737682329792649, Train_acc 0.9968377976190477\n",
      "\n",
      "Epoch 50. Loss: 0.009842137083869162, Train_acc 0.9967296511627907\n",
      "\n",
      "Epoch 50. Loss: 0.010581921042914078, Train_acc 0.9966264204545454\n",
      "\n",
      "Epoch 50. Loss: 0.009544775687938826, Train_acc 0.9967013888888889\n",
      "\n",
      "Epoch 50. Loss: 0.008770989855895249, Train_acc 0.9967730978260869\n",
      "\n",
      "Epoch 50. Loss: 0.0138925667680232, Train_acc 0.9965093085106383\n",
      "\n",
      "Epoch 50. Loss: 0.014863980918550039, Train_acc 0.9962565104166666\n",
      "\n",
      "Epoch 50. Loss: 0.013844336182853767, Train_acc 0.9963329081632653\n",
      "\n",
      "Epoch 50. Loss: 0.013733201200647225, Train_acc 0.99625\n",
      "\n",
      "Epoch 50. Loss: 0.012394168978452446, Train_acc 0.9963235294117647\n",
      "\n",
      "Epoch 50. Loss: 0.012373700407612112, Train_acc 0.9962439903846154\n",
      "\n",
      "Epoch 50. Loss: 0.0112543233724023, Train_acc 0.996314858490566\n",
      "\n",
      "Epoch 50. Loss: 0.0103052502360122, Train_acc 0.9963831018518519\n",
      "\n",
      "Epoch 50. Loss: 0.00957425242911368, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 50. Loss: 0.011156098674988056, Train_acc 0.9962332589285714\n",
      "\n",
      "Epoch 50. Loss: 0.012019262431194161, Train_acc 0.9961622807017544\n",
      "\n",
      "Epoch 50. Loss: 0.011167539995540477, Train_acc 0.9962284482758621\n",
      "\n",
      "Epoch 50. Loss: 0.011189936742153137, Train_acc 0.9961599576271186\n",
      "\n",
      "Epoch 50. Loss: 0.011337654273181888, Train_acc 0.99609375\n",
      "\n",
      "Epoch 50. Loss: 0.011662714668783308, Train_acc 0.9960297131147541\n",
      "\n",
      "Epoch 50. Loss: 0.011594072979992116, Train_acc 0.9959677419354839\n",
      "\n",
      "Epoch 50. Loss: 0.010587640211184756, Train_acc 0.996031746031746\n",
      "\n",
      "Epoch 50. Loss: 0.01028285627345735, Train_acc 0.9959716796875\n",
      "\n",
      "Epoch 50. Loss: 0.012085472946886666, Train_acc 0.9959134615384615\n",
      "\n",
      "Epoch 50. Loss: 0.011145363505281013, Train_acc 0.9959753787878788\n",
      "\n",
      "Epoch 50. Loss: 0.010159344443001898, Train_acc 0.996035447761194\n",
      "\n",
      "Epoch 50. Loss: 0.009877901458727018, Train_acc 0.99609375\n",
      "\n",
      "Epoch 50. Loss: 0.009265640016298022, Train_acc 0.9961503623188406\n",
      "\n",
      "Epoch 50. Loss: 0.008569926992491358, Train_acc 0.9962053571428572\n",
      "\n",
      "Epoch 50. Loss: 0.007729197761084004, Train_acc 0.9962588028169014\n",
      "\n",
      "Epoch 50. Loss: 0.0070853819016728084, Train_acc 0.9963107638888888\n",
      "\n",
      "Epoch 50. Loss: 0.0068903617543679425, Train_acc 0.996361301369863\n",
      "\n",
      "Epoch 50. Loss: 0.006242639316096331, Train_acc 0.996410472972973\n",
      "\n",
      "Epoch 50. Loss: 0.00567879642081023, Train_acc 0.9964583333333333\n",
      "\n",
      "Epoch 50. Loss: 0.007299186758980996, Train_acc 0.9964021381578947\n",
      "\n",
      "Epoch 50. Loss: 0.007484442641841633, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 50. Loss: 0.006790483192994233, Train_acc 0.9964943910256411\n",
      "\n",
      "Epoch 50. Loss: 0.006182903630927461, Train_acc 0.9965387658227848\n",
      "\n",
      "Epoch 50. Loss: 0.008372977189775043, Train_acc 0.996484375\n",
      "\n",
      "Epoch 50. Loss: 0.008494543489118576, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 50. Loss: 0.008020194091878975, Train_acc 0.9965701219512195\n",
      "\n",
      "Epoch 50. Loss: 0.01215012376172779, Train_acc 0.9964231927710844\n",
      "\n",
      "Epoch 50. Loss: 0.011374767399177893, Train_acc 0.9964657738095238\n",
      "\n",
      "Epoch 50. Loss: 0.011229819287818025, Train_acc 0.9964154411764706\n",
      "\n",
      "Epoch 50. Loss: 0.01064559564065458, Train_acc 0.9964571220930233\n",
      "\n",
      "Epoch 50. Loss: 0.010534785271330373, Train_acc 0.9964080459770115\n",
      "\n",
      "Epoch 50. Loss: 0.018714067710021463, Train_acc 0.9961825284090909\n",
      "\n",
      "Epoch 50. Loss: 0.02173086914948761, Train_acc 0.9960498595505618\n",
      "\n",
      "Epoch 50. Loss: 0.02354618270872956, Train_acc 0.9960069444444445\n",
      "\n",
      "Epoch 50. Loss: 0.024790509653201034, Train_acc 0.9959649725274725\n",
      "\n",
      "Epoch 50. Loss: 0.031994973819354476, Train_acc 0.9957540760869565\n",
      "\n",
      "Epoch 50. Loss: 0.03008247762253818, Train_acc 0.9957997311827957\n",
      "\n",
      "Epoch 50. Loss: 0.028729009026267564, Train_acc 0.9957613031914894\n",
      "\n",
      "Epoch 50. Loss: 0.025943861510110366, Train_acc 0.9958059210526315\n",
      "\n",
      "Epoch 50. Loss: 0.023433757974088535, Train_acc 0.995849609375\n",
      "\n",
      "Epoch 50. Loss: 0.023309238652926993, Train_acc 0.9958118556701031\n",
      "\n",
      "Epoch 50. Loss: 0.022813547201939507, Train_acc 0.9957748724489796\n",
      "\n",
      "Epoch 50. Loss: 0.021253217995230632, Train_acc 0.9958175505050505\n",
      "\n",
      "Epoch 50. Loss: 0.024075799575505506, Train_acc 0.99578125\n",
      "\n",
      "[Epoch 50 Batch 100] Loss: 0.02324392633085655 Training: accuracy=0.995746\n",
      "Epoch 50. Loss: 0.02324392633085655, Train_acc 0.9957456683168316\n",
      "\n",
      "Epoch 50. Loss: 0.024005637755500138, Train_acc 0.9956341911764706\n",
      "\n",
      "Epoch 50. Loss: 0.023097357380098278, Train_acc 0.9956007281553398\n",
      "\n",
      "Epoch 50. Loss: 0.021361743173187533, Train_acc 0.9956430288461539\n",
      "\n",
      "Epoch 50. Loss: 0.021450331779884303, Train_acc 0.9956101190476191\n",
      "\n",
      "Epoch 50. Loss: 0.02828329217961461, Train_acc 0.9955041273584906\n",
      "\n",
      "Epoch 50. Loss: 0.026542122345695175, Train_acc 0.9955461448598131\n",
      "\n",
      "Epoch 50. Loss: 0.029711668728169154, Train_acc 0.9954427083333334\n",
      "\n",
      "Epoch 50. Loss: 0.02841683406088622, Train_acc 0.9954128440366973\n",
      "\n",
      "Epoch 50. Loss: 0.027553364181106137, Train_acc 0.9953835227272727\n",
      "\n",
      "Epoch 50. Loss: 0.025670692847893996, Train_acc 0.9954251126126126\n",
      "\n",
      "Epoch 50. Loss: 0.0236097610608277, Train_acc 0.9954659598214286\n",
      "\n",
      "Epoch 50. Loss: 0.02172217659195101, Train_acc 0.9955060840707964\n",
      "\n",
      "Epoch 50. Loss: 0.023032312620042284, Train_acc 0.9954084429824561\n",
      "\n",
      "Epoch 50. Loss: 0.02140383783469366, Train_acc 0.9954483695652174\n",
      "\n",
      "Epoch 50. Loss: 0.02402161908289582, Train_acc 0.9953529094827587\n",
      "\n",
      "Epoch 50. Loss: 0.022784776688135777, Train_acc 0.9953258547008547\n",
      "\n",
      "Epoch 50. Loss: 0.020824995671861274, Train_acc 0.995365466101695\n",
      "\n",
      "Epoch 50. Loss: 0.019584380419689032, Train_acc 0.9953387605042017\n",
      "\n",
      "Epoch 50. Loss: 0.01856411781010414, Train_acc 0.9953776041666667\n",
      "\n",
      "Epoch 50. Loss: 0.01968198693034695, Train_acc 0.9953512396694215\n",
      "\n",
      "Epoch 50. Loss: 0.01982202091429514, Train_acc 0.9952612704918032\n",
      "\n",
      "Epoch 50. Loss: 0.01793761721597358, Train_acc 0.9952997967479674\n",
      "\n",
      "Epoch 50. Loss: 0.017053223815675776, Train_acc 0.9953377016129032\n",
      "\n",
      "Epoch 50. Loss: 0.01976429827551502, Train_acc 0.99525\n",
      "\n",
      "Epoch 50. Loss: 0.01793893264829032, Train_acc 0.9952876984126984\n",
      "\n",
      "Epoch 50. Loss: 0.016766316477348615, Train_acc 0.9953248031496063\n",
      "\n",
      "Epoch 50. Loss: 0.015519453224292585, Train_acc 0.995361328125\n",
      "\n",
      "Epoch 50. Loss: 0.015596567663625946, Train_acc 0.9953367248062015\n",
      "\n",
      "Epoch 50. Loss: 0.01427677479586846, Train_acc 0.9953725961538461\n",
      "\n",
      "Epoch 50. Loss: 0.014768879477994261, Train_acc 0.9952886450381679\n",
      "\n",
      "Epoch 50. Loss: 0.013898201687470035, Train_acc 0.9953243371212122\n",
      "\n",
      "Epoch 50. Loss: 0.013976117211581728, Train_acc 0.9952420112781954\n",
      "\n",
      "Epoch 50. Loss: 0.012854764357657545, Train_acc 0.9952775186567164\n",
      "\n",
      "Epoch 50. Loss: 0.011799944020466191, Train_acc 0.9953125\n",
      "\n",
      "Epoch 50. Loss: 0.015228543872078821, Train_acc 0.9951746323529411\n",
      "\n",
      "Epoch 50. Loss: 0.013922959264985232, Train_acc 0.9952098540145985\n",
      "\n",
      "Epoch 50. Loss: 0.014174447496418514, Train_acc 0.9951879528985508\n",
      "\n",
      "Epoch 50. Loss: 0.01358414515675696, Train_acc 0.995222571942446\n",
      "\n",
      "Epoch 50. Loss: 0.01260111389522188, Train_acc 0.9952566964285714\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50. Loss: 0.011778188419024048, Train_acc 0.9952903368794326\n",
      "\n",
      "Epoch 50. Loss: 0.014681602422904878, Train_acc 0.995268485915493\n",
      "\n",
      "Epoch 50. Loss: 0.013840725746314444, Train_acc 0.9953015734265734\n",
      "\n",
      "Epoch 50. Loss: 0.019371215903664276, Train_acc 0.9951714409722222\n",
      "\n",
      "Epoch 50. Loss: 0.019819360997293575, Train_acc 0.9951508620689655\n",
      "\n",
      "Epoch 50. Loss: 0.018178774272067117, Train_acc 0.9951840753424658\n",
      "\n",
      "Epoch 50. Loss: 0.017935443316098542, Train_acc 0.9951636904761905\n",
      "\n",
      "Epoch 50. Loss: 0.0194115799464552, Train_acc 0.995090793918919\n",
      "\n",
      "Epoch 50. Loss: 0.018654971134463107, Train_acc 0.9951237416107382\n",
      "\n",
      "Epoch 50. Loss: 0.0170214416546069, Train_acc 0.99515625\n",
      "\n",
      "Epoch 50. Loss: 0.015548664427729765, Train_acc 0.9951883278145696\n",
      "\n",
      "Epoch 50. Loss: 0.014122020230214137, Train_acc 0.9952199835526315\n",
      "\n",
      "Epoch 50. Loss: 0.013971055843401256, Train_acc 0.9952001633986928\n",
      "\n",
      "Epoch 50. Loss: 0.01338383284029511, Train_acc 0.9952313311688312\n",
      "\n",
      "Epoch 50. Loss: 0.01870048323408199, Train_acc 0.9951612903225806\n",
      "\n",
      "Epoch 50. Loss: 0.020707104615587883, Train_acc 0.9950420673076923\n",
      "\n",
      "Epoch 50. Loss: 0.02131444947023889, Train_acc 0.9949741242038217\n",
      "\n",
      "Epoch 50. Loss: 0.019649603419524733, Train_acc 0.9950059335443038\n",
      "\n",
      "Epoch 50. Loss: 0.01775082560712603, Train_acc 0.9950373427672956\n",
      "\n",
      "Epoch 50. Loss: 0.018263701981316573, Train_acc 0.994970703125\n",
      "\n",
      "Epoch 50. Loss: 0.022867138879904658, Train_acc 0.9949048913043478\n",
      "\n",
      "Epoch 50. Loss: 0.02068664548640431, Train_acc 0.9949363425925926\n",
      "\n",
      "Epoch 50. Loss: 0.020396696972951125, Train_acc 0.9949194785276073\n",
      "\n",
      "Epoch 50. Loss: 0.019195456383918074, Train_acc 0.9949028201219512\n",
      "\n",
      "Epoch 50. Loss: 0.017425739942269935, Train_acc 0.9949337121212121\n",
      "\n",
      "Epoch 50. Loss: 0.02047106065894134, Train_acc 0.9948230421686747\n",
      "\n",
      "Epoch 50. Loss: 0.019524569446250504, Train_acc 0.9948540419161677\n",
      "\n",
      "Epoch 50. Loss: 0.0194998854110283, Train_acc 0.9948381696428571\n",
      "\n",
      "Epoch 50. Loss: 0.019109447091934892, Train_acc 0.9948224852071006\n",
      "\n",
      "Epoch 50. Loss: 0.018425017891929577, Train_acc 0.9948069852941176\n",
      "\n",
      "Epoch 50. Loss: 0.017181021148955252, Train_acc 0.9948373538011696\n",
      "\n",
      "Epoch 50. Loss: 0.016314493015404427, Train_acc 0.9948219476744186\n",
      "\n",
      "Epoch 50. Loss: 0.015968504118915695, Train_acc 0.9947615606936416\n",
      "\n",
      "Epoch 50. Loss: 0.016274350011047392, Train_acc 0.9947018678160919\n",
      "\n",
      "Epoch 50. Loss: 0.020453539899316434, Train_acc 0.9946875\n",
      "\n",
      "Epoch 50. Loss: 0.01889078963070542, Train_acc 0.9947176846590909\n",
      "\n",
      "Epoch 50. Loss: 0.01707259153331307, Train_acc 0.9947475282485876\n",
      "\n",
      "Epoch 50. Loss: 0.02498411910240341, Train_acc 0.9946892556179775\n",
      "\n",
      "Epoch 50. Loss: 0.0237286542117997, Train_acc 0.994675279329609\n",
      "\n",
      "Epoch 50. Loss: 0.02254861007351315, Train_acc 0.9946614583333333\n",
      "\n",
      "Epoch 50. Loss: 0.020951623784470286, Train_acc 0.994690953038674\n",
      "\n",
      "Epoch 50. Loss: 0.0207781207415173, Train_acc 0.994634271978022\n",
      "\n",
      "Epoch 50. Loss: 0.024218218343202133, Train_acc 0.9945782103825137\n",
      "\n",
      "Epoch 50. Loss: 0.02318763122341978, Train_acc 0.9945652173913043\n",
      "\n",
      "Epoch 50. Loss: 0.021349251735645062, Train_acc 0.9945945945945946\n",
      "\n",
      "Epoch 50. Loss: 0.021021090866718464, Train_acc 0.9945816532258065\n",
      "\n",
      "Epoch 50. Loss: 0.019770517018372215, Train_acc 0.994610628342246\n",
      "\n",
      "Epoch 50. Loss: 0.019593584075809477, Train_acc 0.9945977393617021\n",
      "\n",
      "Epoch 50. Loss: 0.017798090070794637, Train_acc 0.9946263227513228\n",
      "\n",
      "Epoch 50. Loss: 0.01722642437247391, Train_acc 0.9946134868421053\n",
      "\n",
      "Epoch 50. Loss: 0.01579114933873375, Train_acc 0.9946416884816754\n",
      "\n",
      "Epoch 50. Loss: 0.014283867204445912, Train_acc 0.9946695963541666\n",
      "\n",
      "Epoch 50. Loss: 0.015755898005597277, Train_acc 0.994616256476684\n",
      "\n",
      "Epoch 50. Loss: 0.015725800392179922, Train_acc 0.9946037371134021\n",
      "\n",
      "Epoch 50. Loss: 0.015480131224974308, Train_acc 0.9945913461538461\n",
      "\n",
      "Epoch 50. Loss: 0.013957741563009975, Train_acc 0.9946\n",
      "\n",
      "Epoch 51. Loss: 0.01272787167346873, Train_acc 1.0\n",
      "\n",
      "Epoch 51. Loss: 0.011615197355092897, Train_acc 1.0\n",
      "\n",
      "Epoch 51. Loss: 0.010780702810510696, Train_acc 1.0\n",
      "\n",
      "Epoch 51. Loss: 0.009830187388960005, Train_acc 1.0\n",
      "\n",
      "Epoch 51. Loss: 0.010078655372890963, Train_acc 0.9984375\n",
      "\n",
      "Epoch 51. Loss: 0.009516208640485826, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 51. Loss: 0.011998709385171374, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 51. Loss: 0.01599388913325206, Train_acc 0.9951171875\n",
      "\n",
      "Epoch 51. Loss: 0.018673662954673785, Train_acc 0.9930555555555556\n",
      "\n",
      "Epoch 51. Loss: 0.017323490771969215, Train_acc 0.99375\n",
      "\n",
      "Epoch 51. Loss: 0.016160926103207518, Train_acc 0.9943181818181818\n",
      "\n",
      "Epoch 51. Loss: 0.02627830882037853, Train_acc 0.9921875\n",
      "\n",
      "Epoch 51. Loss: 0.02443404320626117, Train_acc 0.9927884615384616\n",
      "\n",
      "Epoch 51. Loss: 0.0223316451376184, Train_acc 0.9933035714285714\n",
      "\n",
      "Epoch 51. Loss: 0.021449229721621055, Train_acc 0.9932291666666667\n",
      "\n",
      "Epoch 51. Loss: 0.019720288589801235, Train_acc 0.99365234375\n",
      "\n",
      "Epoch 51. Loss: 0.018928063638692358, Train_acc 0.9935661764705882\n",
      "\n",
      "Epoch 51. Loss: 0.019604214298145708, Train_acc 0.9934895833333334\n",
      "\n",
      "Epoch 51. Loss: 0.01936356791920966, Train_acc 0.993421052631579\n",
      "\n",
      "Epoch 51. Loss: 0.018289098667956943, Train_acc 0.99375\n",
      "\n",
      "Epoch 51. Loss: 0.016821066170691748, Train_acc 0.9940476190476191\n",
      "\n",
      "Epoch 51. Loss: 0.015561031871073812, Train_acc 0.9943181818181818\n",
      "\n",
      "Epoch 51. Loss: 0.014497125772863658, Train_acc 0.9945652173913043\n",
      "\n",
      "Epoch 51. Loss: 0.014953649084177643, Train_acc 0.9944661458333334\n",
      "\n",
      "Epoch 51. Loss: 0.013607287126398412, Train_acc 0.9946875\n",
      "\n",
      "Epoch 51. Loss: 0.013997575984254176, Train_acc 0.9945913461538461\n",
      "\n",
      "Epoch 51. Loss: 0.01769969918953302, Train_acc 0.9945023148148148\n",
      "\n",
      "Epoch 51. Loss: 0.017110793537291193, Train_acc 0.9944196428571429\n",
      "\n",
      "Epoch 51. Loss: 0.0216418810156515, Train_acc 0.9938038793103449\n",
      "\n",
      "Epoch 51. Loss: 0.020350023188519247, Train_acc 0.9940104166666667\n",
      "\n",
      "Epoch 51. Loss: 0.018446313662170113, Train_acc 0.9942036290322581\n",
      "\n",
      "Epoch 51. Loss: 0.01673519053023792, Train_acc 0.994384765625\n",
      "\n",
      "Epoch 51. Loss: 0.018451594751731186, Train_acc 0.9943181818181818\n",
      "\n",
      "Epoch 51. Loss: 0.017421069093038703, Train_acc 0.9942555147058824\n",
      "\n",
      "Epoch 51. Loss: 0.015791730178604333, Train_acc 0.9944196428571429\n",
      "\n",
      "Epoch 51. Loss: 0.014417859469057449, Train_acc 0.9945746527777778\n",
      "\n",
      "Epoch 51. Loss: 0.01330071282762408, Train_acc 0.9947212837837838\n",
      "\n",
      "Epoch 51. Loss: 0.013779622397227166, Train_acc 0.9946546052631579\n",
      "\n",
      "Epoch 51. Loss: 0.013965350760283839, Train_acc 0.9943910256410257\n",
      "\n",
      "Epoch 51. Loss: 0.013273182723980639, Train_acc 0.99453125\n",
      "\n",
      "Epoch 51. Loss: 0.014521164712960864, Train_acc 0.9944740853658537\n",
      "\n",
      "Epoch 51. Loss: 0.01330729273329408, Train_acc 0.9946056547619048\n",
      "\n",
      "Epoch 51. Loss: 0.012081876485379617, Train_acc 0.9947311046511628\n",
      "\n",
      "Epoch 51. Loss: 0.011077469014822318, Train_acc 0.9948508522727273\n",
      "\n",
      "Epoch 51. Loss: 0.01259212848427791, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 51. Loss: 0.012686129851337363, Train_acc 0.994735054347826\n",
      "\n",
      "Epoch 51. Loss: 0.011886472101759395, Train_acc 0.9948470744680851\n",
      "\n",
      "Epoch 51. Loss: 0.01124708355583383, Train_acc 0.9949544270833334\n",
      "\n",
      "Epoch 51. Loss: 0.010874813060024083, Train_acc 0.9948979591836735\n",
      "\n",
      "Epoch 51. Loss: 0.011810203315370114, Train_acc 0.99484375\n",
      "\n",
      "Epoch 51. Loss: 0.011058781365575938, Train_acc 0.9949448529411765\n",
      "\n",
      "Epoch 51. Loss: 0.01000695706901294, Train_acc 0.9950420673076923\n",
      "\n",
      "Epoch 51. Loss: 0.009235518567612845, Train_acc 0.9951356132075472\n",
      "\n",
      "Epoch 51. Loss: 0.009321313255594144, Train_acc 0.9950810185185185\n",
      "\n",
      "Epoch 51. Loss: 0.009747796326338622, Train_acc 0.9950284090909091\n",
      "\n",
      "Epoch 51. Loss: 0.009978747783862985, Train_acc 0.9949776785714286\n",
      "\n",
      "Epoch 51. Loss: 0.011335123667505477, Train_acc 0.9949287280701754\n",
      "\n",
      "Epoch 51. Loss: 0.010724046990099932, Train_acc 0.9950161637931034\n",
      "\n",
      "Epoch 51. Loss: 0.010258325932762073, Train_acc 0.9951006355932204\n",
      "\n",
      "Epoch 51. Loss: 0.009330542398064775, Train_acc 0.9951822916666667\n",
      "\n",
      "Epoch 51. Loss: 0.009339113023194172, Train_acc 0.9952612704918032\n",
      "\n",
      "Epoch 51. Loss: 0.011943967106621711, Train_acc 0.995085685483871\n",
      "\n",
      "Epoch 51. Loss: 0.010929952421387657, Train_acc 0.9951636904761905\n",
      "\n",
      "Epoch 51. Loss: 0.010159270553157292, Train_acc 0.9952392578125\n",
      "\n",
      "Epoch 51. Loss: 0.009390563191688564, Train_acc 0.9953125\n",
      "\n",
      "Epoch 51. Loss: 0.012195703764304375, Train_acc 0.9951467803030303\n",
      "\n",
      "Epoch 51. Loss: 0.015910281505773834, Train_acc 0.9949860074626866\n",
      "\n",
      "Epoch 51. Loss: 0.01441862044476602, Train_acc 0.9950597426470589\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51. Loss: 0.013766011627702118, Train_acc 0.9951313405797102\n",
      "\n",
      "Epoch 51. Loss: 0.013666836536396922, Train_acc 0.9952008928571429\n",
      "\n",
      "Epoch 51. Loss: 0.013296436138274713, Train_acc 0.995268485915493\n",
      "\n",
      "Epoch 51. Loss: 0.017352700263848105, Train_acc 0.9950086805555556\n",
      "\n",
      "Epoch 51. Loss: 0.015758923189124644, Train_acc 0.9950770547945206\n",
      "\n",
      "Epoch 51. Loss: 0.015306546293599468, Train_acc 0.995143581081081\n",
      "\n",
      "Epoch 51. Loss: 0.013925054290133472, Train_acc 0.9952083333333334\n",
      "\n",
      "Epoch 51. Loss: 0.013401082599077603, Train_acc 0.9952713815789473\n",
      "\n",
      "Epoch 51. Loss: 0.014400680722815378, Train_acc 0.9951298701298701\n",
      "\n",
      "Epoch 51. Loss: 0.01822091999234788, Train_acc 0.9950921474358975\n",
      "\n",
      "Epoch 51. Loss: 0.016655007545638374, Train_acc 0.9951542721518988\n",
      "\n",
      "Epoch 51. Loss: 0.017395234818299077, Train_acc 0.9951171875\n",
      "\n",
      "Epoch 51. Loss: 0.016584548769926547, Train_acc 0.9951774691358025\n",
      "\n",
      "Epoch 51. Loss: 0.015191225341329443, Train_acc 0.9952362804878049\n",
      "\n",
      "Epoch 51. Loss: 0.013773045752769978, Train_acc 0.9952936746987951\n",
      "\n",
      "Epoch 51. Loss: 0.012803534410664086, Train_acc 0.9953497023809523\n",
      "\n",
      "Epoch 51. Loss: 0.011708774478247294, Train_acc 0.9954044117647058\n",
      "\n",
      "Epoch 51. Loss: 0.012219783830056067, Train_acc 0.9953670058139535\n",
      "\n",
      "Epoch 51. Loss: 0.014437638298341163, Train_acc 0.9953304597701149\n",
      "\n",
      "Epoch 51. Loss: 0.01321470748879182, Train_acc 0.9953835227272727\n",
      "\n",
      "Epoch 51. Loss: 0.013827048531153806, Train_acc 0.9953476123595506\n",
      "\n",
      "Epoch 51. Loss: 0.012865475918482848, Train_acc 0.9953993055555556\n",
      "\n",
      "Epoch 51. Loss: 0.01500293875244061, Train_acc 0.9952781593406593\n",
      "\n",
      "Epoch 51. Loss: 0.014500787145705222, Train_acc 0.9952445652173914\n",
      "\n",
      "Epoch 51. Loss: 0.013206491305342644, Train_acc 0.9952956989247311\n",
      "\n",
      "Epoch 51. Loss: 0.012009438855158983, Train_acc 0.995345744680851\n",
      "\n",
      "Epoch 51. Loss: 0.012020415629632204, Train_acc 0.9953125\n",
      "\n",
      "Epoch 51. Loss: 0.015373797996956345, Train_acc 0.9952799479166666\n",
      "\n",
      "Epoch 51. Loss: 0.015480508015261504, Train_acc 0.9952480670103093\n",
      "\n",
      "Epoch 51. Loss: 0.018073914220070614, Train_acc 0.9952168367346939\n",
      "\n",
      "Epoch 51. Loss: 0.016417038821922938, Train_acc 0.9952651515151515\n",
      "\n",
      "Epoch 51. Loss: 0.015823290579391004, Train_acc 0.995234375\n",
      "\n",
      "[Epoch 51 Batch 100] Loss: 0.014696647924890354 Training: accuracy=0.995282\n",
      "Epoch 51. Loss: 0.014696647924890354, Train_acc 0.9952815594059405\n",
      "\n",
      "Epoch 51. Loss: 0.01592107358817181, Train_acc 0.9951746323529411\n",
      "\n",
      "Epoch 51. Loss: 0.014600366200452337, Train_acc 0.9952214805825242\n",
      "\n",
      "Epoch 51. Loss: 0.013374780841756126, Train_acc 0.9952674278846154\n",
      "\n",
      "Epoch 51. Loss: 0.013712455349941487, Train_acc 0.9952380952380953\n",
      "\n",
      "Epoch 51. Loss: 0.012497826444048675, Train_acc 0.9952830188679245\n",
      "\n",
      "Epoch 51. Loss: 0.011736211661120348, Train_acc 0.9953271028037384\n",
      "\n",
      "Epoch 51. Loss: 0.010762748573231779, Train_acc 0.9953703703703703\n",
      "\n",
      "Epoch 51. Loss: 0.010607479285307003, Train_acc 0.9953411697247706\n",
      "\n",
      "Epoch 51. Loss: 0.012431943733490058, Train_acc 0.9952414772727273\n",
      "\n",
      "Epoch 51. Loss: 0.011241019187715544, Train_acc 0.9952843468468469\n",
      "\n",
      "Epoch 51. Loss: 0.011083860138070787, Train_acc 0.9953264508928571\n",
      "\n",
      "Epoch 51. Loss: 0.010999298264693206, Train_acc 0.9952986725663717\n",
      "\n",
      "Epoch 51. Loss: 0.013786057683924723, Train_acc 0.995202850877193\n",
      "\n",
      "Epoch 51. Loss: 0.014489102038532396, Train_acc 0.9951086956521739\n",
      "\n",
      "Epoch 51. Loss: 0.014078230472168237, Train_acc 0.9950835129310345\n",
      "\n",
      "Epoch 51. Loss: 0.016074839587593894, Train_acc 0.9950587606837606\n",
      "\n",
      "Epoch 51. Loss: 0.014675550555215616, Train_acc 0.9951006355932204\n",
      "\n",
      "Epoch 51. Loss: 0.013663237941661183, Train_acc 0.995141806722689\n",
      "\n",
      "Epoch 51. Loss: 0.013450063323884045, Train_acc 0.9951171875\n",
      "\n",
      "Epoch 51. Loss: 0.01337934050119713, Train_acc 0.9950929752066116\n",
      "\n",
      "Epoch 51. Loss: 0.014219106851429896, Train_acc 0.9950691598360656\n",
      "\n",
      "Epoch 51. Loss: 0.013488615261087855, Train_acc 0.9951092479674797\n",
      "\n",
      "Epoch 51. Loss: 0.013832381105336584, Train_acc 0.995085685483871\n",
      "\n",
      "Epoch 51. Loss: 0.012554353714433048, Train_acc 0.995125\n",
      "\n",
      "Epoch 51. Loss: 0.011464087423709095, Train_acc 0.9951636904761905\n",
      "\n",
      "Epoch 51. Loss: 0.019925746253455036, Train_acc 0.9950172244094488\n",
      "\n",
      "Epoch 51. Loss: 0.021938845155827124, Train_acc 0.99493408203125\n",
      "\n",
      "Epoch 51. Loss: 0.01993880004404508, Train_acc 0.9949733527131783\n",
      "\n",
      "Epoch 51. Loss: 0.019717568321989683, Train_acc 0.994951923076923\n",
      "\n",
      "Epoch 51. Loss: 0.017819812722651325, Train_acc 0.9949904580152672\n",
      "\n",
      "Epoch 51. Loss: 0.016216888704376514, Train_acc 0.9950284090909091\n",
      "\n",
      "Epoch 51. Loss: 0.014890025291906682, Train_acc 0.9950657894736842\n",
      "\n",
      "Epoch 51. Loss: 0.013468527147503767, Train_acc 0.9951026119402985\n",
      "\n",
      "Epoch 51. Loss: 0.012418717532752819, Train_acc 0.9951388888888889\n",
      "\n",
      "Epoch 51. Loss: 0.011231036750900479, Train_acc 0.9951746323529411\n",
      "\n",
      "Epoch 51. Loss: 0.010947590132887123, Train_acc 0.9952098540145985\n",
      "\n",
      "Epoch 51. Loss: 0.01512534996301081, Train_acc 0.9951313405797102\n",
      "\n",
      "Epoch 51. Loss: 0.015354716006786938, Train_acc 0.9951101618705036\n",
      "\n",
      "Epoch 51. Loss: 0.015415977402512415, Train_acc 0.9950892857142857\n",
      "\n",
      "Epoch 51. Loss: 0.014083277970016763, Train_acc 0.9951241134751773\n",
      "\n",
      "Epoch 51. Loss: 0.01882358688663909, Train_acc 0.994993397887324\n",
      "\n",
      "Epoch 51. Loss: 0.01749631647588136, Train_acc 0.9950284090909091\n",
      "\n",
      "Epoch 51. Loss: 0.016343694542986058, Train_acc 0.9950629340277778\n",
      "\n",
      "Epoch 51. Loss: 0.018190450547762426, Train_acc 0.994989224137931\n",
      "\n",
      "Epoch 51. Loss: 0.018552137720848065, Train_acc 0.9949165239726028\n",
      "\n",
      "Epoch 51. Loss: 0.01716144562320257, Train_acc 0.9949511054421769\n",
      "\n",
      "Epoch 51. Loss: 0.01898951729139398, Train_acc 0.9948796452702703\n",
      "\n",
      "Epoch 51. Loss: 0.017622224371886645, Train_acc 0.9949140100671141\n",
      "\n",
      "Epoch 51. Loss: 0.017011922324082013, Train_acc 0.9948958333333333\n",
      "\n",
      "Epoch 51. Loss: 0.028264194778544388, Train_acc 0.9947744205298014\n",
      "\n",
      "Epoch 51. Loss: 0.02722870116109492, Train_acc 0.9947574013157895\n",
      "\n",
      "Epoch 51. Loss: 0.026137414690925256, Train_acc 0.9947406045751634\n",
      "\n",
      "Epoch 51. Loss: 0.023685314336224117, Train_acc 0.9947747564935064\n",
      "\n",
      "Epoch 51. Loss: 0.023096703137877928, Train_acc 0.994758064516129\n",
      "\n",
      "Epoch 51. Loss: 0.021346147395750893, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 51. Loss: 0.020915906984431458, Train_acc 0.9947750796178344\n",
      "\n",
      "Epoch 51. Loss: 0.021218494236906988, Train_acc 0.9947587025316456\n",
      "\n",
      "Epoch 51. Loss: 0.02001231446305569, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 51. Loss: 0.02066530224924972, Train_acc 0.994775390625\n",
      "\n",
      "Epoch 51. Loss: 0.018925169224439774, Train_acc 0.9948078416149069\n",
      "\n",
      "Epoch 51. Loss: 0.017266569310149894, Train_acc 0.9948398919753086\n",
      "\n",
      "Epoch 51. Loss: 0.015887935960453462, Train_acc 0.9948715490797546\n",
      "\n",
      "Epoch 51. Loss: 0.018557283658529856, Train_acc 0.9948075457317073\n",
      "\n",
      "Epoch 51. Loss: 0.01710953111163873, Train_acc 0.9948390151515152\n",
      "\n",
      "Epoch 51. Loss: 0.015691890734467792, Train_acc 0.9948701054216867\n",
      "\n",
      "Epoch 51. Loss: 0.01587939340743472, Train_acc 0.9948540419161677\n",
      "\n",
      "Epoch 51. Loss: 0.014823964570817798, Train_acc 0.9948846726190477\n",
      "\n",
      "Epoch 51. Loss: 0.016035764181486473, Train_acc 0.9948687130177515\n",
      "\n",
      "Epoch 51. Loss: 0.019787935179953312, Train_acc 0.9948529411764706\n",
      "\n",
      "Epoch 51. Loss: 0.01794401582049686, Train_acc 0.9948830409356725\n",
      "\n",
      "Epoch 51. Loss: 0.016589610603904948, Train_acc 0.9949127906976745\n",
      "\n",
      "Epoch 51. Loss: 0.01580029239352604, Train_acc 0.994942196531792\n",
      "\n",
      "Epoch 51. Loss: 0.016375296653175893, Train_acc 0.9948814655172413\n",
      "\n",
      "Epoch 51. Loss: 0.015171872039539703, Train_acc 0.9949107142857143\n",
      "\n",
      "Epoch 51. Loss: 0.013820349100518008, Train_acc 0.9949396306818182\n",
      "\n",
      "Epoch 51. Loss: 0.01286529788408081, Train_acc 0.994968220338983\n",
      "\n",
      "Epoch 51. Loss: 0.01380827238291562, Train_acc 0.9949525983146067\n",
      "\n",
      "Epoch 51. Loss: 0.0193666074585622, Train_acc 0.9948935055865922\n",
      "\n",
      "Epoch 51. Loss: 0.017911570915508757, Train_acc 0.994921875\n",
      "\n",
      "Epoch 51. Loss: 0.017481220926131448, Train_acc 0.9949067679558011\n",
      "\n",
      "Epoch 51. Loss: 0.015905341274267265, Train_acc 0.9949347527472527\n",
      "\n",
      "Epoch 51. Loss: 0.01672311177110001, Train_acc 0.9949197404371585\n",
      "\n",
      "Epoch 51. Loss: 0.015188729315950642, Train_acc 0.9949473505434783\n",
      "\n",
      "Epoch 51. Loss: 0.0140513117219843, Train_acc 0.9949746621621621\n",
      "\n",
      "Epoch 51. Loss: 0.016341576883718748, Train_acc 0.9949176747311828\n",
      "\n",
      "Epoch 51. Loss: 0.019714113989048047, Train_acc 0.9948612967914439\n",
      "\n",
      "Epoch 51. Loss: 0.01814969339578406, Train_acc 0.994888630319149\n",
      "\n",
      "Epoch 51. Loss: 0.017116678415468836, Train_acc 0.9949156746031746\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51. Loss: 0.016621766381321703, Train_acc 0.9949013157894737\n",
      "\n",
      "Epoch 51. Loss: 0.015185139167256672, Train_acc 0.9949280104712042\n",
      "\n",
      "Epoch 51. Loss: 0.015156509377462435, Train_acc 0.9949137369791666\n",
      "\n",
      "Epoch 51. Loss: 0.013835229419159384, Train_acc 0.9949400906735751\n",
      "\n",
      "Epoch 51. Loss: 0.01370897369905188, Train_acc 0.9949259020618557\n",
      "\n",
      "Epoch 51. Loss: 0.012548247638446459, Train_acc 0.994951923076923\n",
      "\n",
      "Epoch 51. Loss: 0.013923842903765174, Train_acc 0.99492\n",
      "\n",
      "Epoch 52. Loss: 0.01316944903593552, Train_acc 1.0\n",
      "\n",
      "Epoch 52. Loss: 0.011971926706403868, Train_acc 1.0\n",
      "\n",
      "Epoch 52. Loss: 0.011580251694354752, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 52. Loss: 0.010498274624355144, Train_acc 0.998046875\n",
      "\n",
      "Epoch 52. Loss: 0.011530782738334692, Train_acc 0.9953125\n",
      "\n",
      "Epoch 52. Loss: 0.010582769611521147, Train_acc 0.99609375\n",
      "\n",
      "Epoch 52. Loss: 0.012530072136858328, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 52. Loss: 0.012599214967315695, Train_acc 0.9951171875\n",
      "\n",
      "Epoch 52. Loss: 0.012470664413623782, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 52. Loss: 0.011488978758993242, Train_acc 0.9953125\n",
      "\n",
      "Epoch 52. Loss: 0.01054956787984892, Train_acc 0.9957386363636364\n",
      "\n",
      "Epoch 52. Loss: 0.010759180068921962, Train_acc 0.9954427083333334\n",
      "\n",
      "Epoch 52. Loss: 0.010425022075654792, Train_acc 0.9957932692307693\n",
      "\n",
      "Epoch 52. Loss: 0.009514986709112728, Train_acc 0.99609375\n",
      "\n",
      "Epoch 52. Loss: 0.00926767454104555, Train_acc 0.9958333333333333\n",
      "\n",
      "Epoch 52. Loss: 0.008960509802537552, Train_acc 0.99609375\n",
      "\n",
      "Epoch 52. Loss: 0.008088911939213886, Train_acc 0.9963235294117647\n",
      "\n",
      "Epoch 52. Loss: 0.007510874447234167, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 52. Loss: 0.007099357574179197, Train_acc 0.9967105263157895\n",
      "\n",
      "Epoch 52. Loss: 0.006480179882687189, Train_acc 0.996875\n",
      "\n",
      "Epoch 52. Loss: 0.006068549957476728, Train_acc 0.9970238095238095\n",
      "\n",
      "Epoch 52. Loss: 0.005728268213885432, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 52. Loss: 0.009063313011363809, Train_acc 0.9962635869565217\n",
      "\n",
      "Epoch 52. Loss: 0.008257053147418645, Train_acc 0.9964192708333334\n",
      "\n",
      "Epoch 52. Loss: 0.00775296879153402, Train_acc 0.9965625\n",
      "\n",
      "Epoch 52. Loss: 0.007206614237719339, Train_acc 0.9966947115384616\n",
      "\n",
      "Epoch 52. Loss: 0.007933849100792614, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 52. Loss: 0.01006945617901463, Train_acc 0.9963727678571429\n",
      "\n",
      "Epoch 52. Loss: 0.00917504378120314, Train_acc 0.9964978448275862\n",
      "\n",
      "Epoch 52. Loss: 0.008356074181308992, Train_acc 0.9966145833333333\n",
      "\n",
      "Epoch 52. Loss: 0.008070600125590546, Train_acc 0.9967237903225806\n",
      "\n",
      "Epoch 52. Loss: 0.010875220978319272, Train_acc 0.996337890625\n",
      "\n",
      "Epoch 52. Loss: 0.01014713402716186, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 52. Loss: 0.010612855831931826, Train_acc 0.9963235294117647\n",
      "\n",
      "Epoch 52. Loss: 0.010751671121404289, Train_acc 0.9962053571428572\n",
      "\n",
      "Epoch 52. Loss: 0.012050605066912518, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 52. Loss: 0.011079596051355134, Train_acc 0.995777027027027\n",
      "\n",
      "Epoch 52. Loss: 0.01075032083879107, Train_acc 0.9958881578947368\n",
      "\n",
      "Epoch 52. Loss: 0.009815765028284733, Train_acc 0.9959935897435898\n",
      "\n",
      "Epoch 52. Loss: 0.010549344030100178, Train_acc 0.9958984375\n",
      "\n",
      "Epoch 52. Loss: 0.01313912487662858, Train_acc 0.9956173780487805\n",
      "\n",
      "Epoch 52. Loss: 0.017166629358861086, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 52. Loss: 0.015556015344563785, Train_acc 0.9956395348837209\n",
      "\n",
      "Epoch 52. Loss: 0.014204065698403415, Train_acc 0.9957386363636364\n",
      "\n",
      "Epoch 52. Loss: 0.012816943834859474, Train_acc 0.9958333333333333\n",
      "\n",
      "Epoch 52. Loss: 0.013089650111471125, Train_acc 0.9957540760869565\n",
      "\n",
      "Epoch 52. Loss: 0.01182288046818369, Train_acc 0.995844414893617\n",
      "\n",
      "Epoch 52. Loss: 0.012104631601793111, Train_acc 0.9957682291666666\n",
      "\n",
      "Epoch 52. Loss: 0.011669501004239208, Train_acc 0.9958545918367347\n",
      "\n",
      "Epoch 52. Loss: 0.010779954645890254, Train_acc 0.9959375\n",
      "\n",
      "Epoch 52. Loss: 0.011618455264441602, Train_acc 0.9958639705882353\n",
      "\n",
      "Epoch 52. Loss: 0.011723544088130384, Train_acc 0.9957932692307693\n",
      "\n",
      "Epoch 52. Loss: 0.013623001474552027, Train_acc 0.9955778301886793\n",
      "\n",
      "Epoch 52. Loss: 0.012866005493771438, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 52. Loss: 0.013331233696852391, Train_acc 0.9955965909090909\n",
      "\n",
      "Epoch 52. Loss: 0.020613139930410026, Train_acc 0.9951171875\n",
      "\n",
      "Epoch 52. Loss: 0.01890862162273482, Train_acc 0.995202850877193\n",
      "\n",
      "Epoch 52. Loss: 0.01726869894980361, Train_acc 0.9952855603448276\n",
      "\n",
      "Epoch 52. Loss: 0.015570854648362949, Train_acc 0.995365466101695\n",
      "\n",
      "Epoch 52. Loss: 0.01405300801548632, Train_acc 0.9954427083333334\n",
      "\n",
      "Epoch 52. Loss: 0.013648678095369984, Train_acc 0.9953893442622951\n",
      "\n",
      "Epoch 52. Loss: 0.012357883288739501, Train_acc 0.9954637096774194\n",
      "\n",
      "Epoch 52. Loss: 0.01420654890025709, Train_acc 0.9954117063492064\n",
      "\n",
      "Epoch 52. Loss: 0.013406306929901727, Train_acc 0.9954833984375\n",
      "\n",
      "Epoch 52. Loss: 0.013309098231061238, Train_acc 0.9954326923076923\n",
      "\n",
      "Epoch 52. Loss: 0.017701547098693794, Train_acc 0.9951467803030303\n",
      "\n",
      "Epoch 52. Loss: 0.016123670500177933, Train_acc 0.9952192164179104\n",
      "\n",
      "Epoch 52. Loss: 0.014821272003643625, Train_acc 0.9952895220588235\n",
      "\n",
      "Epoch 52. Loss: 0.01378673596463464, Train_acc 0.9953577898550725\n",
      "\n",
      "Epoch 52. Loss: 0.012637159805284699, Train_acc 0.9954241071428571\n",
      "\n",
      "Epoch 52. Loss: 0.01148820427950033, Train_acc 0.9954885563380281\n",
      "\n",
      "Epoch 52. Loss: 0.010669961060210838, Train_acc 0.9955512152777778\n",
      "\n",
      "Epoch 52. Loss: 0.011877621436230638, Train_acc 0.9955051369863014\n",
      "\n",
      "Epoch 52. Loss: 0.012539811818998128, Train_acc 0.9954603040540541\n",
      "\n",
      "Epoch 52. Loss: 0.011729122301221851, Train_acc 0.9955208333333333\n",
      "\n",
      "Epoch 52. Loss: 0.010905603790906934, Train_acc 0.9955797697368421\n",
      "\n",
      "Epoch 52. Loss: 0.012615194745029092, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 52. Loss: 0.011383102063279112, Train_acc 0.9955929487179487\n",
      "\n",
      "Epoch 52. Loss: 0.011013584206796372, Train_acc 0.9955498417721519\n",
      "\n",
      "Epoch 52. Loss: 0.01057851993989648, Train_acc 0.99560546875\n",
      "\n",
      "Epoch 52. Loss: 0.010857312535807802, Train_acc 0.9955632716049383\n",
      "\n",
      "Epoch 52. Loss: 0.010223257829754336, Train_acc 0.9956173780487805\n",
      "\n",
      "Epoch 52. Loss: 0.010362502521284327, Train_acc 0.9955760542168675\n",
      "\n",
      "Epoch 52. Loss: 0.009638578768416858, Train_acc 0.9956287202380952\n",
      "\n",
      "Epoch 52. Loss: 0.008898771165693953, Train_acc 0.9956801470588236\n",
      "\n",
      "Epoch 52. Loss: 0.008196864421041448, Train_acc 0.9957303779069767\n",
      "\n",
      "Epoch 52. Loss: 0.007873867814500606, Train_acc 0.9957794540229885\n",
      "\n",
      "Epoch 52. Loss: 0.007164191130007707, Train_acc 0.9958274147727273\n",
      "\n",
      "Epoch 52. Loss: 0.006836902803068224, Train_acc 0.995874297752809\n",
      "\n",
      "Epoch 52. Loss: 0.006239007861725492, Train_acc 0.9959201388888889\n",
      "\n",
      "Epoch 52. Loss: 0.006295281009058955, Train_acc 0.9959649725274725\n",
      "\n",
      "Epoch 52. Loss: 0.007389562634689333, Train_acc 0.9959239130434783\n",
      "\n",
      "Epoch 52. Loss: 0.007249139031153371, Train_acc 0.9959677419354839\n",
      "\n",
      "Epoch 52. Loss: 0.006718163531428382, Train_acc 0.9960106382978723\n",
      "\n",
      "Epoch 52. Loss: 0.0063382059547580525, Train_acc 0.9960526315789474\n",
      "\n",
      "Epoch 52. Loss: 0.0057872989126244705, Train_acc 0.99609375\n",
      "\n",
      "Epoch 52. Loss: 0.005914844946402269, Train_acc 0.9960534793814433\n",
      "\n",
      "Epoch 52. Loss: 0.005437348665468803, Train_acc 0.99609375\n",
      "\n",
      "Epoch 52. Loss: 0.005101635429454963, Train_acc 0.9961332070707071\n",
      "\n",
      "Epoch 52. Loss: 0.007654206266873885, Train_acc 0.99609375\n",
      "\n",
      "[Epoch 52 Batch 100] Loss: 0.007023265290482767 Training: accuracy=0.996132\n",
      "Epoch 52. Loss: 0.007023265290482767, Train_acc 0.9961324257425742\n",
      "\n",
      "Epoch 52. Loss: 0.0064031170472455875, Train_acc 0.9961703431372549\n",
      "\n",
      "Epoch 52. Loss: 0.0058238007196555605, Train_acc 0.9962075242718447\n",
      "\n",
      "Epoch 52. Loss: 0.0052778785271588025, Train_acc 0.9962439903846154\n",
      "\n",
      "Epoch 52. Loss: 0.012117481068653738, Train_acc 0.9959821428571428\n",
      "\n",
      "Epoch 52. Loss: 0.011239742233834752, Train_acc 0.9960200471698113\n",
      "\n",
      "Epoch 52. Loss: 0.010313777830174944, Train_acc 0.9960572429906542\n",
      "\n",
      "Epoch 52. Loss: 0.009329714839912509, Train_acc 0.99609375\n",
      "\n",
      "Epoch 52. Loss: 0.009792944068691481, Train_acc 0.9960579128440367\n",
      "\n",
      "Epoch 52. Loss: 0.009162490432133987, Train_acc 0.99609375\n",
      "\n",
      "Epoch 52. Loss: 0.008455092688169224, Train_acc 0.9961289414414415\n",
      "\n",
      "Epoch 52. Loss: 0.008318152027740607, Train_acc 0.9961635044642857\n",
      "\n",
      "Epoch 52. Loss: 0.015018939373565791, Train_acc 0.9959900442477876\n",
      "\n",
      "Epoch 52. Loss: 0.01376894104458965, Train_acc 0.9960252192982456\n",
      "\n",
      "Epoch 52. Loss: 0.012506632364438419, Train_acc 0.9960597826086957\n",
      "\n",
      "Epoch 52. Loss: 0.011305325860046397, Train_acc 0.99609375\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52. Loss: 0.012820643269356833, Train_acc 0.9960603632478633\n",
      "\n",
      "Epoch 52. Loss: 0.021933678910139275, Train_acc 0.995895127118644\n",
      "\n",
      "Epoch 52. Loss: 0.02054728657007492, Train_acc 0.9958639705882353\n",
      "\n",
      "Epoch 52. Loss: 0.019225526101889698, Train_acc 0.9958333333333333\n",
      "\n",
      "Epoch 52. Loss: 0.019141258222611982, Train_acc 0.9958032024793388\n",
      "\n",
      "Epoch 52. Loss: 0.01858025283165476, Train_acc 0.9957735655737705\n",
      "\n",
      "Epoch 52. Loss: 0.017898603909889173, Train_acc 0.9957444105691057\n",
      "\n",
      "Epoch 52. Loss: 0.02645640191466747, Train_acc 0.9955267137096774\n",
      "\n",
      "Epoch 52. Loss: 0.02842796624032681, Train_acc 0.9954375\n",
      "\n",
      "Epoch 52. Loss: 0.02620335150617085, Train_acc 0.9954737103174603\n",
      "\n",
      "Epoch 52. Loss: 0.023742423005899536, Train_acc 0.9955093503937008\n",
      "\n",
      "Epoch 52. Loss: 0.028233496589661313, Train_acc 0.99530029296875\n",
      "\n",
      "Epoch 52. Loss: 0.03154520160842002, Train_acc 0.9952156007751938\n",
      "\n",
      "Epoch 52. Loss: 0.030272068532300536, Train_acc 0.9951923076923077\n",
      "\n",
      "Epoch 52. Loss: 0.027849742466502677, Train_acc 0.9952290076335878\n",
      "\n",
      "Epoch 52. Loss: 0.025119528083849287, Train_acc 0.9952651515151515\n",
      "\n",
      "Epoch 52. Loss: 0.022891807707487048, Train_acc 0.9953007518796992\n",
      "\n",
      "Epoch 52. Loss: 0.02506467870086894, Train_acc 0.9951609141791045\n",
      "\n",
      "Epoch 52. Loss: 0.026567977334950556, Train_acc 0.9951388888888889\n",
      "\n",
      "Epoch 52. Loss: 0.02405214784597831, Train_acc 0.9951746323529411\n",
      "\n",
      "Epoch 52. Loss: 0.023300071982045267, Train_acc 0.995095802919708\n",
      "\n",
      "Epoch 52. Loss: 0.02224441320672568, Train_acc 0.9951313405797102\n",
      "\n",
      "Epoch 52. Loss: 0.020282740475944604, Train_acc 0.9951663669064749\n",
      "\n",
      "Epoch 52. Loss: 0.020825780815373594, Train_acc 0.9950892857142857\n",
      "\n",
      "Epoch 52. Loss: 0.019009063500939966, Train_acc 0.9951241134751773\n",
      "\n",
      "Epoch 52. Loss: 0.024513520174127067, Train_acc 0.9949383802816901\n",
      "\n",
      "Epoch 52. Loss: 0.02241513601316623, Train_acc 0.9949737762237763\n",
      "\n",
      "Epoch 52. Loss: 0.023049143445851912, Train_acc 0.9949544270833334\n",
      "\n",
      "Epoch 52. Loss: 0.024692777909960606, Train_acc 0.9949353448275862\n",
      "\n",
      "Epoch 52. Loss: 0.025015752905422087, Train_acc 0.9948630136986302\n",
      "\n",
      "Epoch 52. Loss: 0.024233002902996813, Train_acc 0.99484481292517\n",
      "\n",
      "Epoch 52. Loss: 0.022106375465407023, Train_acc 0.9948796452702703\n",
      "\n",
      "Epoch 52. Loss: 0.020918031058115405, Train_acc 0.9949140100671141\n",
      "\n",
      "Epoch 52. Loss: 0.02017274530655382, Train_acc 0.99484375\n",
      "\n",
      "Epoch 52. Loss: 0.023104454862411958, Train_acc 0.9948261589403974\n",
      "\n",
      "Epoch 52. Loss: 0.022344429563584456, Train_acc 0.9948087993421053\n",
      "\n",
      "Epoch 52. Loss: 0.02131087575131881, Train_acc 0.9948427287581699\n",
      "\n",
      "Epoch 52. Loss: 0.019789503040008795, Train_acc 0.9948762175324676\n",
      "\n",
      "Epoch 52. Loss: 0.019942691345894083, Train_acc 0.994858870967742\n",
      "\n",
      "Epoch 52. Loss: 0.018040007437195995, Train_acc 0.9948918269230769\n",
      "\n",
      "Epoch 52. Loss: 0.019633708746665673, Train_acc 0.9948248407643312\n",
      "\n",
      "Epoch 52. Loss: 0.018075931367815098, Train_acc 0.9948575949367089\n",
      "\n",
      "Epoch 52. Loss: 0.016818055897614863, Train_acc 0.9948899371069182\n",
      "\n",
      "Epoch 52. Loss: 0.015480143776233352, Train_acc 0.994921875\n",
      "\n",
      "Epoch 52. Loss: 0.014832448896642347, Train_acc 0.9949534161490683\n",
      "\n",
      "Epoch 52. Loss: 0.013651903471351402, Train_acc 0.9949845679012346\n",
      "\n",
      "Epoch 52. Loss: 0.012633730714172784, Train_acc 0.9950153374233128\n",
      "\n",
      "Epoch 52. Loss: 0.011998796281278727, Train_acc 0.995045731707317\n",
      "\n",
      "Epoch 52. Loss: 0.014489864245409309, Train_acc 0.9950284090909091\n",
      "\n",
      "Epoch 52. Loss: 0.016176922934074286, Train_acc 0.9950112951807228\n",
      "\n",
      "Epoch 52. Loss: 0.01480223053521134, Train_acc 0.9950411676646707\n",
      "\n",
      "Epoch 52. Loss: 0.0148067836768289, Train_acc 0.9950241815476191\n",
      "\n",
      "Epoch 52. Loss: 0.013620909742506706, Train_acc 0.995053624260355\n",
      "\n",
      "Epoch 52. Loss: 0.012397881573357313, Train_acc 0.9950827205882353\n",
      "\n",
      "Epoch 52. Loss: 0.011611874566303011, Train_acc 0.9951114766081871\n",
      "\n",
      "Epoch 52. Loss: 0.010842345412069247, Train_acc 0.995139898255814\n",
      "\n",
      "Epoch 52. Loss: 0.01354702055945428, Train_acc 0.9950776734104047\n",
      "\n",
      "Epoch 52. Loss: 0.013364950482497499, Train_acc 0.9950610632183908\n",
      "\n",
      "Epoch 52. Loss: 0.012350538818046349, Train_acc 0.9950892857142857\n",
      "\n",
      "Epoch 52. Loss: 0.011253867922429649, Train_acc 0.9951171875\n",
      "\n",
      "Epoch 52. Loss: 0.010257396593760916, Train_acc 0.9951447740112994\n",
      "\n",
      "Epoch 52. Loss: 0.009473639917810084, Train_acc 0.9951720505617978\n",
      "\n",
      "Epoch 52. Loss: 0.008591869551215088, Train_acc 0.9951990223463687\n",
      "\n",
      "Epoch 52. Loss: 0.008071824689528509, Train_acc 0.9952256944444444\n",
      "\n",
      "Epoch 52. Loss: 0.00788174591830775, Train_acc 0.9952520718232044\n",
      "\n",
      "Epoch 52. Loss: 0.007219630714753165, Train_acc 0.9952781593406593\n",
      "\n",
      "Epoch 52. Loss: 0.006729213248043264, Train_acc 0.9953039617486339\n",
      "\n",
      "Epoch 52. Loss: 0.006167376040327404, Train_acc 0.9953294836956522\n",
      "\n",
      "Epoch 52. Loss: 0.007899613714731801, Train_acc 0.9953125\n",
      "\n",
      "Epoch 52. Loss: 0.007702671992645027, Train_acc 0.9953377016129032\n",
      "\n",
      "Epoch 52. Loss: 0.007506701273425248, Train_acc 0.9953626336898396\n",
      "\n",
      "Epoch 52. Loss: 0.006872466502986545, Train_acc 0.9953873005319149\n",
      "\n",
      "Epoch 52. Loss: 0.00649555478847223, Train_acc 0.9954117063492064\n",
      "\n",
      "Epoch 52. Loss: 0.008868996763433792, Train_acc 0.9953536184210526\n",
      "\n",
      "Epoch 52. Loss: 0.008846200989221733, Train_acc 0.9953370418848168\n",
      "\n",
      "Epoch 52. Loss: 0.008512664201738119, Train_acc 0.995361328125\n",
      "\n",
      "Epoch 52. Loss: 0.007909764119765175, Train_acc 0.9953853626943006\n",
      "\n",
      "Epoch 52. Loss: 0.007303899908931714, Train_acc 0.9954091494845361\n",
      "\n",
      "Epoch 52. Loss: 0.016343441353623565, Train_acc 0.9953125\n",
      "\n",
      "Epoch 52. Loss: 0.015876811814055886, Train_acc 0.99532\n",
      "\n",
      "Epoch 53. Loss: 0.015179127910059136, Train_acc 0.9921875\n",
      "\n",
      "Epoch 53. Loss: 0.019398473240424492, Train_acc 0.9921875\n",
      "\n",
      "Epoch 53. Loss: 0.017690527193238707, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 53. Loss: 0.016313609334072804, Train_acc 0.99609375\n",
      "\n",
      "Epoch 53. Loss: 0.01590734951025963, Train_acc 0.9953125\n",
      "\n",
      "Epoch 53. Loss: 0.01757080017620373, Train_acc 0.9921875\n",
      "\n",
      "Epoch 53. Loss: 0.016125263625106648, Train_acc 0.9933035714285714\n",
      "\n",
      "Epoch 53. Loss: 0.015662242080618234, Train_acc 0.9931640625\n",
      "\n",
      "Epoch 53. Loss: 0.014320743891052269, Train_acc 0.9939236111111112\n",
      "\n",
      "Epoch 53. Loss: 0.01293513015839624, Train_acc 0.99453125\n",
      "\n",
      "Epoch 53. Loss: 0.011954501108227678, Train_acc 0.9950284090909091\n",
      "\n",
      "Epoch 53. Loss: 0.011584090946673013, Train_acc 0.9954427083333334\n",
      "\n",
      "Epoch 53. Loss: 0.013419894919000856, Train_acc 0.9951923076923077\n",
      "\n",
      "Epoch 53. Loss: 0.014482514749648684, Train_acc 0.9949776785714286\n",
      "\n",
      "Epoch 53. Loss: 0.013181085580080014, Train_acc 0.9953125\n",
      "\n",
      "Epoch 53. Loss: 0.014280774058540996, Train_acc 0.9951171875\n",
      "\n",
      "Epoch 53. Loss: 0.013189569904631677, Train_acc 0.9954044117647058\n",
      "\n",
      "Epoch 53. Loss: 0.012137497414329323, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 53. Loss: 0.010959731413132069, Train_acc 0.9958881578947368\n",
      "\n",
      "Epoch 53. Loss: 0.012898656165486085, Train_acc 0.9953125\n",
      "\n",
      "Epoch 53. Loss: 0.012269634509878315, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 53. Loss: 0.012391747966972254, Train_acc 0.9953835227272727\n",
      "\n",
      "Epoch 53. Loss: 0.011436170812830862, Train_acc 0.9955842391304348\n",
      "\n",
      "Epoch 53. Loss: 0.01032461832960147, Train_acc 0.9957682291666666\n",
      "\n",
      "Epoch 53. Loss: 0.009359177501729786, Train_acc 0.9959375\n",
      "\n",
      "Epoch 53. Loss: 0.009318940052448207, Train_acc 0.9957932692307693\n",
      "\n",
      "Epoch 53. Loss: 0.010574068986527765, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 53. Loss: 0.009706681043493133, Train_acc 0.9958147321428571\n",
      "\n",
      "Epoch 53. Loss: 0.00895205993928377, Train_acc 0.9959590517241379\n",
      "\n",
      "Epoch 53. Loss: 0.008248659212596246, Train_acc 0.99609375\n",
      "\n",
      "Epoch 53. Loss: 0.008282196009195174, Train_acc 0.9959677419354839\n",
      "\n",
      "Epoch 53. Loss: 0.008499452308448844, Train_acc 0.99609375\n",
      "\n",
      "Epoch 53. Loss: 0.00912361506578269, Train_acc 0.9959753787878788\n",
      "\n",
      "Epoch 53. Loss: 0.008493449654417715, Train_acc 0.99609375\n",
      "\n",
      "Epoch 53. Loss: 0.007978784606408312, Train_acc 0.9962053571428572\n",
      "\n",
      "Epoch 53. Loss: 0.0076991028738479916, Train_acc 0.9963107638888888\n",
      "\n",
      "Epoch 53. Loss: 0.0072316993369127315, Train_acc 0.996410472972973\n",
      "\n",
      "Epoch 53. Loss: 0.006736024336863906, Train_acc 0.9965049342105263\n",
      "\n",
      "Epoch 53. Loss: 0.006298269473179595, Train_acc 0.9965945512820513\n",
      "\n",
      "Epoch 53. Loss: 0.005773458936678097, Train_acc 0.9966796875\n",
      "\n",
      "Epoch 53. Loss: 0.00529722945905482, Train_acc 0.9967606707317073\n",
      "\n",
      "Epoch 53. Loss: 0.0050130330392726226, Train_acc 0.9968377976190477\n",
      "\n",
      "Epoch 53. Loss: 0.004717024709493633, Train_acc 0.9969113372093024\n",
      "\n",
      "Epoch 53. Loss: 0.004502725385951147, Train_acc 0.9969815340909091\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53. Loss: 0.004450181836256813, Train_acc 0.9970486111111111\n",
      "\n",
      "Epoch 53. Loss: 0.004057108390419422, Train_acc 0.9971127717391305\n",
      "\n",
      "Epoch 53. Loss: 0.005219150210698312, Train_acc 0.996841755319149\n",
      "\n",
      "Epoch 53. Loss: 0.004721065202279641, Train_acc 0.9969075520833334\n",
      "\n",
      "Epoch 53. Loss: 0.004360804702496905, Train_acc 0.9969706632653061\n",
      "\n",
      "Epoch 53. Loss: 0.008965572859933716, Train_acc 0.996875\n",
      "\n",
      "Epoch 53. Loss: 0.008128886291754537, Train_acc 0.9969362745098039\n",
      "\n",
      "Epoch 53. Loss: 0.008337318035398984, Train_acc 0.9969951923076923\n",
      "\n",
      "Epoch 53. Loss: 0.007572170688898918, Train_acc 0.9970518867924528\n",
      "\n",
      "Epoch 53. Loss: 0.006849933315928928, Train_acc 0.9971064814814815\n",
      "\n",
      "Epoch 53. Loss: 0.008019227444782392, Train_acc 0.9970170454545455\n",
      "\n",
      "Epoch 53. Loss: 0.00770937452397156, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 53. Loss: 0.007008127939832881, Train_acc 0.9971217105263158\n",
      "\n",
      "Epoch 53. Loss: 0.006433376408412464, Train_acc 0.9971713362068966\n",
      "\n",
      "Epoch 53. Loss: 0.006550663977230555, Train_acc 0.9970868644067796\n",
      "\n",
      "Epoch 53. Loss: 0.0169375800514504, Train_acc 0.9966145833333333\n",
      "\n",
      "Epoch 53. Loss: 0.015459690605040016, Train_acc 0.9966700819672131\n",
      "\n",
      "Epoch 53. Loss: 0.014861612999679705, Train_acc 0.9965977822580645\n",
      "\n",
      "Epoch 53. Loss: 0.01624676017544454, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 53. Loss: 0.020694410162405245, Train_acc 0.9962158203125\n",
      "\n",
      "Epoch 53. Loss: 0.0198067699027682, Train_acc 0.9961538461538462\n",
      "\n",
      "Epoch 53. Loss: 0.01831518012904745, Train_acc 0.9962121212121212\n",
      "\n",
      "Epoch 53. Loss: 0.01657880617006381, Train_acc 0.996268656716418\n",
      "\n",
      "Epoch 53. Loss: 0.015147695358943279, Train_acc 0.9963235294117647\n",
      "\n",
      "Epoch 53. Loss: 0.02570614315541208, Train_acc 0.9959239130434783\n",
      "\n",
      "Epoch 53. Loss: 0.02404403624658245, Train_acc 0.9958705357142857\n",
      "\n",
      "Epoch 53. Loss: 0.021933132970849797, Train_acc 0.9959286971830986\n",
      "\n",
      "Epoch 53. Loss: 0.01982729681831721, Train_acc 0.9959852430555556\n",
      "\n",
      "Epoch 53. Loss: 0.018130503469724567, Train_acc 0.9960402397260274\n",
      "\n",
      "Epoch 53. Loss: 0.01810614120127479, Train_acc 0.9959881756756757\n",
      "\n",
      "Epoch 53. Loss: 0.01735881890277612, Train_acc 0.9960416666666667\n",
      "\n",
      "Epoch 53. Loss: 0.02026657134670509, Train_acc 0.9959909539473685\n",
      "\n",
      "Epoch 53. Loss: 0.019352142844007846, Train_acc 0.9959415584415584\n",
      "\n",
      "Epoch 53. Loss: 0.01772934742278436, Train_acc 0.9959935897435898\n",
      "\n",
      "Epoch 53. Loss: 0.017985435999988725, Train_acc 0.9958465189873418\n",
      "\n",
      "Epoch 53. Loss: 0.017711553601973542, Train_acc 0.99580078125\n",
      "\n",
      "Epoch 53. Loss: 0.022155575718182285, Train_acc 0.9955632716049383\n",
      "\n",
      "Epoch 53. Loss: 0.02065156884963628, Train_acc 0.9956173780487805\n",
      "\n",
      "Epoch 53. Loss: 0.018754943119886364, Train_acc 0.9956701807228916\n",
      "\n",
      "Epoch 53. Loss: 0.017555100797774954, Train_acc 0.9957217261904762\n",
      "\n",
      "Epoch 53. Loss: 0.015894217573568282, Train_acc 0.9957720588235294\n",
      "\n",
      "Epoch 53. Loss: 0.0151936885450468, Train_acc 0.9957303779069767\n",
      "\n",
      "Epoch 53. Loss: 0.014015359539987345, Train_acc 0.9957794540229885\n",
      "\n",
      "Epoch 53. Loss: 0.013647079788924783, Train_acc 0.9957386363636364\n",
      "\n",
      "Epoch 53. Loss: 0.012706060344679531, Train_acc 0.9957865168539326\n",
      "\n",
      "Epoch 53. Loss: 0.011829246179494301, Train_acc 0.9958333333333333\n",
      "\n",
      "Epoch 53. Loss: 0.011002785183846689, Train_acc 0.9958791208791209\n",
      "\n",
      "Epoch 53. Loss: 0.010065766127449784, Train_acc 0.9959239130434783\n",
      "\n",
      "Epoch 53. Loss: 0.00918328084375785, Train_acc 0.9959677419354839\n",
      "\n",
      "Epoch 53. Loss: 0.008692218317773875, Train_acc 0.9960106382978723\n",
      "\n",
      "Epoch 53. Loss: 0.00795787492861921, Train_acc 0.9960526315789474\n",
      "\n",
      "Epoch 53. Loss: 0.007615697502081761, Train_acc 0.99609375\n",
      "\n",
      "Epoch 53. Loss: 0.006944086929294991, Train_acc 0.9961340206185567\n",
      "\n",
      "Epoch 53. Loss: 0.006276850335000256, Train_acc 0.9961734693877551\n",
      "\n",
      "Epoch 53. Loss: 0.005708824871024459, Train_acc 0.9962121212121212\n",
      "\n",
      "Epoch 53. Loss: 0.005257402571774396, Train_acc 0.99625\n",
      "\n",
      "[Epoch 53 Batch 100] Loss: 0.008115614693823641 Training: accuracy=0.996132\n",
      "Epoch 53. Loss: 0.008115614693823641, Train_acc 0.9961324257425742\n",
      "\n",
      "Epoch 53. Loss: 0.00744972126028003, Train_acc 0.9961703431372549\n",
      "\n",
      "Epoch 53. Loss: 0.008250317596713259, Train_acc 0.9961316747572816\n",
      "\n",
      "Epoch 53. Loss: 0.008179939499485095, Train_acc 0.9961688701923077\n",
      "\n",
      "Epoch 53. Loss: 0.007632655457172632, Train_acc 0.9962053571428572\n",
      "\n",
      "Epoch 53. Loss: 0.006916235215769416, Train_acc 0.9962411556603774\n",
      "\n",
      "Epoch 53. Loss: 0.007651096409385985, Train_acc 0.9962032710280374\n",
      "\n",
      "Epoch 53. Loss: 0.006942231084958243, Train_acc 0.9962384259259259\n",
      "\n",
      "Epoch 53. Loss: 0.006685485440318758, Train_acc 0.9962729357798165\n",
      "\n",
      "Epoch 53. Loss: 0.006117111954756059, Train_acc 0.9963068181818182\n",
      "\n",
      "Epoch 53. Loss: 0.005869831683226655, Train_acc 0.9963400900900901\n",
      "\n",
      "Epoch 53. Loss: 0.005399996077463684, Train_acc 0.9963727678571429\n",
      "\n",
      "Epoch 53. Loss: 0.00494698956518232, Train_acc 0.9964048672566371\n",
      "\n",
      "Epoch 53. Loss: 0.005415508746285968, Train_acc 0.9964364035087719\n",
      "\n",
      "Epoch 53. Loss: 0.00518123560139215, Train_acc 0.9964673913043478\n",
      "\n",
      "Epoch 53. Loss: 0.005610086143660629, Train_acc 0.9964304956896551\n",
      "\n",
      "Epoch 53. Loss: 0.005120174333753214, Train_acc 0.9964610042735043\n",
      "\n",
      "Epoch 53. Loss: 0.004744054745407724, Train_acc 0.9964909957627118\n",
      "\n",
      "Epoch 53. Loss: 0.005517017744426571, Train_acc 0.9964548319327731\n",
      "\n",
      "Epoch 53. Loss: 0.005568185985411384, Train_acc 0.9964192708333334\n",
      "\n",
      "Epoch 53. Loss: 0.005060225267626505, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 53. Loss: 0.0046018951499983245, Train_acc 0.9964779713114754\n",
      "\n",
      "Epoch 53. Loss: 0.0054736183611623565, Train_acc 0.9964430894308943\n",
      "\n",
      "Epoch 53. Loss: 0.004987492573396231, Train_acc 0.9964717741935484\n",
      "\n",
      "Epoch 53. Loss: 0.004855499077262758, Train_acc 0.9965\n",
      "\n",
      "Epoch 53. Loss: 0.005391279693772446, Train_acc 0.9964657738095238\n",
      "\n",
      "Epoch 53. Loss: 0.0049287974360649, Train_acc 0.9964936023622047\n",
      "\n",
      "Epoch 53. Loss: 0.004517806104118158, Train_acc 0.99652099609375\n",
      "\n",
      "Epoch 53. Loss: 0.004405233059118267, Train_acc 0.9965479651162791\n",
      "\n",
      "Epoch 53. Loss: 0.00405939957782484, Train_acc 0.9965745192307692\n",
      "\n",
      "Epoch 53. Loss: 0.0038371449069442474, Train_acc 0.9966006679389313\n",
      "\n",
      "Epoch 53. Loss: 0.005390501463973116, Train_acc 0.9965672348484849\n",
      "\n",
      "Epoch 53. Loss: 0.005204849724453919, Train_acc 0.9965930451127819\n",
      "\n",
      "Epoch 53. Loss: 0.004711748854585871, Train_acc 0.9966184701492538\n",
      "\n",
      "Epoch 53. Loss: 0.004325255684943543, Train_acc 0.9966435185185185\n",
      "\n",
      "Epoch 53. Loss: 0.004006578294165325, Train_acc 0.9966681985294118\n",
      "\n",
      "Epoch 53. Loss: 0.0038362039178780247, Train_acc 0.9966925182481752\n",
      "\n",
      "Epoch 53. Loss: 0.0039055079527352625, Train_acc 0.9967164855072463\n",
      "\n",
      "Epoch 53. Loss: 0.0036811124156553485, Train_acc 0.9967401079136691\n",
      "\n",
      "Epoch 53. Loss: 0.004767081070301438, Train_acc 0.9967075892857142\n",
      "\n",
      "Epoch 53. Loss: 0.004364983211246509, Train_acc 0.9967309397163121\n",
      "\n",
      "Epoch 53. Loss: 0.00423685270964716, Train_acc 0.9967539612676056\n",
      "\n",
      "Epoch 53. Loss: 0.0061033323042358235, Train_acc 0.996722027972028\n",
      "\n",
      "Epoch 53. Loss: 0.005554590864102791, Train_acc 0.9967447916666666\n",
      "\n",
      "Epoch 53. Loss: 0.005033298484302052, Train_acc 0.9967672413793104\n",
      "\n",
      "Epoch 53. Loss: 0.004616935217747305, Train_acc 0.9967893835616438\n",
      "\n",
      "Epoch 53. Loss: 0.004450669882627619, Train_acc 0.9968112244897959\n",
      "\n",
      "Epoch 53. Loss: 0.004030100735151211, Train_acc 0.9968327702702703\n",
      "\n",
      "Epoch 53. Loss: 0.003955054276472424, Train_acc 0.9968540268456376\n",
      "\n",
      "Epoch 53. Loss: 0.005651051619606699, Train_acc 0.9968229166666667\n",
      "\n",
      "Epoch 53. Loss: 0.005232947786524134, Train_acc 0.9968439569536424\n",
      "\n",
      "Epoch 53. Loss: 0.004902915236148301, Train_acc 0.9968647203947368\n",
      "\n",
      "Epoch 53. Loss: 0.004623840454706309, Train_acc 0.9968852124183006\n",
      "\n",
      "Epoch 53. Loss: 0.004337606039223454, Train_acc 0.9969054383116883\n",
      "\n",
      "Epoch 53. Loss: 0.003923137530686135, Train_acc 0.9969254032258065\n",
      "\n",
      "Epoch 53. Loss: 0.006273052062095709, Train_acc 0.996895032051282\n",
      "\n",
      "Epoch 53. Loss: 0.0068200675089670785, Train_acc 0.9969148089171974\n",
      "\n",
      "Epoch 53. Loss: 0.006226570361008219, Train_acc 0.996934335443038\n",
      "\n",
      "Epoch 53. Loss: 0.006619653399124717, Train_acc 0.9969044811320755\n",
      "\n",
      "Epoch 53. Loss: 0.008471967692972697, Train_acc 0.996826171875\n",
      "\n",
      "Epoch 53. Loss: 0.008175752720953354, Train_acc 0.9968458850931677\n",
      "\n",
      "Epoch 53. Loss: 0.007384412180052582, Train_acc 0.9968653549382716\n",
      "\n",
      "Epoch 53. Loss: 0.006683156966967255, Train_acc 0.9968845858895705\n",
      "\n",
      "Epoch 53. Loss: 0.007443513569059554, Train_acc 0.9968559451219512\n",
      "\n",
      "Epoch 53. Loss: 0.006931143675883935, Train_acc 0.996875\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53. Loss: 0.006914481583661132, Train_acc 0.9968467620481928\n",
      "\n",
      "Epoch 53. Loss: 0.006349646531407946, Train_acc 0.9968656437125748\n",
      "\n",
      "Epoch 53. Loss: 0.00588593083065964, Train_acc 0.9968843005952381\n",
      "\n",
      "Epoch 53. Loss: 0.010884550116439616, Train_acc 0.9968565088757396\n",
      "\n",
      "Epoch 53. Loss: 0.010098767165002187, Train_acc 0.996875\n",
      "\n",
      "Epoch 53. Loss: 0.010910365924528504, Train_acc 0.9968475877192983\n",
      "\n",
      "Epoch 53. Loss: 0.009997293201721845, Train_acc 0.9968659156976745\n",
      "\n",
      "Epoch 53. Loss: 0.01130834003326637, Train_acc 0.9967937138728323\n",
      "\n",
      "Epoch 53. Loss: 0.010427853081709229, Train_acc 0.9968121408045977\n",
      "\n",
      "Epoch 53. Loss: 0.010745616619961932, Train_acc 0.9967857142857143\n",
      "\n",
      "Epoch 53. Loss: 0.009828598322878012, Train_acc 0.9968039772727273\n",
      "\n",
      "Epoch 53. Loss: 0.009747245611169693, Train_acc 0.996777895480226\n",
      "\n",
      "Epoch 53. Loss: 0.009278310140000664, Train_acc 0.9967959971910112\n",
      "\n",
      "Epoch 53. Loss: 0.009178146336251691, Train_acc 0.9967702513966481\n",
      "\n",
      "Epoch 53. Loss: 0.008454789155370767, Train_acc 0.9967881944444444\n",
      "\n",
      "Epoch 53. Loss: 0.00766170824649828, Train_acc 0.9968059392265194\n",
      "\n",
      "Epoch 53. Loss: 0.00733856519572047, Train_acc 0.996823489010989\n",
      "\n",
      "Epoch 53. Loss: 0.006742563718851873, Train_acc 0.9968408469945356\n",
      "\n",
      "Epoch 53. Loss: 0.009688547439244213, Train_acc 0.9967730978260869\n",
      "\n",
      "Epoch 53. Loss: 0.0096318869287075, Train_acc 0.9967483108108108\n",
      "\n",
      "Epoch 53. Loss: 0.008756767381404466, Train_acc 0.9967657930107527\n",
      "\n",
      "Epoch 53. Loss: 0.008104699423916303, Train_acc 0.9967830882352942\n",
      "\n",
      "Epoch 53. Loss: 0.0075583625754032996, Train_acc 0.9968001994680851\n",
      "\n",
      "Epoch 53. Loss: 0.0068447756675073775, Train_acc 0.9968171296296297\n",
      "\n",
      "Epoch 53. Loss: 0.006334340031342739, Train_acc 0.9968338815789474\n",
      "\n",
      "Epoch 53. Loss: 0.006236820143816204, Train_acc 0.9968504581151832\n",
      "\n",
      "Epoch 53. Loss: 0.006167035152635573, Train_acc 0.9968668619791666\n",
      "\n",
      "Epoch 53. Loss: 0.006214381769408225, Train_acc 0.9968830958549223\n",
      "\n",
      "Epoch 53. Loss: 0.0056341631438164615, Train_acc 0.9968991623711341\n",
      "\n",
      "Epoch 53. Loss: 0.005883385101034823, Train_acc 0.996875\n",
      "\n",
      "Epoch 53. Loss: 0.005383352094526962, Train_acc 0.99688\n",
      "\n",
      "Epoch 54. Loss: 0.00643274380591739, Train_acc 0.9921875\n",
      "\n",
      "Epoch 54. Loss: 0.005880984103531947, Train_acc 0.99609375\n",
      "\n",
      "Epoch 54. Loss: 0.0067656242646437674, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 54. Loss: 0.006193329756684166, Train_acc 0.99609375\n",
      "\n",
      "Epoch 54. Loss: 0.005624911772895586, Train_acc 0.996875\n",
      "\n",
      "Epoch 54. Loss: 0.005739494808186947, Train_acc 0.99609375\n",
      "\n",
      "Epoch 54. Loss: 0.005288945917750769, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 54. Loss: 0.004799820266744828, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 54. Loss: 0.004345930691368956, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 54. Loss: 0.003947379794228147, Train_acc 0.99765625\n",
      "\n",
      "Epoch 54. Loss: 0.003633531208380822, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 54. Loss: 0.0032861589833842342, Train_acc 0.998046875\n",
      "\n",
      "Epoch 54. Loss: 0.0031875563149300185, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 54. Loss: 0.004069863239793208, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 54. Loss: 0.00437742438230058, Train_acc 0.9984375\n",
      "\n",
      "Epoch 54. Loss: 0.003977204194274869, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 54. Loss: 0.003857266728191667, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 54. Loss: 0.005067262939312244, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 54. Loss: 0.004585974091692136, Train_acc 0.9983552631578947\n",
      "\n",
      "Epoch 54. Loss: 0.004423564013491601, Train_acc 0.9984375\n",
      "\n",
      "Epoch 54. Loss: 0.0041374301753793925, Train_acc 0.9985119047619048\n",
      "\n",
      "Epoch 54. Loss: 0.0049438202202935315, Train_acc 0.9982244318181818\n",
      "\n",
      "Epoch 54. Loss: 0.00555297768374854, Train_acc 0.9979619565217391\n",
      "\n",
      "Epoch 54. Loss: 0.005352823434492115, Train_acc 0.998046875\n",
      "\n",
      "Epoch 54. Loss: 0.004996102264422324, Train_acc 0.998125\n",
      "\n",
      "Epoch 54. Loss: 0.004696951888000798, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 54. Loss: 0.004249605296322609, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 54. Loss: 0.003848846551671763, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 54. Loss: 0.003560351256764805, Train_acc 0.9983836206896551\n",
      "\n",
      "Epoch 54. Loss: 0.0034311717117832983, Train_acc 0.9984375\n",
      "\n",
      "Epoch 54. Loss: 0.0031365852040850196, Train_acc 0.9984879032258065\n",
      "\n",
      "Epoch 54. Loss: 0.006684548823488033, Train_acc 0.998291015625\n",
      "\n",
      "Epoch 54. Loss: 0.0061743592207452146, Train_acc 0.998342803030303\n",
      "\n",
      "Epoch 54. Loss: 0.005605951029381498, Train_acc 0.9983915441176471\n",
      "\n",
      "Epoch 54. Loss: 0.005470156227414021, Train_acc 0.9984375\n",
      "\n",
      "Epoch 54. Loss: 0.006509802651283928, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 54. Loss: 0.006839636839369942, Train_acc 0.9980996621621622\n",
      "\n",
      "Epoch 54. Loss: 0.007009190341329583, Train_acc 0.9981496710526315\n",
      "\n",
      "Epoch 54. Loss: 0.006360121888272621, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 54. Loss: 0.005880401366817348, Train_acc 0.9982421875\n",
      "\n",
      "Epoch 54. Loss: 0.005351537827414179, Train_acc 0.9982850609756098\n",
      "\n",
      "Epoch 54. Loss: 0.005072219520072851, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 54. Loss: 0.005569579280251903, Train_acc 0.9981831395348837\n",
      "\n",
      "Epoch 54. Loss: 0.009265861654431799, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 54. Loss: 0.008465013407995116, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 54. Loss: 0.007898251915533672, Train_acc 0.9979619565217391\n",
      "\n",
      "Epoch 54. Loss: 0.009357611347340939, Train_acc 0.9978390957446809\n",
      "\n",
      "Epoch 54. Loss: 0.008584035591910837, Train_acc 0.9978841145833334\n",
      "\n",
      "Epoch 54. Loss: 0.00783835392712181, Train_acc 0.9979272959183674\n",
      "\n",
      "Epoch 54. Loss: 0.007274908710810171, Train_acc 0.99796875\n",
      "\n",
      "Epoch 54. Loss: 0.006635156482198203, Train_acc 0.9980085784313726\n",
      "\n",
      "Epoch 54. Loss: 0.007310053726051776, Train_acc 0.9978966346153846\n",
      "\n",
      "Epoch 54. Loss: 0.006690155648825641, Train_acc 0.9979363207547169\n",
      "\n",
      "Epoch 54. Loss: 0.007986723572288225, Train_acc 0.9978298611111112\n",
      "\n",
      "Epoch 54. Loss: 0.007231608135777804, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 54. Loss: 0.006698378617080831, Train_acc 0.9979073660714286\n",
      "\n",
      "Epoch 54. Loss: 0.006254062053498135, Train_acc 0.9979440789473685\n",
      "\n",
      "Epoch 54. Loss: 0.006250055038425182, Train_acc 0.997979525862069\n",
      "\n",
      "Epoch 54. Loss: 0.005784425719038715, Train_acc 0.9980137711864406\n",
      "\n",
      "Epoch 54. Loss: 0.0054641712132076055, Train_acc 0.998046875\n",
      "\n",
      "Epoch 54. Loss: 0.005445082810340491, Train_acc 0.9980788934426229\n",
      "\n",
      "Epoch 54. Loss: 0.008958498606221228, Train_acc 0.9979838709677419\n",
      "\n",
      "Epoch 54. Loss: 0.008225606039977535, Train_acc 0.998015873015873\n",
      "\n",
      "Epoch 54. Loss: 0.008557652318462549, Train_acc 0.9979248046875\n",
      "\n",
      "Epoch 54. Loss: 0.0102585774740441, Train_acc 0.9977163461538462\n",
      "\n",
      "Epoch 54. Loss: 0.01776049930580229, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 54. Loss: 0.01602334761669542, Train_acc 0.9974347014925373\n",
      "\n",
      "Epoch 54. Loss: 0.014568564397639533, Train_acc 0.9974724264705882\n",
      "\n",
      "Epoch 54. Loss: 0.013128870207299142, Train_acc 0.9975090579710145\n",
      "\n",
      "Epoch 54. Loss: 0.01184221657025644, Train_acc 0.9975446428571428\n",
      "\n",
      "Epoch 54. Loss: 0.011957836428950687, Train_acc 0.9974691901408451\n",
      "\n",
      "Epoch 54. Loss: 0.011074816052321012, Train_acc 0.9975043402777778\n",
      "\n",
      "Epoch 54. Loss: 0.011452950695189907, Train_acc 0.997431506849315\n",
      "\n",
      "Epoch 54. Loss: 0.01043796406842, Train_acc 0.9974662162162162\n",
      "\n",
      "Epoch 54. Loss: 0.009720231331795991, Train_acc 0.9975\n",
      "\n",
      "Epoch 54. Loss: 0.012590352285573371, Train_acc 0.9974300986842105\n",
      "\n",
      "Epoch 54. Loss: 0.011400905293526789, Train_acc 0.997463474025974\n",
      "\n",
      "Epoch 54. Loss: 0.011864967980059274, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 54. Loss: 0.01227199055678155, Train_acc 0.9973299050632911\n",
      "\n",
      "Epoch 54. Loss: 0.017100040774880403, Train_acc 0.99716796875\n",
      "\n",
      "Epoch 54. Loss: 0.01548040139594582, Train_acc 0.9972029320987654\n",
      "\n",
      "Epoch 54. Loss: 0.017519596021642454, Train_acc 0.997046493902439\n",
      "\n",
      "Epoch 54. Loss: 0.01610971567148283, Train_acc 0.997082078313253\n",
      "\n",
      "Epoch 54. Loss: 0.01498331608278437, Train_acc 0.9971168154761905\n",
      "\n",
      "Epoch 54. Loss: 0.017562111305322203, Train_acc 0.9970588235294118\n",
      "\n",
      "Epoch 54. Loss: 0.016013525597416717, Train_acc 0.997093023255814\n",
      "\n",
      "Epoch 54. Loss: 0.014887754493650816, Train_acc 0.9971264367816092\n",
      "\n",
      "Epoch 54. Loss: 0.014008061446947178, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 54. Loss: 0.01597947078186481, Train_acc 0.9970154494382022\n",
      "\n",
      "Epoch 54. Loss: 0.019583985482795916, Train_acc 0.9969618055555556\n",
      "\n",
      "Epoch 54. Loss: 0.01947518742097367, Train_acc 0.9969093406593407\n",
      "\n",
      "Epoch 54. Loss: 0.01865025613245025, Train_acc 0.9968580163043478\n",
      "\n",
      "Epoch 54. Loss: 0.022142309727102412, Train_acc 0.9967237903225806\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54. Loss: 0.020755234575417544, Train_acc 0.9967586436170213\n",
      "\n",
      "Epoch 54. Loss: 0.018849856383168166, Train_acc 0.9967927631578948\n",
      "\n",
      "Epoch 54. Loss: 0.01935154726496053, Train_acc 0.9967447916666666\n",
      "\n",
      "Epoch 54. Loss: 0.021121697772062232, Train_acc 0.9966978092783505\n",
      "\n",
      "Epoch 54. Loss: 0.019509683188587198, Train_acc 0.9967315051020408\n",
      "\n",
      "Epoch 54. Loss: 0.01767881796119565, Train_acc 0.9967645202020202\n",
      "\n",
      "Epoch 54. Loss: 0.018291882816177198, Train_acc 0.996640625\n",
      "\n",
      "[Epoch 54 Batch 100] Loss: 0.017314785586197607 Training: accuracy=0.996597\n",
      "Epoch 54. Loss: 0.017314785586197607, Train_acc 0.9965965346534653\n",
      "\n",
      "Epoch 54. Loss: 0.01564465382182361, Train_acc 0.9966299019607843\n",
      "\n",
      "Epoch 54. Loss: 0.014645449833426727, Train_acc 0.9966626213592233\n",
      "\n",
      "Epoch 54. Loss: 0.01341954580573337, Train_acc 0.9966947115384616\n",
      "\n",
      "Epoch 54. Loss: 0.012868056196374567, Train_acc 0.9967261904761905\n",
      "\n",
      "Epoch 54. Loss: 0.011858967103498761, Train_acc 0.9967570754716981\n",
      "\n",
      "Epoch 54. Loss: 0.011841499499622807, Train_acc 0.9967873831775701\n",
      "\n",
      "Epoch 54. Loss: 0.011858091172257506, Train_acc 0.9967447916666666\n",
      "\n",
      "Epoch 54. Loss: 0.01220862399787853, Train_acc 0.9967029816513762\n",
      "\n",
      "Epoch 54. Loss: 0.01233243279160097, Train_acc 0.9966619318181819\n",
      "\n",
      "Epoch 54. Loss: 0.017924327395865632, Train_acc 0.996410472972973\n",
      "\n",
      "Epoch 54. Loss: 0.01625774059706269, Train_acc 0.9964425223214286\n",
      "\n",
      "Epoch 54. Loss: 0.0149775145002902, Train_acc 0.9964740044247787\n",
      "\n",
      "Epoch 54. Loss: 0.015166961555066746, Train_acc 0.9964364035087719\n",
      "\n",
      "Epoch 54. Loss: 0.023051314864501096, Train_acc 0.9961277173913043\n",
      "\n",
      "Epoch 54. Loss: 0.02127134323249287, Train_acc 0.996161099137931\n",
      "\n",
      "Epoch 54. Loss: 0.01939784534578049, Train_acc 0.9961939102564102\n",
      "\n",
      "Epoch 54. Loss: 0.024479835162799276, Train_acc 0.9960275423728814\n",
      "\n",
      "Epoch 54. Loss: 0.022596137200511145, Train_acc 0.9960609243697479\n",
      "\n",
      "Epoch 54. Loss: 0.028536343402907234, Train_acc 0.9958333333333333\n",
      "\n",
      "Epoch 54. Loss: 0.02803219247065036, Train_acc 0.9957386363636364\n",
      "\n",
      "Epoch 54. Loss: 0.02616508484514399, Train_acc 0.9957735655737705\n",
      "\n",
      "Epoch 54. Loss: 0.026158051690147913, Train_acc 0.9957444105691057\n",
      "\n",
      "Epoch 54. Loss: 0.027191691399234472, Train_acc 0.9957157258064516\n",
      "\n",
      "Epoch 54. Loss: 0.028773606464819256, Train_acc 0.9955\n",
      "\n",
      "Epoch 54. Loss: 0.03318644223709954, Train_acc 0.9954737103174603\n",
      "\n",
      "Epoch 54. Loss: 0.031942446080744744, Train_acc 0.9953863188976378\n",
      "\n",
      "Epoch 54. Loss: 0.029314988186568452, Train_acc 0.99542236328125\n",
      "\n",
      "Epoch 54. Loss: 0.027209288997003825, Train_acc 0.9954578488372093\n",
      "\n",
      "Epoch 54. Loss: 0.029989075323238426, Train_acc 0.9953725961538461\n",
      "\n",
      "Epoch 54. Loss: 0.028953607747221995, Train_acc 0.9953482824427481\n",
      "\n",
      "Epoch 54. Loss: 0.031500672581134745, Train_acc 0.9952651515151515\n",
      "\n",
      "Epoch 54. Loss: 0.031228844515089848, Train_acc 0.9952420112781954\n",
      "\n",
      "Epoch 54. Loss: 0.028910392079446904, Train_acc 0.9952775186567164\n",
      "\n",
      "Epoch 54. Loss: 0.02747256859349685, Train_acc 0.9952546296296296\n",
      "\n",
      "Epoch 54. Loss: 0.02561878247223029, Train_acc 0.9952320772058824\n",
      "\n",
      "Epoch 54. Loss: 0.023555517195121018, Train_acc 0.9952668795620438\n",
      "\n",
      "Epoch 54. Loss: 0.021513269211647423, Train_acc 0.9953011775362319\n",
      "\n",
      "Epoch 54. Loss: 0.019756289600548906, Train_acc 0.9953349820143885\n",
      "\n",
      "Epoch 54. Loss: 0.022809449385897306, Train_acc 0.9953125\n",
      "\n",
      "Epoch 54. Loss: 0.02122219224390029, Train_acc 0.995345744680851\n",
      "\n",
      "Epoch 54. Loss: 0.020945790659934037, Train_acc 0.9953235035211268\n",
      "\n",
      "Epoch 54. Loss: 0.01908492119655736, Train_acc 0.9953562062937062\n",
      "\n",
      "Epoch 54. Loss: 0.01756059442352409, Train_acc 0.9953884548611112\n",
      "\n",
      "Epoch 54. Loss: 0.01630508091128905, Train_acc 0.9954202586206896\n",
      "\n",
      "Epoch 54. Loss: 0.01538817220026588, Train_acc 0.9954516267123288\n",
      "\n",
      "Epoch 54. Loss: 0.014228328552754244, Train_acc 0.9954825680272109\n",
      "\n",
      "Epoch 54. Loss: 0.012936877547702808, Train_acc 0.9955130912162162\n",
      "\n",
      "Epoch 54. Loss: 0.012094237744288104, Train_acc 0.9955432046979866\n",
      "\n",
      "Epoch 54. Loss: 0.011124685482026449, Train_acc 0.9955729166666667\n",
      "\n",
      "Epoch 54. Loss: 0.011368259948499182, Train_acc 0.9955504966887417\n",
      "\n",
      "Epoch 54. Loss: 0.01344431690455125, Train_acc 0.9955283717105263\n",
      "\n",
      "Epoch 54. Loss: 0.012545001618540103, Train_acc 0.9955575980392157\n",
      "\n",
      "Epoch 54. Loss: 0.015424496706553534, Train_acc 0.9954849837662337\n",
      "\n",
      "Epoch 54. Loss: 0.014173806230704399, Train_acc 0.9955141129032258\n",
      "\n",
      "Epoch 54. Loss: 0.012971244775374601, Train_acc 0.9955428685897436\n",
      "\n",
      "Epoch 54. Loss: 0.011720794672444534, Train_acc 0.9955712579617835\n",
      "\n",
      "Epoch 54. Loss: 0.010818763198599283, Train_acc 0.9955992879746836\n",
      "\n",
      "Epoch 54. Loss: 0.010653635000120162, Train_acc 0.995626965408805\n",
      "\n",
      "Epoch 54. Loss: 0.00973868193527063, Train_acc 0.995654296875\n",
      "\n",
      "Epoch 54. Loss: 0.010590481659471991, Train_acc 0.9955842391304348\n",
      "\n",
      "Epoch 54. Loss: 0.010118878804773095, Train_acc 0.9956114969135802\n",
      "\n",
      "Epoch 54. Loss: 0.009372918490511183, Train_acc 0.9956384202453987\n",
      "\n",
      "Epoch 54. Loss: 0.012452636972613935, Train_acc 0.9956173780487805\n",
      "\n",
      "Epoch 54. Loss: 0.012665006912244384, Train_acc 0.9955965909090909\n",
      "\n",
      "Epoch 54. Loss: 0.011621746244498812, Train_acc 0.9956231174698795\n",
      "\n",
      "Epoch 54. Loss: 0.01157678431791251, Train_acc 0.9956025449101796\n",
      "\n",
      "Epoch 54. Loss: 0.010793866085459456, Train_acc 0.9956287202380952\n",
      "\n",
      "Epoch 54. Loss: 0.010079212661601304, Train_acc 0.9956545857988166\n",
      "\n",
      "Epoch 54. Loss: 0.009173549706094443, Train_acc 0.9956801470588236\n",
      "\n",
      "Epoch 54. Loss: 0.012868211040812413, Train_acc 0.9956140350877193\n",
      "\n",
      "Epoch 54. Loss: 0.013851957353875947, Train_acc 0.9955486918604651\n",
      "\n",
      "Epoch 54. Loss: 0.012722700144731324, Train_acc 0.9955744219653179\n",
      "\n",
      "Epoch 54. Loss: 0.011665597170263518, Train_acc 0.9955998563218391\n",
      "\n",
      "Epoch 54. Loss: 0.011007760209295146, Train_acc 0.995625\n",
      "\n",
      "Epoch 54. Loss: 0.010667506393748217, Train_acc 0.9956498579545454\n",
      "\n",
      "Epoch 54. Loss: 0.0114999901461223, Train_acc 0.9956302966101694\n",
      "\n",
      "Epoch 54. Loss: 0.01489432300993376, Train_acc 0.9956109550561798\n",
      "\n",
      "Epoch 54. Loss: 0.01414754851752734, Train_acc 0.9956354748603352\n",
      "\n",
      "Epoch 54. Loss: 0.014801089368112825, Train_acc 0.9955729166666667\n",
      "\n",
      "Epoch 54. Loss: 0.01431057958470101, Train_acc 0.9955542127071824\n",
      "\n",
      "Epoch 54. Loss: 0.013233357615020706, Train_acc 0.9955786401098901\n",
      "\n",
      "Epoch 54. Loss: 0.012100599008963406, Train_acc 0.9956028005464481\n",
      "\n",
      "Epoch 54. Loss: 0.011080263311731876, Train_acc 0.9956266983695652\n",
      "\n",
      "Epoch 54. Loss: 0.01149127923405295, Train_acc 0.9955658783783784\n",
      "\n",
      "Epoch 54. Loss: 0.010524776845591893, Train_acc 0.9955897177419355\n",
      "\n",
      "Epoch 54. Loss: 0.009617037119940785, Train_acc 0.9956133021390374\n",
      "\n",
      "Epoch 54. Loss: 0.011135567241140487, Train_acc 0.995595079787234\n",
      "\n",
      "Epoch 54. Loss: 0.010068639093846223, Train_acc 0.9956183862433863\n",
      "\n",
      "Epoch 54. Loss: 0.009782170797923335, Train_acc 0.9956414473684211\n",
      "\n",
      "Epoch 54. Loss: 0.009482100115825948, Train_acc 0.9956642670157068\n",
      "\n",
      "Epoch 54. Loss: 0.008731240896830158, Train_acc 0.9956868489583334\n",
      "\n",
      "Epoch 54. Loss: 0.00932778406302559, Train_acc 0.9956687176165803\n",
      "\n",
      "Epoch 54. Loss: 0.008438389028390038, Train_acc 0.995691043814433\n",
      "\n",
      "Epoch 54. Loss: 0.008369753513735343, Train_acc 0.995713141025641\n",
      "\n",
      "Epoch 54. Loss: 0.007561238786523917, Train_acc 0.99572\n",
      "\n",
      "Epoch 55. Loss: 0.006845216848847981, Train_acc 1.0\n",
      "\n",
      "Epoch 55. Loss: 0.006810033658949479, Train_acc 0.99609375\n",
      "\n",
      "Epoch 55. Loss: 0.009478410860724401, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 55. Loss: 0.008570591406518654, Train_acc 0.99609375\n",
      "\n",
      "Epoch 55. Loss: 0.007928979261438044, Train_acc 0.996875\n",
      "\n",
      "Epoch 55. Loss: 0.007224584290917211, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 55. Loss: 0.006527329307518969, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 55. Loss: 0.0062232104398809995, Train_acc 0.998046875\n",
      "\n",
      "Epoch 55. Loss: 0.0057494900151791985, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 55. Loss: 0.0052210796363618885, Train_acc 0.9984375\n",
      "\n",
      "Epoch 55. Loss: 0.004818845798537902, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 55. Loss: 0.004378799299189952, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 55. Loss: 0.004105740926971591, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 55. Loss: 0.00376874038634648, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 55. Loss: 0.0049129873131926365, Train_acc 0.9984375\n",
      "\n",
      "Epoch 55. Loss: 0.004619029921536045, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 55. Loss: 0.004206015439009872, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 55. Loss: 0.003885121220098025, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 55. Loss: 0.00503223699591704, Train_acc 0.9983552631578947\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55. Loss: 0.005809148305763135, Train_acc 0.998046875\n",
      "\n",
      "Epoch 55. Loss: 0.00583688826108813, Train_acc 0.9981398809523809\n",
      "\n",
      "Epoch 55. Loss: 0.005427298269374726, Train_acc 0.9982244318181818\n",
      "\n",
      "Epoch 55. Loss: 0.005073962096437268, Train_acc 0.9983016304347826\n",
      "\n",
      "Epoch 55. Loss: 0.004787124166918802, Train_acc 0.9983723958333334\n",
      "\n",
      "Epoch 55. Loss: 0.0044209866586436405, Train_acc 0.9984375\n",
      "\n",
      "Epoch 55. Loss: 0.004107118631581328, Train_acc 0.9984975961538461\n",
      "\n",
      "Epoch 55. Loss: 0.003742017322357434, Train_acc 0.9985532407407407\n",
      "\n",
      "Epoch 55. Loss: 0.004814895665862505, Train_acc 0.998046875\n",
      "\n",
      "Epoch 55. Loss: 0.004423983884434785, Train_acc 0.998114224137931\n",
      "\n",
      "Epoch 55. Loss: 0.004079912763906317, Train_acc 0.9981770833333333\n",
      "\n",
      "Epoch 55. Loss: 0.003772981092883167, Train_acc 0.9982358870967742\n",
      "\n",
      "Epoch 55. Loss: 0.0034387477294363987, Train_acc 0.998291015625\n",
      "\n",
      "Epoch 55. Loss: 0.0036654931803725734, Train_acc 0.998342803030303\n",
      "\n",
      "Epoch 55. Loss: 0.00396240423435115, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 55. Loss: 0.0038348170090613644, Train_acc 0.9982142857142857\n",
      "\n",
      "Epoch 55. Loss: 0.005174656462868859, Train_acc 0.998046875\n",
      "\n",
      "Epoch 55. Loss: 0.004719426924933472, Train_acc 0.9980996621621622\n",
      "\n",
      "Epoch 55. Loss: 0.004260929061240983, Train_acc 0.9981496710526315\n",
      "\n",
      "Epoch 55. Loss: 0.003923649421600952, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 55. Loss: 0.003657753102497864, Train_acc 0.9982421875\n",
      "\n",
      "Epoch 55. Loss: 0.003472210328761436, Train_acc 0.9982850609756098\n",
      "\n",
      "Epoch 55. Loss: 0.0031918309166043524, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 55. Loss: 0.004216959248543637, Train_acc 0.9983648255813954\n",
      "\n",
      "Epoch 55. Loss: 0.00454906706115084, Train_acc 0.9982244318181818\n",
      "\n",
      "Epoch 55. Loss: 0.004244148621675168, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 55. Loss: 0.003951765579756464, Train_acc 0.9983016304347826\n",
      "\n",
      "Epoch 55. Loss: 0.0035709731592473673, Train_acc 0.9983377659574468\n",
      "\n",
      "Epoch 55. Loss: 0.0032561486302817052, Train_acc 0.9983723958333334\n",
      "\n",
      "Epoch 55. Loss: 0.00466893377950825, Train_acc 0.9980867346938775\n",
      "\n",
      "Epoch 55. Loss: 0.004824781348267535, Train_acc 0.998125\n",
      "\n",
      "Epoch 55. Loss: 0.004392769738576343, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 55. Loss: 0.004029504437800375, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 55. Loss: 0.005245052930315847, Train_acc 0.9980837264150944\n",
      "\n",
      "Epoch 55. Loss: 0.0049264121384699775, Train_acc 0.9981192129629629\n",
      "\n",
      "Epoch 55. Loss: 0.004471952493002493, Train_acc 0.9981534090909091\n",
      "\n",
      "Epoch 55. Loss: 0.004049903721557987, Train_acc 0.9981863839285714\n",
      "\n",
      "Epoch 55. Loss: 0.005279350195181607, Train_acc 0.9980811403508771\n",
      "\n",
      "Epoch 55. Loss: 0.004831948943713819, Train_acc 0.998114224137931\n",
      "\n",
      "Epoch 55. Loss: 0.004753827354934378, Train_acc 0.998146186440678\n",
      "\n",
      "Epoch 55. Loss: 0.005284203337097076, Train_acc 0.998046875\n",
      "\n",
      "Epoch 55. Loss: 0.004983058610563494, Train_acc 0.9980788934426229\n",
      "\n",
      "Epoch 55. Loss: 0.0044984556303311295, Train_acc 0.9981098790322581\n",
      "\n",
      "Epoch 55. Loss: 0.004640957068954906, Train_acc 0.998015873015873\n",
      "\n",
      "Epoch 55. Loss: 0.004237954056582229, Train_acc 0.998046875\n",
      "\n",
      "Epoch 55. Loss: 0.0038328422710704815, Train_acc 0.9980769230769231\n",
      "\n",
      "Epoch 55. Loss: 0.005063260110206128, Train_acc 0.9979876893939394\n",
      "\n",
      "Epoch 55. Loss: 0.004684123565915276, Train_acc 0.9980177238805971\n",
      "\n",
      "Epoch 55. Loss: 0.004242941940535351, Train_acc 0.998046875\n",
      "\n",
      "Epoch 55. Loss: 0.003842501835276722, Train_acc 0.9980751811594203\n",
      "\n",
      "Epoch 55. Loss: 0.004234283451363479, Train_acc 0.9979910714285715\n",
      "\n",
      "Epoch 55. Loss: 0.005675478757135601, Train_acc 0.9977992957746479\n",
      "\n",
      "Epoch 55. Loss: 0.005245974936042009, Train_acc 0.9978298611111112\n",
      "\n",
      "Epoch 55. Loss: 0.005092307391423385, Train_acc 0.9978595890410958\n",
      "\n",
      "Epoch 55. Loss: 0.004791179144896626, Train_acc 0.9978885135135135\n",
      "\n",
      "Epoch 55. Loss: 0.007604066367016042, Train_acc 0.9977083333333333\n",
      "\n",
      "Epoch 55. Loss: 0.00819140400892419, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 55. Loss: 0.007475705315356009, Train_acc 0.997564935064935\n",
      "\n",
      "Epoch 55. Loss: 0.0075086640332799135, Train_acc 0.9974959935897436\n",
      "\n",
      "Epoch 55. Loss: 0.006784574667371301, Train_acc 0.9975276898734177\n",
      "\n",
      "Epoch 55. Loss: 0.007925547678551366, Train_acc 0.9974609375\n",
      "\n",
      "Epoch 55. Loss: 0.008656128699434957, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 55. Loss: 0.00828418887840494, Train_acc 0.9974275914634146\n",
      "\n",
      "Epoch 55. Loss: 0.00925735297519074, Train_acc 0.9973644578313253\n",
      "\n",
      "Epoch 55. Loss: 0.008551729854283686, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 55. Loss: 0.007729674114621652, Train_acc 0.9974264705882353\n",
      "\n",
      "Epoch 55. Loss: 0.0071725209425049785, Train_acc 0.9974563953488372\n",
      "\n",
      "Epoch 55. Loss: 0.006503295663311282, Train_acc 0.9974856321839081\n",
      "\n",
      "Epoch 55. Loss: 0.012484658595902504, Train_acc 0.9973366477272727\n",
      "\n",
      "Epoch 55. Loss: 0.011385233382231994, Train_acc 0.9973665730337079\n",
      "\n",
      "Epoch 55. Loss: 0.010553442414526944, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 55. Loss: 0.009545850929001171, Train_acc 0.9974244505494505\n",
      "\n",
      "Epoch 55. Loss: 0.01173332543049383, Train_acc 0.9973675271739131\n",
      "\n",
      "Epoch 55. Loss: 0.017365327127642584, Train_acc 0.997059811827957\n",
      "\n",
      "Epoch 55. Loss: 0.01600527737471505, Train_acc 0.9970910904255319\n",
      "\n",
      "Epoch 55. Loss: 0.015559375518706833, Train_acc 0.9970394736842105\n",
      "\n",
      "Epoch 55. Loss: 0.0165838115148074, Train_acc 0.9969889322916666\n",
      "\n",
      "Epoch 55. Loss: 0.015519731512575735, Train_acc 0.9970199742268041\n",
      "\n",
      "Epoch 55. Loss: 0.015087170098044922, Train_acc 0.9969706632653061\n",
      "\n",
      "Epoch 55. Loss: 0.014558746559606596, Train_acc 0.9969223484848485\n",
      "\n",
      "Epoch 55. Loss: 0.013489843301902655, Train_acc 0.996953125\n",
      "\n",
      "[Epoch 55 Batch 100] Loss: 0.01218286940801258 Training: accuracy=0.996983\n",
      "Epoch 55. Loss: 0.01218286940801258, Train_acc 0.9969832920792079\n",
      "\n",
      "Epoch 55. Loss: 0.014101875552667217, Train_acc 0.996859681372549\n",
      "\n",
      "Epoch 55. Loss: 0.014643607493459913, Train_acc 0.9968143203883495\n",
      "\n",
      "Epoch 55. Loss: 0.013363077387186647, Train_acc 0.9968449519230769\n",
      "\n",
      "Epoch 55. Loss: 0.012091955913159856, Train_acc 0.996875\n",
      "\n",
      "Epoch 55. Loss: 0.011409880330908546, Train_acc 0.9969044811320755\n",
      "\n",
      "Epoch 55. Loss: 0.01081164297304891, Train_acc 0.9969334112149533\n",
      "\n",
      "Epoch 55. Loss: 0.011641576068183862, Train_acc 0.9968894675925926\n",
      "\n",
      "Epoch 55. Loss: 0.010551963790336474, Train_acc 0.996918004587156\n",
      "\n",
      "Epoch 55. Loss: 0.009603287081528506, Train_acc 0.9969460227272727\n",
      "\n",
      "Epoch 55. Loss: 0.013248597354241134, Train_acc 0.9967623873873874\n",
      "\n",
      "Epoch 55. Loss: 0.013731060530735185, Train_acc 0.9967215401785714\n",
      "\n",
      "Epoch 55. Loss: 0.015590883215659676, Train_acc 0.996612278761062\n",
      "\n",
      "Epoch 55. Loss: 0.015614751953238682, Train_acc 0.9965049342105263\n",
      "\n",
      "Epoch 55. Loss: 0.014108105801716689, Train_acc 0.9965353260869565\n",
      "\n",
      "Epoch 55. Loss: 0.014190944219984333, Train_acc 0.9964978448275862\n",
      "\n",
      "Epoch 55. Loss: 0.014945987516961443, Train_acc 0.9964610042735043\n",
      "\n",
      "Epoch 55. Loss: 0.013563740796548379, Train_acc 0.9964909957627118\n",
      "\n",
      "Epoch 55. Loss: 0.012475553718241083, Train_acc 0.9965204831932774\n",
      "\n",
      "Epoch 55. Loss: 0.014170845993189836, Train_acc 0.996484375\n",
      "\n",
      "Epoch 55. Loss: 0.015709362944509527, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 55. Loss: 0.014647080860775062, Train_acc 0.9964779713114754\n",
      "\n",
      "Epoch 55. Loss: 0.014134078461445583, Train_acc 0.9964430894308943\n",
      "\n",
      "Epoch 55. Loss: 0.014011590712681902, Train_acc 0.9964087701612904\n",
      "\n",
      "Epoch 55. Loss: 0.013055515542699837, Train_acc 0.9964375\n",
      "\n",
      "Epoch 55. Loss: 0.01627922110713179, Train_acc 0.9963417658730159\n",
      "\n",
      "Epoch 55. Loss: 0.014771351249314741, Train_acc 0.9963705708661418\n",
      "\n",
      "Epoch 55. Loss: 0.019904477028218563, Train_acc 0.9962158203125\n",
      "\n",
      "Epoch 55. Loss: 0.01850263799823909, Train_acc 0.9962451550387597\n",
      "\n",
      "Epoch 55. Loss: 0.01684378876419445, Train_acc 0.9962740384615385\n",
      "\n",
      "Epoch 55. Loss: 0.0160467649099074, Train_acc 0.9963024809160306\n",
      "\n",
      "Epoch 55. Loss: 0.014876450795025427, Train_acc 0.9963304924242424\n",
      "\n",
      "Epoch 55. Loss: 0.013978145383454084, Train_acc 0.996358082706767\n",
      "\n",
      "Epoch 55. Loss: 0.012793378870143042, Train_acc 0.9963852611940298\n",
      "\n",
      "Epoch 55. Loss: 0.011588933718703133, Train_acc 0.9964120370370371\n",
      "\n",
      "Epoch 55. Loss: 0.01320466897115285, Train_acc 0.9963809742647058\n",
      "\n",
      "Epoch 55. Loss: 0.012086407571809068, Train_acc 0.996407390510949\n",
      "\n",
      "Epoch 55. Loss: 0.011029433440962352, Train_acc 0.9964334239130435\n",
      "\n",
      "Epoch 55. Loss: 0.010688272381692157, Train_acc 0.9964028776978417\n",
      "\n",
      "Epoch 55. Loss: 0.009984712697820987, Train_acc 0.9964285714285714\n",
      "\n",
      "Epoch 55. Loss: 0.00910534143852707, Train_acc 0.9964539007092199\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55. Loss: 0.012354014936752762, Train_acc 0.9964238556338029\n",
      "\n",
      "Epoch 55. Loss: 0.012265490720719974, Train_acc 0.9963942307692307\n",
      "\n",
      "Epoch 55. Loss: 0.011352095721148743, Train_acc 0.9964192708333334\n",
      "\n",
      "Epoch 55. Loss: 0.010492126754730904, Train_acc 0.9964439655172413\n",
      "\n",
      "Epoch 55. Loss: 0.009597787051310359, Train_acc 0.9964683219178082\n",
      "\n",
      "Epoch 55. Loss: 0.008938177616664964, Train_acc 0.9964923469387755\n",
      "\n",
      "Epoch 55. Loss: 0.010237266331555724, Train_acc 0.996410472972973\n",
      "\n",
      "Epoch 55. Loss: 0.01213172536460365, Train_acc 0.9963821308724832\n",
      "\n",
      "Epoch 55. Loss: 0.011711739123920846, Train_acc 0.9963541666666667\n",
      "\n",
      "Epoch 55. Loss: 0.015975618470663054, Train_acc 0.9963265728476821\n",
      "\n",
      "Epoch 55. Loss: 0.015269206412691675, Train_acc 0.996350740131579\n",
      "\n",
      "Epoch 55. Loss: 0.0169512582850982, Train_acc 0.9962214052287581\n",
      "\n",
      "Epoch 55. Loss: 0.015338207796330383, Train_acc 0.9962459415584416\n",
      "\n",
      "Epoch 55. Loss: 0.014011674043266592, Train_acc 0.9962701612903225\n",
      "\n",
      "Epoch 55. Loss: 0.012681457534254969, Train_acc 0.9962940705128205\n",
      "\n",
      "Epoch 55. Loss: 0.011557263784975302, Train_acc 0.9963176751592356\n",
      "\n",
      "Epoch 55. Loss: 0.01277247885915979, Train_acc 0.9962915348101266\n",
      "\n",
      "Epoch 55. Loss: 0.01194834185066829, Train_acc 0.996314858490566\n",
      "\n",
      "Epoch 55. Loss: 0.01093386985385874, Train_acc 0.996337890625\n",
      "\n",
      "Epoch 55. Loss: 0.010449098492259912, Train_acc 0.9963606366459627\n",
      "\n",
      "Epoch 55. Loss: 0.009695190812285362, Train_acc 0.9963831018518519\n",
      "\n",
      "Epoch 55. Loss: 0.008855524035291926, Train_acc 0.996405291411043\n",
      "\n",
      "Epoch 55. Loss: 0.009386325140592804, Train_acc 0.9963795731707317\n",
      "\n",
      "Epoch 55. Loss: 0.010121014797506349, Train_acc 0.9963541666666667\n",
      "\n",
      "Epoch 55. Loss: 0.01343854293270494, Train_acc 0.9963290662650602\n",
      "\n",
      "Epoch 55. Loss: 0.012220306615734866, Train_acc 0.9963510479041916\n",
      "\n",
      "Epoch 55. Loss: 0.012991101745401119, Train_acc 0.9963262648809523\n",
      "\n",
      "Epoch 55. Loss: 0.011780130379357302, Train_acc 0.9963480029585798\n",
      "\n",
      "Epoch 55. Loss: 0.011065165337584941, Train_acc 0.9963694852941176\n",
      "\n",
      "Epoch 55. Loss: 0.010178521444272275, Train_acc 0.996390716374269\n",
      "\n",
      "Epoch 55. Loss: 0.00967422562006528, Train_acc 0.9964117005813954\n",
      "\n",
      "Epoch 55. Loss: 0.009209148117125764, Train_acc 0.9964324421965318\n",
      "\n",
      "Epoch 55. Loss: 0.009452195788819255, Train_acc 0.9964080459770115\n",
      "\n",
      "Epoch 55. Loss: 0.008592129058561023, Train_acc 0.9964285714285714\n",
      "\n",
      "Epoch 55. Loss: 0.007909009751998302, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 55. Loss: 0.0073333449907880275, Train_acc 0.9964689265536724\n",
      "\n",
      "Epoch 55. Loss: 0.006773657797637395, Train_acc 0.9964887640449438\n",
      "\n",
      "Epoch 55. Loss: 0.006741514858704339, Train_acc 0.9964647346368715\n",
      "\n",
      "Epoch 55. Loss: 0.008061549826355157, Train_acc 0.9964409722222223\n",
      "\n",
      "Epoch 55. Loss: 0.00789535892506663, Train_acc 0.996460635359116\n",
      "\n",
      "Epoch 55. Loss: 0.007139548402863695, Train_acc 0.9964800824175825\n",
      "\n",
      "Epoch 55. Loss: 0.006519884519199316, Train_acc 0.9964993169398907\n",
      "\n",
      "Epoch 55. Loss: 0.006240280672277317, Train_acc 0.9965183423913043\n",
      "\n",
      "Epoch 55. Loss: 0.005772466402212803, Train_acc 0.9965371621621621\n",
      "\n",
      "Epoch 55. Loss: 0.005525160108992479, Train_acc 0.9965557795698925\n",
      "\n",
      "Epoch 55. Loss: 0.0050636187605461675, Train_acc 0.9965741978609626\n",
      "\n",
      "Epoch 55. Loss: 0.00471768388020854, Train_acc 0.996592420212766\n",
      "\n",
      "Epoch 55. Loss: 0.004457469605963178, Train_acc 0.9966104497354498\n",
      "\n",
      "Epoch 55. Loss: 0.004110441161895467, Train_acc 0.9966282894736842\n",
      "\n",
      "Epoch 55. Loss: 0.004269152210612303, Train_acc 0.996645942408377\n",
      "\n",
      "Epoch 55. Loss: 0.004046651398205047, Train_acc 0.9966634114583334\n",
      "\n",
      "Epoch 55. Loss: 0.0038537834939181372, Train_acc 0.9966806994818653\n",
      "\n",
      "Epoch 55. Loss: 0.003772274908846876, Train_acc 0.9966978092783505\n",
      "\n",
      "Epoch 55. Loss: 0.0040895980849202825, Train_acc 0.9966746794871795\n",
      "\n",
      "Epoch 55. Loss: 0.003706596026468361, Train_acc 0.99668\n",
      "\n",
      "Epoch 56. Loss: 0.0033852799078097208, Train_acc 1.0\n",
      "\n",
      "Epoch 56. Loss: 0.0030922605115137488, Train_acc 1.0\n",
      "\n",
      "Epoch 56. Loss: 0.0058723068774904595, Train_acc 0.9921875\n",
      "\n",
      "Epoch 56. Loss: 0.005314058401111435, Train_acc 0.994140625\n",
      "\n",
      "Epoch 56. Loss: 0.005130660961760882, Train_acc 0.9953125\n",
      "\n",
      "Epoch 56. Loss: 0.00464602097260398, Train_acc 0.99609375\n",
      "\n",
      "Epoch 56. Loss: 0.004936402971036216, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 56. Loss: 0.0046946105287480186, Train_acc 0.99609375\n",
      "\n",
      "Epoch 56. Loss: 0.00713083735191892, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 56. Loss: 0.006817658501125012, Train_acc 0.99609375\n",
      "\n",
      "Epoch 56. Loss: 0.006178854770927102, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 56. Loss: 0.0056305722859871865, Train_acc 0.9967447916666666\n",
      "\n",
      "Epoch 56. Loss: 0.005234093904372079, Train_acc 0.9969951923076923\n",
      "\n",
      "Epoch 56. Loss: 0.004722302343230445, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 56. Loss: 0.006068143414659202, Train_acc 0.9963541666666667\n",
      "\n",
      "Epoch 56. Loss: 0.005626229292726874, Train_acc 0.99658203125\n",
      "\n",
      "Epoch 56. Loss: 0.008694376361289346, Train_acc 0.9958639705882353\n",
      "\n",
      "Epoch 56. Loss: 0.007861397774603193, Train_acc 0.99609375\n",
      "\n",
      "Epoch 56. Loss: 0.007186536213497423, Train_acc 0.9962993421052632\n",
      "\n",
      "Epoch 56. Loss: 0.01064825882381806, Train_acc 0.995703125\n",
      "\n",
      "Epoch 56. Loss: 0.009837623910717153, Train_acc 0.9959077380952381\n",
      "\n",
      "Epoch 56. Loss: 0.009256042649548038, Train_acc 0.99609375\n",
      "\n",
      "Epoch 56. Loss: 0.008386607712174535, Train_acc 0.9962635869565217\n",
      "\n",
      "Epoch 56. Loss: 0.008624577443896306, Train_acc 0.99609375\n",
      "\n",
      "Epoch 56. Loss: 0.0077986206118991885, Train_acc 0.99625\n",
      "\n",
      "Epoch 56. Loss: 0.00884002652806618, Train_acc 0.9957932692307693\n",
      "\n",
      "Epoch 56. Loss: 0.008898926235371037, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 56. Loss: 0.00821196626298863, Train_acc 0.9958147321428571\n",
      "\n",
      "Epoch 56. Loss: 0.0074375374666071385, Train_acc 0.9959590517241379\n",
      "\n",
      "Epoch 56. Loss: 0.006797482402452062, Train_acc 0.99609375\n",
      "\n",
      "Epoch 56. Loss: 0.006267854292481301, Train_acc 0.9962197580645161\n",
      "\n",
      "Epoch 56. Loss: 0.007264862554629885, Train_acc 0.99609375\n",
      "\n",
      "Epoch 56. Loss: 0.007769882672900179, Train_acc 0.9959753787878788\n",
      "\n",
      "Epoch 56. Loss: 0.007339597534499365, Train_acc 0.99609375\n",
      "\n",
      "Epoch 56. Loss: 0.006675565147034196, Train_acc 0.9962053571428572\n",
      "\n",
      "Epoch 56. Loss: 0.00614335393531862, Train_acc 0.9963107638888888\n",
      "\n",
      "Epoch 56. Loss: 0.0055939954160600285, Train_acc 0.996410472972973\n",
      "\n",
      "Epoch 56. Loss: 0.0074760654543891, Train_acc 0.9962993421052632\n",
      "\n",
      "Epoch 56. Loss: 0.006826408211239825, Train_acc 0.9963942307692307\n",
      "\n",
      "Epoch 56. Loss: 0.0071301150170105555, Train_acc 0.9962890625\n",
      "\n",
      "Epoch 56. Loss: 0.006714368782309103, Train_acc 0.9963795731707317\n",
      "\n",
      "Epoch 56. Loss: 0.0067546225385672525, Train_acc 0.9964657738095238\n",
      "\n",
      "Epoch 56. Loss: 0.011585549872828126, Train_acc 0.9960029069767442\n",
      "\n",
      "Epoch 56. Loss: 0.010728850152570845, Train_acc 0.99609375\n",
      "\n",
      "Epoch 56. Loss: 0.009767348127457953, Train_acc 0.9961805555555555\n",
      "\n",
      "Epoch 56. Loss: 0.010903782560134044, Train_acc 0.99609375\n",
      "\n",
      "Epoch 56. Loss: 0.010172739077504675, Train_acc 0.9961768617021277\n",
      "\n",
      "Epoch 56. Loss: 0.01290987159213084, Train_acc 0.99609375\n",
      "\n",
      "Epoch 56. Loss: 0.012054272521144075, Train_acc 0.9961734693877551\n",
      "\n",
      "Epoch 56. Loss: 0.012577861461287072, Train_acc 0.99609375\n",
      "\n",
      "Epoch 56. Loss: 0.011524219873096346, Train_acc 0.9961703431372549\n",
      "\n",
      "Epoch 56. Loss: 0.011097027948167144, Train_acc 0.9962439903846154\n",
      "\n",
      "Epoch 56. Loss: 0.013791010833382206, Train_acc 0.9960200471698113\n",
      "\n",
      "Epoch 56. Loss: 0.0128434390894469, Train_acc 0.99609375\n",
      "\n",
      "Epoch 56. Loss: 0.011631711123419975, Train_acc 0.9961647727272728\n",
      "\n",
      "Epoch 56. Loss: 0.010506349679070383, Train_acc 0.9962332589285714\n",
      "\n",
      "Epoch 56. Loss: 0.009708088879648748, Train_acc 0.9962993421052632\n",
      "\n",
      "Epoch 56. Loss: 0.00912575864239535, Train_acc 0.9963631465517241\n",
      "\n",
      "Epoch 56. Loss: 0.01091917125234605, Train_acc 0.9961599576271186\n",
      "\n",
      "Epoch 56. Loss: 0.015037834058847437, Train_acc 0.99609375\n",
      "\n",
      "Epoch 56. Loss: 0.01371557000951893, Train_acc 0.9961577868852459\n",
      "\n",
      "Epoch 56. Loss: 0.013119214161577169, Train_acc 0.99609375\n",
      "\n",
      "Epoch 56. Loss: 0.015064986840792606, Train_acc 0.996031746031746\n",
      "\n",
      "Epoch 56. Loss: 0.013710312805205384, Train_acc 0.99609375\n",
      "\n",
      "Epoch 56. Loss: 0.012433182821762383, Train_acc 0.9961538461538462\n",
      "\n",
      "Epoch 56. Loss: 0.011241626825461303, Train_acc 0.9962121212121212\n",
      "\n",
      "Epoch 56. Loss: 0.010370772684056622, Train_acc 0.996268656716418\n",
      "\n",
      "Epoch 56. Loss: 0.009411848269180862, Train_acc 0.9963235294117647\n",
      "\n",
      "Epoch 56. Loss: 0.009541197600760826, Train_acc 0.9962635869565217\n",
      "\n",
      "Epoch 56. Loss: 0.012392666399000975, Train_acc 0.99609375\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56. Loss: 0.013427325339185201, Train_acc 0.9959286971830986\n",
      "\n",
      "Epoch 56. Loss: 0.012961368096083704, Train_acc 0.9959852430555556\n",
      "\n",
      "Epoch 56. Loss: 0.011833248840572212, Train_acc 0.9960402397260274\n",
      "\n",
      "Epoch 56. Loss: 0.012024622200550235, Train_acc 0.9958826013513513\n",
      "\n",
      "Epoch 56. Loss: 0.011851005719114778, Train_acc 0.9958333333333333\n",
      "\n",
      "Epoch 56. Loss: 0.011811808913358543, Train_acc 0.9957853618421053\n",
      "\n",
      "Epoch 56. Loss: 0.011049972635351265, Train_acc 0.9958400974025974\n",
      "\n",
      "Epoch 56. Loss: 0.010012710142525787, Train_acc 0.9958934294871795\n",
      "\n",
      "Epoch 56. Loss: 0.00935084716086932, Train_acc 0.9959454113924051\n",
      "\n",
      "Epoch 56. Loss: 0.008871988968747985, Train_acc 0.99599609375\n",
      "\n",
      "Epoch 56. Loss: 0.008474494010238169, Train_acc 0.996045524691358\n",
      "\n",
      "Epoch 56. Loss: 0.007725460702019916, Train_acc 0.99609375\n",
      "\n",
      "Epoch 56. Loss: 0.007247332845706928, Train_acc 0.9961408132530121\n",
      "\n",
      "Epoch 56. Loss: 0.0068177364533730045, Train_acc 0.9961867559523809\n",
      "\n",
      "Epoch 56. Loss: 0.00749796638032088, Train_acc 0.9961397058823529\n",
      "\n",
      "Epoch 56. Loss: 0.00768699076748153, Train_acc 0.99609375\n",
      "\n",
      "Epoch 56. Loss: 0.006997784793118108, Train_acc 0.9961386494252874\n",
      "\n",
      "Epoch 56. Loss: 0.006599392473650993, Train_acc 0.9961825284090909\n",
      "\n",
      "Epoch 56. Loss: 0.00598748214846002, Train_acc 0.9962254213483146\n",
      "\n",
      "Epoch 56. Loss: 0.007473917866991284, Train_acc 0.9961805555555555\n",
      "\n",
      "Epoch 56. Loss: 0.008028667962771347, Train_acc 0.9961366758241759\n",
      "\n",
      "Epoch 56. Loss: 0.007343750993602744, Train_acc 0.9961786684782609\n",
      "\n",
      "Epoch 56. Loss: 0.007375589132481758, Train_acc 0.9962197580645161\n",
      "\n",
      "Epoch 56. Loss: 0.006766332267194043, Train_acc 0.9962599734042553\n",
      "\n",
      "Epoch 56. Loss: 0.00620109567449455, Train_acc 0.9962993421052632\n",
      "\n",
      "Epoch 56. Loss: 0.006173748525136392, Train_acc 0.996337890625\n",
      "\n",
      "Epoch 56. Loss: 0.008269817384022785, Train_acc 0.9962145618556701\n",
      "\n",
      "Epoch 56. Loss: 0.010631420390550773, Train_acc 0.99609375\n",
      "\n",
      "Epoch 56. Loss: 0.010447383904526665, Train_acc 0.9961332070707071\n",
      "\n",
      "Epoch 56. Loss: 0.009523983085255355, Train_acc 0.996171875\n",
      "\n",
      "[Epoch 56 Batch 100] Loss: 0.010131217607051608 Training: accuracy=0.996132\n",
      "Epoch 56. Loss: 0.010131217607051608, Train_acc 0.9961324257425742\n",
      "\n",
      "Epoch 56. Loss: 0.011080651418737004, Train_acc 0.99609375\n",
      "\n",
      "Epoch 56. Loss: 0.012222646157179561, Train_acc 0.9960558252427184\n",
      "\n",
      "Epoch 56. Loss: 0.011603271021530885, Train_acc 0.99609375\n",
      "\n",
      "Epoch 56. Loss: 0.01069343534942942, Train_acc 0.9961309523809524\n",
      "\n",
      "Epoch 56. Loss: 0.010871257445989347, Train_acc 0.9961674528301887\n",
      "\n",
      "Epoch 56. Loss: 0.01008863192452785, Train_acc 0.9962032710280374\n",
      "\n",
      "Epoch 56. Loss: 0.009642135295901865, Train_acc 0.9962384259259259\n",
      "\n",
      "Epoch 56. Loss: 0.008865821532335881, Train_acc 0.9962729357798165\n",
      "\n",
      "Epoch 56. Loss: 0.01343792140954167, Train_acc 0.99609375\n",
      "\n",
      "Epoch 56. Loss: 0.013506453503430757, Train_acc 0.9960585585585585\n",
      "\n",
      "Epoch 56. Loss: 0.012337113817679173, Train_acc 0.99609375\n",
      "\n",
      "Epoch 56. Loss: 0.011367780351211684, Train_acc 0.9961283185840708\n",
      "\n",
      "Epoch 56. Loss: 0.010724288400474243, Train_acc 0.9961622807017544\n",
      "\n",
      "Epoch 56. Loss: 0.009897693935227143, Train_acc 0.996195652173913\n",
      "\n",
      "Epoch 56. Loss: 0.00987341808664061, Train_acc 0.996161099137931\n",
      "\n",
      "Epoch 56. Loss: 0.012707595295196094, Train_acc 0.9960603632478633\n",
      "\n",
      "Epoch 56. Loss: 0.012022974710749375, Train_acc 0.99609375\n",
      "\n",
      "Epoch 56. Loss: 0.011554959058988202, Train_acc 0.9961265756302521\n",
      "\n",
      "Epoch 56. Loss: 0.012125806449557639, Train_acc 0.99609375\n",
      "\n",
      "Epoch 56. Loss: 0.011343363654946056, Train_acc 0.9961260330578512\n",
      "\n",
      "Epoch 56. Loss: 0.011763066689522357, Train_acc 0.99609375\n",
      "\n",
      "Epoch 56. Loss: 0.010711464346141777, Train_acc 0.9961255081300813\n",
      "\n",
      "Epoch 56. Loss: 0.011240590306244339, Train_acc 0.99609375\n",
      "\n",
      "Epoch 56. Loss: 0.011761210434545916, Train_acc 0.996\n",
      "\n",
      "Epoch 56. Loss: 0.011046115765341976, Train_acc 0.996031746031746\n",
      "\n",
      "Epoch 56. Loss: 0.011472187508823447, Train_acc 0.9960014763779528\n",
      "\n",
      "Epoch 56. Loss: 0.012858664418472623, Train_acc 0.99591064453125\n",
      "\n",
      "Epoch 56. Loss: 0.011962462643352547, Train_acc 0.9959423449612403\n",
      "\n",
      "Epoch 56. Loss: 0.011066890845433532, Train_acc 0.9959735576923077\n",
      "\n",
      "Epoch 56. Loss: 0.01260694414949625, Train_acc 0.9958850190839694\n",
      "\n",
      "Epoch 56. Loss: 0.012246225574548924, Train_acc 0.9958570075757576\n",
      "\n",
      "Epoch 56. Loss: 0.013939162275733843, Train_acc 0.995829417293233\n",
      "\n",
      "Epoch 56. Loss: 0.014630663743503955, Train_acc 0.9958022388059702\n",
      "\n",
      "Epoch 56. Loss: 0.01333578587915054, Train_acc 0.9958333333333333\n",
      "\n",
      "Epoch 56. Loss: 0.012407938203697363, Train_acc 0.9958639705882353\n",
      "\n",
      "Epoch 56. Loss: 0.011599270048575068, Train_acc 0.9958941605839416\n",
      "\n",
      "Epoch 56. Loss: 0.016675337442311464, Train_acc 0.9958106884057971\n",
      "\n",
      "Epoch 56. Loss: 0.017813746926384703, Train_acc 0.9957846223021583\n",
      "\n",
      "Epoch 56. Loss: 0.016112845820895987, Train_acc 0.9958147321428571\n",
      "\n",
      "Epoch 56. Loss: 0.014654575162943146, Train_acc 0.995844414893617\n",
      "\n",
      "Epoch 56. Loss: 0.013218222865358278, Train_acc 0.9958736795774648\n",
      "\n",
      "Epoch 56. Loss: 0.013331481121982888, Train_acc 0.9958479020979021\n",
      "\n",
      "Epoch 56. Loss: 0.012297588862372122, Train_acc 0.9958767361111112\n",
      "\n",
      "Epoch 56. Loss: 0.012316016616576327, Train_acc 0.9958512931034482\n",
      "\n",
      "Epoch 56. Loss: 0.01712012508108027, Train_acc 0.995826198630137\n",
      "\n",
      "Epoch 56. Loss: 0.016382533124182887, Train_acc 0.9958014455782312\n",
      "\n",
      "Epoch 56. Loss: 0.014907382194558621, Train_acc 0.9958298141891891\n",
      "\n",
      "Epoch 56. Loss: 0.013987067503654815, Train_acc 0.9958578020134228\n",
      "\n",
      "Epoch 56. Loss: 0.014140926055989139, Train_acc 0.99578125\n",
      "\n",
      "Epoch 56. Loss: 0.013086614117739922, Train_acc 0.9958091887417219\n",
      "\n",
      "Epoch 56. Loss: 0.012222342166574293, Train_acc 0.995836759868421\n",
      "\n",
      "Epoch 56. Loss: 0.011071580601242031, Train_acc 0.9958639705882353\n",
      "\n",
      "Epoch 56. Loss: 0.01043500768431143, Train_acc 0.995890827922078\n",
      "\n",
      "Epoch 56. Loss: 0.011134812017870987, Train_acc 0.995866935483871\n",
      "\n",
      "Epoch 56. Loss: 0.010134097344120333, Train_acc 0.9958934294871795\n",
      "\n",
      "Epoch 56. Loss: 0.00918482791183739, Train_acc 0.9959195859872612\n",
      "\n",
      "Epoch 56. Loss: 0.008273179354881078, Train_acc 0.9959454113924051\n",
      "\n",
      "Epoch 56. Loss: 0.008604040017081645, Train_acc 0.9959217767295597\n",
      "\n",
      "Epoch 56. Loss: 0.009398604426103843, Train_acc 0.995947265625\n",
      "\n",
      "Epoch 56. Loss: 0.009238671738268148, Train_acc 0.9959239130434783\n",
      "\n",
      "Epoch 56. Loss: 0.008455294551539014, Train_acc 0.9959490740740741\n",
      "\n",
      "Epoch 56. Loss: 0.00774043762805321, Train_acc 0.9959739263803681\n",
      "\n",
      "Epoch 56. Loss: 0.0073187406226747475, Train_acc 0.9959984756097561\n",
      "\n",
      "Epoch 56. Loss: 0.01657077196521341, Train_acc 0.9958806818181818\n",
      "\n",
      "Epoch 56. Loss: 0.015234107662471645, Train_acc 0.9959054969879518\n",
      "\n",
      "Epoch 56. Loss: 0.016415354696720105, Train_acc 0.9958832335329342\n",
      "\n",
      "Epoch 56. Loss: 0.01484959323825025, Train_acc 0.9959077380952381\n",
      "\n",
      "Epoch 56. Loss: 0.013524534154094011, Train_acc 0.9959319526627219\n",
      "\n",
      "Epoch 56. Loss: 0.012214448508904763, Train_acc 0.9959558823529412\n",
      "\n",
      "Epoch 56. Loss: 0.011539775458159793, Train_acc 0.9959795321637427\n",
      "\n",
      "Epoch 56. Loss: 0.010411183219142667, Train_acc 0.9960029069767442\n",
      "\n",
      "Epoch 56. Loss: 0.012590962810207527, Train_acc 0.9959808526011561\n",
      "\n",
      "Epoch 56. Loss: 0.011422922181779104, Train_acc 0.9960039511494253\n",
      "\n",
      "Epoch 56. Loss: 0.01826297414394673, Train_acc 0.9959375\n",
      "\n",
      "Epoch 56. Loss: 0.01657226272121778, Train_acc 0.9959605823863636\n",
      "\n",
      "Epoch 56. Loss: 0.020204286688825884, Train_acc 0.995895127118644\n",
      "\n",
      "Epoch 56. Loss: 0.018922437939505037, Train_acc 0.995874297752809\n",
      "\n",
      "Epoch 56. Loss: 0.017291461420172682, Train_acc 0.9958973463687151\n",
      "\n",
      "Epoch 56. Loss: 0.016300582971824018, Train_acc 0.9959201388888889\n",
      "\n",
      "Epoch 56. Loss: 0.014865666323515303, Train_acc 0.9959426795580111\n",
      "\n",
      "Epoch 56. Loss: 0.015871001878630393, Train_acc 0.9959220467032966\n",
      "\n",
      "Epoch 56. Loss: 0.015852498873398846, Train_acc 0.9958589480874317\n",
      "\n",
      "Epoch 56. Loss: 0.01461830304446919, Train_acc 0.9958814538043478\n",
      "\n",
      "Epoch 56. Loss: 0.013278599746784001, Train_acc 0.9959037162162162\n",
      "\n",
      "Epoch 56. Loss: 0.014539111145818618, Train_acc 0.9958837365591398\n",
      "\n",
      "Epoch 56. Loss: 0.013376004434139478, Train_acc 0.9959057486631016\n",
      "\n",
      "Epoch 56. Loss: 0.013141887038061871, Train_acc 0.9958859707446809\n",
      "\n",
      "Epoch 56. Loss: 0.012558666833811868, Train_acc 0.9958664021164021\n",
      "\n",
      "Epoch 56. Loss: 0.011521469405694785, Train_acc 0.9958881578947368\n",
      "\n",
      "Epoch 56. Loss: 0.011252226789805874, Train_acc 0.9958687827225131\n",
      "\n",
      "Epoch 56. Loss: 0.01088376689293705, Train_acc 0.9958902994791666\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56. Loss: 0.009953138832051064, Train_acc 0.9959115932642487\n",
      "\n",
      "Epoch 56. Loss: 0.010026645380674456, Train_acc 0.9959326675257731\n",
      "\n",
      "Epoch 56. Loss: 0.009364565694408406, Train_acc 0.9959535256410257\n",
      "\n",
      "Epoch 56. Loss: 0.008433612636023869, Train_acc 0.99596\n",
      "\n",
      "Epoch 57. Loss: 0.007742990288643488, Train_acc 1.0\n",
      "\n",
      "Epoch 57. Loss: 0.007659953566424653, Train_acc 1.0\n",
      "\n",
      "Epoch 57. Loss: 0.007052358379821573, Train_acc 1.0\n",
      "\n",
      "Epoch 57. Loss: 0.006831048648083742, Train_acc 1.0\n",
      "\n",
      "Epoch 57. Loss: 0.006285312745444062, Train_acc 1.0\n",
      "\n",
      "Epoch 57. Loss: 0.005731792798762395, Train_acc 1.0\n",
      "\n",
      "Epoch 57. Loss: 0.005984942697994299, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 57. Loss: 0.00567414607868706, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 57. Loss: 0.005328888761955037, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 57. Loss: 0.005030741649902642, Train_acc 0.99921875\n",
      "\n",
      "Epoch 57. Loss: 0.006288533232840998, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 57. Loss: 0.006822879174113068, Train_acc 0.998046875\n",
      "\n",
      "Epoch 57. Loss: 0.006318047392563337, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 57. Loss: 0.005722115705854689, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 57. Loss: 0.005355039760124977, Train_acc 0.9984375\n",
      "\n",
      "Epoch 57. Loss: 0.005105336889313723, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 57. Loss: 0.004851083079631982, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 57. Loss: 0.004606774439913802, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 57. Loss: 0.004210599780439085, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 57. Loss: 0.003838188903913271, Train_acc 0.998828125\n",
      "\n",
      "Epoch 57. Loss: 0.0035993266353290124, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 57. Loss: 0.0035146109917489447, Train_acc 0.9989346590909091\n",
      "\n",
      "Epoch 57. Loss: 0.0032575840516834193, Train_acc 0.9989809782608695\n",
      "\n",
      "Epoch 57. Loss: 0.00445981297394175, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 57. Loss: 0.004311145139490414, Train_acc 0.99875\n",
      "\n",
      "Epoch 57. Loss: 0.00533360667624013, Train_acc 0.9984975961538461\n",
      "\n",
      "Epoch 57. Loss: 0.004827955649178652, Train_acc 0.9985532407407407\n",
      "\n",
      "Epoch 57. Loss: 0.004440951442295844, Train_acc 0.9986049107142857\n",
      "\n",
      "Epoch 57. Loss: 0.004114886265482338, Train_acc 0.9986530172413793\n",
      "\n",
      "Epoch 57. Loss: 0.003738658614644221, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 57. Loss: 0.006005387295206319, Train_acc 0.9984879032258065\n",
      "\n",
      "Epoch 57. Loss: 0.006411519420671401, Train_acc 0.998291015625\n",
      "\n",
      "Epoch 57. Loss: 0.005806649210049604, Train_acc 0.998342803030303\n",
      "\n",
      "Epoch 57. Loss: 0.005263352152159567, Train_acc 0.9983915441176471\n",
      "\n",
      "Epoch 57. Loss: 0.005480350792587479, Train_acc 0.9982142857142857\n",
      "\n",
      "Epoch 57. Loss: 0.005936532067669047, Train_acc 0.998046875\n",
      "\n",
      "Epoch 57. Loss: 0.005667144543040645, Train_acc 0.9980996621621622\n",
      "\n",
      "Epoch 57. Loss: 0.005422608094908761, Train_acc 0.9981496710526315\n",
      "\n",
      "Epoch 57. Loss: 0.005679194811729759, Train_acc 0.9979967948717948\n",
      "\n",
      "Epoch 57. Loss: 0.005121607283501181, Train_acc 0.998046875\n",
      "\n",
      "Epoch 57. Loss: 0.004695482111310976, Train_acc 0.9980945121951219\n",
      "\n",
      "Epoch 57. Loss: 0.004378529427649991, Train_acc 0.9981398809523809\n",
      "\n",
      "Epoch 57. Loss: 0.0052648188142798095, Train_acc 0.9980014534883721\n",
      "\n",
      "Epoch 57. Loss: 0.005361993555917301, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 57. Loss: 0.004895055338885821, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 57. Loss: 0.004485488603441584, Train_acc 0.9979619565217391\n",
      "\n",
      "Epoch 57. Loss: 0.004321726521599592, Train_acc 0.9980053191489362\n",
      "\n",
      "Epoch 57. Loss: 0.004444669621361764, Train_acc 0.998046875\n",
      "\n",
      "Epoch 57. Loss: 0.0040646690639541795, Train_acc 0.9980867346938775\n",
      "\n",
      "Epoch 57. Loss: 0.0038240402538495884, Train_acc 0.998125\n",
      "\n",
      "Epoch 57. Loss: 0.003484462753633123, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 57. Loss: 0.0033981624557371097, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 57. Loss: 0.005737298948806091, Train_acc 0.9980837264150944\n",
      "\n",
      "Epoch 57. Loss: 0.005239634545810429, Train_acc 0.9981192129629629\n",
      "\n",
      "Epoch 57. Loss: 0.004759636498760164, Train_acc 0.9981534090909091\n",
      "\n",
      "Epoch 57. Loss: 0.004544880635272842, Train_acc 0.9981863839285714\n",
      "\n",
      "Epoch 57. Loss: 0.004104823899618002, Train_acc 0.9982182017543859\n",
      "\n",
      "Epoch 57. Loss: 0.004160315348819982, Train_acc 0.9982489224137931\n",
      "\n",
      "Epoch 57. Loss: 0.0038685805112602632, Train_acc 0.9982786016949152\n",
      "\n",
      "Epoch 57. Loss: 0.007430748851044385, Train_acc 0.9981770833333333\n",
      "\n",
      "Epoch 57. Loss: 0.007583711056509681, Train_acc 0.9980788934426229\n",
      "\n",
      "Epoch 57. Loss: 0.007018873356985957, Train_acc 0.9981098790322581\n",
      "\n",
      "Epoch 57. Loss: 0.006381293228063355, Train_acc 0.9981398809523809\n",
      "\n",
      "Epoch 57. Loss: 0.005859941185602579, Train_acc 0.9981689453125\n",
      "\n",
      "Epoch 57. Loss: 0.006738580896934004, Train_acc 0.9979567307692307\n",
      "\n",
      "Epoch 57. Loss: 0.007045209621173261, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 57. Loss: 0.006463631876922058, Train_acc 0.9979011194029851\n",
      "\n",
      "Epoch 57. Loss: 0.005858767934210365, Train_acc 0.9979319852941176\n",
      "\n",
      "Epoch 57. Loss: 0.005300068577066599, Train_acc 0.9979619565217391\n",
      "\n",
      "Epoch 57. Loss: 0.004801071690640522, Train_acc 0.9979910714285715\n",
      "\n",
      "Epoch 57. Loss: 0.004985475239191955, Train_acc 0.9979093309859155\n",
      "\n",
      "Epoch 57. Loss: 0.004518835513529484, Train_acc 0.9979383680555556\n",
      "\n",
      "Epoch 57. Loss: 0.00410053403103986, Train_acc 0.997966609589041\n",
      "\n",
      "Epoch 57. Loss: 0.00372911749372867, Train_acc 0.9979940878378378\n",
      "\n",
      "Epoch 57. Loss: 0.004552131218522673, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 57. Loss: 0.004460295997464554, Train_acc 0.9979440789473685\n",
      "\n",
      "Epoch 57. Loss: 0.005008932784113792, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 57. Loss: 0.004837343992215551, Train_acc 0.9978966346153846\n",
      "\n",
      "Epoch 57. Loss: 0.005754802381028674, Train_acc 0.9977254746835443\n",
      "\n",
      "Epoch 57. Loss: 0.005491111338910408, Train_acc 0.99775390625\n",
      "\n",
      "Epoch 57. Loss: 0.008111746156910314, Train_acc 0.9976851851851852\n",
      "\n",
      "Epoch 57. Loss: 0.007708913742481995, Train_acc 0.9977134146341463\n",
      "\n",
      "Epoch 57. Loss: 0.007122603471037145, Train_acc 0.9977409638554217\n",
      "\n",
      "Epoch 57. Loss: 0.007597948721012231, Train_acc 0.9976748511904762\n",
      "\n",
      "Epoch 57. Loss: 0.006865119295797614, Train_acc 0.9977022058823529\n",
      "\n",
      "Epoch 57. Loss: 0.00712339947296548, Train_acc 0.9976380813953488\n",
      "\n",
      "Epoch 57. Loss: 0.006647668056063665, Train_acc 0.9976652298850575\n",
      "\n",
      "Epoch 57. Loss: 0.008225253318881524, Train_acc 0.9976029829545454\n",
      "\n",
      "Epoch 57. Loss: 0.007541493327664315, Train_acc 0.9976299157303371\n",
      "\n",
      "Epoch 57. Loss: 0.0104847765725079, Train_acc 0.9975694444444444\n",
      "\n",
      "Epoch 57. Loss: 0.009680986063626959, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 57. Loss: 0.012732778182876905, Train_acc 0.9975373641304348\n",
      "\n",
      "Epoch 57. Loss: 0.01182363375425589, Train_acc 0.9975638440860215\n",
      "\n",
      "Epoch 57. Loss: 0.010690178027136642, Train_acc 0.9975897606382979\n",
      "\n",
      "Epoch 57. Loss: 0.009658847714535127, Train_acc 0.9976151315789473\n",
      "\n",
      "Epoch 57. Loss: 0.008888235675607679, Train_acc 0.9976399739583334\n",
      "\n",
      "Epoch 57. Loss: 0.011165208507163427, Train_acc 0.9975032216494846\n",
      "\n",
      "Epoch 57. Loss: 0.010078533413391353, Train_acc 0.9975286989795918\n",
      "\n",
      "Epoch 57. Loss: 0.011679317770046927, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 57. Loss: 0.011539895803609137, Train_acc 0.99734375\n",
      "\n",
      "[Epoch 57 Batch 100] Loss: 0.010772035403217655 Training: accuracy=0.997370\n",
      "Epoch 57. Loss: 0.010772035403217655, Train_acc 0.9973700495049505\n",
      "\n",
      "Epoch 57. Loss: 0.016477952197044295, Train_acc 0.9972426470588235\n",
      "\n",
      "Epoch 57. Loss: 0.017200534607335213, Train_acc 0.9971935679611651\n",
      "\n",
      "Epoch 57. Loss: 0.01745320713403608, Train_acc 0.9971454326923077\n",
      "\n",
      "Epoch 57. Loss: 0.015881099415919503, Train_acc 0.997172619047619\n",
      "\n",
      "Epoch 57. Loss: 0.014522163931817997, Train_acc 0.9971992924528302\n",
      "\n",
      "Epoch 57. Loss: 0.014809124832711688, Train_acc 0.9971524532710281\n",
      "\n",
      "Epoch 57. Loss: 0.02080307960393614, Train_acc 0.9970341435185185\n",
      "\n",
      "Epoch 57. Loss: 0.01902312082226652, Train_acc 0.9970613532110092\n",
      "\n",
      "Epoch 57. Loss: 0.0205698508814774, Train_acc 0.9969460227272727\n",
      "\n",
      "Epoch 57. Loss: 0.02310028847716469, Train_acc 0.9968327702702703\n",
      "\n",
      "Epoch 57. Loss: 0.021949823569466637, Train_acc 0.9968610491071429\n",
      "\n",
      "Epoch 57. Loss: 0.023250255767592758, Train_acc 0.9966814159292036\n",
      "\n",
      "Epoch 57. Loss: 0.021062779422128027, Train_acc 0.9967105263157895\n",
      "\n",
      "Epoch 57. Loss: 0.019091185392535175, Train_acc 0.9967391304347826\n",
      "\n",
      "Epoch 57. Loss: 0.02107159775042216, Train_acc 0.9966325431034483\n",
      "\n",
      "Epoch 57. Loss: 0.01903510361241114, Train_acc 0.9966613247863247\n",
      "\n",
      "Epoch 57. Loss: 0.017622260363341677, Train_acc 0.9966896186440678\n",
      "\n",
      "Epoch 57. Loss: 0.02758322189281104, Train_acc 0.9964548319327731\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57. Loss: 0.025556517055523854, Train_acc 0.996484375\n",
      "\n",
      "Epoch 57. Loss: 0.026086852992378885, Train_acc 0.9963842975206612\n",
      "\n",
      "Epoch 57. Loss: 0.023906775659891858, Train_acc 0.9964139344262295\n",
      "\n",
      "Epoch 57. Loss: 0.02455143743447026, Train_acc 0.9963795731707317\n",
      "\n",
      "Epoch 57. Loss: 0.027768277648313883, Train_acc 0.9962827620967742\n",
      "\n",
      "Epoch 57. Loss: 0.025277188846184948, Train_acc 0.9963125\n",
      "\n",
      "Epoch 57. Loss: 0.023135018438627544, Train_acc 0.9963417658730159\n",
      "\n",
      "Epoch 57. Loss: 0.020930735773322186, Train_acc 0.9963705708661418\n",
      "\n",
      "Epoch 57. Loss: 0.01958115181533444, Train_acc 0.99639892578125\n",
      "\n",
      "Epoch 57. Loss: 0.018674421775710118, Train_acc 0.9964268410852714\n",
      "\n",
      "Epoch 57. Loss: 0.018135260445658743, Train_acc 0.9963341346153847\n",
      "\n",
      "Epoch 57. Loss: 0.022034250634417874, Train_acc 0.9962428435114504\n",
      "\n",
      "Epoch 57. Loss: 0.020261112013837047, Train_acc 0.9962713068181818\n",
      "\n",
      "Epoch 57. Loss: 0.018912753307265353, Train_acc 0.9962993421052632\n",
      "\n",
      "Epoch 57. Loss: 0.018356060152598302, Train_acc 0.996268656716418\n",
      "\n",
      "Epoch 57. Loss: 0.01952288463593848, Train_acc 0.9962384259259259\n",
      "\n",
      "Epoch 57. Loss: 0.01851839775485987, Train_acc 0.9962086397058824\n",
      "\n",
      "Epoch 57. Loss: 0.016714349792641282, Train_acc 0.9962363138686131\n",
      "\n",
      "Epoch 57. Loss: 0.01579807418397833, Train_acc 0.9962635869565217\n",
      "\n",
      "Epoch 57. Loss: 0.014434650694944881, Train_acc 0.9962904676258992\n",
      "\n",
      "Epoch 57. Loss: 0.013149423919984778, Train_acc 0.9963169642857143\n",
      "\n",
      "Epoch 57. Loss: 0.012214425934436094, Train_acc 0.996343085106383\n",
      "\n",
      "Epoch 57. Loss: 0.013025338001324688, Train_acc 0.9963138204225352\n",
      "\n",
      "Epoch 57. Loss: 0.01834227998310979, Train_acc 0.9961756993006993\n",
      "\n",
      "Epoch 57. Loss: 0.016805027587194644, Train_acc 0.9962022569444444\n",
      "\n",
      "Epoch 57. Loss: 0.015434741393160286, Train_acc 0.9962284482758621\n",
      "\n",
      "Epoch 57. Loss: 0.015062226298092122, Train_acc 0.9962007705479452\n",
      "\n",
      "Epoch 57. Loss: 0.014713646196697636, Train_acc 0.9962266156462585\n",
      "\n",
      "Epoch 57. Loss: 0.01466888894740446, Train_acc 0.9961993243243243\n",
      "\n",
      "Epoch 57. Loss: 0.013965056898999545, Train_acc 0.9962248322147651\n",
      "\n",
      "Epoch 57. Loss: 0.014406543690986932, Train_acc 0.9961979166666667\n",
      "\n",
      "Epoch 57. Loss: 0.013813330931837113, Train_acc 0.996171357615894\n",
      "\n",
      "Epoch 57. Loss: 0.012612900496683793, Train_acc 0.9961965460526315\n",
      "\n",
      "Epoch 57. Loss: 0.011905061040740262, Train_acc 0.9962214052287581\n",
      "\n",
      "Epoch 57. Loss: 0.011369217989076122, Train_acc 0.9962459415584416\n",
      "\n",
      "Epoch 57. Loss: 0.011451421747859368, Train_acc 0.9962197580645161\n",
      "\n",
      "Epoch 57. Loss: 0.010849935633545563, Train_acc 0.9962439903846154\n",
      "\n",
      "Epoch 57. Loss: 0.009982687988971572, Train_acc 0.9962679140127388\n",
      "\n",
      "Epoch 57. Loss: 0.009353845728310854, Train_acc 0.9962915348101266\n",
      "\n",
      "Epoch 57. Loss: 0.008816358806898811, Train_acc 0.996314858490566\n",
      "\n",
      "Epoch 57. Loss: 0.00836247244637664, Train_acc 0.996337890625\n",
      "\n",
      "Epoch 57. Loss: 0.012637539930595063, Train_acc 0.9962635869565217\n",
      "\n",
      "Epoch 57. Loss: 0.01195753482948521, Train_acc 0.9962866512345679\n",
      "\n",
      "Epoch 57. Loss: 0.011293995410687738, Train_acc 0.9963094325153374\n",
      "\n",
      "Epoch 57. Loss: 0.014888500896531655, Train_acc 0.9962842987804879\n",
      "\n",
      "Epoch 57. Loss: 0.017006195986960813, Train_acc 0.9962121212121212\n",
      "\n",
      "Epoch 57. Loss: 0.020246367443824846, Train_acc 0.9961408132530121\n",
      "\n",
      "Epoch 57. Loss: 0.018405263202875888, Train_acc 0.9961639221556886\n",
      "\n",
      "Epoch 57. Loss: 0.01791582982464734, Train_acc 0.9961402529761905\n",
      "\n",
      "Epoch 57. Loss: 0.018654288737989397, Train_acc 0.9961168639053254\n",
      "\n",
      "Epoch 57. Loss: 0.02130688523264253, Train_acc 0.9960477941176471\n",
      "\n",
      "Epoch 57. Loss: 0.021197633847697295, Train_acc 0.9960252192982456\n",
      "\n",
      "Epoch 57. Loss: 0.019384322947728978, Train_acc 0.9960483284883721\n",
      "\n",
      "Epoch 57. Loss: 0.017703299621129046, Train_acc 0.9960711705202312\n",
      "\n",
      "Epoch 57. Loss: 0.017329412795052537, Train_acc 0.9960488505747126\n",
      "\n",
      "Epoch 57. Loss: 0.023226210263620862, Train_acc 0.9958928571428571\n",
      "\n",
      "Epoch 57. Loss: 0.025297275591419085, Train_acc 0.9958274147727273\n",
      "\n",
      "Epoch 57. Loss: 0.022813670109314756, Train_acc 0.995850988700565\n",
      "\n",
      "Epoch 57. Loss: 0.020639635626952087, Train_acc 0.995874297752809\n",
      "\n",
      "Epoch 57. Loss: 0.022983515266609404, Train_acc 0.9957664106145251\n",
      "\n",
      "Epoch 57. Loss: 0.02452536732318897, Train_acc 0.995703125\n",
      "\n",
      "Epoch 57. Loss: 0.023446425031389884, Train_acc 0.9956837016574586\n",
      "\n",
      "Epoch 57. Loss: 0.022355415170579637, Train_acc 0.9957074175824175\n",
      "\n",
      "Epoch 57. Loss: 0.020753432191332716, Train_acc 0.9957308743169399\n",
      "\n",
      "Epoch 57. Loss: 0.023652425894368178, Train_acc 0.9956691576086957\n",
      "\n",
      "Epoch 57. Loss: 0.02309368777057095, Train_acc 0.9956503378378379\n",
      "\n",
      "Epoch 57. Loss: 0.02372229321551827, Train_acc 0.9955897177419355\n",
      "\n",
      "Epoch 57. Loss: 0.032644074175529246, Train_acc 0.9954879679144385\n",
      "\n",
      "Epoch 57. Loss: 0.029653063647655457, Train_acc 0.9955119680851063\n",
      "\n",
      "Epoch 57. Loss: 0.02833633458558423, Train_acc 0.9954943783068783\n",
      "\n",
      "Epoch 57. Loss: 0.025990258040893402, Train_acc 0.9955180921052632\n",
      "\n",
      "Epoch 57. Loss: 0.033078675314368304, Train_acc 0.995377945026178\n",
      "\n",
      "Epoch 57. Loss: 0.03183654458336368, Train_acc 0.995361328125\n",
      "\n",
      "Epoch 57. Loss: 0.028963634237384808, Train_acc 0.9953853626943006\n",
      "\n",
      "Epoch 57. Loss: 0.02828502870178462, Train_acc 0.9953688788659794\n",
      "\n",
      "Epoch 57. Loss: 0.026473955324973833, Train_acc 0.9953525641025641\n",
      "\n",
      "Epoch 57. Loss: 0.030255774568038737, Train_acc 0.99532\n",
      "\n",
      "Epoch 58. Loss: 0.027475578583867153, Train_acc 1.0\n",
      "\n",
      "Epoch 58. Loss: 0.02550586413376701, Train_acc 1.0\n",
      "\n",
      "Epoch 58. Loss: 0.024714441383181563, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 58. Loss: 0.023152990669875043, Train_acc 0.998046875\n",
      "\n",
      "Epoch 58. Loss: 0.022960649793626695, Train_acc 0.996875\n",
      "\n",
      "Epoch 58. Loss: 0.02432841229314968, Train_acc 0.99609375\n",
      "\n",
      "Epoch 58. Loss: 0.022729873947429938, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 58. Loss: 0.023558958694751518, Train_acc 0.994140625\n",
      "\n",
      "Epoch 58. Loss: 0.022764174502714386, Train_acc 0.9939236111111112\n",
      "\n",
      "Epoch 58. Loss: 0.025342247660419863, Train_acc 0.9921875\n",
      "\n",
      "Epoch 58. Loss: 0.02486115144979494, Train_acc 0.9921875\n",
      "\n",
      "Epoch 58. Loss: 0.023168589727951917, Train_acc 0.9928385416666666\n",
      "\n",
      "Epoch 58. Loss: 0.022492945766634197, Train_acc 0.9927884615384616\n",
      "\n",
      "Epoch 58. Loss: 0.02241293578701, Train_acc 0.9927455357142857\n",
      "\n",
      "Epoch 58. Loss: 0.023198331424803563, Train_acc 0.9927083333333333\n",
      "\n",
      "Epoch 58. Loss: 0.02194233557958397, Train_acc 0.9931640625\n",
      "\n",
      "Epoch 58. Loss: 0.02049579539824122, Train_acc 0.9931066176470589\n",
      "\n",
      "Epoch 58. Loss: 0.02027189066793257, Train_acc 0.9930555555555556\n",
      "\n",
      "Epoch 58. Loss: 0.021395136393181094, Train_acc 0.9925986842105263\n",
      "\n",
      "Epoch 58. Loss: 0.021195987517003665, Train_acc 0.9921875\n",
      "\n",
      "Epoch 58. Loss: 0.019811969407079622, Train_acc 0.9925595238095238\n",
      "\n",
      "Epoch 58. Loss: 0.02027954994828523, Train_acc 0.9925426136363636\n",
      "\n",
      "Epoch 58. Loss: 0.020057024859109707, Train_acc 0.9925271739130435\n",
      "\n",
      "Epoch 58. Loss: 0.019644869873868695, Train_acc 0.9925130208333334\n",
      "\n",
      "Epoch 58. Loss: 0.021059637302113122, Train_acc 0.9921875\n",
      "\n",
      "Epoch 58. Loss: 0.025997342944698826, Train_acc 0.9918870192307693\n",
      "\n",
      "Epoch 58. Loss: 0.027256070253751246, Train_acc 0.9916087962962963\n",
      "\n",
      "Epoch 58. Loss: 0.024610694153608295, Train_acc 0.9919084821428571\n",
      "\n",
      "Epoch 58. Loss: 0.022504885697142554, Train_acc 0.9921875\n",
      "\n",
      "Epoch 58. Loss: 0.020753568099462636, Train_acc 0.9924479166666667\n",
      "\n",
      "Epoch 58. Loss: 0.02362901853310196, Train_acc 0.9921875\n",
      "\n",
      "Epoch 58. Loss: 0.027952738584164936, Train_acc 0.991943359375\n",
      "\n",
      "Epoch 58. Loss: 0.02708315277643576, Train_acc 0.9919507575757576\n",
      "\n",
      "Epoch 58. Loss: 0.024897286040388718, Train_acc 0.9921875\n",
      "\n",
      "Epoch 58. Loss: 0.022699849836613096, Train_acc 0.9924107142857143\n",
      "\n",
      "Epoch 58. Loss: 0.02326812609218242, Train_acc 0.9921875\n",
      "\n",
      "Epoch 58. Loss: 0.02259155356898322, Train_acc 0.9923986486486487\n",
      "\n",
      "Epoch 58. Loss: 0.020473120517598815, Train_acc 0.9925986842105263\n",
      "\n",
      "Epoch 58. Loss: 0.01862670410497537, Train_acc 0.9927884615384616\n",
      "\n",
      "Epoch 58. Loss: 0.017046827419387258, Train_acc 0.99296875\n",
      "\n",
      "Epoch 58. Loss: 0.015468923023469262, Train_acc 0.993140243902439\n",
      "\n",
      "Epoch 58. Loss: 0.014777305498981786, Train_acc 0.9933035714285714\n",
      "\n",
      "Epoch 58. Loss: 0.017823275797305384, Train_acc 0.9932776162790697\n",
      "\n",
      "Epoch 58. Loss: 0.01683658109775592, Train_acc 0.9934303977272727\n",
      "\n",
      "Epoch 58. Loss: 0.015649123972324215, Train_acc 0.9935763888888889\n",
      "\n",
      "Epoch 58. Loss: 0.015399753233642295, Train_acc 0.9937160326086957\n",
      "\n",
      "Epoch 58. Loss: 0.01403622967295058, Train_acc 0.9938497340425532\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58. Loss: 0.013488146631051964, Train_acc 0.9939778645833334\n",
      "\n",
      "Epoch 58. Loss: 0.01411417988073516, Train_acc 0.993781887755102\n",
      "\n",
      "Epoch 58. Loss: 0.014316705171451165, Train_acc 0.99359375\n",
      "\n",
      "Epoch 58. Loss: 0.015113288734124774, Train_acc 0.9935661764705882\n",
      "\n",
      "Epoch 58. Loss: 0.014423647886902102, Train_acc 0.9936899038461539\n",
      "\n",
      "Epoch 58. Loss: 0.013562812229371078, Train_acc 0.9938089622641509\n",
      "\n",
      "Epoch 58. Loss: 0.012316321400050975, Train_acc 0.9939236111111112\n",
      "\n",
      "Epoch 58. Loss: 0.011174654386290228, Train_acc 0.9940340909090909\n",
      "\n",
      "Epoch 58. Loss: 0.010690826927287862, Train_acc 0.994140625\n",
      "\n",
      "Epoch 58. Loss: 0.010840744715628164, Train_acc 0.9942434210526315\n",
      "\n",
      "Epoch 58. Loss: 0.009855599658590977, Train_acc 0.9943426724137931\n",
      "\n",
      "Epoch 58. Loss: 0.009128994120868227, Train_acc 0.9944385593220338\n",
      "\n",
      "Epoch 58. Loss: 0.009468853491138381, Train_acc 0.9944010416666667\n",
      "\n",
      "Epoch 58. Loss: 0.010891015098325279, Train_acc 0.9941086065573771\n",
      "\n",
      "Epoch 58. Loss: 0.009960905229857743, Train_acc 0.9942036290322581\n",
      "\n",
      "Epoch 58. Loss: 0.009350611404682262, Train_acc 0.9942956349206349\n",
      "\n",
      "Epoch 58. Loss: 0.008581058986634816, Train_acc 0.994384765625\n",
      "\n",
      "Epoch 58. Loss: 0.008801405816660052, Train_acc 0.9943509615384616\n",
      "\n",
      "Epoch 58. Loss: 0.008658701537000291, Train_acc 0.994436553030303\n",
      "\n",
      "Epoch 58. Loss: 0.010965415261340577, Train_acc 0.9944029850746269\n",
      "\n",
      "Epoch 58. Loss: 0.01020426676633427, Train_acc 0.9944852941176471\n",
      "\n",
      "Epoch 58. Loss: 0.009423830881006744, Train_acc 0.9945652173913043\n",
      "\n",
      "Epoch 58. Loss: 0.008563593179747218, Train_acc 0.9946428571428572\n",
      "\n",
      "Epoch 58. Loss: 0.007822674112146873, Train_acc 0.9947183098591549\n",
      "\n",
      "Epoch 58. Loss: 0.007150824899096739, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 58. Loss: 0.007213608308913814, Train_acc 0.9948630136986302\n",
      "\n",
      "Epoch 58. Loss: 0.006507558578309795, Train_acc 0.9949324324324325\n",
      "\n",
      "Epoch 58. Loss: 0.006109011229961259, Train_acc 0.995\n",
      "\n",
      "Epoch 58. Loss: 0.006284124380727837, Train_acc 0.9949629934210527\n",
      "\n",
      "Epoch 58. Loss: 0.005852765736472812, Train_acc 0.9950284090909091\n",
      "\n",
      "Epoch 58. Loss: 0.005351166889623291, Train_acc 0.9950921474358975\n",
      "\n",
      "Epoch 58. Loss: 0.006544799289603967, Train_acc 0.9950553797468354\n",
      "\n",
      "Epoch 58. Loss: 0.005965394711112549, Train_acc 0.9951171875\n",
      "\n",
      "Epoch 58. Loss: 0.005426884442047166, Train_acc 0.9951774691358025\n",
      "\n",
      "Epoch 58. Loss: 0.0052627456556045, Train_acc 0.9952362804878049\n",
      "\n",
      "Epoch 58. Loss: 0.004839003325949578, Train_acc 0.9952936746987951\n",
      "\n",
      "Epoch 58. Loss: 0.004617502476826729, Train_acc 0.9953497023809523\n",
      "\n",
      "Epoch 58. Loss: 0.005834388154198606, Train_acc 0.9952205882352941\n",
      "\n",
      "Epoch 58. Loss: 0.0052845334070752235, Train_acc 0.9952761627906976\n",
      "\n",
      "Epoch 58. Loss: 0.004925177337649927, Train_acc 0.9953304597701149\n",
      "\n",
      "Epoch 58. Loss: 0.0045737137279906566, Train_acc 0.9953835227272727\n",
      "\n",
      "Epoch 58. Loss: 0.004177681908404338, Train_acc 0.995435393258427\n",
      "\n",
      "Epoch 58. Loss: 0.005287255638446368, Train_acc 0.9953993055555556\n",
      "\n",
      "Epoch 58. Loss: 0.005159096244593821, Train_acc 0.9954498626373627\n",
      "\n",
      "Epoch 58. Loss: 0.004869468412991192, Train_acc 0.995499320652174\n",
      "\n",
      "Epoch 58. Loss: 0.004409448182427318, Train_acc 0.9955477150537635\n",
      "\n",
      "Epoch 58. Loss: 0.004137223054011999, Train_acc 0.995595079787234\n",
      "\n",
      "Epoch 58. Loss: 0.003962403196356003, Train_acc 0.9956414473684211\n",
      "\n",
      "Epoch 58. Loss: 0.0037237509334747242, Train_acc 0.9956868489583334\n",
      "\n",
      "Epoch 58. Loss: 0.0035269857686830385, Train_acc 0.9957313144329897\n",
      "\n",
      "Epoch 58. Loss: 0.003319527552685692, Train_acc 0.9957748724489796\n",
      "\n",
      "Epoch 58. Loss: 0.004345033422405917, Train_acc 0.9957386363636364\n",
      "\n",
      "Epoch 58. Loss: 0.003998313594920172, Train_acc 0.99578125\n",
      "\n",
      "[Epoch 58 Batch 100] Loss: 0.0036562573784964386 Training: accuracy=0.995823\n",
      "Epoch 58. Loss: 0.0036562573784964386, Train_acc 0.9958230198019802\n",
      "\n",
      "Epoch 58. Loss: 0.0033486346667075547, Train_acc 0.9958639705882353\n",
      "\n",
      "Epoch 58. Loss: 0.0030845630603806877, Train_acc 0.9959041262135923\n",
      "\n",
      "Epoch 58. Loss: 0.003973379479745928, Train_acc 0.9958683894230769\n",
      "\n",
      "Epoch 58. Loss: 0.003793090821266088, Train_acc 0.9959077380952381\n",
      "\n",
      "Epoch 58. Loss: 0.0035070019541974333, Train_acc 0.9959463443396226\n",
      "\n",
      "Epoch 58. Loss: 0.0031839285465556804, Train_acc 0.9959842289719626\n",
      "\n",
      "Epoch 58. Loss: 0.003344691563917258, Train_acc 0.9960214120370371\n",
      "\n",
      "Epoch 58. Loss: 0.0034458812312242915, Train_acc 0.9960579128440367\n",
      "\n",
      "Epoch 58. Loss: 0.003211815695885497, Train_acc 0.99609375\n",
      "\n",
      "Epoch 58. Loss: 0.002948486831073398, Train_acc 0.9961289414414415\n",
      "\n",
      "Epoch 58. Loss: 0.0027572359798783974, Train_acc 0.9961635044642857\n",
      "\n",
      "Epoch 58. Loss: 0.0026354751840324624, Train_acc 0.9961974557522124\n",
      "\n",
      "Epoch 58. Loss: 0.002395272559627217, Train_acc 0.9962308114035088\n",
      "\n",
      "Epoch 58. Loss: 0.002273705107566108, Train_acc 0.9962635869565217\n",
      "\n",
      "Epoch 58. Loss: 0.0022020071675000097, Train_acc 0.9962957974137931\n",
      "\n",
      "Epoch 58. Loss: 0.002050350575701595, Train_acc 0.9963274572649573\n",
      "\n",
      "Epoch 58. Loss: 0.009553570719709576, Train_acc 0.996292372881356\n",
      "\n",
      "Epoch 58. Loss: 0.008979166490272207, Train_acc 0.9963235294117647\n",
      "\n",
      "Epoch 58. Loss: 0.008273932612257173, Train_acc 0.9963541666666667\n",
      "\n",
      "Epoch 58. Loss: 0.00783197823470858, Train_acc 0.9963842975206612\n",
      "\n",
      "Epoch 58. Loss: 0.00716282097691471, Train_acc 0.9964139344262295\n",
      "\n",
      "Epoch 58. Loss: 0.006488907959115763, Train_acc 0.9964430894308943\n",
      "\n",
      "Epoch 58. Loss: 0.0064453904340138375, Train_acc 0.9964717741935484\n",
      "\n",
      "Epoch 58. Loss: 0.006377118362960548, Train_acc 0.9964375\n",
      "\n",
      "Epoch 58. Loss: 0.005864650274271367, Train_acc 0.9964657738095238\n",
      "\n",
      "Epoch 58. Loss: 0.005321038154635032, Train_acc 0.9964936023622047\n",
      "\n",
      "Epoch 58. Loss: 0.0048562355035527355, Train_acc 0.99652099609375\n",
      "\n",
      "Epoch 58. Loss: 0.004403791632500892, Train_acc 0.9965479651162791\n",
      "\n",
      "Epoch 58. Loss: 0.004461262173948531, Train_acc 0.9965745192307692\n",
      "\n",
      "Epoch 58. Loss: 0.004158375277740816, Train_acc 0.9966006679389313\n",
      "\n",
      "Epoch 58. Loss: 0.0037730933667981417, Train_acc 0.9966264204545454\n",
      "\n",
      "Epoch 58. Loss: 0.003413769316949718, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 58. Loss: 0.00313479396634469, Train_acc 0.9966767723880597\n",
      "\n",
      "Epoch 58. Loss: 0.0037249806822821758, Train_acc 0.9966435185185185\n",
      "\n",
      "Epoch 58. Loss: 0.0033833004593081632, Train_acc 0.9966681985294118\n",
      "\n",
      "Epoch 58. Loss: 0.0034680037160272027, Train_acc 0.9966925182481752\n",
      "\n",
      "Epoch 58. Loss: 0.0043217634522516694, Train_acc 0.9966598731884058\n",
      "\n",
      "Epoch 58. Loss: 0.009292881148779318, Train_acc 0.9966276978417267\n",
      "\n",
      "Epoch 58. Loss: 0.008404363478221901, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 58. Loss: 0.007660475479064948, Train_acc 0.9966755319148937\n",
      "\n",
      "Epoch 58. Loss: 0.006918641599233844, Train_acc 0.9966989436619719\n",
      "\n",
      "Epoch 58. Loss: 0.006251283929755224, Train_acc 0.996722027972028\n",
      "\n",
      "Epoch 58. Loss: 0.007912138577708543, Train_acc 0.9966905381944444\n",
      "\n",
      "Epoch 58. Loss: 0.00801328355199898, Train_acc 0.9966594827586207\n",
      "\n",
      "Epoch 58. Loss: 0.007464748367310805, Train_acc 0.9966823630136986\n",
      "\n",
      "Epoch 58. Loss: 0.0070143304298218275, Train_acc 0.9967049319727891\n",
      "\n",
      "Epoch 58. Loss: 0.006382561502857166, Train_acc 0.9967271959459459\n",
      "\n",
      "Epoch 58. Loss: 0.005843465525548003, Train_acc 0.9967491610738255\n",
      "\n",
      "Epoch 58. Loss: 0.005480345244235106, Train_acc 0.9967708333333334\n",
      "\n",
      "Epoch 58. Loss: 0.005290534448647178, Train_acc 0.9967922185430463\n",
      "\n",
      "Epoch 58. Loss: 0.004802632714102724, Train_acc 0.996813322368421\n",
      "\n",
      "Epoch 58. Loss: 0.005859680706074887, Train_acc 0.9967830882352942\n",
      "\n",
      "Epoch 58. Loss: 0.005324174387574765, Train_acc 0.9968039772727273\n",
      "\n",
      "Epoch 58. Loss: 0.004817665178689873, Train_acc 0.9968245967741935\n",
      "\n",
      "Epoch 58. Loss: 0.004361796427866421, Train_acc 0.9968449519230769\n",
      "\n",
      "Epoch 58. Loss: 0.004270434288435223, Train_acc 0.9968650477707006\n",
      "\n",
      "Epoch 58. Loss: 0.003920065733299517, Train_acc 0.9968848892405063\n",
      "\n",
      "Epoch 58. Loss: 0.0035700137401983413, Train_acc 0.9969044811320755\n",
      "\n",
      "Epoch 58. Loss: 0.003935935961636776, Train_acc 0.996875\n",
      "\n",
      "Epoch 58. Loss: 0.0035852520752098034, Train_acc 0.9968944099378882\n",
      "\n",
      "Epoch 58. Loss: 0.00503034814490192, Train_acc 0.9968171296296297\n",
      "\n",
      "Epoch 58. Loss: 0.004690609183829095, Train_acc 0.9968366564417178\n",
      "\n",
      "Epoch 58. Loss: 0.004526695012714923, Train_acc 0.9968559451219512\n",
      "\n",
      "Epoch 58. Loss: 0.004240805058441871, Train_acc 0.996875\n",
      "\n",
      "Epoch 58. Loss: 0.005407051539804621, Train_acc 0.9968467620481928\n",
      "\n",
      "Epoch 58. Loss: 0.0049093212008295955, Train_acc 0.9968656437125748\n",
      "\n",
      "Epoch 58. Loss: 0.0045491664327705055, Train_acc 0.9968843005952381\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58. Loss: 0.0042736709461382765, Train_acc 0.9969027366863905\n",
      "\n",
      "Epoch 58. Loss: 0.00394838947168932, Train_acc 0.996920955882353\n",
      "\n",
      "Epoch 58. Loss: 0.003572820118278896, Train_acc 0.9969389619883041\n",
      "\n",
      "Epoch 58. Loss: 0.0035965360948464, Train_acc 0.9969567587209303\n",
      "\n",
      "Epoch 58. Loss: 0.0032635572868455103, Train_acc 0.9969743497109826\n",
      "\n",
      "Epoch 58. Loss: 0.0030854354342589067, Train_acc 0.9969917385057471\n",
      "\n",
      "Epoch 58. Loss: 0.002954525723041828, Train_acc 0.9970089285714285\n",
      "\n",
      "Epoch 58. Loss: 0.003381173550172212, Train_acc 0.9969815340909091\n",
      "\n",
      "Epoch 58. Loss: 0.0035105672753604315, Train_acc 0.9969985875706214\n",
      "\n",
      "Epoch 58. Loss: 0.003304804040648228, Train_acc 0.9970154494382022\n",
      "\n",
      "Epoch 58. Loss: 0.003623907441935855, Train_acc 0.9969884776536313\n",
      "\n",
      "Epoch 58. Loss: 0.003776824928857611, Train_acc 0.9970052083333333\n",
      "\n",
      "Epoch 58. Loss: 0.0034875885227101085, Train_acc 0.9970217541436464\n",
      "\n",
      "Epoch 58. Loss: 0.003370191385562155, Train_acc 0.9970381181318682\n",
      "\n",
      "Epoch 58. Loss: 0.0031510140057712196, Train_acc 0.9970543032786885\n",
      "\n",
      "Epoch 58. Loss: 0.0031525967627816856, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 58. Loss: 0.005485592315499794, Train_acc 0.9970016891891892\n",
      "\n",
      "Epoch 58. Loss: 0.005918774761919508, Train_acc 0.997017809139785\n",
      "\n",
      "Epoch 58. Loss: 0.005501720107009408, Train_acc 0.997033756684492\n",
      "\n",
      "Epoch 58. Loss: 0.004976922698718478, Train_acc 0.9970495345744681\n",
      "\n",
      "Epoch 58. Loss: 0.0052903863143046225, Train_acc 0.9970238095238095\n",
      "\n",
      "Epoch 58. Loss: 0.004871425715468334, Train_acc 0.9970394736842105\n",
      "\n",
      "Epoch 58. Loss: 0.00497267770570398, Train_acc 0.9970549738219895\n",
      "\n",
      "Epoch 58. Loss: 0.0044989737583306195, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 58. Loss: 0.004490510430613765, Train_acc 0.9970854922279793\n",
      "\n",
      "Epoch 58. Loss: 0.0062268089264746985, Train_acc 0.9970602448453608\n",
      "\n",
      "Epoch 58. Loss: 0.0058310792147844865, Train_acc 0.9970753205128206\n",
      "\n",
      "Epoch 58. Loss: 0.005260029780788174, Train_acc 0.99708\n",
      "\n",
      "Epoch 59. Loss: 0.004785695607081086, Train_acc 1.0\n",
      "\n",
      "Epoch 59. Loss: 0.004317250589414435, Train_acc 1.0\n",
      "\n",
      "Epoch 59. Loss: 0.006010219706491229, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 59. Loss: 0.005647280386891005, Train_acc 0.998046875\n",
      "\n",
      "Epoch 59. Loss: 0.0051093657013809276, Train_acc 0.9984375\n",
      "\n",
      "Epoch 59. Loss: 0.005205983280125462, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 59. Loss: 0.004702289009814966, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 59. Loss: 0.004242502002225013, Train_acc 0.998046875\n",
      "\n",
      "Epoch 59. Loss: 0.004026489406240605, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 59. Loss: 0.006828507288765272, Train_acc 0.99765625\n",
      "\n",
      "Epoch 59. Loss: 0.009613034580175305, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 59. Loss: 0.008689104168664903, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 59. Loss: 0.008110961227761051, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 59. Loss: 0.007345114256283722, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 59. Loss: 0.008968920205838456, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 59. Loss: 0.010049871976501024, Train_acc 0.99658203125\n",
      "\n",
      "Epoch 59. Loss: 0.009716917183541904, Train_acc 0.9967830882352942\n",
      "\n",
      "Epoch 59. Loss: 0.008791764958092854, Train_acc 0.9969618055555556\n",
      "\n",
      "Epoch 59. Loss: 0.019589553371121844, Train_acc 0.9962993421052632\n",
      "\n",
      "Epoch 59. Loss: 0.01840928251971337, Train_acc 0.99609375\n",
      "\n",
      "Epoch 59. Loss: 0.017815366044755573, Train_acc 0.9959077380952381\n",
      "\n",
      "Epoch 59. Loss: 0.017521111545070227, Train_acc 0.9957386363636364\n",
      "\n",
      "Epoch 59. Loss: 0.01578964201164902, Train_acc 0.9959239130434783\n",
      "\n",
      "Epoch 59. Loss: 0.014335061667957852, Train_acc 0.99609375\n",
      "\n",
      "Epoch 59. Loss: 0.013064342398433938, Train_acc 0.99625\n",
      "\n",
      "Epoch 59. Loss: 0.013562970564355601, Train_acc 0.99609375\n",
      "\n",
      "Epoch 59. Loss: 0.01305295264103128, Train_acc 0.9959490740740741\n",
      "\n",
      "Epoch 59. Loss: 0.012072099614543736, Train_acc 0.99609375\n",
      "\n",
      "Epoch 59. Loss: 0.011261787576290686, Train_acc 0.9962284482758621\n",
      "\n",
      "Epoch 59. Loss: 0.012970092054736065, Train_acc 0.99609375\n",
      "\n",
      "Epoch 59. Loss: 0.014874886041758758, Train_acc 0.9957157258064516\n",
      "\n",
      "Epoch 59. Loss: 0.0134259959678102, Train_acc 0.995849609375\n",
      "\n",
      "Epoch 59. Loss: 0.012286310512147706, Train_acc 0.9959753787878788\n",
      "\n",
      "Epoch 59. Loss: 0.011538141000633563, Train_acc 0.99609375\n",
      "\n",
      "Epoch 59. Loss: 0.011464165344117693, Train_acc 0.9959821428571428\n",
      "\n",
      "Epoch 59. Loss: 0.010614738614771019, Train_acc 0.99609375\n",
      "\n",
      "Epoch 59. Loss: 0.009648494197853581, Train_acc 0.9961993243243243\n",
      "\n",
      "Epoch 59. Loss: 0.008695491399850975, Train_acc 0.9962993421052632\n",
      "\n",
      "Epoch 59. Loss: 0.01071675300284016, Train_acc 0.9959935897435898\n",
      "\n",
      "Epoch 59. Loss: 0.01029350885652412, Train_acc 0.99609375\n",
      "\n",
      "Epoch 59. Loss: 0.01042943808945634, Train_acc 0.9959984756097561\n",
      "\n",
      "Epoch 59. Loss: 0.010850219698363108, Train_acc 0.9959077380952381\n",
      "\n",
      "Epoch 59. Loss: 0.011322898157638516, Train_acc 0.9958212209302325\n",
      "\n",
      "Epoch 59. Loss: 0.011318237323941773, Train_acc 0.9957386363636364\n",
      "\n",
      "Epoch 59. Loss: 0.010218025901524076, Train_acc 0.9958333333333333\n",
      "\n",
      "Epoch 59. Loss: 0.010425706200547086, Train_acc 0.9957540760869565\n",
      "\n",
      "Epoch 59. Loss: 0.013533695706200957, Train_acc 0.9956781914893617\n",
      "\n",
      "Epoch 59. Loss: 0.012273923035695652, Train_acc 0.9957682291666666\n",
      "\n",
      "Epoch 59. Loss: 0.012552511931569428, Train_acc 0.9956951530612245\n",
      "\n",
      "Epoch 59. Loss: 0.011333748158269197, Train_acc 0.99578125\n",
      "\n",
      "Epoch 59. Loss: 0.01331289511005855, Train_acc 0.9957107843137255\n",
      "\n",
      "Epoch 59. Loss: 0.014906825358397751, Train_acc 0.9953425480769231\n",
      "\n",
      "Epoch 59. Loss: 0.01345734960314623, Train_acc 0.9954304245283019\n",
      "\n",
      "Epoch 59. Loss: 0.012172574408519193, Train_acc 0.9955150462962963\n",
      "\n",
      "Epoch 59. Loss: 0.01102901245896817, Train_acc 0.9955965909090909\n",
      "\n",
      "Epoch 59. Loss: 0.0129387147344184, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 59. Loss: 0.014506747055086382, Train_acc 0.9954769736842105\n",
      "\n",
      "Epoch 59. Loss: 0.013566164801746208, Train_acc 0.9955549568965517\n",
      "\n",
      "Epoch 59. Loss: 0.013267014441099404, Train_acc 0.9954978813559322\n",
      "\n",
      "Epoch 59. Loss: 0.012003995263034827, Train_acc 0.9955729166666667\n",
      "\n",
      "Epoch 59. Loss: 0.01127145583007162, Train_acc 0.9956454918032787\n",
      "\n",
      "Epoch 59. Loss: 0.012811524782241214, Train_acc 0.9954637096774194\n",
      "\n",
      "Epoch 59. Loss: 0.013902108547384289, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 59. Loss: 0.015080356830920053, Train_acc 0.9954833984375\n",
      "\n",
      "Epoch 59. Loss: 0.013978669527156895, Train_acc 0.9955528846153846\n",
      "\n",
      "Epoch 59. Loss: 0.013084383126035702, Train_acc 0.9956202651515151\n",
      "\n",
      "Epoch 59. Loss: 0.013596601843180095, Train_acc 0.9955690298507462\n",
      "\n",
      "Epoch 59. Loss: 0.015082746424682589, Train_acc 0.9954044117647058\n",
      "\n",
      "Epoch 59. Loss: 0.01363757219283967, Train_acc 0.9954710144927537\n",
      "\n",
      "Epoch 59. Loss: 0.014666147601925035, Train_acc 0.9954241071428571\n",
      "\n",
      "Epoch 59. Loss: 0.015792462108125717, Train_acc 0.9953785211267606\n",
      "\n",
      "Epoch 59. Loss: 0.0160295454435859, Train_acc 0.9953342013888888\n",
      "\n",
      "Epoch 59. Loss: 0.015450655320881058, Train_acc 0.995291095890411\n",
      "\n",
      "Epoch 59. Loss: 0.016027646273015363, Train_acc 0.995143581081081\n",
      "\n",
      "Epoch 59. Loss: 0.015610475679163715, Train_acc 0.9951041666666667\n",
      "\n",
      "Epoch 59. Loss: 0.014292411824062093, Train_acc 0.9951685855263158\n",
      "\n",
      "Epoch 59. Loss: 0.013213389303716681, Train_acc 0.9952313311688312\n",
      "\n",
      "Epoch 59. Loss: 0.013243271931051607, Train_acc 0.9951923076923077\n",
      "\n",
      "Epoch 59. Loss: 0.01211663709308749, Train_acc 0.995253164556962\n",
      "\n",
      "Epoch 59. Loss: 0.01209918708705347, Train_acc 0.9953125\n",
      "\n",
      "Epoch 59. Loss: 0.011260200562507879, Train_acc 0.9953703703703703\n",
      "\n",
      "Epoch 59. Loss: 0.010512407111501072, Train_acc 0.9954268292682927\n",
      "\n",
      "Epoch 59. Loss: 0.010610537946112789, Train_acc 0.9954819277108434\n",
      "\n",
      "Epoch 59. Loss: 0.00961684827328876, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 59. Loss: 0.008713390920761127, Train_acc 0.9955882352941177\n",
      "\n",
      "Epoch 59. Loss: 0.00957044757384321, Train_acc 0.9954578488372093\n",
      "\n",
      "Epoch 59. Loss: 0.008717860457013645, Train_acc 0.9955100574712644\n",
      "\n",
      "Epoch 59. Loss: 0.010721670323649584, Train_acc 0.9953835227272727\n",
      "\n",
      "Epoch 59. Loss: 0.009754447815639857, Train_acc 0.995435393258427\n",
      "\n",
      "Epoch 59. Loss: 0.009230599487861767, Train_acc 0.9954861111111111\n",
      "\n",
      "Epoch 59. Loss: 0.013037896768785216, Train_acc 0.9954498626373627\n",
      "\n",
      "Epoch 59. Loss: 0.012314070856082467, Train_acc 0.995499320652174\n",
      "\n",
      "Epoch 59. Loss: 0.01630424336687448, Train_acc 0.9953797043010753\n",
      "\n",
      "Epoch 59. Loss: 0.015048850477225088, Train_acc 0.9954288563829787\n",
      "\n",
      "Epoch 59. Loss: 0.013609158498670015, Train_acc 0.9954769736842105\n",
      "\n",
      "Epoch 59. Loss: 0.012328605670500863, Train_acc 0.9955240885416666\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59. Loss: 0.011177033958740817, Train_acc 0.9955702319587629\n",
      "\n",
      "Epoch 59. Loss: 0.010921390584475804, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 59. Loss: 0.009942731109552391, Train_acc 0.9955808080808081\n",
      "\n",
      "Epoch 59. Loss: 0.010481454258226879, Train_acc 0.995546875\n",
      "\n",
      "[Epoch 59 Batch 100] Loss: 0.015100031189677293 Training: accuracy=0.995436\n",
      "Epoch 59. Loss: 0.015100031189677293, Train_acc 0.9954362623762376\n",
      "\n",
      "Epoch 59. Loss: 0.014286015395871259, Train_acc 0.9954810049019608\n",
      "\n",
      "Epoch 59. Loss: 0.0175258552711172, Train_acc 0.9954490291262136\n",
      "\n",
      "Epoch 59. Loss: 0.015846657730054538, Train_acc 0.9954927884615384\n",
      "\n",
      "Epoch 59. Loss: 0.015126140842060758, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 59. Loss: 0.017755383860367995, Train_acc 0.9954304245283019\n",
      "\n",
      "Epoch 59. Loss: 0.019378292585580166, Train_acc 0.9954001168224299\n",
      "\n",
      "Epoch 59. Loss: 0.018942109313012913, Train_acc 0.9953703703703703\n",
      "\n",
      "Epoch 59. Loss: 0.017183898090148052, Train_acc 0.9954128440366973\n",
      "\n",
      "Epoch 59. Loss: 0.01566390413406409, Train_acc 0.9954545454545455\n",
      "\n",
      "Epoch 59. Loss: 0.014335145308900628, Train_acc 0.9954954954954955\n",
      "\n",
      "Epoch 59. Loss: 0.013964302618201451, Train_acc 0.9954659598214286\n",
      "\n",
      "Epoch 59. Loss: 0.014258296217527281, Train_acc 0.9954369469026548\n",
      "\n",
      "Epoch 59. Loss: 0.013288527251189612, Train_acc 0.9954769736842105\n",
      "\n",
      "Epoch 59. Loss: 0.012252593496879037, Train_acc 0.9955163043478261\n",
      "\n",
      "Epoch 59. Loss: 0.011350958683586206, Train_acc 0.9955549568965517\n",
      "\n",
      "Epoch 59. Loss: 0.010402454294223564, Train_acc 0.9955929487179487\n",
      "\n",
      "Epoch 59. Loss: 0.009841194211654941, Train_acc 0.9956302966101694\n",
      "\n",
      "Epoch 59. Loss: 0.009961458147358668, Train_acc 0.9956013655462185\n",
      "\n",
      "Epoch 59. Loss: 0.00991607989814142, Train_acc 0.9955729166666667\n",
      "\n",
      "Epoch 59. Loss: 0.009108600318510171, Train_acc 0.9956095041322314\n",
      "\n",
      "Epoch 59. Loss: 0.010515596166323577, Train_acc 0.9955814549180327\n",
      "\n",
      "Epoch 59. Loss: 0.012478740762237569, Train_acc 0.9954903455284553\n",
      "\n",
      "Epoch 59. Loss: 0.012922720127311821, Train_acc 0.9954637096774194\n",
      "\n",
      "Epoch 59. Loss: 0.011729831618710586, Train_acc 0.9955\n",
      "\n",
      "Epoch 59. Loss: 0.010633644943813289, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 59. Loss: 0.010088851196658437, Train_acc 0.9955708661417323\n",
      "\n",
      "Epoch 59. Loss: 0.009422597719699286, Train_acc 0.99560546875\n",
      "\n",
      "Epoch 59. Loss: 0.009978074334684141, Train_acc 0.9955789728682171\n",
      "\n",
      "Epoch 59. Loss: 0.012659725325664695, Train_acc 0.9955528846153846\n",
      "\n",
      "Epoch 59. Loss: 0.013490269618356959, Train_acc 0.9955271946564885\n",
      "\n",
      "Epoch 59. Loss: 0.012581978957764568, Train_acc 0.9955610795454546\n",
      "\n",
      "Epoch 59. Loss: 0.011477983470145399, Train_acc 0.9955944548872181\n",
      "\n",
      "Epoch 59. Loss: 0.01096143416722137, Train_acc 0.9956273320895522\n",
      "\n",
      "Epoch 59. Loss: 0.01277326278829144, Train_acc 0.9955439814814815\n",
      "\n",
      "Epoch 59. Loss: 0.013120239261778294, Train_acc 0.9955193014705882\n",
      "\n",
      "Epoch 59. Loss: 0.015081268802874177, Train_acc 0.9954949817518248\n",
      "\n",
      "Epoch 59. Loss: 0.013639853938128029, Train_acc 0.9955276268115942\n",
      "\n",
      "Epoch 59. Loss: 0.01618573989901436, Train_acc 0.9954473920863309\n",
      "\n",
      "Epoch 59. Loss: 0.014765232329966063, Train_acc 0.9954799107142858\n",
      "\n",
      "Epoch 59. Loss: 0.013733890181766243, Train_acc 0.9955119680851063\n",
      "\n",
      "Epoch 59. Loss: 0.019221677505361696, Train_acc 0.9953235035211268\n",
      "\n",
      "Epoch 59. Loss: 0.01735563770840145, Train_acc 0.9953562062937062\n",
      "\n",
      "Epoch 59. Loss: 0.015770640101499797, Train_acc 0.9953884548611112\n",
      "\n",
      "Epoch 59. Loss: 0.014251886005661211, Train_acc 0.9954202586206896\n",
      "\n",
      "Epoch 59. Loss: 0.01347092647817253, Train_acc 0.9954516267123288\n",
      "\n",
      "Epoch 59. Loss: 0.015233657370208374, Train_acc 0.9953762755102041\n",
      "\n",
      "Epoch 59. Loss: 0.013811177942706946, Train_acc 0.9954075168918919\n",
      "\n",
      "Epoch 59. Loss: 0.014353942737180415, Train_acc 0.9953334731543624\n",
      "\n",
      "Epoch 59. Loss: 0.018409611462234042, Train_acc 0.9952083333333334\n",
      "\n",
      "Epoch 59. Loss: 0.01745448299826257, Train_acc 0.9952400662251656\n",
      "\n",
      "Epoch 59. Loss: 0.020169928269813113, Train_acc 0.9951685855263158\n",
      "\n",
      "Epoch 59. Loss: 0.01854493377110033, Train_acc 0.9952001633986928\n",
      "\n",
      "Epoch 59. Loss: 0.01690276745893659, Train_acc 0.9952313311688312\n",
      "\n",
      "Epoch 59. Loss: 0.018017135677678302, Train_acc 0.9952116935483871\n",
      "\n",
      "Epoch 59. Loss: 0.016846150777512416, Train_acc 0.9952423878205128\n",
      "\n",
      "Epoch 59. Loss: 0.015736850813871883, Train_acc 0.9952726910828026\n",
      "\n",
      "Epoch 59. Loss: 0.014595048601936932, Train_acc 0.9953026107594937\n",
      "\n",
      "Epoch 59. Loss: 0.015502888985435637, Train_acc 0.9952338836477987\n",
      "\n",
      "Epoch 59. Loss: 0.01908707718070788, Train_acc 0.995166015625\n",
      "\n",
      "Epoch 59. Loss: 0.017506949589734762, Train_acc 0.9951960403726708\n",
      "\n",
      "Epoch 59. Loss: 0.01721733267106309, Train_acc 0.9951774691358025\n",
      "\n",
      "Epoch 59. Loss: 0.016018061356598386, Train_acc 0.995207055214724\n",
      "\n",
      "Epoch 59. Loss: 0.017613385409284456, Train_acc 0.995141006097561\n",
      "\n",
      "Epoch 59. Loss: 0.019338672718556663, Train_acc 0.995123106060606\n",
      "\n",
      "Epoch 59. Loss: 0.017602682692656167, Train_acc 0.995152484939759\n",
      "\n",
      "Epoch 59. Loss: 0.01609142181420259, Train_acc 0.9951815119760479\n",
      "\n",
      "Epoch 59. Loss: 0.014652915344184031, Train_acc 0.9952101934523809\n",
      "\n",
      "Epoch 59. Loss: 0.013986828125755838, Train_acc 0.9952385355029586\n",
      "\n",
      "Epoch 59. Loss: 0.013370331385500001, Train_acc 0.995266544117647\n",
      "\n",
      "Epoch 59. Loss: 0.014765635326892228, Train_acc 0.995202850877193\n",
      "\n",
      "Epoch 59. Loss: 0.016950162674835408, Train_acc 0.9951853197674418\n",
      "\n",
      "Epoch 59. Loss: 0.016046760630623474, Train_acc 0.9952131502890174\n",
      "\n",
      "Epoch 59. Loss: 0.015037005372285224, Train_acc 0.9952406609195402\n",
      "\n",
      "Epoch 59. Loss: 0.013889575254490414, Train_acc 0.9952678571428571\n",
      "\n",
      "Epoch 59. Loss: 0.012745103292639946, Train_acc 0.9952947443181818\n",
      "\n",
      "Epoch 59. Loss: 0.012201417014800812, Train_acc 0.9952771892655368\n",
      "\n",
      "Epoch 59. Loss: 0.01138193722327349, Train_acc 0.9953037219101124\n",
      "\n",
      "Epoch 59. Loss: 0.013065536349354364, Train_acc 0.995286312849162\n",
      "\n",
      "Epoch 59. Loss: 0.011877629764531415, Train_acc 0.9953125\n",
      "\n",
      "Epoch 59. Loss: 0.015510916582632985, Train_acc 0.9952520718232044\n",
      "\n",
      "Epoch 59. Loss: 0.014106325818703852, Train_acc 0.9952781593406593\n",
      "\n",
      "Epoch 59. Loss: 0.012877445098070456, Train_acc 0.9953039617486339\n",
      "\n",
      "Epoch 59. Loss: 0.012145723727769989, Train_acc 0.9953294836956522\n",
      "\n",
      "Epoch 59. Loss: 0.012814093189621572, Train_acc 0.9952702702702703\n",
      "\n",
      "Epoch 59. Loss: 0.016707106134758537, Train_acc 0.9952116935483871\n",
      "\n",
      "Epoch 59. Loss: 0.015069388441306073, Train_acc 0.9952372994652406\n",
      "\n",
      "Epoch 59. Loss: 0.015995807171221125, Train_acc 0.9952210771276596\n",
      "\n",
      "Epoch 59. Loss: 0.015729456722309187, Train_acc 0.9952050264550265\n",
      "\n",
      "Epoch 59. Loss: 0.014506387334677575, Train_acc 0.9952302631578948\n",
      "\n",
      "Epoch 59. Loss: 0.013115150188560111, Train_acc 0.9952552356020943\n",
      "\n",
      "Epoch 59. Loss: 0.012617851381142279, Train_acc 0.9952392578125\n",
      "\n",
      "Epoch 59. Loss: 0.012213021126812107, Train_acc 0.995223445595855\n",
      "\n",
      "Epoch 59. Loss: 0.012022148373656338, Train_acc 0.9952077963917526\n",
      "\n",
      "Epoch 59. Loss: 0.014871742921709598, Train_acc 0.9951522435897436\n",
      "\n",
      "Epoch 59. Loss: 0.013428434714427215, Train_acc 0.99516\n",
      "\n",
      "Epoch 60. Loss: 0.012220338217784276, Train_acc 1.0\n",
      "\n",
      "Epoch 60. Loss: 0.012719892173143605, Train_acc 0.99609375\n",
      "\n",
      "Epoch 60. Loss: 0.013334789872883899, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 60. Loss: 0.01218758155888913, Train_acc 0.99609375\n",
      "\n",
      "Epoch 60. Loss: 0.011145613387107236, Train_acc 0.996875\n",
      "\n",
      "Epoch 60. Loss: 0.010494105911892102, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 60. Loss: 0.00976475924791376, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 60. Loss: 0.012844056417418839, Train_acc 0.99609375\n",
      "\n",
      "Epoch 60. Loss: 0.012946486946827162, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 60. Loss: 0.012366585301058879, Train_acc 0.9953125\n",
      "\n",
      "Epoch 60. Loss: 0.011261518250246993, Train_acc 0.9957386363636364\n",
      "\n",
      "Epoch 60. Loss: 0.010485557543417947, Train_acc 0.99609375\n",
      "\n",
      "Epoch 60. Loss: 0.015648235300643267, Train_acc 0.9933894230769231\n",
      "\n",
      "Epoch 60. Loss: 0.014633910770234189, Train_acc 0.9938616071428571\n",
      "\n",
      "Epoch 60. Loss: 0.013318946481138518, Train_acc 0.9942708333333333\n",
      "\n",
      "Epoch 60. Loss: 0.014457411225488829, Train_acc 0.99365234375\n",
      "\n",
      "Epoch 60. Loss: 0.0134436914134929, Train_acc 0.9940257352941176\n",
      "\n",
      "Epoch 60. Loss: 0.014278073576889285, Train_acc 0.9939236111111112\n",
      "\n",
      "Epoch 60. Loss: 0.015575315886260733, Train_acc 0.9938322368421053\n",
      "\n",
      "Epoch 60. Loss: 0.016999379061330852, Train_acc 0.99375\n",
      "\n",
      "Epoch 60. Loss: 0.015622310668381599, Train_acc 0.9940476190476191\n",
      "\n",
      "Epoch 60. Loss: 0.014593909882890476, Train_acc 0.9943181818181818\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60. Loss: 0.01337404034589585, Train_acc 0.9945652173913043\n",
      "\n",
      "Epoch 60. Loss: 0.012088029514045102, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 60. Loss: 0.012219584056249783, Train_acc 0.995\n",
      "\n",
      "Epoch 60. Loss: 0.01155607954205113, Train_acc 0.9951923076923077\n",
      "\n",
      "Epoch 60. Loss: 0.012326714520523287, Train_acc 0.9950810185185185\n",
      "\n",
      "Epoch 60. Loss: 0.011214054087060096, Train_acc 0.9952566964285714\n",
      "\n",
      "Epoch 60. Loss: 0.01051370124415225, Train_acc 0.9954202586206896\n",
      "\n",
      "Epoch 60. Loss: 0.011340544257125256, Train_acc 0.9953125\n",
      "\n",
      "Epoch 60. Loss: 0.010322942918370067, Train_acc 0.9954637096774194\n",
      "\n",
      "Epoch 60. Loss: 0.010649616925415306, Train_acc 0.995361328125\n",
      "\n",
      "Epoch 60. Loss: 0.00986460868004433, Train_acc 0.9955018939393939\n",
      "\n",
      "Epoch 60. Loss: 0.009888009005637214, Train_acc 0.9954044117647058\n",
      "\n",
      "Epoch 60. Loss: 0.00936023536408059, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 60. Loss: 0.008736143376312663, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 60. Loss: 0.008256004072024235, Train_acc 0.995777027027027\n",
      "\n",
      "Epoch 60. Loss: 0.008550740297997423, Train_acc 0.9956825657894737\n",
      "\n",
      "Epoch 60. Loss: 0.007743142779297056, Train_acc 0.9957932692307693\n",
      "\n",
      "Epoch 60. Loss: 0.0070163715525543005, Train_acc 0.9958984375\n",
      "\n",
      "Epoch 60. Loss: 0.006387892166228248, Train_acc 0.9959984756097561\n",
      "\n",
      "Epoch 60. Loss: 0.005884369532552648, Train_acc 0.99609375\n",
      "\n",
      "Epoch 60. Loss: 0.00550230313788708, Train_acc 0.9961845930232558\n",
      "\n",
      "Epoch 60. Loss: 0.008316685731269622, Train_acc 0.9959161931818182\n",
      "\n",
      "Epoch 60. Loss: 0.007579161751601282, Train_acc 0.9960069444444445\n",
      "\n",
      "Epoch 60. Loss: 0.0075903393488376, Train_acc 0.9959239130434783\n",
      "\n",
      "Epoch 60. Loss: 0.00803333952601987, Train_acc 0.995844414893617\n",
      "\n",
      "Epoch 60. Loss: 0.007410391254287106, Train_acc 0.9959309895833334\n",
      "\n",
      "Epoch 60. Loss: 0.006692434207991414, Train_acc 0.9960140306122449\n",
      "\n",
      "Epoch 60. Loss: 0.006039914791136819, Train_acc 0.99609375\n",
      "\n",
      "Epoch 60. Loss: 0.005495065240818862, Train_acc 0.9961703431372549\n",
      "\n",
      "Epoch 60. Loss: 0.005126466334060076, Train_acc 0.9962439903846154\n",
      "\n",
      "Epoch 60. Loss: 0.005595566500897924, Train_acc 0.9961674528301887\n",
      "\n",
      "Epoch 60. Loss: 0.006282747539587963, Train_acc 0.99609375\n",
      "\n",
      "Epoch 60. Loss: 0.005780106315016581, Train_acc 0.9961647727272728\n",
      "\n",
      "Epoch 60. Loss: 0.005876468408703655, Train_acc 0.9962332589285714\n",
      "\n",
      "Epoch 60. Loss: 0.005326511214539275, Train_acc 0.9962993421052632\n",
      "\n",
      "Epoch 60. Loss: 0.00532316754604715, Train_acc 0.9963631465517241\n",
      "\n",
      "Epoch 60. Loss: 0.005113461629781168, Train_acc 0.9964247881355932\n",
      "\n",
      "Epoch 60. Loss: 0.00538959228953693, Train_acc 0.996484375\n",
      "\n",
      "Epoch 60. Loss: 0.005303220907249812, Train_acc 0.9965420081967213\n",
      "\n",
      "Epoch 60. Loss: 0.004822603839936492, Train_acc 0.9965977822580645\n",
      "\n",
      "Epoch 60. Loss: 0.006108513939353201, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 60. Loss: 0.005519435867495814, Train_acc 0.99658203125\n",
      "\n",
      "Epoch 60. Loss: 0.005006543841198441, Train_acc 0.9966346153846154\n",
      "\n",
      "Epoch 60. Loss: 0.004550065372615068, Train_acc 0.9966856060606061\n",
      "\n",
      "Epoch 60. Loss: 0.004142272687293448, Train_acc 0.9967350746268657\n",
      "\n",
      "Epoch 60. Loss: 0.008912173926535868, Train_acc 0.9966681985294118\n",
      "\n",
      "Epoch 60. Loss: 0.010647222864362857, Train_acc 0.9966032608695652\n",
      "\n",
      "Epoch 60. Loss: 0.009594578287761129, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 60. Loss: 0.009086851907978102, Train_acc 0.9966989436619719\n",
      "\n",
      "Epoch 60. Loss: 0.008273589446098786, Train_acc 0.9967447916666666\n",
      "\n",
      "Epoch 60. Loss: 0.0075505110510561005, Train_acc 0.9967893835616438\n",
      "\n",
      "Epoch 60. Loss: 0.013064146747145636, Train_acc 0.9965160472972973\n",
      "\n",
      "Epoch 60. Loss: 0.012167200382384882, Train_acc 0.9965625\n",
      "\n",
      "Epoch 60. Loss: 0.011068759126029813, Train_acc 0.9966077302631579\n",
      "\n",
      "Epoch 60. Loss: 0.010068972620237532, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 60. Loss: 0.009599568391548392, Train_acc 0.9966947115384616\n",
      "\n",
      "Epoch 60. Loss: 0.009429856824612734, Train_acc 0.9966376582278481\n",
      "\n",
      "Epoch 60. Loss: 0.009084511734756336, Train_acc 0.9966796875\n",
      "\n",
      "Epoch 60. Loss: 0.008874772004973148, Train_acc 0.9967206790123457\n",
      "\n",
      "Epoch 60. Loss: 0.010404358890078595, Train_acc 0.9966653963414634\n",
      "\n",
      "Epoch 60. Loss: 0.009715248609860656, Train_acc 0.9967055722891566\n",
      "\n",
      "Epoch 60. Loss: 0.008894106756587253, Train_acc 0.9967447916666666\n",
      "\n",
      "Epoch 60. Loss: 0.008237335989719116, Train_acc 0.9967830882352942\n",
      "\n",
      "Epoch 60. Loss: 0.007879659443583027, Train_acc 0.9968204941860465\n",
      "\n",
      "Epoch 60. Loss: 0.0073928828007602115, Train_acc 0.9968570402298851\n",
      "\n",
      "Epoch 60. Loss: 0.006957825219068535, Train_acc 0.9968927556818182\n",
      "\n",
      "Epoch 60. Loss: 0.006468693141468114, Train_acc 0.9969276685393258\n",
      "\n",
      "Epoch 60. Loss: 0.006665985598559153, Train_acc 0.996875\n",
      "\n",
      "Epoch 60. Loss: 0.007536318043078458, Train_acc 0.9967376373626373\n",
      "\n",
      "Epoch 60. Loss: 0.008043010061268934, Train_acc 0.996688179347826\n",
      "\n",
      "Epoch 60. Loss: 0.010346325360493298, Train_acc 0.9966397849462365\n",
      "\n",
      "Epoch 60. Loss: 0.009540941974004898, Train_acc 0.9966755319148937\n",
      "\n",
      "Epoch 60. Loss: 0.008707171230634267, Train_acc 0.9967105263157895\n",
      "\n",
      "Epoch 60. Loss: 0.00851121733631511, Train_acc 0.9967447916666666\n",
      "\n",
      "Epoch 60. Loss: 0.011560242832116659, Train_acc 0.9965367268041238\n",
      "\n",
      "Epoch 60. Loss: 0.010572188221380003, Train_acc 0.9965720663265306\n",
      "\n",
      "Epoch 60. Loss: 0.009756435778035123, Train_acc 0.9966066919191919\n",
      "\n",
      "Epoch 60. Loss: 0.008852857871206165, Train_acc 0.996640625\n",
      "\n",
      "[Epoch 60 Batch 100] Loss: 0.008320214862392749 Training: accuracy=0.996674\n",
      "Epoch 60. Loss: 0.008320214862392749, Train_acc 0.9966738861386139\n",
      "\n",
      "Epoch 60. Loss: 0.007719956444740062, Train_acc 0.9967064950980392\n",
      "\n",
      "Epoch 60. Loss: 0.006994605724707408, Train_acc 0.9967384708737864\n",
      "\n",
      "Epoch 60. Loss: 0.014143954811717718, Train_acc 0.9966947115384616\n",
      "\n",
      "Epoch 60. Loss: 0.014719433201753184, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 60. Loss: 0.015518841844859497, Train_acc 0.9966096698113207\n",
      "\n",
      "Epoch 60. Loss: 0.01402145604391607, Train_acc 0.9966413551401869\n",
      "\n",
      "Epoch 60. Loss: 0.017771966577467734, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 60. Loss: 0.016916554167924, Train_acc 0.9965596330275229\n",
      "\n",
      "Epoch 60. Loss: 0.016657022158853122, Train_acc 0.9965198863636363\n",
      "\n",
      "Epoch 60. Loss: 0.015162541828797975, Train_acc 0.9965512387387387\n",
      "\n",
      "Epoch 60. Loss: 0.016000318702083873, Train_acc 0.9965122767857143\n",
      "\n",
      "Epoch 60. Loss: 0.015278150466253205, Train_acc 0.9964740044247787\n",
      "\n",
      "Epoch 60. Loss: 0.014161332961249213, Train_acc 0.9965049342105263\n",
      "\n",
      "Epoch 60. Loss: 0.017134151920373316, Train_acc 0.9963994565217391\n",
      "\n",
      "Epoch 60. Loss: 0.016839588696236977, Train_acc 0.9963631465517241\n",
      "\n",
      "Epoch 60. Loss: 0.019463223604389044, Train_acc 0.9963274572649573\n",
      "\n",
      "Epoch 60. Loss: 0.019483017821336997, Train_acc 0.9962261652542372\n",
      "\n",
      "Epoch 60. Loss: 0.02764058819343914, Train_acc 0.9960609243697479\n",
      "\n",
      "Epoch 60. Loss: 0.025112102297070053, Train_acc 0.99609375\n",
      "\n",
      "Epoch 60. Loss: 0.023579483732988623, Train_acc 0.9960614669421488\n",
      "\n",
      "Epoch 60. Loss: 0.02154430736340003, Train_acc 0.99609375\n",
      "\n",
      "Epoch 60. Loss: 0.01947656944666468, Train_acc 0.9961255081300813\n",
      "\n",
      "Epoch 60. Loss: 0.017771238444961573, Train_acc 0.9961567540322581\n",
      "\n",
      "Epoch 60. Loss: 0.016577535992831707, Train_acc 0.9961875\n",
      "\n",
      "Epoch 60. Loss: 0.015551994332048942, Train_acc 0.9962177579365079\n",
      "\n",
      "Epoch 60. Loss: 0.014107434239553943, Train_acc 0.9962475393700787\n",
      "\n",
      "Epoch 60. Loss: 0.01388170947796184, Train_acc 0.9962158203125\n",
      "\n",
      "Epoch 60. Loss: 0.012851310148457392, Train_acc 0.9962451550387597\n",
      "\n",
      "Epoch 60. Loss: 0.014442148878830406, Train_acc 0.99609375\n",
      "\n",
      "Epoch 60. Loss: 0.01320436000979638, Train_acc 0.9961235687022901\n",
      "\n",
      "Epoch 60. Loss: 0.012006867820401007, Train_acc 0.9961529356060606\n",
      "\n",
      "Epoch 60. Loss: 0.011640930863659693, Train_acc 0.9961231203007519\n",
      "\n",
      "Epoch 60. Loss: 0.010583809115685027, Train_acc 0.996152052238806\n",
      "\n",
      "Epoch 60. Loss: 0.009875701022585035, Train_acc 0.9961805555555555\n",
      "\n",
      "Epoch 60. Loss: 0.009683678957021057, Train_acc 0.9961511948529411\n",
      "\n",
      "Epoch 60. Loss: 0.008855369939196842, Train_acc 0.9961792883211679\n",
      "\n",
      "Epoch 60. Loss: 0.009597860429098073, Train_acc 0.9961503623188406\n",
      "\n",
      "Epoch 60. Loss: 0.009304523232647655, Train_acc 0.9961780575539568\n",
      "\n",
      "Epoch 60. Loss: 0.008456024321537579, Train_acc 0.9962053571428572\n",
      "\n",
      "Epoch 60. Loss: 0.007970321067531138, Train_acc 0.9962322695035462\n",
      "\n",
      "Epoch 60. Loss: 0.007856030690320637, Train_acc 0.9962037852112676\n",
      "\n",
      "Epoch 60. Loss: 0.007322375313883997, Train_acc 0.9962303321678322\n",
      "\n",
      "Epoch 60. Loss: 0.0070804751599097045, Train_acc 0.9962565104166666\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60. Loss: 0.006870885595389944, Train_acc 0.9962823275862069\n",
      "\n",
      "Epoch 60. Loss: 0.006491897076852986, Train_acc 0.9963077910958904\n",
      "\n",
      "Epoch 60. Loss: 0.007317810941178682, Train_acc 0.9962266156462585\n",
      "\n",
      "Epoch 60. Loss: 0.006769377028943523, Train_acc 0.9962521114864865\n",
      "\n",
      "Epoch 60. Loss: 0.0075651538693917615, Train_acc 0.9962248322147651\n",
      "\n",
      "Epoch 60. Loss: 0.006837647213232919, Train_acc 0.99625\n",
      "\n",
      "Epoch 60. Loss: 0.009381314936601284, Train_acc 0.9962230960264901\n",
      "\n",
      "Epoch 60. Loss: 0.010140807172646966, Train_acc 0.9961965460526315\n",
      "\n",
      "Epoch 60. Loss: 0.009527171693138046, Train_acc 0.9962214052287581\n",
      "\n",
      "Epoch 60. Loss: 0.008705616977732715, Train_acc 0.9962459415584416\n",
      "\n",
      "Epoch 60. Loss: 0.007956853960589025, Train_acc 0.9962701612903225\n",
      "\n",
      "Epoch 60. Loss: 0.008015121702523935, Train_acc 0.9962940705128205\n",
      "\n",
      "Epoch 60. Loss: 0.0072613460599026, Train_acc 0.9963176751592356\n",
      "\n",
      "Epoch 60. Loss: 0.006586868110345237, Train_acc 0.9963409810126582\n",
      "\n",
      "Epoch 60. Loss: 0.006046690699946671, Train_acc 0.9963639937106918\n",
      "\n",
      "Epoch 60. Loss: 0.005591967428282014, Train_acc 0.99638671875\n",
      "\n",
      "Epoch 60. Loss: 0.005084753537618468, Train_acc 0.9964091614906833\n",
      "\n",
      "Epoch 60. Loss: 0.008649778817096367, Train_acc 0.9963831018518519\n",
      "\n",
      "Epoch 60. Loss: 0.013221432227491451, Train_acc 0.9963573619631901\n",
      "\n",
      "Epoch 60. Loss: 0.012047185916691225, Train_acc 0.9963795731707317\n",
      "\n",
      "Epoch 60. Loss: 0.012943675967147232, Train_acc 0.9963068181818182\n",
      "\n",
      "Epoch 60. Loss: 0.011835107270634427, Train_acc 0.9963290662650602\n",
      "\n",
      "Epoch 60. Loss: 0.010781625868944456, Train_acc 0.9963510479041916\n",
      "\n",
      "Epoch 60. Loss: 0.012771030667783139, Train_acc 0.9963262648809523\n",
      "\n",
      "Epoch 60. Loss: 0.011558369535232768, Train_acc 0.9963480029585798\n",
      "\n",
      "Epoch 60. Loss: 0.010778842175848949, Train_acc 0.9963694852941176\n",
      "\n",
      "Epoch 60. Loss: 0.010151836036382022, Train_acc 0.996390716374269\n",
      "\n",
      "Epoch 60. Loss: 0.009467541122239444, Train_acc 0.9964117005813954\n",
      "\n",
      "Epoch 60. Loss: 0.008677807448943656, Train_acc 0.9964324421965318\n",
      "\n",
      "Epoch 60. Loss: 0.009639870858466806, Train_acc 0.9964080459770115\n",
      "\n",
      "Epoch 60. Loss: 0.01284433609510319, Train_acc 0.9963839285714285\n",
      "\n",
      "Epoch 60. Loss: 0.011730972868523211, Train_acc 0.9964044744318182\n",
      "\n",
      "Epoch 60. Loss: 0.010598404985157179, Train_acc 0.9964247881355932\n",
      "\n",
      "Epoch 60. Loss: 0.00957497815157103, Train_acc 0.9964448735955056\n",
      "\n",
      "Epoch 60. Loss: 0.008693217729176602, Train_acc 0.9964647346368715\n",
      "\n",
      "Epoch 60. Loss: 0.008581230104770233, Train_acc 0.996484375\n",
      "\n",
      "Epoch 60. Loss: 0.0077715969862171734, Train_acc 0.9965037983425414\n",
      "\n",
      "Epoch 60. Loss: 0.0072085116533901145, Train_acc 0.9965230082417582\n",
      "\n",
      "Epoch 60. Loss: 0.006645632598952131, Train_acc 0.9965420081967213\n",
      "\n",
      "Epoch 60. Loss: 0.00753115862755985, Train_acc 0.9965183423913043\n",
      "\n",
      "Epoch 60. Loss: 0.007107360545946756, Train_acc 0.9965371621621621\n",
      "\n",
      "Epoch 60. Loss: 0.007401157122838735, Train_acc 0.9965137768817204\n",
      "\n",
      "Epoch 60. Loss: 0.008453159177590822, Train_acc 0.9964906417112299\n",
      "\n",
      "Epoch 60. Loss: 0.0076522093892729265, Train_acc 0.9965093085106383\n",
      "\n",
      "Epoch 60. Loss: 0.009780652393159507, Train_acc 0.9964864417989417\n",
      "\n",
      "Epoch 60. Loss: 0.00883509141473281, Train_acc 0.9965049342105263\n",
      "\n",
      "Epoch 60. Loss: 0.00805566263503931, Train_acc 0.9965232329842932\n",
      "\n",
      "Epoch 60. Loss: 0.008223346157137471, Train_acc 0.9965006510416666\n",
      "\n",
      "Epoch 60. Loss: 0.010069183103678154, Train_acc 0.9964783031088082\n",
      "\n",
      "Epoch 60. Loss: 0.009335183984357887, Train_acc 0.996496456185567\n",
      "\n",
      "Epoch 60. Loss: 0.00866646108298192, Train_acc 0.9965144230769231\n",
      "\n",
      "Epoch 60. Loss: 0.007889295644387062, Train_acc 0.99652\n",
      "\n",
      "Epoch 61. Loss: 0.007282731845743468, Train_acc 1.0\n",
      "\n",
      "Epoch 61. Loss: 0.006632473248221288, Train_acc 1.0\n",
      "\n",
      "Epoch 61. Loss: 0.00610990648237867, Train_acc 1.0\n",
      "\n",
      "Epoch 61. Loss: 0.0061905458735049025, Train_acc 1.0\n",
      "\n",
      "Epoch 61. Loss: 0.007258680850263261, Train_acc 0.9984375\n",
      "\n",
      "Epoch 61. Loss: 0.007661528693880877, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 61. Loss: 0.00785273221783004, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 61. Loss: 0.007398503286261813, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 61. Loss: 0.0074956802391583826, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 61. Loss: 0.008337031151077905, Train_acc 0.996875\n",
      "\n",
      "Epoch 61. Loss: 0.007964485167910242, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 61. Loss: 0.007364966974846647, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 61. Loss: 0.006696851636231356, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 61. Loss: 0.006097302373358976, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 61. Loss: 0.005565054611922238, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 61. Loss: 0.005115034513360352, Train_acc 0.998046875\n",
      "\n",
      "Epoch 61. Loss: 0.005809327437895021, Train_acc 0.9977022058823529\n",
      "\n",
      "Epoch 61. Loss: 0.005905791237429512, Train_acc 0.9978298611111112\n",
      "\n",
      "Epoch 61. Loss: 0.005484231130589455, Train_acc 0.9979440789473685\n",
      "\n",
      "Epoch 61. Loss: 0.005059425256826946, Train_acc 0.998046875\n",
      "\n",
      "Epoch 61. Loss: 0.004619959221027169, Train_acc 0.9981398809523809\n",
      "\n",
      "Epoch 61. Loss: 0.004357130566343849, Train_acc 0.9982244318181818\n",
      "\n",
      "Epoch 61. Loss: 0.00680497772017585, Train_acc 0.9979619565217391\n",
      "\n",
      "Epoch 61. Loss: 0.006157622653955482, Train_acc 0.998046875\n",
      "\n",
      "Epoch 61. Loss: 0.005654059042656508, Train_acc 0.998125\n",
      "\n",
      "Epoch 61. Loss: 0.005398967212549526, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 61. Loss: 0.006750933464865398, Train_acc 0.9979745370370371\n",
      "\n",
      "Epoch 61. Loss: 0.00619765534162567, Train_acc 0.998046875\n",
      "\n",
      "Epoch 61. Loss: 0.005659981771313065, Train_acc 0.998114224137931\n",
      "\n",
      "Epoch 61. Loss: 0.005237703780497236, Train_acc 0.9981770833333333\n",
      "\n",
      "Epoch 61. Loss: 0.004754727982574625, Train_acc 0.9982358870967742\n",
      "\n",
      "Epoch 61. Loss: 0.0046965413884913244, Train_acc 0.998291015625\n",
      "\n",
      "Epoch 61. Loss: 0.00476018439538139, Train_acc 0.998342803030303\n",
      "\n",
      "Epoch 61. Loss: 0.004912753512846153, Train_acc 0.9983915441176471\n",
      "\n",
      "Epoch 61. Loss: 0.0048818294666439785, Train_acc 0.9984375\n",
      "\n",
      "Epoch 61. Loss: 0.0049714734576401555, Train_acc 0.9984809027777778\n",
      "\n",
      "Epoch 61. Loss: 0.0067783404891721116, Train_acc 0.9983108108108109\n",
      "\n",
      "Epoch 61. Loss: 0.006453618814687286, Train_acc 0.9983552631578947\n",
      "\n",
      "Epoch 61. Loss: 0.006159428850500602, Train_acc 0.9983974358974359\n",
      "\n",
      "Epoch 61. Loss: 0.00587678161157413, Train_acc 0.9984375\n",
      "\n",
      "Epoch 61. Loss: 0.005337030305457431, Train_acc 0.9984756097560976\n",
      "\n",
      "Epoch 61. Loss: 0.004852093979187891, Train_acc 0.9985119047619048\n",
      "\n",
      "Epoch 61. Loss: 0.004425512385079043, Train_acc 0.998546511627907\n",
      "\n",
      "Epoch 61. Loss: 0.004278564212322632, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 61. Loss: 0.0038810361011851428, Train_acc 0.9986111111111111\n",
      "\n",
      "Epoch 61. Loss: 0.0035714997074722736, Train_acc 0.998641304347826\n",
      "\n",
      "Epoch 61. Loss: 0.0060860739548551585, Train_acc 0.9985039893617021\n",
      "\n",
      "Epoch 61. Loss: 0.005498442161461864, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 61. Loss: 0.004980645313901741, Train_acc 0.9985650510204082\n",
      "\n",
      "Epoch 61. Loss: 0.004502516210792881, Train_acc 0.99859375\n",
      "\n",
      "Epoch 61. Loss: 0.004355040958048483, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 61. Loss: 0.004620145084057671, Train_acc 0.9984975961538461\n",
      "\n",
      "Epoch 61. Loss: 0.00420328446429283, Train_acc 0.9985259433962265\n",
      "\n",
      "Epoch 61. Loss: 0.0038211791668856343, Train_acc 0.9985532407407407\n",
      "\n",
      "Epoch 61. Loss: 0.00385576710070886, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 61. Loss: 0.0034866996708869846, Train_acc 0.9986049107142857\n",
      "\n",
      "Epoch 61. Loss: 0.003173332190301783, Train_acc 0.9986293859649122\n",
      "\n",
      "Epoch 61. Loss: 0.0028918107544354133, Train_acc 0.9986530172413793\n",
      "\n",
      "Epoch 61. Loss: 0.0035714562411580863, Train_acc 0.9985434322033898\n",
      "\n",
      "Epoch 61. Loss: 0.0032566210207022176, Train_acc 0.9985677083333333\n",
      "\n",
      "Epoch 61. Loss: 0.0029961843163343023, Train_acc 0.9985911885245902\n",
      "\n",
      "Epoch 61. Loss: 0.002711871254444018, Train_acc 0.9986139112903226\n",
      "\n",
      "Epoch 61. Loss: 0.0039570113909243605, Train_acc 0.9985119047619048\n",
      "\n",
      "Epoch 61. Loss: 0.0035947817494225783, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 61. Loss: 0.004899693244375493, Train_acc 0.9984375\n",
      "\n",
      "Epoch 61. Loss: 0.0047457350465754024, Train_acc 0.9984611742424242\n",
      "\n",
      "Epoch 61. Loss: 0.004307418724282214, Train_acc 0.9984841417910447\n",
      "\n",
      "Epoch 61. Loss: 0.003931907720601451, Train_acc 0.9985064338235294\n",
      "\n",
      "Epoch 61. Loss: 0.004298169483380817, Train_acc 0.9984148550724637\n",
      "\n",
      "Epoch 61. Loss: 0.004773839569512579, Train_acc 0.9984375\n",
      "\n",
      "Epoch 61. Loss: 0.004429370082138694, Train_acc 0.9984595070422535\n",
      "\n",
      "Epoch 61. Loss: 0.004798833299474762, Train_acc 0.9983723958333334\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61. Loss: 0.004403889684979778, Train_acc 0.998394691780822\n",
      "\n",
      "Epoch 61. Loss: 0.004231952539403434, Train_acc 0.9984163851351351\n",
      "\n",
      "Epoch 61. Loss: 0.0038406239076204853, Train_acc 0.9984375\n",
      "\n",
      "Epoch 61. Loss: 0.003587381116002598, Train_acc 0.9984580592105263\n",
      "\n",
      "Epoch 61. Loss: 0.004934518065854727, Train_acc 0.9983766233766234\n",
      "\n",
      "Epoch 61. Loss: 0.004508626086854027, Train_acc 0.9983974358974359\n",
      "\n",
      "Epoch 61. Loss: 0.004092148466416973, Train_acc 0.9984177215189873\n",
      "\n",
      "Epoch 61. Loss: 0.004373095522232751, Train_acc 0.9984375\n",
      "\n",
      "Epoch 61. Loss: 0.0039698922949019675, Train_acc 0.9984567901234568\n",
      "\n",
      "Epoch 61. Loss: 0.0038209042553141955, Train_acc 0.9984756097560976\n",
      "\n",
      "Epoch 61. Loss: 0.0039947002045692724, Train_acc 0.9984939759036144\n",
      "\n",
      "Epoch 61. Loss: 0.0037180055310843934, Train_acc 0.9985119047619048\n",
      "\n",
      "Epoch 61. Loss: 0.003537832560511102, Train_acc 0.9985294117647059\n",
      "\n",
      "Epoch 61. Loss: 0.0038360031395003225, Train_acc 0.9984556686046512\n",
      "\n",
      "Epoch 61. Loss: 0.004144005251200052, Train_acc 0.9983836206896551\n",
      "\n",
      "Epoch 61. Loss: 0.0075423827221432795, Train_acc 0.9983132102272727\n",
      "\n",
      "Epoch 61. Loss: 0.007164206079432917, Train_acc 0.9983321629213483\n",
      "\n",
      "Epoch 61. Loss: 0.0072737880357708505, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 61. Loss: 0.008019434464747248, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 61. Loss: 0.008186581889785414, Train_acc 0.9981317934782609\n",
      "\n",
      "Epoch 61. Loss: 0.00741054514292367, Train_acc 0.9981518817204301\n",
      "\n",
      "Epoch 61. Loss: 0.007102501748816559, Train_acc 0.9981715425531915\n",
      "\n",
      "Epoch 61. Loss: 0.014540416621103634, Train_acc 0.9979440789473685\n",
      "\n",
      "Epoch 61. Loss: 0.013196891050801948, Train_acc 0.9979654947916666\n",
      "\n",
      "Epoch 61. Loss: 0.0173354779195186, Train_acc 0.9978253865979382\n",
      "\n",
      "Epoch 61. Loss: 0.01701819665086834, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 61. Loss: 0.015355724287717285, Train_acc 0.9977904040404041\n",
      "\n",
      "Epoch 61. Loss: 0.013842284118564512, Train_acc 0.9978125\n",
      "\n",
      "[Epoch 61 Batch 100] Loss: 0.012474934342214207 Training: accuracy=0.997834\n",
      "Epoch 61. Loss: 0.012474934342214207, Train_acc 0.9978341584158416\n",
      "\n",
      "Epoch 61. Loss: 0.011468649077602096, Train_acc 0.9978553921568627\n",
      "\n",
      "Epoch 61. Loss: 0.011372071841229082, Train_acc 0.9978003640776699\n",
      "\n",
      "Epoch 61. Loss: 0.010354216473935468, Train_acc 0.9978215144230769\n",
      "\n",
      "Epoch 61. Loss: 0.01024435437706568, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 61. Loss: 0.009273606362128256, Train_acc 0.9977889150943396\n",
      "\n",
      "Epoch 61. Loss: 0.010427932170495986, Train_acc 0.9977365654205608\n",
      "\n",
      "Epoch 61. Loss: 0.009820974914698839, Train_acc 0.9977575231481481\n",
      "\n",
      "Epoch 61. Loss: 0.012321412904681897, Train_acc 0.997634747706422\n",
      "\n",
      "Epoch 61. Loss: 0.012653036722799065, Train_acc 0.9975852272727272\n",
      "\n",
      "Epoch 61. Loss: 0.01211032453634732, Train_acc 0.9976069819819819\n",
      "\n",
      "Epoch 61. Loss: 0.016083146781847416, Train_acc 0.9974888392857143\n",
      "\n",
      "Epoch 61. Loss: 0.014765086770132666, Train_acc 0.9975110619469026\n",
      "\n",
      "Epoch 61. Loss: 0.014269826728918092, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 61. Loss: 0.015982853250638786, Train_acc 0.9974864130434783\n",
      "\n",
      "Epoch 61. Loss: 0.016954371893646847, Train_acc 0.9973733836206896\n",
      "\n",
      "Epoch 61. Loss: 0.015401148755729972, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 61. Loss: 0.013939667482399892, Train_acc 0.9974179025423728\n",
      "\n",
      "Epoch 61. Loss: 0.012640051149907516, Train_acc 0.9974396008403361\n",
      "\n",
      "Epoch 61. Loss: 0.013707578014060385, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 61. Loss: 0.018359943700484507, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 61. Loss: 0.016836410987885658, Train_acc 0.9971823770491803\n",
      "\n",
      "Epoch 61. Loss: 0.015433985860432861, Train_acc 0.9972052845528455\n",
      "\n",
      "Epoch 61. Loss: 0.014382242054151605, Train_acc 0.9972278225806451\n",
      "\n",
      "Epoch 61. Loss: 0.01466553410030047, Train_acc 0.9971875\n",
      "\n",
      "Epoch 61. Loss: 0.01477793417993164, Train_acc 0.9971478174603174\n",
      "\n",
      "Epoch 61. Loss: 0.014800643642601155, Train_acc 0.9971087598425197\n",
      "\n",
      "Epoch 61. Loss: 0.013400498420058296, Train_acc 0.99713134765625\n",
      "\n",
      "Epoch 61. Loss: 0.01366693848227734, Train_acc 0.997093023255814\n",
      "\n",
      "Epoch 61. Loss: 0.012353557729172182, Train_acc 0.9971153846153846\n",
      "\n",
      "Epoch 61. Loss: 0.01208249111483765, Train_acc 0.9970777671755725\n",
      "\n",
      "Epoch 61. Loss: 0.011109097714814, Train_acc 0.9970999053030303\n",
      "\n",
      "Epoch 61. Loss: 0.011880771032505441, Train_acc 0.997062969924812\n",
      "\n",
      "Epoch 61. Loss: 0.015596684332072622, Train_acc 0.9969682835820896\n",
      "\n",
      "Epoch 61. Loss: 0.014340117065948147, Train_acc 0.9969907407407408\n",
      "\n",
      "Epoch 61. Loss: 0.014687656712986736, Train_acc 0.9969554227941176\n",
      "\n",
      "Epoch 61. Loss: 0.014501977226100304, Train_acc 0.9968635948905109\n",
      "\n",
      "Epoch 61. Loss: 0.017316905344392605, Train_acc 0.9968297101449275\n",
      "\n",
      "Epoch 61. Loss: 0.015604217344053201, Train_acc 0.9968525179856115\n",
      "\n",
      "Epoch 61. Loss: 0.014652272512937436, Train_acc 0.996875\n",
      "\n",
      "Epoch 61. Loss: 0.013714904601134226, Train_acc 0.9968971631205674\n",
      "\n",
      "Epoch 61. Loss: 0.012619074517085282, Train_acc 0.996919014084507\n",
      "\n",
      "Epoch 61. Loss: 0.011655025538290257, Train_acc 0.9969405594405595\n",
      "\n",
      "Epoch 61. Loss: 0.010623354620510086, Train_acc 0.9969618055555556\n",
      "\n",
      "Epoch 61. Loss: 0.009993057419082891, Train_acc 0.9969827586206896\n",
      "\n",
      "Epoch 61. Loss: 0.009610905154098306, Train_acc 0.9970034246575342\n",
      "\n",
      "Epoch 61. Loss: 0.01030031102468005, Train_acc 0.9969706632653061\n",
      "\n",
      "Epoch 61. Loss: 0.009826362386966625, Train_acc 0.9969911317567568\n",
      "\n",
      "Epoch 61. Loss: 0.010032422137819123, Train_acc 0.9970113255033557\n",
      "\n",
      "Epoch 61. Loss: 0.009190391640514039, Train_acc 0.99703125\n",
      "\n",
      "Epoch 61. Loss: 0.009387917253211054, Train_acc 0.9969991721854304\n",
      "\n",
      "Epoch 61. Loss: 0.008554678671547692, Train_acc 0.9970189144736842\n",
      "\n",
      "Epoch 61. Loss: 0.0077529374125593934, Train_acc 0.9970383986928104\n",
      "\n",
      "Epoch 61. Loss: 0.006995506895214717, Train_acc 0.9970576298701299\n",
      "\n",
      "Epoch 61. Loss: 0.007000446971622468, Train_acc 0.9970262096774194\n",
      "\n",
      "Epoch 61. Loss: 0.006498041823611284, Train_acc 0.9970452724358975\n",
      "\n",
      "Epoch 61. Loss: 0.005921861461458168, Train_acc 0.9970640923566879\n",
      "\n",
      "Epoch 61. Loss: 0.005674637453063633, Train_acc 0.9970826740506329\n",
      "\n",
      "Epoch 61. Loss: 0.005958181072447574, Train_acc 0.9970518867924528\n",
      "\n",
      "Epoch 61. Loss: 0.005424444928026685, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 61. Loss: 0.005066744437987198, Train_acc 0.9970885093167702\n",
      "\n",
      "Epoch 61. Loss: 0.004611260983513302, Train_acc 0.9971064814814815\n",
      "\n",
      "Epoch 61. Loss: 0.004172154400907314, Train_acc 0.9971242331288344\n",
      "\n",
      "Epoch 61. Loss: 0.00416834806911262, Train_acc 0.997141768292683\n",
      "\n",
      "Epoch 61. Loss: 0.005796456609774639, Train_acc 0.9971117424242424\n",
      "\n",
      "Epoch 61. Loss: 0.005484483138308534, Train_acc 0.9971291415662651\n",
      "\n",
      "Epoch 61. Loss: 0.004956753975257449, Train_acc 0.9971463323353293\n",
      "\n",
      "Epoch 61. Loss: 0.004747382387575661, Train_acc 0.9971633184523809\n",
      "\n",
      "Epoch 61. Loss: 0.004389609859003563, Train_acc 0.9971801035502958\n",
      "\n",
      "Epoch 61. Loss: 0.004174458167505806, Train_acc 0.9971966911764706\n",
      "\n",
      "Epoch 61. Loss: 0.004965755058722984, Train_acc 0.9971673976608187\n",
      "\n",
      "Epoch 61. Loss: 0.005041419905481301, Train_acc 0.9971838662790697\n",
      "\n",
      "Epoch 61. Loss: 0.0047509365383305215, Train_acc 0.9972001445086706\n",
      "\n",
      "Epoch 61. Loss: 0.004569920467154807, Train_acc 0.9972162356321839\n",
      "\n",
      "Epoch 61. Loss: 0.004327487958729231, Train_acc 0.9972321428571429\n",
      "\n",
      "Epoch 61. Loss: 0.007553737547928063, Train_acc 0.9972034801136364\n",
      "\n",
      "Epoch 61. Loss: 0.006925825648435027, Train_acc 0.997219279661017\n",
      "\n",
      "Epoch 61. Loss: 0.006324429383278776, Train_acc 0.9972349016853933\n",
      "\n",
      "Epoch 61. Loss: 0.005822997943111559, Train_acc 0.9972503491620112\n",
      "\n",
      "Epoch 61. Loss: 0.005438351434959442, Train_acc 0.997265625\n",
      "\n",
      "Epoch 61. Loss: 0.004904159445507668, Train_acc 0.9972807320441989\n",
      "\n",
      "Epoch 61. Loss: 0.005235537697920211, Train_acc 0.9972527472527473\n",
      "\n",
      "Epoch 61. Loss: 0.004725219283564526, Train_acc 0.9972677595628415\n",
      "\n",
      "Epoch 61. Loss: 0.008593464470562612, Train_acc 0.9971552309782609\n",
      "\n",
      "Epoch 61. Loss: 0.007771966850702636, Train_acc 0.9971706081081081\n",
      "\n",
      "Epoch 61. Loss: 0.007005931941542668, Train_acc 0.9971858198924731\n",
      "\n",
      "Epoch 61. Loss: 0.006315140662827712, Train_acc 0.9972008689839572\n",
      "\n",
      "Epoch 61. Loss: 0.008262385231171806, Train_acc 0.9971742021276596\n",
      "\n",
      "Epoch 61. Loss: 0.007821884988656425, Train_acc 0.9971891534391535\n",
      "\n",
      "Epoch 61. Loss: 0.011035634716371402, Train_acc 0.9971628289473684\n",
      "\n",
      "Epoch 61. Loss: 0.010964903695898986, Train_acc 0.9971367801047121\n",
      "\n",
      "Epoch 61. Loss: 0.010240037925520005, Train_acc 0.9971516927083334\n",
      "\n",
      "Epoch 61. Loss: 0.010737284272889908, Train_acc 0.9971259715025906\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61. Loss: 0.00993096617048736, Train_acc 0.9971407860824743\n",
      "\n",
      "Epoch 61. Loss: 0.009064326080943694, Train_acc 0.9971554487179487\n",
      "\n",
      "Epoch 61. Loss: 0.008377743575288848, Train_acc 0.99716\n",
      "\n",
      "Epoch 62. Loss: 0.007579456707026285, Train_acc 1.0\n",
      "\n",
      "Epoch 62. Loss: 0.007414740233289351, Train_acc 1.0\n",
      "\n",
      "Epoch 62. Loss: 0.006735041494081229, Train_acc 1.0\n",
      "\n",
      "Epoch 62. Loss: 0.0076750525876073325, Train_acc 0.998046875\n",
      "\n",
      "Epoch 62. Loss: 0.0077046637127567786, Train_acc 0.996875\n",
      "\n",
      "Epoch 62. Loss: 0.006951918381539051, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 62. Loss: 0.0063887744871560315, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 62. Loss: 0.005772722335932519, Train_acc 0.998046875\n",
      "\n",
      "Epoch 62. Loss: 0.006872658868680477, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 62. Loss: 0.006553648591458869, Train_acc 0.99765625\n",
      "\n",
      "Epoch 62. Loss: 0.008196101461726491, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 62. Loss: 0.007510256874266027, Train_acc 0.9967447916666666\n",
      "\n",
      "Epoch 62. Loss: 0.00680213026203648, Train_acc 0.9969951923076923\n",
      "\n",
      "Epoch 62. Loss: 0.006315746581349693, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 62. Loss: 0.008397704110259344, Train_acc 0.996875\n",
      "\n",
      "Epoch 62. Loss: 0.008048726959047792, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 62. Loss: 0.007961469599322746, Train_acc 0.9972426470588235\n",
      "\n",
      "Epoch 62. Loss: 0.007240299543242548, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 62. Loss: 0.006564043270499313, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 62. Loss: 0.006464952150986318, Train_acc 0.99765625\n",
      "\n",
      "Epoch 62. Loss: 0.006164277939317277, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 62. Loss: 0.00896680982260494, Train_acc 0.9975142045454546\n",
      "\n",
      "Epoch 62. Loss: 0.008101191524482751, Train_acc 0.9976222826086957\n",
      "\n",
      "Epoch 62. Loss: 0.007733672575712488, Train_acc 0.9977213541666666\n",
      "\n",
      "Epoch 62. Loss: 0.007807807370925205, Train_acc 0.9975\n",
      "\n",
      "Epoch 62. Loss: 0.0070634788438753105, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 62. Loss: 0.006630239721245392, Train_acc 0.9976851851851852\n",
      "\n",
      "Epoch 62. Loss: 0.006148090630455455, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 62. Loss: 0.008932605239466108, Train_acc 0.9973060344827587\n",
      "\n",
      "Epoch 62. Loss: 0.01225243681912, Train_acc 0.996875\n",
      "\n",
      "Epoch 62. Loss: 0.01105814972915314, Train_acc 0.9969758064516129\n",
      "\n",
      "Epoch 62. Loss: 0.010271550830659828, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 62. Loss: 0.009368180415406133, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 62. Loss: 0.009125986661873137, Train_acc 0.9972426470588235\n",
      "\n",
      "Epoch 62. Loss: 0.014843518107856996, Train_acc 0.996875\n",
      "\n",
      "Epoch 62. Loss: 0.013443655910144243, Train_acc 0.9969618055555556\n",
      "\n",
      "Epoch 62. Loss: 0.012412849726498122, Train_acc 0.997043918918919\n",
      "\n",
      "Epoch 62. Loss: 0.011589747356000539, Train_acc 0.9971217105263158\n",
      "\n",
      "Epoch 62. Loss: 0.010791796137726007, Train_acc 0.9971955128205128\n",
      "\n",
      "Epoch 62. Loss: 0.01122319799125406, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 62. Loss: 0.010593240916745777, Train_acc 0.997141768292683\n",
      "\n",
      "Epoch 62. Loss: 0.01324317906202398, Train_acc 0.9970238095238095\n",
      "\n",
      "Epoch 62. Loss: 0.011988209797958484, Train_acc 0.997093023255814\n",
      "\n",
      "Epoch 62. Loss: 0.011847960976380065, Train_acc 0.9969815340909091\n",
      "\n",
      "Epoch 62. Loss: 0.010703466768854518, Train_acc 0.9970486111111111\n",
      "\n",
      "Epoch 62. Loss: 0.009711209877498368, Train_acc 0.9971127717391305\n",
      "\n",
      "Epoch 62. Loss: 0.010142107574642378, Train_acc 0.9970079787234043\n",
      "\n",
      "Epoch 62. Loss: 0.009815088452548396, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 62. Loss: 0.00951394422909672, Train_acc 0.9969706632653061\n",
      "\n",
      "Epoch 62. Loss: 0.008720829230254636, Train_acc 0.99703125\n",
      "\n",
      "Epoch 62. Loss: 0.007934697054827135, Train_acc 0.9970894607843137\n",
      "\n",
      "Epoch 62. Loss: 0.007206486740320701, Train_acc 0.9971454326923077\n",
      "\n",
      "Epoch 62. Loss: 0.007019668301069539, Train_acc 0.9971992924528302\n",
      "\n",
      "Epoch 62. Loss: 0.0063257890856592905, Train_acc 0.9972511574074074\n",
      "\n",
      "Epoch 62. Loss: 0.005903217410638545, Train_acc 0.9973011363636364\n",
      "\n",
      "Epoch 62. Loss: 0.005792204930419875, Train_acc 0.9973493303571429\n",
      "\n",
      "Epoch 62. Loss: 0.005249153135366502, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 62. Loss: 0.004955505659637389, Train_acc 0.9974407327586207\n",
      "\n",
      "Epoch 62. Loss: 0.004473031517457437, Train_acc 0.9974841101694916\n",
      "\n",
      "Epoch 62. Loss: 0.004097911150500004, Train_acc 0.9975260416666667\n",
      "\n",
      "Epoch 62. Loss: 0.004512759888540051, Train_acc 0.9975665983606558\n",
      "\n",
      "Epoch 62. Loss: 0.004072120528989964, Train_acc 0.9976058467741935\n",
      "\n",
      "Epoch 62. Loss: 0.004681284457362235, Train_acc 0.9975198412698413\n",
      "\n",
      "Epoch 62. Loss: 0.004328222894780225, Train_acc 0.99755859375\n",
      "\n",
      "Epoch 62. Loss: 0.00539397816280638, Train_acc 0.9974759615384615\n",
      "\n",
      "Epoch 62. Loss: 0.004888213917527443, Train_acc 0.9975142045454546\n",
      "\n",
      "Epoch 62. Loss: 0.004414543956627409, Train_acc 0.9975513059701493\n",
      "\n",
      "Epoch 62. Loss: 0.0040172164860233315, Train_acc 0.9975873161764706\n",
      "\n",
      "Epoch 62. Loss: 0.0036327630946366173, Train_acc 0.9976222826086957\n",
      "\n",
      "Epoch 62. Loss: 0.0038503426632429524, Train_acc 0.99765625\n",
      "\n",
      "Epoch 62. Loss: 0.0034838623274862346, Train_acc 0.9976892605633803\n",
      "\n",
      "Epoch 62. Loss: 0.003299915821824185, Train_acc 0.9977213541666666\n",
      "\n",
      "Epoch 62. Loss: 0.0032541246341678907, Train_acc 0.9977525684931506\n",
      "\n",
      "Epoch 62. Loss: 0.0038470415847313474, Train_acc 0.9976773648648649\n",
      "\n",
      "Epoch 62. Loss: 0.004252022321684247, Train_acc 0.9977083333333333\n",
      "\n",
      "Epoch 62. Loss: 0.005661508238908428, Train_acc 0.9976356907894737\n",
      "\n",
      "Epoch 62. Loss: 0.005138253294614057, Train_acc 0.9976663961038961\n",
      "\n",
      "Epoch 62. Loss: 0.004740188311095923, Train_acc 0.9976963141025641\n",
      "\n",
      "Epoch 62. Loss: 0.004470354713437756, Train_acc 0.9977254746835443\n",
      "\n",
      "Epoch 62. Loss: 0.004088250702750206, Train_acc 0.99775390625\n",
      "\n",
      "Epoch 62. Loss: 0.00381106427161606, Train_acc 0.9977816358024691\n",
      "\n",
      "Epoch 62. Loss: 0.003464111390311861, Train_acc 0.9978086890243902\n",
      "\n",
      "Epoch 62. Loss: 0.0034929731902623275, Train_acc 0.9978350903614458\n",
      "\n",
      "Epoch 62. Loss: 0.004245371058625946, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 62. Loss: 0.003834385243376019, Train_acc 0.9977941176470588\n",
      "\n",
      "Epoch 62. Loss: 0.006582853779780795, Train_acc 0.9977289244186046\n",
      "\n",
      "Epoch 62. Loss: 0.008105835767615971, Train_acc 0.9976652298850575\n",
      "\n",
      "Epoch 62. Loss: 0.00737136642583457, Train_acc 0.9976917613636364\n",
      "\n",
      "Epoch 62. Loss: 0.006791231991539872, Train_acc 0.9977176966292135\n",
      "\n",
      "Epoch 62. Loss: 0.006493647390252778, Train_acc 0.9977430555555555\n",
      "\n",
      "Epoch 62. Loss: 0.006021787204221423, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 62. Loss: 0.006137380887531223, Train_acc 0.9977072010869565\n",
      "\n",
      "Epoch 62. Loss: 0.0063526306244399994, Train_acc 0.9977318548387096\n",
      "\n",
      "Epoch 62. Loss: 0.005752836522409708, Train_acc 0.9977559840425532\n",
      "\n",
      "Epoch 62. Loss: 0.005297141813367061, Train_acc 0.9977796052631579\n",
      "\n",
      "Epoch 62. Loss: 0.004800731733119371, Train_acc 0.997802734375\n",
      "\n",
      "Epoch 62. Loss: 0.00490954048269321, Train_acc 0.9978253865979382\n",
      "\n",
      "Epoch 62. Loss: 0.006421855704486335, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 62. Loss: 0.005843816507225825, Train_acc 0.9977904040404041\n",
      "\n",
      "Epoch 62. Loss: 0.005293800071609178, Train_acc 0.9978125\n",
      "\n",
      "[Epoch 62 Batch 100] Loss: 0.004774015965513301 Training: accuracy=0.997834\n",
      "Epoch 62. Loss: 0.004774015965513301, Train_acc 0.9978341584158416\n",
      "\n",
      "Epoch 62. Loss: 0.004356552386473711, Train_acc 0.9978553921568627\n",
      "\n",
      "Epoch 62. Loss: 0.003977244072801854, Train_acc 0.997876213592233\n",
      "\n",
      "Epoch 62. Loss: 0.003715255716537225, Train_acc 0.9978966346153846\n",
      "\n",
      "Epoch 62. Loss: 0.0034157835573246672, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 62. Loss: 0.0031399545089880907, Train_acc 0.9979363207547169\n",
      "\n",
      "Epoch 62. Loss: 0.002865287174780022, Train_acc 0.9979556074766355\n",
      "\n",
      "Epoch 62. Loss: 0.006152641782163546, Train_acc 0.9978298611111112\n",
      "\n",
      "Epoch 62. Loss: 0.005562408396987251, Train_acc 0.9978497706422018\n",
      "\n",
      "Epoch 62. Loss: 0.005107916353002755, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 62. Loss: 0.0050640405896504835, Train_acc 0.9978885135135135\n",
      "\n",
      "Epoch 62. Loss: 0.006109572166192542, Train_acc 0.9978376116071429\n",
      "\n",
      "Epoch 62. Loss: 0.0083251718854797, Train_acc 0.9977184734513275\n",
      "\n",
      "Epoch 62. Loss: 0.008007646185239444, Train_acc 0.9977384868421053\n",
      "\n",
      "Epoch 62. Loss: 0.007277579322733989, Train_acc 0.9977581521739131\n",
      "\n",
      "Epoch 62. Loss: 0.006593487045999961, Train_acc 0.9977774784482759\n",
      "\n",
      "Epoch 62. Loss: 0.006382865204068956, Train_acc 0.9977964743589743\n",
      "\n",
      "Epoch 62. Loss: 0.00959379150896037, Train_acc 0.9975503177966102\n",
      "\n",
      "Epoch 62. Loss: 0.008704928395586217, Train_acc 0.9975709033613446\n",
      "\n",
      "Epoch 62. Loss: 0.007844735638822452, Train_acc 0.9975911458333333\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62. Loss: 0.007261161811895969, Train_acc 0.9976110537190083\n",
      "\n",
      "Epoch 62. Loss: 0.007296915832383457, Train_acc 0.9976306352459017\n",
      "\n",
      "Epoch 62. Loss: 0.008473830431601128, Train_acc 0.9975863821138211\n",
      "\n",
      "Epoch 62. Loss: 0.01198821731796925, Train_acc 0.9974798387096774\n",
      "\n",
      "Epoch 62. Loss: 0.014984685645023569, Train_acc 0.9974375\n",
      "\n",
      "Epoch 62. Loss: 0.01369207168640457, Train_acc 0.9974578373015873\n",
      "\n",
      "Epoch 62. Loss: 0.013500254251257442, Train_acc 0.9974163385826772\n",
      "\n",
      "Epoch 62. Loss: 0.016252403018798704, Train_acc 0.997314453125\n",
      "\n",
      "Epoch 62. Loss: 0.0155038505565461, Train_acc 0.9973352713178295\n",
      "\n",
      "Epoch 62. Loss: 0.016369647996545122, Train_acc 0.9972956730769231\n",
      "\n",
      "Epoch 62. Loss: 0.014998250760364788, Train_acc 0.9973163167938931\n",
      "\n",
      "Epoch 62. Loss: 0.013877376742120019, Train_acc 0.9973366477272727\n",
      "\n",
      "Epoch 62. Loss: 0.015591803783436504, Train_acc 0.9971804511278195\n",
      "\n",
      "Epoch 62. Loss: 0.014705848787435789, Train_acc 0.9972014925373134\n",
      "\n",
      "Epoch 62. Loss: 0.013303811747292563, Train_acc 0.9972222222222222\n",
      "\n",
      "Epoch 62. Loss: 0.013716275228673119, Train_acc 0.9971852022058824\n",
      "\n",
      "Epoch 62. Loss: 0.013283643447113542, Train_acc 0.9971487226277372\n",
      "\n",
      "Epoch 62. Loss: 0.021367920180635908, Train_acc 0.9969995471014492\n",
      "\n",
      "Epoch 62. Loss: 0.02021889046845787, Train_acc 0.996964928057554\n",
      "\n",
      "Epoch 62. Loss: 0.019463568271857083, Train_acc 0.9969308035714286\n",
      "\n",
      "Epoch 62. Loss: 0.018616638395930748, Train_acc 0.9968971631205674\n",
      "\n",
      "Epoch 62. Loss: 0.022374148425828296, Train_acc 0.9967539612676056\n",
      "\n",
      "Epoch 62. Loss: 0.020781559308130335, Train_acc 0.9967766608391608\n",
      "\n",
      "Epoch 62. Loss: 0.01890579835266661, Train_acc 0.9967990451388888\n",
      "\n",
      "Epoch 62. Loss: 0.01804477140925042, Train_acc 0.9968211206896552\n",
      "\n",
      "Epoch 62. Loss: 0.017544664991990137, Train_acc 0.9967893835616438\n",
      "\n",
      "Epoch 62. Loss: 0.01585353222300447, Train_acc 0.9968112244897959\n",
      "\n",
      "Epoch 62. Loss: 0.018754261867491934, Train_acc 0.9966216216216216\n",
      "\n",
      "Epoch 62. Loss: 0.019083782668073656, Train_acc 0.9965918624161074\n",
      "\n",
      "Epoch 62. Loss: 0.018567946785831166, Train_acc 0.9965625\n",
      "\n",
      "Epoch 62. Loss: 0.01725463992429708, Train_acc 0.9965852649006622\n",
      "\n",
      "Epoch 62. Loss: 0.01947907553082348, Train_acc 0.9965049342105263\n",
      "\n",
      "Epoch 62. Loss: 0.019560345524242295, Train_acc 0.9964767156862745\n",
      "\n",
      "Epoch 62. Loss: 0.02700899259480009, Train_acc 0.9963474025974026\n",
      "\n",
      "Epoch 62. Loss: 0.024415751337845647, Train_acc 0.9963709677419355\n",
      "\n",
      "Epoch 62. Loss: 0.023258975835746102, Train_acc 0.9963441506410257\n",
      "\n",
      "Epoch 62. Loss: 0.0211263661733096, Train_acc 0.9963674363057324\n",
      "\n",
      "Epoch 62. Loss: 0.021986470794751512, Train_acc 0.9962915348101266\n",
      "\n",
      "Epoch 62. Loss: 0.020068443966127277, Train_acc 0.996314858490566\n",
      "\n",
      "Epoch 62. Loss: 0.020029591085508624, Train_acc 0.996240234375\n",
      "\n",
      "Epoch 62. Loss: 0.018213914031642818, Train_acc 0.9962635869565217\n",
      "\n",
      "Epoch 62. Loss: 0.01649826324737055, Train_acc 0.9962866512345679\n",
      "\n",
      "Epoch 62. Loss: 0.01670606429209694, Train_acc 0.9962615030674846\n",
      "\n",
      "Epoch 62. Loss: 0.01543537853320287, Train_acc 0.9962842987804879\n",
      "\n",
      "Epoch 62. Loss: 0.017634988902448235, Train_acc 0.9962594696969697\n",
      "\n",
      "Epoch 62. Loss: 0.024234219114576534, Train_acc 0.9961408132530121\n",
      "\n",
      "Epoch 62. Loss: 0.02253170797766276, Train_acc 0.9961639221556886\n",
      "\n",
      "Epoch 62. Loss: 0.021620478201279294, Train_acc 0.9961402529761905\n",
      "\n",
      "Epoch 62. Loss: 0.020348550872536827, Train_acc 0.9961168639053254\n",
      "\n",
      "Epoch 62. Loss: 0.018604265960558353, Train_acc 0.9961397058823529\n",
      "\n",
      "Epoch 62. Loss: 0.017412153463814348, Train_acc 0.9961622807017544\n",
      "\n",
      "Epoch 62. Loss: 0.016482224946844898, Train_acc 0.9961845930232558\n",
      "\n",
      "Epoch 62. Loss: 0.016635103570486597, Train_acc 0.9961614884393064\n",
      "\n",
      "Epoch 62. Loss: 0.01580366865283146, Train_acc 0.9961386494252874\n",
      "\n",
      "Epoch 62. Loss: 0.01574417613881136, Train_acc 0.9960714285714286\n",
      "\n",
      "Epoch 62. Loss: 0.015023256059920536, Train_acc 0.9960493607954546\n",
      "\n",
      "Epoch 62. Loss: 0.013686952893881422, Train_acc 0.9960716807909604\n",
      "\n",
      "Epoch 62. Loss: 0.012340168328665184, Train_acc 0.99609375\n",
      "\n",
      "Epoch 62. Loss: 0.01130944356761797, Train_acc 0.9961155726256983\n",
      "\n",
      "Epoch 62. Loss: 0.011422441255531523, Train_acc 0.99609375\n",
      "\n",
      "Epoch 62. Loss: 0.011912360431088639, Train_acc 0.9960721685082873\n",
      "\n",
      "Epoch 62. Loss: 0.010863926453218133, Train_acc 0.99609375\n",
      "\n",
      "Epoch 62. Loss: 0.01061774379118556, Train_acc 0.9960724043715847\n",
      "\n",
      "Epoch 62. Loss: 0.009677036608663418, Train_acc 0.99609375\n",
      "\n",
      "Epoch 62. Loss: 0.010344755877918499, Train_acc 0.9960726351351351\n",
      "\n",
      "Epoch 62. Loss: 0.009861564022183267, Train_acc 0.99609375\n",
      "\n",
      "Epoch 62. Loss: 0.009545902923312647, Train_acc 0.9961146390374331\n",
      "\n",
      "Epoch 62. Loss: 0.00870168765070307, Train_acc 0.9961353058510638\n",
      "\n",
      "Epoch 62. Loss: 0.008106921867420682, Train_acc 0.996155753968254\n",
      "\n",
      "Epoch 62. Loss: 0.007451682412675388, Train_acc 0.9961759868421053\n",
      "\n",
      "Epoch 62. Loss: 0.009556065834210545, Train_acc 0.9961551047120419\n",
      "\n",
      "Epoch 62. Loss: 0.008673995480109362, Train_acc 0.9961751302083334\n",
      "\n",
      "Epoch 62. Loss: 0.00804153255220721, Train_acc 0.9961949481865285\n",
      "\n",
      "Epoch 62. Loss: 0.007577104235371677, Train_acc 0.9962145618556701\n",
      "\n",
      "Epoch 62. Loss: 0.0093053007033593, Train_acc 0.9961939102564102\n",
      "\n",
      "Epoch 62. Loss: 0.010828899494450678, Train_acc 0.99616\n",
      "\n",
      "Epoch 63. Loss: 0.011849087351537993, Train_acc 0.9921875\n",
      "\n",
      "Epoch 63. Loss: 0.012291455454209968, Train_acc 0.98828125\n",
      "\n",
      "Epoch 63. Loss: 0.011184432177447103, Train_acc 0.9921875\n",
      "\n",
      "Epoch 63. Loss: 0.01323270625058069, Train_acc 0.9921875\n",
      "\n",
      "Epoch 63. Loss: 0.013183953735380657, Train_acc 0.9921875\n",
      "\n",
      "Epoch 63. Loss: 0.016678184157445392, Train_acc 0.9921875\n",
      "\n",
      "Epoch 63. Loss: 0.01652766064778062, Train_acc 0.9921875\n",
      "\n",
      "Epoch 63. Loss: 0.015070676842109195, Train_acc 0.9931640625\n",
      "\n",
      "Epoch 63. Loss: 0.013674305740021913, Train_acc 0.9939236111111112\n",
      "\n",
      "Epoch 63. Loss: 0.012794579368552491, Train_acc 0.99453125\n",
      "\n",
      "Epoch 63. Loss: 0.012752066449869506, Train_acc 0.9943181818181818\n",
      "\n",
      "Epoch 63. Loss: 0.012917001993103772, Train_acc 0.994140625\n",
      "\n",
      "Epoch 63. Loss: 0.01291408487839456, Train_acc 0.9939903846153846\n",
      "\n",
      "Epoch 63. Loss: 0.012880454256531199, Train_acc 0.9938616071428571\n",
      "\n",
      "Epoch 63. Loss: 0.012821479423549711, Train_acc 0.99375\n",
      "\n",
      "Epoch 63. Loss: 0.01161418312216053, Train_acc 0.994140625\n",
      "\n",
      "Epoch 63. Loss: 0.010821307243660835, Train_acc 0.9944852941176471\n",
      "\n",
      "Epoch 63. Loss: 0.009999260292468143, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 63. Loss: 0.009142365969323522, Train_acc 0.9950657894736842\n",
      "\n",
      "Epoch 63. Loss: 0.010274496525916523, Train_acc 0.994921875\n",
      "\n",
      "Epoch 63. Loss: 0.011400934100502491, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 63. Loss: 0.012708649783152724, Train_acc 0.9946732954545454\n",
      "\n",
      "Epoch 63. Loss: 0.011626078764782891, Train_acc 0.9949048913043478\n",
      "\n",
      "Epoch 63. Loss: 0.013753156286644828, Train_acc 0.9944661458333334\n",
      "\n",
      "Epoch 63. Loss: 0.015460517634899522, Train_acc 0.9940625\n",
      "\n",
      "Epoch 63. Loss: 0.013968495392243435, Train_acc 0.9942908653846154\n",
      "\n",
      "Epoch 63. Loss: 0.012692584759930852, Train_acc 0.9945023148148148\n",
      "\n",
      "Epoch 63. Loss: 0.011656005541107132, Train_acc 0.9946986607142857\n",
      "\n",
      "Epoch 63. Loss: 0.010549345424153126, Train_acc 0.9948814655172413\n",
      "\n",
      "Epoch 63. Loss: 0.00979235082209353, Train_acc 0.9950520833333333\n",
      "\n",
      "Epoch 63. Loss: 0.009223372321265142, Train_acc 0.9952116935483871\n",
      "\n",
      "Epoch 63. Loss: 0.00934737115884173, Train_acc 0.995361328125\n",
      "\n",
      "Epoch 63. Loss: 0.010197834877231849, Train_acc 0.9952651515151515\n",
      "\n",
      "Epoch 63. Loss: 0.01292792338853401, Train_acc 0.9949448529411765\n",
      "\n",
      "Epoch 63. Loss: 0.014533122289705176, Train_acc 0.9948660714285714\n",
      "\n",
      "Epoch 63. Loss: 0.013678729824895767, Train_acc 0.9950086805555556\n",
      "\n",
      "Epoch 63. Loss: 0.01264916668270538, Train_acc 0.995143581081081\n",
      "\n",
      "Epoch 63. Loss: 0.012209921679805306, Train_acc 0.9952713815789473\n",
      "\n",
      "Epoch 63. Loss: 0.011144330019908178, Train_acc 0.9953926282051282\n",
      "\n",
      "Epoch 63. Loss: 0.010577140719211425, Train_acc 0.9955078125\n",
      "\n",
      "Epoch 63. Loss: 0.00960295307491503, Train_acc 0.9956173780487805\n",
      "\n",
      "Epoch 63. Loss: 0.010130697223731416, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 63. Loss: 0.009165472824928349, Train_acc 0.9956395348837209\n",
      "\n",
      "Epoch 63. Loss: 0.008344754793657826, Train_acc 0.9957386363636364\n",
      "\n",
      "Epoch 63. Loss: 0.007663894616698295, Train_acc 0.9958333333333333\n",
      "\n",
      "Epoch 63. Loss: 0.007381664371313218, Train_acc 0.9959239130434783\n",
      "\n",
      "Epoch 63. Loss: 0.0070602965444221165, Train_acc 0.9960106382978723\n",
      "\n",
      "Epoch 63. Loss: 0.00950996812491662, Train_acc 0.9957682291666666\n",
      "\n",
      "Epoch 63. Loss: 0.01159645716526252, Train_acc 0.9955357142857143\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63. Loss: 0.010523774642925861, Train_acc 0.995625\n",
      "\n",
      "Epoch 63. Loss: 0.010003457807390157, Train_acc 0.9957107843137255\n",
      "\n",
      "Epoch 63. Loss: 0.00959290082489395, Train_acc 0.9957932692307693\n",
      "\n",
      "Epoch 63. Loss: 0.008714058083720003, Train_acc 0.995872641509434\n",
      "\n",
      "Epoch 63. Loss: 0.008198975966432985, Train_acc 0.9959490740740741\n",
      "\n",
      "Epoch 63. Loss: 0.0076530397107982305, Train_acc 0.9960227272727272\n",
      "\n",
      "Epoch 63. Loss: 0.007215105147469074, Train_acc 0.99609375\n",
      "\n",
      "Epoch 63. Loss: 0.006991433301247386, Train_acc 0.9961622807017544\n",
      "\n",
      "Epoch 63. Loss: 0.006924961051652337, Train_acc 0.9962284482758621\n",
      "\n",
      "Epoch 63. Loss: 0.01028189424393431, Train_acc 0.995895127118644\n",
      "\n",
      "Epoch 63. Loss: 0.009556454319219492, Train_acc 0.9959635416666667\n",
      "\n",
      "Epoch 63. Loss: 0.008641426027191127, Train_acc 0.9960297131147541\n",
      "\n",
      "Epoch 63. Loss: 0.012959267282818954, Train_acc 0.9958417338709677\n",
      "\n",
      "Epoch 63. Loss: 0.011933697444351197, Train_acc 0.9959077380952381\n",
      "\n",
      "Epoch 63. Loss: 0.012011742363558722, Train_acc 0.995849609375\n",
      "\n",
      "Epoch 63. Loss: 0.01784833738522516, Train_acc 0.9956730769230769\n",
      "\n",
      "Epoch 63. Loss: 0.016324690408484215, Train_acc 0.9957386363636364\n",
      "\n",
      "Epoch 63. Loss: 0.014713540835850436, Train_acc 0.9958022388059702\n",
      "\n",
      "Epoch 63. Loss: 0.01326749442168612, Train_acc 0.9958639705882353\n",
      "\n",
      "Epoch 63. Loss: 0.012273010908836472, Train_acc 0.9959239130434783\n",
      "\n",
      "Epoch 63. Loss: 0.011157178513056948, Train_acc 0.9959821428571428\n",
      "\n",
      "Epoch 63. Loss: 0.011057816992116196, Train_acc 0.9959286971830986\n",
      "\n",
      "Epoch 63. Loss: 0.010153450610037647, Train_acc 0.9959852430555556\n",
      "\n",
      "Epoch 63. Loss: 0.01173468597244859, Train_acc 0.995826198630137\n",
      "\n",
      "Epoch 63. Loss: 0.011329666206717257, Train_acc 0.995777027027027\n",
      "\n",
      "Epoch 63. Loss: 0.010530731465947418, Train_acc 0.9958333333333333\n",
      "\n",
      "Epoch 63. Loss: 0.009670403093165268, Train_acc 0.9958881578947368\n",
      "\n",
      "Epoch 63. Loss: 0.010589903248905639, Train_acc 0.9958400974025974\n",
      "\n",
      "Epoch 63. Loss: 0.009840980430522114, Train_acc 0.9958934294871795\n",
      "\n",
      "Epoch 63. Loss: 0.008910783973685846, Train_acc 0.9959454113924051\n",
      "\n",
      "Epoch 63. Loss: 0.00873216818408842, Train_acc 0.99599609375\n",
      "\n",
      "Epoch 63. Loss: 0.008015914144098834, Train_acc 0.996045524691358\n",
      "\n",
      "Epoch 63. Loss: 0.009197916133982012, Train_acc 0.9959984756097561\n",
      "\n",
      "Epoch 63. Loss: 0.008474530207021894, Train_acc 0.9960466867469879\n",
      "\n",
      "Epoch 63. Loss: 0.008098408086064931, Train_acc 0.99609375\n",
      "\n",
      "Epoch 63. Loss: 0.007328052447149472, Train_acc 0.9961397058823529\n",
      "\n",
      "Epoch 63. Loss: 0.006677976604199916, Train_acc 0.9961845930232558\n",
      "\n",
      "Epoch 63. Loss: 0.006158324972876022, Train_acc 0.9962284482758621\n",
      "\n",
      "Epoch 63. Loss: 0.0056499030839135735, Train_acc 0.9962713068181818\n",
      "\n",
      "Epoch 63. Loss: 0.006015861610388502, Train_acc 0.9962254213483146\n",
      "\n",
      "Epoch 63. Loss: 0.005598819741628239, Train_acc 0.9962673611111111\n",
      "\n",
      "Epoch 63. Loss: 0.005989891224969926, Train_acc 0.9962225274725275\n",
      "\n",
      "Epoch 63. Loss: 0.0060962241203661284, Train_acc 0.9961786684782609\n",
      "\n",
      "Epoch 63. Loss: 0.006429164973891573, Train_acc 0.996135752688172\n",
      "\n",
      "Epoch 63. Loss: 0.01516504529237461, Train_acc 0.9959275265957447\n",
      "\n",
      "Epoch 63. Loss: 0.013687696564778903, Train_acc 0.9959703947368421\n",
      "\n",
      "Epoch 63. Loss: 0.013790432967470782, Train_acc 0.9959309895833334\n",
      "\n",
      "Epoch 63. Loss: 0.0130785126084626, Train_acc 0.9959729381443299\n",
      "\n",
      "Epoch 63. Loss: 0.012152956086281563, Train_acc 0.9960140306122449\n",
      "\n",
      "Epoch 63. Loss: 0.01809794559289541, Train_acc 0.9958964646464646\n",
      "\n",
      "Epoch 63. Loss: 0.01754014659711295, Train_acc 0.995859375\n",
      "\n",
      "[Epoch 63 Batch 100] Loss: 0.016827884596186043 Training: accuracy=0.995823\n",
      "Epoch 63. Loss: 0.016827884596186043, Train_acc 0.9958230198019802\n",
      "\n",
      "Epoch 63. Loss: 0.01587272062928721, Train_acc 0.9958639705882353\n",
      "\n",
      "Epoch 63. Loss: 0.020430504903476636, Train_acc 0.9956765776699029\n",
      "\n",
      "Epoch 63. Loss: 0.019071207000194074, Train_acc 0.9956430288461539\n",
      "\n",
      "Epoch 63. Loss: 0.01722803502925016, Train_acc 0.9956845238095238\n",
      "\n",
      "Epoch 63. Loss: 0.0179082000447611, Train_acc 0.9956515330188679\n",
      "\n",
      "Epoch 63. Loss: 0.017125609277334808, Train_acc 0.9956921728971962\n",
      "\n",
      "Epoch 63. Loss: 0.015477708312264754, Train_acc 0.9957320601851852\n",
      "\n",
      "Epoch 63. Loss: 0.014076168955393141, Train_acc 0.9957712155963303\n",
      "\n",
      "Epoch 63. Loss: 0.01407429407926873, Train_acc 0.9957386363636364\n",
      "\n",
      "Epoch 63. Loss: 0.013755272772691927, Train_acc 0.9957066441441441\n",
      "\n",
      "Epoch 63. Loss: 0.013725354903294696, Train_acc 0.9956752232142857\n",
      "\n",
      "Epoch 63. Loss: 0.012930642066541959, Train_acc 0.9957134955752213\n",
      "\n",
      "Epoch 63. Loss: 0.011803968498220577, Train_acc 0.9957510964912281\n",
      "\n",
      "Epoch 63. Loss: 0.01266417186627734, Train_acc 0.9957201086956522\n",
      "\n",
      "Epoch 63. Loss: 0.011511189094028906, Train_acc 0.9957570043103449\n",
      "\n",
      "Epoch 63. Loss: 0.010538367491036984, Train_acc 0.9957932692307693\n",
      "\n",
      "Epoch 63. Loss: 0.011996576132837236, Train_acc 0.9956965042372882\n",
      "\n",
      "Epoch 63. Loss: 0.012497202851590485, Train_acc 0.9956670168067226\n",
      "\n",
      "Epoch 63. Loss: 0.011480034418672595, Train_acc 0.995703125\n",
      "\n",
      "Epoch 63. Loss: 0.011262070468309767, Train_acc 0.9957386363636364\n",
      "\n",
      "Epoch 63. Loss: 0.011967374457040351, Train_acc 0.9957095286885246\n",
      "\n",
      "Epoch 63. Loss: 0.011122311889374783, Train_acc 0.9957444105691057\n",
      "\n",
      "Epoch 63. Loss: 0.010421437313477276, Train_acc 0.9957787298387096\n",
      "\n",
      "Epoch 63. Loss: 0.01133360396950252, Train_acc 0.99575\n",
      "\n",
      "Epoch 63. Loss: 0.01041043006241, Train_acc 0.9957837301587301\n",
      "\n",
      "Epoch 63. Loss: 0.00948967125495234, Train_acc 0.9958169291338582\n",
      "\n",
      "Epoch 63. Loss: 0.010302026784240833, Train_acc 0.99578857421875\n",
      "\n",
      "Epoch 63. Loss: 0.0093711869927932, Train_acc 0.9958212209302325\n",
      "\n",
      "Epoch 63. Loss: 0.011633949608745205, Train_acc 0.9957932692307693\n",
      "\n",
      "Epoch 63. Loss: 0.010505055882638642, Train_acc 0.9958253816793893\n",
      "\n",
      "Epoch 63. Loss: 0.01485395401546891, Train_acc 0.995797821969697\n",
      "\n",
      "Epoch 63. Loss: 0.013675291333686133, Train_acc 0.995829417293233\n",
      "\n",
      "Epoch 63. Loss: 0.013764088353446861, Train_acc 0.9958022388059702\n",
      "\n",
      "Epoch 63. Loss: 0.015399498493312364, Train_acc 0.9957175925925926\n",
      "\n",
      "Epoch 63. Loss: 0.015920311436806826, Train_acc 0.9956916360294118\n",
      "\n",
      "Epoch 63. Loss: 0.014459766300138571, Train_acc 0.9957230839416058\n",
      "\n",
      "Epoch 63. Loss: 0.016265628354206745, Train_acc 0.9956408514492754\n",
      "\n",
      "Epoch 63. Loss: 0.016781217522729992, Train_acc 0.9955598021582733\n",
      "\n",
      "Epoch 63. Loss: 0.016446162574567998, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 63. Loss: 0.017250756491492932, Train_acc 0.9955119680851063\n",
      "\n",
      "Epoch 63. Loss: 0.015616854994092058, Train_acc 0.995543573943662\n",
      "\n",
      "Epoch 63. Loss: 0.014321151776099508, Train_acc 0.9955747377622378\n",
      "\n",
      "Epoch 63. Loss: 0.015797448779330526, Train_acc 0.9955512152777778\n",
      "\n",
      "Epoch 63. Loss: 0.01616180550323654, Train_acc 0.9955280172413793\n",
      "\n",
      "Epoch 63. Loss: 0.017617287364006598, Train_acc 0.9954516267123288\n",
      "\n",
      "Epoch 63. Loss: 0.017079989091814064, Train_acc 0.9954294217687075\n",
      "\n",
      "Epoch 63. Loss: 0.016504393962407563, Train_acc 0.9954603040540541\n",
      "\n",
      "Epoch 63. Loss: 0.015535581456021477, Train_acc 0.9954907718120806\n",
      "\n",
      "Epoch 63. Loss: 0.01482504523595811, Train_acc 0.99546875\n",
      "\n",
      "Epoch 63. Loss: 0.013565155958091985, Train_acc 0.9954987582781457\n",
      "\n",
      "Epoch 63. Loss: 0.01244598205309132, Train_acc 0.9955283717105263\n",
      "\n",
      "Epoch 63. Loss: 0.012072958726474816, Train_acc 0.9955575980392157\n",
      "\n",
      "Epoch 63. Loss: 0.010965466105041661, Train_acc 0.9955864448051948\n",
      "\n",
      "Epoch 63. Loss: 0.010271763865811608, Train_acc 0.9956149193548387\n",
      "\n",
      "Epoch 63. Loss: 0.009470031058486981, Train_acc 0.9956430288461539\n",
      "\n",
      "Epoch 63. Loss: 0.008969239406165496, Train_acc 0.9956707802547771\n",
      "\n",
      "Epoch 63. Loss: 0.008649865567574216, Train_acc 0.9956981803797469\n",
      "\n",
      "Epoch 63. Loss: 0.0080831135052198, Train_acc 0.9957252358490566\n",
      "\n",
      "Epoch 63. Loss: 0.008829362257220193, Train_acc 0.995703125\n",
      "\n",
      "Epoch 63. Loss: 0.008095953107198637, Train_acc 0.9957298136645962\n",
      "\n",
      "Epoch 63. Loss: 0.00731806234522512, Train_acc 0.9957561728395061\n",
      "\n",
      "Epoch 63. Loss: 0.006621412472694148, Train_acc 0.995782208588957\n",
      "\n",
      "Epoch 63. Loss: 0.006093174515104171, Train_acc 0.9958079268292683\n",
      "\n",
      "Epoch 63. Loss: 0.005645605606044123, Train_acc 0.9958333333333333\n",
      "\n",
      "Epoch 63. Loss: 0.006080083991323223, Train_acc 0.9958113704819277\n",
      "\n",
      "Epoch 63. Loss: 0.0057823984673479, Train_acc 0.9958364520958084\n",
      "\n",
      "Epoch 63. Loss: 0.006548188319134009, Train_acc 0.9958147321428571\n",
      "\n",
      "Epoch 63. Loss: 0.0061122064736804, Train_acc 0.9958394970414202\n",
      "\n",
      "Epoch 63. Loss: 0.0055806751874673925, Train_acc 0.9958639705882353\n",
      "\n",
      "Epoch 63. Loss: 0.005985859892748764, Train_acc 0.9958424707602339\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63. Loss: 0.006751314371362005, Train_acc 0.9958212209302325\n",
      "\n",
      "Epoch 63. Loss: 0.006233483689607389, Train_acc 0.9958453757225434\n",
      "\n",
      "Epoch 63. Loss: 0.0058581264522652695, Train_acc 0.9958692528735632\n",
      "\n",
      "Epoch 63. Loss: 0.0053299072607142515, Train_acc 0.9958928571428571\n",
      "\n",
      "Epoch 63. Loss: 0.005232544112469207, Train_acc 0.9959161931818182\n",
      "\n",
      "Epoch 63. Loss: 0.0048145484770972585, Train_acc 0.9959392655367232\n",
      "\n",
      "Epoch 63. Loss: 0.004467428493948048, Train_acc 0.9959620786516854\n",
      "\n",
      "Epoch 63. Loss: 0.004257541021996379, Train_acc 0.9959846368715084\n",
      "\n",
      "Epoch 63. Loss: 0.00874957728799609, Train_acc 0.9959635416666667\n",
      "\n",
      "Epoch 63. Loss: 0.007982408738506684, Train_acc 0.9959858425414365\n",
      "\n",
      "Epoch 63. Loss: 0.007245314762152672, Train_acc 0.9960078983516484\n",
      "\n",
      "Epoch 63. Loss: 0.007713653835795021, Train_acc 0.9959870218579235\n",
      "\n",
      "Epoch 63. Loss: 0.006984453950813998, Train_acc 0.9960088315217391\n",
      "\n",
      "Epoch 63. Loss: 0.006752689734391798, Train_acc 0.9960304054054054\n",
      "\n",
      "Epoch 63. Loss: 0.006392870497033683, Train_acc 0.996051747311828\n",
      "\n",
      "Epoch 63. Loss: 0.008576256209307034, Train_acc 0.9960310828877005\n",
      "\n",
      "Epoch 63. Loss: 0.008082314009541082, Train_acc 0.9960521941489362\n",
      "\n",
      "Epoch 63. Loss: 0.007943980980730481, Train_acc 0.996031746031746\n",
      "\n",
      "Epoch 63. Loss: 0.00738005932910719, Train_acc 0.9960526315789474\n",
      "\n",
      "Epoch 63. Loss: 0.006692603012767986, Train_acc 0.9960732984293194\n",
      "\n",
      "Epoch 63. Loss: 0.006404021046695909, Train_acc 0.99609375\n",
      "\n",
      "Epoch 63. Loss: 0.005798498683750899, Train_acc 0.9961139896373057\n",
      "\n",
      "Epoch 63. Loss: 0.005922570263815169, Train_acc 0.9961340206185567\n",
      "\n",
      "Epoch 63. Loss: 0.005779306691189627, Train_acc 0.9961538461538462\n",
      "\n",
      "Epoch 63. Loss: 0.0052132495423411205, Train_acc 0.99616\n",
      "\n",
      "Epoch 64. Loss: 0.005009555411808629, Train_acc 1.0\n",
      "\n",
      "Epoch 64. Loss: 0.004561516501730327, Train_acc 1.0\n",
      "\n",
      "Epoch 64. Loss: 0.004113225767787424, Train_acc 1.0\n",
      "\n",
      "Epoch 64. Loss: 0.0038127573296288793, Train_acc 1.0\n",
      "\n",
      "Epoch 64. Loss: 0.0034524410374011604, Train_acc 1.0\n",
      "\n",
      "Epoch 64. Loss: 0.00849622572127396, Train_acc 0.99609375\n",
      "\n",
      "Epoch 64. Loss: 0.010676307615608699, Train_acc 0.9944196428571429\n",
      "\n",
      "Epoch 64. Loss: 0.009679845742873752, Train_acc 0.9951171875\n",
      "\n",
      "Epoch 64. Loss: 0.009306185414635305, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 64. Loss: 0.008397839376873745, Train_acc 0.99609375\n",
      "\n",
      "Epoch 64. Loss: 0.009712348723006524, Train_acc 0.9957386363636364\n",
      "\n",
      "Epoch 64. Loss: 0.008888975255981634, Train_acc 0.99609375\n",
      "\n",
      "Epoch 64. Loss: 0.008034837063740686, Train_acc 0.9963942307692307\n",
      "\n",
      "Epoch 64. Loss: 0.007604583673111494, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 64. Loss: 0.009444838380007651, Train_acc 0.9958333333333333\n",
      "\n",
      "Epoch 64. Loss: 0.008572746699751502, Train_acc 0.99609375\n",
      "\n",
      "Epoch 64. Loss: 0.008074660282836335, Train_acc 0.9963235294117647\n",
      "\n",
      "Epoch 64. Loss: 0.008113407543157916, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 64. Loss: 0.007906552835201067, Train_acc 0.9967105263157895\n",
      "\n",
      "Epoch 64. Loss: 0.007135901312845805, Train_acc 0.996875\n",
      "\n",
      "Epoch 64. Loss: 0.0065015920238896685, Train_acc 0.9970238095238095\n",
      "\n",
      "Epoch 64. Loss: 0.006431037700522346, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 64. Loss: 0.005834452320187787, Train_acc 0.9972826086956522\n",
      "\n",
      "Epoch 64. Loss: 0.005625472337647826, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 64. Loss: 0.005848089359531895, Train_acc 0.9971875\n",
      "\n",
      "Epoch 64. Loss: 0.005270645621540623, Train_acc 0.9972956730769231\n",
      "\n",
      "Epoch 64. Loss: 0.005018071857278774, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 64. Loss: 0.007293433198796418, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 64. Loss: 0.0068211498106718425, Train_acc 0.9973060344827587\n",
      "\n",
      "Epoch 64. Loss: 0.007193664233702454, Train_acc 0.9971354166666667\n",
      "\n",
      "Epoch 64. Loss: 0.00680898382792744, Train_acc 0.9972278225806451\n",
      "\n",
      "Epoch 64. Loss: 0.006337976146942732, Train_acc 0.997314453125\n",
      "\n",
      "Epoch 64. Loss: 0.005721062316222212, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 64. Loss: 0.005320335713191231, Train_acc 0.9974724264705882\n",
      "\n",
      "Epoch 64. Loss: 0.0061545499373943215, Train_acc 0.9973214285714286\n",
      "\n",
      "Epoch 64. Loss: 0.005733569951829666, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 64. Loss: 0.005260992769429703, Train_acc 0.9974662162162162\n",
      "\n",
      "Epoch 64. Loss: 0.004772641306108269, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 64. Loss: 0.004400811540602326, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 64. Loss: 0.005522770685719263, Train_acc 0.9974609375\n",
      "\n",
      "Epoch 64. Loss: 0.005612359272927176, Train_acc 0.9973323170731707\n",
      "\n",
      "Epoch 64. Loss: 0.005100814678604272, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 64. Loss: 0.004608017018136077, Train_acc 0.9974563953488372\n",
      "\n",
      "Epoch 64. Loss: 0.004434756341640675, Train_acc 0.9975142045454546\n",
      "\n",
      "Epoch 64. Loss: 0.004030556227724946, Train_acc 0.9975694444444444\n",
      "\n",
      "Epoch 64. Loss: 0.003890094292464432, Train_acc 0.9976222826086957\n",
      "\n",
      "Epoch 64. Loss: 0.003560204748772526, Train_acc 0.9976728723404256\n",
      "\n",
      "Epoch 64. Loss: 0.0033844395928871135, Train_acc 0.9977213541666666\n",
      "\n",
      "Epoch 64. Loss: 0.0034110680292509347, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 64. Loss: 0.0031103698169015212, Train_acc 0.9978125\n",
      "\n",
      "Epoch 64. Loss: 0.0029092025193040694, Train_acc 0.9978553921568627\n",
      "\n",
      "Epoch 64. Loss: 0.0052297018258987485, Train_acc 0.9977463942307693\n",
      "\n",
      "Epoch 64. Loss: 0.00486210683105978, Train_acc 0.9977889150943396\n",
      "\n",
      "Epoch 64. Loss: 0.00440081421021697, Train_acc 0.9978298611111112\n",
      "\n",
      "Epoch 64. Loss: 0.004994440962976907, Train_acc 0.9977272727272727\n",
      "\n",
      "Epoch 64. Loss: 0.0046666371957421555, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 64. Loss: 0.004225839947864585, Train_acc 0.9978070175438597\n",
      "\n",
      "Epoch 64. Loss: 0.004129795901660776, Train_acc 0.9978448275862069\n",
      "\n",
      "Epoch 64. Loss: 0.0053318646976512575, Train_acc 0.9977489406779662\n",
      "\n",
      "Epoch 64. Loss: 0.004847487269504501, Train_acc 0.9977864583333333\n",
      "\n",
      "Epoch 64. Loss: 0.004872587640133769, Train_acc 0.9978227459016393\n",
      "\n",
      "Epoch 64. Loss: 0.004679498752844874, Train_acc 0.9978578629032258\n",
      "\n",
      "Epoch 64. Loss: 0.004250930708280618, Train_acc 0.9978918650793651\n",
      "\n",
      "Epoch 64. Loss: 0.0043553846731466785, Train_acc 0.9979248046875\n",
      "\n",
      "Epoch 64. Loss: 0.004770510843814856, Train_acc 0.9978365384615384\n",
      "\n",
      "Epoch 64. Loss: 0.004401891504753929, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 64. Loss: 0.004049844824036704, Train_acc 0.9979011194029851\n",
      "\n",
      "Epoch 64. Loss: 0.0037307004306468337, Train_acc 0.9979319852941176\n",
      "\n",
      "Epoch 64. Loss: 0.003366095884230719, Train_acc 0.9979619565217391\n",
      "\n",
      "Epoch 64. Loss: 0.0033582759472015377, Train_acc 0.9979910714285715\n",
      "\n",
      "Epoch 64. Loss: 0.003060143039970804, Train_acc 0.9980193661971831\n",
      "\n",
      "Epoch 64. Loss: 0.002936860511540659, Train_acc 0.998046875\n",
      "\n",
      "Epoch 64. Loss: 0.002767767853798081, Train_acc 0.9980736301369864\n",
      "\n",
      "Epoch 64. Loss: 0.002513990597446584, Train_acc 0.9980996621621622\n",
      "\n",
      "Epoch 64. Loss: 0.0025763276635287617, Train_acc 0.998125\n",
      "\n",
      "Epoch 64. Loss: 0.002480376337834753, Train_acc 0.9981496710526315\n",
      "\n",
      "Epoch 64. Loss: 0.002367979015106163, Train_acc 0.9981737012987013\n",
      "\n",
      "Epoch 64. Loss: 0.0029515209572263377, Train_acc 0.9980969551282052\n",
      "\n",
      "Epoch 64. Loss: 0.002835871625289126, Train_acc 0.9981210443037974\n",
      "\n",
      "Epoch 64. Loss: 0.002611419569618079, Train_acc 0.99814453125\n",
      "\n",
      "Epoch 64. Loss: 0.004165637838393367, Train_acc 0.998070987654321\n",
      "\n",
      "Epoch 64. Loss: 0.0038043740332572903, Train_acc 0.9980945121951219\n",
      "\n",
      "Epoch 64. Loss: 0.0035488329709350386, Train_acc 0.9981174698795181\n",
      "\n",
      "Epoch 64. Loss: 0.0032340097460474954, Train_acc 0.9981398809523809\n",
      "\n",
      "Epoch 64. Loss: 0.002941052876947758, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 64. Loss: 0.005903733458851371, Train_acc 0.9980922965116279\n",
      "\n",
      "Epoch 64. Loss: 0.005644262120374674, Train_acc 0.998114224137931\n",
      "\n",
      "Epoch 64. Loss: 0.006003199307097765, Train_acc 0.998046875\n",
      "\n",
      "Epoch 64. Loss: 0.005564447603146379, Train_acc 0.9980688202247191\n",
      "\n",
      "Epoch 64. Loss: 0.006717413391041885, Train_acc 0.9980034722222222\n",
      "\n",
      "Epoch 64. Loss: 0.009659384318025228, Train_acc 0.9978537087912088\n",
      "\n",
      "Epoch 64. Loss: 0.008721879915304542, Train_acc 0.9978770380434783\n",
      "\n",
      "Epoch 64. Loss: 0.00789011801157264, Train_acc 0.9978998655913979\n",
      "\n",
      "Epoch 64. Loss: 0.007130304942642464, Train_acc 0.9979222074468085\n",
      "\n",
      "Epoch 64. Loss: 0.007055743803559077, Train_acc 0.9979440789473685\n",
      "\n",
      "Epoch 64. Loss: 0.00661826895007789, Train_acc 0.9979654947916666\n",
      "\n",
      "Epoch 64. Loss: 0.006766514905506072, Train_acc 0.9979059278350515\n",
      "\n",
      "Epoch 64. Loss: 0.0065918692397746725, Train_acc 0.9979272959183674\n",
      "\n",
      "Epoch 64. Loss: 0.006112454697467978, Train_acc 0.9979482323232324\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64. Loss: 0.0055261319669699036, Train_acc 0.99796875\n",
      "\n",
      "[Epoch 64 Batch 100] Loss: 0.005028206829299289 Training: accuracy=0.997989\n",
      "Epoch 64. Loss: 0.005028206829299289, Train_acc 0.9979888613861386\n",
      "\n",
      "Epoch 64. Loss: 0.005792745738389872, Train_acc 0.9979319852941176\n",
      "\n",
      "Epoch 64. Loss: 0.007199192454662427, Train_acc 0.9978003640776699\n",
      "\n",
      "Epoch 64. Loss: 0.007137823648598646, Train_acc 0.9977463942307693\n",
      "\n",
      "Epoch 64. Loss: 0.007312811729920079, Train_acc 0.9976934523809524\n",
      "\n",
      "Epoch 64. Loss: 0.006879760557699653, Train_acc 0.9977152122641509\n",
      "\n",
      "Epoch 64. Loss: 0.006310253424958247, Train_acc 0.9977365654205608\n",
      "\n",
      "Epoch 64. Loss: 0.006811468787654511, Train_acc 0.9976851851851852\n",
      "\n",
      "Epoch 64. Loss: 0.009083017174301392, Train_acc 0.9975630733944955\n",
      "\n",
      "Epoch 64. Loss: 0.008727098335830432, Train_acc 0.9975852272727272\n",
      "\n",
      "Epoch 64. Loss: 0.008714377541847285, Train_acc 0.9976069819819819\n",
      "\n",
      "Epoch 64. Loss: 0.008074829702383808, Train_acc 0.9976283482142857\n",
      "\n",
      "Epoch 64. Loss: 0.008462762959128498, Train_acc 0.9975801991150443\n",
      "\n",
      "Epoch 64. Loss: 0.01386418108104993, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 64. Loss: 0.012623355979108774, Train_acc 0.9974184782608696\n",
      "\n",
      "Epoch 64. Loss: 0.012015671233282057, Train_acc 0.9974407327586207\n",
      "\n",
      "Epoch 64. Loss: 0.024692012995432826, Train_acc 0.9973290598290598\n",
      "\n",
      "Epoch 64. Loss: 0.022503148708262453, Train_acc 0.9973516949152542\n",
      "\n",
      "Epoch 64. Loss: 0.02715329411046363, Train_acc 0.9972426470588235\n",
      "\n",
      "Epoch 64. Loss: 0.02457731827506787, Train_acc 0.997265625\n",
      "\n",
      "Epoch 64. Loss: 0.024583220387184915, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 64. Loss: 0.025861596603409316, Train_acc 0.9971183401639344\n",
      "\n",
      "Epoch 64. Loss: 0.025432988738312602, Train_acc 0.9970782520325203\n",
      "\n",
      "Epoch 64. Loss: 0.023275845959673178, Train_acc 0.997101814516129\n",
      "\n",
      "Epoch 64. Loss: 0.03330886472602772, Train_acc 0.996875\n",
      "\n",
      "Epoch 64. Loss: 0.03135697352668721, Train_acc 0.9968377976190477\n",
      "\n",
      "Epoch 64. Loss: 0.028414089749286282, Train_acc 0.9968626968503937\n",
      "\n",
      "Epoch 64. Loss: 0.02750453324916635, Train_acc 0.996826171875\n",
      "\n",
      "Epoch 64. Loss: 0.029151617483520572, Train_acc 0.9967296511627907\n",
      "\n",
      "Epoch 64. Loss: 0.02674790451896852, Train_acc 0.9967548076923077\n",
      "\n",
      "Epoch 64. Loss: 0.025183810114616147, Train_acc 0.9967199427480916\n",
      "\n",
      "Epoch 64. Loss: 0.022832309605520063, Train_acc 0.9967447916666666\n",
      "\n",
      "Epoch 64. Loss: 0.021710352586365722, Train_acc 0.9967692669172933\n",
      "\n",
      "Epoch 64. Loss: 0.019717970888307974, Train_acc 0.9967933768656716\n",
      "\n",
      "Epoch 64. Loss: 0.025191637337647038, Train_acc 0.9966435185185185\n",
      "\n",
      "Epoch 64. Loss: 0.023507654072739623, Train_acc 0.9966681985294118\n",
      "\n",
      "Epoch 64. Loss: 0.02446962541511471, Train_acc 0.9966354927007299\n",
      "\n",
      "Epoch 64. Loss: 0.02287413990426792, Train_acc 0.9966598731884058\n",
      "\n",
      "Epoch 64. Loss: 0.020775271447297038, Train_acc 0.9966839028776978\n",
      "\n",
      "Epoch 64. Loss: 0.020107786145176977, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 64. Loss: 0.018386292131535552, Train_acc 0.9966755319148937\n",
      "\n",
      "Epoch 64. Loss: 0.016758994283080704, Train_acc 0.9966989436619719\n",
      "\n",
      "Epoch 64. Loss: 0.016980614122868127, Train_acc 0.9966673951048951\n",
      "\n",
      "Epoch 64. Loss: 0.015614764553341758, Train_acc 0.9966905381944444\n",
      "\n",
      "Epoch 64. Loss: 0.014305312438450894, Train_acc 0.9967133620689655\n",
      "\n",
      "Epoch 64. Loss: 0.015454030822494007, Train_acc 0.9965753424657534\n",
      "\n",
      "Epoch 64. Loss: 0.015248412749867182, Train_acc 0.9965454931972789\n",
      "\n",
      "Epoch 64. Loss: 0.014034178659536429, Train_acc 0.9965688344594594\n",
      "\n",
      "Epoch 64. Loss: 0.015865427379505026, Train_acc 0.9965394295302014\n",
      "\n",
      "Epoch 64. Loss: 0.014812406003203559, Train_acc 0.9965625\n",
      "\n",
      "Epoch 64. Loss: 0.014064021832996518, Train_acc 0.9965852649006622\n",
      "\n",
      "Epoch 64. Loss: 0.013767897812802117, Train_acc 0.9965563322368421\n",
      "\n",
      "Epoch 64. Loss: 0.013104323054801095, Train_acc 0.9965788398692811\n",
      "\n",
      "Epoch 64. Loss: 0.01329181135188103, Train_acc 0.9966010551948052\n",
      "\n",
      "Epoch 64. Loss: 0.012454916805689576, Train_acc 0.9966229838709677\n",
      "\n",
      "Epoch 64. Loss: 0.011721221431939342, Train_acc 0.9966446314102564\n",
      "\n",
      "Epoch 64. Loss: 0.010687414497932975, Train_acc 0.9966660031847133\n",
      "\n",
      "Epoch 64. Loss: 0.00970428037053825, Train_acc 0.9966871044303798\n",
      "\n",
      "Epoch 64. Loss: 0.008978497875018254, Train_acc 0.9967079402515723\n",
      "\n",
      "Epoch 64. Loss: 0.008298617803111674, Train_acc 0.996728515625\n",
      "\n",
      "Epoch 64. Loss: 0.007659017913912238, Train_acc 0.9967488354037267\n",
      "\n",
      "Epoch 64. Loss: 0.006978293790891321, Train_acc 0.9967689043209876\n",
      "\n",
      "Epoch 64. Loss: 0.007329419174320595, Train_acc 0.996788726993865\n",
      "\n",
      "Epoch 64. Loss: 0.006960477513993171, Train_acc 0.9968083079268293\n",
      "\n",
      "Epoch 64. Loss: 0.006451708918537397, Train_acc 0.9968276515151515\n",
      "\n",
      "Epoch 64. Loss: 0.007747509267084925, Train_acc 0.9967996987951807\n",
      "\n",
      "Epoch 64. Loss: 0.008468167631614025, Train_acc 0.9967720808383234\n",
      "\n",
      "Epoch 64. Loss: 0.008283980919827058, Train_acc 0.9967912946428571\n",
      "\n",
      "Epoch 64. Loss: 0.007651042989038558, Train_acc 0.9968102810650887\n",
      "\n",
      "Epoch 64. Loss: 0.006959448790035589, Train_acc 0.9968290441176471\n",
      "\n",
      "Epoch 64. Loss: 0.008427845792903253, Train_acc 0.9968019005847953\n",
      "\n",
      "Epoch 64. Loss: 0.007629321032582223, Train_acc 0.9968204941860465\n",
      "\n",
      "Epoch 64. Loss: 0.009468074676828236, Train_acc 0.9967937138728323\n",
      "\n",
      "Epoch 64. Loss: 0.00862863298593013, Train_acc 0.9968121408045977\n",
      "\n",
      "Epoch 64. Loss: 0.007880030522444533, Train_acc 0.9968303571428572\n",
      "\n",
      "Epoch 64. Loss: 0.008153547357498426, Train_acc 0.9968039772727273\n",
      "\n",
      "Epoch 64. Loss: 0.007443590281102495, Train_acc 0.996822033898305\n",
      "\n",
      "Epoch 64. Loss: 0.007252856795662735, Train_acc 0.9968398876404494\n",
      "\n",
      "Epoch 64. Loss: 0.006614345432247157, Train_acc 0.9968575418994413\n",
      "\n",
      "Epoch 64. Loss: 0.00658793523543367, Train_acc 0.996875\n",
      "\n",
      "Epoch 64. Loss: 0.006067451950143628, Train_acc 0.9968922651933702\n",
      "\n",
      "Epoch 64. Loss: 0.00566656022014247, Train_acc 0.9969093406593407\n",
      "\n",
      "Epoch 64. Loss: 0.006882411274987698, Train_acc 0.9968835382513661\n",
      "\n",
      "Epoch 64. Loss: 0.006255024708650179, Train_acc 0.9969004755434783\n",
      "\n",
      "Epoch 64. Loss: 0.006938892114765943, Train_acc 0.996875\n",
      "\n",
      "Epoch 64. Loss: 0.0069690875786013904, Train_acc 0.9968918010752689\n",
      "\n",
      "Epoch 64. Loss: 0.006401959389855043, Train_acc 0.9969084224598931\n",
      "\n",
      "Epoch 64. Loss: 0.006270771564164378, Train_acc 0.9969248670212766\n",
      "\n",
      "Epoch 64. Loss: 0.006953226055459933, Train_acc 0.9969411375661376\n",
      "\n",
      "Epoch 64. Loss: 0.006362693933515331, Train_acc 0.9969572368421052\n",
      "\n",
      "Epoch 64. Loss: 0.005814504104902817, Train_acc 0.996973167539267\n",
      "\n",
      "Epoch 64. Loss: 0.005670170270771211, Train_acc 0.9969889322916666\n",
      "\n",
      "Epoch 64. Loss: 0.005219268179066115, Train_acc 0.9970045336787565\n",
      "\n",
      "Epoch 64. Loss: 0.008002612256521404, Train_acc 0.9969797036082474\n",
      "\n",
      "Epoch 64. Loss: 0.007258702676486079, Train_acc 0.9969951923076923\n",
      "\n",
      "Epoch 64. Loss: 0.006567976803333926, Train_acc 0.997\n",
      "\n",
      "Epoch 65. Loss: 0.007408149497137697, Train_acc 0.9921875\n",
      "\n",
      "Epoch 65. Loss: 0.006754377462825908, Train_acc 0.99609375\n",
      "\n",
      "Epoch 65. Loss: 0.006987096759702325, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 65. Loss: 0.006473189468779171, Train_acc 0.998046875\n",
      "\n",
      "Epoch 65. Loss: 0.00621366695554376, Train_acc 0.9984375\n",
      "\n",
      "Epoch 65. Loss: 0.010772734025043133, Train_acc 0.99609375\n",
      "\n",
      "Epoch 65. Loss: 0.009893178472635345, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 65. Loss: 0.009063764276009528, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 65. Loss: 0.008495604998828525, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 65. Loss: 0.007865717254283925, Train_acc 0.99765625\n",
      "\n",
      "Epoch 65. Loss: 0.011907923810663433, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 65. Loss: 0.011997970053240012, Train_acc 0.99609375\n",
      "\n",
      "Epoch 65. Loss: 0.01088479215333888, Train_acc 0.9963942307692307\n",
      "\n",
      "Epoch 65. Loss: 0.009919139251604937, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 65. Loss: 0.009290542225609955, Train_acc 0.996875\n",
      "\n",
      "Epoch 65. Loss: 0.00844972667260832, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 65. Loss: 0.008415156730239388, Train_acc 0.9972426470588235\n",
      "\n",
      "Epoch 65. Loss: 0.008332259080461975, Train_acc 0.9969618055555556\n",
      "\n",
      "Epoch 65. Loss: 0.010697014589594886, Train_acc 0.9962993421052632\n",
      "\n",
      "Epoch 65. Loss: 0.011766981669801849, Train_acc 0.995703125\n",
      "\n",
      "Epoch 65. Loss: 0.010744527599305699, Train_acc 0.9959077380952381\n",
      "\n",
      "Epoch 65. Loss: 0.009720659677402264, Train_acc 0.99609375\n",
      "\n",
      "Epoch 65. Loss: 0.008898069597545492, Train_acc 0.9962635869565217\n",
      "\n",
      "Epoch 65. Loss: 0.009414604428943898, Train_acc 0.99609375\n",
      "\n",
      "Epoch 65. Loss: 0.008514905293560988, Train_acc 0.99625\n",
      "\n",
      "Epoch 65. Loss: 0.008313665629351407, Train_acc 0.99609375\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65. Loss: 0.007603120254154596, Train_acc 0.9962384259259259\n",
      "\n",
      "Epoch 65. Loss: 0.009746572364874716, Train_acc 0.99609375\n",
      "\n",
      "Epoch 65. Loss: 0.010788298724151883, Train_acc 0.9959590517241379\n",
      "\n",
      "Epoch 65. Loss: 0.011363665382317215, Train_acc 0.9958333333333333\n",
      "\n",
      "Epoch 65. Loss: 0.01026974457473629, Train_acc 0.9959677419354839\n",
      "\n",
      "Epoch 65. Loss: 0.010228780512253106, Train_acc 0.995849609375\n",
      "\n",
      "Epoch 65. Loss: 0.00924552640069283, Train_acc 0.9959753787878788\n",
      "\n",
      "Epoch 65. Loss: 0.01258557880594215, Train_acc 0.9956341911764706\n",
      "\n",
      "Epoch 65. Loss: 0.011414221892011593, Train_acc 0.9957589285714286\n",
      "\n",
      "Epoch 65. Loss: 0.010765969790967491, Train_acc 0.9958767361111112\n",
      "\n",
      "Epoch 65. Loss: 0.01107041727419393, Train_acc 0.995777027027027\n",
      "\n",
      "Epoch 65. Loss: 0.010045564350709961, Train_acc 0.9958881578947368\n",
      "\n",
      "Epoch 65. Loss: 0.009228369877800924, Train_acc 0.9959935897435898\n",
      "\n",
      "Epoch 65. Loss: 0.008703257874234541, Train_acc 0.99609375\n",
      "\n",
      "Epoch 65. Loss: 0.009963766100034735, Train_acc 0.9959984756097561\n",
      "\n",
      "Epoch 65. Loss: 0.009347733596847017, Train_acc 0.99609375\n",
      "\n",
      "Epoch 65. Loss: 0.008674690192835533, Train_acc 0.9961845930232558\n",
      "\n",
      "Epoch 65. Loss: 0.0095217264287743, Train_acc 0.99609375\n",
      "\n",
      "Epoch 65. Loss: 0.009163249575472448, Train_acc 0.9961805555555555\n",
      "\n",
      "Epoch 65. Loss: 0.008915557415822065, Train_acc 0.9962635869565217\n",
      "\n",
      "Epoch 65. Loss: 0.009057874040191398, Train_acc 0.9961768617021277\n",
      "\n",
      "Epoch 65. Loss: 0.00834142966114881, Train_acc 0.9962565104166666\n",
      "\n",
      "Epoch 65. Loss: 0.008997687519729755, Train_acc 0.9961734693877551\n",
      "\n",
      "Epoch 65. Loss: 0.00917462573227938, Train_acc 0.99625\n",
      "\n",
      "Epoch 65. Loss: 0.013833574421206021, Train_acc 0.9960171568627451\n",
      "\n",
      "Epoch 65. Loss: 0.013184854843019459, Train_acc 0.99609375\n",
      "\n",
      "Epoch 65. Loss: 0.012000839742354167, Train_acc 0.9961674528301887\n",
      "\n",
      "Epoch 65. Loss: 0.011020624124480736, Train_acc 0.9962384259259259\n",
      "\n",
      "Epoch 65. Loss: 0.01018388482661407, Train_acc 0.9963068181818182\n",
      "\n",
      "Epoch 65. Loss: 0.009318912797347702, Train_acc 0.9963727678571429\n",
      "\n",
      "Epoch 65. Loss: 0.019009300863602162, Train_acc 0.9957510964912281\n",
      "\n",
      "Epoch 65. Loss: 0.017179066461067708, Train_acc 0.9958243534482759\n",
      "\n",
      "Epoch 65. Loss: 0.015698825792289952, Train_acc 0.995895127118644\n",
      "\n",
      "Epoch 65. Loss: 0.01472862670829938, Train_acc 0.9959635416666667\n",
      "\n",
      "Epoch 65. Loss: 0.014171768218377645, Train_acc 0.9960297131147541\n",
      "\n",
      "Epoch 65. Loss: 0.013036402785680667, Train_acc 0.99609375\n",
      "\n",
      "Epoch 65. Loss: 0.016087003252418616, Train_acc 0.9957837301587301\n",
      "\n",
      "Epoch 65. Loss: 0.01516037540831725, Train_acc 0.995849609375\n",
      "\n",
      "Epoch 65. Loss: 0.013952575418265703, Train_acc 0.9959134615384615\n",
      "\n",
      "Epoch 65. Loss: 0.012652413455020228, Train_acc 0.9959753787878788\n",
      "\n",
      "Epoch 65. Loss: 0.011417523685215045, Train_acc 0.996035447761194\n",
      "\n",
      "Epoch 65. Loss: 0.011847662587271449, Train_acc 0.9959788602941176\n",
      "\n",
      "Epoch 65. Loss: 0.012825695195173905, Train_acc 0.9958106884057971\n",
      "\n",
      "Epoch 65. Loss: 0.011660952626392858, Train_acc 0.9958705357142857\n",
      "\n",
      "Epoch 65. Loss: 0.010547319753911898, Train_acc 0.9959286971830986\n",
      "\n",
      "Epoch 65. Loss: 0.009976741965663557, Train_acc 0.9959852430555556\n",
      "\n",
      "Epoch 65. Loss: 0.009716260902779213, Train_acc 0.9959332191780822\n",
      "\n",
      "Epoch 65. Loss: 0.009806996615407092, Train_acc 0.9958826013513513\n",
      "\n",
      "Epoch 65. Loss: 0.01235333438069572, Train_acc 0.9958333333333333\n",
      "\n",
      "Epoch 65. Loss: 0.011181560879451335, Train_acc 0.9958881578947368\n",
      "\n",
      "Epoch 65. Loss: 0.011382457815559776, Train_acc 0.9958400974025974\n",
      "\n",
      "Epoch 65. Loss: 0.012492959308283393, Train_acc 0.9957932692307693\n",
      "\n",
      "Epoch 65. Loss: 0.011597801766684828, Train_acc 0.9958465189873418\n",
      "\n",
      "Epoch 65. Loss: 0.0108254438648145, Train_acc 0.9958984375\n",
      "\n",
      "Epoch 65. Loss: 0.009763652904693948, Train_acc 0.9959490740740741\n",
      "\n",
      "Epoch 65. Loss: 0.010519229463217854, Train_acc 0.9958079268292683\n",
      "\n",
      "Epoch 65. Loss: 0.010532486501912654, Train_acc 0.9958584337349398\n",
      "\n",
      "Epoch 65. Loss: 0.01033354731373225, Train_acc 0.9958147321428571\n",
      "\n",
      "Epoch 65. Loss: 0.009514505133902142, Train_acc 0.9958639705882353\n",
      "\n",
      "Epoch 65. Loss: 0.008582474212502229, Train_acc 0.9959120639534884\n",
      "\n",
      "Epoch 65. Loss: 0.007993235871036161, Train_acc 0.9959590517241379\n",
      "\n",
      "Epoch 65. Loss: 0.007330004938361921, Train_acc 0.9960049715909091\n",
      "\n",
      "Epoch 65. Loss: 0.006681114421413433, Train_acc 0.9960498595505618\n",
      "\n",
      "Epoch 65. Loss: 0.006618202418723188, Train_acc 0.99609375\n",
      "\n",
      "Epoch 65. Loss: 0.006054000446352123, Train_acc 0.9961366758241759\n",
      "\n",
      "Epoch 65. Loss: 0.006610501588868582, Train_acc 0.9961786684782609\n",
      "\n",
      "Epoch 65. Loss: 0.006355553521055713, Train_acc 0.9962197580645161\n",
      "\n",
      "Epoch 65. Loss: 0.005762725272523412, Train_acc 0.9962599734042553\n",
      "\n",
      "Epoch 65. Loss: 0.005240193096266284, Train_acc 0.9962993421052632\n",
      "\n",
      "Epoch 65. Loss: 0.005389880103960122, Train_acc 0.996337890625\n",
      "\n",
      "Epoch 65. Loss: 0.0052219306580449515, Train_acc 0.9963756443298969\n",
      "\n",
      "Epoch 65. Loss: 0.004747231114528734, Train_acc 0.9964126275510204\n",
      "\n",
      "Epoch 65. Loss: 0.004387975552843206, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 65. Loss: 0.003983476867572912, Train_acc 0.996484375\n",
      "\n",
      "[Epoch 65 Batch 100] Loss: 0.0037154630952371194 Training: accuracy=0.996519\n",
      "Epoch 65. Loss: 0.0037154630952371194, Train_acc 0.9965191831683168\n",
      "\n",
      "Epoch 65. Loss: 0.0034023835405671333, Train_acc 0.9965533088235294\n",
      "\n",
      "Epoch 65. Loss: 0.004724985880699492, Train_acc 0.9965109223300971\n",
      "\n",
      "Epoch 65. Loss: 0.0047002903764367734, Train_acc 0.9965444711538461\n",
      "\n",
      "Epoch 65. Loss: 0.004242355356231454, Train_acc 0.9965773809523809\n",
      "\n",
      "Epoch 65. Loss: 0.0039130515504446975, Train_acc 0.9966096698113207\n",
      "\n",
      "Epoch 65. Loss: 0.0036015776435495035, Train_acc 0.9966413551401869\n",
      "\n",
      "Epoch 65. Loss: 0.005892747168835456, Train_acc 0.9966001157407407\n",
      "\n",
      "Epoch 65. Loss: 0.006269090794113089, Train_acc 0.9965596330275229\n",
      "\n",
      "Epoch 65. Loss: 0.005852062800604233, Train_acc 0.9965909090909091\n",
      "\n",
      "Epoch 65. Loss: 0.005643074239711281, Train_acc 0.9966216216216216\n",
      "\n",
      "Epoch 65. Loss: 0.0051496170991133, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 65. Loss: 0.0046447011961957005, Train_acc 0.9966814159292036\n",
      "\n",
      "Epoch 65. Loss: 0.004241424813777523, Train_acc 0.9967105263157895\n",
      "\n",
      "Epoch 65. Loss: 0.0038897692405748226, Train_acc 0.9967391304347826\n",
      "\n",
      "Epoch 65. Loss: 0.003561872374156969, Train_acc 0.9967672413793104\n",
      "\n",
      "Epoch 65. Loss: 0.004723215481167904, Train_acc 0.9967280982905983\n",
      "\n",
      "Epoch 65. Loss: 0.0065801899929575965, Train_acc 0.9966896186440678\n",
      "\n",
      "Epoch 65. Loss: 0.005931093635816922, Train_acc 0.9967174369747899\n",
      "\n",
      "Epoch 65. Loss: 0.0057162389801379, Train_acc 0.9967447916666666\n",
      "\n",
      "Epoch 65. Loss: 0.0062484215777906145, Train_acc 0.9967071280991735\n",
      "\n",
      "Epoch 65. Loss: 0.005646419524077389, Train_acc 0.996734118852459\n",
      "\n",
      "Epoch 65. Loss: 0.0051286482195992585, Train_acc 0.9967606707317073\n",
      "\n",
      "Epoch 65. Loss: 0.004689635601425706, Train_acc 0.9967867943548387\n",
      "\n",
      "Epoch 65. Loss: 0.004353037158598339, Train_acc 0.9968125\n",
      "\n",
      "Epoch 65. Loss: 0.003938167780523041, Train_acc 0.9968377976190477\n",
      "\n",
      "Epoch 65. Loss: 0.0036038798608716187, Train_acc 0.9968626968503937\n",
      "\n",
      "Epoch 65. Loss: 0.0035979245386647454, Train_acc 0.99688720703125\n",
      "\n",
      "Epoch 65. Loss: 0.0033238168932350517, Train_acc 0.9969113372093024\n",
      "\n",
      "Epoch 65. Loss: 0.0030978073293583433, Train_acc 0.9969350961538461\n",
      "\n",
      "Epoch 65. Loss: 0.0028169078233216114, Train_acc 0.9969584923664122\n",
      "\n",
      "Epoch 65. Loss: 0.0036091847995555915, Train_acc 0.9969223484848485\n",
      "\n",
      "Epoch 65. Loss: 0.003944153434452699, Train_acc 0.9969454887218046\n",
      "\n",
      "Epoch 65. Loss: 0.0036329558666894166, Train_acc 0.9969682835820896\n",
      "\n",
      "Epoch 65. Loss: 0.003630094200307071, Train_acc 0.9969907407407408\n",
      "\n",
      "Epoch 65. Loss: 0.0038982915888881144, Train_acc 0.9970128676470589\n",
      "\n",
      "Epoch 65. Loss: 0.005424642235993337, Train_acc 0.9969206204379562\n",
      "\n",
      "Epoch 65. Loss: 0.005370105173551134, Train_acc 0.9969429347826086\n",
      "\n",
      "Epoch 65. Loss: 0.004888445019450568, Train_acc 0.996964928057554\n",
      "\n",
      "Epoch 65. Loss: 0.005299044665449962, Train_acc 0.9969866071428571\n",
      "\n",
      "Epoch 65. Loss: 0.004787963983098922, Train_acc 0.9970079787234043\n",
      "\n",
      "Epoch 65. Loss: 0.004478416871198497, Train_acc 0.9970290492957746\n",
      "\n",
      "Epoch 65. Loss: 0.00407725389806716, Train_acc 0.9970498251748252\n",
      "\n",
      "Epoch 65. Loss: 0.006595800662114815, Train_acc 0.9970160590277778\n",
      "\n",
      "Epoch 65. Loss: 0.007874137098259862, Train_acc 0.9969827586206896\n",
      "\n",
      "Epoch 65. Loss: 0.007278190899901511, Train_acc 0.9970034246575342\n",
      "\n",
      "Epoch 65. Loss: 0.010186079680037131, Train_acc 0.9969175170068028\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65. Loss: 0.00943724661837068, Train_acc 0.9969383445945946\n",
      "\n",
      "Epoch 65. Loss: 0.008549285349708469, Train_acc 0.9969588926174496\n",
      "\n",
      "Epoch 65. Loss: 0.007818788099813465, Train_acc 0.9969791666666666\n",
      "\n",
      "Epoch 65. Loss: 0.0070825515698519385, Train_acc 0.9969991721854304\n",
      "\n",
      "Epoch 65. Loss: 0.006439047947822321, Train_acc 0.9970189144736842\n",
      "\n",
      "Epoch 65. Loss: 0.014240210856763996, Train_acc 0.9968852124183006\n",
      "\n",
      "Epoch 65. Loss: 0.0163734135977344, Train_acc 0.9967532467532467\n",
      "\n",
      "Epoch 65. Loss: 0.014879977210316774, Train_acc 0.9967741935483871\n",
      "\n",
      "Epoch 65. Loss: 0.013463369171410397, Train_acc 0.9967948717948718\n",
      "\n",
      "Epoch 65. Loss: 0.013391848853012558, Train_acc 0.9968152866242038\n",
      "\n",
      "Epoch 65. Loss: 0.03175413887272534, Train_acc 0.9965882120253164\n",
      "\n",
      "Epoch 65. Loss: 0.031205692043038524, Train_acc 0.996560534591195\n",
      "\n",
      "Epoch 65. Loss: 0.02832432989881097, Train_acc 0.99658203125\n",
      "\n",
      "Epoch 65. Loss: 0.03437540892904096, Train_acc 0.9964576863354038\n",
      "\n",
      "Epoch 65. Loss: 0.04303841856847787, Train_acc 0.9962866512345679\n",
      "\n",
      "Epoch 65. Loss: 0.04009065045995043, Train_acc 0.9962135736196319\n",
      "\n",
      "Epoch 65. Loss: 0.037290906845771014, Train_acc 0.9962366615853658\n",
      "\n",
      "Epoch 65. Loss: 0.0356859243490482, Train_acc 0.9962121212121212\n",
      "\n",
      "Epoch 65. Loss: 0.03929485841794473, Train_acc 0.99609375\n",
      "\n",
      "Epoch 65. Loss: 0.044633344240817385, Train_acc 0.9960235778443114\n",
      "\n",
      "Epoch 65. Loss: 0.04363688566788998, Train_acc 0.9959542410714286\n",
      "\n",
      "Epoch 65. Loss: 0.04224087976817757, Train_acc 0.9959319526627219\n",
      "\n",
      "Epoch 65. Loss: 0.047113685459534566, Train_acc 0.9958180147058824\n",
      "\n",
      "Epoch 65. Loss: 0.05184477298018954, Train_acc 0.9955226608187134\n",
      "\n",
      "Epoch 65. Loss: 0.04768360834024211, Train_acc 0.9955486918604651\n",
      "\n",
      "Epoch 65. Loss: 0.04423693282039636, Train_acc 0.9955292630057804\n",
      "\n",
      "Epoch 65. Loss: 0.04249971605955071, Train_acc 0.995465158045977\n",
      "\n",
      "Epoch 65. Loss: 0.04029923302786208, Train_acc 0.9954464285714286\n",
      "\n",
      "Epoch 65. Loss: 0.03698730746230475, Train_acc 0.9954723011363636\n",
      "\n",
      "Epoch 65. Loss: 0.036182672233769225, Train_acc 0.9954537429378532\n",
      "\n",
      "Epoch 65. Loss: 0.033488960502048366, Train_acc 0.995435393258427\n",
      "\n",
      "Epoch 65. Loss: 0.03128485221415761, Train_acc 0.9954608938547486\n",
      "\n",
      "Epoch 65. Loss: 0.028708325002342487, Train_acc 0.9954861111111111\n",
      "\n",
      "Epoch 65. Loss: 0.027639155207946922, Train_acc 0.9954678867403315\n",
      "\n",
      "Epoch 65. Loss: 0.026665132524557437, Train_acc 0.9954498626373627\n",
      "\n",
      "Epoch 65. Loss: 0.024588449933294232, Train_acc 0.9954747267759563\n",
      "\n",
      "Epoch 65. Loss: 0.022942877907899416, Train_acc 0.9954568614130435\n",
      "\n",
      "Epoch 65. Loss: 0.025211961954248605, Train_acc 0.9953125\n",
      "\n",
      "Epoch 65. Loss: 0.02572185305304467, Train_acc 0.9952536962365591\n",
      "\n",
      "Epoch 65. Loss: 0.027250902422193937, Train_acc 0.9951955213903744\n",
      "\n",
      "Epoch 65. Loss: 0.025901194387308583, Train_acc 0.9951795212765957\n",
      "\n",
      "Epoch 65. Loss: 0.026105836159257732, Train_acc 0.9951223544973545\n",
      "\n",
      "Epoch 65. Loss: 0.024981853944452386, Train_acc 0.9951480263157895\n",
      "\n",
      "Epoch 65. Loss: 0.024877010359518333, Train_acc 0.9951325261780105\n",
      "\n",
      "Epoch 65. Loss: 0.024163969448941294, Train_acc 0.9951171875\n",
      "\n",
      "Epoch 65. Loss: 0.02303776887065531, Train_acc 0.9951020077720207\n",
      "\n",
      "Epoch 65. Loss: 0.022169065262434135, Train_acc 0.9950869845360825\n",
      "\n",
      "Epoch 65. Loss: 0.02195008314599745, Train_acc 0.9950721153846154\n",
      "\n",
      "Epoch 65. Loss: 0.020430107352064422, Train_acc 0.99508\n",
      "\n",
      "Epoch 66. Loss: 0.01934376764991257, Train_acc 1.0\n",
      "\n",
      "Epoch 66. Loss: 0.01873041067598796, Train_acc 0.99609375\n",
      "\n",
      "Epoch 66. Loss: 0.017309895848067428, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 66. Loss: 0.016718395824580037, Train_acc 0.99609375\n",
      "\n",
      "Epoch 66. Loss: 0.015295594296729841, Train_acc 0.996875\n",
      "\n",
      "Epoch 66. Loss: 0.013912780804001938, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 66. Loss: 0.012749461199772643, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 66. Loss: 0.011717041536509057, Train_acc 0.998046875\n",
      "\n",
      "Epoch 66. Loss: 0.010713162083332891, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 66. Loss: 0.009745155509141226, Train_acc 0.9984375\n",
      "\n",
      "Epoch 66. Loss: 0.009134230899060196, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 66. Loss: 0.008986053263540053, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 66. Loss: 0.009803653787429617, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 66. Loss: 0.010204810639490622, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 66. Loss: 0.009555966212096756, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 66. Loss: 0.008739886683498722, Train_acc 0.998046875\n",
      "\n",
      "Epoch 66. Loss: 0.008244424482978793, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 66. Loss: 0.008032605325771044, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 66. Loss: 0.007269038279372234, Train_acc 0.9983552631578947\n",
      "\n",
      "Epoch 66. Loss: 0.006787947918043535, Train_acc 0.9984375\n",
      "\n",
      "Epoch 66. Loss: 0.006781788934826256, Train_acc 0.9985119047619048\n",
      "\n",
      "Epoch 66. Loss: 0.006289410862398357, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 66. Loss: 0.006285849811648319, Train_acc 0.9983016304347826\n",
      "\n",
      "Epoch 66. Loss: 0.0057240696115739564, Train_acc 0.9983723958333334\n",
      "\n",
      "Epoch 66. Loss: 0.00520560074447743, Train_acc 0.9984375\n",
      "\n",
      "Epoch 66. Loss: 0.005603089010856914, Train_acc 0.9984975961538461\n",
      "\n",
      "Epoch 66. Loss: 0.005549441848971577, Train_acc 0.9985532407407407\n",
      "\n",
      "Epoch 66. Loss: 0.005095756060245453, Train_acc 0.9986049107142857\n",
      "\n",
      "Epoch 66. Loss: 0.005369390329446929, Train_acc 0.9986530172413793\n",
      "\n",
      "Epoch 66. Loss: 0.00560111400624502, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 66. Loss: 0.005143236620396122, Train_acc 0.9987399193548387\n",
      "\n",
      "Epoch 66. Loss: 0.004706999548285227, Train_acc 0.998779296875\n",
      "\n",
      "Epoch 66. Loss: 0.004392376509484519, Train_acc 0.9988162878787878\n",
      "\n",
      "Epoch 66. Loss: 0.004406705478662434, Train_acc 0.9988511029411765\n",
      "\n",
      "Epoch 66. Loss: 0.0042751543043561425, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 66. Loss: 0.0038611934940114005, Train_acc 0.9989149305555556\n",
      "\n",
      "Epoch 66. Loss: 0.0034886950952411266, Train_acc 0.9989442567567568\n",
      "\n",
      "Epoch 66. Loss: 0.0032219997213218873, Train_acc 0.9989720394736842\n",
      "\n",
      "Epoch 66. Loss: 0.0031153963151664375, Train_acc 0.9989983974358975\n",
      "\n",
      "Epoch 66. Loss: 0.002904638603550122, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 66. Loss: 0.0026351372325565193, Train_acc 0.999047256097561\n",
      "\n",
      "Epoch 66. Loss: 0.0024038974744901007, Train_acc 0.9990699404761905\n",
      "\n",
      "Epoch 66. Loss: 0.0022506435826152517, Train_acc 0.9990915697674418\n",
      "\n",
      "Epoch 66. Loss: 0.0021091901520398216, Train_acc 0.9991122159090909\n",
      "\n",
      "Epoch 66. Loss: 0.002021135820925858, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 66. Loss: 0.0018740521572729585, Train_acc 0.9991508152173914\n",
      "\n",
      "Epoch 66. Loss: 0.001984263759534118, Train_acc 0.9991688829787234\n",
      "\n",
      "Epoch 66. Loss: 0.001806030567026078, Train_acc 0.9991861979166666\n",
      "\n",
      "Epoch 66. Loss: 0.0016946363842249863, Train_acc 0.9992028061224489\n",
      "\n",
      "Epoch 66. Loss: 0.001799547407769646, Train_acc 0.99921875\n",
      "\n",
      "Epoch 66. Loss: 0.0016537224728555852, Train_acc 0.999234068627451\n",
      "\n",
      "Epoch 66. Loss: 0.0015753446830942964, Train_acc 0.9992487980769231\n",
      "\n",
      "Epoch 66. Loss: 0.0014783850415692988, Train_acc 0.9992629716981132\n",
      "\n",
      "Epoch 66. Loss: 0.0013417833619150717, Train_acc 0.9992766203703703\n",
      "\n",
      "Epoch 66. Loss: 0.001228391023636318, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 66. Loss: 0.0014641258273963246, Train_acc 0.9993024553571429\n",
      "\n",
      "Epoch 66. Loss: 0.001327209478199142, Train_acc 0.9993146929824561\n",
      "\n",
      "Epoch 66. Loss: 0.0012087309962198803, Train_acc 0.9993265086206896\n",
      "\n",
      "Epoch 66. Loss: 0.001339543072642595, Train_acc 0.9993379237288136\n",
      "\n",
      "Epoch 66. Loss: 0.0012148443378915469, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 66. Loss: 0.0011047126236959526, Train_acc 0.999359631147541\n",
      "\n",
      "Epoch 66. Loss: 0.001100458398281416, Train_acc 0.9993699596774194\n",
      "\n",
      "Epoch 66. Loss: 0.0011004158407693036, Train_acc 0.9993799603174603\n",
      "\n",
      "Epoch 66. Loss: 0.0010040594394770572, Train_acc 0.9993896484375\n",
      "\n",
      "Epoch 66. Loss: 0.0010542217549436368, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 66. Loss: 0.0012884164145666134, Train_acc 0.9994081439393939\n",
      "\n",
      "Epoch 66. Loss: 0.0011931333639132475, Train_acc 0.9994169776119403\n",
      "\n",
      "Epoch 66. Loss: 0.0011055398092131312, Train_acc 0.9994255514705882\n",
      "\n",
      "Epoch 66. Loss: 0.001017778560052819, Train_acc 0.9994338768115942\n",
      "\n",
      "Epoch 66. Loss: 0.000961751637397601, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 66. Loss: 0.0017731793798849526, Train_acc 0.999449823943662\n",
      "\n",
      "Epoch 66. Loss: 0.0016082449151186013, Train_acc 0.9994574652777778\n",
      "\n",
      "Epoch 66. Loss: 0.0014743576048532082, Train_acc 0.999464897260274\n",
      "\n",
      "Epoch 66. Loss: 0.0017002038252325912, Train_acc 0.9994721283783784\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66. Loss: 0.001599857209557032, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 66. Loss: 0.0015674789794687051, Train_acc 0.9994860197368421\n",
      "\n",
      "Epoch 66. Loss: 0.0038278763784531013, Train_acc 0.9993912337662337\n",
      "\n",
      "Epoch 66. Loss: 0.0034519855487982957, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 66. Loss: 0.0033243350532180544, Train_acc 0.9994066455696202\n",
      "\n",
      "Epoch 66. Loss: 0.0032314223239818048, Train_acc 0.9994140625\n",
      "\n",
      "Epoch 66. Loss: 0.002972942650308728, Train_acc 0.9994212962962963\n",
      "\n",
      "Epoch 66. Loss: 0.0026924878368418657, Train_acc 0.9994283536585366\n",
      "\n",
      "Epoch 66. Loss: 0.004096269533900134, Train_acc 0.9993411144578314\n",
      "\n",
      "Epoch 66. Loss: 0.0038956259878659655, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 66. Loss: 0.0035364705851065954, Train_acc 0.9993566176470589\n",
      "\n",
      "Epoch 66. Loss: 0.0032616162045553633, Train_acc 0.9993640988372093\n",
      "\n",
      "Epoch 66. Loss: 0.0030589488888164143, Train_acc 0.999371408045977\n",
      "\n",
      "Epoch 66. Loss: 0.0029114887220416767, Train_acc 0.9993785511363636\n",
      "\n",
      "Epoch 66. Loss: 0.002733391478997109, Train_acc 0.9993855337078652\n",
      "\n",
      "Epoch 66. Loss: 0.0025908847242854275, Train_acc 0.9993923611111111\n",
      "\n",
      "Epoch 66. Loss: 0.0023536714096927783, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 66. Loss: 0.0021241975069906634, Train_acc 0.999405570652174\n",
      "\n",
      "Epoch 66. Loss: 0.0019241814086545883, Train_acc 0.9994119623655914\n",
      "\n",
      "Epoch 66. Loss: 0.002024602447535936, Train_acc 0.9994182180851063\n",
      "\n",
      "Epoch 66. Loss: 0.0018396291112554172, Train_acc 0.9994243421052632\n",
      "\n",
      "Epoch 66. Loss: 0.002510035266785511, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 66. Loss: 0.006054482665933987, Train_acc 0.9992751288659794\n",
      "\n",
      "Epoch 66. Loss: 0.006115005384186942, Train_acc 0.9992028061224489\n",
      "\n",
      "Epoch 66. Loss: 0.00565627536875013, Train_acc 0.9992108585858586\n",
      "\n",
      "Epoch 66. Loss: 0.005135558584206023, Train_acc 0.99921875\n",
      "\n",
      "[Epoch 66 Batch 100] Loss: 0.005224262352397488 Training: accuracy=0.999226\n",
      "Epoch 66. Loss: 0.005224262352397488, Train_acc 0.9992264851485149\n",
      "\n",
      "Epoch 66. Loss: 0.00500059466677348, Train_acc 0.999234068627451\n",
      "\n",
      "Epoch 66. Loss: 0.005971817462451221, Train_acc 0.9991656553398058\n",
      "\n",
      "Epoch 66. Loss: 0.00545676738350157, Train_acc 0.9991736778846154\n",
      "\n",
      "Epoch 66. Loss: 0.005060358033193476, Train_acc 0.9991815476190476\n",
      "\n",
      "Epoch 66. Loss: 0.004950184149843448, Train_acc 0.9991892688679245\n",
      "\n",
      "Epoch 66. Loss: 0.00660693066415369, Train_acc 0.999123831775701\n",
      "\n",
      "Epoch 66. Loss: 0.009198141474400574, Train_acc 0.9989149305555556\n",
      "\n",
      "Epoch 66. Loss: 0.008294873995445325, Train_acc 0.9989248853211009\n",
      "\n",
      "Epoch 66. Loss: 0.008129580710407036, Train_acc 0.9989346590909091\n",
      "\n",
      "Epoch 66. Loss: 0.007813301438757126, Train_acc 0.9989442567567568\n",
      "\n",
      "Epoch 66. Loss: 0.008810553592146943, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 66. Loss: 0.007942220048369792, Train_acc 0.9988938053097345\n",
      "\n",
      "Epoch 66. Loss: 0.00836443990209266, Train_acc 0.9988349780701754\n",
      "\n",
      "Epoch 66. Loss: 0.007537871951868496, Train_acc 0.9988451086956521\n",
      "\n",
      "Epoch 66. Loss: 0.0070428817680198205, Train_acc 0.9988550646551724\n",
      "\n",
      "Epoch 66. Loss: 0.008067106683020436, Train_acc 0.9987313034188035\n",
      "\n",
      "Epoch 66. Loss: 0.008376116081891635, Train_acc 0.9986758474576272\n",
      "\n",
      "Epoch 66. Loss: 0.008439740858809512, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 66. Loss: 0.010734706436696377, Train_acc 0.9985677083333333\n",
      "\n",
      "Epoch 66. Loss: 0.010221248951273616, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 66. Loss: 0.009217910811536719, Train_acc 0.9985911885245902\n",
      "\n",
      "Epoch 66. Loss: 0.011388132843583712, Train_acc 0.9985391260162602\n",
      "\n",
      "Epoch 66. Loss: 0.0141294899194329, Train_acc 0.9984879032258065\n",
      "\n",
      "Epoch 66. Loss: 0.014366647275586935, Train_acc 0.9984375\n",
      "\n",
      "Epoch 66. Loss: 0.012987491309557122, Train_acc 0.9984499007936508\n",
      "\n",
      "Epoch 66. Loss: 0.012354125219506408, Train_acc 0.9984621062992126\n",
      "\n",
      "Epoch 66. Loss: 0.011143920636880668, Train_acc 0.99847412109375\n",
      "\n",
      "Epoch 66. Loss: 0.010717079233415371, Train_acc 0.9984859496124031\n",
      "\n",
      "Epoch 66. Loss: 0.010903969764370424, Train_acc 0.9984375\n",
      "\n",
      "Epoch 66. Loss: 0.01136576220884207, Train_acc 0.9983897900763359\n",
      "\n",
      "Epoch 66. Loss: 0.010410280870967655, Train_acc 0.9984019886363636\n",
      "\n",
      "Epoch 66. Loss: 0.013009100569105342, Train_acc 0.9983552631578947\n",
      "\n",
      "Epoch 66. Loss: 0.011858001804261978, Train_acc 0.9983675373134329\n",
      "\n",
      "Epoch 66. Loss: 0.010728105798059323, Train_acc 0.9983796296296297\n",
      "\n",
      "Epoch 66. Loss: 0.009832904253998654, Train_acc 0.9983915441176471\n",
      "\n",
      "Epoch 66. Loss: 0.008886966793462901, Train_acc 0.9984032846715328\n",
      "\n",
      "Epoch 66. Loss: 0.008761467450462522, Train_acc 0.9983582427536232\n",
      "\n",
      "Epoch 66. Loss: 0.008352076203616925, Train_acc 0.9983700539568345\n",
      "\n",
      "Epoch 66. Loss: 0.010509170390062751, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 66. Loss: 0.009763106219486794, Train_acc 0.9983377659574468\n",
      "\n",
      "Epoch 66. Loss: 0.009414222307517888, Train_acc 0.9983494718309859\n",
      "\n",
      "Epoch 66. Loss: 0.008565719585227009, Train_acc 0.998361013986014\n",
      "\n",
      "Epoch 66. Loss: 0.007797912900971951, Train_acc 0.9983723958333334\n",
      "\n",
      "Epoch 66. Loss: 0.007094695686376168, Train_acc 0.9983836206896551\n",
      "\n",
      "Epoch 66. Loss: 0.006487488142040587, Train_acc 0.998394691780822\n",
      "\n",
      "Epoch 66. Loss: 0.008820718914020554, Train_acc 0.9983524659863946\n",
      "\n",
      "Epoch 66. Loss: 0.008726919008566585, Train_acc 0.9983108108108109\n",
      "\n",
      "Epoch 66. Loss: 0.00916057707811026, Train_acc 0.9982697147651006\n",
      "\n",
      "Epoch 66. Loss: 0.008401732476585013, Train_acc 0.99828125\n",
      "\n",
      "Epoch 66. Loss: 0.008480238168269011, Train_acc 0.9982926324503312\n",
      "\n",
      "Epoch 66. Loss: 0.013989907278564227, Train_acc 0.9982010690789473\n",
      "\n",
      "Epoch 66. Loss: 0.016267891324114787, Train_acc 0.9981107026143791\n",
      "\n",
      "Epoch 66. Loss: 0.014849873373927463, Train_acc 0.9981229707792207\n",
      "\n",
      "Epoch 66. Loss: 0.015571845611949376, Train_acc 0.9980846774193548\n",
      "\n",
      "Epoch 66. Loss: 0.0141912135010388, Train_acc 0.9980969551282052\n",
      "\n",
      "Epoch 66. Loss: 0.013550300358273967, Train_acc 0.9980593152866242\n",
      "\n",
      "Epoch 66. Loss: 0.012668366776962623, Train_acc 0.9980715981012658\n",
      "\n",
      "Epoch 66. Loss: 0.012060700194143842, Train_acc 0.9980837264150944\n",
      "\n",
      "Epoch 66. Loss: 0.0110442636675755, Train_acc 0.998095703125\n",
      "\n",
      "Epoch 66. Loss: 0.01041702389125107, Train_acc 0.9981075310559007\n",
      "\n",
      "Epoch 66. Loss: 0.009789442280567393, Train_acc 0.9981192129629629\n",
      "\n",
      "Epoch 66. Loss: 0.009933880110505259, Train_acc 0.9981307515337423\n",
      "\n",
      "Epoch 66. Loss: 0.010705372592738004, Train_acc 0.9980945121951219\n",
      "\n",
      "Epoch 66. Loss: 0.010844235741434156, Train_acc 0.9980587121212121\n",
      "\n",
      "Epoch 66. Loss: 0.010340451512862139, Train_acc 0.998070406626506\n",
      "\n",
      "Epoch 66. Loss: 0.016184482855316006, Train_acc 0.9979883982035929\n",
      "\n",
      "Epoch 66. Loss: 0.014970082582353952, Train_acc 0.9980003720238095\n",
      "\n",
      "Epoch 66. Loss: 0.013687101727972393, Train_acc 0.9980122041420119\n",
      "\n",
      "Epoch 66. Loss: 0.018523481690511077, Train_acc 0.9978860294117647\n",
      "\n",
      "Epoch 66. Loss: 0.017698438014350806, Train_acc 0.9978983918128655\n",
      "\n",
      "Epoch 66. Loss: 0.01926948633411152, Train_acc 0.9978197674418605\n",
      "\n",
      "Epoch 66. Loss: 0.0173909849060362, Train_acc 0.9978323699421965\n",
      "\n",
      "Epoch 66. Loss: 0.015825339703585396, Train_acc 0.9978448275862069\n",
      "\n",
      "Epoch 66. Loss: 0.015504585864835104, Train_acc 0.9978125\n",
      "\n",
      "Epoch 66. Loss: 0.016370370682501603, Train_acc 0.9977805397727273\n",
      "\n",
      "Epoch 66. Loss: 0.016025812745622224, Train_acc 0.9977489406779662\n",
      "\n",
      "Epoch 66. Loss: 0.01912379755425283, Train_acc 0.9977176966292135\n",
      "\n",
      "Epoch 66. Loss: 0.019765828122328178, Train_acc 0.9976868016759777\n",
      "\n",
      "Epoch 66. Loss: 0.017875756143448166, Train_acc 0.9976996527777777\n",
      "\n",
      "Epoch 66. Loss: 0.018564519943819115, Train_acc 0.9976691988950276\n",
      "\n",
      "Epoch 66. Loss: 0.017049197508529425, Train_acc 0.9976820054945055\n",
      "\n",
      "Epoch 66. Loss: 0.015598813595706763, Train_acc 0.9976946721311475\n",
      "\n",
      "Epoch 66. Loss: 0.014148556761202552, Train_acc 0.9977072010869565\n",
      "\n",
      "Epoch 66. Loss: 0.014005953193984037, Train_acc 0.9976773648648649\n",
      "\n",
      "Epoch 66. Loss: 0.0126455015271719, Train_acc 0.9976898521505376\n",
      "\n",
      "Epoch 66. Loss: 0.011779622023610685, Train_acc 0.9977022058823529\n",
      "\n",
      "Epoch 66. Loss: 0.010853248698540104, Train_acc 0.9977144281914894\n",
      "\n",
      "Epoch 66. Loss: 0.011071688727016067, Train_acc 0.9976438492063492\n",
      "\n",
      "Epoch 66. Loss: 0.015142078067786828, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 66. Loss: 0.014859571653688553, Train_acc 0.9975458115183246\n",
      "\n",
      "Epoch 66. Loss: 0.014601123439298216, Train_acc 0.9975179036458334\n",
      "\n",
      "Epoch 66. Loss: 0.013762473988109359, Train_acc 0.9975307642487047\n",
      "\n",
      "Epoch 66. Loss: 0.013115819478845771, Train_acc 0.9975434922680413\n",
      "\n",
      "Epoch 66. Loss: 0.01213511450907544, Train_acc 0.9975560897435898\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66. Loss: 0.010958177300571626, Train_acc 0.99756\n",
      "\n",
      "Epoch 67. Loss: 0.010246001886379027, Train_acc 1.0\n",
      "\n",
      "Epoch 67. Loss: 0.015478717422829243, Train_acc 0.9921875\n",
      "\n",
      "Epoch 67. Loss: 0.01406090604224459, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 67. Loss: 0.01396838073693504, Train_acc 0.994140625\n",
      "\n",
      "Epoch 67. Loss: 0.01379706873532644, Train_acc 0.99375\n",
      "\n",
      "Epoch 67. Loss: 0.012862868583528796, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 67. Loss: 0.01359029819935137, Train_acc 0.9944196428571429\n",
      "\n",
      "Epoch 67. Loss: 0.012663556793283588, Train_acc 0.9951171875\n",
      "\n",
      "Epoch 67. Loss: 0.011839429487095326, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 67. Loss: 0.01276006843087618, Train_acc 0.9953125\n",
      "\n",
      "Epoch 67. Loss: 0.013028384499438503, Train_acc 0.9950284090909091\n",
      "\n",
      "Epoch 67. Loss: 0.011913286349811017, Train_acc 0.9954427083333334\n",
      "\n",
      "Epoch 67. Loss: 0.010987036869462901, Train_acc 0.9957932692307693\n",
      "\n",
      "Epoch 67. Loss: 0.01161031788933567, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 67. Loss: 0.010816213271528112, Train_acc 0.9958333333333333\n",
      "\n",
      "Epoch 67. Loss: 0.009996051420689786, Train_acc 0.99609375\n",
      "\n",
      "Epoch 67. Loss: 0.00918501770284429, Train_acc 0.9963235294117647\n",
      "\n",
      "Epoch 67. Loss: 0.00865624430175115, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 67. Loss: 0.007853602289451936, Train_acc 0.9967105263157895\n",
      "\n",
      "Epoch 67. Loss: 0.007120309558251899, Train_acc 0.996875\n",
      "\n",
      "Epoch 67. Loss: 0.00661876439607686, Train_acc 0.9970238095238095\n",
      "\n",
      "Epoch 67. Loss: 0.008362733330338117, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 67. Loss: 0.01037110321760975, Train_acc 0.9962635869565217\n",
      "\n",
      "Epoch 67. Loss: 0.00954012396483841, Train_acc 0.9964192708333334\n",
      "\n",
      "Epoch 67. Loss: 0.008954815144159398, Train_acc 0.9965625\n",
      "\n",
      "Epoch 67. Loss: 0.01734215132130802, Train_acc 0.9954927884615384\n",
      "\n",
      "Epoch 67. Loss: 0.01589851563111204, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 67. Loss: 0.014966760999875588, Train_acc 0.9958147321428571\n",
      "\n",
      "Epoch 67. Loss: 0.013714066035897126, Train_acc 0.9959590517241379\n",
      "\n",
      "Epoch 67. Loss: 0.015142494674638442, Train_acc 0.9958333333333333\n",
      "\n",
      "Epoch 67. Loss: 0.016607446658118544, Train_acc 0.9957157258064516\n",
      "\n",
      "Epoch 67. Loss: 0.015336311035793106, Train_acc 0.995849609375\n",
      "\n",
      "Epoch 67. Loss: 0.01454098618263699, Train_acc 0.9959753787878788\n",
      "\n",
      "Epoch 67. Loss: 0.014393404520911254, Train_acc 0.9958639705882353\n",
      "\n",
      "Epoch 67. Loss: 0.016370946151640066, Train_acc 0.9957589285714286\n",
      "\n",
      "Epoch 67. Loss: 0.014938257376962347, Train_acc 0.9958767361111112\n",
      "\n",
      "Epoch 67. Loss: 0.014911633684289553, Train_acc 0.995777027027027\n",
      "\n",
      "Epoch 67. Loss: 0.01763494487469086, Train_acc 0.9952713815789473\n",
      "\n",
      "Epoch 67. Loss: 0.022671561025363406, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 67. Loss: 0.020601971642552792, Train_acc 0.994921875\n",
      "\n",
      "Epoch 67. Loss: 0.018948162019740623, Train_acc 0.995045731707317\n",
      "\n",
      "Epoch 67. Loss: 0.017383820161848737, Train_acc 0.9951636904761905\n",
      "\n",
      "Epoch 67. Loss: 0.018247503872778542, Train_acc 0.995094476744186\n",
      "\n",
      "Epoch 67. Loss: 0.019316893147885678, Train_acc 0.9950284090909091\n",
      "\n",
      "Epoch 67. Loss: 0.018183640832418094, Train_acc 0.9951388888888889\n",
      "\n",
      "Epoch 67. Loss: 0.01676102998380115, Train_acc 0.9952445652173914\n",
      "\n",
      "Epoch 67. Loss: 0.015897539086856694, Train_acc 0.9951795212765957\n",
      "\n",
      "Epoch 67. Loss: 0.01443194685700305, Train_acc 0.9952799479166666\n",
      "\n",
      "Epoch 67. Loss: 0.0131541745019132, Train_acc 0.9953762755102041\n",
      "\n",
      "Epoch 67. Loss: 0.019055036260382005, Train_acc 0.995\n",
      "\n",
      "Epoch 67. Loss: 0.019076613198544683, Train_acc 0.9949448529411765\n",
      "\n",
      "Epoch 67. Loss: 0.017803641321503614, Train_acc 0.9950420673076923\n",
      "\n",
      "Epoch 67. Loss: 0.017277329765030887, Train_acc 0.9951356132075472\n",
      "\n",
      "Epoch 67. Loss: 0.01653082931244595, Train_acc 0.9952256944444444\n",
      "\n",
      "Epoch 67. Loss: 0.01560315213758549, Train_acc 0.9951704545454545\n",
      "\n",
      "Epoch 67. Loss: 0.017952806626189956, Train_acc 0.9949776785714286\n",
      "\n",
      "Epoch 67. Loss: 0.01719616483845938, Train_acc 0.9949287280701754\n",
      "\n",
      "Epoch 67. Loss: 0.016149274594622513, Train_acc 0.9948814655172413\n",
      "\n",
      "Epoch 67. Loss: 0.014603979597851776, Train_acc 0.994968220338983\n",
      "\n",
      "Epoch 67. Loss: 0.01429050501617653, Train_acc 0.9950520833333333\n",
      "\n",
      "Epoch 67. Loss: 0.01291148926108655, Train_acc 0.9951331967213115\n",
      "\n",
      "Epoch 67. Loss: 0.01344546082129696, Train_acc 0.995085685483871\n",
      "\n",
      "Epoch 67. Loss: 0.01337523550177174, Train_acc 0.9950396825396826\n",
      "\n",
      "Epoch 67. Loss: 0.012756760220687603, Train_acc 0.9949951171875\n",
      "\n",
      "Epoch 67. Loss: 0.011637878093330724, Train_acc 0.9950721153846154\n",
      "\n",
      "Epoch 67. Loss: 0.010860262165107128, Train_acc 0.9951467803030303\n",
      "\n",
      "Epoch 67. Loss: 0.00996006273026791, Train_acc 0.9952192164179104\n",
      "\n",
      "Epoch 67. Loss: 0.00919432710468495, Train_acc 0.9952895220588235\n",
      "\n",
      "Epoch 67. Loss: 0.008683789335427202, Train_acc 0.9953577898550725\n",
      "\n",
      "Epoch 67. Loss: 0.008412433667320774, Train_acc 0.9954241071428571\n",
      "\n",
      "Epoch 67. Loss: 0.007770509117474049, Train_acc 0.9954885563380281\n",
      "\n",
      "Epoch 67. Loss: 0.007435678010699055, Train_acc 0.9955512152777778\n",
      "\n",
      "Epoch 67. Loss: 0.006923707176834554, Train_acc 0.9956121575342466\n",
      "\n",
      "Epoch 67. Loss: 0.006486592791608165, Train_acc 0.9956714527027027\n",
      "\n",
      "Epoch 67. Loss: 0.006272593865213862, Train_acc 0.9957291666666667\n",
      "\n",
      "Epoch 67. Loss: 0.005938519481794302, Train_acc 0.9957853618421053\n",
      "\n",
      "Epoch 67. Loss: 0.005980009880119203, Train_acc 0.9958400974025974\n",
      "\n",
      "Epoch 67. Loss: 0.005423215888063882, Train_acc 0.9958934294871795\n",
      "\n",
      "Epoch 67. Loss: 0.004986067894041485, Train_acc 0.9959454113924051\n",
      "\n",
      "Epoch 67. Loss: 0.0045125375906912134, Train_acc 0.99599609375\n",
      "\n",
      "Epoch 67. Loss: 0.00445656507196614, Train_acc 0.996045524691358\n",
      "\n",
      "Epoch 67. Loss: 0.004025158019895063, Train_acc 0.99609375\n",
      "\n",
      "Epoch 67. Loss: 0.00772456011060003, Train_acc 0.9959525602409639\n",
      "\n",
      "Epoch 67. Loss: 0.007582159746883425, Train_acc 0.9960007440476191\n",
      "\n",
      "Epoch 67. Loss: 0.008528838709769945, Train_acc 0.9959558823529412\n",
      "\n",
      "Epoch 67. Loss: 0.0077358065983719835, Train_acc 0.9960029069767442\n",
      "\n",
      "Epoch 67. Loss: 0.007029513447398741, Train_acc 0.9960488505747126\n",
      "\n",
      "Epoch 67. Loss: 0.006413704081678955, Train_acc 0.99609375\n",
      "\n",
      "Epoch 67. Loss: 0.005857678747114153, Train_acc 0.9961376404494382\n",
      "\n",
      "Epoch 67. Loss: 0.006063646353873561, Train_acc 0.99609375\n",
      "\n",
      "Epoch 67. Loss: 0.006081910223224417, Train_acc 0.9960508241758241\n",
      "\n",
      "Epoch 67. Loss: 0.005593828578796526, Train_acc 0.99609375\n",
      "\n",
      "Epoch 67. Loss: 0.008768320950871593, Train_acc 0.9959677419354839\n",
      "\n",
      "Epoch 67. Loss: 0.008935427049254673, Train_acc 0.9959275265957447\n",
      "\n",
      "Epoch 67. Loss: 0.008351559577767816, Train_acc 0.9959703947368421\n",
      "\n",
      "Epoch 67. Loss: 0.00848594515849778, Train_acc 0.9959309895833334\n",
      "\n",
      "Epoch 67. Loss: 0.011013447502222322, Train_acc 0.9958923969072165\n",
      "\n",
      "Epoch 67. Loss: 0.010003127199465405, Train_acc 0.9959343112244898\n",
      "\n",
      "Epoch 67. Loss: 0.00946261751500163, Train_acc 0.9959753787878788\n",
      "\n",
      "Epoch 67. Loss: 0.008911592626324833, Train_acc 0.996015625\n",
      "\n",
      "[Epoch 67 Batch 100] Loss: 0.008046065130458661 Training: accuracy=0.996055\n",
      "Epoch 67. Loss: 0.008046065130458661, Train_acc 0.9960550742574258\n",
      "\n",
      "Epoch 67. Loss: 0.007590290307329346, Train_acc 0.99609375\n",
      "\n",
      "Epoch 67. Loss: 0.007452979258590564, Train_acc 0.9961316747572816\n",
      "\n",
      "Epoch 67. Loss: 0.007583892055803799, Train_acc 0.9961688701923077\n",
      "\n",
      "Epoch 67. Loss: 0.007247957475591538, Train_acc 0.9962053571428572\n",
      "\n",
      "Epoch 67. Loss: 0.00815075260783032, Train_acc 0.9961674528301887\n",
      "\n",
      "Epoch 67. Loss: 0.01252615449474569, Train_acc 0.9961302570093458\n",
      "\n",
      "Epoch 67. Loss: 0.011558055600528262, Train_acc 0.9961660879629629\n",
      "\n",
      "Epoch 67. Loss: 0.011250365462307043, Train_acc 0.9961295871559633\n",
      "\n",
      "Epoch 67. Loss: 0.01042677489011339, Train_acc 0.9961647727272728\n",
      "\n",
      "Epoch 67. Loss: 0.009866902846892343, Train_acc 0.9961993243243243\n",
      "\n",
      "Epoch 67. Loss: 0.009242323235653042, Train_acc 0.9962332589285714\n",
      "\n",
      "Epoch 67. Loss: 0.00885907421646911, Train_acc 0.996266592920354\n",
      "\n",
      "Epoch 67. Loss: 0.013539073855922207, Train_acc 0.9961622807017544\n",
      "\n",
      "Epoch 67. Loss: 0.012401245158720538, Train_acc 0.996195652173913\n",
      "\n",
      "Epoch 67. Loss: 0.011428085679128938, Train_acc 0.9962284482758621\n",
      "\n",
      "Epoch 67. Loss: 0.010640028264133787, Train_acc 0.9962606837606838\n",
      "\n",
      "Epoch 67. Loss: 0.010241075949900142, Train_acc 0.996292372881356\n",
      "\n",
      "Epoch 67. Loss: 0.010278647684633248, Train_acc 0.9962578781512605\n",
      "\n",
      "Epoch 67. Loss: 0.009341008865122062, Train_acc 0.9962890625\n",
      "\n",
      "Epoch 67. Loss: 0.008823948546454963, Train_acc 0.9963197314049587\n",
      "\n",
      "Epoch 67. Loss: 0.00872008162218838, Train_acc 0.9963498975409836\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67. Loss: 0.008225677289807878, Train_acc 0.9963795731707317\n",
      "\n",
      "Epoch 67. Loss: 0.007432289817942603, Train_acc 0.9964087701612904\n",
      "\n",
      "Epoch 67. Loss: 0.006821824641016207, Train_acc 0.9964375\n",
      "\n",
      "Epoch 67. Loss: 0.006537837711859121, Train_acc 0.9964657738095238\n",
      "\n",
      "Epoch 67. Loss: 0.0059090400622439, Train_acc 0.9964936023622047\n",
      "\n",
      "Epoch 67. Loss: 0.005529594336702074, Train_acc 0.99652099609375\n",
      "\n",
      "Epoch 67. Loss: 0.004986091503705596, Train_acc 0.9965479651162791\n",
      "\n",
      "Epoch 67. Loss: 0.004600100021099462, Train_acc 0.9965745192307692\n",
      "\n",
      "Epoch 67. Loss: 0.004243697804411871, Train_acc 0.9966006679389313\n",
      "\n",
      "Epoch 67. Loss: 0.003960907053120991, Train_acc 0.9966264204545454\n",
      "\n",
      "Epoch 67. Loss: 0.003572816197722068, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 67. Loss: 0.0035776703505431807, Train_acc 0.9966767723880597\n",
      "\n",
      "Epoch 67. Loss: 0.003238279287774729, Train_acc 0.9967013888888889\n",
      "\n",
      "Epoch 67. Loss: 0.0034287762997383185, Train_acc 0.9967256433823529\n",
      "\n",
      "Epoch 67. Loss: 0.003631449459448544, Train_acc 0.9967495437956204\n",
      "\n",
      "Epoch 67. Loss: 0.003282636510002785, Train_acc 0.9967730978260869\n",
      "\n",
      "Epoch 67. Loss: 0.0029813759225899785, Train_acc 0.9967963129496403\n",
      "\n",
      "Epoch 67. Loss: 0.004358017276075018, Train_acc 0.9967633928571429\n",
      "\n",
      "Epoch 67. Loss: 0.004058687705204516, Train_acc 0.9967863475177305\n",
      "\n",
      "Epoch 67. Loss: 0.0036857240921067116, Train_acc 0.9968089788732394\n",
      "\n",
      "Epoch 67. Loss: 0.003327960109200761, Train_acc 0.9968312937062938\n",
      "\n",
      "Epoch 67. Loss: 0.0030809728890352117, Train_acc 0.9968532986111112\n",
      "\n",
      "Epoch 67. Loss: 0.002894623803077728, Train_acc 0.996875\n",
      "\n",
      "Epoch 67. Loss: 0.0026647053220304165, Train_acc 0.996896404109589\n",
      "\n",
      "Epoch 67. Loss: 0.002710758962304799, Train_acc 0.9969175170068028\n",
      "\n",
      "Epoch 67. Loss: 0.0026019526602221203, Train_acc 0.9969383445945946\n",
      "\n",
      "Epoch 67. Loss: 0.0023566325583972004, Train_acc 0.9969588926174496\n",
      "\n",
      "Epoch 67. Loss: 0.0022625563177988647, Train_acc 0.9969791666666666\n",
      "\n",
      "Epoch 67. Loss: 0.0029987536490135537, Train_acc 0.9969991721854304\n",
      "\n",
      "Epoch 67. Loss: 0.0028162501440724564, Train_acc 0.9970189144736842\n",
      "\n",
      "Epoch 67. Loss: 0.0025410516919875145, Train_acc 0.9970383986928104\n",
      "\n",
      "Epoch 67. Loss: 0.002346933050565109, Train_acc 0.9970576298701299\n",
      "\n",
      "Epoch 67. Loss: 0.0021158881456697807, Train_acc 0.9970766129032258\n",
      "\n",
      "Epoch 67. Loss: 0.002408985409159496, Train_acc 0.9970953525641025\n",
      "\n",
      "Epoch 67. Loss: 0.002615123473571868, Train_acc 0.9971138535031847\n",
      "\n",
      "Epoch 67. Loss: 0.0031925897147957664, Train_acc 0.9971321202531646\n",
      "\n",
      "Epoch 67. Loss: 0.0029722462462108594, Train_acc 0.9971501572327044\n",
      "\n",
      "Epoch 67. Loss: 0.0027580379463781057, Train_acc 0.99716796875\n",
      "\n",
      "Epoch 67. Loss: 0.0025178532588153307, Train_acc 0.9971855590062112\n",
      "\n",
      "Epoch 67. Loss: 0.002304155277662208, Train_acc 0.9972029320987654\n",
      "\n",
      "Epoch 67. Loss: 0.002105869846120124, Train_acc 0.9972200920245399\n",
      "\n",
      "Epoch 67. Loss: 0.0019020176675919526, Train_acc 0.9972370426829268\n",
      "\n",
      "Epoch 67. Loss: 0.0017225569124797993, Train_acc 0.9972537878787879\n",
      "\n",
      "Epoch 67. Loss: 0.0015709861138927575, Train_acc 0.9972703313253012\n",
      "\n",
      "Epoch 67. Loss: 0.0014684395942547296, Train_acc 0.9972866766467066\n",
      "\n",
      "Epoch 67. Loss: 0.0013485651155067644, Train_acc 0.9973028273809523\n",
      "\n",
      "Epoch 67. Loss: 0.001389463783908918, Train_acc 0.9973187869822485\n",
      "\n",
      "Epoch 67. Loss: 0.0012533497120815313, Train_acc 0.9973345588235294\n",
      "\n",
      "Epoch 67. Loss: 0.0011357331960362088, Train_acc 0.9973501461988304\n",
      "\n",
      "Epoch 67. Loss: 0.0010862359173040295, Train_acc 0.9973655523255814\n",
      "\n",
      "Epoch 67. Loss: 0.0009830088880565554, Train_acc 0.9973807803468208\n",
      "\n",
      "Epoch 67. Loss: 0.0012272806659555547, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 67. Loss: 0.0011598670484877628, Train_acc 0.9974107142857143\n",
      "\n",
      "Epoch 67. Loss: 0.001048040762396224, Train_acc 0.9974254261363636\n",
      "\n",
      "Epoch 67. Loss: 0.0009921584032545844, Train_acc 0.9974399717514124\n",
      "\n",
      "Epoch 67. Loss: 0.0009239240793946706, Train_acc 0.9974543539325843\n",
      "\n",
      "Epoch 67. Loss: 0.0008688265916398531, Train_acc 0.9974685754189944\n",
      "\n",
      "Epoch 67. Loss: 0.0007882351219687808, Train_acc 0.9974826388888889\n",
      "\n",
      "Epoch 67. Loss: 0.0007120422324292097, Train_acc 0.997496546961326\n",
      "\n",
      "Epoch 67. Loss: 0.0006932380822228403, Train_acc 0.9975103021978022\n",
      "\n",
      "Epoch 67. Loss: 0.0011841643607104133, Train_acc 0.9975239071038251\n",
      "\n",
      "Epoch 67. Loss: 0.0012997907777563612, Train_acc 0.9975373641304348\n",
      "\n",
      "Epoch 67. Loss: 0.0014114011996182096, Train_acc 0.9975506756756757\n",
      "\n",
      "Epoch 67. Loss: 0.0012928217476596683, Train_acc 0.9975638440860215\n",
      "\n",
      "Epoch 67. Loss: 0.001170409491327651, Train_acc 0.997576871657754\n",
      "\n",
      "Epoch 67. Loss: 0.0010935609553386994, Train_acc 0.9975897606382979\n",
      "\n",
      "Epoch 67. Loss: 0.000989679793082412, Train_acc 0.9976025132275133\n",
      "\n",
      "Epoch 67. Loss: 0.0009272602207076051, Train_acc 0.9976151315789473\n",
      "\n",
      "Epoch 67. Loss: 0.0008457211100703142, Train_acc 0.9976276178010471\n",
      "\n",
      "Epoch 67. Loss: 0.0007669217838521429, Train_acc 0.9976399739583334\n",
      "\n",
      "Epoch 67. Loss: 0.0006972670179003479, Train_acc 0.9976522020725389\n",
      "\n",
      "Epoch 67. Loss: 0.0006304994717188637, Train_acc 0.9976643041237113\n",
      "\n",
      "Epoch 67. Loss: 0.0005801962790568399, Train_acc 0.997676282051282\n",
      "\n",
      "Epoch 67. Loss: 0.0005353099016191008, Train_acc 0.99768\n",
      "\n",
      "Epoch 68. Loss: 0.0006490982995860078, Train_acc 1.0\n",
      "\n",
      "Epoch 68. Loss: 0.0005879687086853669, Train_acc 1.0\n",
      "\n",
      "Epoch 68. Loss: 0.0005353042513626865, Train_acc 1.0\n",
      "\n",
      "Epoch 68. Loss: 0.0004828943786324821, Train_acc 1.0\n",
      "\n",
      "Epoch 68. Loss: 0.0004451301162268214, Train_acc 1.0\n",
      "\n",
      "Epoch 68. Loss: 0.0004092150164053285, Train_acc 1.0\n",
      "\n",
      "Epoch 68. Loss: 0.00044595940300349386, Train_acc 1.0\n",
      "\n",
      "Epoch 68. Loss: 0.0020774011840390323, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 68. Loss: 0.001871151251785606, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 68. Loss: 0.0016843819171293059, Train_acc 0.99921875\n",
      "\n",
      "Epoch 68. Loss: 0.002245905930930687, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 68. Loss: 0.0020223925017075406, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 68. Loss: 0.0019055545479195566, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 68. Loss: 0.0017254828203650434, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 68. Loss: 0.0015997815132024543, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 68. Loss: 0.001719068654802381, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 68. Loss: 0.0015535545599144988, Train_acc 0.9990808823529411\n",
      "\n",
      "Epoch 68. Loss: 0.0014017727450749372, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 68. Loss: 0.0012679180710969725, Train_acc 0.9991776315789473\n",
      "\n",
      "Epoch 68. Loss: 0.004169986020874235, Train_acc 0.998828125\n",
      "\n",
      "Epoch 68. Loss: 0.003769844095452878, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 68. Loss: 0.0034286911810957666, Train_acc 0.9989346590909091\n",
      "\n",
      "Epoch 68. Loss: 0.0030886680574449565, Train_acc 0.9989809782608695\n",
      "\n",
      "Epoch 68. Loss: 0.002792265637936849, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 68. Loss: 0.002514429809776486, Train_acc 0.9990625\n",
      "\n",
      "Epoch 68. Loss: 0.005175369051510878, Train_acc 0.9984975961538461\n",
      "\n",
      "Epoch 68. Loss: 0.004664748975802861, Train_acc 0.9985532407407407\n",
      "\n",
      "Epoch 68. Loss: 0.004201576470219415, Train_acc 0.9986049107142857\n",
      "\n",
      "Epoch 68. Loss: 0.003830265190478404, Train_acc 0.9986530172413793\n",
      "\n",
      "Epoch 68. Loss: 0.0034513647563990117, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 68. Loss: 0.005073088984883085, Train_acc 0.9984879032258065\n",
      "\n",
      "Epoch 68. Loss: 0.004607627547065173, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 68. Loss: 0.004161122192829908, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 68. Loss: 0.004212913140556271, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 68. Loss: 0.005371701657683601, Train_acc 0.9984375\n",
      "\n",
      "Epoch 68. Loss: 0.0055377731680073886, Train_acc 0.9984809027777778\n",
      "\n",
      "Epoch 68. Loss: 0.005097109378392865, Train_acc 0.9985219594594594\n",
      "\n",
      "Epoch 68. Loss: 0.0045894412096733036, Train_acc 0.9985608552631579\n",
      "\n",
      "Epoch 68. Loss: 0.009927442928826288, Train_acc 0.9983974358974359\n",
      "\n",
      "Epoch 68. Loss: 0.009084038678788075, Train_acc 0.9984375\n",
      "\n",
      "Epoch 68. Loss: 0.01019600223211908, Train_acc 0.9982850609756098\n",
      "\n",
      "Epoch 68. Loss: 0.009201497863560218, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 68. Loss: 0.009071265244480339, Train_acc 0.9981831395348837\n",
      "\n",
      "Epoch 68. Loss: 0.009464565571990342, Train_acc 0.998046875\n",
      "\n",
      "Epoch 68. Loss: 0.00880532712728983, Train_acc 0.9980902777777778\n",
      "\n",
      "Epoch 68. Loss: 0.008007578514065198, Train_acc 0.9981317934782609\n",
      "\n",
      "Epoch 68. Loss: 0.007250373671822266, Train_acc 0.9981715425531915\n",
      "\n",
      "Epoch 68. Loss: 0.006556970919792182, Train_acc 0.9982096354166666\n",
      "\n",
      "Epoch 68. Loss: 0.005941527815930875, Train_acc 0.9982461734693877\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68. Loss: 0.0067512108227069665, Train_acc 0.998125\n",
      "\n",
      "Epoch 68. Loss: 0.011716433317105965, Train_acc 0.9980085784313726\n",
      "\n",
      "Epoch 68. Loss: 0.011042574124983844, Train_acc 0.998046875\n",
      "\n",
      "Epoch 68. Loss: 0.00996889449188376, Train_acc 0.9980837264150944\n",
      "\n",
      "Epoch 68. Loss: 0.008998174037068095, Train_acc 0.9981192129629629\n",
      "\n",
      "Epoch 68. Loss: 0.015020205288108294, Train_acc 0.9977272727272727\n",
      "\n",
      "Epoch 68. Loss: 0.014108704226666186, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 68. Loss: 0.012703246477999239, Train_acc 0.9978070175438597\n",
      "\n",
      "Epoch 68. Loss: 0.01152292705570127, Train_acc 0.9978448275862069\n",
      "\n",
      "Epoch 68. Loss: 0.010424156998653773, Train_acc 0.9978813559322034\n",
      "\n",
      "Epoch 68. Loss: 0.011603661640041677, Train_acc 0.99765625\n",
      "\n",
      "Epoch 68. Loss: 0.01089696435538257, Train_acc 0.9976946721311475\n",
      "\n",
      "Epoch 68. Loss: 0.014072913066214249, Train_acc 0.9976058467741935\n",
      "\n",
      "Epoch 68. Loss: 0.01288311028409683, Train_acc 0.9976438492063492\n",
      "\n",
      "Epoch 68. Loss: 0.012471218874412925, Train_acc 0.9976806640625\n",
      "\n",
      "Epoch 68. Loss: 0.014552597675047652, Train_acc 0.9974759615384615\n",
      "\n",
      "Epoch 68. Loss: 0.014371806843568983, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 68. Loss: 0.018890014556190465, Train_acc 0.9970848880597015\n",
      "\n",
      "Epoch 68. Loss: 0.017196916757575655, Train_acc 0.9971277573529411\n",
      "\n",
      "Epoch 68. Loss: 0.01599825899098991, Train_acc 0.9971693840579711\n",
      "\n",
      "Epoch 68. Loss: 0.02550893706346761, Train_acc 0.9969866071428571\n",
      "\n",
      "Epoch 68. Loss: 0.026639941474186277, Train_acc 0.996919014084507\n",
      "\n",
      "Epoch 68. Loss: 0.024617256051647867, Train_acc 0.9969618055555556\n",
      "\n",
      "Epoch 68. Loss: 0.02545857920618195, Train_acc 0.996896404109589\n",
      "\n",
      "Epoch 68. Loss: 0.023725186517429397, Train_acc 0.9968327702702703\n",
      "\n",
      "Epoch 68. Loss: 0.022124424335889858, Train_acc 0.996875\n",
      "\n",
      "Epoch 68. Loss: 0.020592684966727653, Train_acc 0.9969161184210527\n",
      "\n",
      "Epoch 68. Loss: 0.019205935816754005, Train_acc 0.9969561688311688\n",
      "\n",
      "Epoch 68. Loss: 0.018845407571604043, Train_acc 0.996895032051282\n",
      "\n",
      "Epoch 68. Loss: 0.019888972556182914, Train_acc 0.9968354430379747\n",
      "\n",
      "Epoch 68. Loss: 0.02798486752711759, Train_acc 0.9966796875\n",
      "\n",
      "Epoch 68. Loss: 0.025634524489444727, Train_acc 0.9967206790123457\n",
      "\n",
      "Epoch 68. Loss: 0.02844679744392833, Train_acc 0.9965701219512195\n",
      "\n",
      "Epoch 68. Loss: 0.027006280288996112, Train_acc 0.9966114457831325\n",
      "\n",
      "Epoch 68. Loss: 0.0331162581138925, Train_acc 0.99609375\n",
      "\n",
      "Epoch 68. Loss: 0.03021229598870423, Train_acc 0.9961397058823529\n",
      "\n",
      "Epoch 68. Loss: 0.02842529064223659, Train_acc 0.99609375\n",
      "\n",
      "Epoch 68. Loss: 0.02824482999717139, Train_acc 0.9959590517241379\n",
      "\n",
      "Epoch 68. Loss: 0.030233656756355847, Train_acc 0.9956498579545454\n",
      "\n",
      "Epoch 68. Loss: 0.028482081439889506, Train_acc 0.9956109550561798\n",
      "\n",
      "Epoch 68. Loss: 0.029931916174409122, Train_acc 0.9955729166666667\n",
      "\n",
      "Epoch 68. Loss: 0.029946896845505236, Train_acc 0.9954498626373627\n",
      "\n",
      "Epoch 68. Loss: 0.027209155753095984, Train_acc 0.995499320652174\n",
      "\n",
      "Epoch 68. Loss: 0.025747384200847184, Train_acc 0.9954637096774194\n",
      "\n",
      "Epoch 68. Loss: 0.02447547740074042, Train_acc 0.9954288563829787\n",
      "\n",
      "Epoch 68. Loss: 0.022401005097467095, Train_acc 0.9954769736842105\n",
      "\n",
      "Epoch 68. Loss: 0.02056521239272212, Train_acc 0.9955240885416666\n",
      "\n",
      "Epoch 68. Loss: 0.018766231484672026, Train_acc 0.9955702319587629\n",
      "\n",
      "Epoch 68. Loss: 0.018366164212638675, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 68. Loss: 0.01905429586340297, Train_acc 0.9954229797979798\n",
      "\n",
      "Epoch 68. Loss: 0.017557806620248934, Train_acc 0.99546875\n",
      "\n",
      "[Epoch 68 Batch 100] Loss: 0.016239637672229513 Training: accuracy=0.995514\n",
      "Epoch 68. Loss: 0.016239637672229513, Train_acc 0.9955136138613861\n",
      "\n",
      "Epoch 68. Loss: 0.01692346405028454, Train_acc 0.9954810049019608\n",
      "\n",
      "Epoch 68. Loss: 0.01709697902386622, Train_acc 0.9954490291262136\n",
      "\n",
      "Epoch 68. Loss: 0.016506606431471435, Train_acc 0.9954927884615384\n",
      "\n",
      "Epoch 68. Loss: 0.01521953831240576, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 68. Loss: 0.0183028457175944, Train_acc 0.9953567216981132\n",
      "\n",
      "Epoch 68. Loss: 0.016700129444413223, Train_acc 0.9954001168224299\n",
      "\n",
      "Epoch 68. Loss: 0.015258517680328642, Train_acc 0.9954427083333334\n",
      "\n",
      "Epoch 68. Loss: 0.014228982101242143, Train_acc 0.9954845183486238\n",
      "\n",
      "Epoch 68. Loss: 0.013055682881312428, Train_acc 0.9955255681818181\n",
      "\n",
      "Epoch 68. Loss: 0.014635896194252544, Train_acc 0.9954954954954955\n",
      "\n",
      "Epoch 68. Loss: 0.013874590059688545, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 68. Loss: 0.012594959441710284, Train_acc 0.995575221238938\n",
      "\n",
      "Epoch 68. Loss: 0.011549811439340207, Train_acc 0.9956140350877193\n",
      "\n",
      "Epoch 68. Loss: 0.01324350260343393, Train_acc 0.9955842391304348\n",
      "\n",
      "Epoch 68. Loss: 0.012135895506855014, Train_acc 0.9956223060344828\n",
      "\n",
      "Epoch 68. Loss: 0.013039974048420336, Train_acc 0.9955929487179487\n",
      "\n",
      "Epoch 68. Loss: 0.011848794894942238, Train_acc 0.9956302966101694\n",
      "\n",
      "Epoch 68. Loss: 0.010837941375493492, Train_acc 0.9956670168067226\n",
      "\n",
      "Epoch 68. Loss: 0.010436774088847177, Train_acc 0.995703125\n",
      "\n",
      "Epoch 68. Loss: 0.010557613859093968, Train_acc 0.9956740702479339\n",
      "\n",
      "Epoch 68. Loss: 0.012740453710720048, Train_acc 0.9956454918032787\n",
      "\n",
      "Epoch 68. Loss: 0.012057964601872955, Train_acc 0.9956173780487805\n",
      "\n",
      "Epoch 68. Loss: 0.01095129917590716, Train_acc 0.9956527217741935\n",
      "\n",
      "Epoch 68. Loss: 0.009971571906541871, Train_acc 0.9956875\n",
      "\n",
      "Epoch 68. Loss: 0.009099404235714752, Train_acc 0.9957217261904762\n",
      "\n",
      "Epoch 68. Loss: 0.009005347836048078, Train_acc 0.9956938976377953\n",
      "\n",
      "Epoch 68. Loss: 0.008337832754579787, Train_acc 0.9957275390625\n",
      "\n",
      "Epoch 68. Loss: 0.00797653112104023, Train_acc 0.9957606589147286\n",
      "\n",
      "Epoch 68. Loss: 0.007983839574818175, Train_acc 0.9957932692307693\n",
      "\n",
      "Epoch 68. Loss: 0.00883655885311755, Train_acc 0.9957657442748091\n",
      "\n",
      "Epoch 68. Loss: 0.008164670191469423, Train_acc 0.995797821969697\n",
      "\n",
      "Epoch 68. Loss: 0.008293947928931681, Train_acc 0.9957706766917294\n",
      "\n",
      "Epoch 68. Loss: 0.0075585825481777206, Train_acc 0.9958022388059702\n",
      "\n",
      "Epoch 68. Loss: 0.006941420879141821, Train_acc 0.9958333333333333\n",
      "\n",
      "Epoch 68. Loss: 0.006460171564788819, Train_acc 0.9958639705882353\n",
      "\n",
      "Epoch 68. Loss: 0.00747699398491192, Train_acc 0.9958371350364964\n",
      "\n",
      "Epoch 68. Loss: 0.008371772285044862, Train_acc 0.9957540760869565\n",
      "\n",
      "Epoch 68. Loss: 0.008070424561492212, Train_acc 0.9957846223021583\n",
      "\n",
      "Epoch 68. Loss: 0.0074537603419273565, Train_acc 0.9958147321428571\n",
      "\n",
      "Epoch 68. Loss: 0.006913548151664389, Train_acc 0.995844414893617\n",
      "\n",
      "Epoch 68. Loss: 0.006269676064175511, Train_acc 0.9958736795774648\n",
      "\n",
      "Epoch 68. Loss: 0.005679510443455781, Train_acc 0.995902534965035\n",
      "\n",
      "Epoch 68. Loss: 0.005937163543594008, Train_acc 0.9958767361111112\n",
      "\n",
      "Epoch 68. Loss: 0.005444525688808822, Train_acc 0.9959051724137931\n",
      "\n",
      "Epoch 68. Loss: 0.005110650904965397, Train_acc 0.9959332191780822\n",
      "\n",
      "Epoch 68. Loss: 0.007299779227070806, Train_acc 0.9958545918367347\n",
      "\n",
      "Epoch 68. Loss: 0.006595836223210288, Train_acc 0.9958826013513513\n",
      "\n",
      "Epoch 68. Loss: 0.0063628565477240615, Train_acc 0.9959102348993288\n",
      "\n",
      "Epoch 68. Loss: 0.005773090269289184, Train_acc 0.9959375\n",
      "\n",
      "Epoch 68. Loss: 0.005252589724982993, Train_acc 0.9959644039735099\n",
      "\n",
      "Epoch 68. Loss: 0.004908272467855557, Train_acc 0.9959909539473685\n",
      "\n",
      "Epoch 68. Loss: 0.004517852306917111, Train_acc 0.9960171568627451\n",
      "\n",
      "Epoch 68. Loss: 0.005770807041723848, Train_acc 0.995992288961039\n",
      "\n",
      "Epoch 68. Loss: 0.005515182242765416, Train_acc 0.9960181451612903\n",
      "\n",
      "Epoch 68. Loss: 0.006504111883170356, Train_acc 0.9959935897435898\n",
      "\n",
      "Epoch 68. Loss: 0.006017196060849234, Train_acc 0.9960191082802548\n",
      "\n",
      "Epoch 68. Loss: 0.0055510211306323155, Train_acc 0.9960443037974683\n",
      "\n",
      "Epoch 68. Loss: 0.005384573152736683, Train_acc 0.9960691823899371\n",
      "\n",
      "Epoch 68. Loss: 0.004928371487076231, Train_acc 0.99609375\n",
      "\n",
      "Epoch 68. Loss: 0.0062344395843283665, Train_acc 0.9960694875776398\n",
      "\n",
      "Epoch 68. Loss: 0.005774981892020524, Train_acc 0.99609375\n",
      "\n",
      "Epoch 68. Loss: 0.007453461020509321, Train_acc 0.9960697852760736\n",
      "\n",
      "Epoch 68. Loss: 0.006765430960242749, Train_acc 0.99609375\n",
      "\n",
      "Epoch 68. Loss: 0.00615394225945455, Train_acc 0.9961174242424242\n",
      "\n",
      "Epoch 68. Loss: 0.005855846421617706, Train_acc 0.9961408132530121\n",
      "\n",
      "Epoch 68. Loss: 0.005321966212736911, Train_acc 0.9961639221556886\n",
      "\n",
      "Epoch 68. Loss: 0.0059658536107069365, Train_acc 0.9961402529761905\n",
      "\n",
      "Epoch 68. Loss: 0.005921721536582063, Train_acc 0.9961630917159763\n",
      "\n",
      "Epoch 68. Loss: 0.005523689359443949, Train_acc 0.9961856617647059\n",
      "\n",
      "Epoch 68. Loss: 0.005354443783142477, Train_acc 0.9962079678362573\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68. Loss: 0.005725642676274457, Train_acc 0.9961845930232558\n",
      "\n",
      "Epoch 68. Loss: 0.005362439723420571, Train_acc 0.9962066473988439\n",
      "\n",
      "Epoch 68. Loss: 0.004850234176259575, Train_acc 0.9962284482758621\n",
      "\n",
      "Epoch 68. Loss: 0.0051986595262956655, Train_acc 0.9962053571428572\n",
      "\n",
      "Epoch 68. Loss: 0.004732007890388104, Train_acc 0.9962269176136364\n",
      "\n",
      "Epoch 68. Loss: 0.004302635269767553, Train_acc 0.9962482344632768\n",
      "\n",
      "Epoch 68. Loss: 0.005643893497353652, Train_acc 0.9962254213483146\n",
      "\n",
      "Epoch 68. Loss: 0.006203053098618262, Train_acc 0.9962028631284916\n",
      "\n",
      "Epoch 68. Loss: 0.005600855167611784, Train_acc 0.9962239583333333\n",
      "\n",
      "Epoch 68. Loss: 0.005086398304457005, Train_acc 0.9962448204419889\n",
      "\n",
      "Epoch 68. Loss: 0.005086327329013828, Train_acc 0.9962654532967034\n",
      "\n",
      "Epoch 68. Loss: 0.0046370283249716465, Train_acc 0.9962858606557377\n",
      "\n",
      "Epoch 68. Loss: 0.0044899588696986886, Train_acc 0.9963060461956522\n",
      "\n",
      "Epoch 68. Loss: 0.004183342076178383, Train_acc 0.9963260135135135\n",
      "\n",
      "Epoch 68. Loss: 0.003982656464132063, Train_acc 0.9963457661290323\n",
      "\n",
      "Epoch 68. Loss: 0.0037515418460092476, Train_acc 0.996365307486631\n",
      "\n",
      "Epoch 68. Loss: 0.004874073943208593, Train_acc 0.996343085106383\n",
      "\n",
      "Epoch 68. Loss: 0.007910060641805177, Train_acc 0.9962797619047619\n",
      "\n",
      "Epoch 68. Loss: 0.007645983898392181, Train_acc 0.9962993421052632\n",
      "\n",
      "Epoch 68. Loss: 0.007173344355636114, Train_acc 0.9963187172774869\n",
      "\n",
      "Epoch 68. Loss: 0.012836344416570611, Train_acc 0.9962565104166666\n",
      "\n",
      "Epoch 68. Loss: 0.011930830246402575, Train_acc 0.9962759067357513\n",
      "\n",
      "Epoch 68. Loss: 0.010904273204548287, Train_acc 0.9962951030927835\n",
      "\n",
      "Epoch 68. Loss: 0.011756207775363143, Train_acc 0.9962740384615385\n",
      "\n",
      "Epoch 68. Loss: 0.010587346383550683, Train_acc 0.99628\n",
      "\n",
      "Epoch 69. Loss: 0.009628432481991278, Train_acc 1.0\n",
      "\n",
      "Epoch 69. Loss: 0.008767048760714704, Train_acc 1.0\n",
      "\n",
      "Epoch 69. Loss: 0.008559487000744857, Train_acc 1.0\n",
      "\n",
      "Epoch 69. Loss: 0.008194916663892254, Train_acc 1.0\n",
      "\n",
      "Epoch 69. Loss: 0.007388764562114698, Train_acc 1.0\n",
      "\n",
      "Epoch 69. Loss: 0.0067705737279992895, Train_acc 1.0\n",
      "\n",
      "Epoch 69. Loss: 0.006174599807295569, Train_acc 1.0\n",
      "\n",
      "Epoch 69. Loss: 0.005818181674554976, Train_acc 1.0\n",
      "\n",
      "Epoch 69. Loss: 0.00527648339058741, Train_acc 1.0\n",
      "\n",
      "Epoch 69. Loss: 0.004765313851336043, Train_acc 1.0\n",
      "\n",
      "Epoch 69. Loss: 0.005712377101182402, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 69. Loss: 0.005162398839904445, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 69. Loss: 0.004670010834272984, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 69. Loss: 0.004250233946286917, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 69. Loss: 0.003872743722094734, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 69. Loss: 0.00431650105606941, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 69. Loss: 0.003939063225889304, Train_acc 0.9990808823529411\n",
      "\n",
      "Epoch 69. Loss: 0.0036080506767294696, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 69. Loss: 0.0032844746439897846, Train_acc 0.9991776315789473\n",
      "\n",
      "Epoch 69. Loss: 0.0031593388557503072, Train_acc 0.99921875\n",
      "\n",
      "Epoch 69. Loss: 0.004813979788726817, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 69. Loss: 0.004385775230025873, Train_acc 0.9989346590909091\n",
      "\n",
      "Epoch 69. Loss: 0.003989203923268058, Train_acc 0.9989809782608695\n",
      "\n",
      "Epoch 69. Loss: 0.0038507629997935337, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 69. Loss: 0.0036089348918488424, Train_acc 0.9990625\n",
      "\n",
      "Epoch 69. Loss: 0.0033035380650534452, Train_acc 0.9990985576923077\n",
      "\n",
      "Epoch 69. Loss: 0.003022002901520138, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 69. Loss: 0.0027315376614340326, Train_acc 0.9991629464285714\n",
      "\n",
      "Epoch 69. Loss: 0.003921514756811397, Train_acc 0.9989224137931034\n",
      "\n",
      "Epoch 69. Loss: 0.0037921510795498516, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 69. Loss: 0.0034218524109960852, Train_acc 0.998991935483871\n",
      "\n",
      "Epoch 69. Loss: 0.0031650324648409716, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 69. Loss: 0.0029655665356067983, Train_acc 0.9990530303030303\n",
      "\n",
      "Epoch 69. Loss: 0.0028577310163734704, Train_acc 0.9990808823529411\n",
      "\n",
      "Epoch 69. Loss: 0.0026643485483899727, Train_acc 0.9991071428571429\n",
      "\n",
      "Epoch 69. Loss: 0.0024484990612678244, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 69. Loss: 0.002223573433744909, Train_acc 0.9991554054054054\n",
      "\n",
      "Epoch 69. Loss: 0.002772760591555835, Train_acc 0.9989720394736842\n",
      "\n",
      "Epoch 69. Loss: 0.00258675271280411, Train_acc 0.9989983974358975\n",
      "\n",
      "Epoch 69. Loss: 0.002387914503668351, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 69. Loss: 0.0027606683385115295, Train_acc 0.9988567073170732\n",
      "\n",
      "Epoch 69. Loss: 0.00253464297999365, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 69. Loss: 0.002289230054418519, Train_acc 0.9989098837209303\n",
      "\n",
      "Epoch 69. Loss: 0.002071951081178397, Train_acc 0.9989346590909091\n",
      "\n",
      "Epoch 69. Loss: 0.0019450858163916859, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 69. Loss: 0.0027417203347161823, Train_acc 0.9988111413043478\n",
      "\n",
      "Epoch 69. Loss: 0.0029575819278009606, Train_acc 0.9988364361702128\n",
      "\n",
      "Epoch 69. Loss: 0.003057155732445229, Train_acc 0.9988606770833334\n",
      "\n",
      "Epoch 69. Loss: 0.0027677514766501414, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 69. Loss: 0.002510092261794782, Train_acc 0.99890625\n",
      "\n",
      "Epoch 69. Loss: 0.002281937266680443, Train_acc 0.9989276960784313\n",
      "\n",
      "Epoch 69. Loss: 0.0020944819264636654, Train_acc 0.9989483173076923\n",
      "\n",
      "Epoch 69. Loss: 0.0019168876055865708, Train_acc 0.9989681603773585\n",
      "\n",
      "Epoch 69. Loss: 0.0017629785040607355, Train_acc 0.9989872685185185\n",
      "\n",
      "Epoch 69. Loss: 0.0016520362851774964, Train_acc 0.9990056818181818\n",
      "\n",
      "Epoch 69. Loss: 0.001575111204287598, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 69. Loss: 0.0014814702267713304, Train_acc 0.9990405701754386\n",
      "\n",
      "Epoch 69. Loss: 0.0037354585613549015, Train_acc 0.9989224137931034\n",
      "\n",
      "Epoch 69. Loss: 0.0033688753470020043, Train_acc 0.9989406779661016\n",
      "\n",
      "Epoch 69. Loss: 0.005077421221813847, Train_acc 0.998828125\n",
      "\n",
      "Epoch 69. Loss: 0.004634956238124556, Train_acc 0.9988473360655737\n",
      "\n",
      "Epoch 69. Loss: 0.004185993537835902, Train_acc 0.9988659274193549\n",
      "\n",
      "Epoch 69. Loss: 0.0038134837928566353, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 69. Loss: 0.004760213512166114, Train_acc 0.998779296875\n",
      "\n",
      "Epoch 69. Loss: 0.004678159817368184, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 69. Loss: 0.004772989330569262, Train_acc 0.9988162878787878\n",
      "\n",
      "Epoch 69. Loss: 0.00851858746517839, Train_acc 0.9987173507462687\n",
      "\n",
      "Epoch 69. Loss: 0.007746431444294531, Train_acc 0.9987362132352942\n",
      "\n",
      "Epoch 69. Loss: 0.007172995280138205, Train_acc 0.9987545289855072\n",
      "\n",
      "Epoch 69. Loss: 0.007023404941032723, Train_acc 0.9986607142857142\n",
      "\n",
      "Epoch 69. Loss: 0.006401624973041545, Train_acc 0.9986795774647887\n",
      "\n",
      "Epoch 69. Loss: 0.008200332175573168, Train_acc 0.9985894097222222\n",
      "\n",
      "Epoch 69. Loss: 0.0077541922357354685, Train_acc 0.9986087328767124\n",
      "\n",
      "Epoch 69. Loss: 0.008068837005049657, Train_acc 0.9985219594594594\n",
      "\n",
      "Epoch 69. Loss: 0.007676009449199443, Train_acc 0.9985416666666667\n",
      "\n",
      "Epoch 69. Loss: 0.007528418347539549, Train_acc 0.9985608552631579\n",
      "\n",
      "Epoch 69. Loss: 0.006864055207455496, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 69. Loss: 0.006627969483510561, Train_acc 0.9985977564102564\n",
      "\n",
      "Epoch 69. Loss: 0.006381585670986093, Train_acc 0.9986155063291139\n",
      "\n",
      "Epoch 69. Loss: 0.010048459744583056, Train_acc 0.99833984375\n",
      "\n",
      "Epoch 69. Loss: 0.009471409623590547, Train_acc 0.9983603395061729\n",
      "\n",
      "Epoch 69. Loss: 0.008691533287592923, Train_acc 0.9983803353658537\n",
      "\n",
      "Epoch 69. Loss: 0.008184961578826484, Train_acc 0.9983998493975904\n",
      "\n",
      "Epoch 69. Loss: 0.007534045137015322, Train_acc 0.9984188988095238\n",
      "\n",
      "Epoch 69. Loss: 0.007013320020181542, Train_acc 0.9984375\n",
      "\n",
      "Epoch 69. Loss: 0.009816815264233296, Train_acc 0.9983648255813954\n",
      "\n",
      "Epoch 69. Loss: 0.009270290671773264, Train_acc 0.9983836206896551\n",
      "\n",
      "Epoch 69. Loss: 0.008549100424561659, Train_acc 0.9984019886363636\n",
      "\n",
      "Epoch 69. Loss: 0.0078584594559718, Train_acc 0.9984199438202247\n",
      "\n",
      "Epoch 69. Loss: 0.007201418169845536, Train_acc 0.9984375\n",
      "\n",
      "Epoch 69. Loss: 0.006489059422893002, Train_acc 0.9984546703296703\n",
      "\n",
      "Epoch 69. Loss: 0.005864152599606539, Train_acc 0.9984714673913043\n",
      "\n",
      "Epoch 69. Loss: 0.005307462042117753, Train_acc 0.9984879032258065\n",
      "\n",
      "Epoch 69. Loss: 0.004935247801731203, Train_acc 0.9985039893617021\n",
      "\n",
      "Epoch 69. Loss: 0.004452038335842609, Train_acc 0.9985197368421053\n",
      "\n",
      "Epoch 69. Loss: 0.004115594503861862, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 69. Loss: 0.004015625505222855, Train_acc 0.9985502577319587\n",
      "\n",
      "Epoch 69. Loss: 0.004077115886873583, Train_acc 0.9985650510204082\n",
      "\n",
      "Epoch 69. Loss: 0.005168103672683162, Train_acc 0.9985006313131313\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69. Loss: 0.00470586580477201, Train_acc 0.998515625\n",
      "\n",
      "[Epoch 69 Batch 100] Loss: 0.00437016859831625 Training: accuracy=0.998530\n",
      "Epoch 69. Loss: 0.00437016859831625, Train_acc 0.9985303217821783\n",
      "\n",
      "Epoch 69. Loss: 0.004246927468803946, Train_acc 0.9985447303921569\n",
      "\n",
      "Epoch 69. Loss: 0.006980909483576499, Train_acc 0.9984830097087378\n",
      "\n",
      "Epoch 69. Loss: 0.006334046096417024, Train_acc 0.9984975961538461\n",
      "\n",
      "Epoch 69. Loss: 0.0057359773611931186, Train_acc 0.9985119047619048\n",
      "\n",
      "Epoch 69. Loss: 0.005197016300337562, Train_acc 0.9985259433962265\n",
      "\n",
      "Epoch 69. Loss: 0.00476913520066437, Train_acc 0.9985397196261683\n",
      "\n",
      "Epoch 69. Loss: 0.004360042720881822, Train_acc 0.9985532407407407\n",
      "\n",
      "Epoch 69. Loss: 0.004083764600990167, Train_acc 0.9985665137614679\n",
      "\n",
      "Epoch 69. Loss: 0.0037080301560307224, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 69. Loss: 0.003443162044850261, Train_acc 0.9985923423423423\n",
      "\n",
      "Epoch 69. Loss: 0.0031189190141657185, Train_acc 0.9986049107142857\n",
      "\n",
      "Epoch 69. Loss: 0.0030040627224936357, Train_acc 0.9986172566371682\n",
      "\n",
      "Epoch 69. Loss: 0.0028055168533275368, Train_acc 0.9986293859649122\n",
      "\n",
      "Epoch 69. Loss: 0.0031837830366745453, Train_acc 0.998641304347826\n",
      "\n",
      "Epoch 69. Loss: 0.002889709477154321, Train_acc 0.9986530172413793\n",
      "\n",
      "Epoch 69. Loss: 0.002942042059588051, Train_acc 0.9986645299145299\n",
      "\n",
      "Epoch 69. Loss: 0.003135848228458419, Train_acc 0.9986758474576272\n",
      "\n",
      "Epoch 69. Loss: 0.002946043346962799, Train_acc 0.998686974789916\n",
      "\n",
      "Epoch 69. Loss: 0.0030126198998240853, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 69. Loss: 0.00428450739721789, Train_acc 0.9986441115702479\n",
      "\n",
      "Epoch 69. Loss: 0.0038979688887411795, Train_acc 0.9986552254098361\n",
      "\n",
      "Epoch 69. Loss: 0.0036364153861468533, Train_acc 0.9986661585365854\n",
      "\n",
      "Epoch 69. Loss: 0.004318247140002146, Train_acc 0.9986139112903226\n",
      "\n",
      "Epoch 69. Loss: 0.004023863798500802, Train_acc 0.998625\n",
      "\n",
      "Epoch 69. Loss: 0.0036479824749537162, Train_acc 0.9986359126984127\n",
      "\n",
      "Epoch 69. Loss: 0.00348010679792534, Train_acc 0.9986466535433071\n",
      "\n",
      "Epoch 69. Loss: 0.003463255682799256, Train_acc 0.9986572265625\n",
      "\n",
      "Epoch 69. Loss: 0.0034935690243211716, Train_acc 0.9986676356589147\n",
      "\n",
      "Epoch 69. Loss: 0.003192379633593432, Train_acc 0.9986778846153846\n",
      "\n",
      "Epoch 69. Loss: 0.0029086684512277666, Train_acc 0.9986879770992366\n",
      "\n",
      "Epoch 69. Loss: 0.003120447715194245, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 69. Loss: 0.002851629617408264, Train_acc 0.9987077067669173\n",
      "\n",
      "Epoch 69. Loss: 0.002742545353799625, Train_acc 0.9987173507462687\n",
      "\n",
      "Epoch 69. Loss: 0.002486980321905465, Train_acc 0.9987268518518518\n",
      "\n",
      "Epoch 69. Loss: 0.002254303354663209, Train_acc 0.9987362132352942\n",
      "\n",
      "Epoch 69. Loss: 0.0020396021899505086, Train_acc 0.9987454379562044\n",
      "\n",
      "Epoch 69. Loss: 0.0019429218332326676, Train_acc 0.9987545289855072\n",
      "\n",
      "Epoch 69. Loss: 0.0024856620373150348, Train_acc 0.9987634892086331\n",
      "\n",
      "Epoch 69. Loss: 0.0024739518629524684, Train_acc 0.9987723214285714\n",
      "\n",
      "Epoch 69. Loss: 0.002276375763801209, Train_acc 0.9987810283687943\n",
      "\n",
      "Epoch 69. Loss: 0.004369966199863677, Train_acc 0.9986795774647887\n",
      "\n",
      "Epoch 69. Loss: 0.003972266005407066, Train_acc 0.9986888111888111\n",
      "\n",
      "Epoch 69. Loss: 0.003586513687521758, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 69. Loss: 0.0036406179645811403, Train_acc 0.9987068965517242\n",
      "\n",
      "Epoch 69. Loss: 0.003320510964397219, Train_acc 0.9987157534246576\n",
      "\n",
      "Epoch 69. Loss: 0.0029950129431756045, Train_acc 0.9987244897959183\n",
      "\n",
      "Epoch 69. Loss: 0.0031713218376581403, Train_acc 0.9987331081081081\n",
      "\n",
      "Epoch 69. Loss: 0.003955147792596626, Train_acc 0.998689177852349\n",
      "\n",
      "Epoch 69. Loss: 0.003774920403501995, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 69. Loss: 0.0034051729317265034, Train_acc 0.9987065397350994\n",
      "\n",
      "Epoch 69. Loss: 0.00307205424334756, Train_acc 0.9987150493421053\n",
      "\n",
      "Epoch 69. Loss: 0.004575298180813952, Train_acc 0.998672385620915\n",
      "\n",
      "Epoch 69. Loss: 0.004617673682616976, Train_acc 0.9986810064935064\n",
      "\n",
      "Epoch 69. Loss: 0.004203873996249358, Train_acc 0.9986895161290322\n",
      "\n",
      "Epoch 69. Loss: 0.003808725781821701, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 69. Loss: 0.00343704172602054, Train_acc 0.9987062101910829\n",
      "\n",
      "Epoch 69. Loss: 0.003146696521998628, Train_acc 0.9987143987341772\n",
      "\n",
      "Epoch 69. Loss: 0.0028428777294882916, Train_acc 0.9987224842767296\n",
      "\n",
      "Epoch 69. Loss: 0.0027198752824242815, Train_acc 0.99873046875\n",
      "\n",
      "Epoch 69. Loss: 0.0024630954951257323, Train_acc 0.9987383540372671\n",
      "\n",
      "Epoch 69. Loss: 0.0022275792386536376, Train_acc 0.9987461419753086\n",
      "\n",
      "Epoch 69. Loss: 0.0020694355436925212, Train_acc 0.9987538343558282\n",
      "\n",
      "Epoch 69. Loss: 0.0021588361550135124, Train_acc 0.9987614329268293\n",
      "\n",
      "Epoch 69. Loss: 0.0027513524552073517, Train_acc 0.9987689393939394\n",
      "\n",
      "Epoch 69. Loss: 0.002561764811025093, Train_acc 0.9987763554216867\n",
      "\n",
      "Epoch 69. Loss: 0.0023212800995811712, Train_acc 0.9987836826347305\n",
      "\n",
      "Epoch 69. Loss: 0.002095461651636539, Train_acc 0.9987909226190477\n",
      "\n",
      "Epoch 69. Loss: 0.0019003389388488072, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 69. Loss: 0.001940332244686753, Train_acc 0.9988051470588235\n",
      "\n",
      "Epoch 69. Loss: 0.002196757071854893, Train_acc 0.9988121345029239\n",
      "\n",
      "Epoch 69. Loss: 0.007509474969186387, Train_acc 0.9987736191860465\n",
      "\n",
      "Epoch 69. Loss: 0.008946891329835059, Train_acc 0.9987355491329479\n",
      "\n",
      "Epoch 69. Loss: 0.008083608309099632, Train_acc 0.998742816091954\n",
      "\n",
      "Epoch 69. Loss: 0.007284637388891098, Train_acc 0.99875\n",
      "\n",
      "Epoch 69. Loss: 0.006614320547938228, Train_acc 0.9987571022727273\n",
      "\n",
      "Epoch 69. Loss: 0.006108476488103611, Train_acc 0.9987641242937854\n",
      "\n",
      "Epoch 69. Loss: 0.006007995333129295, Train_acc 0.9987710674157303\n",
      "\n",
      "Epoch 69. Loss: 0.007012851425278898, Train_acc 0.9987342877094972\n",
      "\n",
      "Epoch 69. Loss: 0.007396500457765504, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 69. Loss: 0.006684846812592978, Train_acc 0.9987051104972375\n",
      "\n",
      "Epoch 69. Loss: 0.00667288629221055, Train_acc 0.9987122252747253\n",
      "\n",
      "Epoch 69. Loss: 0.0061266289221760615, Train_acc 0.998719262295082\n",
      "\n",
      "Epoch 69. Loss: 0.005598668921721755, Train_acc 0.9987262228260869\n",
      "\n",
      "Epoch 69. Loss: 0.005411881727151077, Train_acc 0.9987331081081081\n",
      "\n",
      "Epoch 69. Loss: 0.005212114058700502, Train_acc 0.9987399193548387\n",
      "\n",
      "Epoch 69. Loss: 0.00591677052030024, Train_acc 0.9987048796791443\n",
      "\n",
      "Epoch 69. Loss: 0.005468376142523203, Train_acc 0.9987117686170213\n",
      "\n",
      "Epoch 69. Loss: 0.0061776849033607665, Train_acc 0.9986772486772487\n",
      "\n",
      "Epoch 69. Loss: 0.006004225360796477, Train_acc 0.9986842105263158\n",
      "\n",
      "Epoch 69. Loss: 0.005715936866167747, Train_acc 0.9986910994764397\n",
      "\n",
      "Epoch 69. Loss: 0.005434295701694695, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 69. Loss: 0.007706920915286727, Train_acc 0.9986641839378239\n",
      "\n",
      "Epoch 69. Loss: 0.007023143379626189, Train_acc 0.9986710695876289\n",
      "\n",
      "Epoch 69. Loss: 0.009410232775274677, Train_acc 0.9985977564102564\n",
      "\n",
      "Epoch 69. Loss: 0.008482252166908432, Train_acc 0.9986\n",
      "\n",
      "Epoch 70. Loss: 0.008592758627600774, Train_acc 1.0\n",
      "\n",
      "Epoch 70. Loss: 0.01471258093583641, Train_acc 0.98828125\n",
      "\n",
      "Epoch 70. Loss: 0.01357802473084382, Train_acc 0.9921875\n",
      "\n",
      "Epoch 70. Loss: 0.0174987380734943, Train_acc 0.990234375\n",
      "\n",
      "Epoch 70. Loss: 0.015862147759700955, Train_acc 0.9921875\n",
      "\n",
      "Epoch 70. Loss: 0.014326101648623996, Train_acc 0.9934895833333334\n",
      "\n",
      "Epoch 70. Loss: 0.017785664520694543, Train_acc 0.9921875\n",
      "\n",
      "Epoch 70. Loss: 0.021928292771011944, Train_acc 0.9912109375\n",
      "\n",
      "Epoch 70. Loss: 0.02081586361810299, Train_acc 0.9913194444444444\n",
      "\n",
      "Epoch 70. Loss: 0.019493444527027597, Train_acc 0.99140625\n",
      "\n",
      "Epoch 70. Loss: 0.017645428040292194, Train_acc 0.9921875\n",
      "\n",
      "Epoch 70. Loss: 0.017735525481700598, Train_acc 0.9921875\n",
      "\n",
      "Epoch 70. Loss: 0.018798433739959926, Train_acc 0.9921875\n",
      "\n",
      "Epoch 70. Loss: 0.01751869784580445, Train_acc 0.9927455357142857\n",
      "\n",
      "Epoch 70. Loss: 0.01697181847053864, Train_acc 0.9927083333333333\n",
      "\n",
      "Epoch 70. Loss: 0.017752078165335344, Train_acc 0.99267578125\n",
      "\n",
      "Epoch 70. Loss: 0.016178126176943978, Train_acc 0.9931066176470589\n",
      "\n",
      "Epoch 70. Loss: 0.01494633782573098, Train_acc 0.9934895833333334\n",
      "\n",
      "Epoch 70. Loss: 0.013626727750719079, Train_acc 0.9938322368421053\n",
      "\n",
      "Epoch 70. Loss: 0.013557955119002301, Train_acc 0.99375\n",
      "\n",
      "Epoch 70. Loss: 0.01276002816229025, Train_acc 0.9940476190476191\n",
      "\n",
      "Epoch 70. Loss: 0.011995186677148576, Train_acc 0.9943181818181818\n",
      "\n",
      "Epoch 70. Loss: 0.013702427465233775, Train_acc 0.993546195652174\n",
      "\n",
      "Epoch 70. Loss: 0.012968505186748719, Train_acc 0.9934895833333334\n",
      "\n",
      "Epoch 70. Loss: 0.014403308343510822, Train_acc 0.993125\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70. Loss: 0.01332748740926027, Train_acc 0.9933894230769231\n",
      "\n",
      "Epoch 70. Loss: 0.014025613270830867, Train_acc 0.9933449074074074\n",
      "\n",
      "Epoch 70. Loss: 0.013088998215763353, Train_acc 0.9935825892857143\n",
      "\n",
      "Epoch 70. Loss: 0.013712204188736006, Train_acc 0.9935344827586207\n",
      "\n",
      "Epoch 70. Loss: 0.012888727963908069, Train_acc 0.99375\n",
      "\n",
      "Epoch 70. Loss: 0.012020193502032952, Train_acc 0.9939516129032258\n",
      "\n",
      "Epoch 70. Loss: 0.011517624506852802, Train_acc 0.994140625\n",
      "\n",
      "Epoch 70. Loss: 0.012245893694014945, Train_acc 0.9940814393939394\n",
      "\n",
      "Epoch 70. Loss: 0.013116015129135489, Train_acc 0.9940257352941176\n",
      "\n",
      "Epoch 70. Loss: 0.012420141005453264, Train_acc 0.9941964285714285\n",
      "\n",
      "Epoch 70. Loss: 0.011255626942058394, Train_acc 0.9943576388888888\n",
      "\n",
      "Epoch 70. Loss: 0.010442841134710602, Train_acc 0.9945101351351351\n",
      "\n",
      "Epoch 70. Loss: 0.009681266182059192, Train_acc 0.9946546052631579\n",
      "\n",
      "Epoch 70. Loss: 0.010082038089687356, Train_acc 0.9945913461538461\n",
      "\n",
      "Epoch 70. Loss: 0.009776809831385073, Train_acc 0.9947265625\n",
      "\n",
      "Epoch 70. Loss: 0.0090620949949392, Train_acc 0.9948551829268293\n",
      "\n",
      "Epoch 70. Loss: 0.008344014529804288, Train_acc 0.9949776785714286\n",
      "\n",
      "Epoch 70. Loss: 0.010416302497166303, Train_acc 0.9949127906976745\n",
      "\n",
      "Epoch 70. Loss: 0.009784591084698953, Train_acc 0.9950284090909091\n",
      "\n",
      "Epoch 70. Loss: 0.013060949938875542, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 70. Loss: 0.013866055747016166, Train_acc 0.994735054347826\n",
      "\n",
      "Epoch 70. Loss: 0.012603700198734307, Train_acc 0.9948470744680851\n",
      "\n",
      "Epoch 70. Loss: 0.013356215540770742, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 70. Loss: 0.012082878954555737, Train_acc 0.9948979591836735\n",
      "\n",
      "Epoch 70. Loss: 0.011040268327623887, Train_acc 0.995\n",
      "\n",
      "Epoch 70. Loss: 0.011525544586029904, Train_acc 0.9949448529411765\n",
      "\n",
      "Epoch 70. Loss: 0.011462780870271257, Train_acc 0.9948918269230769\n",
      "\n",
      "Epoch 70. Loss: 0.013618962202017783, Train_acc 0.9946933962264151\n",
      "\n",
      "Epoch 70. Loss: 0.012695798915069055, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 70. Loss: 0.012094941926918106, Train_acc 0.9948863636363636\n",
      "\n",
      "Epoch 70. Loss: 0.011488721524555991, Train_acc 0.9949776785714286\n",
      "\n",
      "Epoch 70. Loss: 0.010678325942423501, Train_acc 0.9950657894736842\n",
      "\n",
      "Epoch 70. Loss: 0.010549661291032934, Train_acc 0.9950161637931034\n",
      "\n",
      "Epoch 70. Loss: 0.009883355443826233, Train_acc 0.9951006355932204\n",
      "\n",
      "Epoch 70. Loss: 0.009244020438142939, Train_acc 0.9951822916666667\n",
      "\n",
      "Epoch 70. Loss: 0.010053847385300688, Train_acc 0.9950051229508197\n",
      "\n",
      "Epoch 70. Loss: 0.009323281014095389, Train_acc 0.995085685483871\n",
      "\n",
      "Epoch 70. Loss: 0.008452330364906618, Train_acc 0.9951636904761905\n",
      "\n",
      "Epoch 70. Loss: 0.007864798475763645, Train_acc 0.9952392578125\n",
      "\n",
      "Epoch 70. Loss: 0.00791364429023395, Train_acc 0.9953125\n",
      "\n",
      "Epoch 70. Loss: 0.007453787321424753, Train_acc 0.9953835227272727\n",
      "\n",
      "Epoch 70. Loss: 0.006953346053877119, Train_acc 0.9954524253731343\n",
      "\n",
      "Epoch 70. Loss: 0.006675930346654633, Train_acc 0.9955193014705882\n",
      "\n",
      "Epoch 70. Loss: 0.006117465849576991, Train_acc 0.9955842391304348\n",
      "\n",
      "Epoch 70. Loss: 0.006407781546585501, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 70. Loss: 0.005841843734785758, Train_acc 0.9955985915492958\n",
      "\n",
      "Epoch 70. Loss: 0.005501558308099069, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 70. Loss: 0.005109390746636859, Train_acc 0.9957191780821918\n",
      "\n",
      "Epoch 70. Loss: 0.004698398090750282, Train_acc 0.995777027027027\n",
      "\n",
      "Epoch 70. Loss: 0.004320220679283415, Train_acc 0.9958333333333333\n",
      "\n",
      "Epoch 70. Loss: 0.004438077350175626, Train_acc 0.9958881578947368\n",
      "\n",
      "Epoch 70. Loss: 0.00554903870646618, Train_acc 0.9958400974025974\n",
      "\n",
      "Epoch 70. Loss: 0.005009327442771603, Train_acc 0.9958934294871795\n",
      "\n",
      "Epoch 70. Loss: 0.004870225579359898, Train_acc 0.9959454113924051\n",
      "\n",
      "Epoch 70. Loss: 0.0044639062494374986, Train_acc 0.99599609375\n",
      "\n",
      "Epoch 70. Loss: 0.004118467417631686, Train_acc 0.996045524691358\n",
      "\n",
      "Epoch 70. Loss: 0.004423778732664115, Train_acc 0.9959984756097561\n",
      "\n",
      "Epoch 70. Loss: 0.005115254801553542, Train_acc 0.9959525602409639\n",
      "\n",
      "Epoch 70. Loss: 0.004996421484984804, Train_acc 0.9960007440476191\n",
      "\n",
      "Epoch 70. Loss: 0.004579200802263184, Train_acc 0.9960477941176471\n",
      "\n",
      "Epoch 70. Loss: 0.004144792172890996, Train_acc 0.99609375\n",
      "\n",
      "Epoch 70. Loss: 0.006296875176056113, Train_acc 0.9959590517241379\n",
      "\n",
      "Epoch 70. Loss: 0.0056792121592070255, Train_acc 0.9960049715909091\n",
      "\n",
      "Epoch 70. Loss: 0.005202193113918358, Train_acc 0.9960498595505618\n",
      "\n",
      "Epoch 70. Loss: 0.004685666104360758, Train_acc 0.99609375\n",
      "\n",
      "Epoch 70. Loss: 0.008994745558682984, Train_acc 0.9959649725274725\n",
      "\n",
      "Epoch 70. Loss: 0.008465024598256266, Train_acc 0.9960088315217391\n",
      "\n",
      "Epoch 70. Loss: 0.008020003100021645, Train_acc 0.996051747311828\n",
      "\n",
      "Epoch 70. Loss: 0.007247328685612982, Train_acc 0.99609375\n",
      "\n",
      "Epoch 70. Loss: 0.008489590445361888, Train_acc 0.9960526315789474\n",
      "\n",
      "Epoch 70. Loss: 0.007749920719614496, Train_acc 0.99609375\n",
      "\n",
      "Epoch 70. Loss: 0.0070644378682140595, Train_acc 0.9961340206185567\n",
      "\n",
      "Epoch 70. Loss: 0.00685579433286167, Train_acc 0.9961734693877551\n",
      "\n",
      "Epoch 70. Loss: 0.006184237469969948, Train_acc 0.9962121212121212\n",
      "\n",
      "Epoch 70. Loss: 0.007209837417070949, Train_acc 0.996171875\n",
      "\n",
      "[Epoch 70 Batch 100] Loss: 0.006607789877852694 Training: accuracy=0.996210\n",
      "Epoch 70. Loss: 0.006607789877852694, Train_acc 0.9962097772277227\n",
      "\n",
      "Epoch 70. Loss: 0.006043988211731297, Train_acc 0.9962469362745098\n",
      "\n",
      "Epoch 70. Loss: 0.005631498127737059, Train_acc 0.9962833737864077\n",
      "\n",
      "Epoch 70. Loss: 0.0055884363729283935, Train_acc 0.9963191105769231\n",
      "\n",
      "Epoch 70. Loss: 0.007224594129192149, Train_acc 0.9962797619047619\n",
      "\n",
      "Epoch 70. Loss: 0.009904255336285219, Train_acc 0.9962411556603774\n",
      "\n",
      "Epoch 70. Loss: 0.010258461508089829, Train_acc 0.9962032710280374\n",
      "\n",
      "Epoch 70. Loss: 0.009347957795501825, Train_acc 0.9962384259259259\n",
      "\n",
      "Epoch 70. Loss: 0.008849637376717696, Train_acc 0.9962729357798165\n",
      "\n",
      "Epoch 70. Loss: 0.00803878089716089, Train_acc 0.9963068181818182\n",
      "\n",
      "Epoch 70. Loss: 0.0074798646726910965, Train_acc 0.9963400900900901\n",
      "\n",
      "Epoch 70. Loss: 0.009994444980505529, Train_acc 0.9962332589285714\n",
      "\n",
      "Epoch 70. Loss: 0.011170829855755052, Train_acc 0.9961974557522124\n",
      "\n",
      "Epoch 70. Loss: 0.012480778528769387, Train_acc 0.99609375\n",
      "\n",
      "Epoch 70. Loss: 0.011262534634143851, Train_acc 0.9961277173913043\n",
      "\n",
      "Epoch 70. Loss: 0.010357993080127902, Train_acc 0.996161099137931\n",
      "\n",
      "Epoch 70. Loss: 0.011001629889525773, Train_acc 0.9961271367521367\n",
      "\n",
      "Epoch 70. Loss: 0.01362482042060894, Train_acc 0.9959613347457628\n",
      "\n",
      "Epoch 70. Loss: 0.013797208645462414, Train_acc 0.9959296218487395\n",
      "\n",
      "Epoch 70. Loss: 0.012468201275336224, Train_acc 0.9959635416666667\n",
      "\n",
      "Epoch 70. Loss: 0.011243768771705943, Train_acc 0.9959969008264463\n",
      "\n",
      "Epoch 70. Loss: 0.010523042232365535, Train_acc 0.9960297131147541\n",
      "\n",
      "Epoch 70. Loss: 0.009543063705366367, Train_acc 0.9960619918699187\n",
      "\n",
      "Epoch 70. Loss: 0.010308529591740532, Train_acc 0.9959677419354839\n",
      "\n",
      "Epoch 70. Loss: 0.010021180640844729, Train_acc 0.996\n",
      "\n",
      "Epoch 70. Loss: 0.009235346691627707, Train_acc 0.996031746031746\n",
      "\n",
      "Epoch 70. Loss: 0.009048944666745728, Train_acc 0.9960014763779528\n",
      "\n",
      "Epoch 70. Loss: 0.009804919843163312, Train_acc 0.9959716796875\n",
      "\n",
      "Epoch 70. Loss: 0.010070576299833853, Train_acc 0.9959423449612403\n",
      "\n",
      "Epoch 70. Loss: 0.012097423959917664, Train_acc 0.9959134615384615\n",
      "\n",
      "Epoch 70. Loss: 0.010956353204400247, Train_acc 0.9959446564885496\n",
      "\n",
      "Epoch 70. Loss: 0.010624734411642765, Train_acc 0.9959161931818182\n",
      "\n",
      "Epoch 70. Loss: 0.012937715217476322, Train_acc 0.995829417293233\n",
      "\n",
      "Epoch 70. Loss: 0.011932746639852436, Train_acc 0.9958605410447762\n",
      "\n",
      "Epoch 70. Loss: 0.010841522543378663, Train_acc 0.9958912037037037\n",
      "\n",
      "Epoch 70. Loss: 0.011218199293686143, Train_acc 0.9958639705882353\n",
      "\n",
      "Epoch 70. Loss: 0.010889997886901967, Train_acc 0.9958941605839416\n",
      "\n",
      "Epoch 70. Loss: 0.016049602231936938, Train_acc 0.9957540760869565\n",
      "\n",
      "Epoch 70. Loss: 0.014749530057883818, Train_acc 0.9957846223021583\n",
      "\n",
      "Epoch 70. Loss: 0.013448001387757712, Train_acc 0.9958147321428571\n",
      "\n",
      "Epoch 70. Loss: 0.012249602910895784, Train_acc 0.995844414893617\n",
      "\n",
      "Epoch 70. Loss: 0.012039972073900377, Train_acc 0.995818661971831\n",
      "\n",
      "Epoch 70. Loss: 0.012932443449259706, Train_acc 0.9957932692307693\n",
      "\n",
      "Epoch 70. Loss: 0.01283768012764535, Train_acc 0.9957682291666666\n",
      "\n",
      "Epoch 70. Loss: 0.011618467722849756, Train_acc 0.9957974137931035\n",
      "\n",
      "Epoch 70. Loss: 0.010475050936649593, Train_acc 0.995826198630137\n",
      "\n",
      "Epoch 70. Loss: 0.009925145999798494, Train_acc 0.9958545918367347\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70. Loss: 0.010081984971054779, Train_acc 0.9958298141891891\n",
      "\n",
      "Epoch 70. Loss: 0.011815707049448836, Train_acc 0.9957529362416108\n",
      "\n",
      "Epoch 70. Loss: 0.010745499194797468, Train_acc 0.99578125\n",
      "\n",
      "Epoch 70. Loss: 0.00993152040959441, Train_acc 0.9958091887417219\n",
      "\n",
      "Epoch 70. Loss: 0.009903694648036747, Train_acc 0.995836759868421\n",
      "\n",
      "Epoch 70. Loss: 0.009789117928733876, Train_acc 0.995812908496732\n",
      "\n",
      "Epoch 70. Loss: 0.010752737900367782, Train_acc 0.9957893668831169\n",
      "\n",
      "Epoch 70. Loss: 0.010001042546258634, Train_acc 0.9958165322580645\n",
      "\n",
      "Epoch 70. Loss: 0.00959039092899227, Train_acc 0.9958433493589743\n",
      "\n",
      "Epoch 70. Loss: 0.009111459799178217, Train_acc 0.9958698248407644\n",
      "\n",
      "Epoch 70. Loss: 0.008390390947614856, Train_acc 0.9958959651898734\n",
      "\n",
      "Epoch 70. Loss: 0.007641363364782703, Train_acc 0.9959217767295597\n",
      "\n",
      "Epoch 70. Loss: 0.007000621425391828, Train_acc 0.995947265625\n",
      "\n",
      "Epoch 70. Loss: 0.0071423860421314204, Train_acc 0.9959724378881988\n",
      "\n",
      "Epoch 70. Loss: 0.00666031833266029, Train_acc 0.9959972993827161\n",
      "\n",
      "Epoch 70. Loss: 0.00756110075808891, Train_acc 0.9959739263803681\n",
      "\n",
      "Epoch 70. Loss: 0.0068566084210708285, Train_acc 0.9959984756097561\n",
      "\n",
      "Epoch 70. Loss: 0.011230237138685692, Train_acc 0.9959280303030303\n",
      "\n",
      "Epoch 70. Loss: 0.0113020892984424, Train_acc 0.9959054969879518\n",
      "\n",
      "Epoch 70. Loss: 0.010687872283615526, Train_acc 0.9959300149700598\n",
      "\n",
      "Epoch 70. Loss: 0.011059658911488525, Train_acc 0.9958612351190477\n",
      "\n",
      "Epoch 70. Loss: 0.010061573899998878, Train_acc 0.995885724852071\n",
      "\n",
      "Epoch 70. Loss: 0.009094959820412129, Train_acc 0.9959099264705882\n",
      "\n",
      "Epoch 70. Loss: 0.008433276621716496, Train_acc 0.9959338450292398\n",
      "\n",
      "Epoch 70. Loss: 0.007851864225127347, Train_acc 0.9959574854651163\n",
      "\n",
      "Epoch 70. Loss: 0.008743133687786503, Train_acc 0.9959356936416185\n",
      "\n",
      "Epoch 70. Loss: 0.008076938597541074, Train_acc 0.9959590517241379\n",
      "\n",
      "Epoch 70. Loss: 0.007411014839404989, Train_acc 0.9959821428571428\n",
      "\n",
      "Epoch 70. Loss: 0.007010240137780459, Train_acc 0.9960049715909091\n",
      "\n",
      "Epoch 70. Loss: 0.007869244952682928, Train_acc 0.9959834039548022\n",
      "\n",
      "Epoch 70. Loss: 0.007295381893494077, Train_acc 0.9960059691011236\n",
      "\n",
      "Epoch 70. Loss: 0.006667454454570277, Train_acc 0.9960282821229051\n",
      "\n",
      "Epoch 70. Loss: 0.006084593012219754, Train_acc 0.9960503472222222\n",
      "\n",
      "Epoch 70. Loss: 0.0054988591547027645, Train_acc 0.9960721685082873\n",
      "\n",
      "Epoch 70. Loss: 0.008392142833043525, Train_acc 0.9959649725274725\n",
      "\n",
      "Epoch 70. Loss: 0.007596612016822783, Train_acc 0.9959870218579235\n",
      "\n",
      "Epoch 70. Loss: 0.007564269414960642, Train_acc 0.9960088315217391\n",
      "\n",
      "Epoch 70. Loss: 0.008945575910585491, Train_acc 0.9959881756756757\n",
      "\n",
      "Epoch 70. Loss: 0.008510877187798055, Train_acc 0.9960097446236559\n",
      "\n",
      "Epoch 70. Loss: 0.007904485301971107, Train_acc 0.9960310828877005\n",
      "\n",
      "Epoch 70. Loss: 0.007244715962398503, Train_acc 0.9960521941489362\n",
      "\n",
      "Epoch 70. Loss: 0.0066587959217325925, Train_acc 0.996073082010582\n",
      "\n",
      "Epoch 70. Loss: 0.0070769297059443065, Train_acc 0.9960526315789474\n",
      "\n",
      "Epoch 70. Loss: 0.008968829242235405, Train_acc 0.9959914921465969\n",
      "\n",
      "Epoch 70. Loss: 0.009254140744667634, Train_acc 0.9959716796875\n",
      "\n",
      "Epoch 70. Loss: 0.008401055032349126, Train_acc 0.9959925518134715\n",
      "\n",
      "Epoch 70. Loss: 0.0075977540119206875, Train_acc 0.9960132087628866\n",
      "\n",
      "Epoch 70. Loss: 0.0070328530282310515, Train_acc 0.9960336538461538\n",
      "\n",
      "Epoch 70. Loss: 0.0063576671070056595, Train_acc 0.99604\n",
      "\n",
      "Epoch 71. Loss: 0.006037314602429936, Train_acc 1.0\n",
      "\n",
      "Epoch 71. Loss: 0.007273223506237807, Train_acc 0.99609375\n",
      "\n",
      "Epoch 71. Loss: 0.006704473119743832, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 71. Loss: 0.006453236077816636, Train_acc 0.998046875\n",
      "\n",
      "Epoch 71. Loss: 0.008313475297026054, Train_acc 0.9953125\n",
      "\n",
      "Epoch 71. Loss: 0.007499381386767539, Train_acc 0.99609375\n",
      "\n",
      "Epoch 71. Loss: 0.008541755475280327, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 71. Loss: 0.011095513118217267, Train_acc 0.994140625\n",
      "\n",
      "Epoch 71. Loss: 0.010637135798478017, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 71. Loss: 0.010422818767795465, Train_acc 0.99453125\n",
      "\n",
      "Epoch 71. Loss: 0.009562749815135003, Train_acc 0.9950284090909091\n",
      "\n",
      "Epoch 71. Loss: 0.011441950859560492, Train_acc 0.994140625\n",
      "\n",
      "Epoch 71. Loss: 0.010356489259243538, Train_acc 0.9945913461538461\n",
      "\n",
      "Epoch 71. Loss: 0.010192093440062283, Train_acc 0.9944196428571429\n",
      "\n",
      "Epoch 71. Loss: 0.009179605979311577, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 71. Loss: 0.009060909953941208, Train_acc 0.9951171875\n",
      "\n",
      "Epoch 71. Loss: 0.008173121407281263, Train_acc 0.9954044117647058\n",
      "\n",
      "Epoch 71. Loss: 0.007403901943578262, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 71. Loss: 0.006950590931673889, Train_acc 0.9958881578947368\n",
      "\n",
      "Epoch 71. Loss: 0.006284764075063209, Train_acc 0.99609375\n",
      "\n",
      "Epoch 71. Loss: 0.007028858118905908, Train_acc 0.9959077380952381\n",
      "\n",
      "Epoch 71. Loss: 0.006542121170561868, Train_acc 0.99609375\n",
      "\n",
      "Epoch 71. Loss: 0.0067529355237794155, Train_acc 0.9959239130434783\n",
      "\n",
      "Epoch 71. Loss: 0.006089644635554007, Train_acc 0.99609375\n",
      "\n",
      "Epoch 71. Loss: 0.005592919140721128, Train_acc 0.99625\n",
      "\n",
      "Epoch 71. Loss: 0.005054759675104334, Train_acc 0.9963942307692307\n",
      "\n",
      "Epoch 71. Loss: 0.004606977272625415, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 71. Loss: 0.004167609798001892, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 71. Loss: 0.005150330580402297, Train_acc 0.9964978448275862\n",
      "\n",
      "Epoch 71. Loss: 0.004910526789206757, Train_acc 0.9966145833333333\n",
      "\n",
      "Epoch 71. Loss: 0.00444501922330759, Train_acc 0.9967237903225806\n",
      "\n",
      "Epoch 71. Loss: 0.004111609462364036, Train_acc 0.996826171875\n",
      "\n",
      "Epoch 71. Loss: 0.005527104008314179, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 71. Loss: 0.0059310710666631156, Train_acc 0.9963235294117647\n",
      "\n",
      "Epoch 71. Loss: 0.005591161510770425, Train_acc 0.9964285714285714\n",
      "\n",
      "Epoch 71. Loss: 0.005042911142371975, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 71. Loss: 0.004624289330050692, Train_acc 0.9966216216216216\n",
      "\n",
      "Epoch 71. Loss: 0.00566708741146804, Train_acc 0.9965049342105263\n",
      "\n",
      "Epoch 71. Loss: 0.005172389049838687, Train_acc 0.9965945512820513\n",
      "\n",
      "Epoch 71. Loss: 0.005583206850597893, Train_acc 0.996484375\n",
      "\n",
      "Epoch 71. Loss: 0.006519650515892775, Train_acc 0.9963795731707317\n",
      "\n",
      "Epoch 71. Loss: 0.009242770162503723, Train_acc 0.99609375\n",
      "\n",
      "Epoch 71. Loss: 0.009088161591244462, Train_acc 0.9960029069767442\n",
      "\n",
      "Epoch 71. Loss: 0.008196959888130068, Train_acc 0.99609375\n",
      "\n",
      "Epoch 71. Loss: 0.007517849870847588, Train_acc 0.9961805555555555\n",
      "\n",
      "Epoch 71. Loss: 0.007191826076799862, Train_acc 0.9962635869565217\n",
      "\n",
      "Epoch 71. Loss: 0.006495657016008126, Train_acc 0.996343085106383\n",
      "\n",
      "Epoch 71. Loss: 0.008299448109420265, Train_acc 0.9962565104166666\n",
      "\n",
      "Epoch 71. Loss: 0.007551659861190283, Train_acc 0.9963329081632653\n",
      "\n",
      "Epoch 71. Loss: 0.006941516585856525, Train_acc 0.99640625\n",
      "\n",
      "Epoch 71. Loss: 0.006263223725267643, Train_acc 0.9964767156862745\n",
      "\n",
      "Epoch 71. Loss: 0.007103813011385555, Train_acc 0.9963942307692307\n",
      "\n",
      "Epoch 71. Loss: 0.007343721321020325, Train_acc 0.996314858490566\n",
      "\n",
      "Epoch 71. Loss: 0.007531059583241165, Train_acc 0.9963831018518519\n",
      "\n",
      "Epoch 71. Loss: 0.010865213245345135, Train_acc 0.9961647727272728\n",
      "\n",
      "Epoch 71. Loss: 0.009996231994019132, Train_acc 0.9962332589285714\n",
      "\n",
      "Epoch 71. Loss: 0.009141984930678023, Train_acc 0.9962993421052632\n",
      "\n",
      "Epoch 71. Loss: 0.008991418189371062, Train_acc 0.9962284482758621\n",
      "\n",
      "Epoch 71. Loss: 0.008257421993465958, Train_acc 0.996292372881356\n",
      "\n",
      "Epoch 71. Loss: 0.007552957341560786, Train_acc 0.9963541666666667\n",
      "\n",
      "Epoch 71. Loss: 0.007120278033678888, Train_acc 0.9964139344262295\n",
      "\n",
      "Epoch 71. Loss: 0.0064885193164856666, Train_acc 0.9964717741935484\n",
      "\n",
      "Epoch 71. Loss: 0.006055892803099284, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 71. Loss: 0.005921352697455761, Train_acc 0.99658203125\n",
      "\n",
      "Epoch 71. Loss: 0.005425823122562954, Train_acc 0.9966346153846154\n",
      "\n",
      "Epoch 71. Loss: 0.005131356389904311, Train_acc 0.9966856060606061\n",
      "\n",
      "Epoch 71. Loss: 0.006319571447298787, Train_acc 0.9966184701492538\n",
      "\n",
      "Epoch 71. Loss: 0.005744816990754406, Train_acc 0.9966681985294118\n",
      "\n",
      "Epoch 71. Loss: 0.005302349253817409, Train_acc 0.9967164855072463\n",
      "\n",
      "Epoch 71. Loss: 0.004936955769873271, Train_acc 0.9967633928571429\n",
      "\n",
      "Epoch 71. Loss: 0.005140984434649298, Train_acc 0.9968089788732394\n",
      "\n",
      "Epoch 71. Loss: 0.004705903088780447, Train_acc 0.9968532986111112\n",
      "\n",
      "Epoch 71. Loss: 0.004276876757622619, Train_acc 0.996896404109589\n",
      "\n",
      "Epoch 71. Loss: 0.0039023832470901545, Train_acc 0.9969383445945946\n",
      "\n",
      "Epoch 71. Loss: 0.003549327853936574, Train_acc 0.9969791666666666\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71. Loss: 0.003429086378285546, Train_acc 0.9970189144736842\n",
      "\n",
      "Epoch 71. Loss: 0.0031345585512244038, Train_acc 0.9970576298701299\n",
      "\n",
      "Epoch 71. Loss: 0.0029068554328790307, Train_acc 0.9970953525641025\n",
      "\n",
      "Epoch 71. Loss: 0.003543704123369843, Train_acc 0.9970332278481012\n",
      "\n",
      "Epoch 71. Loss: 0.0036102558451044475, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 71. Loss: 0.003298305843822844, Train_acc 0.9971064814814815\n",
      "\n",
      "Epoch 71. Loss: 0.00704184364487471, Train_acc 0.997046493902439\n",
      "\n",
      "Epoch 71. Loss: 0.0066095294064036775, Train_acc 0.997082078313253\n",
      "\n",
      "Epoch 71. Loss: 0.006022942666478613, Train_acc 0.9971168154761905\n",
      "\n",
      "Epoch 71. Loss: 0.005452064430664249, Train_acc 0.9971507352941177\n",
      "\n",
      "Epoch 71. Loss: 0.0049544317491466705, Train_acc 0.9971838662790697\n",
      "\n",
      "Epoch 71. Loss: 0.004470525098339217, Train_acc 0.9972162356321839\n",
      "\n",
      "Epoch 71. Loss: 0.004419684918593315, Train_acc 0.9972478693181818\n",
      "\n",
      "Epoch 71. Loss: 0.004073373493874549, Train_acc 0.9972787921348315\n",
      "\n",
      "Epoch 71. Loss: 0.00374743050116254, Train_acc 0.9973090277777777\n",
      "\n",
      "Epoch 71. Loss: 0.003432234225765196, Train_acc 0.9973385989010989\n",
      "\n",
      "Epoch 71. Loss: 0.003264448728106464, Train_acc 0.9973675271739131\n",
      "\n",
      "Epoch 71. Loss: 0.004564855264969509, Train_acc 0.9973118279569892\n",
      "\n",
      "Epoch 71. Loss: 0.004358139183981277, Train_acc 0.9973404255319149\n",
      "\n",
      "Epoch 71. Loss: 0.004015447918780646, Train_acc 0.9973684210526316\n",
      "\n",
      "Epoch 71. Loss: 0.003649933561323845, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 71. Loss: 0.004199565656160203, Train_acc 0.9973421391752577\n",
      "\n",
      "Epoch 71. Loss: 0.003912348192080755, Train_acc 0.9973692602040817\n",
      "\n",
      "Epoch 71. Loss: 0.003524611648200409, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 71. Loss: 0.0048427492808805015, Train_acc 0.99734375\n",
      "\n",
      "[Epoch 71 Batch 100] Loss: 0.004370241631712612 Training: accuracy=0.997370\n",
      "Epoch 71. Loss: 0.004370241631712612, Train_acc 0.9973700495049505\n",
      "\n",
      "Epoch 71. Loss: 0.003967928349841622, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 71. Loss: 0.004345763764785815, Train_acc 0.9974211165048543\n",
      "\n",
      "Epoch 71. Loss: 0.0040865345674816565, Train_acc 0.9974459134615384\n",
      "\n",
      "Epoch 71. Loss: 0.004373849669745308, Train_acc 0.997470238095238\n",
      "\n",
      "Epoch 71. Loss: 0.007382248705313273, Train_acc 0.9973466981132075\n",
      "\n",
      "Epoch 71. Loss: 0.006864638227092327, Train_acc 0.9973714953271028\n",
      "\n",
      "Epoch 71. Loss: 0.0062533099997811184, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 71. Loss: 0.0057883335386236905, Train_acc 0.9974197247706422\n",
      "\n",
      "Epoch 71. Loss: 0.009149052789913452, Train_acc 0.997372159090909\n",
      "\n",
      "Epoch 71. Loss: 0.008355663395451907, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 71. Loss: 0.01003373016553587, Train_acc 0.9972795758928571\n",
      "\n",
      "Epoch 71. Loss: 0.00903960145831311, Train_acc 0.9973036504424779\n",
      "\n",
      "Epoch 71. Loss: 0.008151708607409578, Train_acc 0.997327302631579\n",
      "\n",
      "Epoch 71. Loss: 0.0075061550451934475, Train_acc 0.9973505434782609\n",
      "\n",
      "Epoch 71. Loss: 0.006768326128141521, Train_acc 0.9973733836206896\n",
      "\n",
      "Epoch 71. Loss: 0.007339489514037762, Train_acc 0.9973290598290598\n",
      "\n",
      "Epoch 71. Loss: 0.010275665272240157, Train_acc 0.9972854872881356\n",
      "\n",
      "Epoch 71. Loss: 0.01108447854873328, Train_acc 0.9972426470588235\n",
      "\n",
      "Epoch 71. Loss: 0.01057076332485785, Train_acc 0.997265625\n",
      "\n",
      "Epoch 71. Loss: 0.009862340357298641, Train_acc 0.9972882231404959\n",
      "\n",
      "Epoch 71. Loss: 0.00909320201421081, Train_acc 0.9973104508196722\n",
      "\n",
      "Epoch 71. Loss: 0.008799678538986732, Train_acc 0.9972688008130082\n",
      "\n",
      "Epoch 71. Loss: 0.009211155862136503, Train_acc 0.9972278225806451\n",
      "\n",
      "Epoch 71. Loss: 0.008777489435768563, Train_acc 0.99725\n",
      "\n",
      "Epoch 71. Loss: 0.007960600606363808, Train_acc 0.9972718253968254\n",
      "\n",
      "Epoch 71. Loss: 0.011420394884134943, Train_acc 0.9972317913385826\n",
      "\n",
      "Epoch 71. Loss: 0.011310483580755246, Train_acc 0.99725341796875\n",
      "\n",
      "Epoch 71. Loss: 0.010675460140490875, Train_acc 0.9972747093023255\n",
      "\n",
      "Epoch 71. Loss: 0.010357534595728825, Train_acc 0.997235576923077\n",
      "\n",
      "Epoch 71. Loss: 0.009442589168962906, Train_acc 0.997256679389313\n",
      "\n",
      "Epoch 71. Loss: 0.01022721475531197, Train_acc 0.9972182765151515\n",
      "\n",
      "Epoch 71. Loss: 0.013566423769320872, Train_acc 0.9971804511278195\n",
      "\n",
      "Epoch 71. Loss: 0.012402427888386691, Train_acc 0.9972014925373134\n",
      "\n",
      "Epoch 71. Loss: 0.011184374977475325, Train_acc 0.9972222222222222\n",
      "\n",
      "Epoch 71. Loss: 0.010920990044020938, Train_acc 0.9972426470588235\n",
      "\n",
      "Epoch 71. Loss: 0.010065327158921951, Train_acc 0.9972627737226277\n",
      "\n",
      "Epoch 71. Loss: 0.011615870584267968, Train_acc 0.9972259963768116\n",
      "\n",
      "Epoch 71. Loss: 0.01493557231654399, Train_acc 0.9971335431654677\n",
      "\n",
      "Epoch 71. Loss: 0.014567573923137844, Train_acc 0.9970982142857143\n",
      "\n",
      "Epoch 71. Loss: 0.013205914495919253, Train_acc 0.9971187943262412\n",
      "\n",
      "Epoch 71. Loss: 0.0163128816025264, Train_acc 0.9970290492957746\n",
      "\n",
      "Epoch 71. Loss: 0.015359802192015078, Train_acc 0.9970498251748252\n",
      "\n",
      "Epoch 71. Loss: 0.014617446176465715, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 71. Loss: 0.015179056849112835, Train_acc 0.9970366379310345\n",
      "\n",
      "Epoch 71. Loss: 0.0137249617141108, Train_acc 0.9970569349315068\n",
      "\n",
      "Epoch 71. Loss: 0.012560550107355739, Train_acc 0.9970769557823129\n",
      "\n",
      "Epoch 71. Loss: 0.011387146610714488, Train_acc 0.997096706081081\n",
      "\n",
      "Epoch 71. Loss: 0.011570326532004023, Train_acc 0.9970637583892618\n",
      "\n",
      "Epoch 71. Loss: 0.010480033350898544, Train_acc 0.9970833333333333\n",
      "\n",
      "Epoch 71. Loss: 0.009560679237541904, Train_acc 0.9971026490066225\n",
      "\n",
      "Epoch 71. Loss: 0.01070313364907862, Train_acc 0.9970189144736842\n",
      "\n",
      "Epoch 71. Loss: 0.010079745503319157, Train_acc 0.9970383986928104\n",
      "\n",
      "Epoch 71. Loss: 0.00912941064682858, Train_acc 0.9970576298701299\n",
      "\n",
      "Epoch 71. Loss: 0.008358881108903945, Train_acc 0.9970766129032258\n",
      "\n",
      "Epoch 71. Loss: 0.007905688997010047, Train_acc 0.9970953525641025\n",
      "\n",
      "Epoch 71. Loss: 0.012295546039253164, Train_acc 0.9970143312101911\n",
      "\n",
      "Epoch 71. Loss: 0.011110388790268731, Train_acc 0.9970332278481012\n",
      "\n",
      "Epoch 71. Loss: 0.010109730751729638, Train_acc 0.9970518867924528\n",
      "\n",
      "Epoch 71. Loss: 0.011885628536120026, Train_acc 0.997021484375\n",
      "\n",
      "Epoch 71. Loss: 0.01073934042233412, Train_acc 0.9970399844720497\n",
      "\n",
      "Epoch 71. Loss: 0.011640063371761305, Train_acc 0.9969618055555556\n",
      "\n",
      "Epoch 71. Loss: 0.011638641346845327, Train_acc 0.9968845858895705\n",
      "\n",
      "Epoch 71. Loss: 0.010647156673743543, Train_acc 0.9969035823170732\n",
      "\n",
      "Epoch 71. Loss: 0.009772381311795905, Train_acc 0.9969223484848485\n",
      "\n",
      "Epoch 71. Loss: 0.009135157620623823, Train_acc 0.9969408885542169\n",
      "\n",
      "Epoch 71. Loss: 0.008474381524591252, Train_acc 0.9969592065868264\n",
      "\n",
      "Epoch 71. Loss: 0.008695725805999581, Train_acc 0.9969308035714286\n",
      "\n",
      "Epoch 71. Loss: 0.009394713155128132, Train_acc 0.9969027366863905\n",
      "\n",
      "Epoch 71. Loss: 0.008577392152724479, Train_acc 0.996920955882353\n",
      "\n",
      "Epoch 71. Loss: 0.008028011071222555, Train_acc 0.9969389619883041\n",
      "\n",
      "Epoch 71. Loss: 0.008342308854345261, Train_acc 0.9969113372093024\n",
      "\n",
      "Epoch 71. Loss: 0.007826306678422193, Train_acc 0.996929190751445\n",
      "\n",
      "Epoch 71. Loss: 0.007213324263938874, Train_acc 0.9969468390804598\n",
      "\n",
      "Epoch 71. Loss: 0.008534055535717556, Train_acc 0.9969196428571429\n",
      "\n",
      "Epoch 71. Loss: 0.007903324762671068, Train_acc 0.9969371448863636\n",
      "\n",
      "Epoch 71. Loss: 0.00718189022662241, Train_acc 0.9969544491525424\n",
      "\n",
      "Epoch 71. Loss: 0.006490676333691168, Train_acc 0.996971558988764\n",
      "\n",
      "Epoch 71. Loss: 0.006089052307399054, Train_acc 0.9969884776536313\n",
      "\n",
      "Epoch 71. Loss: 0.006290099041424936, Train_acc 0.9969618055555556\n",
      "\n",
      "Epoch 71. Loss: 0.00639720272840209, Train_acc 0.996978591160221\n",
      "\n",
      "Epoch 71. Loss: 0.00691526831452084, Train_acc 0.9969522664835165\n",
      "\n",
      "Epoch 71. Loss: 0.008159567352509788, Train_acc 0.9969262295081968\n",
      "\n",
      "Epoch 71. Loss: 0.007446982149427049, Train_acc 0.9969429347826086\n",
      "\n",
      "Epoch 71. Loss: 0.006852420630659085, Train_acc 0.9969594594594594\n",
      "\n",
      "Epoch 71. Loss: 0.010910762440507493, Train_acc 0.9969338037634409\n",
      "\n",
      "Epoch 71. Loss: 0.011096458852003409, Train_acc 0.9969084224598931\n",
      "\n",
      "Epoch 71. Loss: 0.011208162522802108, Train_acc 0.9968833111702128\n",
      "\n",
      "Epoch 71. Loss: 0.010915746338506956, Train_acc 0.9968998015873016\n",
      "\n",
      "Epoch 71. Loss: 0.010931568448847906, Train_acc 0.996875\n",
      "\n",
      "Epoch 71. Loss: 0.009964488850349673, Train_acc 0.9968913612565445\n",
      "\n",
      "Epoch 71. Loss: 0.009318052409274418, Train_acc 0.9969075520833334\n",
      "\n",
      "Epoch 71. Loss: 0.008423418688290489, Train_acc 0.9969235751295337\n",
      "\n",
      "Epoch 71. Loss: 0.011441062066715812, Train_acc 0.9968991623711341\n",
      "\n",
      "Epoch 71. Loss: 0.010511356468136777, Train_acc 0.9969150641025641\n",
      "\n",
      "Epoch 71. Loss: 0.010084479171904031, Train_acc 0.99692\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72. Loss: 0.009184920803287271, Train_acc 1.0\n",
      "\n",
      "Epoch 72. Loss: 0.009234241354237775, Train_acc 0.99609375\n",
      "\n",
      "Epoch 72. Loss: 0.00850222743066023, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 72. Loss: 0.007812374884275677, Train_acc 0.998046875\n",
      "\n",
      "Epoch 72. Loss: 0.00990857080762513, Train_acc 0.996875\n",
      "\n",
      "Epoch 72. Loss: 0.0089312125898351, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 72. Loss: 0.008539515265326177, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 72. Loss: 0.007729953384129755, Train_acc 0.998046875\n",
      "\n",
      "Epoch 72. Loss: 0.007029856679960537, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 72. Loss: 0.006576553308963283, Train_acc 0.9984375\n",
      "\n",
      "Epoch 72. Loss: 0.006365470831319247, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 72. Loss: 0.007543030413738985, Train_acc 0.998046875\n",
      "\n",
      "Epoch 72. Loss: 0.007218026752995341, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 72. Loss: 0.006511515605657188, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 72. Loss: 0.006018178797401984, Train_acc 0.9984375\n",
      "\n",
      "Epoch 72. Loss: 0.010144920694802403, Train_acc 0.99755859375\n",
      "\n",
      "Epoch 72. Loss: 0.009465116715110123, Train_acc 0.9977022058823529\n",
      "\n",
      "Epoch 72. Loss: 0.00855882903439897, Train_acc 0.9978298611111112\n",
      "\n",
      "Epoch 72. Loss: 0.007996595281949022, Train_acc 0.9979440789473685\n",
      "\n",
      "Epoch 72. Loss: 0.007230323199482414, Train_acc 0.998046875\n",
      "\n",
      "Epoch 72. Loss: 0.006804352093757677, Train_acc 0.9981398809523809\n",
      "\n",
      "Epoch 72. Loss: 0.00628372487654968, Train_acc 0.9982244318181818\n",
      "\n",
      "Epoch 72. Loss: 0.005687688726502997, Train_acc 0.9983016304347826\n",
      "\n",
      "Epoch 72. Loss: 0.005188813238205024, Train_acc 0.9983723958333334\n",
      "\n",
      "Epoch 72. Loss: 0.004792419948342301, Train_acc 0.9984375\n",
      "\n",
      "Epoch 72. Loss: 0.005842629785683327, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 72. Loss: 0.0053761761092885494, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 72. Loss: 0.005120141387506797, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 72. Loss: 0.004743756535280027, Train_acc 0.9983836206896551\n",
      "\n",
      "Epoch 72. Loss: 0.004791523716713438, Train_acc 0.9984375\n",
      "\n",
      "Epoch 72. Loss: 0.0065403497533787335, Train_acc 0.9982358870967742\n",
      "\n",
      "Epoch 72. Loss: 0.005965161833597112, Train_acc 0.998291015625\n",
      "\n",
      "Epoch 72. Loss: 0.0066404866733547055, Train_acc 0.9981060606060606\n",
      "\n",
      "Epoch 72. Loss: 0.005993292198673372, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 72. Loss: 0.005810926386575834, Train_acc 0.9982142857142857\n",
      "\n",
      "Epoch 72. Loss: 0.0054275136466198585, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 72. Loss: 0.007429834979060896, Train_acc 0.9980996621621622\n",
      "\n",
      "Epoch 72. Loss: 0.00681975288893307, Train_acc 0.9981496710526315\n",
      "\n",
      "Epoch 72. Loss: 0.006393697476548178, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 72. Loss: 0.005776482484318069, Train_acc 0.9982421875\n",
      "\n",
      "Epoch 72. Loss: 0.005241576816876569, Train_acc 0.9982850609756098\n",
      "\n",
      "Epoch 72. Loss: 0.005045146450205004, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 72. Loss: 0.004757355574156364, Train_acc 0.9983648255813954\n",
      "\n",
      "Epoch 72. Loss: 0.004937347943382431, Train_acc 0.9984019886363636\n",
      "\n",
      "Epoch 72. Loss: 0.004450958156951322, Train_acc 0.9984375\n",
      "\n",
      "Epoch 72. Loss: 0.004336721158580232, Train_acc 0.9984714673913043\n",
      "\n",
      "Epoch 72. Loss: 0.005026299132307991, Train_acc 0.9985039893617021\n",
      "\n",
      "Epoch 72. Loss: 0.004706747632906399, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 72. Loss: 0.0042689901051280454, Train_acc 0.9985650510204082\n",
      "\n",
      "Epoch 72. Loss: 0.005180765595199844, Train_acc 0.9984375\n",
      "\n",
      "Epoch 72. Loss: 0.004667351352903706, Train_acc 0.9984681372549019\n",
      "\n",
      "Epoch 72. Loss: 0.004257918743578833, Train_acc 0.9984975961538461\n",
      "\n",
      "Epoch 72. Loss: 0.00390739517226509, Train_acc 0.9985259433962265\n",
      "\n",
      "Epoch 72. Loss: 0.0036291448934199673, Train_acc 0.9985532407407407\n",
      "\n",
      "Epoch 72. Loss: 0.0038891566839804287, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 72. Loss: 0.0035235470807049828, Train_acc 0.9986049107142857\n",
      "\n",
      "Epoch 72. Loss: 0.00318217952556204, Train_acc 0.9986293859649122\n",
      "\n",
      "Epoch 72. Loss: 0.0038547408052395987, Train_acc 0.9986530172413793\n",
      "\n",
      "Epoch 72. Loss: 0.0037827193326676976, Train_acc 0.9986758474576272\n",
      "\n",
      "Epoch 72. Loss: 0.003558169477940359, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 72. Loss: 0.003275552819771998, Train_acc 0.998719262295082\n",
      "\n",
      "Epoch 72. Loss: 0.002954029280099711, Train_acc 0.9987399193548387\n",
      "\n",
      "Epoch 72. Loss: 0.0026724307703574223, Train_acc 0.9987599206349206\n",
      "\n",
      "Epoch 72. Loss: 0.0024705416659261785, Train_acc 0.998779296875\n",
      "\n",
      "Epoch 72. Loss: 0.0023281670158501865, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 72. Loss: 0.0023067212834563615, Train_acc 0.9988162878787878\n",
      "\n",
      "Epoch 72. Loss: 0.0021699746141883073, Train_acc 0.9988339552238806\n",
      "\n",
      "Epoch 72. Loss: 0.0019761613528779935, Train_acc 0.9988511029411765\n",
      "\n",
      "Epoch 72. Loss: 0.004470719942824703, Train_acc 0.9987545289855072\n",
      "\n",
      "Epoch 72. Loss: 0.00435738206133395, Train_acc 0.9987723214285714\n",
      "\n",
      "Epoch 72. Loss: 0.005007547630147483, Train_acc 0.9986795774647887\n",
      "\n",
      "Epoch 72. Loss: 0.004612663067919474, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 72. Loss: 0.0041564351893351534, Train_acc 0.9987157534246576\n",
      "\n",
      "Epoch 72. Loss: 0.006581448830087727, Train_acc 0.9986275337837838\n",
      "\n",
      "Epoch 72. Loss: 0.006149263758438599, Train_acc 0.9986458333333333\n",
      "\n",
      "Epoch 72. Loss: 0.005621559490280842, Train_acc 0.9986636513157895\n",
      "\n",
      "Epoch 72. Loss: 0.005702998057693984, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 72. Loss: 0.0054945891099638456, Train_acc 0.9985977564102564\n",
      "\n",
      "Epoch 72. Loss: 0.009049184173119073, Train_acc 0.9984177215189873\n",
      "\n",
      "Epoch 72. Loss: 0.008156070239608992, Train_acc 0.9984375\n",
      "\n",
      "Epoch 72. Loss: 0.007367981318081626, Train_acc 0.9984567901234568\n",
      "\n",
      "Epoch 72. Loss: 0.0066378436437120195, Train_acc 0.9984756097560976\n",
      "\n",
      "Epoch 72. Loss: 0.006913397374826982, Train_acc 0.9984939759036144\n",
      "\n",
      "Epoch 72. Loss: 0.006355563846002502, Train_acc 0.9985119047619048\n",
      "\n",
      "Epoch 72. Loss: 0.006847074669692353, Train_acc 0.9985294117647059\n",
      "\n",
      "Epoch 72. Loss: 0.007380468771243187, Train_acc 0.9983648255813954\n",
      "\n",
      "Epoch 72. Loss: 0.008104702364996753, Train_acc 0.9982938218390804\n",
      "\n",
      "Epoch 72. Loss: 0.007467149207677557, Train_acc 0.9983132102272727\n",
      "\n",
      "Epoch 72. Loss: 0.006767531071602059, Train_acc 0.9983321629213483\n",
      "\n",
      "Epoch 72. Loss: 0.006433015937096255, Train_acc 0.9983506944444445\n",
      "\n",
      "Epoch 72. Loss: 0.006446069096687177, Train_acc 0.998282967032967\n",
      "\n",
      "Epoch 72. Loss: 0.006621725848462647, Train_acc 0.9982167119565217\n",
      "\n",
      "Epoch 72. Loss: 0.00614525488717538, Train_acc 0.9982358870967742\n",
      "\n",
      "Epoch 72. Loss: 0.007742527753441171, Train_acc 0.9981715425531915\n",
      "\n",
      "Epoch 72. Loss: 0.007611832986693356, Train_acc 0.9981907894736842\n",
      "\n",
      "Epoch 72. Loss: 0.006865617370387952, Train_acc 0.9982096354166666\n",
      "\n",
      "Epoch 72. Loss: 0.006220381305995211, Train_acc 0.9982280927835051\n",
      "\n",
      "Epoch 72. Loss: 0.006694128189727031, Train_acc 0.9982461734693877\n",
      "\n",
      "Epoch 72. Loss: 0.009579226441005792, Train_acc 0.9981060606060606\n",
      "\n",
      "Epoch 72. Loss: 0.008848442057284647, Train_acc 0.998125\n",
      "\n",
      "[Epoch 72 Batch 100] Loss: 0.008926401178103328 Training: accuracy=0.998144\n",
      "Epoch 72. Loss: 0.008926401178103328, Train_acc 0.9981435643564357\n",
      "\n",
      "Epoch 72. Loss: 0.012382078221495426, Train_acc 0.9980085784313726\n",
      "\n",
      "Epoch 72. Loss: 0.012968500451197155, Train_acc 0.9979520631067961\n",
      "\n",
      "Epoch 72. Loss: 0.013055407345399197, Train_acc 0.9978966346153846\n",
      "\n",
      "Epoch 72. Loss: 0.011999568582047464, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 72. Loss: 0.012868080279650786, Train_acc 0.9977889150943396\n",
      "\n",
      "Epoch 72. Loss: 0.01403393223114833, Train_acc 0.9977365654205608\n",
      "\n",
      "Epoch 72. Loss: 0.014138701551211101, Train_acc 0.9976851851851852\n",
      "\n",
      "Epoch 72. Loss: 0.013027799197780092, Train_acc 0.9977064220183486\n",
      "\n",
      "Epoch 72. Loss: 0.012586666164917052, Train_acc 0.9977272727272727\n",
      "\n",
      "Epoch 72. Loss: 0.011372257749221668, Train_acc 0.9977477477477478\n",
      "\n",
      "Epoch 72. Loss: 0.01393146468399341, Train_acc 0.9976283482142857\n",
      "\n",
      "Epoch 72. Loss: 0.012747719297841563, Train_acc 0.9976493362831859\n",
      "\n",
      "Epoch 72. Loss: 0.016137803936036265, Train_acc 0.9976014254385965\n",
      "\n",
      "Epoch 72. Loss: 0.015052291779099556, Train_acc 0.9976222826086957\n",
      "\n",
      "Epoch 72. Loss: 0.017743264611105907, Train_acc 0.9975080818965517\n",
      "\n",
      "Epoch 72. Loss: 0.016022468679835235, Train_acc 0.9975293803418803\n",
      "\n",
      "Epoch 72. Loss: 0.01683124105515167, Train_acc 0.9974179025423728\n",
      "\n",
      "Epoch 72. Loss: 0.015319941261474058, Train_acc 0.9974396008403361\n",
      "\n",
      "Epoch 72. Loss: 0.01485335631882885, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 72. Loss: 0.013694163193619897, Train_acc 0.9974173553719008\n",
      "\n",
      "Epoch 72. Loss: 0.015632780072376118, Train_acc 0.997374487704918\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72. Loss: 0.014836812867031979, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 72. Loss: 0.014094425280740697, Train_acc 0.9974168346774194\n",
      "\n",
      "Epoch 72. Loss: 0.013967476802185928, Train_acc 0.997375\n",
      "\n",
      "Epoch 72. Loss: 0.012725238365988364, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 72. Loss: 0.013356876735145238, Train_acc 0.9973548228346457\n",
      "\n",
      "Epoch 72. Loss: 0.012075622037224669, Train_acc 0.99737548828125\n",
      "\n",
      "Epoch 72. Loss: 0.011177562120338708, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 72. Loss: 0.010320595554140595, Train_acc 0.9974158653846154\n",
      "\n",
      "Epoch 72. Loss: 0.009422603096405316, Train_acc 0.9974355916030534\n",
      "\n",
      "Epoch 72. Loss: 0.015633735369896574, Train_acc 0.9973366477272727\n",
      "\n",
      "Epoch 72. Loss: 0.01716618666314097, Train_acc 0.9972391917293233\n",
      "\n",
      "Epoch 72. Loss: 0.016358260084804996, Train_acc 0.9972597947761194\n",
      "\n",
      "Epoch 72. Loss: 0.014872157567955945, Train_acc 0.9972800925925925\n",
      "\n",
      "Epoch 72. Loss: 0.016263635674909856, Train_acc 0.9972426470588235\n",
      "\n",
      "Epoch 72. Loss: 0.01585948574450264, Train_acc 0.9972057481751825\n",
      "\n",
      "Epoch 72. Loss: 0.014465311366043832, Train_acc 0.9972259963768116\n",
      "\n",
      "Epoch 72. Loss: 0.01306868894473971, Train_acc 0.99724595323741\n",
      "\n",
      "Epoch 72. Loss: 0.011883649685729393, Train_acc 0.997265625\n",
      "\n",
      "Epoch 72. Loss: 0.01325165994502501, Train_acc 0.9971742021276596\n",
      "\n",
      "Epoch 72. Loss: 0.02072086498919782, Train_acc 0.9970840669014085\n",
      "\n",
      "Epoch 72. Loss: 0.020767756767126833, Train_acc 0.9970498251748252\n",
      "\n",
      "Epoch 72. Loss: 0.018924639772969112, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 72. Loss: 0.018779528611836696, Train_acc 0.9970366379310345\n",
      "\n",
      "Epoch 72. Loss: 0.01867444959932971, Train_acc 0.9970034246575342\n",
      "\n",
      "Epoch 72. Loss: 0.017783114702889992, Train_acc 0.9969706632653061\n",
      "\n",
      "Epoch 72. Loss: 0.0180749286112693, Train_acc 0.9969383445945946\n",
      "\n",
      "Epoch 72. Loss: 0.016596404355168973, Train_acc 0.9969588926174496\n",
      "\n",
      "Epoch 72. Loss: 0.015673946482822866, Train_acc 0.9969270833333334\n",
      "\n",
      "Epoch 72. Loss: 0.01438326032103053, Train_acc 0.9969474337748344\n",
      "\n",
      "Epoch 72. Loss: 0.013297202303030652, Train_acc 0.9969675164473685\n",
      "\n",
      "Epoch 72. Loss: 0.012595207364724782, Train_acc 0.9969362745098039\n",
      "\n",
      "Epoch 72. Loss: 0.011527805949106849, Train_acc 0.9969561688311688\n",
      "\n",
      "Epoch 72. Loss: 0.010869851799552176, Train_acc 0.9969758064516129\n",
      "\n",
      "Epoch 72. Loss: 0.009988986140186668, Train_acc 0.9969951923076923\n",
      "\n",
      "Epoch 72. Loss: 0.01212627680810846, Train_acc 0.9969645700636943\n",
      "\n",
      "Epoch 72. Loss: 0.01139473623637161, Train_acc 0.9969837816455697\n",
      "\n",
      "Epoch 72. Loss: 0.011463322568122757, Train_acc 0.9969536163522013\n",
      "\n",
      "Epoch 72. Loss: 0.010656631267682503, Train_acc 0.99697265625\n",
      "\n",
      "Epoch 72. Loss: 0.01366582105453234, Train_acc 0.9968944099378882\n",
      "\n",
      "Epoch 72. Loss: 0.012419529865026513, Train_acc 0.9969135802469136\n",
      "\n",
      "Epoch 72. Loss: 0.012719064937388933, Train_acc 0.9968845858895705\n",
      "\n",
      "Epoch 72. Loss: 0.011992548952719005, Train_acc 0.9969035823170732\n",
      "\n",
      "Epoch 72. Loss: 0.011200258646357446, Train_acc 0.9969223484848485\n",
      "\n",
      "Epoch 72. Loss: 0.010218611181145957, Train_acc 0.9969408885542169\n",
      "\n",
      "Epoch 72. Loss: 0.009470677690162705, Train_acc 0.9969592065868264\n",
      "\n",
      "Epoch 72. Loss: 0.010851537495661777, Train_acc 0.9968843005952381\n",
      "\n",
      "Epoch 72. Loss: 0.010191498508133593, Train_acc 0.9969027366863905\n",
      "\n",
      "Epoch 72. Loss: 0.010357026548753472, Train_acc 0.996875\n",
      "\n",
      "Epoch 72. Loss: 0.01026586845508542, Train_acc 0.9968932748538012\n",
      "\n",
      "Epoch 72. Loss: 0.010301072977405725, Train_acc 0.9968659156976745\n",
      "\n",
      "Epoch 72. Loss: 0.009305328991380576, Train_acc 0.9968840317919075\n",
      "\n",
      "Epoch 72. Loss: 0.008713509241782645, Train_acc 0.9969019396551724\n",
      "\n",
      "Epoch 72. Loss: 0.009533419996538478, Train_acc 0.996875\n",
      "\n",
      "Epoch 72. Loss: 0.01163409221771841, Train_acc 0.9968483664772727\n",
      "\n",
      "Epoch 72. Loss: 0.010535883422562344, Train_acc 0.9968661723163842\n",
      "\n",
      "Epoch 72. Loss: 0.00966629622525918, Train_acc 0.9968837780898876\n",
      "\n",
      "Epoch 72. Loss: 0.009037557813535163, Train_acc 0.996901187150838\n",
      "\n",
      "Epoch 72. Loss: 0.008198721467135128, Train_acc 0.9969184027777778\n",
      "\n",
      "Epoch 72. Loss: 0.00749238680892686, Train_acc 0.9969354281767956\n",
      "\n",
      "Epoch 72. Loss: 0.006780865015925466, Train_acc 0.9969522664835165\n",
      "\n",
      "Epoch 72. Loss: 0.006584765374146252, Train_acc 0.9969689207650273\n",
      "\n",
      "Epoch 72. Loss: 0.006019607987350836, Train_acc 0.9969853940217391\n",
      "\n",
      "Epoch 72. Loss: 0.007340181408536388, Train_acc 0.9969594594594594\n",
      "\n",
      "Epoch 72. Loss: 0.009585025717209535, Train_acc 0.9969338037634409\n",
      "\n",
      "Epoch 72. Loss: 0.008893636727719686, Train_acc 0.9969502005347594\n",
      "\n",
      "Epoch 72. Loss: 0.009261651849200591, Train_acc 0.9969248670212766\n",
      "\n",
      "Epoch 72. Loss: 0.008392709701864287, Train_acc 0.9969411375661376\n",
      "\n",
      "Epoch 72. Loss: 0.009969635942228168, Train_acc 0.996875\n",
      "\n",
      "Epoch 72. Loss: 0.00910632555429044, Train_acc 0.9968913612565445\n",
      "\n",
      "Epoch 72. Loss: 0.008554364135061823, Train_acc 0.9969075520833334\n",
      "\n",
      "Epoch 72. Loss: 0.009881972609634807, Train_acc 0.9968830958549223\n",
      "\n",
      "Epoch 72. Loss: 0.008938352358647237, Train_acc 0.9968991623711341\n",
      "\n",
      "Epoch 72. Loss: 0.008405569930203007, Train_acc 0.9969150641025641\n",
      "\n",
      "Epoch 72. Loss: 0.007637179132787656, Train_acc 0.99692\n",
      "\n",
      "Epoch 73. Loss: 0.007923004950423484, Train_acc 0.9921875\n",
      "\n",
      "Epoch 73. Loss: 0.007291985450615983, Train_acc 0.99609375\n",
      "\n",
      "Epoch 73. Loss: 0.007496672479895205, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 73. Loss: 0.006766306342202195, Train_acc 0.99609375\n",
      "\n",
      "Epoch 73. Loss: 0.006287875424378606, Train_acc 0.996875\n",
      "\n",
      "Epoch 73. Loss: 0.006360605959344052, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 73. Loss: 0.0061494407058490606, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 73. Loss: 0.005543834198360933, Train_acc 0.998046875\n",
      "\n",
      "Epoch 73. Loss: 0.005030929633361735, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 73. Loss: 0.007999349762543415, Train_acc 0.99765625\n",
      "\n",
      "Epoch 73. Loss: 0.007227039635751955, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 73. Loss: 0.006522417185002789, Train_acc 0.998046875\n",
      "\n",
      "Epoch 73. Loss: 0.005968946393209003, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 73. Loss: 0.005654321609849307, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 73. Loss: 0.0051154611558495, Train_acc 0.9984375\n",
      "\n",
      "Epoch 73. Loss: 0.004629828436067041, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 73. Loss: 0.004399334766692223, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 73. Loss: 0.004713183653631481, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 73. Loss: 0.0045268980057793905, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 73. Loss: 0.0042822548417456195, Train_acc 0.998828125\n",
      "\n",
      "Epoch 73. Loss: 0.005404378671336822, Train_acc 0.9985119047619048\n",
      "\n",
      "Epoch 73. Loss: 0.004873399907078693, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 73. Loss: 0.0045345375894357415, Train_acc 0.998641304347826\n",
      "\n",
      "Epoch 73. Loss: 0.004102542447030606, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 73. Loss: 0.004691344377678689, Train_acc 0.99875\n",
      "\n",
      "Epoch 73. Loss: 0.004374271807904145, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 73. Loss: 0.0040312935767897375, Train_acc 0.9988425925925926\n",
      "\n",
      "Epoch 73. Loss: 0.0036463507865784014, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 73. Loss: 0.003411033398073236, Train_acc 0.9989224137931034\n",
      "\n",
      "Epoch 73. Loss: 0.0033827052454602604, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 73. Loss: 0.0042315251103447575, Train_acc 0.9987399193548387\n",
      "\n",
      "Epoch 73. Loss: 0.005824692120081786, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 73. Loss: 0.005261846286539956, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 73. Loss: 0.0049409380987149995, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 73. Loss: 0.004809185348215329, Train_acc 0.9986607142857142\n",
      "\n",
      "Epoch 73. Loss: 0.004406657293878609, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 73. Loss: 0.004197558193863286, Train_acc 0.9987331081081081\n",
      "\n",
      "Epoch 73. Loss: 0.004118427436130512, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 73. Loss: 0.0037613217798566235, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 73. Loss: 0.0034131136154278738, Train_acc 0.998828125\n",
      "\n",
      "Epoch 73. Loss: 0.0038316057576368414, Train_acc 0.9986661585365854\n",
      "\n",
      "Epoch 73. Loss: 0.0034859864252372603, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 73. Loss: 0.0031755707568080593, Train_acc 0.9987281976744186\n",
      "\n",
      "Epoch 73. Loss: 0.002875566733875807, Train_acc 0.9987571022727273\n",
      "\n",
      "Epoch 73. Loss: 0.002669696625442224, Train_acc 0.9987847222222223\n",
      "\n",
      "Epoch 73. Loss: 0.002420794044589699, Train_acc 0.9988111413043478\n",
      "\n",
      "Epoch 73. Loss: 0.002263499476639063, Train_acc 0.9988364361702128\n",
      "\n",
      "Epoch 73. Loss: 0.00208435022889406, Train_acc 0.9988606770833334\n",
      "\n",
      "Epoch 73. Loss: 0.0019382434163380162, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 73. Loss: 0.0018668221953262536, Train_acc 0.99890625\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73. Loss: 0.005313468503005772, Train_acc 0.9987745098039216\n",
      "\n",
      "Epoch 73. Loss: 0.0052550066038645525, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 73. Loss: 0.004877787363593479, Train_acc 0.9988207547169812\n",
      "\n",
      "Epoch 73. Loss: 0.00451887655843246, Train_acc 0.9988425925925926\n",
      "\n",
      "Epoch 73. Loss: 0.004131290533071291, Train_acc 0.9988636363636364\n",
      "\n",
      "Epoch 73. Loss: 0.003984333704419909, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 73. Loss: 0.004090867252356987, Train_acc 0.9989035087719298\n",
      "\n",
      "Epoch 73. Loss: 0.003763019277256814, Train_acc 0.9989224137931034\n",
      "\n",
      "Epoch 73. Loss: 0.003435434484163303, Train_acc 0.9989406779661016\n",
      "\n",
      "Epoch 73. Loss: 0.003822954111110609, Train_acc 0.998828125\n",
      "\n",
      "Epoch 73. Loss: 0.003775285345780648, Train_acc 0.9988473360655737\n",
      "\n",
      "Epoch 73. Loss: 0.004326871126861391, Train_acc 0.9987399193548387\n",
      "\n",
      "Epoch 73. Loss: 0.004127656408932224, Train_acc 0.9987599206349206\n",
      "\n",
      "Epoch 73. Loss: 0.0049656833421764515, Train_acc 0.9986572265625\n",
      "\n",
      "Epoch 73. Loss: 0.004494128213554121, Train_acc 0.9986778846153846\n",
      "\n",
      "Epoch 73. Loss: 0.004058132243487347, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 73. Loss: 0.003827530458047786, Train_acc 0.9987173507462687\n",
      "\n",
      "Epoch 73. Loss: 0.0038577281235678187, Train_acc 0.9987362132352942\n",
      "\n",
      "Epoch 73. Loss: 0.0035680630686285224, Train_acc 0.9987545289855072\n",
      "\n",
      "Epoch 73. Loss: 0.003638249442643117, Train_acc 0.9987723214285714\n",
      "\n",
      "Epoch 73. Loss: 0.003289141391580499, Train_acc 0.9987896126760564\n",
      "\n",
      "Epoch 73. Loss: 0.004770793588338968, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 73. Loss: 0.004321604232325712, Train_acc 0.9987157534246576\n",
      "\n",
      "Epoch 73. Loss: 0.003919148863569067, Train_acc 0.9987331081081081\n",
      "\n",
      "Epoch 73. Loss: 0.003564020339973792, Train_acc 0.99875\n",
      "\n",
      "Epoch 73. Loss: 0.0032160188181371463, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 73. Loss: 0.002951533919549001, Train_acc 0.9987824675324676\n",
      "\n",
      "Epoch 73. Loss: 0.00267666826356386, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 73. Loss: 0.00246859827051477, Train_acc 0.9988132911392406\n",
      "\n",
      "Epoch 73. Loss: 0.0022426711566957617, Train_acc 0.998828125\n",
      "\n",
      "Epoch 73. Loss: 0.0026016241280179724, Train_acc 0.9988425925925926\n",
      "\n",
      "Epoch 73. Loss: 0.0045263884336896095, Train_acc 0.9987614329268293\n",
      "\n",
      "Epoch 73. Loss: 0.004790247199712458, Train_acc 0.9986822289156626\n",
      "\n",
      "Epoch 73. Loss: 0.004565548257964786, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 73. Loss: 0.004157597783636692, Train_acc 0.9987132352941176\n",
      "\n",
      "Epoch 73. Loss: 0.0037962817783880765, Train_acc 0.9987281976744186\n",
      "\n",
      "Epoch 73. Loss: 0.0063566651838179115, Train_acc 0.9986530172413793\n",
      "\n",
      "Epoch 73. Loss: 0.005875890415280076, Train_acc 0.9986683238636364\n",
      "\n",
      "Epoch 73. Loss: 0.005441114306835693, Train_acc 0.9986832865168539\n",
      "\n",
      "Epoch 73. Loss: 0.006826495007027711, Train_acc 0.9986111111111111\n",
      "\n",
      "Epoch 73. Loss: 0.006180486186952837, Train_acc 0.9986263736263736\n",
      "\n",
      "Epoch 73. Loss: 0.006249197582180602, Train_acc 0.9985563858695652\n",
      "\n",
      "Epoch 73. Loss: 0.005982952778585526, Train_acc 0.9985719086021505\n",
      "\n",
      "Epoch 73. Loss: 0.01031259816740254, Train_acc 0.9985039893617021\n",
      "\n",
      "Epoch 73. Loss: 0.009335794207687747, Train_acc 0.9985197368421053\n",
      "\n",
      "Epoch 73. Loss: 0.008695163886012647, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 73. Loss: 0.0078517626409666, Train_acc 0.9985502577319587\n",
      "\n",
      "Epoch 73. Loss: 0.009290919961178564, Train_acc 0.9984853316326531\n",
      "\n",
      "Epoch 73. Loss: 0.00898411936236405, Train_acc 0.9985006313131313\n",
      "\n",
      "Epoch 73. Loss: 0.008251985770241025, Train_acc 0.998515625\n",
      "\n",
      "[Epoch 73 Batch 100] Loss: 0.007666806925371829 Training: accuracy=0.998530\n",
      "Epoch 73. Loss: 0.007666806925371829, Train_acc 0.9985303217821783\n",
      "\n",
      "Epoch 73. Loss: 0.0074450204401035995, Train_acc 0.9985447303921569\n",
      "\n",
      "Epoch 73. Loss: 0.007329585258259168, Train_acc 0.998558859223301\n",
      "\n",
      "Epoch 73. Loss: 0.006609635192952156, Train_acc 0.9985727163461539\n",
      "\n",
      "Epoch 73. Loss: 0.006403756396146059, Train_acc 0.9985863095238096\n",
      "\n",
      "Epoch 73. Loss: 0.0075228327567918064, Train_acc 0.9985259433962265\n",
      "\n",
      "Epoch 73. Loss: 0.007137861078914371, Train_acc 0.9985397196261683\n",
      "\n",
      "Epoch 73. Loss: 0.006515574363897473, Train_acc 0.9985532407407407\n",
      "\n",
      "Epoch 73. Loss: 0.007070051535693017, Train_acc 0.9984948394495413\n",
      "\n",
      "Epoch 73. Loss: 0.006660034301260597, Train_acc 0.9985085227272728\n",
      "\n",
      "Epoch 73. Loss: 0.006100677271079558, Train_acc 0.9985219594594594\n",
      "\n",
      "Epoch 73. Loss: 0.00590757150819141, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 73. Loss: 0.006028044592546568, Train_acc 0.9984789823008849\n",
      "\n",
      "Epoch 73. Loss: 0.00548033220587192, Train_acc 0.9984923245614035\n",
      "\n",
      "Epoch 73. Loss: 0.007095933061999245, Train_acc 0.9984375\n",
      "\n",
      "Epoch 73. Loss: 0.00655052766490325, Train_acc 0.9984509698275862\n",
      "\n",
      "Epoch 73. Loss: 0.007017557482019168, Train_acc 0.9983974358974359\n",
      "\n",
      "Epoch 73. Loss: 0.00632621933496911, Train_acc 0.9984110169491526\n",
      "\n",
      "Epoch 73. Loss: 0.0062703935978733185, Train_acc 0.9984243697478992\n",
      "\n",
      "Epoch 73. Loss: 0.009138442830257656, Train_acc 0.9983723958333334\n",
      "\n",
      "Epoch 73. Loss: 0.008234931961916174, Train_acc 0.998385847107438\n",
      "\n",
      "Epoch 73. Loss: 0.008634757603307622, Train_acc 0.9983350409836066\n",
      "\n",
      "Epoch 73. Loss: 0.007820540041100285, Train_acc 0.9983485772357723\n",
      "\n",
      "Epoch 73. Loss: 0.007301128991466435, Train_acc 0.9983618951612904\n",
      "\n",
      "Epoch 73. Loss: 0.007019859370310609, Train_acc 0.998375\n",
      "\n",
      "Epoch 73. Loss: 0.008999283187138591, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 73. Loss: 0.008147482679593985, Train_acc 0.9982775590551181\n",
      "\n",
      "Epoch 73. Loss: 0.007664985323377035, Train_acc 0.998291015625\n",
      "\n",
      "Epoch 73. Loss: 0.013033792553330287, Train_acc 0.9981831395348837\n",
      "\n",
      "Epoch 73. Loss: 0.011739607136920497, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 73. Loss: 0.010790940618344014, Train_acc 0.9982108778625954\n",
      "\n",
      "Epoch 73. Loss: 0.016271700557316422, Train_acc 0.9979876893939394\n",
      "\n",
      "Epoch 73. Loss: 0.015491992321233522, Train_acc 0.9979440789473685\n",
      "\n",
      "Epoch 73. Loss: 0.014344951075646793, Train_acc 0.9979594216417911\n",
      "\n",
      "Epoch 73. Loss: 0.014290627874285146, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 73. Loss: 0.013542165007308272, Train_acc 0.9979319852941176\n",
      "\n",
      "Epoch 73. Loss: 0.021552911084397268, Train_acc 0.9976619525547445\n",
      "\n",
      "Epoch 73. Loss: 0.01961356951319006, Train_acc 0.9976788949275363\n",
      "\n",
      "Epoch 73. Loss: 0.019052766369487287, Train_acc 0.9976393884892086\n",
      "\n",
      "Epoch 73. Loss: 0.024657679444586137, Train_acc 0.9974888392857143\n",
      "\n",
      "Epoch 73. Loss: 0.025279207278223248, Train_acc 0.9974512411347518\n",
      "\n",
      "Epoch 73. Loss: 0.024287191702960207, Train_acc 0.9974141725352113\n",
      "\n",
      "Epoch 73. Loss: 0.03234571308556641, Train_acc 0.9972137237762237\n",
      "\n",
      "Epoch 73. Loss: 0.03150232124176722, Train_acc 0.9971788194444444\n",
      "\n",
      "Epoch 73. Loss: 0.031172020438436577, Train_acc 0.9971443965517242\n",
      "\n",
      "Epoch 73. Loss: 0.028931346419266382, Train_acc 0.9971104452054794\n",
      "\n",
      "Epoch 73. Loss: 0.02701160563854413, Train_acc 0.9971301020408163\n",
      "\n",
      "Epoch 73. Loss: 0.02664949655230078, Train_acc 0.997043918918919\n",
      "\n",
      "Epoch 73. Loss: 0.032496190753834545, Train_acc 0.9968540268456376\n",
      "\n",
      "Epoch 73. Loss: 0.03309074306838849, Train_acc 0.99671875\n",
      "\n",
      "Epoch 73. Loss: 0.03085090633275931, Train_acc 0.9967404801324503\n",
      "\n",
      "Epoch 73. Loss: 0.036620382213975414, Train_acc 0.9967105263157895\n",
      "\n",
      "Epoch 73. Loss: 0.037581767509328214, Train_acc 0.9966299019607843\n",
      "\n",
      "Epoch 73. Loss: 0.03806988302166482, Train_acc 0.9965503246753247\n",
      "\n",
      "Epoch 73. Loss: 0.037125976450400534, Train_acc 0.9965221774193549\n",
      "\n",
      "Epoch 73. Loss: 0.03422006927846996, Train_acc 0.9965444711538461\n",
      "\n",
      "Epoch 73. Loss: 0.031199120631463483, Train_acc 0.9965664808917197\n",
      "\n",
      "Epoch 73. Loss: 0.028304026019406753, Train_acc 0.9965882120253164\n",
      "\n",
      "Epoch 73. Loss: 0.026539089132248558, Train_acc 0.9966096698113207\n",
      "\n",
      "Epoch 73. Loss: 0.026962088583915706, Train_acc 0.99658203125\n",
      "\n",
      "Epoch 73. Loss: 0.03404721650988693, Train_acc 0.9964576863354038\n",
      "\n",
      "Epoch 73. Loss: 0.03454015284935386, Train_acc 0.9963831018518519\n",
      "\n",
      "Epoch 73. Loss: 0.03481004056477324, Train_acc 0.9963094325153374\n",
      "\n",
      "Epoch 73. Loss: 0.04070098475048342, Train_acc 0.9961413871951219\n",
      "\n",
      "Epoch 73. Loss: 0.04251041099813043, Train_acc 0.9960700757575758\n",
      "\n",
      "Epoch 73. Loss: 0.03849607260870748, Train_acc 0.99609375\n",
      "\n",
      "Epoch 73. Loss: 0.03809277796907258, Train_acc 0.9960235778443114\n",
      "\n",
      "Epoch 73. Loss: 0.038988520584968024, Train_acc 0.9960007440476191\n",
      "\n",
      "Epoch 73. Loss: 0.035519743652240005, Train_acc 0.9960244082840237\n",
      "\n",
      "Epoch 73. Loss: 0.03478143932619295, Train_acc 0.9959099264705882\n",
      "\n",
      "Epoch 73. Loss: 0.031905334343301665, Train_acc 0.9959338450292398\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73. Loss: 0.03104622802119322, Train_acc 0.9958666424418605\n",
      "\n",
      "Epoch 73. Loss: 0.028728243478961593, Train_acc 0.9958905346820809\n",
      "\n",
      "Epoch 73. Loss: 0.026014819460059232, Train_acc 0.9959141522988506\n",
      "\n",
      "Epoch 73. Loss: 0.023754634292113806, Train_acc 0.9959375\n",
      "\n",
      "Epoch 73. Loss: 0.021796977722961925, Train_acc 0.9959605823863636\n",
      "\n",
      "Epoch 73. Loss: 0.020088613923775454, Train_acc 0.9959834039548022\n",
      "\n",
      "Epoch 73. Loss: 0.019682149272907346, Train_acc 0.9959620786516854\n",
      "\n",
      "Epoch 73. Loss: 0.019671792140676294, Train_acc 0.9959409916201117\n",
      "\n",
      "Epoch 73. Loss: 0.017981729146121783, Train_acc 0.9959635416666667\n",
      "\n",
      "Epoch 73. Loss: 0.017011279227982918, Train_acc 0.9959858425414365\n",
      "\n",
      "Epoch 73. Loss: 0.015652786743030812, Train_acc 0.9960078983516484\n",
      "\n",
      "Epoch 73. Loss: 0.014986204737173795, Train_acc 0.9960297131147541\n",
      "\n",
      "Epoch 73. Loss: 0.013884489264709306, Train_acc 0.9960512907608695\n",
      "\n",
      "Epoch 73. Loss: 0.012654199284089404, Train_acc 0.9960726351351351\n",
      "\n",
      "Epoch 73. Loss: 0.01167572915414524, Train_acc 0.99609375\n",
      "\n",
      "Epoch 73. Loss: 0.010782113924298153, Train_acc 0.9961146390374331\n",
      "\n",
      "Epoch 73. Loss: 0.009878649578417211, Train_acc 0.9961353058510638\n",
      "\n",
      "Epoch 73. Loss: 0.009998908634565654, Train_acc 0.996155753968254\n",
      "\n",
      "Epoch 73. Loss: 0.009882263704910025, Train_acc 0.9961759868421053\n",
      "\n",
      "Epoch 73. Loss: 0.010268624751067887, Train_acc 0.9961551047120419\n",
      "\n",
      "Epoch 73. Loss: 0.010272193404999432, Train_acc 0.9961344401041666\n",
      "\n",
      "Epoch 73. Loss: 0.009335409130294224, Train_acc 0.9961544689119171\n",
      "\n",
      "Epoch 73. Loss: 0.008631382328098208, Train_acc 0.9961742912371134\n",
      "\n",
      "Epoch 73. Loss: 0.008087544291421942, Train_acc 0.9961939102564102\n",
      "\n",
      "Epoch 73. Loss: 0.007417584434838002, Train_acc 0.9962\n",
      "\n",
      "Epoch 74. Loss: 0.006716172302643087, Train_acc 1.0\n",
      "\n",
      "Epoch 74. Loss: 0.006169567293193602, Train_acc 1.0\n",
      "\n",
      "Epoch 74. Loss: 0.00564785678388178, Train_acc 1.0\n",
      "\n",
      "Epoch 74. Loss: 0.005123925223326681, Train_acc 1.0\n",
      "\n",
      "Epoch 74. Loss: 0.004688859215286521, Train_acc 1.0\n",
      "\n",
      "Epoch 74. Loss: 0.004743333367324306, Train_acc 1.0\n",
      "\n",
      "Epoch 74. Loss: 0.004538267924919516, Train_acc 1.0\n",
      "\n",
      "Epoch 74. Loss: 0.004152313057848624, Train_acc 1.0\n",
      "\n",
      "Epoch 74. Loss: 0.007366154880167971, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 74. Loss: 0.006688585872024534, Train_acc 0.9984375\n",
      "\n",
      "Epoch 74. Loss: 0.0062712253115954145, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 74. Loss: 0.005774906523813201, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 74. Loss: 0.00521937194373721, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 74. Loss: 0.004974294645621009, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 74. Loss: 0.0046228211236300715, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 74. Loss: 0.004299159973655878, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 74. Loss: 0.003884515205785119, Train_acc 0.9990808823529411\n",
      "\n",
      "Epoch 74. Loss: 0.0035683784325829743, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 74. Loss: 0.003384208656131768, Train_acc 0.9991776315789473\n",
      "\n",
      "Epoch 74. Loss: 0.0035675412395115586, Train_acc 0.99921875\n",
      "\n",
      "Epoch 74. Loss: 0.0033034487757249978, Train_acc 0.9992559523809523\n",
      "\n",
      "Epoch 74. Loss: 0.0031007021572848534, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 74. Loss: 0.003749340522139702, Train_acc 0.9989809782608695\n",
      "\n",
      "Epoch 74. Loss: 0.0038536018765861694, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 74. Loss: 0.003499046876925892, Train_acc 0.9990625\n",
      "\n",
      "Epoch 74. Loss: 0.0031772149408261477, Train_acc 0.9990985576923077\n",
      "\n",
      "Epoch 74. Loss: 0.0029174814028408826, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 74. Loss: 0.0026817795682467552, Train_acc 0.9991629464285714\n",
      "\n",
      "Epoch 74. Loss: 0.002426799075126353, Train_acc 0.9991918103448276\n",
      "\n",
      "Epoch 74. Loss: 0.0021956642191432556, Train_acc 0.99921875\n",
      "\n",
      "Epoch 74. Loss: 0.0019843361239288686, Train_acc 0.9992439516129032\n",
      "\n",
      "Epoch 74. Loss: 0.003298015259413818, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 74. Loss: 0.0030550213211221096, Train_acc 0.9990530303030303\n",
      "\n",
      "Epoch 74. Loss: 0.0027679041514689934, Train_acc 0.9990808823529411\n",
      "\n",
      "Epoch 74. Loss: 0.003477683017989565, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 74. Loss: 0.0034901931521733724, Train_acc 0.9989149305555556\n",
      "\n",
      "Epoch 74. Loss: 0.0031808250469102075, Train_acc 0.9989442567567568\n",
      "\n",
      "Epoch 74. Loss: 0.0028974200443363067, Train_acc 0.9989720394736842\n",
      "\n",
      "Epoch 74. Loss: 0.0026466259470627126, Train_acc 0.9989983974358975\n",
      "\n",
      "Epoch 74. Loss: 0.0023903646736036614, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 74. Loss: 0.0021565928949048505, Train_acc 0.999047256097561\n",
      "\n",
      "Epoch 74. Loss: 0.0021317502271761346, Train_acc 0.9990699404761905\n",
      "\n",
      "Epoch 74. Loss: 0.002000782786185355, Train_acc 0.9990915697674418\n",
      "\n",
      "Epoch 74. Loss: 0.0019371160235626798, Train_acc 0.9991122159090909\n",
      "\n",
      "Epoch 74. Loss: 0.002221578865494427, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 74. Loss: 0.00205467372795218, Train_acc 0.9991508152173914\n",
      "\n",
      "Epoch 74. Loss: 0.0019015184182102122, Train_acc 0.9991688829787234\n",
      "\n",
      "Epoch 74. Loss: 0.001761586586260018, Train_acc 0.9991861979166666\n",
      "\n",
      "Epoch 74. Loss: 0.0018037573200075782, Train_acc 0.9992028061224489\n",
      "\n",
      "Epoch 74. Loss: 0.0018534442711197398, Train_acc 0.99921875\n",
      "\n",
      "Epoch 74. Loss: 0.001840122911724275, Train_acc 0.999234068627451\n",
      "\n",
      "Epoch 74. Loss: 0.0017173872687454455, Train_acc 0.9992487980769231\n",
      "\n",
      "Epoch 74. Loss: 0.0032332987381251546, Train_acc 0.9991155660377359\n",
      "\n",
      "Epoch 74. Loss: 0.0029620384400712903, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 74. Loss: 0.002752345080171, Train_acc 0.9991477272727273\n",
      "\n",
      "Epoch 74. Loss: 0.0025244182490224134, Train_acc 0.9991629464285714\n",
      "\n",
      "Epoch 74. Loss: 0.0028374738150460568, Train_acc 0.9990405701754386\n",
      "\n",
      "Epoch 74. Loss: 0.002700870697151695, Train_acc 0.9990571120689655\n",
      "\n",
      "Epoch 74. Loss: 0.002445267314555153, Train_acc 0.999073093220339\n",
      "\n",
      "Epoch 74. Loss: 0.0022160726818006753, Train_acc 0.9990885416666667\n",
      "\n",
      "Epoch 74. Loss: 0.0020203455088202895, Train_acc 0.9991034836065574\n",
      "\n",
      "Epoch 74. Loss: 0.0027268136149047086, Train_acc 0.998991935483871\n",
      "\n",
      "Epoch 74. Loss: 0.002457900167727595, Train_acc 0.9990079365079365\n",
      "\n",
      "Epoch 74. Loss: 0.002248779382440411, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 74. Loss: 0.0021052628087696104, Train_acc 0.9990384615384615\n",
      "\n",
      "Epoch 74. Loss: 0.0021912211137440803, Train_acc 0.9990530303030303\n",
      "\n",
      "Epoch 74. Loss: 0.0023634372557634416, Train_acc 0.9990671641791045\n",
      "\n",
      "Epoch 74. Loss: 0.002163677324467984, Train_acc 0.9990808823529411\n",
      "\n",
      "Epoch 74. Loss: 0.0019956109784352812, Train_acc 0.9990942028985508\n",
      "\n",
      "Epoch 74. Loss: 0.0018491800406776101, Train_acc 0.9991071428571429\n",
      "\n",
      "Epoch 74. Loss: 0.001670241690698, Train_acc 0.9991197183098591\n",
      "\n",
      "Epoch 74. Loss: 0.0020215867306495297, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 74. Loss: 0.0018348801819376094, Train_acc 0.9991438356164384\n",
      "\n",
      "Epoch 74. Loss: 0.001656620458429215, Train_acc 0.9991554054054054\n",
      "\n",
      "Epoch 74. Loss: 0.0014950648415552467, Train_acc 0.9991666666666666\n",
      "\n",
      "Epoch 74. Loss: 0.0014070386450950256, Train_acc 0.9991776315789473\n",
      "\n",
      "Epoch 74. Loss: 0.0018135978999552684, Train_acc 0.9991883116883117\n",
      "\n",
      "Epoch 74. Loss: 0.0016393396403144446, Train_acc 0.999198717948718\n",
      "\n",
      "Epoch 74. Loss: 0.0015088147257846427, Train_acc 0.9992088607594937\n",
      "\n",
      "Epoch 74. Loss: 0.0014023236115862205, Train_acc 0.99921875\n",
      "\n",
      "Epoch 74. Loss: 0.0013920895045516737, Train_acc 0.9992283950617284\n",
      "\n",
      "Epoch 74. Loss: 0.0012927316287855743, Train_acc 0.9992378048780488\n",
      "\n",
      "Epoch 74. Loss: 0.0011964351081580314, Train_acc 0.9992469879518072\n",
      "\n",
      "Epoch 74. Loss: 0.0010804477609501852, Train_acc 0.9992559523809523\n",
      "\n",
      "Epoch 74. Loss: 0.000977876056215196, Train_acc 0.9992647058823529\n",
      "\n",
      "Epoch 74. Loss: 0.0010070798715779445, Train_acc 0.9992732558139535\n",
      "\n",
      "Epoch 74. Loss: 0.0009216869719322855, Train_acc 0.9992816091954023\n",
      "\n",
      "Epoch 74. Loss: 0.0012100795426961484, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 74. Loss: 0.0010998974566568467, Train_acc 0.9992977528089888\n",
      "\n",
      "Epoch 74. Loss: 0.0010036616806791306, Train_acc 0.9993055555555556\n",
      "\n",
      "Epoch 74. Loss: 0.0010801658814979566, Train_acc 0.9993131868131868\n",
      "\n",
      "Epoch 74. Loss: 0.0013456440348550355, Train_acc 0.9993206521739131\n",
      "\n",
      "Epoch 74. Loss: 0.001275522555127711, Train_acc 0.9993279569892473\n",
      "\n",
      "Epoch 74. Loss: 0.0011515936610231848, Train_acc 0.9993351063829787\n",
      "\n",
      "Epoch 74. Loss: 0.0010438734464435697, Train_acc 0.9993421052631579\n",
      "\n",
      "Epoch 74. Loss: 0.0009444093828844245, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 74. Loss: 0.0009552925294664993, Train_acc 0.9993556701030928\n",
      "\n",
      "Epoch 74. Loss: 0.0009119947394250328, Train_acc 0.9993622448979592\n",
      "\n",
      "Epoch 74. Loss: 0.0025069061717854584, Train_acc 0.9992897727272727\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74. Loss: 0.002279580183912346, Train_acc 0.999296875\n",
      "\n",
      "[Epoch 74 Batch 100] Loss: 0.002083584513087262 Training: accuracy=0.999304\n",
      "Epoch 74. Loss: 0.002083584513087262, Train_acc 0.9993038366336634\n",
      "\n",
      "Epoch 74. Loss: 0.0018828256860016115, Train_acc 0.9993106617647058\n",
      "\n",
      "Epoch 74. Loss: 0.0017266091735570499, Train_acc 0.999317354368932\n",
      "\n",
      "Epoch 74. Loss: 0.0016373627213903251, Train_acc 0.9993239182692307\n",
      "\n",
      "Epoch 74. Loss: 0.004101826764190315, Train_acc 0.9992559523809523\n",
      "\n",
      "Epoch 74. Loss: 0.003699427039932789, Train_acc 0.9992629716981132\n",
      "\n",
      "Epoch 74. Loss: 0.003955455155904515, Train_acc 0.9991968457943925\n",
      "\n",
      "Epoch 74. Loss: 0.008250262095095596, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 74. Loss: 0.0075624931356119045, Train_acc 0.9991399082568807\n",
      "\n",
      "Epoch 74. Loss: 0.006815557800130886, Train_acc 0.9991477272727273\n",
      "\n",
      "Epoch 74. Loss: 0.006145340884105273, Train_acc 0.9991554054054054\n",
      "\n",
      "Epoch 74. Loss: 0.0055403460323294835, Train_acc 0.9991629464285714\n",
      "\n",
      "Epoch 74. Loss: 0.005041503525721059, Train_acc 0.9991703539823009\n",
      "\n",
      "Epoch 74. Loss: 0.005086695516732655, Train_acc 0.9991776315789473\n",
      "\n",
      "Epoch 74. Loss: 0.004630110843612096, Train_acc 0.9991847826086957\n",
      "\n",
      "Epoch 74. Loss: 0.004573774334311493, Train_acc 0.9991918103448276\n",
      "\n",
      "Epoch 74. Loss: 0.004240756590533264, Train_acc 0.999198717948718\n",
      "\n",
      "Epoch 74. Loss: 0.004441332020790584, Train_acc 0.9992055084745762\n",
      "\n",
      "Epoch 74. Loss: 0.004329243349371439, Train_acc 0.9992121848739496\n",
      "\n",
      "Epoch 74. Loss: 0.005559079987410979, Train_acc 0.9991536458333333\n",
      "\n",
      "Epoch 74. Loss: 0.005142878011707315, Train_acc 0.9991606404958677\n",
      "\n",
      "Epoch 74. Loss: 0.005068572699287994, Train_acc 0.9991675204918032\n",
      "\n",
      "Epoch 74. Loss: 0.004782446772501883, Train_acc 0.9991742886178862\n",
      "\n",
      "Epoch 74. Loss: 0.004370646640770301, Train_acc 0.9991809475806451\n",
      "\n",
      "Epoch 74. Loss: 0.0040388323706650716, Train_acc 0.9991875\n",
      "\n",
      "Epoch 74. Loss: 0.004366009228729962, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 74. Loss: 0.004112374262485288, Train_acc 0.999138779527559\n",
      "\n",
      "Epoch 74. Loss: 0.0037644609272614563, Train_acc 0.9991455078125\n",
      "\n",
      "Epoch 74. Loss: 0.004005074899804781, Train_acc 0.9991521317829457\n",
      "\n",
      "Epoch 74. Loss: 0.003679660228412321, Train_acc 0.9991586538461539\n",
      "\n",
      "Epoch 74. Loss: 0.0033642013632414233, Train_acc 0.9991650763358778\n",
      "\n",
      "Epoch 74. Loss: 0.00340782272374548, Train_acc 0.9991714015151515\n",
      "\n",
      "Epoch 74. Loss: 0.004608584017061449, Train_acc 0.9991188909774437\n",
      "\n",
      "Epoch 74. Loss: 0.004235657548003948, Train_acc 0.9991254664179104\n",
      "\n",
      "Epoch 74. Loss: 0.0039156403232270985, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 74. Loss: 0.0035723560269790076, Train_acc 0.9991383272058824\n",
      "\n",
      "Epoch 74. Loss: 0.003534183901499258, Train_acc 0.9991446167883211\n",
      "\n",
      "Epoch 74. Loss: 0.003404047793590021, Train_acc 0.9991508152173914\n",
      "\n",
      "Epoch 74. Loss: 0.005327005533674054, Train_acc 0.9991007194244604\n",
      "\n",
      "Epoch 74. Loss: 0.004903304878963851, Train_acc 0.9991071428571429\n",
      "\n",
      "Epoch 74. Loss: 0.004436356782440627, Train_acc 0.999113475177305\n",
      "\n",
      "Epoch 74. Loss: 0.004007732087239448, Train_acc 0.9991197183098591\n",
      "\n",
      "Epoch 74. Loss: 0.003804166945917747, Train_acc 0.9991258741258742\n",
      "\n",
      "Epoch 74. Loss: 0.0034400049952945746, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 74. Loss: 0.0036902564711822545, Train_acc 0.999084051724138\n",
      "\n",
      "Epoch 74. Loss: 0.0033690576579706124, Train_acc 0.9990903253424658\n",
      "\n",
      "Epoch 74. Loss: 0.0030570152945327386, Train_acc 0.9990965136054422\n",
      "\n",
      "Epoch 74. Loss: 0.0029194894926741085, Train_acc 0.9991026182432432\n",
      "\n",
      "Epoch 74. Loss: 0.0031398451195205177, Train_acc 0.9991086409395973\n",
      "\n",
      "Epoch 74. Loss: 0.0028331459555335464, Train_acc 0.9991145833333334\n",
      "\n",
      "Epoch 74. Loss: 0.004702861025331106, Train_acc 0.9990687086092715\n",
      "\n",
      "Epoch 74. Loss: 0.004966071124953943, Train_acc 0.9990748355263158\n",
      "\n",
      "Epoch 74. Loss: 0.004498199321482889, Train_acc 0.9990808823529411\n",
      "\n",
      "Epoch 74. Loss: 0.004069895304039251, Train_acc 0.9990868506493507\n",
      "\n",
      "Epoch 74. Loss: 0.0037031783911151118, Train_acc 0.9990927419354839\n",
      "\n",
      "Epoch 74. Loss: 0.00682627723388932, Train_acc 0.9990484775641025\n",
      "\n",
      "Epoch 74. Loss: 0.006201834191029327, Train_acc 0.9990545382165605\n",
      "\n",
      "Epoch 74. Loss: 0.005606273244045911, Train_acc 0.9990605221518988\n",
      "\n",
      "Epoch 74. Loss: 0.00657817502786762, Train_acc 0.99906643081761\n",
      "\n",
      "Epoch 74. Loss: 0.008065687574178396, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 74. Loss: 0.008992463051286714, Train_acc 0.9989809782608695\n",
      "\n",
      "Epoch 74. Loss: 0.008507104135162272, Train_acc 0.9989872685185185\n",
      "\n",
      "Epoch 74. Loss: 0.00990591473872063, Train_acc 0.9989455521472392\n",
      "\n",
      "Epoch 74. Loss: 0.008927457738066451, Train_acc 0.998951981707317\n",
      "\n",
      "Epoch 74. Loss: 0.010723746828566257, Train_acc 0.9989109848484848\n",
      "\n",
      "Epoch 74. Loss: 0.009763582522829113, Train_acc 0.9989175451807228\n",
      "\n",
      "Epoch 74. Loss: 0.010263532415175204, Train_acc 0.998877245508982\n",
      "\n",
      "Epoch 74. Loss: 0.0125009700791333, Train_acc 0.9987909226190477\n",
      "\n",
      "Epoch 74. Loss: 0.011306388103947242, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 74. Loss: 0.010283533921023639, Train_acc 0.9988051470588235\n",
      "\n",
      "Epoch 74. Loss: 0.012016228793722777, Train_acc 0.9987207602339181\n",
      "\n",
      "Epoch 74. Loss: 0.015542877726551045, Train_acc 0.9986373546511628\n",
      "\n",
      "Epoch 74. Loss: 0.015425611373301878, Train_acc 0.9986000722543352\n",
      "\n",
      "Epoch 74. Loss: 0.014003015643037738, Train_acc 0.9986081178160919\n",
      "\n",
      "Epoch 74. Loss: 0.012621673869493219, Train_acc 0.9986160714285715\n",
      "\n",
      "Epoch 74. Loss: 0.015817613164248418, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 74. Loss: 0.02209979363649698, Train_acc 0.9984110169491526\n",
      "\n",
      "Epoch 74. Loss: 0.020163371908802793, Train_acc 0.9984199438202247\n",
      "\n",
      "Epoch 74. Loss: 0.01819528213419341, Train_acc 0.9984287709497207\n",
      "\n",
      "Epoch 74. Loss: 0.01641751932319449, Train_acc 0.9984375\n",
      "\n",
      "Epoch 74. Loss: 0.015215099164543569, Train_acc 0.9984461325966851\n",
      "\n",
      "Epoch 74. Loss: 0.016158505432633776, Train_acc 0.9984117445054945\n",
      "\n",
      "Epoch 74. Loss: 0.022012164431358772, Train_acc 0.9982923497267759\n",
      "\n",
      "Epoch 74. Loss: 0.024244769875000773, Train_acc 0.9982591711956522\n",
      "\n",
      "Epoch 74. Loss: 0.02292734560113328, Train_acc 0.9982263513513514\n",
      "\n",
      "Epoch 74. Loss: 0.024092415065239466, Train_acc 0.9981938844086021\n",
      "\n",
      "Epoch 74. Loss: 0.02660650231600159, Train_acc 0.9980782085561497\n",
      "\n",
      "Epoch 74. Loss: 0.02524783554891068, Train_acc 0.998046875\n",
      "\n",
      "Epoch 74. Loss: 0.02278511143047871, Train_acc 0.998057208994709\n",
      "\n",
      "Epoch 74. Loss: 0.020812114930399615, Train_acc 0.9980674342105263\n",
      "\n",
      "Epoch 74. Loss: 0.019499800980089625, Train_acc 0.9980775523560209\n",
      "\n",
      "Epoch 74. Loss: 0.019135370370744337, Train_acc 0.9980061848958334\n",
      "\n",
      "Epoch 74. Loss: 0.018608457722066644, Train_acc 0.9979760362694301\n",
      "\n",
      "Epoch 74. Loss: 0.021598995293198947, Train_acc 0.9979059278350515\n",
      "\n",
      "Epoch 74. Loss: 0.020585189147310487, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 74. Loss: 0.018640241702717126, Train_acc 0.99792\n",
      "\n",
      "Epoch 75. Loss: 0.02220433616368912, Train_acc 0.9921875\n",
      "\n",
      "Epoch 75. Loss: 0.02040017211977192, Train_acc 0.99609375\n",
      "\n",
      "Epoch 75. Loss: 0.02395530587026669, Train_acc 0.9895833333333334\n",
      "\n",
      "Epoch 75. Loss: 0.02289213150521392, Train_acc 0.9921875\n",
      "\n",
      "Epoch 75. Loss: 0.02174132590544469, Train_acc 0.9921875\n",
      "\n",
      "Epoch 75. Loss: 0.022249887176325145, Train_acc 0.9921875\n",
      "\n",
      "Epoch 75. Loss: 0.021613195907744964, Train_acc 0.9921875\n",
      "\n",
      "Epoch 75. Loss: 0.019788658299302934, Train_acc 0.9931640625\n",
      "\n",
      "Epoch 75. Loss: 0.019616737078060994, Train_acc 0.9930555555555556\n",
      "\n",
      "Epoch 75. Loss: 0.019520020807174108, Train_acc 0.99296875\n",
      "\n",
      "Epoch 75. Loss: 0.017797740312676665, Train_acc 0.9936079545454546\n",
      "\n",
      "Epoch 75. Loss: 0.016736994387368295, Train_acc 0.994140625\n",
      "\n",
      "Epoch 75. Loss: 0.016355132957541884, Train_acc 0.9939903846153846\n",
      "\n",
      "Epoch 75. Loss: 0.01590385126344318, Train_acc 0.9938616071428571\n",
      "\n",
      "Epoch 75. Loss: 0.014378875243999778, Train_acc 0.9942708333333333\n",
      "\n",
      "Epoch 75. Loss: 0.013377365570892292, Train_acc 0.99462890625\n",
      "\n",
      "Epoch 75. Loss: 0.012419412324730513, Train_acc 0.9949448529411765\n",
      "\n",
      "Epoch 75. Loss: 0.01128698550007101, Train_acc 0.9952256944444444\n",
      "\n",
      "Epoch 75. Loss: 0.011042460946810448, Train_acc 0.9950657894736842\n",
      "\n",
      "Epoch 75. Loss: 0.01002368026425067, Train_acc 0.9953125\n",
      "\n",
      "Epoch 75. Loss: 0.00915290043420753, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 75. Loss: 0.008478572085876714, Train_acc 0.9957386363636364\n",
      "\n",
      "Epoch 75. Loss: 0.009033479272168384, Train_acc 0.9955842391304348\n",
      "\n",
      "Epoch 75. Loss: 0.008154398258484756, Train_acc 0.9957682291666666\n",
      "\n",
      "Epoch 75. Loss: 0.007898095169774313, Train_acc 0.9959375\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75. Loss: 0.007167509584545303, Train_acc 0.99609375\n",
      "\n",
      "Epoch 75. Loss: 0.007916916379111297, Train_acc 0.9959490740740741\n",
      "\n",
      "Epoch 75. Loss: 0.00718608065277915, Train_acc 0.99609375\n",
      "\n",
      "Epoch 75. Loss: 0.0076785521700732185, Train_acc 0.9959590517241379\n",
      "\n",
      "Epoch 75. Loss: 0.007004710276607627, Train_acc 0.99609375\n",
      "\n",
      "Epoch 75. Loss: 0.006430406659000177, Train_acc 0.9962197580645161\n",
      "\n",
      "Epoch 75. Loss: 0.0058572928061121484, Train_acc 0.996337890625\n",
      "\n",
      "Epoch 75. Loss: 0.0054634307140514655, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 75. Loss: 0.005020230034536607, Train_acc 0.9965533088235294\n",
      "\n",
      "Epoch 75. Loss: 0.00485146852095111, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 75. Loss: 0.004376797829097522, Train_acc 0.9967447916666666\n",
      "\n",
      "Epoch 75. Loss: 0.003964735432751451, Train_acc 0.9968327702702703\n",
      "\n",
      "Epoch 75. Loss: 0.003653882721872977, Train_acc 0.9969161184210527\n",
      "\n",
      "Epoch 75. Loss: 0.003321363416495153, Train_acc 0.9969951923076923\n",
      "\n",
      "Epoch 75. Loss: 0.003598520748033132, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 75. Loss: 0.0035117158978483134, Train_acc 0.997141768292683\n",
      "\n",
      "Epoch 75. Loss: 0.0032760203910739173, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 75. Loss: 0.002965338696172099, Train_acc 0.9972747093023255\n",
      "\n",
      "Epoch 75. Loss: 0.002948147326116497, Train_acc 0.9973366477272727\n",
      "\n",
      "Epoch 75. Loss: 0.0027658040785496544, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 75. Loss: 0.003215912323925356, Train_acc 0.9972826086956522\n",
      "\n",
      "Epoch 75. Loss: 0.002922853378056662, Train_acc 0.9973404255319149\n",
      "\n",
      "Epoch 75. Loss: 0.002831784240617612, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 75. Loss: 0.0027125640265882843, Train_acc 0.9974489795918368\n",
      "\n",
      "Epoch 75. Loss: 0.002469472256315053, Train_acc 0.9975\n",
      "\n",
      "Epoch 75. Loss: 0.0023154367043932977, Train_acc 0.9975490196078431\n",
      "\n",
      "Epoch 75. Loss: 0.0021141200103318575, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 75. Loss: 0.004028930485661854, Train_acc 0.9973466981132075\n",
      "\n",
      "Epoch 75. Loss: 0.0036881059772329292, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 75. Loss: 0.003351581836062902, Train_acc 0.9974431818181818\n",
      "\n",
      "Epoch 75. Loss: 0.003162009068341464, Train_acc 0.9974888392857143\n",
      "\n",
      "Epoch 75. Loss: 0.0029679005114277394, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 75. Loss: 0.0026892445040697776, Train_acc 0.9975754310344828\n",
      "\n",
      "Epoch 75. Loss: 0.002704753115851127, Train_acc 0.9976165254237288\n",
      "\n",
      "Epoch 75. Loss: 0.0027079695506722714, Train_acc 0.99765625\n",
      "\n",
      "Epoch 75. Loss: 0.002457996376110497, Train_acc 0.9976946721311475\n",
      "\n",
      "Epoch 75. Loss: 0.004754506015259072, Train_acc 0.9976058467741935\n",
      "\n",
      "Epoch 75. Loss: 0.004335066148721541, Train_acc 0.9976438492063492\n",
      "\n",
      "Epoch 75. Loss: 0.0044162006586045315, Train_acc 0.9976806640625\n",
      "\n",
      "Epoch 75. Loss: 0.004000037299970192, Train_acc 0.9977163461538462\n",
      "\n",
      "Epoch 75. Loss: 0.0036157517353507932, Train_acc 0.997750946969697\n",
      "\n",
      "Epoch 75. Loss: 0.0033818057524990786, Train_acc 0.9977845149253731\n",
      "\n",
      "Epoch 75. Loss: 0.003064435708235808, Train_acc 0.9978170955882353\n",
      "\n",
      "Epoch 75. Loss: 0.0027605737504923377, Train_acc 0.997848731884058\n",
      "\n",
      "Epoch 75. Loss: 0.002501859660878449, Train_acc 0.9978794642857143\n",
      "\n",
      "Epoch 75. Loss: 0.002302481258611458, Train_acc 0.9979093309859155\n",
      "\n",
      "Epoch 75. Loss: 0.005805394597083846, Train_acc 0.9977213541666666\n",
      "\n",
      "Epoch 75. Loss: 0.005247165668142306, Train_acc 0.9977525684931506\n",
      "\n",
      "Epoch 75. Loss: 0.004829954727838904, Train_acc 0.9977829391891891\n",
      "\n",
      "Epoch 75. Loss: 0.006928848437384192, Train_acc 0.9977083333333333\n",
      "\n",
      "Epoch 75. Loss: 0.006380967608130357, Train_acc 0.9977384868421053\n",
      "\n",
      "Epoch 75. Loss: 0.005898914200807854, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 75. Loss: 0.00609970167673699, Train_acc 0.9977964743589743\n",
      "\n",
      "Epoch 75. Loss: 0.005592250578395921, Train_acc 0.9978243670886076\n",
      "\n",
      "Epoch 75. Loss: 0.00814375914882934, Train_acc 0.99775390625\n",
      "\n",
      "Epoch 75. Loss: 0.007736328497913324, Train_acc 0.9977816358024691\n",
      "\n",
      "Epoch 75. Loss: 0.006973122507929913, Train_acc 0.9978086890243902\n",
      "\n",
      "Epoch 75. Loss: 0.007651163966000181, Train_acc 0.9977409638554217\n",
      "\n",
      "Epoch 75. Loss: 0.013584141877776474, Train_acc 0.9976748511904762\n",
      "\n",
      "Epoch 75. Loss: 0.015621506003277979, Train_acc 0.9975183823529412\n",
      "\n",
      "Epoch 75. Loss: 0.01417599012109263, Train_acc 0.997547238372093\n",
      "\n",
      "Epoch 75. Loss: 0.013124815179654567, Train_acc 0.9975754310344828\n",
      "\n",
      "Epoch 75. Loss: 0.011964435448496291, Train_acc 0.9976029829545454\n",
      "\n",
      "Epoch 75. Loss: 0.01082700120046623, Train_acc 0.9976299157303371\n",
      "\n",
      "Epoch 75. Loss: 0.01097891127289731, Train_acc 0.9974826388888889\n",
      "\n",
      "Epoch 75. Loss: 0.010154573194799411, Train_acc 0.9975103021978022\n",
      "\n",
      "Epoch 75. Loss: 0.009190132084500868, Train_acc 0.9975373641304348\n",
      "\n",
      "Epoch 75. Loss: 0.008568544353816283, Train_acc 0.9975638440860215\n",
      "\n",
      "Epoch 75. Loss: 0.009192347525751626, Train_acc 0.9975066489361702\n",
      "\n",
      "Epoch 75. Loss: 0.008413727906745109, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 75. Loss: 0.0076203752838125225, Train_acc 0.99755859375\n",
      "\n",
      "Epoch 75. Loss: 0.008666629056562519, Train_acc 0.9975032216494846\n",
      "\n",
      "Epoch 75. Loss: 0.008960232680674972, Train_acc 0.9975286989795918\n",
      "\n",
      "Epoch 75. Loss: 0.009214381430122182, Train_acc 0.9974747474747475\n",
      "\n",
      "Epoch 75. Loss: 0.011493802118515603, Train_acc 0.997421875\n",
      "\n",
      "[Epoch 75 Batch 100] Loss: 0.010477728730800568 Training: accuracy=0.997447\n",
      "Epoch 75. Loss: 0.010477728730800568, Train_acc 0.997447400990099\n",
      "\n",
      "Epoch 75. Loss: 0.01059176977994694, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 75. Loss: 0.009796143120729807, Train_acc 0.9974211165048543\n",
      "\n",
      "Epoch 75. Loss: 0.008942513027559712, Train_acc 0.9974459134615384\n",
      "\n",
      "Epoch 75. Loss: 0.0090422043804267, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 75. Loss: 0.011007256546968724, Train_acc 0.9972729952830188\n",
      "\n",
      "Epoch 75. Loss: 0.011138606490362739, Train_acc 0.9972254672897196\n",
      "\n",
      "Epoch 75. Loss: 0.01305117149353241, Train_acc 0.9971788194444444\n",
      "\n",
      "Epoch 75. Loss: 0.01183487339650473, Train_acc 0.9972047018348624\n",
      "\n",
      "Epoch 75. Loss: 0.010725120727731713, Train_acc 0.9972301136363636\n",
      "\n",
      "Epoch 75. Loss: 0.00974363135619403, Train_acc 0.9972550675675675\n",
      "\n",
      "Epoch 75. Loss: 0.009295524893612633, Train_acc 0.9972795758928571\n",
      "\n",
      "Epoch 75. Loss: 0.008607765793683502, Train_acc 0.9973036504424779\n",
      "\n",
      "Epoch 75. Loss: 0.008738217623426652, Train_acc 0.9972587719298246\n",
      "\n",
      "Epoch 75. Loss: 0.00794142847325501, Train_acc 0.9972826086956522\n",
      "\n",
      "Epoch 75. Loss: 0.007174916531899509, Train_acc 0.9973060344827587\n",
      "\n",
      "Epoch 75. Loss: 0.009573012373976949, Train_acc 0.9972622863247863\n",
      "\n",
      "Epoch 75. Loss: 0.008653446161977689, Train_acc 0.9972854872881356\n",
      "\n",
      "Epoch 75. Loss: 0.00987700592657826, Train_acc 0.9972426470588235\n",
      "\n",
      "Epoch 75. Loss: 0.009015125395578012, Train_acc 0.997265625\n",
      "\n",
      "Epoch 75. Loss: 0.008486516091276883, Train_acc 0.9972882231404959\n",
      "\n",
      "Epoch 75. Loss: 0.007758824634857189, Train_acc 0.9973104508196722\n",
      "\n",
      "Epoch 75. Loss: 0.007630916371918211, Train_acc 0.9973323170731707\n",
      "\n",
      "Epoch 75. Loss: 0.007154295553991041, Train_acc 0.9973538306451613\n",
      "\n",
      "Epoch 75. Loss: 0.0065860035916042396, Train_acc 0.997375\n",
      "\n",
      "Epoch 75. Loss: 0.00596155720612753, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 75. Loss: 0.005454103359998154, Train_acc 0.9974163385826772\n",
      "\n",
      "Epoch 75. Loss: 0.005687860447023112, Train_acc 0.99737548828125\n",
      "\n",
      "Epoch 75. Loss: 0.005217219235784977, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 75. Loss: 0.00492124536409572, Train_acc 0.9974158653846154\n",
      "\n",
      "Epoch 75. Loss: 0.0044564261520152115, Train_acc 0.9974355916030534\n",
      "\n",
      "Epoch 75. Loss: 0.004254037682421043, Train_acc 0.9974550189393939\n",
      "\n",
      "Epoch 75. Loss: 0.004159311426280768, Train_acc 0.9974741541353384\n",
      "\n",
      "Epoch 75. Loss: 0.0038547209917519968, Train_acc 0.9974930037313433\n",
      "\n",
      "Epoch 75. Loss: 0.00356348997105415, Train_acc 0.9975115740740741\n",
      "\n",
      "Epoch 75. Loss: 0.003499235281900364, Train_acc 0.9975298713235294\n",
      "\n",
      "Epoch 75. Loss: 0.0031709132424076704, Train_acc 0.9975479014598541\n",
      "\n",
      "Epoch 75. Loss: 0.002989386803734777, Train_acc 0.9975656702898551\n",
      "\n",
      "Epoch 75. Loss: 0.0027182253954050493, Train_acc 0.9975831834532374\n",
      "\n",
      "Epoch 75. Loss: 0.002456232208212423, Train_acc 0.9976004464285714\n",
      "\n",
      "Epoch 75. Loss: 0.002434298536993749, Train_acc 0.9976174645390071\n",
      "\n",
      "Epoch 75. Loss: 0.002618322182581741, Train_acc 0.9976342429577465\n",
      "\n",
      "Epoch 75. Loss: 0.0024733227747776375, Train_acc 0.9976507867132867\n",
      "\n",
      "Epoch 75. Loss: 0.005893254556485856, Train_acc 0.9976128472222222\n",
      "\n",
      "Epoch 75. Loss: 0.005346395978331278, Train_acc 0.9976293103448276\n",
      "\n",
      "Epoch 75. Loss: 0.004934212237260977, Train_acc 0.9976455479452054\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75. Loss: 0.004465698711924022, Train_acc 0.9976615646258503\n",
      "\n",
      "Epoch 75. Loss: 0.00402575439394631, Train_acc 0.9976773648648649\n",
      "\n",
      "Epoch 75. Loss: 0.003629117508210459, Train_acc 0.9976929530201343\n",
      "\n",
      "Epoch 75. Loss: 0.0033692469261573715, Train_acc 0.9977083333333333\n",
      "\n",
      "Epoch 75. Loss: 0.0033818819615978267, Train_acc 0.9977235099337748\n",
      "\n",
      "Epoch 75. Loss: 0.0032811836529512647, Train_acc 0.9977384868421053\n",
      "\n",
      "Epoch 75. Loss: 0.005092662301248859, Train_acc 0.9977022058823529\n",
      "\n",
      "Epoch 75. Loss: 0.005593104341554538, Train_acc 0.9976663961038961\n",
      "\n",
      "Epoch 75. Loss: 0.005055839503086899, Train_acc 0.9976814516129032\n",
      "\n",
      "Epoch 75. Loss: 0.004560485437134004, Train_acc 0.9976963141025641\n",
      "\n",
      "Epoch 75. Loss: 0.004213689192137059, Train_acc 0.9977109872611465\n",
      "\n",
      "Epoch 75. Loss: 0.0038236080984733064, Train_acc 0.9977254746835443\n",
      "\n",
      "Epoch 75. Loss: 0.00428021088291361, Train_acc 0.9976906446540881\n",
      "\n",
      "Epoch 75. Loss: 0.003914676318151763, Train_acc 0.997705078125\n",
      "\n",
      "Epoch 75. Loss: 0.0035736729471941395, Train_acc 0.9977193322981367\n",
      "\n",
      "Epoch 75. Loss: 0.0038788114188515787, Train_acc 0.9976851851851852\n",
      "\n",
      "Epoch 75. Loss: 0.003506030898351921, Train_acc 0.9976993865030674\n",
      "\n",
      "Epoch 75. Loss: 0.0038218268757845043, Train_acc 0.9976657774390244\n",
      "\n",
      "Epoch 75. Loss: 0.0039421228454963935, Train_acc 0.9976799242424242\n",
      "\n",
      "Epoch 75. Loss: 0.004399607570003561, Train_acc 0.9976468373493976\n",
      "\n",
      "Epoch 75. Loss: 0.003965062812843102, Train_acc 0.9976609281437125\n",
      "\n",
      "Epoch 75. Loss: 0.003580611176607712, Train_acc 0.9976748511904762\n",
      "\n",
      "Epoch 75. Loss: 0.003235426364792507, Train_acc 0.9976886094674556\n",
      "\n",
      "Epoch 75. Loss: 0.0039030800067959316, Train_acc 0.99765625\n",
      "\n",
      "Epoch 75. Loss: 0.0038930835632081115, Train_acc 0.9976699561403509\n",
      "\n",
      "Epoch 75. Loss: 0.003523327839762575, Train_acc 0.9976835029069767\n",
      "\n",
      "Epoch 75. Loss: 0.003241590226623213, Train_acc 0.9976968930635838\n",
      "\n",
      "Epoch 75. Loss: 0.003102585919979479, Train_acc 0.9977101293103449\n",
      "\n",
      "Epoch 75. Loss: 0.0028034301351657466, Train_acc 0.9977232142857143\n",
      "\n",
      "Epoch 75. Loss: 0.0025830931664542218, Train_acc 0.9977361505681818\n",
      "\n",
      "Epoch 75. Loss: 0.002377636400097462, Train_acc 0.9977489406779662\n",
      "\n",
      "Epoch 75. Loss: 0.0025011947895814653, Train_acc 0.9977615870786517\n",
      "\n",
      "Epoch 75. Loss: 0.0027157929818984574, Train_acc 0.997774092178771\n",
      "\n",
      "Epoch 75. Loss: 0.0030153275085529722, Train_acc 0.9977864583333333\n",
      "\n",
      "Epoch 75. Loss: 0.002784544271968249, Train_acc 0.9977986878453039\n",
      "\n",
      "Epoch 75. Loss: 0.0025099533455227464, Train_acc 0.997810782967033\n",
      "\n",
      "Epoch 75. Loss: 0.0023196831473976803, Train_acc 0.9978227459016393\n",
      "\n",
      "Epoch 75. Loss: 0.0022130254957917718, Train_acc 0.9978345788043478\n",
      "\n",
      "Epoch 75. Loss: 0.0020414225097456625, Train_acc 0.9978462837837838\n",
      "\n",
      "Epoch 75. Loss: 0.0019541911606230484, Train_acc 0.9978578629032258\n",
      "\n",
      "Epoch 75. Loss: 0.0017702583114459292, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 75. Loss: 0.0016045036029406366, Train_acc 0.9978806515957447\n",
      "\n",
      "Epoch 75. Loss: 0.0015951987707172018, Train_acc 0.9978918650793651\n",
      "\n",
      "Epoch 75. Loss: 0.0030277906674344105, Train_acc 0.9978618421052632\n",
      "\n",
      "Epoch 75. Loss: 0.00283018743064914, Train_acc 0.9978730366492147\n",
      "\n",
      "Epoch 75. Loss: 0.0025545638734054505, Train_acc 0.9978841145833334\n",
      "\n",
      "Epoch 75. Loss: 0.0023054022138560065, Train_acc 0.9978950777202072\n",
      "\n",
      "Epoch 75. Loss: 0.002088024407886852, Train_acc 0.9979059278350515\n",
      "\n",
      "Epoch 75. Loss: 0.001893408883912818, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 75. Loss: 0.0017147853864997794, Train_acc 0.99792\n",
      "\n",
      "Epoch 76. Loss: 0.0015947755808494392, Train_acc 1.0\n",
      "\n",
      "Epoch 76. Loss: 0.0015712868929344628, Train_acc 1.0\n",
      "\n",
      "Epoch 76. Loss: 0.0014245820628440182, Train_acc 1.0\n",
      "\n",
      "Epoch 76. Loss: 0.003622065492287499, Train_acc 0.998046875\n",
      "\n",
      "Epoch 76. Loss: 0.0032686422950088637, Train_acc 0.9984375\n",
      "\n",
      "Epoch 76. Loss: 0.0029489952268362766, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 76. Loss: 0.002684259240000909, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 76. Loss: 0.002499800625911622, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 76. Loss: 0.0027162901454907077, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 76. Loss: 0.0025105158349491437, Train_acc 0.99921875\n",
      "\n",
      "Epoch 76. Loss: 0.0025472000163227868, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 76. Loss: 0.0023062605299822366, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 76. Loss: 0.0021260933478121644, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 76. Loss: 0.0021293458895261306, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 76. Loss: 0.002307830113369991, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 76. Loss: 0.002360090747355315, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 76. Loss: 0.003775595621656382, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 76. Loss: 0.004350603685281578, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 76. Loss: 0.0040189681089313955, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 76. Loss: 0.00400523066808809, Train_acc 0.998828125\n",
      "\n",
      "Epoch 76. Loss: 0.0036221241861668233, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 76. Loss: 0.0033568332680671965, Train_acc 0.9989346590909091\n",
      "\n",
      "Epoch 76. Loss: 0.0031691402997882268, Train_acc 0.9989809782608695\n",
      "\n",
      "Epoch 76. Loss: 0.0035432061528841647, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 76. Loss: 0.003320172916786074, Train_acc 0.99875\n",
      "\n",
      "Epoch 76. Loss: 0.004551347038986861, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 76. Loss: 0.004518818300374669, Train_acc 0.9988425925925926\n",
      "\n",
      "Epoch 76. Loss: 0.004091617965024885, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 76. Loss: 0.0036869232550687525, Train_acc 0.9989224137931034\n",
      "\n",
      "Epoch 76. Loss: 0.0033325928142396597, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 76. Loss: 0.0030083552749686753, Train_acc 0.998991935483871\n",
      "\n",
      "Epoch 76. Loss: 0.002934660894951223, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 76. Loss: 0.003252837786404191, Train_acc 0.9988162878787878\n",
      "\n",
      "Epoch 76. Loss: 0.003531597117106228, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 76. Loss: 0.0032758220468082507, Train_acc 0.9986607142857142\n",
      "\n",
      "Epoch 76. Loss: 0.0029667739573520364, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 76. Loss: 0.002905695142528588, Train_acc 0.9987331081081081\n",
      "\n",
      "Epoch 76. Loss: 0.0026649527015107943, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 76. Loss: 0.00247341430595567, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 76. Loss: 0.002342694415288122, Train_acc 0.998828125\n",
      "\n",
      "Epoch 76. Loss: 0.002128133360148848, Train_acc 0.9988567073170732\n",
      "\n",
      "Epoch 76. Loss: 0.0019166128930442044, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 76. Loss: 0.0017380575373524623, Train_acc 0.9989098837209303\n",
      "\n",
      "Epoch 76. Loss: 0.0015685707171146318, Train_acc 0.9989346590909091\n",
      "\n",
      "Epoch 76. Loss: 0.001888561979477189, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 76. Loss: 0.0017128478257197877, Train_acc 0.9989809782608695\n",
      "\n",
      "Epoch 76. Loss: 0.0022337806073581047, Train_acc 0.9988364361702128\n",
      "\n",
      "Epoch 76. Loss: 0.004301943906940955, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 76. Loss: 0.003915123627075014, Train_acc 0.9987244897959183\n",
      "\n",
      "Epoch 76. Loss: 0.0038107359652118002, Train_acc 0.99875\n",
      "\n",
      "Epoch 76. Loss: 0.0034653326402995987, Train_acc 0.9987745098039216\n",
      "\n",
      "Epoch 76. Loss: 0.003550932026436389, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 76. Loss: 0.0033456374964390342, Train_acc 0.9988207547169812\n",
      "\n",
      "Epoch 76. Loss: 0.003023453724647237, Train_acc 0.9988425925925926\n",
      "\n",
      "Epoch 76. Loss: 0.002871873458264476, Train_acc 0.9988636363636364\n",
      "\n",
      "Epoch 76. Loss: 0.002802792965282386, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 76. Loss: 0.0025642781544039117, Train_acc 0.9989035087719298\n",
      "\n",
      "Epoch 76. Loss: 0.0037425075960137964, Train_acc 0.9987877155172413\n",
      "\n",
      "Epoch 76. Loss: 0.0037444302711914647, Train_acc 0.9988082627118644\n",
      "\n",
      "Epoch 76. Loss: 0.003465218795749307, Train_acc 0.998828125\n",
      "\n",
      "Epoch 76. Loss: 0.0031202156988391653, Train_acc 0.9988473360655737\n",
      "\n",
      "Epoch 76. Loss: 0.003213721966529731, Train_acc 0.9988659274193549\n",
      "\n",
      "Epoch 76. Loss: 0.003007989276715974, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 76. Loss: 0.0031995601051469386, Train_acc 0.9989013671875\n",
      "\n",
      "Epoch 76. Loss: 0.003496961438067532, Train_acc 0.9989182692307692\n",
      "\n",
      "Epoch 76. Loss: 0.00343870886384646, Train_acc 0.9989346590909091\n",
      "\n",
      "Epoch 76. Loss: 0.0031094325006979697, Train_acc 0.9989505597014925\n",
      "\n",
      "Epoch 76. Loss: 0.004084542442498624, Train_acc 0.9987362132352942\n",
      "\n",
      "Epoch 76. Loss: 0.0037152437030314456, Train_acc 0.9987545289855072\n",
      "\n",
      "Epoch 76. Loss: 0.0033541713171454605, Train_acc 0.9987723214285714\n",
      "\n",
      "Epoch 76. Loss: 0.0030374611119248197, Train_acc 0.9987896126760564\n",
      "\n",
      "Epoch 76. Loss: 0.002752980901214761, Train_acc 0.9988064236111112\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76. Loss: 0.003854244259071305, Train_acc 0.9987157534246576\n",
      "\n",
      "Epoch 76. Loss: 0.0034719056966641933, Train_acc 0.9987331081081081\n",
      "\n",
      "Epoch 76. Loss: 0.005580973736888712, Train_acc 0.9986458333333333\n",
      "\n",
      "Epoch 76. Loss: 0.005186369272832464, Train_acc 0.9986636513157895\n",
      "\n",
      "Epoch 76. Loss: 0.010152290242401711, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 76. Loss: 0.009191010767490076, Train_acc 0.9985977564102564\n",
      "\n",
      "Epoch 76. Loss: 0.015571064687613018, Train_acc 0.9984177215189873\n",
      "\n",
      "Epoch 76. Loss: 0.014785017687240274, Train_acc 0.99833984375\n",
      "\n",
      "Epoch 76. Loss: 0.013360389087752132, Train_acc 0.9983603395061729\n",
      "\n",
      "Epoch 76. Loss: 0.012232199933928814, Train_acc 0.9983803353658537\n",
      "\n",
      "Epoch 76. Loss: 0.011015769423986053, Train_acc 0.9983998493975904\n",
      "\n",
      "Epoch 76. Loss: 0.009931956336290381, Train_acc 0.9984188988095238\n",
      "\n",
      "Epoch 76. Loss: 0.008943933652411319, Train_acc 0.9984375\n",
      "\n",
      "Epoch 76. Loss: 0.008275070037047938, Train_acc 0.9984556686046512\n",
      "\n",
      "Epoch 76. Loss: 0.007466659900233467, Train_acc 0.9984734195402298\n",
      "\n",
      "Epoch 76. Loss: 0.006799898628069001, Train_acc 0.9984907670454546\n",
      "\n",
      "Epoch 76. Loss: 0.006202157994570318, Train_acc 0.9985077247191011\n",
      "\n",
      "Epoch 76. Loss: 0.006808003777678595, Train_acc 0.9984375\n",
      "\n",
      "Epoch 76. Loss: 0.006487698857336449, Train_acc 0.9984546703296703\n",
      "\n",
      "Epoch 76. Loss: 0.008141445037140734, Train_acc 0.9983865489130435\n",
      "\n",
      "Epoch 76. Loss: 0.008506325762493272, Train_acc 0.9983198924731183\n",
      "\n",
      "Epoch 76. Loss: 0.007712554049940729, Train_acc 0.9983377659574468\n",
      "\n",
      "Epoch 76. Loss: 0.009198290917979322, Train_acc 0.9982730263157895\n",
      "\n",
      "Epoch 76. Loss: 0.009103631229287364, Train_acc 0.9982096354166666\n",
      "\n",
      "Epoch 76. Loss: 0.008209978737093079, Train_acc 0.9982280927835051\n",
      "\n",
      "Epoch 76. Loss: 0.010955966068199636, Train_acc 0.9981664540816326\n",
      "\n",
      "Epoch 76. Loss: 0.009973028316884961, Train_acc 0.9981849747474747\n",
      "\n",
      "Epoch 76. Loss: 0.009031538570251444, Train_acc 0.998203125\n",
      "\n",
      "[Epoch 76 Batch 100] Loss: 0.013105237323933584 Training: accuracy=0.998066\n",
      "Epoch 76. Loss: 0.013105237323933584, Train_acc 0.9980662128712872\n",
      "\n",
      "Epoch 76. Loss: 0.011941363765241571, Train_acc 0.9980851715686274\n",
      "\n",
      "Epoch 76. Loss: 0.010827672506500215, Train_acc 0.9981037621359223\n",
      "\n",
      "Epoch 76. Loss: 0.010011265887062786, Train_acc 0.9981219951923077\n",
      "\n",
      "Epoch 76. Loss: 0.012585772019542193, Train_acc 0.9980654761904761\n",
      "\n",
      "Epoch 76. Loss: 0.01188594403140271, Train_acc 0.9980837264150944\n",
      "\n",
      "Epoch 76. Loss: 0.012646924426608004, Train_acc 0.9980286214953271\n",
      "\n",
      "Epoch 76. Loss: 0.01144986830803995, Train_acc 0.998046875\n",
      "\n",
      "Epoch 76. Loss: 0.010670422235011263, Train_acc 0.9980647935779816\n",
      "\n",
      "Epoch 76. Loss: 0.0124867003132813, Train_acc 0.9980113636363637\n",
      "\n",
      "Epoch 76. Loss: 0.011372282666258171, Train_acc 0.9980292792792793\n",
      "\n",
      "Epoch 76. Loss: 0.012371763940714736, Train_acc 0.9979771205357143\n",
      "\n",
      "Epoch 76. Loss: 0.012124699858781344, Train_acc 0.9979950221238938\n",
      "\n",
      "Epoch 76. Loss: 0.012378786697646959, Train_acc 0.9979440789473685\n",
      "\n",
      "Epoch 76. Loss: 0.011241747247403993, Train_acc 0.9979619565217391\n",
      "\n",
      "Epoch 76. Loss: 0.013205678551399232, Train_acc 0.9978448275862069\n",
      "\n",
      "Epoch 76. Loss: 0.012755546567443182, Train_acc 0.9977964743589743\n",
      "\n",
      "Epoch 76. Loss: 0.013483133217039558, Train_acc 0.9977489406779662\n",
      "\n",
      "Epoch 76. Loss: 0.012758078284868168, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 76. Loss: 0.01182657286850384, Train_acc 0.9977864583333333\n",
      "\n",
      "Epoch 76. Loss: 0.01587675226027761, Train_acc 0.9977401859504132\n",
      "\n",
      "Epoch 76. Loss: 0.0173856195416599, Train_acc 0.9976946721311475\n",
      "\n",
      "Epoch 76. Loss: 0.016388849312652602, Train_acc 0.9977134146341463\n",
      "\n",
      "Epoch 76. Loss: 0.016190844456484426, Train_acc 0.9976688508064516\n",
      "\n",
      "Epoch 76. Loss: 0.014722381460410813, Train_acc 0.9976875\n",
      "\n",
      "Epoch 76. Loss: 0.013963878108777816, Train_acc 0.9977058531746031\n",
      "\n",
      "Epoch 76. Loss: 0.015006602514134243, Train_acc 0.9976624015748031\n",
      "\n",
      "Epoch 76. Loss: 0.014780992902827021, Train_acc 0.99761962890625\n",
      "\n",
      "Epoch 76. Loss: 0.013378002577937474, Train_acc 0.9976380813953488\n",
      "\n",
      "Epoch 76. Loss: 0.01232787517417237, Train_acc 0.99765625\n",
      "\n",
      "Epoch 76. Loss: 0.014065339097757024, Train_acc 0.9976145038167938\n",
      "\n",
      "Epoch 76. Loss: 0.013369293717857196, Train_acc 0.9975733901515151\n",
      "\n",
      "Epoch 76. Loss: 0.013741688840075726, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 76. Loss: 0.012767249053330178, Train_acc 0.9975513059701493\n",
      "\n",
      "Epoch 76. Loss: 0.012827460428128502, Train_acc 0.9974537037037037\n",
      "\n",
      "Epoch 76. Loss: 0.01280456947316217, Train_acc 0.9974149816176471\n",
      "\n",
      "Epoch 76. Loss: 0.014718704301382491, Train_acc 0.997319799270073\n",
      "\n",
      "Epoch 76. Loss: 0.014550953417210629, Train_acc 0.9972826086956522\n",
      "\n",
      "Epoch 76. Loss: 0.013155868136623219, Train_acc 0.9973021582733813\n",
      "\n",
      "Epoch 76. Loss: 0.017010388210778278, Train_acc 0.9971540178571429\n",
      "\n",
      "Epoch 76. Loss: 0.016963455954520264, Train_acc 0.9971187943262412\n",
      "\n",
      "Epoch 76. Loss: 0.015435257576550565, Train_acc 0.9971390845070423\n",
      "\n",
      "Epoch 76. Loss: 0.013945414742212465, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 76. Loss: 0.012563690517799214, Train_acc 0.9971788194444444\n",
      "\n",
      "Epoch 76. Loss: 0.0122622190746273, Train_acc 0.997198275862069\n",
      "\n",
      "Epoch 76. Loss: 0.011266341784903891, Train_acc 0.9972174657534246\n",
      "\n",
      "Epoch 76. Loss: 0.01211013136444344, Train_acc 0.9971832482993197\n",
      "\n",
      "Epoch 76. Loss: 0.013694800330440885, Train_acc 0.9971494932432432\n",
      "\n",
      "Epoch 76. Loss: 0.012818017506516594, Train_acc 0.9971686241610739\n",
      "\n",
      "Epoch 76. Loss: 0.011551661749496081, Train_acc 0.9971875\n",
      "\n",
      "Epoch 76. Loss: 0.012098915242982525, Train_acc 0.9971543874172185\n",
      "\n",
      "Epoch 76. Loss: 0.01116418444018747, Train_acc 0.9971731085526315\n",
      "\n",
      "Epoch 76. Loss: 0.010263926384832135, Train_acc 0.9971915849673203\n",
      "\n",
      "Epoch 76. Loss: 0.015875365523683134, Train_acc 0.9970576298701299\n",
      "\n",
      "Epoch 76. Loss: 0.015138872936982307, Train_acc 0.9970262096774194\n",
      "\n",
      "Epoch 76. Loss: 0.013733247096271866, Train_acc 0.9970452724358975\n",
      "\n",
      "Epoch 76. Loss: 0.012419050322318721, Train_acc 0.9970640923566879\n",
      "\n",
      "Epoch 76. Loss: 0.011499648979763372, Train_acc 0.9970826740506329\n",
      "\n",
      "Epoch 76. Loss: 0.01302085655164139, Train_acc 0.9970518867924528\n",
      "\n",
      "Epoch 76. Loss: 0.01566040929166749, Train_acc 0.997021484375\n",
      "\n",
      "Epoch 76. Loss: 0.014320063026323392, Train_acc 0.9970399844720497\n",
      "\n",
      "Epoch 76. Loss: 0.013899008868552274, Train_acc 0.9970582561728395\n",
      "\n",
      "Epoch 76. Loss: 0.01445624345995518, Train_acc 0.9970283742331288\n",
      "\n",
      "Epoch 76. Loss: 0.0135591321613568, Train_acc 0.997046493902439\n",
      "\n",
      "Epoch 76. Loss: 0.012674185465009027, Train_acc 0.997064393939394\n",
      "\n",
      "Epoch 76. Loss: 0.01709893822392614, Train_acc 0.9969879518072289\n",
      "\n",
      "Epoch 76. Loss: 0.015939456695057076, Train_acc 0.9970059880239521\n",
      "\n",
      "Epoch 76. Loss: 0.015638191788259554, Train_acc 0.9969773065476191\n",
      "\n",
      "Epoch 76. Loss: 0.015695480552789635, Train_acc 0.9969489644970414\n",
      "\n",
      "Epoch 76. Loss: 0.015134083037802936, Train_acc 0.996920955882353\n",
      "\n",
      "Epoch 76. Loss: 0.013833695727419283, Train_acc 0.9969389619883041\n",
      "\n",
      "Epoch 76. Loss: 0.01423091731473633, Train_acc 0.9969113372093024\n",
      "\n",
      "Epoch 76. Loss: 0.015373200367434278, Train_acc 0.9968840317919075\n",
      "\n",
      "Epoch 76. Loss: 0.014904499783107747, Train_acc 0.9969019396551724\n",
      "\n",
      "Epoch 76. Loss: 0.013776804674071767, Train_acc 0.9969196428571429\n",
      "\n",
      "Epoch 76. Loss: 0.013042177624689965, Train_acc 0.9969371448863636\n",
      "\n",
      "Epoch 76. Loss: 0.012345546700525966, Train_acc 0.9969544491525424\n",
      "\n",
      "Epoch 76. Loss: 0.011378624452510793, Train_acc 0.996971558988764\n",
      "\n",
      "Epoch 76. Loss: 0.011497680914425242, Train_acc 0.9969448324022346\n",
      "\n",
      "Epoch 76. Loss: 0.011816843682101418, Train_acc 0.996875\n",
      "\n",
      "Epoch 76. Loss: 0.011786299720619066, Train_acc 0.9968491022099447\n",
      "\n",
      "Epoch 76. Loss: 0.01079699800042937, Train_acc 0.9968664148351648\n",
      "\n",
      "Epoch 76. Loss: 0.009771974518927603, Train_acc 0.9968835382513661\n",
      "\n",
      "Epoch 76. Loss: 0.009135061264626088, Train_acc 0.9969004755434783\n",
      "\n",
      "Epoch 76. Loss: 0.008366837210644247, Train_acc 0.9969172297297297\n",
      "\n",
      "Epoch 76. Loss: 0.007539635217045577, Train_acc 0.9969338037634409\n",
      "\n",
      "Epoch 76. Loss: 0.011055986865629105, Train_acc 0.9969084224598931\n",
      "\n",
      "Epoch 76. Loss: 0.009989385629676818, Train_acc 0.9969248670212766\n",
      "\n",
      "Epoch 76. Loss: 0.009156010259859002, Train_acc 0.9969411375661376\n",
      "\n",
      "Epoch 76. Loss: 0.008521922460091624, Train_acc 0.9969572368421052\n",
      "\n",
      "Epoch 76. Loss: 0.007724437318655488, Train_acc 0.996973167539267\n",
      "\n",
      "Epoch 76. Loss: 0.009314952114891384, Train_acc 0.9969482421875\n",
      "\n",
      "Epoch 76. Loss: 0.009022841748673953, Train_acc 0.996964054404145\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76. Loss: 0.008945651074122702, Train_acc 0.9969394329896907\n",
      "\n",
      "Epoch 76. Loss: 0.010104842233542783, Train_acc 0.996875\n",
      "\n",
      "Epoch 76. Loss: 0.009793516255886122, Train_acc 0.99688\n",
      "\n",
      "Epoch 77. Loss: 0.009083814809258966, Train_acc 1.0\n",
      "\n",
      "Epoch 77. Loss: 0.008275094657628556, Train_acc 1.0\n",
      "\n",
      "Epoch 77. Loss: 0.007523617714931506, Train_acc 1.0\n",
      "\n",
      "Epoch 77. Loss: 0.00914058248277599, Train_acc 0.998046875\n",
      "\n",
      "Epoch 77. Loss: 0.012746147752488505, Train_acc 0.9953125\n",
      "\n",
      "Epoch 77. Loss: 0.01733338790299134, Train_acc 0.9934895833333334\n",
      "\n",
      "Epoch 77. Loss: 0.015619211358427266, Train_acc 0.9944196428571429\n",
      "\n",
      "Epoch 77. Loss: 0.014213680586866373, Train_acc 0.9951171875\n",
      "\n",
      "Epoch 77. Loss: 0.012917463830379547, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 77. Loss: 0.012180250098199757, Train_acc 0.99609375\n",
      "\n",
      "Epoch 77. Loss: 0.01232888946448962, Train_acc 0.9957386363636364\n",
      "\n",
      "Epoch 77. Loss: 0.011857271972434521, Train_acc 0.99609375\n",
      "\n",
      "Epoch 77. Loss: 0.012475657231930018, Train_acc 0.9951923076923077\n",
      "\n",
      "Epoch 77. Loss: 0.013580838271072317, Train_acc 0.9944196428571429\n",
      "\n",
      "Epoch 77. Loss: 0.012367557246207424, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 77. Loss: 0.012255934652286077, Train_acc 0.99462890625\n",
      "\n",
      "Epoch 77. Loss: 0.012089660824773286, Train_acc 0.9944852941176471\n",
      "\n",
      "Epoch 77. Loss: 0.012597605789993027, Train_acc 0.9939236111111112\n",
      "\n",
      "Epoch 77. Loss: 0.011581602783018785, Train_acc 0.9942434210526315\n",
      "\n",
      "Epoch 77. Loss: 0.01225657329650024, Train_acc 0.99375\n",
      "\n",
      "Epoch 77. Loss: 0.011639239714142378, Train_acc 0.9936755952380952\n",
      "\n",
      "Epoch 77. Loss: 0.011852074444827464, Train_acc 0.9936079545454546\n",
      "\n",
      "Epoch 77. Loss: 0.01102964196290406, Train_acc 0.9938858695652174\n",
      "\n",
      "Epoch 77. Loss: 0.01058881468268483, Train_acc 0.994140625\n",
      "\n",
      "Epoch 77. Loss: 0.009606483482984447, Train_acc 0.994375\n",
      "\n",
      "Epoch 77. Loss: 0.008746425062437575, Train_acc 0.9945913461538461\n",
      "\n",
      "Epoch 77. Loss: 0.007923252272902925, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 77. Loss: 0.007217514282341152, Train_acc 0.9949776785714286\n",
      "\n",
      "Epoch 77. Loss: 0.0071576417472589155, Train_acc 0.9948814655172413\n",
      "\n",
      "Epoch 77. Loss: 0.008192517771121396, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 77. Loss: 0.0074242633031631556, Train_acc 0.9949596774193549\n",
      "\n",
      "Epoch 77. Loss: 0.007059286878346656, Train_acc 0.9951171875\n",
      "\n",
      "Epoch 77. Loss: 0.006983271671464373, Train_acc 0.9950284090909091\n",
      "\n",
      "Epoch 77. Loss: 0.006450539967795012, Train_acc 0.9951746323529411\n",
      "\n",
      "Epoch 77. Loss: 0.005971336209424404, Train_acc 0.9953125\n",
      "\n",
      "Epoch 77. Loss: 0.005417455810729549, Train_acc 0.9954427083333334\n",
      "\n",
      "Epoch 77. Loss: 0.005149558228707807, Train_acc 0.9955658783783784\n",
      "\n",
      "Epoch 77. Loss: 0.00477052677027717, Train_acc 0.9956825657894737\n",
      "\n",
      "Epoch 77. Loss: 0.004343773987314117, Train_acc 0.9957932692307693\n",
      "\n",
      "Epoch 77. Loss: 0.004373275929842305, Train_acc 0.9958984375\n",
      "\n",
      "Epoch 77. Loss: 0.0040232379887139005, Train_acc 0.9959984756097561\n",
      "\n",
      "Epoch 77. Loss: 0.003730032738995719, Train_acc 0.99609375\n",
      "\n",
      "Epoch 77. Loss: 0.003376521444133559, Train_acc 0.9961845930232558\n",
      "\n",
      "Epoch 77. Loss: 0.0030850565722483894, Train_acc 0.9962713068181818\n",
      "\n",
      "Epoch 77. Loss: 0.002894742781227693, Train_acc 0.9963541666666667\n",
      "\n",
      "Epoch 77. Loss: 0.002636030678552231, Train_acc 0.9964334239130435\n",
      "\n",
      "Epoch 77. Loss: 0.0024634813657195935, Train_acc 0.9965093085106383\n",
      "\n",
      "Epoch 77. Loss: 0.005477035676609716, Train_acc 0.9964192708333334\n",
      "\n",
      "Epoch 77. Loss: 0.005270805861581482, Train_acc 0.9964923469387755\n",
      "\n",
      "Epoch 77. Loss: 0.004847863507259594, Train_acc 0.9965625\n",
      "\n",
      "Epoch 77. Loss: 0.004635270940427815, Train_acc 0.9966299019607843\n",
      "\n",
      "Epoch 77. Loss: 0.004260302524201797, Train_acc 0.9966947115384616\n",
      "\n",
      "Epoch 77. Loss: 0.004098047481677884, Train_acc 0.9967570754716981\n",
      "\n",
      "Epoch 77. Loss: 0.003794473041811842, Train_acc 0.9968171296296297\n",
      "\n",
      "Epoch 77. Loss: 0.003595617718091689, Train_acc 0.996875\n",
      "\n",
      "Epoch 77. Loss: 0.0033604139129886773, Train_acc 0.9969308035714286\n",
      "\n",
      "Epoch 77. Loss: 0.003134211472137548, Train_acc 0.996984649122807\n",
      "\n",
      "Epoch 77. Loss: 0.004476479206797878, Train_acc 0.9969019396551724\n",
      "\n",
      "Epoch 77. Loss: 0.004777802390739978, Train_acc 0.996822033898305\n",
      "\n",
      "Epoch 77. Loss: 0.004442222012086059, Train_acc 0.996875\n",
      "\n",
      "Epoch 77. Loss: 0.005545880747291457, Train_acc 0.9967981557377049\n",
      "\n",
      "Epoch 77. Loss: 0.005013238183087567, Train_acc 0.9968497983870968\n",
      "\n",
      "Epoch 77. Loss: 0.0045339921289304285, Train_acc 0.9968998015873016\n",
      "\n",
      "Epoch 77. Loss: 0.004199034271917736, Train_acc 0.9969482421875\n",
      "\n",
      "Epoch 77. Loss: 0.003920350197097953, Train_acc 0.9969951923076923\n",
      "\n",
      "Epoch 77. Loss: 0.0041676427463215255, Train_acc 0.9970407196969697\n",
      "\n",
      "Epoch 77. Loss: 0.0038109146214966474, Train_acc 0.9970848880597015\n",
      "\n",
      "Epoch 77. Loss: 0.003461906832051158, Train_acc 0.9971277573529411\n",
      "\n",
      "Epoch 77. Loss: 0.0032576554135682104, Train_acc 0.9971693840579711\n",
      "\n",
      "Epoch 77. Loss: 0.002943306232423414, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 77. Loss: 0.0026674110405925625, Train_acc 0.9972491197183099\n",
      "\n",
      "Epoch 77. Loss: 0.002429489183915068, Train_acc 0.9972873263888888\n",
      "\n",
      "Epoch 77. Loss: 0.00222612726660698, Train_acc 0.9973244863013698\n",
      "\n",
      "Epoch 77. Loss: 0.0020927470180042477, Train_acc 0.9973606418918919\n",
      "\n",
      "Epoch 77. Loss: 0.0021272618791593214, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 77. Loss: 0.0019593638905592054, Train_acc 0.9974300986842105\n",
      "\n",
      "Epoch 77. Loss: 0.002158482896122988, Train_acc 0.997463474025974\n",
      "\n",
      "Epoch 77. Loss: 0.0019919457328601833, Train_acc 0.9974959935897436\n",
      "\n",
      "Epoch 77. Loss: 0.002193164965193047, Train_acc 0.9975276898734177\n",
      "\n",
      "Epoch 77. Loss: 0.0019811593392429416, Train_acc 0.99755859375\n",
      "\n",
      "Epoch 77. Loss: 0.001999352782310933, Train_acc 0.9975887345679012\n",
      "\n",
      "Epoch 77. Loss: 0.0018040850890969993, Train_acc 0.9976181402439024\n",
      "\n",
      "Epoch 77. Loss: 0.0017953059196438577, Train_acc 0.9976468373493976\n",
      "\n",
      "Epoch 77. Loss: 0.0016264974895031227, Train_acc 0.9976748511904762\n",
      "\n",
      "Epoch 77. Loss: 0.0014695661888540056, Train_acc 0.9977022058823529\n",
      "\n",
      "Epoch 77. Loss: 0.0013301483759171754, Train_acc 0.9977289244186046\n",
      "\n",
      "Epoch 77. Loss: 0.001243910084840051, Train_acc 0.9977550287356322\n",
      "\n",
      "Epoch 77. Loss: 0.0011380217347055077, Train_acc 0.9977805397727273\n",
      "\n",
      "Epoch 77. Loss: 0.0010584235585824608, Train_acc 0.9978054775280899\n",
      "\n",
      "Epoch 77. Loss: 0.0009785350324783588, Train_acc 0.9978298611111112\n",
      "\n",
      "Epoch 77. Loss: 0.003764777808970857, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 77. Loss: 0.0033962294328929226, Train_acc 0.9977921195652174\n",
      "\n",
      "Epoch 77. Loss: 0.003102820543476603, Train_acc 0.9978158602150538\n",
      "\n",
      "Epoch 77. Loss: 0.0029030682713794666, Train_acc 0.9978390957446809\n",
      "\n",
      "Epoch 77. Loss: 0.002855669999324497, Train_acc 0.9978618421052632\n",
      "\n",
      "Epoch 77. Loss: 0.002638337645852089, Train_acc 0.9978841145833334\n",
      "\n",
      "Epoch 77. Loss: 0.003360070314786005, Train_acc 0.9978253865979382\n",
      "\n",
      "Epoch 77. Loss: 0.0032771147561351972, Train_acc 0.9978475765306123\n",
      "\n",
      "Epoch 77. Loss: 0.002985895549076544, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 77. Loss: 0.0026888926287764094, Train_acc 0.997890625\n",
      "\n",
      "[Epoch 77 Batch 100] Loss: 0.002424315661540053 Training: accuracy=0.997912\n",
      "Epoch 77. Loss: 0.002424315661540053, Train_acc 0.9979115099009901\n",
      "\n",
      "Epoch 77. Loss: 0.0021872308641254484, Train_acc 0.9979319852941176\n",
      "\n",
      "Epoch 77. Loss: 0.0019812072836092112, Train_acc 0.9979520631067961\n",
      "\n",
      "Epoch 77. Loss: 0.001790670348442789, Train_acc 0.9979717548076923\n",
      "\n",
      "Epoch 77. Loss: 0.001614658547863558, Train_acc 0.9979910714285715\n",
      "\n",
      "Epoch 77. Loss: 0.0014666295954498345, Train_acc 0.9980100235849056\n",
      "\n",
      "Epoch 77. Loss: 0.0018641280320059682, Train_acc 0.9980286214953271\n",
      "\n",
      "Epoch 77. Loss: 0.001698909537452326, Train_acc 0.998046875\n",
      "\n",
      "Epoch 77. Loss: 0.0017227114555421763, Train_acc 0.9980647935779816\n",
      "\n",
      "Epoch 77. Loss: 0.0015558474342509602, Train_acc 0.9980823863636363\n",
      "\n",
      "Epoch 77. Loss: 0.0038019713160828794, Train_acc 0.9980292792792793\n",
      "\n",
      "Epoch 77. Loss: 0.0034272225430445843, Train_acc 0.998046875\n",
      "\n",
      "Epoch 77. Loss: 0.003095689169775322, Train_acc 0.9980641592920354\n",
      "\n",
      "Epoch 77. Loss: 0.0027990450703631524, Train_acc 0.9980811403508771\n",
      "\n",
      "Epoch 77. Loss: 0.00262546813662997, Train_acc 0.9980978260869565\n",
      "\n",
      "Epoch 77. Loss: 0.002367619791513822, Train_acc 0.998114224137931\n",
      "\n",
      "Epoch 77. Loss: 0.002189477554411344, Train_acc 0.9981303418803419\n",
      "\n",
      "Epoch 77. Loss: 0.002244579219811248, Train_acc 0.998146186440678\n",
      "\n",
      "Epoch 77. Loss: 0.0020429059838371947, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 77. Loss: 0.0018663338153728074, Train_acc 0.9981770833333333\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77. Loss: 0.0029931210983545984, Train_acc 0.9981275826446281\n",
      "\n",
      "Epoch 77. Loss: 0.0027190150302742935, Train_acc 0.9981429303278688\n",
      "\n",
      "Epoch 77. Loss: 0.002471208939183151, Train_acc 0.9981580284552846\n",
      "\n",
      "Epoch 77. Loss: 0.002397781731057222, Train_acc 0.9981728830645161\n",
      "\n",
      "Epoch 77. Loss: 0.010527008284361412, Train_acc 0.998125\n",
      "\n",
      "Epoch 77. Loss: 0.009500027692515404, Train_acc 0.9981398809523809\n",
      "\n",
      "Epoch 77. Loss: 0.008589890092938023, Train_acc 0.9981545275590551\n",
      "\n",
      "Epoch 77. Loss: 0.007746670662393535, Train_acc 0.9981689453125\n",
      "\n",
      "Epoch 77. Loss: 0.006987958727829764, Train_acc 0.9981831395348837\n",
      "\n",
      "Epoch 77. Loss: 0.006326539370730506, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 77. Loss: 0.005709813415824797, Train_acc 0.9982108778625954\n",
      "\n",
      "Epoch 77. Loss: 0.005302663566196942, Train_acc 0.9982244318181818\n",
      "\n",
      "Epoch 77. Loss: 0.005463343332208678, Train_acc 0.9981790413533834\n",
      "\n",
      "Epoch 77. Loss: 0.005370686073971526, Train_acc 0.9981926305970149\n",
      "\n",
      "Epoch 77. Loss: 0.00499138107763401, Train_acc 0.9982060185185185\n",
      "\n",
      "Epoch 77. Loss: 0.004510678718513851, Train_acc 0.9982192095588235\n",
      "\n",
      "Epoch 77. Loss: 0.004164403856476341, Train_acc 0.9982322080291971\n",
      "\n",
      "Epoch 77. Loss: 0.003970598181200201, Train_acc 0.998245018115942\n",
      "\n",
      "Epoch 77. Loss: 0.0037806510460634602, Train_acc 0.9982576438848921\n",
      "\n",
      "Epoch 77. Loss: 0.0034439191519952555, Train_acc 0.9982700892857143\n",
      "\n",
      "Epoch 77. Loss: 0.003142585798073306, Train_acc 0.9982823581560284\n",
      "\n",
      "Epoch 77. Loss: 0.002888668486810992, Train_acc 0.9982944542253521\n",
      "\n",
      "Epoch 77. Loss: 0.0026148112751206193, Train_acc 0.9983063811188811\n",
      "\n",
      "Epoch 77. Loss: 0.0024475715345865135, Train_acc 0.9983181423611112\n",
      "\n",
      "Epoch 77. Loss: 0.0022815270119120015, Train_acc 0.9983297413793103\n",
      "\n",
      "Epoch 77. Loss: 0.005243253594029784, Train_acc 0.9982876712328768\n",
      "\n",
      "Epoch 77. Loss: 0.004756776692204444, Train_acc 0.9982993197278912\n",
      "\n",
      "Epoch 77. Loss: 0.004321747219575064, Train_acc 0.9983108108108109\n",
      "\n",
      "Epoch 77. Loss: 0.004227552998971298, Train_acc 0.9983221476510067\n",
      "\n",
      "Epoch 77. Loss: 0.004371975940982719, Train_acc 0.99828125\n",
      "\n",
      "Epoch 77. Loss: 0.004280554739962715, Train_acc 0.9982926324503312\n",
      "\n",
      "Epoch 77. Loss: 0.0051327736943936626, Train_acc 0.9982524671052632\n",
      "\n",
      "Epoch 77. Loss: 0.0046221519934586, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 77. Loss: 0.0042040478692253365, Train_acc 0.9982751623376623\n",
      "\n",
      "Epoch 77. Loss: 0.003827074565511936, Train_acc 0.9982862903225806\n",
      "\n",
      "Epoch 77. Loss: 0.0034937778984672524, Train_acc 0.9982972756410257\n",
      "\n",
      "Epoch 77. Loss: 0.0031843445891430633, Train_acc 0.9983081210191083\n",
      "\n",
      "Epoch 77. Loss: 0.0029170273471641386, Train_acc 0.998318829113924\n",
      "\n",
      "Epoch 77. Loss: 0.002963718411477016, Train_acc 0.9983294025157232\n",
      "\n",
      "Epoch 77. Loss: 0.0027813202088377833, Train_acc 0.99833984375\n",
      "\n",
      "Epoch 77. Loss: 0.0031901021029325095, Train_acc 0.9983501552795031\n",
      "\n",
      "Epoch 77. Loss: 0.004336523027787069, Train_acc 0.9983121141975309\n",
      "\n",
      "Epoch 77. Loss: 0.004005231644126289, Train_acc 0.9983224693251533\n",
      "\n",
      "Epoch 77. Loss: 0.0038177213938869656, Train_acc 0.9983326981707317\n",
      "\n",
      "Epoch 77. Loss: 0.0034474511152158133, Train_acc 0.998342803030303\n",
      "\n",
      "Epoch 77. Loss: 0.003349557289613779, Train_acc 0.9983527861445783\n",
      "\n",
      "Epoch 77. Loss: 0.003051402390928153, Train_acc 0.9983626497005988\n",
      "\n",
      "Epoch 77. Loss: 0.0031056307089457665, Train_acc 0.9983723958333334\n",
      "\n",
      "Epoch 77. Loss: 0.0028041218862724085, Train_acc 0.998382026627219\n",
      "\n",
      "Epoch 77. Loss: 0.00288156012910978, Train_acc 0.9983915441176471\n",
      "\n",
      "Epoch 77. Loss: 0.0026372997938621883, Train_acc 0.9984009502923976\n",
      "\n",
      "Epoch 77. Loss: 0.0023995603558018518, Train_acc 0.9984102470930233\n",
      "\n",
      "Epoch 77. Loss: 0.002280438953929667, Train_acc 0.998419436416185\n",
      "\n",
      "Epoch 77. Loss: 0.003844146257007293, Train_acc 0.9983836206896551\n",
      "\n",
      "Epoch 77. Loss: 0.0035954555052794567, Train_acc 0.9983928571428572\n",
      "\n",
      "Epoch 77. Loss: 0.0034889668525333005, Train_acc 0.9984019886363636\n",
      "\n",
      "Epoch 77. Loss: 0.0032840841043770136, Train_acc 0.9984110169491526\n",
      "\n",
      "Epoch 77. Loss: 0.002971839865332342, Train_acc 0.9984199438202247\n",
      "\n",
      "Epoch 77. Loss: 0.0026992780278661073, Train_acc 0.9984287709497207\n",
      "\n",
      "Epoch 77. Loss: 0.0054994604939703545, Train_acc 0.9983940972222223\n",
      "\n",
      "Epoch 77. Loss: 0.00501224322256679, Train_acc 0.9984029696132597\n",
      "\n",
      "Epoch 77. Loss: 0.004526288598943458, Train_acc 0.9984117445054945\n",
      "\n",
      "Epoch 77. Loss: 0.00571254327759329, Train_acc 0.9983777322404371\n",
      "\n",
      "Epoch 77. Loss: 0.005969518492655607, Train_acc 0.9983440896739131\n",
      "\n",
      "Epoch 77. Loss: 0.005380029693523129, Train_acc 0.9983530405405405\n",
      "\n",
      "Epoch 77. Loss: 0.004866536509169189, Train_acc 0.9983618951612904\n",
      "\n",
      "Epoch 77. Loss: 0.004384337075084798, Train_acc 0.9983706550802139\n",
      "\n",
      "Epoch 77. Loss: 0.005235856472727972, Train_acc 0.9983377659574468\n",
      "\n",
      "Epoch 77. Loss: 0.005033498510072217, Train_acc 0.9983465608465608\n",
      "\n",
      "Epoch 77. Loss: 0.004656556897494572, Train_acc 0.9983552631578947\n",
      "\n",
      "Epoch 77. Loss: 0.004204243625987361, Train_acc 0.9983638743455497\n",
      "\n",
      "Epoch 77. Loss: 0.003951842917648366, Train_acc 0.9983723958333334\n",
      "\n",
      "Epoch 77. Loss: 0.01109345957664914, Train_acc 0.9983403497409327\n",
      "\n",
      "Epoch 77. Loss: 0.010384601976975206, Train_acc 0.9983489046391752\n",
      "\n",
      "Epoch 77. Loss: 0.010351019745175008, Train_acc 0.9983173076923076\n",
      "\n",
      "Epoch 77. Loss: 0.009316360019095556, Train_acc 0.99832\n",
      "\n",
      "Epoch 78. Loss: 0.009366667605889872, Train_acc 0.9921875\n",
      "\n",
      "Epoch 78. Loss: 0.008854169849264355, Train_acc 0.99609375\n",
      "\n",
      "Epoch 78. Loss: 0.00890008931565976, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 78. Loss: 0.008081984691790752, Train_acc 0.998046875\n",
      "\n",
      "Epoch 78. Loss: 0.008252887694214592, Train_acc 0.996875\n",
      "\n",
      "Epoch 78. Loss: 0.007443550256963649, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 78. Loss: 0.006834905601062846, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 78. Loss: 0.006290961423663173, Train_acc 0.998046875\n",
      "\n",
      "Epoch 78. Loss: 0.005864657651988752, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 78. Loss: 0.009390787951595862, Train_acc 0.996875\n",
      "\n",
      "Epoch 78. Loss: 0.008737419457686496, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 78. Loss: 0.008780403281556862, Train_acc 0.9967447916666666\n",
      "\n",
      "Epoch 78. Loss: 0.008676522515243855, Train_acc 0.9963942307692307\n",
      "\n",
      "Epoch 78. Loss: 0.007844034448820637, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 78. Loss: 0.007778441087283152, Train_acc 0.9963541666666667\n",
      "\n",
      "Epoch 78. Loss: 0.007975556113610378, Train_acc 0.99658203125\n",
      "\n",
      "Epoch 78. Loss: 0.010762206606527904, Train_acc 0.9963235294117647\n",
      "\n",
      "Epoch 78. Loss: 0.010008744072879022, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 78. Loss: 0.010179569576947092, Train_acc 0.9962993421052632\n",
      "\n",
      "Epoch 78. Loss: 0.009263904760198175, Train_acc 0.996484375\n",
      "\n",
      "Epoch 78. Loss: 0.008510001953802747, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 78. Loss: 0.007862185121614256, Train_acc 0.9968039772727273\n",
      "\n",
      "Epoch 78. Loss: 0.008567601250295508, Train_acc 0.9966032608695652\n",
      "\n",
      "Epoch 78. Loss: 0.007833698102661671, Train_acc 0.9967447916666666\n",
      "\n",
      "Epoch 78. Loss: 0.007160809226776989, Train_acc 0.996875\n",
      "\n",
      "Epoch 78. Loss: 0.0065425264527350655, Train_acc 0.9969951923076923\n",
      "\n",
      "Epoch 78. Loss: 0.006315472450326382, Train_acc 0.9971064814814815\n",
      "\n",
      "Epoch 78. Loss: 0.008006530085030644, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 78. Loss: 0.009146082769772513, Train_acc 0.9962284482758621\n",
      "\n",
      "Epoch 78. Loss: 0.00824528968675617, Train_acc 0.9963541666666667\n",
      "\n",
      "Epoch 78. Loss: 0.0074958069239737125, Train_acc 0.9964717741935484\n",
      "\n",
      "Epoch 78. Loss: 0.007269164928243894, Train_acc 0.99658203125\n",
      "\n",
      "Epoch 78. Loss: 0.006549460603258093, Train_acc 0.9966856060606061\n",
      "\n",
      "Epoch 78. Loss: 0.005906642165108478, Train_acc 0.9967830882352942\n",
      "\n",
      "Epoch 78. Loss: 0.005319934666007523, Train_acc 0.996875\n",
      "\n",
      "Epoch 78. Loss: 0.004820871487987016, Train_acc 0.9969618055555556\n",
      "\n",
      "Epoch 78. Loss: 0.0043767142904016145, Train_acc 0.997043918918919\n",
      "\n",
      "Epoch 78. Loss: 0.0073753296088170505, Train_acc 0.9969161184210527\n",
      "\n",
      "Epoch 78. Loss: 0.007233101390390828, Train_acc 0.9969951923076923\n",
      "\n",
      "Epoch 78. Loss: 0.010099828180005462, Train_acc 0.9966796875\n",
      "\n",
      "Epoch 78. Loss: 0.009135718676962052, Train_acc 0.9967606707317073\n",
      "\n",
      "Epoch 78. Loss: 0.00826161882111513, Train_acc 0.9968377976190477\n",
      "\n",
      "Epoch 78. Loss: 0.007733012964911015, Train_acc 0.9969113372093024\n",
      "\n",
      "Epoch 78. Loss: 0.0069970591122873885, Train_acc 0.9969815340909091\n",
      "\n",
      "Epoch 78. Loss: 0.00801119516834333, Train_acc 0.996875\n",
      "\n",
      "Epoch 78. Loss: 0.00738057179258136, Train_acc 0.9969429347826086\n",
      "\n",
      "Epoch 78. Loss: 0.009141226631455434, Train_acc 0.996841755319149\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78. Loss: 0.011241920684623253, Train_acc 0.99658203125\n",
      "\n",
      "Epoch 78. Loss: 0.010157793362442059, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 78. Loss: 0.011363503165099088, Train_acc 0.9965625\n",
      "\n",
      "Epoch 78. Loss: 0.010615582907545325, Train_acc 0.9966299019607843\n",
      "\n",
      "Epoch 78. Loss: 0.009769031283048771, Train_acc 0.9966947115384616\n",
      "\n",
      "Epoch 78. Loss: 0.009553502427149996, Train_acc 0.9967570754716981\n",
      "\n",
      "Epoch 78. Loss: 0.00867540981578158, Train_acc 0.9968171296296297\n",
      "\n",
      "Epoch 78. Loss: 0.007863898341162443, Train_acc 0.996875\n",
      "\n",
      "Epoch 78. Loss: 0.007263326732191539, Train_acc 0.9969308035714286\n",
      "\n",
      "Epoch 78. Loss: 0.00820166796851733, Train_acc 0.9968475877192983\n",
      "\n",
      "Epoch 78. Loss: 0.008633669868039298, Train_acc 0.9967672413793104\n",
      "\n",
      "Epoch 78. Loss: 0.007813961409246662, Train_acc 0.996822033898305\n",
      "\n",
      "Epoch 78. Loss: 0.0072343824278629475, Train_acc 0.996875\n",
      "\n",
      "Epoch 78. Loss: 0.00904637825232595, Train_acc 0.9967981557377049\n",
      "\n",
      "Epoch 78. Loss: 0.008167291678112707, Train_acc 0.9968497983870968\n",
      "\n",
      "Epoch 78. Loss: 0.0075439828887927185, Train_acc 0.9968998015873016\n",
      "\n",
      "Epoch 78. Loss: 0.007089161665656952, Train_acc 0.9969482421875\n",
      "\n",
      "Epoch 78. Loss: 0.00645376680396687, Train_acc 0.9969951923076923\n",
      "\n",
      "Epoch 78. Loss: 0.009282576111877184, Train_acc 0.9969223484848485\n",
      "\n",
      "Epoch 78. Loss: 0.008383988796460677, Train_acc 0.9969682835820896\n",
      "\n",
      "Epoch 78. Loss: 0.00834974784444694, Train_acc 0.9970128676470589\n",
      "\n",
      "Epoch 78. Loss: 0.008034991922222892, Train_acc 0.9970561594202898\n",
      "\n",
      "Epoch 78. Loss: 0.008002647752085316, Train_acc 0.9970982142857143\n",
      "\n",
      "Epoch 78. Loss: 0.007323543224239935, Train_acc 0.9971390845070423\n",
      "\n",
      "Epoch 78. Loss: 0.007143888709847263, Train_acc 0.9971788194444444\n",
      "\n",
      "Epoch 78. Loss: 0.006438934951450644, Train_acc 0.9972174657534246\n",
      "\n",
      "Epoch 78. Loss: 0.008060806229197578, Train_acc 0.997043918918919\n",
      "\n",
      "Epoch 78. Loss: 0.0072806372936854635, Train_acc 0.9970833333333333\n",
      "\n",
      "Epoch 78. Loss: 0.0068419732533803465, Train_acc 0.9971217105263158\n",
      "\n",
      "Epoch 78. Loss: 0.007158530370108267, Train_acc 0.9970576298701299\n",
      "\n",
      "Epoch 78. Loss: 0.01258046786401747, Train_acc 0.9969951923076923\n",
      "\n",
      "Epoch 78. Loss: 0.012188115585572229, Train_acc 0.996934335443038\n",
      "\n",
      "Epoch 78. Loss: 0.011591564783805644, Train_acc 0.99697265625\n",
      "\n",
      "Epoch 78. Loss: 0.010537617441806825, Train_acc 0.9970100308641975\n",
      "\n",
      "Epoch 78. Loss: 0.009680817942434815, Train_acc 0.997046493902439\n",
      "\n",
      "Epoch 78. Loss: 0.011172819699896218, Train_acc 0.9969879518072289\n",
      "\n",
      "Epoch 78. Loss: 0.010090701149577021, Train_acc 0.9970238095238095\n",
      "\n",
      "Epoch 78. Loss: 0.009629831437028157, Train_acc 0.9970588235294118\n",
      "\n",
      "Epoch 78. Loss: 0.009588157567015327, Train_acc 0.9970021802325582\n",
      "\n",
      "Epoch 78. Loss: 0.011873396872846219, Train_acc 0.9968570402298851\n",
      "\n",
      "Epoch 78. Loss: 0.010972886773565053, Train_acc 0.9968927556818182\n",
      "\n",
      "Epoch 78. Loss: 0.009980797965930677, Train_acc 0.9969276685393258\n",
      "\n",
      "Epoch 78. Loss: 0.009590651692471006, Train_acc 0.9969618055555556\n",
      "\n",
      "Epoch 78. Loss: 0.008782237134836852, Train_acc 0.9969951923076923\n",
      "\n",
      "Epoch 78. Loss: 0.007998226327322638, Train_acc 0.9970278532608695\n",
      "\n",
      "Epoch 78. Loss: 0.0072905807526948, Train_acc 0.997059811827957\n",
      "\n",
      "Epoch 78. Loss: 0.006699912322569663, Train_acc 0.9970910904255319\n",
      "\n",
      "Epoch 78. Loss: 0.006211597211741306, Train_acc 0.9971217105263158\n",
      "\n",
      "Epoch 78. Loss: 0.005657980507779477, Train_acc 0.9971516927083334\n",
      "\n",
      "Epoch 78. Loss: 0.005275484027361147, Train_acc 0.997181056701031\n",
      "\n",
      "Epoch 78. Loss: 0.004776849930937832, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 78. Loss: 0.004463512429071139, Train_acc 0.9972380050505051\n",
      "\n",
      "Epoch 78. Loss: 0.0054864708141738215, Train_acc 0.9971875\n",
      "\n",
      "[Epoch 78 Batch 100] Loss: 0.00567228953484482 Training: accuracy=0.997138\n",
      "Epoch 78. Loss: 0.00567228953484482, Train_acc 0.997137995049505\n",
      "\n",
      "Epoch 78. Loss: 0.00522442668234962, Train_acc 0.9971660539215687\n",
      "\n",
      "Epoch 78. Loss: 0.005965671960017006, Train_acc 0.9971177184466019\n",
      "\n",
      "Epoch 78. Loss: 0.005428133164589185, Train_acc 0.9971454326923077\n",
      "\n",
      "Epoch 78. Loss: 0.004973247083420675, Train_acc 0.997172619047619\n",
      "\n",
      "Epoch 78. Loss: 0.0051968959673301465, Train_acc 0.9971992924528302\n",
      "\n",
      "Epoch 78. Loss: 0.00469160783066357, Train_acc 0.9972254672897196\n",
      "\n",
      "Epoch 78. Loss: 0.005104143167501731, Train_acc 0.9972511574074074\n",
      "\n",
      "Epoch 78. Loss: 0.0046295181104609754, Train_acc 0.997276376146789\n",
      "\n",
      "Epoch 78. Loss: 0.0058803901990416105, Train_acc 0.9972301136363636\n",
      "\n",
      "Epoch 78. Loss: 0.005310568916807506, Train_acc 0.9972550675675675\n",
      "\n",
      "Epoch 78. Loss: 0.004918801106689066, Train_acc 0.9972795758928571\n",
      "\n",
      "Epoch 78. Loss: 0.004589165805345944, Train_acc 0.9973036504424779\n",
      "\n",
      "Epoch 78. Loss: 0.005775212250858102, Train_acc 0.9972587719298246\n",
      "\n",
      "Epoch 78. Loss: 0.005409238713422018, Train_acc 0.9972826086956522\n",
      "\n",
      "Epoch 78. Loss: 0.007256432304476437, Train_acc 0.9971713362068966\n",
      "\n",
      "Epoch 78. Loss: 0.008847014021600548, Train_acc 0.9971287393162394\n",
      "\n",
      "Epoch 78. Loss: 0.008929116348974642, Train_acc 0.9970868644067796\n",
      "\n",
      "Epoch 78. Loss: 0.00807043539963721, Train_acc 0.9971113445378151\n",
      "\n",
      "Epoch 78. Loss: 0.010457605518244732, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 78. Loss: 0.009471119882258874, Train_acc 0.9970945247933884\n",
      "\n",
      "Epoch 78. Loss: 0.008578608833653273, Train_acc 0.9971183401639344\n",
      "\n",
      "Epoch 78. Loss: 0.007762536912259125, Train_acc 0.997141768292683\n",
      "\n",
      "Epoch 78. Loss: 0.00832520079680979, Train_acc 0.997101814516129\n",
      "\n",
      "Epoch 78. Loss: 0.007899068863931593, Train_acc 0.997125\n",
      "\n",
      "Epoch 78. Loss: 0.007530460412496296, Train_acc 0.9971478174603174\n",
      "\n",
      "Epoch 78. Loss: 0.009053548862213464, Train_acc 0.9971087598425197\n",
      "\n",
      "Epoch 78. Loss: 0.008727884257293853, Train_acc 0.99713134765625\n",
      "\n",
      "Epoch 78. Loss: 0.00882502088870744, Train_acc 0.9971535852713178\n",
      "\n",
      "Epoch 78. Loss: 0.008484644650752604, Train_acc 0.9971754807692308\n",
      "\n",
      "Epoch 78. Loss: 0.009475164339842135, Train_acc 0.9971374045801527\n",
      "\n",
      "Epoch 78. Loss: 0.00853972528245362, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 78. Loss: 0.008862218988236597, Train_acc 0.9971217105263158\n",
      "\n",
      "Epoch 78. Loss: 0.00831213415414555, Train_acc 0.9971431902985075\n",
      "\n",
      "Epoch 78. Loss: 0.007740983184617427, Train_acc 0.9971643518518518\n",
      "\n",
      "Epoch 78. Loss: 0.007773671265490354, Train_acc 0.9971277573529411\n",
      "\n",
      "Epoch 78. Loss: 0.011519174247426541, Train_acc 0.9970346715328468\n",
      "\n",
      "Epoch 78. Loss: 0.010477892240197437, Train_acc 0.9970561594202898\n",
      "\n",
      "Epoch 78. Loss: 0.009989319660792629, Train_acc 0.9970773381294964\n",
      "\n",
      "Epoch 78. Loss: 0.010449648259010803, Train_acc 0.9970982142857143\n",
      "\n",
      "Epoch 78. Loss: 0.014227718434864483, Train_acc 0.9970633865248227\n",
      "\n",
      "Epoch 78. Loss: 0.01827624916029054, Train_acc 0.9969740316901409\n",
      "\n",
      "Epoch 78. Loss: 0.0182248348354585, Train_acc 0.9969405594405595\n",
      "\n",
      "Epoch 78. Loss: 0.016721098179455433, Train_acc 0.9969618055555556\n",
      "\n",
      "Epoch 78. Loss: 0.015395652607681604, Train_acc 0.9969827586206896\n",
      "\n",
      "Epoch 78. Loss: 0.028460555990578756, Train_acc 0.9967893835616438\n",
      "\n",
      "Epoch 78. Loss: 0.027563640075959586, Train_acc 0.9967049319727891\n",
      "\n",
      "Epoch 78. Loss: 0.02482958340498508, Train_acc 0.9967271959459459\n",
      "\n",
      "Epoch 78. Loss: 0.02296841284910769, Train_acc 0.9967491610738255\n",
      "\n",
      "Epoch 78. Loss: 0.021278578840463736, Train_acc 0.9967708333333334\n",
      "\n",
      "Epoch 78. Loss: 0.02444971655556802, Train_acc 0.9966887417218543\n",
      "\n",
      "Epoch 78. Loss: 0.023204199993603625, Train_acc 0.9966591282894737\n",
      "\n",
      "Epoch 78. Loss: 0.021112650956989703, Train_acc 0.9966809640522876\n",
      "\n",
      "Epoch 78. Loss: 0.019327041356107334, Train_acc 0.9967025162337663\n",
      "\n",
      "Epoch 78. Loss: 0.01913314440698094, Train_acc 0.9966733870967742\n",
      "\n",
      "Epoch 78. Loss: 0.017700301424568896, Train_acc 0.9966947115384616\n",
      "\n",
      "Epoch 78. Loss: 0.016033534804144656, Train_acc 0.9967157643312102\n",
      "\n",
      "Epoch 78. Loss: 0.014642730043449242, Train_acc 0.9967365506329114\n",
      "\n",
      "Epoch 78. Loss: 0.013567535252006269, Train_acc 0.9967570754716981\n",
      "\n",
      "Epoch 78. Loss: 0.013821647357015089, Train_acc 0.996728515625\n",
      "\n",
      "Epoch 78. Loss: 0.01351603805965329, Train_acc 0.9967488354037267\n",
      "\n",
      "Epoch 78. Loss: 0.012562458984072312, Train_acc 0.9967689043209876\n",
      "\n",
      "Epoch 78. Loss: 0.011737427265508745, Train_acc 0.996788726993865\n",
      "\n",
      "Epoch 78. Loss: 0.013235332542118824, Train_acc 0.9967606707317073\n",
      "\n",
      "Epoch 78. Loss: 0.012173945358506497, Train_acc 0.9967803030303031\n",
      "\n",
      "Epoch 78. Loss: 0.011520473440240316, Train_acc 0.9967996987951807\n",
      "\n",
      "Epoch 78. Loss: 0.01114942491851791, Train_acc 0.9968188622754491\n",
      "\n",
      "Epoch 78. Loss: 0.010277136521138647, Train_acc 0.9968377976190477\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78. Loss: 0.009671535279912859, Train_acc 0.9968565088757396\n",
      "\n",
      "Epoch 78. Loss: 0.009949593189266123, Train_acc 0.9968290441176471\n",
      "\n",
      "Epoch 78. Loss: 0.010526389167821525, Train_acc 0.9968019005847953\n",
      "\n",
      "Epoch 78. Loss: 0.009625132381610082, Train_acc 0.9968204941860465\n",
      "\n",
      "Epoch 78. Loss: 0.00952089808853746, Train_acc 0.9968388728323699\n",
      "\n",
      "Epoch 78. Loss: 0.010301327176144248, Train_acc 0.9968121408045977\n",
      "\n",
      "Epoch 78. Loss: 0.010190919179991358, Train_acc 0.9967857142857143\n",
      "\n",
      "Epoch 78. Loss: 0.009406055983812042, Train_acc 0.9968039772727273\n",
      "\n",
      "Epoch 78. Loss: 0.00956238772518375, Train_acc 0.996822033898305\n",
      "\n",
      "Epoch 78. Loss: 0.008783434249042169, Train_acc 0.9968398876404494\n",
      "\n",
      "Epoch 78. Loss: 0.008030407692208466, Train_acc 0.9968575418994413\n",
      "\n",
      "Epoch 78. Loss: 0.007770195549918333, Train_acc 0.996875\n",
      "\n",
      "Epoch 78. Loss: 0.007292539927498805, Train_acc 0.9968922651933702\n",
      "\n",
      "Epoch 78. Loss: 0.006611932402370363, Train_acc 0.9969093406593407\n",
      "\n",
      "Epoch 78. Loss: 0.00595874781522762, Train_acc 0.9969262295081968\n",
      "\n",
      "Epoch 78. Loss: 0.0056588863237674045, Train_acc 0.9969429347826086\n",
      "\n",
      "Epoch 78. Loss: 0.005178306507441775, Train_acc 0.9969594594594594\n",
      "\n",
      "Epoch 78. Loss: 0.004736353011874892, Train_acc 0.9969758064516129\n",
      "\n",
      "Epoch 78. Loss: 0.0068340725171105905, Train_acc 0.9969502005347594\n",
      "\n",
      "Epoch 78. Loss: 0.0062080244914475245, Train_acc 0.9969664228723404\n",
      "\n",
      "Epoch 78. Loss: 0.006008744274075314, Train_acc 0.9969824735449735\n",
      "\n",
      "Epoch 78. Loss: 0.00688744674726917, Train_acc 0.9969572368421052\n",
      "\n",
      "Epoch 78. Loss: 0.006303583849039022, Train_acc 0.996973167539267\n",
      "\n",
      "Epoch 78. Loss: 0.0061502295619097445, Train_acc 0.9969889322916666\n",
      "\n",
      "Epoch 78. Loss: 0.005742243013383189, Train_acc 0.9970045336787565\n",
      "\n",
      "Epoch 78. Loss: 0.006267059909493839, Train_acc 0.9969797036082474\n",
      "\n",
      "Epoch 78. Loss: 0.005918393753937884, Train_acc 0.9969951923076923\n",
      "\n",
      "Epoch 78. Loss: 0.005743245467593077, Train_acc 0.997\n",
      "\n",
      "Epoch 79. Loss: 0.005182797010194335, Train_acc 1.0\n",
      "\n",
      "Epoch 79. Loss: 0.004728776261799998, Train_acc 1.0\n",
      "\n",
      "Epoch 79. Loss: 0.004701313389250756, Train_acc 1.0\n",
      "\n",
      "Epoch 79. Loss: 0.004283768387877155, Train_acc 1.0\n",
      "\n",
      "Epoch 79. Loss: 0.003913021487326809, Train_acc 1.0\n",
      "\n",
      "Epoch 79. Loss: 0.0036285901290719707, Train_acc 1.0\n",
      "\n",
      "Epoch 79. Loss: 0.007512370203960984, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 79. Loss: 0.006764558027745586, Train_acc 0.998046875\n",
      "\n",
      "Epoch 79. Loss: 0.006219764892234327, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 79. Loss: 0.006394992796904375, Train_acc 0.99765625\n",
      "\n",
      "Epoch 79. Loss: 0.006409542921179411, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 79. Loss: 0.005973584904777, Train_acc 0.998046875\n",
      "\n",
      "Epoch 79. Loss: 0.005545116734063914, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 79. Loss: 0.00797295587201979, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 79. Loss: 0.007609020371571775, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 79. Loss: 0.007306882153602478, Train_acc 0.99755859375\n",
      "\n",
      "Epoch 79. Loss: 0.007207805173682007, Train_acc 0.9977022058823529\n",
      "\n",
      "Epoch 79. Loss: 0.006505578423899934, Train_acc 0.9978298611111112\n",
      "\n",
      "Epoch 79. Loss: 0.006417548822935693, Train_acc 0.9979440789473685\n",
      "\n",
      "Epoch 79. Loss: 0.0068574215479877045, Train_acc 0.99765625\n",
      "\n",
      "Epoch 79. Loss: 0.011583685771362762, Train_acc 0.9970238095238095\n",
      "\n",
      "Epoch 79. Loss: 0.01053719983893196, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 79. Loss: 0.009504010117593293, Train_acc 0.9972826086956522\n",
      "\n",
      "Epoch 79. Loss: 0.009031255071127012, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 79. Loss: 0.010148102663246032, Train_acc 0.9971875\n",
      "\n",
      "Epoch 79. Loss: 0.009240494354065272, Train_acc 0.9972956730769231\n",
      "\n",
      "Epoch 79. Loss: 0.008882390787970436, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 79. Loss: 0.008154903736468924, Train_acc 0.9974888392857143\n",
      "\n",
      "Epoch 79. Loss: 0.0073841669137231095, Train_acc 0.9975754310344828\n",
      "\n",
      "Epoch 79. Loss: 0.006748177556409829, Train_acc 0.99765625\n",
      "\n",
      "Epoch 79. Loss: 0.00608549872687279, Train_acc 0.9977318548387096\n",
      "\n",
      "Epoch 79. Loss: 0.005507291855893899, Train_acc 0.997802734375\n",
      "\n",
      "Epoch 79. Loss: 0.005461549472420546, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 79. Loss: 0.005547486788728058, Train_acc 0.9979319852941176\n",
      "\n",
      "Epoch 79. Loss: 0.005489755770964819, Train_acc 0.9979910714285715\n",
      "\n",
      "Epoch 79. Loss: 0.004985544574304728, Train_acc 0.998046875\n",
      "\n",
      "Epoch 79. Loss: 0.00456920133075913, Train_acc 0.9980996621621622\n",
      "\n",
      "Epoch 79. Loss: 0.004598914099858405, Train_acc 0.9981496710526315\n",
      "\n",
      "Epoch 79. Loss: 0.005167833876424614, Train_acc 0.9979967948717948\n",
      "\n",
      "Epoch 79. Loss: 0.004663863998747933, Train_acc 0.998046875\n",
      "\n",
      "Epoch 79. Loss: 0.005980978769448759, Train_acc 0.9979039634146342\n",
      "\n",
      "Epoch 79. Loss: 0.0054524837798828885, Train_acc 0.9979538690476191\n",
      "\n",
      "Epoch 79. Loss: 0.008740174296524078, Train_acc 0.9976380813953488\n",
      "\n",
      "Epoch 79. Loss: 0.008001206591357396, Train_acc 0.9976917613636364\n",
      "\n",
      "Epoch 79. Loss: 0.010549148864712959, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 79. Loss: 0.00952207942891864, Train_acc 0.997452445652174\n",
      "\n",
      "Epoch 79. Loss: 0.008598250878487696, Train_acc 0.9975066489361702\n",
      "\n",
      "Epoch 79. Loss: 0.007771049528572971, Train_acc 0.99755859375\n",
      "\n",
      "Epoch 79. Loss: 0.008820984331596508, Train_acc 0.9974489795918368\n",
      "\n",
      "Epoch 79. Loss: 0.008306281245421125, Train_acc 0.9975\n",
      "\n",
      "Epoch 79. Loss: 0.007733312591541487, Train_acc 0.9975490196078431\n",
      "\n",
      "Epoch 79. Loss: 0.007035718224564131, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 79. Loss: 0.0064116505232026605, Train_acc 0.9976415094339622\n",
      "\n",
      "Epoch 79. Loss: 0.006264266692912915, Train_acc 0.9976851851851852\n",
      "\n",
      "Epoch 79. Loss: 0.011273519536837643, Train_acc 0.9974431818181818\n",
      "\n",
      "Epoch 79. Loss: 0.010460917802849148, Train_acc 0.9974888392857143\n",
      "\n",
      "Epoch 79. Loss: 0.011208428317784134, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 79. Loss: 0.01651156250340837, Train_acc 0.9971713362068966\n",
      "\n",
      "Epoch 79. Loss: 0.01708302229228405, Train_acc 0.9970868644067796\n",
      "\n",
      "Epoch 79. Loss: 0.015574153106654774, Train_acc 0.9971354166666667\n",
      "\n",
      "Epoch 79. Loss: 0.014079805039889447, Train_acc 0.9971823770491803\n",
      "\n",
      "Epoch 79. Loss: 0.013082107985937744, Train_acc 0.9972278225806451\n",
      "\n",
      "Epoch 79. Loss: 0.011915587288352833, Train_acc 0.9972718253968254\n",
      "\n",
      "Epoch 79. Loss: 0.011968477616202521, Train_acc 0.9971923828125\n",
      "\n",
      "Epoch 79. Loss: 0.014309145405434091, Train_acc 0.9969951923076923\n",
      "\n",
      "Epoch 79. Loss: 0.01295432959335001, Train_acc 0.9970407196969697\n",
      "\n",
      "Epoch 79. Loss: 0.012564221711489127, Train_acc 0.9969682835820896\n",
      "\n",
      "Epoch 79. Loss: 0.011364244731488882, Train_acc 0.9970128676470589\n",
      "\n",
      "Epoch 79. Loss: 0.010368690411312633, Train_acc 0.9970561594202898\n",
      "\n",
      "Epoch 79. Loss: 0.01058183135395937, Train_acc 0.9969866071428571\n",
      "\n",
      "Epoch 79. Loss: 0.014966908292225238, Train_acc 0.9968089788732394\n",
      "\n",
      "Epoch 79. Loss: 0.014348253019527706, Train_acc 0.9968532986111112\n",
      "\n",
      "Epoch 79. Loss: 0.013778498239406448, Train_acc 0.996896404109589\n",
      "\n",
      "Epoch 79. Loss: 0.012767338681411894, Train_acc 0.9969383445945946\n",
      "\n",
      "Epoch 79. Loss: 0.015670707608633178, Train_acc 0.996875\n",
      "\n",
      "Epoch 79. Loss: 0.01745798024717534, Train_acc 0.996813322368421\n",
      "\n",
      "Epoch 79. Loss: 0.018683504498155992, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 79. Loss: 0.01702635691380687, Train_acc 0.9966947115384616\n",
      "\n",
      "Epoch 79. Loss: 0.015490806767098048, Train_acc 0.9967365506329114\n",
      "\n",
      "Epoch 79. Loss: 0.014350098745899147, Train_acc 0.99677734375\n",
      "\n",
      "Epoch 79. Loss: 0.01301845031026907, Train_acc 0.9968171296296297\n",
      "\n",
      "Epoch 79. Loss: 0.0198603968356005, Train_acc 0.9966653963414634\n",
      "\n",
      "Epoch 79. Loss: 0.020297274413760155, Train_acc 0.9965173192771084\n",
      "\n",
      "Epoch 79. Loss: 0.018638112867375302, Train_acc 0.9965587797619048\n",
      "\n",
      "Epoch 79. Loss: 0.019677115767747243, Train_acc 0.9965073529411764\n",
      "\n",
      "Epoch 79. Loss: 0.017831901840835884, Train_acc 0.9965479651162791\n",
      "\n",
      "Epoch 79. Loss: 0.016603207147839732, Train_acc 0.9965876436781609\n",
      "\n",
      "Epoch 79. Loss: 0.01545200127591765, Train_acc 0.9966264204545454\n",
      "\n",
      "Epoch 79. Loss: 0.015375471889049495, Train_acc 0.9965765449438202\n",
      "\n",
      "Epoch 79. Loss: 0.01634367137021186, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 79. Loss: 0.015394518065375345, Train_acc 0.9965659340659341\n",
      "\n",
      "Epoch 79. Loss: 0.015801985297729602, Train_acc 0.9965183423913043\n",
      "\n",
      "Epoch 79. Loss: 0.015491034989026218, Train_acc 0.9964717741935484\n",
      "\n",
      "Epoch 79. Loss: 0.01406818595555457, Train_acc 0.9965093085106383\n",
      "\n",
      "Epoch 79. Loss: 0.014131581861022407, Train_acc 0.9964638157894737\n",
      "\n",
      "Epoch 79. Loss: 0.013457609978610242, Train_acc 0.9965006510416666\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79. Loss: 0.012297429788487224, Train_acc 0.9965367268041238\n",
      "\n",
      "Epoch 79. Loss: 0.011870101394543411, Train_acc 0.9965720663265306\n",
      "\n",
      "Epoch 79. Loss: 0.012209650585612084, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 79. Loss: 0.011347213798368358, Train_acc 0.9965625\n",
      "\n",
      "[Epoch 79 Batch 100] Loss: 0.011565783188734398 Training: accuracy=0.996519\n",
      "Epoch 79. Loss: 0.011565783188734398, Train_acc 0.9965191831683168\n",
      "\n",
      "Epoch 79. Loss: 0.0112483919815665, Train_acc 0.9965533088235294\n",
      "\n",
      "Epoch 79. Loss: 0.010566870990226762, Train_acc 0.9965867718446602\n",
      "\n",
      "Epoch 79. Loss: 0.009709549041387525, Train_acc 0.9966195913461539\n",
      "\n",
      "Epoch 79. Loss: 0.008950947954436022, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 79. Loss: 0.0081029911896332, Train_acc 0.9966833726415094\n",
      "\n",
      "Epoch 79. Loss: 0.008343079207308046, Train_acc 0.9966413551401869\n",
      "\n",
      "Epoch 79. Loss: 0.007557884774634869, Train_acc 0.9966724537037037\n",
      "\n",
      "Epoch 79. Loss: 0.007079788120601742, Train_acc 0.9967029816513762\n",
      "\n",
      "Epoch 79. Loss: 0.0072924926403291545, Train_acc 0.9967329545454545\n",
      "\n",
      "Epoch 79. Loss: 0.007135895559769349, Train_acc 0.9967623873873874\n",
      "\n",
      "Epoch 79. Loss: 0.006478530151348764, Train_acc 0.9967912946428571\n",
      "\n",
      "Epoch 79. Loss: 0.00614938321839403, Train_acc 0.9968196902654868\n",
      "\n",
      "Epoch 79. Loss: 0.005559491277606279, Train_acc 0.9968475877192983\n",
      "\n",
      "Epoch 79. Loss: 0.005177152947928897, Train_acc 0.996875\n",
      "\n",
      "Epoch 79. Loss: 0.006976460371625177, Train_acc 0.9968345905172413\n",
      "\n",
      "Epoch 79. Loss: 0.006324881507124083, Train_acc 0.9968616452991453\n",
      "\n",
      "Epoch 79. Loss: 0.006546699186264495, Train_acc 0.996822033898305\n",
      "\n",
      "Epoch 79. Loss: 0.006376173955290634, Train_acc 0.9968487394957983\n",
      "\n",
      "Epoch 79. Loss: 0.00582698590597655, Train_acc 0.996875\n",
      "\n",
      "Epoch 79. Loss: 0.005267917844555339, Train_acc 0.996900826446281\n",
      "\n",
      "Epoch 79. Loss: 0.0047872421795832915, Train_acc 0.9969262295081968\n",
      "\n",
      "Epoch 79. Loss: 0.0043543960117753125, Train_acc 0.9969512195121951\n",
      "\n",
      "Epoch 79. Loss: 0.0039697120764681645, Train_acc 0.9969758064516129\n",
      "\n",
      "Epoch 79. Loss: 0.01101287426163217, Train_acc 0.996875\n",
      "\n",
      "Epoch 79. Loss: 0.009929699541780466, Train_acc 0.9968998015873016\n",
      "\n",
      "Epoch 79. Loss: 0.010475667871522707, Train_acc 0.9968626968503937\n",
      "\n",
      "Epoch 79. Loss: 0.010066368109721962, Train_acc 0.99688720703125\n",
      "\n",
      "Epoch 79. Loss: 0.02047836148149284, Train_acc 0.9966690891472868\n",
      "\n",
      "Epoch 79. Loss: 0.02101724845236402, Train_acc 0.9965745192307692\n",
      "\n",
      "Epoch 79. Loss: 0.018988030387398106, Train_acc 0.9966006679389313\n",
      "\n",
      "Epoch 79. Loss: 0.01779173942664549, Train_acc 0.9966264204545454\n",
      "\n",
      "Epoch 79. Loss: 0.023007192155056762, Train_acc 0.9965343045112782\n",
      "\n",
      "Epoch 79. Loss: 0.027537062412798616, Train_acc 0.9964435634328358\n",
      "\n",
      "Epoch 79. Loss: 0.03376462055411954, Train_acc 0.9962962962962963\n",
      "\n",
      "Epoch 79. Loss: 0.033616128130260284, Train_acc 0.9962660845588235\n",
      "\n",
      "Epoch 79. Loss: 0.030626211977529384, Train_acc 0.9962933394160584\n",
      "\n",
      "Epoch 79. Loss: 0.0284430050662409, Train_acc 0.9962635869565217\n",
      "\n",
      "Epoch 79. Loss: 0.026376788016296986, Train_acc 0.9962904676258992\n",
      "\n",
      "Epoch 79. Loss: 0.029780587952856034, Train_acc 0.9961495535714285\n",
      "\n",
      "Epoch 79. Loss: 0.03481405726211412, Train_acc 0.9960106382978723\n",
      "\n",
      "Epoch 79. Loss: 0.037844934324656215, Train_acc 0.9959286971830986\n",
      "\n",
      "Epoch 79. Loss: 0.03566007942876305, Train_acc 0.995902534965035\n",
      "\n",
      "Epoch 79. Loss: 0.034960225277433574, Train_acc 0.9958224826388888\n",
      "\n",
      "Epoch 79. Loss: 0.034886387038191954, Train_acc 0.9957974137931035\n",
      "\n",
      "Epoch 79. Loss: 0.03427882452126813, Train_acc 0.9957191780821918\n",
      "\n",
      "Epoch 79. Loss: 0.032597388335911685, Train_acc 0.9956951530612245\n",
      "\n",
      "Epoch 79. Loss: 0.030532028608484498, Train_acc 0.9957242398648649\n",
      "\n",
      "Epoch 79. Loss: 0.02811941339601287, Train_acc 0.9957529362416108\n",
      "\n",
      "Epoch 79. Loss: 0.026668918977193912, Train_acc 0.9957291666666667\n",
      "\n",
      "Epoch 79. Loss: 0.026011482939135626, Train_acc 0.9957057119205298\n",
      "\n",
      "Epoch 79. Loss: 0.027548184452961325, Train_acc 0.9956825657894737\n",
      "\n",
      "Epoch 79. Loss: 0.025674348361948526, Train_acc 0.9957107843137255\n",
      "\n",
      "Epoch 79. Loss: 0.025385256555073912, Train_acc 0.9956879058441559\n",
      "\n",
      "Epoch 79. Loss: 0.023228580233210436, Train_acc 0.9957157258064516\n",
      "\n",
      "Epoch 79. Loss: 0.021461802206639152, Train_acc 0.9957431891025641\n",
      "\n",
      "Epoch 79. Loss: 0.020619885235014887, Train_acc 0.9957703025477707\n",
      "\n",
      "Epoch 79. Loss: 0.018893593260668216, Train_acc 0.9957970727848101\n",
      "\n",
      "Epoch 79. Loss: 0.01757099894868359, Train_acc 0.9958235062893082\n",
      "\n",
      "Epoch 79. Loss: 0.016869703787002192, Train_acc 0.995849609375\n",
      "\n",
      "Epoch 79. Loss: 0.01562981797674289, Train_acc 0.9958753881987578\n",
      "\n",
      "Epoch 79. Loss: 0.014930112787356887, Train_acc 0.9959008487654321\n",
      "\n",
      "Epoch 79. Loss: 0.013658390760552211, Train_acc 0.9959259969325154\n",
      "\n",
      "Epoch 79. Loss: 0.01363062790345966, Train_acc 0.9959032012195121\n",
      "\n",
      "Epoch 79. Loss: 0.012860130789311105, Train_acc 0.9959280303030303\n",
      "\n",
      "Epoch 79. Loss: 0.011791263787573314, Train_acc 0.9959525602409639\n",
      "\n",
      "Epoch 79. Loss: 0.011985310984664323, Train_acc 0.9959767964071856\n",
      "\n",
      "Epoch 79. Loss: 0.01235192186207756, Train_acc 0.9959542410714286\n",
      "\n",
      "Epoch 79. Loss: 0.011356367589052183, Train_acc 0.9959781804733728\n",
      "\n",
      "Epoch 79. Loss: 0.010518167786463197, Train_acc 0.9960018382352941\n",
      "\n",
      "Epoch 79. Loss: 0.009498829436146218, Train_acc 0.9960252192982456\n",
      "\n",
      "Epoch 79. Loss: 0.008778871013940572, Train_acc 0.9960483284883721\n",
      "\n",
      "Epoch 79. Loss: 0.008075838282380579, Train_acc 0.9960711705202312\n",
      "\n",
      "Epoch 79. Loss: 0.007447394677332709, Train_acc 0.99609375\n",
      "\n",
      "Epoch 79. Loss: 0.007674093759058419, Train_acc 0.9960714285714286\n",
      "\n",
      "Epoch 79. Loss: 0.008037753950207087, Train_acc 0.9960493607954546\n",
      "\n",
      "Epoch 79. Loss: 0.007300031252552482, Train_acc 0.9960716807909604\n",
      "\n",
      "Epoch 79. Loss: 0.006648182924963009, Train_acc 0.99609375\n",
      "\n",
      "Epoch 79. Loss: 0.006651504527890955, Train_acc 0.9960719273743017\n",
      "\n",
      "Epoch 79. Loss: 0.006054571177772902, Train_acc 0.99609375\n",
      "\n",
      "Epoch 79. Loss: 0.006558254240046939, Train_acc 0.9960721685082873\n",
      "\n",
      "Epoch 79. Loss: 0.006132271916575135, Train_acc 0.99609375\n",
      "\n",
      "Epoch 79. Loss: 0.0062494231384905286, Train_acc 0.9960724043715847\n",
      "\n",
      "Epoch 79. Loss: 0.00574855273561884, Train_acc 0.99609375\n",
      "\n",
      "Epoch 79. Loss: 0.005200309300313896, Train_acc 0.9961148648648649\n",
      "\n",
      "Epoch 79. Loss: 0.004786981103601759, Train_acc 0.996135752688172\n",
      "\n",
      "Epoch 79. Loss: 0.004320740806377863, Train_acc 0.9961564171122995\n",
      "\n",
      "Epoch 79. Loss: 0.004177399727538468, Train_acc 0.9961768617021277\n",
      "\n",
      "Epoch 79. Loss: 0.003783322260339588, Train_acc 0.99619708994709\n",
      "\n",
      "Epoch 79. Loss: 0.0034313715448483348, Train_acc 0.9962171052631579\n",
      "\n",
      "Epoch 79. Loss: 0.0031868727549430303, Train_acc 0.9962369109947644\n",
      "\n",
      "Epoch 79. Loss: 0.0028872481304207734, Train_acc 0.9962565104166666\n",
      "\n",
      "Epoch 79. Loss: 0.002628399153131742, Train_acc 0.9962759067357513\n",
      "\n",
      "Epoch 79. Loss: 0.003528460013489573, Train_acc 0.9962548324742269\n",
      "\n",
      "Epoch 79. Loss: 0.0034809438574275216, Train_acc 0.9962740384615385\n",
      "\n",
      "Epoch 79. Loss: 0.0031393322233173445, Train_acc 0.99628\n",
      "\n",
      "Epoch 80. Loss: 0.003463444371564376, Train_acc 1.0\n",
      "\n",
      "Epoch 80. Loss: 0.0031335429350486587, Train_acc 1.0\n",
      "\n",
      "Epoch 80. Loss: 0.0028262606617310685, Train_acc 1.0\n",
      "\n",
      "Epoch 80. Loss: 0.0025557102841314936, Train_acc 1.0\n",
      "\n",
      "Epoch 80. Loss: 0.0025115224019522007, Train_acc 1.0\n",
      "\n",
      "Epoch 80. Loss: 0.002283947249024748, Train_acc 1.0\n",
      "\n",
      "Epoch 80. Loss: 0.0021441803409986697, Train_acc 1.0\n",
      "\n",
      "Epoch 80. Loss: 0.0019791364313997035, Train_acc 1.0\n",
      "\n",
      "Epoch 80. Loss: 0.0017877157094982655, Train_acc 1.0\n",
      "\n",
      "Epoch 80. Loss: 0.001624728059665402, Train_acc 1.0\n",
      "\n",
      "Epoch 80. Loss: 0.0018770296343231562, Train_acc 1.0\n",
      "\n",
      "Epoch 80. Loss: 0.0017040305837841508, Train_acc 1.0\n",
      "\n",
      "Epoch 80. Loss: 0.0016194090866164872, Train_acc 1.0\n",
      "\n",
      "Epoch 80. Loss: 0.0014718994316125149, Train_acc 1.0\n",
      "\n",
      "Epoch 80. Loss: 0.0013519318843258233, Train_acc 1.0\n",
      "\n",
      "Epoch 80. Loss: 0.001377943206261648, Train_acc 1.0\n",
      "\n",
      "Epoch 80. Loss: 0.002451097896782505, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 80. Loss: 0.0022327731830016056, Train_acc 0.9995659722222222\n",
      "\n",
      "Epoch 80. Loss: 0.0020117060606999315, Train_acc 0.9995888157894737\n",
      "\n",
      "Epoch 80. Loss: 0.0019470796840926812, Train_acc 0.999609375\n",
      "\n",
      "Epoch 80. Loss: 0.0017624334206445304, Train_acc 0.9996279761904762\n",
      "\n",
      "Epoch 80. Loss: 0.00271471629681557, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 80. Loss: 0.0024717809030476473, Train_acc 0.9993206521739131\n",
      "\n",
      "Epoch 80. Loss: 0.0022325000614673582, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 80. Loss: 0.002052994439631762, Train_acc 0.999375\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80. Loss: 0.0018567983682452323, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 80. Loss: 0.0016943614703350453, Train_acc 0.9994212962962963\n",
      "\n",
      "Epoch 80. Loss: 0.0015319759910745418, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 80. Loss: 0.0014150713109248576, Train_acc 0.9994612068965517\n",
      "\n",
      "Epoch 80. Loss: 0.0012770771314942046, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 80. Loss: 0.0011581443680190459, Train_acc 0.9994959677419355\n",
      "\n",
      "Epoch 80. Loss: 0.0014580906290140821, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 80. Loss: 0.001318592318472824, Train_acc 0.9995265151515151\n",
      "\n",
      "Epoch 80. Loss: 0.0012626569068845913, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 80. Loss: 0.001198038530774427, Train_acc 0.9995535714285714\n",
      "\n",
      "Epoch 80. Loss: 0.0010883790375365988, Train_acc 0.9995659722222222\n",
      "\n",
      "Epoch 80. Loss: 0.0010050328267236434, Train_acc 0.9995777027027027\n",
      "\n",
      "Epoch 80. Loss: 0.000922758329535377, Train_acc 0.9995888157894737\n",
      "\n",
      "Epoch 80. Loss: 0.000927030414510386, Train_acc 0.9995993589743589\n",
      "\n",
      "Epoch 80. Loss: 0.000843232446687177, Train_acc 0.999609375\n",
      "\n",
      "Epoch 80. Loss: 0.0007701123810379627, Train_acc 0.9996189024390244\n",
      "\n",
      "Epoch 80. Loss: 0.0007140649958100325, Train_acc 0.9996279761904762\n",
      "\n",
      "Epoch 80. Loss: 0.004959749156562662, Train_acc 0.9994549418604651\n",
      "\n",
      "Epoch 80. Loss: 0.0044774408554472496, Train_acc 0.9994673295454546\n",
      "\n",
      "Epoch 80. Loss: 0.004034046618216248, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 80. Loss: 0.003704912091186355, Train_acc 0.9994904891304348\n",
      "\n",
      "Epoch 80. Loss: 0.0033477239068202508, Train_acc 0.999501329787234\n",
      "\n",
      "Epoch 80. Loss: 0.003061315010126516, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 80. Loss: 0.0028432923814101533, Train_acc 0.9995216836734694\n",
      "\n",
      "Epoch 80. Loss: 0.0025673940762086563, Train_acc 0.99953125\n",
      "\n",
      "Epoch 80. Loss: 0.0023346083681528174, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 80. Loss: 0.0021036503821764726, Train_acc 0.9995492788461539\n",
      "\n",
      "Epoch 80. Loss: 0.0019021728956255285, Train_acc 0.9995577830188679\n",
      "\n",
      "Epoch 80. Loss: 0.0017650457949480833, Train_acc 0.9995659722222222\n",
      "\n",
      "Epoch 80. Loss: 0.0015976829410576973, Train_acc 0.9995738636363637\n",
      "\n",
      "Epoch 80. Loss: 0.0014662293823431048, Train_acc 0.9995814732142857\n",
      "\n",
      "Epoch 80. Loss: 0.0015032204964752598, Train_acc 0.9995888157894737\n",
      "\n",
      "Epoch 80. Loss: 0.0013841795814070646, Train_acc 0.9995959051724138\n",
      "\n",
      "Epoch 80. Loss: 0.0012613806144313145, Train_acc 0.9996027542372882\n",
      "\n",
      "Epoch 80. Loss: 0.001315993428721976, Train_acc 0.999609375\n",
      "\n",
      "Epoch 80. Loss: 0.00122736908711973, Train_acc 0.9996157786885246\n",
      "\n",
      "Epoch 80. Loss: 0.0011220516605816209, Train_acc 0.9996219758064516\n",
      "\n",
      "Epoch 80. Loss: 0.0010184194425140738, Train_acc 0.9996279761904762\n",
      "\n",
      "Epoch 80. Loss: 0.0009474108383962067, Train_acc 0.9996337890625\n",
      "\n",
      "Epoch 80. Loss: 0.0008696753147777366, Train_acc 0.9996394230769231\n",
      "\n",
      "Epoch 80. Loss: 0.0008522691627959712, Train_acc 0.9996448863636364\n",
      "\n",
      "Epoch 80. Loss: 0.0007747416270287233, Train_acc 0.9996501865671642\n",
      "\n",
      "Epoch 80. Loss: 0.0007045326127774028, Train_acc 0.9996553308823529\n",
      "\n",
      "Epoch 80. Loss: 0.0006583345769345619, Train_acc 0.9996603260869565\n",
      "\n",
      "Epoch 80. Loss: 0.0006341722368923819, Train_acc 0.9996651785714286\n",
      "\n",
      "Epoch 80. Loss: 0.0006126890781418305, Train_acc 0.9996698943661971\n",
      "\n",
      "Epoch 80. Loss: 0.002018719352295621, Train_acc 0.9995659722222222\n",
      "\n",
      "Epoch 80. Loss: 0.001837363254307023, Train_acc 0.9995719178082192\n",
      "\n",
      "Epoch 80. Loss: 0.001686650125614534, Train_acc 0.9995777027027027\n",
      "\n",
      "Epoch 80. Loss: 0.0016052647648327621, Train_acc 0.9995833333333334\n",
      "\n",
      "Epoch 80. Loss: 0.0014616175539535609, Train_acc 0.9995888157894737\n",
      "\n",
      "Epoch 80. Loss: 0.0013547675850896757, Train_acc 0.9995941558441559\n",
      "\n",
      "Epoch 80. Loss: 0.0013099536880564293, Train_acc 0.9995993589743589\n",
      "\n",
      "Epoch 80. Loss: 0.001734007667873347, Train_acc 0.9996044303797469\n",
      "\n",
      "Epoch 80. Loss: 0.0015945302734794865, Train_acc 0.999609375\n",
      "\n",
      "Epoch 80. Loss: 0.0014371149371785455, Train_acc 0.9996141975308642\n",
      "\n",
      "Epoch 80. Loss: 0.00130582935879879, Train_acc 0.9996189024390244\n",
      "\n",
      "Epoch 80. Loss: 0.001194851222955088, Train_acc 0.9996234939759037\n",
      "\n",
      "Epoch 80. Loss: 0.0012666864398773615, Train_acc 0.9996279761904762\n",
      "\n",
      "Epoch 80. Loss: 0.0012927133357627189, Train_acc 0.9996323529411765\n",
      "\n",
      "Epoch 80. Loss: 0.0011661038239681046, Train_acc 0.9996366279069767\n",
      "\n",
      "Epoch 80. Loss: 0.0010576186525961839, Train_acc 0.9996408045977011\n",
      "\n",
      "Epoch 80. Loss: 0.0009680174313453435, Train_acc 0.9996448863636364\n",
      "\n",
      "Epoch 80. Loss: 0.0008846465588145791, Train_acc 0.9996488764044944\n",
      "\n",
      "Epoch 80. Loss: 0.0008182137921719817, Train_acc 0.9996527777777777\n",
      "\n",
      "Epoch 80. Loss: 0.0007632114733949587, Train_acc 0.9996565934065934\n",
      "\n",
      "Epoch 80. Loss: 0.000698200448555171, Train_acc 0.9996603260869565\n",
      "\n",
      "Epoch 80. Loss: 0.0006454590174456339, Train_acc 0.9996639784946236\n",
      "\n",
      "Epoch 80. Loss: 0.0005873919223094271, Train_acc 0.9996675531914894\n",
      "\n",
      "Epoch 80. Loss: 0.0027380370969484107, Train_acc 0.9995888157894737\n",
      "\n",
      "Epoch 80. Loss: 0.0025321776589763783, Train_acc 0.9995930989583334\n",
      "\n",
      "Epoch 80. Loss: 0.002476300627381738, Train_acc 0.999597293814433\n",
      "\n",
      "Epoch 80. Loss: 0.002312085000728714, Train_acc 0.9996014030612245\n",
      "\n",
      "Epoch 80. Loss: 0.0021818852441692184, Train_acc 0.9996054292929293\n",
      "\n",
      "Epoch 80. Loss: 0.001969342923978947, Train_acc 0.999609375\n",
      "\n",
      "[Epoch 80 Batch 100] Loss: 0.0017831018620144419 Training: accuracy=0.999613\n",
      "Epoch 80. Loss: 0.0017831018620144419, Train_acc 0.9996132425742574\n",
      "\n",
      "Epoch 80. Loss: 0.0021296311087230825, Train_acc 0.9996170343137255\n",
      "\n",
      "Epoch 80. Loss: 0.0019793082070673988, Train_acc 0.9996207524271845\n",
      "\n",
      "Epoch 80. Loss: 0.0019060323052697318, Train_acc 0.9996243990384616\n",
      "\n",
      "Epoch 80. Loss: 0.0021173684798711187, Train_acc 0.9996279761904762\n",
      "\n",
      "Epoch 80. Loss: 0.001970197367985947, Train_acc 0.9996314858490566\n",
      "\n",
      "Epoch 80. Loss: 0.0017743808970433726, Train_acc 0.999634929906542\n",
      "\n",
      "Epoch 80. Loss: 0.0016024966032660067, Train_acc 0.9996383101851852\n",
      "\n",
      "Epoch 80. Loss: 0.0018976971164068037, Train_acc 0.999641628440367\n",
      "\n",
      "Epoch 80. Loss: 0.0017356210935191843, Train_acc 0.9996448863636364\n",
      "\n",
      "Epoch 80. Loss: 0.0022219905283817534, Train_acc 0.9995777027027027\n",
      "\n",
      "Epoch 80. Loss: 0.0020041635286247475, Train_acc 0.9995814732142857\n",
      "\n",
      "Epoch 80. Loss: 0.0018078057085574432, Train_acc 0.9995851769911505\n",
      "\n",
      "Epoch 80. Loss: 0.001763476805342057, Train_acc 0.9995888157894737\n",
      "\n",
      "Epoch 80. Loss: 0.0015958964296334478, Train_acc 0.9995923913043478\n",
      "\n",
      "Epoch 80. Loss: 0.0017538598915028715, Train_acc 0.9995959051724138\n",
      "\n",
      "Epoch 80. Loss: 0.0031753080403883584, Train_acc 0.9995325854700855\n",
      "\n",
      "Epoch 80. Loss: 0.0028876562560616204, Train_acc 0.9995365466101694\n",
      "\n",
      "Epoch 80. Loss: 0.0026061232655628158, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 80. Loss: 0.0023496968963749977, Train_acc 0.9995442708333333\n",
      "\n",
      "Epoch 80. Loss: 0.0021168836579655726, Train_acc 0.9995480371900827\n",
      "\n",
      "Epoch 80. Loss: 0.001913059830370845, Train_acc 0.9995517418032787\n",
      "\n",
      "Epoch 80. Loss: 0.0017265087820410678, Train_acc 0.9995553861788617\n",
      "\n",
      "Epoch 80. Loss: 0.001587227086911644, Train_acc 0.9995589717741935\n",
      "\n",
      "Epoch 80. Loss: 0.0020177565483957935, Train_acc 0.9995\n",
      "\n",
      "Epoch 80. Loss: 0.0022294760560581453, Train_acc 0.9995039682539683\n",
      "\n",
      "Epoch 80. Loss: 0.002246965135723892, Train_acc 0.999507874015748\n",
      "\n",
      "Epoch 80. Loss: 0.0021968983453390387, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 80. Loss: 0.0020021279060237385, Train_acc 0.999515503875969\n",
      "\n",
      "Epoch 80. Loss: 0.0021903203546308975, Train_acc 0.9995192307692308\n",
      "\n",
      "Epoch 80. Loss: 0.001985688811531883, Train_acc 0.9995229007633588\n",
      "\n",
      "Epoch 80. Loss: 0.001958818525310208, Train_acc 0.9995265151515151\n",
      "\n",
      "Epoch 80. Loss: 0.002248357691454157, Train_acc 0.9995300751879699\n",
      "\n",
      "Epoch 80. Loss: 0.0020357347728696407, Train_acc 0.9995335820895522\n",
      "\n",
      "Epoch 80. Loss: 0.0018353200427139145, Train_acc 0.999537037037037\n",
      "\n",
      "Epoch 80. Loss: 0.001678290504504607, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 80. Loss: 0.0015144879355284305, Train_acc 0.9995437956204379\n",
      "\n",
      "Epoch 80. Loss: 0.0016203419859411774, Train_acc 0.9995471014492754\n",
      "\n",
      "Epoch 80. Loss: 0.001564123098309558, Train_acc 0.9995503597122302\n",
      "\n",
      "Epoch 80. Loss: 0.0014668982356651618, Train_acc 0.9995535714285714\n",
      "\n",
      "Epoch 80. Loss: 0.001602280524994194, Train_acc 0.9995567375886525\n",
      "\n",
      "Epoch 80. Loss: 0.0014462649223525067, Train_acc 0.9995598591549296\n",
      "\n",
      "Epoch 80. Loss: 0.0016226194772334759, Train_acc 0.9995629370629371\n",
      "\n",
      "Epoch 80. Loss: 0.0014676260343609274, Train_acc 0.9995659722222222\n",
      "\n",
      "Epoch 80. Loss: 0.001395495407819869, Train_acc 0.9995689655172414\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80. Loss: 0.0012758466617609535, Train_acc 0.9995719178082192\n",
      "\n",
      "Epoch 80. Loss: 0.001159579194680942, Train_acc 0.9995748299319728\n",
      "\n",
      "Epoch 80. Loss: 0.0010524884796640828, Train_acc 0.9995777027027027\n",
      "\n",
      "Epoch 80. Loss: 0.0010811359131747385, Train_acc 0.9995805369127517\n",
      "\n",
      "Epoch 80. Loss: 0.0009752925352292224, Train_acc 0.9995833333333334\n",
      "\n",
      "Epoch 80. Loss: 0.0008967012358615627, Train_acc 0.9995860927152318\n",
      "\n",
      "Epoch 80. Loss: 0.0008199242575972749, Train_acc 0.9995888157894737\n",
      "\n",
      "Epoch 80. Loss: 0.0007641328287822281, Train_acc 0.9995915032679739\n",
      "\n",
      "Epoch 80. Loss: 0.0007684429486928679, Train_acc 0.9995941558441559\n",
      "\n",
      "Epoch 80. Loss: 0.002046479098529067, Train_acc 0.9995463709677419\n",
      "\n",
      "Epoch 80. Loss: 0.0022130268672753395, Train_acc 0.9995492788461539\n",
      "\n",
      "Epoch 80. Loss: 0.0021309626330866535, Train_acc 0.9995521496815286\n",
      "\n",
      "Epoch 80. Loss: 0.0019225226414086535, Train_acc 0.9995549841772152\n",
      "\n",
      "Epoch 80. Loss: 0.0017312596034592383, Train_acc 0.9995577830188679\n",
      "\n",
      "Epoch 80. Loss: 0.001567193051443673, Train_acc 0.999560546875\n",
      "\n",
      "Epoch 80. Loss: 0.001573432484227726, Train_acc 0.9995632763975155\n",
      "\n",
      "Epoch 80. Loss: 0.0015858852900564456, Train_acc 0.9995659722222222\n",
      "\n",
      "Epoch 80. Loss: 0.0014325702605332289, Train_acc 0.9995686349693251\n",
      "\n",
      "Epoch 80. Loss: 0.002429439168514492, Train_acc 0.9995236280487805\n",
      "\n",
      "Epoch 80. Loss: 0.005422369949229075, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 80. Loss: 0.005552172250784201, Train_acc 0.9994352409638554\n",
      "\n",
      "Epoch 80. Loss: 0.0050012380538075624, Train_acc 0.999438622754491\n",
      "\n",
      "Epoch 80. Loss: 0.008151525094302546, Train_acc 0.9993954613095238\n",
      "\n",
      "Epoch 80. Loss: 0.007568334281280981, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 80. Loss: 0.013197348034234654, Train_acc 0.9993106617647058\n",
      "\n",
      "Epoch 80. Loss: 0.01190490744911855, Train_acc 0.9993146929824561\n",
      "\n",
      "Epoch 80. Loss: 0.01184787744197153, Train_acc 0.9992732558139535\n",
      "\n",
      "Epoch 80. Loss: 0.013975047861751046, Train_acc 0.9992322976878613\n",
      "\n",
      "Epoch 80. Loss: 0.019346432055726163, Train_acc 0.9991469109195402\n",
      "\n",
      "Epoch 80. Loss: 0.01835061741905914, Train_acc 0.9991071428571429\n",
      "\n",
      "Epoch 80. Loss: 0.016606443063039388, Train_acc 0.9991122159090909\n",
      "\n",
      "Epoch 80. Loss: 0.015050923957670157, Train_acc 0.999117231638418\n",
      "\n",
      "Epoch 80. Loss: 0.014504859586129569, Train_acc 0.9990783005617978\n",
      "\n",
      "Epoch 80. Loss: 0.013177485158655033, Train_acc 0.9990834497206704\n",
      "\n",
      "Epoch 80. Loss: 0.01196098137180178, Train_acc 0.9990885416666667\n",
      "\n",
      "Epoch 80. Loss: 0.010906892301970736, Train_acc 0.9990935773480663\n",
      "\n",
      "Epoch 80. Loss: 0.011999686985314503, Train_acc 0.9990556318681318\n",
      "\n",
      "Epoch 80. Loss: 0.013778256449789358, Train_acc 0.9989754098360656\n",
      "\n",
      "Epoch 80. Loss: 0.012929962753078835, Train_acc 0.9989809782608695\n",
      "\n",
      "Epoch 80. Loss: 0.011849890823167411, Train_acc 0.9989864864864865\n",
      "\n",
      "Epoch 80. Loss: 0.011435911010952456, Train_acc 0.998991935483871\n",
      "\n",
      "Epoch 80. Loss: 0.011637407404558358, Train_acc 0.9989555481283422\n",
      "\n",
      "Epoch 80. Loss: 0.017842585917451827, Train_acc 0.9988779920212766\n",
      "\n",
      "Epoch 80. Loss: 0.020648858019237683, Train_acc 0.9988012566137566\n",
      "\n",
      "Epoch 80. Loss: 0.018981419807098776, Train_acc 0.9988075657894737\n",
      "\n",
      "Epoch 80. Loss: 0.017223326855530564, Train_acc 0.9988138089005235\n",
      "\n",
      "Epoch 80. Loss: 0.01557269822003787, Train_acc 0.9988199869791666\n",
      "\n",
      "Epoch 80. Loss: 0.014221452900438117, Train_acc 0.9988261010362695\n",
      "\n",
      "Epoch 80. Loss: 0.014862053002716846, Train_acc 0.9987516108247423\n",
      "\n",
      "Epoch 80. Loss: 0.014403081042291295, Train_acc 0.9987580128205128\n",
      "\n",
      "Epoch 80. Loss: 0.013257714322407459, Train_acc 0.99876\n",
      "\n",
      "Epoch 81. Loss: 0.01290538918483205, Train_acc 1.0\n",
      "\n",
      "Epoch 81. Loss: 0.013351222603094107, Train_acc 0.99609375\n",
      "\n",
      "Epoch 81. Loss: 0.012707634549055867, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 81. Loss: 0.011710392478374576, Train_acc 0.99609375\n",
      "\n",
      "Epoch 81. Loss: 0.010671843156718852, Train_acc 0.996875\n",
      "\n",
      "Epoch 81. Loss: 0.011524037367555775, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 81. Loss: 0.011493255582261037, Train_acc 0.9944196428571429\n",
      "\n",
      "Epoch 81. Loss: 0.01204856214237924, Train_acc 0.994140625\n",
      "\n",
      "Epoch 81. Loss: 0.010911399132760308, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 81. Loss: 0.010154749240243682, Train_acc 0.9953125\n",
      "\n",
      "Epoch 81. Loss: 0.00920212600550957, Train_acc 0.9957386363636364\n",
      "\n",
      "Epoch 81. Loss: 0.008460087241279252, Train_acc 0.99609375\n",
      "\n",
      "Epoch 81. Loss: 0.010031825262201281, Train_acc 0.9957932692307693\n",
      "\n",
      "Epoch 81. Loss: 0.009344994411409603, Train_acc 0.99609375\n",
      "\n",
      "Epoch 81. Loss: 0.008522809841780997, Train_acc 0.9963541666666667\n",
      "\n",
      "Epoch 81. Loss: 0.007732199053612697, Train_acc 0.99658203125\n",
      "\n",
      "Epoch 81. Loss: 0.007096895029602064, Train_acc 0.9967830882352942\n",
      "\n",
      "Epoch 81. Loss: 0.006432584120136973, Train_acc 0.9969618055555556\n",
      "\n",
      "Epoch 81. Loss: 0.0060917000710688325, Train_acc 0.9971217105263158\n",
      "\n",
      "Epoch 81. Loss: 0.0057564719636117485, Train_acc 0.997265625\n",
      "\n",
      "Epoch 81. Loss: 0.005336271864745772, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 81. Loss: 0.004868403915894036, Train_acc 0.9975142045454546\n",
      "\n",
      "Epoch 81. Loss: 0.005906998748480085, Train_acc 0.9972826086956522\n",
      "\n",
      "Epoch 81. Loss: 0.005381620773815412, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 81. Loss: 0.008148239343592493, Train_acc 0.9965625\n",
      "\n",
      "Epoch 81. Loss: 0.007695940218549044, Train_acc 0.9966947115384616\n",
      "\n",
      "Epoch 81. Loss: 0.0070487839974405515, Train_acc 0.9968171296296297\n",
      "\n",
      "Epoch 81. Loss: 0.0063881091793342, Train_acc 0.9969308035714286\n",
      "\n",
      "Epoch 81. Loss: 0.005812065316752067, Train_acc 0.9970366379310345\n",
      "\n",
      "Epoch 81. Loss: 0.005259912853804279, Train_acc 0.9971354166666667\n",
      "\n",
      "Epoch 81. Loss: 0.005864373948008164, Train_acc 0.9969758064516129\n",
      "\n",
      "Epoch 81. Loss: 0.005780939032879779, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 81. Loss: 0.005885579361987689, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 81. Loss: 0.006306698869442266, Train_acc 0.9970128676470589\n",
      "\n",
      "Epoch 81. Loss: 0.005714534726803479, Train_acc 0.9970982142857143\n",
      "\n",
      "Epoch 81. Loss: 0.005186997915648276, Train_acc 0.9971788194444444\n",
      "\n",
      "Epoch 81. Loss: 0.004872886596926619, Train_acc 0.9972550675675675\n",
      "\n",
      "Epoch 81. Loss: 0.00477156834998748, Train_acc 0.997327302631579\n",
      "\n",
      "Epoch 81. Loss: 0.004411324384259624, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 81. Loss: 0.007108147760433652, Train_acc 0.997265625\n",
      "\n",
      "Epoch 81. Loss: 0.006420057781990236, Train_acc 0.9973323170731707\n",
      "\n",
      "Epoch 81. Loss: 0.007930362315585493, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 81. Loss: 0.011753149263510359, Train_acc 0.997093023255814\n",
      "\n",
      "Epoch 81. Loss: 0.014451376660867857, Train_acc 0.9968039772727273\n",
      "\n",
      "Epoch 81. Loss: 0.01312441712397724, Train_acc 0.996875\n",
      "\n",
      "Epoch 81. Loss: 0.011820594710330517, Train_acc 0.9969429347826086\n",
      "\n",
      "Epoch 81. Loss: 0.010775718821707681, Train_acc 0.9970079787234043\n",
      "\n",
      "Epoch 81. Loss: 0.00994552288602887, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 81. Loss: 0.009291062733019278, Train_acc 0.9971301020408163\n",
      "\n",
      "Epoch 81. Loss: 0.008381084137377787, Train_acc 0.9971875\n",
      "\n",
      "Epoch 81. Loss: 0.007583574839531391, Train_acc 0.9972426470588235\n",
      "\n",
      "Epoch 81. Loss: 0.007070937084569641, Train_acc 0.9972956730769231\n",
      "\n",
      "Epoch 81. Loss: 0.00789710059232781, Train_acc 0.9971992924528302\n",
      "\n",
      "Epoch 81. Loss: 0.007170441863020686, Train_acc 0.9972511574074074\n",
      "\n",
      "Epoch 81. Loss: 0.00884053259379902, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 81. Loss: 0.01217453315216814, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 81. Loss: 0.014152043023930621, Train_acc 0.996984649122807\n",
      "\n",
      "Epoch 81. Loss: 0.012773206483905732, Train_acc 0.9970366379310345\n",
      "\n",
      "Epoch 81. Loss: 0.012230864982606667, Train_acc 0.9969544491525424\n",
      "\n",
      "Epoch 81. Loss: 0.011146291506448415, Train_acc 0.9970052083333333\n",
      "\n",
      "Epoch 81. Loss: 0.010240660035677876, Train_acc 0.9970543032786885\n",
      "\n",
      "Epoch 81. Loss: 0.010451818338693493, Train_acc 0.9969758064516129\n",
      "\n",
      "Epoch 81. Loss: 0.009915938217560632, Train_acc 0.9970238095238095\n",
      "\n",
      "Epoch 81. Loss: 0.008998251338075264, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 81. Loss: 0.00835222212979555, Train_acc 0.9971153846153846\n",
      "\n",
      "Epoch 81. Loss: 0.008926449065739153, Train_acc 0.9970407196969697\n",
      "\n",
      "Epoch 81. Loss: 0.008232706884407318, Train_acc 0.9970848880597015\n",
      "\n",
      "Epoch 81. Loss: 0.008369384180632218, Train_acc 0.9970128676470589\n",
      "\n",
      "Epoch 81. Loss: 0.009566049512738274, Train_acc 0.9969429347826086\n",
      "\n",
      "Epoch 81. Loss: 0.010846070486170907, Train_acc 0.996875\n",
      "\n",
      "Epoch 81. Loss: 0.0100448217767741, Train_acc 0.996919014084507\n",
      "\n",
      "Epoch 81. Loss: 0.009419138944440995, Train_acc 0.9969618055555556\n",
      "\n",
      "Epoch 81. Loss: 0.008699480060154719, Train_acc 0.9970034246575342\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81. Loss: 0.008528620636908284, Train_acc 0.9969383445945946\n",
      "\n",
      "Epoch 81. Loss: 0.011152677434487408, Train_acc 0.996875\n",
      "\n",
      "Epoch 81. Loss: 0.010114385073437482, Train_acc 0.9969161184210527\n",
      "\n",
      "Epoch 81. Loss: 0.009258350531712195, Train_acc 0.9969561688311688\n",
      "\n",
      "Epoch 81. Loss: 0.008373103238117715, Train_acc 0.9969951923076923\n",
      "\n",
      "Epoch 81. Loss: 0.007877568811264949, Train_acc 0.9970332278481012\n",
      "\n",
      "Epoch 81. Loss: 0.007427583349574194, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 81. Loss: 0.006893451492595898, Train_acc 0.9971064814814815\n",
      "\n",
      "Epoch 81. Loss: 0.006364310485202724, Train_acc 0.997141768292683\n",
      "\n",
      "Epoch 81. Loss: 0.005803911406775478, Train_acc 0.9971762048192772\n",
      "\n",
      "Epoch 81. Loss: 0.009692346843165306, Train_acc 0.9970238095238095\n",
      "\n",
      "Epoch 81. Loss: 0.008769219238682522, Train_acc 0.9970588235294118\n",
      "\n",
      "Epoch 81. Loss: 0.009566731112412154, Train_acc 0.9969113372093024\n",
      "\n",
      "Epoch 81. Loss: 0.008876247455294316, Train_acc 0.9969468390804598\n",
      "\n",
      "Epoch 81. Loss: 0.008200951823620843, Train_acc 0.9969815340909091\n",
      "\n",
      "Epoch 81. Loss: 0.007473290587233093, Train_acc 0.9970154494382022\n",
      "\n",
      "Epoch 81. Loss: 0.006737005692203225, Train_acc 0.9970486111111111\n",
      "\n",
      "Epoch 81. Loss: 0.006109592987080297, Train_acc 0.9970810439560439\n",
      "\n",
      "Epoch 81. Loss: 0.005662597125452651, Train_acc 0.9971127717391305\n",
      "\n",
      "Epoch 81. Loss: 0.005144554328363964, Train_acc 0.9971438172043011\n",
      "\n",
      "Epoch 81. Loss: 0.004687774293948109, Train_acc 0.9971742021276596\n",
      "\n",
      "Epoch 81. Loss: 0.005364047446097937, Train_acc 0.9971217105263158\n",
      "\n",
      "Epoch 81. Loss: 0.0048654605418361405, Train_acc 0.9971516927083334\n",
      "\n",
      "Epoch 81. Loss: 0.005239253518275962, Train_acc 0.9971005154639175\n",
      "\n",
      "Epoch 81. Loss: 0.0048559116466910055, Train_acc 0.9971301020408163\n",
      "\n",
      "Epoch 81. Loss: 0.0045433297388542074, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 81. Loss: 0.00446294575906143, Train_acc 0.9971875\n",
      "\n",
      "[Epoch 81 Batch 100] Loss: 0.004436074493241418 Training: accuracy=0.997215\n",
      "Epoch 81. Loss: 0.004436074493241418, Train_acc 0.9972153465346535\n",
      "\n",
      "Epoch 81. Loss: 0.005269882684569457, Train_acc 0.9971660539215687\n",
      "\n",
      "Epoch 81. Loss: 0.004768746935432835, Train_acc 0.9971935679611651\n",
      "\n",
      "Epoch 81. Loss: 0.004453678666037933, Train_acc 0.9972205528846154\n",
      "\n",
      "Epoch 81. Loss: 0.0040526193323948525, Train_acc 0.9972470238095238\n",
      "\n",
      "Epoch 81. Loss: 0.0038195135412262566, Train_acc 0.9972729952830188\n",
      "\n",
      "Epoch 81. Loss: 0.003884521166695358, Train_acc 0.9972984813084113\n",
      "\n",
      "Epoch 81. Loss: 0.0035292069857052284, Train_acc 0.9973234953703703\n",
      "\n",
      "Epoch 81. Loss: 0.0032367724578308004, Train_acc 0.9973480504587156\n",
      "\n",
      "Epoch 81. Loss: 0.0029929904828032345, Train_acc 0.997372159090909\n",
      "\n",
      "Epoch 81. Loss: 0.002762221147257655, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 81. Loss: 0.002511698721817719, Train_acc 0.9974190848214286\n",
      "\n",
      "Epoch 81. Loss: 0.002837320622254837, Train_acc 0.997441924778761\n",
      "\n",
      "Epoch 81. Loss: 0.0026175294834575166, Train_acc 0.9974643640350878\n",
      "\n",
      "Epoch 81. Loss: 0.0023644222805135015, Train_acc 0.9974864130434783\n",
      "\n",
      "Epoch 81. Loss: 0.0025862973490416315, Train_acc 0.9975080818965517\n",
      "\n",
      "Epoch 81. Loss: 0.0024461559203171114, Train_acc 0.9975293803418803\n",
      "\n",
      "Epoch 81. Loss: 0.004854895479700272, Train_acc 0.9974841101694916\n",
      "\n",
      "Epoch 81. Loss: 0.005356467137981628, Train_acc 0.9975052521008403\n",
      "\n",
      "Epoch 81. Loss: 0.005599809731765844, Train_acc 0.9974609375\n",
      "\n",
      "Epoch 81. Loss: 0.005297850956111482, Train_acc 0.9974819214876033\n",
      "\n",
      "Epoch 81. Loss: 0.0050426441561484325, Train_acc 0.9975025614754098\n",
      "\n",
      "Epoch 81. Loss: 0.004554515497856944, Train_acc 0.9975228658536586\n",
      "\n",
      "Epoch 81. Loss: 0.004157342698000991, Train_acc 0.9975428427419355\n",
      "\n",
      "Epoch 81. Loss: 0.0042759983412830145, Train_acc 0.9975625\n",
      "\n",
      "Epoch 81. Loss: 0.0038693048697790865, Train_acc 0.9975818452380952\n",
      "\n",
      "Epoch 81. Loss: 0.003511753093115809, Train_acc 0.9976008858267716\n",
      "\n",
      "Epoch 81. Loss: 0.003163310617477009, Train_acc 0.99761962890625\n",
      "\n",
      "Epoch 81. Loss: 0.002984110704678574, Train_acc 0.9976380813953488\n",
      "\n",
      "Epoch 81. Loss: 0.0027166567500248066, Train_acc 0.99765625\n",
      "\n",
      "Epoch 81. Loss: 0.002571946919484244, Train_acc 0.9976741412213741\n",
      "\n",
      "Epoch 81. Loss: 0.0023506372621305044, Train_acc 0.9976917613636364\n",
      "\n",
      "Epoch 81. Loss: 0.002136907563323282, Train_acc 0.9977091165413534\n",
      "\n",
      "Epoch 81. Loss: 0.0019368719720849047, Train_acc 0.9977262126865671\n",
      "\n",
      "Epoch 81. Loss: 0.002008620137111126, Train_acc 0.9977430555555555\n",
      "\n",
      "Epoch 81. Loss: 0.0020462041532344627, Train_acc 0.9977596507352942\n",
      "\n",
      "Epoch 81. Loss: 0.0018812882078749248, Train_acc 0.997776003649635\n",
      "\n",
      "Epoch 81. Loss: 0.001844873371174542, Train_acc 0.9977921195652174\n",
      "\n",
      "Epoch 81. Loss: 0.0016723700106400844, Train_acc 0.9978080035971223\n",
      "\n",
      "Epoch 81. Loss: 0.0015845708728906003, Train_acc 0.9978236607142857\n",
      "\n",
      "Epoch 81. Loss: 0.0014448789910607438, Train_acc 0.9978390957446809\n",
      "\n",
      "Epoch 81. Loss: 0.0013138638618879566, Train_acc 0.9978543133802817\n",
      "\n",
      "Epoch 81. Loss: 0.0012099535958572595, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 81. Loss: 0.001097193237131247, Train_acc 0.9978841145833334\n",
      "\n",
      "Epoch 81. Loss: 0.0010182314933706005, Train_acc 0.9978987068965517\n",
      "\n",
      "Epoch 81. Loss: 0.0009234958528903251, Train_acc 0.9979130993150684\n",
      "\n",
      "Epoch 81. Loss: 0.0008614910504641049, Train_acc 0.9979272959183674\n",
      "\n",
      "Epoch 81. Loss: 0.0007821204385338386, Train_acc 0.9979413006756757\n",
      "\n",
      "Epoch 81. Loss: 0.0007094261535169588, Train_acc 0.9979551174496645\n",
      "\n",
      "Epoch 81. Loss: 0.0006433397916737414, Train_acc 0.99796875\n",
      "\n",
      "Epoch 81. Loss: 0.001596473396967341, Train_acc 0.9979304635761589\n",
      "\n",
      "Epoch 81. Loss: 0.0020744041367475596, Train_acc 0.9978926809210527\n",
      "\n",
      "Epoch 81. Loss: 0.001871726901803886, Train_acc 0.997906454248366\n",
      "\n",
      "Epoch 81. Loss: 0.002043138082898684, Train_acc 0.9979200487012987\n",
      "\n",
      "Epoch 81. Loss: 0.0018496127109475867, Train_acc 0.9979334677419355\n",
      "\n",
      "Epoch 81. Loss: 0.0016705347307945386, Train_acc 0.9979467147435898\n",
      "\n",
      "Epoch 81. Loss: 0.0015368492155185055, Train_acc 0.9979597929936306\n",
      "\n",
      "Epoch 81. Loss: 0.0017023921961853545, Train_acc 0.9979727056962026\n",
      "\n",
      "Epoch 81. Loss: 0.0018382560524212994, Train_acc 0.9979854559748428\n",
      "\n",
      "Epoch 81. Loss: 0.0017072810242281268, Train_acc 0.997998046875\n",
      "\n",
      "Epoch 81. Loss: 0.0015783195291243191, Train_acc 0.9980104813664596\n",
      "\n",
      "Epoch 81. Loss: 0.0015192697369969365, Train_acc 0.998022762345679\n",
      "\n",
      "Epoch 81. Loss: 0.0014756385238803753, Train_acc 0.9980348926380368\n",
      "\n",
      "Epoch 81. Loss: 0.0013846661675967124, Train_acc 0.998046875\n",
      "\n",
      "Epoch 81. Loss: 0.0020604932483134285, Train_acc 0.9980113636363637\n",
      "\n",
      "Epoch 81. Loss: 0.0019330862335910752, Train_acc 0.998023343373494\n",
      "\n",
      "Epoch 81. Loss: 0.001919336602617832, Train_acc 0.9980351796407185\n",
      "\n",
      "Epoch 81. Loss: 0.0018871706082563388, Train_acc 0.998046875\n",
      "\n",
      "Epoch 81. Loss: 0.0019004469830519665, Train_acc 0.9980584319526628\n",
      "\n",
      "Epoch 81. Loss: 0.0017648176001364032, Train_acc 0.9980698529411764\n",
      "\n",
      "Epoch 81. Loss: 0.0016660483294147883, Train_acc 0.9980811403508771\n",
      "\n",
      "Epoch 81. Loss: 0.001610998490255502, Train_acc 0.9980922965116279\n",
      "\n",
      "Epoch 81. Loss: 0.0015874987576616649, Train_acc 0.998103323699422\n",
      "\n",
      "Epoch 81. Loss: 0.0025253490828764, Train_acc 0.9980693247126436\n",
      "\n",
      "Epoch 81. Loss: 0.002277289571006307, Train_acc 0.9980803571428571\n",
      "\n",
      "Epoch 81. Loss: 0.002052424888844151, Train_acc 0.9980912642045454\n",
      "\n",
      "Epoch 81. Loss: 0.0018524414708544167, Train_acc 0.9981020480225988\n",
      "\n",
      "Epoch 81. Loss: 0.0016700930101078634, Train_acc 0.9981127106741573\n",
      "\n",
      "Epoch 81. Loss: 0.0015134361387689887, Train_acc 0.9981232541899442\n",
      "\n",
      "Epoch 81. Loss: 0.001368115851460628, Train_acc 0.9981336805555555\n",
      "\n",
      "Epoch 81. Loss: 0.002333783627312242, Train_acc 0.9981008287292817\n",
      "\n",
      "Epoch 81. Loss: 0.0021140933606591306, Train_acc 0.9981112637362637\n",
      "\n",
      "Epoch 81. Loss: 0.0019631635828990324, Train_acc 0.9981215846994536\n",
      "\n",
      "Epoch 81. Loss: 0.0025536067426960396, Train_acc 0.9980893342391305\n",
      "\n",
      "Epoch 81. Loss: 0.002506499807828134, Train_acc 0.9980996621621622\n",
      "\n",
      "Epoch 81. Loss: 0.00259299956537944, Train_acc 0.9981098790322581\n",
      "\n",
      "Epoch 81. Loss: 0.0023501319763977583, Train_acc 0.9981199866310161\n",
      "\n",
      "Epoch 81. Loss: 0.0021262657597360653, Train_acc 0.9981299867021277\n",
      "\n",
      "Epoch 81. Loss: 0.0019168357949771208, Train_acc 0.9981398809523809\n",
      "\n",
      "Epoch 81. Loss: 0.0017447633397779441, Train_acc 0.9981496710526315\n",
      "\n",
      "Epoch 81. Loss: 0.00170960984780579, Train_acc 0.9981593586387435\n",
      "\n",
      "Epoch 81. Loss: 0.0015603606130394304, Train_acc 0.9981689453125\n",
      "\n",
      "Epoch 81. Loss: 0.0014947394311134188, Train_acc 0.9981784326424871\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81. Loss: 0.0013610834169449286, Train_acc 0.9981878221649485\n",
      "\n",
      "Epoch 81. Loss: 0.0012393600174378978, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 81. Loss: 0.001118479893153809, Train_acc 0.9982\n",
      "\n",
      "Epoch 82. Loss: 0.0010095073313647336, Train_acc 1.0\n",
      "\n",
      "Epoch 82. Loss: 0.001002109860059663, Train_acc 1.0\n",
      "\n",
      "Epoch 82. Loss: 0.0009041263690052089, Train_acc 1.0\n",
      "\n",
      "Epoch 82. Loss: 0.0008171148042766704, Train_acc 1.0\n",
      "\n",
      "Epoch 82. Loss: 0.0007875169220616032, Train_acc 1.0\n",
      "\n",
      "Epoch 82. Loss: 0.0007823467621978023, Train_acc 1.0\n",
      "\n",
      "Epoch 82. Loss: 0.0007106964776452969, Train_acc 1.0\n",
      "\n",
      "Epoch 82. Loss: 0.0009721610033842853, Train_acc 1.0\n",
      "\n",
      "Epoch 82. Loss: 0.0008781311634832167, Train_acc 1.0\n",
      "\n",
      "Epoch 82. Loss: 0.0008368512157776768, Train_acc 1.0\n",
      "\n",
      "Epoch 82. Loss: 0.0008265768627274468, Train_acc 1.0\n",
      "\n",
      "Epoch 82. Loss: 0.0007456339877876334, Train_acc 1.0\n",
      "\n",
      "Epoch 82. Loss: 0.0006803003064066996, Train_acc 1.0\n",
      "\n",
      "Epoch 82. Loss: 0.0006165477603157048, Train_acc 1.0\n",
      "\n",
      "Epoch 82. Loss: 0.0007807192905527071, Train_acc 1.0\n",
      "\n",
      "Epoch 82. Loss: 0.0007073243183118009, Train_acc 1.0\n",
      "\n",
      "Epoch 82. Loss: 0.0007386550384883794, Train_acc 1.0\n",
      "\n",
      "Epoch 82. Loss: 0.0008764198771677654, Train_acc 1.0\n",
      "\n",
      "Epoch 82. Loss: 0.000796957401675149, Train_acc 1.0\n",
      "\n",
      "Epoch 82. Loss: 0.0007203586077462906, Train_acc 1.0\n",
      "\n",
      "Epoch 82. Loss: 0.0006605048966294084, Train_acc 1.0\n",
      "\n",
      "Epoch 82. Loss: 0.000603088395875891, Train_acc 1.0\n",
      "\n",
      "Epoch 82. Loss: 0.0005693045749086067, Train_acc 1.0\n",
      "\n",
      "Epoch 82. Loss: 0.0005306697020135082, Train_acc 1.0\n",
      "\n",
      "Epoch 82. Loss: 0.0004963266636741988, Train_acc 1.0\n",
      "\n",
      "Epoch 82. Loss: 0.0005318708216660022, Train_acc 1.0\n",
      "\n",
      "Epoch 82. Loss: 0.0005228846232120215, Train_acc 1.0\n",
      "\n",
      "Epoch 82. Loss: 0.00049864278306468, Train_acc 1.0\n",
      "\n",
      "Epoch 82. Loss: 0.0013650955169192285, Train_acc 0.9997306034482759\n",
      "\n",
      "Epoch 82. Loss: 0.0012533020410863383, Train_acc 0.9997395833333333\n",
      "\n",
      "Epoch 82. Loss: 0.001623190415703758, Train_acc 0.9997479838709677\n",
      "\n",
      "Epoch 82. Loss: 0.0014718253079488539, Train_acc 0.999755859375\n",
      "\n",
      "Epoch 82. Loss: 0.0013257066958706502, Train_acc 0.9997632575757576\n",
      "\n",
      "Epoch 82. Loss: 0.001199883754468149, Train_acc 0.9997702205882353\n",
      "\n",
      "Epoch 82. Loss: 0.0010971265739640583, Train_acc 0.9997767857142857\n",
      "\n",
      "Epoch 82. Loss: 0.0018722235409713676, Train_acc 0.9995659722222222\n",
      "\n",
      "Epoch 82. Loss: 0.0016952273684951956, Train_acc 0.9995777027027027\n",
      "\n",
      "Epoch 82. Loss: 0.001639051327079978, Train_acc 0.9995888157894737\n",
      "\n",
      "Epoch 82. Loss: 0.001477757674894299, Train_acc 0.9995993589743589\n",
      "\n",
      "Epoch 82. Loss: 0.0013368838116760862, Train_acc 0.999609375\n",
      "\n",
      "Epoch 82. Loss: 0.001205112657345145, Train_acc 0.9996189024390244\n",
      "\n",
      "Epoch 82. Loss: 0.001097462933083006, Train_acc 0.9996279761904762\n",
      "\n",
      "Epoch 82. Loss: 0.0010030896351783008, Train_acc 0.9996366279069767\n",
      "\n",
      "Epoch 82. Loss: 0.0009392355883593288, Train_acc 0.9996448863636364\n",
      "\n",
      "Epoch 82. Loss: 0.0008467236323303071, Train_acc 0.9996527777777777\n",
      "\n",
      "Epoch 82. Loss: 0.0007924649494579289, Train_acc 0.9996603260869565\n",
      "\n",
      "Epoch 82. Loss: 0.0016069963427803686, Train_acc 0.999501329787234\n",
      "\n",
      "Epoch 82. Loss: 0.0014590681823505927, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 82. Loss: 0.0021862523428273772, Train_acc 0.9993622448979592\n",
      "\n",
      "Epoch 82. Loss: 0.0019685668224811714, Train_acc 0.999375\n",
      "\n",
      "Epoch 82. Loss: 0.0018905224418948735, Train_acc 0.9993872549019608\n",
      "\n",
      "Epoch 82. Loss: 0.0019792556889036876, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 82. Loss: 0.0018655250102367624, Train_acc 0.9994103773584906\n",
      "\n",
      "Epoch 82. Loss: 0.0017293863040286264, Train_acc 0.9994212962962963\n",
      "\n",
      "Epoch 82. Loss: 0.0016171517621627863, Train_acc 0.9994318181818181\n",
      "\n",
      "Epoch 82. Loss: 0.0015080439772089348, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 82. Loss: 0.00174790425382972, Train_acc 0.9994517543859649\n",
      "\n",
      "Epoch 82. Loss: 0.0015944426884674787, Train_acc 0.9994612068965517\n",
      "\n",
      "Epoch 82. Loss: 0.0015702280523448072, Train_acc 0.9994703389830508\n",
      "\n",
      "Epoch 82. Loss: 0.001421706342836714, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 82. Loss: 0.0012835754621016108, Train_acc 0.9994877049180327\n",
      "\n",
      "Epoch 82. Loss: 0.0012156577591102234, Train_acc 0.9994959677419355\n",
      "\n",
      "Epoch 82. Loss: 0.0014801474257037858, Train_acc 0.9995039682539683\n",
      "\n",
      "Epoch 82. Loss: 0.0013500618257654632, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 82. Loss: 0.0012256308488586551, Train_acc 0.9995192307692308\n",
      "\n",
      "Epoch 82. Loss: 0.0012034215548855668, Train_acc 0.9995265151515151\n",
      "\n",
      "Epoch 82. Loss: 0.0011115086438091195, Train_acc 0.9995335820895522\n",
      "\n",
      "Epoch 82. Loss: 0.0010095889774834116, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 82. Loss: 0.0009463003636626527, Train_acc 0.9995471014492754\n",
      "\n",
      "Epoch 82. Loss: 0.0036799233878756876, Train_acc 0.9993303571428571\n",
      "\n",
      "Epoch 82. Loss: 0.0033206782533532105, Train_acc 0.9993397887323944\n",
      "\n",
      "Epoch 82. Loss: 0.0029940070417963194, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 82. Loss: 0.0027021064449294953, Train_acc 0.9993578767123288\n",
      "\n",
      "Epoch 82. Loss: 0.002435673833424157, Train_acc 0.9993665540540541\n",
      "\n",
      "Epoch 82. Loss: 0.004146096462489045, Train_acc 0.9992708333333333\n",
      "\n",
      "Epoch 82. Loss: 0.0039991167469896755, Train_acc 0.999280427631579\n",
      "\n",
      "Epoch 82. Loss: 0.004945843312210848, Train_acc 0.9991883116883117\n",
      "\n",
      "Epoch 82. Loss: 0.004928620892897555, Train_acc 0.999198717948718\n",
      "\n",
      "Epoch 82. Loss: 0.0044472508214098835, Train_acc 0.9992088607594937\n",
      "\n",
      "Epoch 82. Loss: 0.005259913008557196, Train_acc 0.99912109375\n",
      "\n",
      "Epoch 82. Loss: 0.007535771587025913, Train_acc 0.9990354938271605\n",
      "\n",
      "Epoch 82. Loss: 0.006936773544820511, Train_acc 0.999047256097561\n",
      "\n",
      "Epoch 82. Loss: 0.009346130016093579, Train_acc 0.9988704819277109\n",
      "\n",
      "Epoch 82. Loss: 0.011639111136774833, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 82. Loss: 0.010513375008190416, Train_acc 0.9987132352941176\n",
      "\n",
      "Epoch 82. Loss: 0.01040966344244904, Train_acc 0.9986373546511628\n",
      "\n",
      "Epoch 82. Loss: 0.009423041528304308, Train_acc 0.9986530172413793\n",
      "\n",
      "Epoch 82. Loss: 0.011409665475046536, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 82. Loss: 0.012096474614521176, Train_acc 0.9984199438202247\n",
      "\n",
      "Epoch 82. Loss: 0.015288538900119344, Train_acc 0.9981770833333333\n",
      "\n",
      "Epoch 82. Loss: 0.01952053204217757, Train_acc 0.9980254120879121\n",
      "\n",
      "Epoch 82. Loss: 0.018272084055818965, Train_acc 0.9979619565217391\n",
      "\n",
      "Epoch 82. Loss: 0.022299568705389964, Train_acc 0.9978998655913979\n",
      "\n",
      "Epoch 82. Loss: 0.030122938769427003, Train_acc 0.9976728723404256\n",
      "\n",
      "Epoch 82. Loss: 0.034751999840766545, Train_acc 0.9976151315789473\n",
      "\n",
      "Epoch 82. Loss: 0.04082414817717406, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 82. Loss: 0.03726564300647437, Train_acc 0.9974226804123711\n",
      "\n",
      "Epoch 82. Loss: 0.035207987152854135, Train_acc 0.9973692602040817\n",
      "\n",
      "Epoch 82. Loss: 0.034190607918786586, Train_acc 0.9972380050505051\n",
      "\n",
      "Epoch 82. Loss: 0.03148601245074354, Train_acc 0.9971875\n",
      "\n",
      "[Epoch 82 Batch 100] Loss: 0.028822512734134935 Training: accuracy=0.997215\n",
      "Epoch 82. Loss: 0.028822512734134935, Train_acc 0.9972153465346535\n",
      "\n",
      "Epoch 82. Loss: 0.02608700914389635, Train_acc 0.9972426470588235\n",
      "\n",
      "Epoch 82. Loss: 0.023669993367776976, Train_acc 0.9972694174757282\n",
      "\n",
      "Epoch 82. Loss: 0.021551549544098113, Train_acc 0.9972956730769231\n",
      "\n",
      "Epoch 82. Loss: 0.020766920229192496, Train_acc 0.9972470238095238\n",
      "\n",
      "Epoch 82. Loss: 0.02368115533625715, Train_acc 0.9971255896226415\n",
      "\n",
      "Epoch 82. Loss: 0.02303853652687937, Train_acc 0.9970794392523364\n",
      "\n",
      "Epoch 82. Loss: 0.023225120650041727, Train_acc 0.9969618055555556\n",
      "\n",
      "Epoch 82. Loss: 0.021124767762102453, Train_acc 0.9969896788990825\n",
      "\n",
      "Epoch 82. Loss: 0.02119764089734355, Train_acc 0.996875\n",
      "\n",
      "Epoch 82. Loss: 0.02071362365172207, Train_acc 0.9968327702702703\n",
      "\n",
      "Epoch 82. Loss: 0.01905179325240165, Train_acc 0.9968610491071429\n",
      "\n",
      "Epoch 82. Loss: 0.017774678872501642, Train_acc 0.9968888274336283\n",
      "\n",
      "Epoch 82. Loss: 0.016694049539246372, Train_acc 0.9969161184210527\n",
      "\n",
      "Epoch 82. Loss: 0.024263114931057286, Train_acc 0.9967391304347826\n",
      "\n",
      "Epoch 82. Loss: 0.024101015509847157, Train_acc 0.9966325431034483\n",
      "\n",
      "Epoch 82. Loss: 0.02602690972240271, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 82. Loss: 0.025557478299899416, Train_acc 0.9964909957627118\n",
      "\n",
      "Epoch 82. Loss: 0.026176908267584606, Train_acc 0.9963235294117647\n",
      "\n",
      "Epoch 82. Loss: 0.02624887852643177, Train_acc 0.9962239583333333\n",
      "\n",
      "Epoch 82. Loss: 0.02408677678204398, Train_acc 0.9962551652892562\n",
      "\n",
      "Epoch 82. Loss: 0.021823486823224908, Train_acc 0.9962858606557377\n",
      "\n",
      "Epoch 82. Loss: 0.020664858904526132, Train_acc 0.9963160569105691\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82. Loss: 0.02046512306068435, Train_acc 0.9962827620967742\n",
      "\n",
      "Epoch 82. Loss: 0.01867877864950086, Train_acc 0.9963125\n",
      "\n",
      "Epoch 82. Loss: 0.01777087698829042, Train_acc 0.9963417658730159\n",
      "\n",
      "Epoch 82. Loss: 0.0169989380839634, Train_acc 0.9963090551181102\n",
      "\n",
      "Epoch 82. Loss: 0.015555924205951517, Train_acc 0.996337890625\n",
      "\n",
      "Epoch 82. Loss: 0.014691936772143206, Train_acc 0.9963662790697675\n",
      "\n",
      "Epoch 82. Loss: 0.013622506185464884, Train_acc 0.9963942307692307\n",
      "\n",
      "Epoch 82. Loss: 0.014217857248270058, Train_acc 0.9963621183206107\n",
      "\n",
      "Epoch 82. Loss: 0.014230942239627429, Train_acc 0.9963304924242424\n",
      "\n",
      "Epoch 82. Loss: 0.013367263870178331, Train_acc 0.996358082706767\n",
      "\n",
      "Epoch 82. Loss: 0.013381103762303594, Train_acc 0.9963269589552238\n",
      "\n",
      "Epoch 82. Loss: 0.012399567230401757, Train_acc 0.9963541666666667\n",
      "\n",
      "Epoch 82. Loss: 0.012508848813645532, Train_acc 0.9963235294117647\n",
      "\n",
      "Epoch 82. Loss: 0.011366228551765523, Train_acc 0.9963503649635036\n",
      "\n",
      "Epoch 82. Loss: 0.01041441975809283, Train_acc 0.9963768115942029\n",
      "\n",
      "Epoch 82. Loss: 0.015511707831416848, Train_acc 0.9962904676258992\n",
      "\n",
      "Epoch 82. Loss: 0.016001064809257677, Train_acc 0.9962053571428572\n",
      "\n",
      "Epoch 82. Loss: 0.01601039810367962, Train_acc 0.9961768617021277\n",
      "\n",
      "Epoch 82. Loss: 0.015546226274715722, Train_acc 0.9962037852112676\n",
      "\n",
      "Epoch 82. Loss: 0.014179384390243317, Train_acc 0.9962303321678322\n",
      "\n",
      "Epoch 82. Loss: 0.012894916071127437, Train_acc 0.9962565104166666\n",
      "\n",
      "Epoch 82. Loss: 0.011781989149549378, Train_acc 0.9962823275862069\n",
      "\n",
      "Epoch 82. Loss: 0.012167948361306285, Train_acc 0.9962542808219178\n",
      "\n",
      "Epoch 82. Loss: 0.011128819103842731, Train_acc 0.9962797619047619\n",
      "\n",
      "Epoch 82. Loss: 0.01026458420900025, Train_acc 0.9963048986486487\n",
      "\n",
      "Epoch 82. Loss: 0.010864402758009893, Train_acc 0.9962248322147651\n",
      "\n",
      "Epoch 82. Loss: 0.00986049650996044, Train_acc 0.99625\n",
      "\n",
      "Epoch 82. Loss: 0.009464543366185857, Train_acc 0.9962748344370861\n",
      "\n",
      "Epoch 82. Loss: 0.008775900142827957, Train_acc 0.9962993421052632\n",
      "\n",
      "Epoch 82. Loss: 0.008011913903934655, Train_acc 0.9963235294117647\n",
      "\n",
      "Epoch 82. Loss: 0.007266493584306521, Train_acc 0.9963474025974026\n",
      "\n",
      "Epoch 82. Loss: 0.007111330672882334, Train_acc 0.9963709677419355\n",
      "\n",
      "Epoch 82. Loss: 0.006922056014641228, Train_acc 0.9963942307692307\n",
      "\n",
      "Epoch 82. Loss: 0.008651331948015782, Train_acc 0.9963674363057324\n",
      "\n",
      "Epoch 82. Loss: 0.009030409950113618, Train_acc 0.9963409810126582\n",
      "\n",
      "Epoch 82. Loss: 0.008382184539150885, Train_acc 0.9963639937106918\n",
      "\n",
      "Epoch 82. Loss: 0.00933688721112462, Train_acc 0.996337890625\n",
      "\n",
      "Epoch 82. Loss: 0.010015329973865022, Train_acc 0.9963121118012422\n",
      "\n",
      "Epoch 82. Loss: 0.009061434580189856, Train_acc 0.9963348765432098\n",
      "\n",
      "Epoch 82. Loss: 0.00828007781158272, Train_acc 0.9963573619631901\n",
      "\n",
      "Epoch 82. Loss: 0.008771246268454644, Train_acc 0.9963795731707317\n",
      "\n",
      "Epoch 82. Loss: 0.007927213471000377, Train_acc 0.9964015151515152\n",
      "\n",
      "Epoch 82. Loss: 0.007276033585826292, Train_acc 0.9964231927710844\n",
      "\n",
      "Epoch 82. Loss: 0.007047785833978416, Train_acc 0.9964446107784432\n",
      "\n",
      "Epoch 82. Loss: 0.0070321292382512345, Train_acc 0.9964192708333334\n",
      "\n",
      "Epoch 82. Loss: 0.0064667233474508395, Train_acc 0.9964404585798816\n",
      "\n",
      "Epoch 82. Loss: 0.007800802765559149, Train_acc 0.9963694852941176\n",
      "\n",
      "Epoch 82. Loss: 0.007043713729260631, Train_acc 0.996390716374269\n",
      "\n",
      "Epoch 82. Loss: 0.007393328868459107, Train_acc 0.9963662790697675\n",
      "\n",
      "Epoch 82. Loss: 0.007626838592985667, Train_acc 0.9963421242774566\n",
      "\n",
      "Epoch 82. Loss: 0.00790035168078488, Train_acc 0.9963182471264368\n",
      "\n",
      "Epoch 82. Loss: 0.007122873459309974, Train_acc 0.9963392857142858\n",
      "\n",
      "Epoch 82. Loss: 0.006425890301506606, Train_acc 0.9963600852272727\n",
      "\n",
      "Epoch 82. Loss: 0.005863840604058702, Train_acc 0.9963806497175142\n",
      "\n",
      "Epoch 82. Loss: 0.005297589835780698, Train_acc 0.9964009831460674\n",
      "\n",
      "Epoch 82. Loss: 0.004815748993556504, Train_acc 0.9964210893854749\n",
      "\n",
      "Epoch 82. Loss: 0.004545967208632057, Train_acc 0.9964409722222223\n",
      "\n",
      "Epoch 82. Loss: 0.004231973758616201, Train_acc 0.996460635359116\n",
      "\n",
      "Epoch 82. Loss: 0.004247370083282726, Train_acc 0.9964800824175825\n",
      "\n",
      "Epoch 82. Loss: 0.003921091554578694, Train_acc 0.9964993169398907\n",
      "\n",
      "Epoch 82. Loss: 0.0040880229306369, Train_acc 0.9965183423913043\n",
      "\n",
      "Epoch 82. Loss: 0.004173107890678851, Train_acc 0.9965371621621621\n",
      "\n",
      "Epoch 82. Loss: 0.003892282168807156, Train_acc 0.9965557795698925\n",
      "\n",
      "Epoch 82. Loss: 0.003896105745725245, Train_acc 0.9965741978609626\n",
      "\n",
      "Epoch 82. Loss: 0.0035385587418411994, Train_acc 0.996592420212766\n",
      "\n",
      "Epoch 82. Loss: 0.0036468101814539577, Train_acc 0.9966104497354498\n",
      "\n",
      "Epoch 82. Loss: 0.005192032041414203, Train_acc 0.9965871710526316\n",
      "\n",
      "Epoch 82. Loss: 0.010603915675518175, Train_acc 0.9965232329842932\n",
      "\n",
      "Epoch 82. Loss: 0.009690538032982284, Train_acc 0.9965413411458334\n",
      "\n",
      "Epoch 82. Loss: 0.008766454391664074, Train_acc 0.9965592616580311\n",
      "\n",
      "Epoch 82. Loss: 0.007913235402704565, Train_acc 0.9965769974226805\n",
      "\n",
      "Epoch 82. Loss: 0.0071321234281114185, Train_acc 0.9965945512820513\n",
      "\n",
      "Epoch 82. Loss: 0.006487820073332767, Train_acc 0.9966\n",
      "\n",
      "Epoch 83. Loss: 0.0058542561693622035, Train_acc 1.0\n",
      "\n",
      "Epoch 83. Loss: 0.005326627697990092, Train_acc 1.0\n",
      "\n",
      "Epoch 83. Loss: 0.004821943377552482, Train_acc 1.0\n",
      "\n",
      "Epoch 83. Loss: 0.004620597953623282, Train_acc 1.0\n",
      "\n",
      "Epoch 83. Loss: 0.004202317187771869, Train_acc 1.0\n",
      "\n",
      "Epoch 83. Loss: 0.0038330862007590434, Train_acc 1.0\n",
      "\n",
      "Epoch 83. Loss: 0.003582819490113315, Train_acc 1.0\n",
      "\n",
      "Epoch 83. Loss: 0.0035726895052374517, Train_acc 1.0\n",
      "\n",
      "Epoch 83. Loss: 0.00324026814787219, Train_acc 1.0\n",
      "\n",
      "Epoch 83. Loss: 0.0029870969832044543, Train_acc 1.0\n",
      "\n",
      "Epoch 83. Loss: 0.0027845253452097657, Train_acc 1.0\n",
      "\n",
      "Epoch 83. Loss: 0.002543909565616201, Train_acc 1.0\n",
      "\n",
      "Epoch 83. Loss: 0.0023124086145481174, Train_acc 1.0\n",
      "\n",
      "Epoch 83. Loss: 0.0029192523651350175, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 83. Loss: 0.002738986477098194, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 83. Loss: 0.0037393922007155364, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 83. Loss: 0.0035869397893761347, Train_acc 0.9990808823529411\n",
      "\n",
      "Epoch 83. Loss: 0.0067935702808393315, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 83. Loss: 0.006120298187039843, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 83. Loss: 0.005577827821158291, Train_acc 0.998828125\n",
      "\n",
      "Epoch 83. Loss: 0.005184281609750915, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 83. Loss: 0.005183218738627847, Train_acc 0.9989346590909091\n",
      "\n",
      "Epoch 83. Loss: 0.004794174426556303, Train_acc 0.9989809782608695\n",
      "\n",
      "Epoch 83. Loss: 0.004810072885835774, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 83. Loss: 0.009932783982352561, Train_acc 0.9984375\n",
      "\n",
      "Epoch 83. Loss: 0.013326308719393146, Train_acc 0.9978966346153846\n",
      "\n",
      "Epoch 83. Loss: 0.01305207510329175, Train_acc 0.9976851851851852\n",
      "\n",
      "Epoch 83. Loss: 0.011831547085246188, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 83. Loss: 0.010661799840569695, Train_acc 0.9978448275862069\n",
      "\n",
      "Epoch 83. Loss: 0.009806349796375811, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 83. Loss: 0.008858267573340175, Train_acc 0.9979838709677419\n",
      "\n",
      "Epoch 83. Loss: 0.009262918442031835, Train_acc 0.997802734375\n",
      "\n",
      "Epoch 83. Loss: 0.010914327995068814, Train_acc 0.9976325757575758\n",
      "\n",
      "Epoch 83. Loss: 0.009999796100187587, Train_acc 0.9977022058823529\n",
      "\n",
      "Epoch 83. Loss: 0.009019274614175461, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 83. Loss: 0.011749098392057691, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 83. Loss: 0.011376914572025783, Train_acc 0.9974662162162162\n",
      "\n",
      "Epoch 83. Loss: 0.010306615281061483, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 83. Loss: 0.011152566691895861, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 83. Loss: 0.012407769236559157, Train_acc 0.997265625\n",
      "\n",
      "Epoch 83. Loss: 0.013666533021862345, Train_acc 0.997141768292683\n",
      "\n",
      "Epoch 83. Loss: 0.012883608122529122, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 83. Loss: 0.011742117043274523, Train_acc 0.9972747093023255\n",
      "\n",
      "Epoch 83. Loss: 0.014821002962533726, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 83. Loss: 0.013568323877686942, Train_acc 0.9972222222222222\n",
      "\n",
      "Epoch 83. Loss: 0.01371083710914971, Train_acc 0.9971127717391305\n",
      "\n",
      "Epoch 83. Loss: 0.012372242170065424, Train_acc 0.9971742021276596\n",
      "\n",
      "Epoch 83. Loss: 0.012462484079590245, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 83. Loss: 0.011864820959485297, Train_acc 0.9971301020408163\n",
      "\n",
      "Epoch 83. Loss: 0.011029905475325934, Train_acc 0.9971875\n",
      "\n",
      "Epoch 83. Loss: 0.009995153037609207, Train_acc 0.9972426470588235\n",
      "\n",
      "Epoch 83. Loss: 0.009886122465492678, Train_acc 0.9971454326923077\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83. Loss: 0.008984665911688412, Train_acc 0.9971992924528302\n",
      "\n",
      "Epoch 83. Loss: 0.00866954336654604, Train_acc 0.9972511574074074\n",
      "\n",
      "Epoch 83. Loss: 0.008204878193212693, Train_acc 0.9973011363636364\n",
      "\n",
      "Epoch 83. Loss: 0.007787191159269046, Train_acc 0.9973493303571429\n",
      "\n",
      "Epoch 83. Loss: 0.007150062201797216, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 83. Loss: 0.006781187325012012, Train_acc 0.9974407327586207\n",
      "\n",
      "Epoch 83. Loss: 0.006511317475251547, Train_acc 0.9974841101694916\n",
      "\n",
      "Epoch 83. Loss: 0.0059431022089139595, Train_acc 0.9975260416666667\n",
      "\n",
      "Epoch 83. Loss: 0.0056879672831072784, Train_acc 0.9975665983606558\n",
      "\n",
      "Epoch 83. Loss: 0.005713241900200341, Train_acc 0.9976058467741935\n",
      "\n",
      "Epoch 83. Loss: 0.005851139687920833, Train_acc 0.9976438492063492\n",
      "\n",
      "Epoch 83. Loss: 0.0054450631941558945, Train_acc 0.9976806640625\n",
      "\n",
      "Epoch 83. Loss: 0.00507544004572499, Train_acc 0.9977163461538462\n",
      "\n",
      "Epoch 83. Loss: 0.0047529879743880175, Train_acc 0.997750946969697\n",
      "\n",
      "Epoch 83. Loss: 0.0045331698417314424, Train_acc 0.9977845149253731\n",
      "\n",
      "Epoch 83. Loss: 0.004278747643275428, Train_acc 0.9978170955882353\n",
      "\n",
      "Epoch 83. Loss: 0.003908542677791448, Train_acc 0.997848731884058\n",
      "\n",
      "Epoch 83. Loss: 0.003592400131402789, Train_acc 0.9978794642857143\n",
      "\n",
      "Epoch 83. Loss: 0.003340516220933984, Train_acc 0.9979093309859155\n",
      "\n",
      "Epoch 83. Loss: 0.003049568675598613, Train_acc 0.9979383680555556\n",
      "\n",
      "Epoch 83. Loss: 0.002803400008879106, Train_acc 0.997966609589041\n",
      "\n",
      "Epoch 83. Loss: 0.002550053991183565, Train_acc 0.9979940878378378\n",
      "\n",
      "Epoch 83. Loss: 0.0023243060849259876, Train_acc 0.9980208333333334\n",
      "\n",
      "Epoch 83. Loss: 0.002161262011757545, Train_acc 0.998046875\n",
      "\n",
      "Epoch 83. Loss: 0.002093854149041521, Train_acc 0.9980722402597403\n",
      "\n",
      "Epoch 83. Loss: 0.001941330453486768, Train_acc 0.9980969551282052\n",
      "\n",
      "Epoch 83. Loss: 0.0018106477748623736, Train_acc 0.9981210443037974\n",
      "\n",
      "Epoch 83. Loss: 0.0018015005695280056, Train_acc 0.99814453125\n",
      "\n",
      "Epoch 83. Loss: 0.0025164550698509773, Train_acc 0.998070987654321\n",
      "\n",
      "Epoch 83. Loss: 0.002317129379179564, Train_acc 0.9980945121951219\n",
      "\n",
      "Epoch 83. Loss: 0.0030862634567914785, Train_acc 0.998023343373494\n",
      "\n",
      "Epoch 83. Loss: 0.003524841031148885, Train_acc 0.9979538690476191\n",
      "\n",
      "Epoch 83. Loss: 0.0050733932427002686, Train_acc 0.9978860294117647\n",
      "\n",
      "Epoch 83. Loss: 0.0046662447861001224, Train_acc 0.9979106104651163\n",
      "\n",
      "Epoch 83. Loss: 0.0077467463622539045, Train_acc 0.9978448275862069\n",
      "\n",
      "Epoch 83. Loss: 0.01339056139082153, Train_acc 0.9977805397727273\n",
      "\n",
      "Epoch 83. Loss: 0.012156157946165855, Train_acc 0.9978054775280899\n",
      "\n",
      "Epoch 83. Loss: 0.01094560302535854, Train_acc 0.9978298611111112\n",
      "\n",
      "Epoch 83. Loss: 0.009927510499493739, Train_acc 0.9978537087912088\n",
      "\n",
      "Epoch 83. Loss: 0.02140786434370559, Train_acc 0.997452445652174\n",
      "\n",
      "Epoch 83. Loss: 0.01931594737923658, Train_acc 0.9974798387096774\n",
      "\n",
      "Epoch 83. Loss: 0.017814336544035518, Train_acc 0.9975066489361702\n",
      "\n",
      "Epoch 83. Loss: 0.016345888322897534, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 83. Loss: 0.01517248404999773, Train_acc 0.99755859375\n",
      "\n",
      "Epoch 83. Loss: 0.013775371402604434, Train_acc 0.9975837628865979\n",
      "\n",
      "Epoch 83. Loss: 0.012587171606252837, Train_acc 0.9976084183673469\n",
      "\n",
      "Epoch 83. Loss: 0.015656134988692626, Train_acc 0.9975536616161617\n",
      "\n",
      "Epoch 83. Loss: 0.014492210927972697, Train_acc 0.997578125\n",
      "\n",
      "[Epoch 83 Batch 100] Loss: 0.014330890864166175 Training: accuracy=0.997525\n",
      "Epoch 83. Loss: 0.014330890864166175, Train_acc 0.9975247524752475\n",
      "\n",
      "Epoch 83. Loss: 0.013578615622996589, Train_acc 0.9975490196078431\n",
      "\n",
      "Epoch 83. Loss: 0.012456767918344706, Train_acc 0.9975728155339806\n",
      "\n",
      "Epoch 83. Loss: 0.013107315856227014, Train_acc 0.9975210336538461\n",
      "\n",
      "Epoch 83. Loss: 0.011921484686144056, Train_acc 0.9975446428571428\n",
      "\n",
      "Epoch 83. Loss: 0.01088021234890404, Train_acc 0.9975678066037735\n",
      "\n",
      "Epoch 83. Loss: 0.010875088859086477, Train_acc 0.997517523364486\n",
      "\n",
      "Epoch 83. Loss: 0.010958296221630493, Train_acc 0.9974681712962963\n",
      "\n",
      "Epoch 83. Loss: 0.009977267136006848, Train_acc 0.9974913990825688\n",
      "\n",
      "Epoch 83. Loss: 0.012137200414981808, Train_acc 0.9974431818181818\n",
      "\n",
      "Epoch 83. Loss: 0.015172565859418837, Train_acc 0.9973254504504504\n",
      "\n",
      "Epoch 83. Loss: 0.0137919327235662, Train_acc 0.9973493303571429\n",
      "\n",
      "Epoch 83. Loss: 0.012498232465403653, Train_acc 0.9973727876106194\n",
      "\n",
      "Epoch 83. Loss: 0.011537805531882385, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 83. Loss: 0.011347836182531542, Train_acc 0.9974184782608696\n",
      "\n",
      "Epoch 83. Loss: 0.010635020294204498, Train_acc 0.9974407327586207\n",
      "\n",
      "Epoch 83. Loss: 0.013735747970713804, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 83. Loss: 0.012668123652293053, Train_acc 0.9974179025423728\n",
      "\n",
      "Epoch 83. Loss: 0.012681688440370948, Train_acc 0.9973739495798319\n",
      "\n",
      "Epoch 83. Loss: 0.011544688627708011, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 83. Loss: 0.011151780394990492, Train_acc 0.9974173553719008\n",
      "\n",
      "Epoch 83. Loss: 0.012995213195633216, Train_acc 0.997374487704918\n",
      "\n",
      "Epoch 83. Loss: 0.012165727818341247, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 83. Loss: 0.01187331564739155, Train_acc 0.9973538306451613\n",
      "\n",
      "Epoch 83. Loss: 0.011325519522784417, Train_acc 0.997375\n",
      "\n",
      "Epoch 83. Loss: 0.01026834976265946, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 83. Loss: 0.009659286116496793, Train_acc 0.9974163385826772\n",
      "\n",
      "Epoch 83. Loss: 0.010758959822299545, Train_acc 0.99737548828125\n",
      "\n",
      "Epoch 83. Loss: 0.009969132281415879, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 83. Loss: 0.009008734575789693, Train_acc 0.9974158653846154\n",
      "\n",
      "Epoch 83. Loss: 0.008466435746109356, Train_acc 0.9974355916030534\n",
      "\n",
      "Epoch 83. Loss: 0.007909787767311218, Train_acc 0.9974550189393939\n",
      "\n",
      "Epoch 83. Loss: 0.007433129591171696, Train_acc 0.9974741541353384\n",
      "\n",
      "Epoch 83. Loss: 0.006820626056499559, Train_acc 0.9974930037313433\n",
      "\n",
      "Epoch 83. Loss: 0.006808956867507647, Train_acc 0.9975115740740741\n",
      "\n",
      "Epoch 83. Loss: 0.006335623133750156, Train_acc 0.9975298713235294\n",
      "\n",
      "Epoch 83. Loss: 0.005957187885258849, Train_acc 0.9975479014598541\n",
      "\n",
      "Epoch 83. Loss: 0.006301555696172347, Train_acc 0.9975090579710145\n",
      "\n",
      "Epoch 83. Loss: 0.00597140506517246, Train_acc 0.9975269784172662\n",
      "\n",
      "Epoch 83. Loss: 0.007730673653882933, Train_acc 0.9974888392857143\n",
      "\n",
      "Epoch 83. Loss: 0.0070406380499546456, Train_acc 0.9975066489361702\n",
      "\n",
      "Epoch 83. Loss: 0.006648356502590602, Train_acc 0.9975242077464789\n",
      "\n",
      "Epoch 83. Loss: 0.00601471770221787, Train_acc 0.9975415209790209\n",
      "\n",
      "Epoch 83. Loss: 0.005421989125753338, Train_acc 0.99755859375\n",
      "\n",
      "Epoch 83. Loss: 0.004914804359302017, Train_acc 0.9975754310344828\n",
      "\n",
      "Epoch 83. Loss: 0.004540048653841102, Train_acc 0.9975920376712328\n",
      "\n",
      "Epoch 83. Loss: 0.004975891495460347, Train_acc 0.9975552721088435\n",
      "\n",
      "Epoch 83. Loss: 0.006070537240547605, Train_acc 0.9975190033783784\n",
      "\n",
      "Epoch 83. Loss: 0.005739936587766708, Train_acc 0.9975356543624161\n",
      "\n",
      "Epoch 83. Loss: 0.005257828576260866, Train_acc 0.9975520833333333\n",
      "\n",
      "Epoch 83. Loss: 0.004792391393499728, Train_acc 0.9975682947019867\n",
      "\n",
      "Epoch 83. Loss: 0.0044344938765843115, Train_acc 0.9975842927631579\n",
      "\n",
      "Epoch 83. Loss: 0.004014396140833314, Train_acc 0.9976000816993464\n",
      "\n",
      "Epoch 83. Loss: 0.003678895806488796, Train_acc 0.9976156655844156\n",
      "\n",
      "Epoch 83. Loss: 0.003765173595593039, Train_acc 0.9976310483870968\n",
      "\n",
      "Epoch 83. Loss: 0.0057805910033991905, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 83. Loss: 0.005223291320443669, Train_acc 0.9976114649681529\n",
      "\n",
      "Epoch 83. Loss: 0.006025763987309205, Train_acc 0.9975771360759493\n",
      "\n",
      "Epoch 83. Loss: 0.005697831519184828, Train_acc 0.9975923742138365\n",
      "\n",
      "Epoch 83. Loss: 0.005181301531781245, Train_acc 0.997607421875\n",
      "\n",
      "Epoch 83. Loss: 0.006232305748095652, Train_acc 0.9975737577639752\n",
      "\n",
      "Epoch 83. Loss: 0.008168123483208306, Train_acc 0.9975405092592593\n",
      "\n",
      "Epoch 83. Loss: 0.008002131038127084, Train_acc 0.9975076687116564\n",
      "\n",
      "Epoch 83. Loss: 0.007406852672890788, Train_acc 0.9975228658536586\n",
      "\n",
      "Epoch 83. Loss: 0.007050415872763961, Train_acc 0.9975378787878788\n",
      "\n",
      "Epoch 83. Loss: 0.006517491160670403, Train_acc 0.9975527108433735\n",
      "\n",
      "Epoch 83. Loss: 0.006394038779741064, Train_acc 0.9975673652694611\n",
      "\n",
      "Epoch 83. Loss: 0.005812925502776461, Train_acc 0.9975818452380952\n",
      "\n",
      "Epoch 83. Loss: 0.00534206657569351, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 83. Loss: 0.005860556082821568, Train_acc 0.9975643382352941\n",
      "\n",
      "Epoch 83. Loss: 0.005325575467637566, Train_acc 0.9975785818713451\n",
      "\n",
      "Epoch 83. Loss: 0.005042737889870752, Train_acc 0.9975926598837209\n",
      "\n",
      "Epoch 83. Loss: 0.004603592745812013, Train_acc 0.9976065751445087\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83. Loss: 0.0041512730638796685, Train_acc 0.9976203304597702\n",
      "\n",
      "Epoch 83. Loss: 0.006412315331752414, Train_acc 0.9975446428571428\n",
      "\n",
      "Epoch 83. Loss: 0.006520780729447587, Train_acc 0.9975142045454546\n",
      "\n",
      "Epoch 83. Loss: 0.005896381624538444, Train_acc 0.9975282485875706\n",
      "\n",
      "Epoch 83. Loss: 0.00784395281642563, Train_acc 0.9974982443820225\n",
      "\n",
      "Epoch 83. Loss: 0.007251892119209202, Train_acc 0.997512220670391\n",
      "\n",
      "Epoch 83. Loss: 0.007101771500313489, Train_acc 0.9975260416666667\n",
      "\n",
      "Epoch 83. Loss: 0.00640258185100047, Train_acc 0.9975397099447514\n",
      "\n",
      "Epoch 83. Loss: 0.005770442407143802, Train_acc 0.997553228021978\n",
      "\n",
      "Epoch 83. Loss: 0.005283337896671316, Train_acc 0.9975665983606558\n",
      "\n",
      "Epoch 83. Loss: 0.004842318776512671, Train_acc 0.9975798233695652\n",
      "\n",
      "Epoch 83. Loss: 0.004404044815743293, Train_acc 0.9975929054054054\n",
      "\n",
      "Epoch 83. Loss: 0.006018094534138733, Train_acc 0.9975638440860215\n",
      "\n",
      "Epoch 83. Loss: 0.009183325825148726, Train_acc 0.9975350935828877\n",
      "\n",
      "Epoch 83. Loss: 0.008423095785261457, Train_acc 0.997548204787234\n",
      "\n",
      "Epoch 83. Loss: 0.007828484809933244, Train_acc 0.9975611772486772\n",
      "\n",
      "Epoch 83. Loss: 0.007092125283043472, Train_acc 0.9975740131578947\n",
      "\n",
      "Epoch 83. Loss: 0.006863852668280203, Train_acc 0.9975867146596858\n",
      "\n",
      "Epoch 83. Loss: 0.0063516742809077795, Train_acc 0.9975992838541666\n",
      "\n",
      "Epoch 83. Loss: 0.0061901381658876565, Train_acc 0.9976117227979274\n",
      "\n",
      "Epoch 83. Loss: 0.006691543311390099, Train_acc 0.9975837628865979\n",
      "\n",
      "Epoch 83. Loss: 0.0060362593055980325, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 83. Loss: 0.005548542744234972, Train_acc 0.9976\n",
      "\n",
      "Epoch 84. Loss: 0.006862439369841611, Train_acc 0.9921875\n",
      "\n",
      "Epoch 84. Loss: 0.00750884576650041, Train_acc 0.9921875\n",
      "\n",
      "Epoch 84. Loss: 0.009224008558794062, Train_acc 0.9921875\n",
      "\n",
      "Epoch 84. Loss: 0.01180174927884716, Train_acc 0.98828125\n",
      "\n",
      "Epoch 84. Loss: 0.011004725277753575, Train_acc 0.990625\n",
      "\n",
      "Epoch 84. Loss: 0.00996364875521383, Train_acc 0.9921875\n",
      "\n",
      "Epoch 84. Loss: 0.01071520424383391, Train_acc 0.9921875\n",
      "\n",
      "Epoch 84. Loss: 0.010456807775773189, Train_acc 0.9931640625\n",
      "\n",
      "Epoch 84. Loss: 0.010323458881060107, Train_acc 0.9939236111111112\n",
      "\n",
      "Epoch 84. Loss: 0.009508080838289698, Train_acc 0.99453125\n",
      "\n",
      "Epoch 84. Loss: 0.008614765846487292, Train_acc 0.9950284090909091\n",
      "\n",
      "Epoch 84. Loss: 0.007845357227144904, Train_acc 0.9954427083333334\n",
      "\n",
      "Epoch 84. Loss: 0.007113353592441918, Train_acc 0.9957932692307693\n",
      "\n",
      "Epoch 84. Loss: 0.009231343804853954, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 84. Loss: 0.00846216490398672, Train_acc 0.9958333333333333\n",
      "\n",
      "Epoch 84. Loss: 0.007849057708956242, Train_acc 0.99609375\n",
      "\n",
      "Epoch 84. Loss: 0.009548963780502177, Train_acc 0.9954044117647058\n",
      "\n",
      "Epoch 84. Loss: 0.008620140907156942, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 84. Loss: 0.007947930357147883, Train_acc 0.9958881578947368\n",
      "\n",
      "Epoch 84. Loss: 0.024028076524695425, Train_acc 0.994140625\n",
      "\n",
      "Epoch 84. Loss: 0.025005706440055966, Train_acc 0.9940476190476191\n",
      "\n",
      "Epoch 84. Loss: 0.02590583484528476, Train_acc 0.9939630681818182\n",
      "\n",
      "Epoch 84. Loss: 0.024288678190779813, Train_acc 0.9942255434782609\n",
      "\n",
      "Epoch 84. Loss: 0.026368583609168647, Train_acc 0.9931640625\n",
      "\n",
      "Epoch 84. Loss: 0.0265870449642881, Train_acc 0.993125\n",
      "\n",
      "Epoch 84. Loss: 0.02488658552919724, Train_acc 0.9933894230769231\n",
      "\n",
      "Epoch 84. Loss: 0.02345795376722424, Train_acc 0.9933449074074074\n",
      "\n",
      "Epoch 84. Loss: 0.023890994543949447, Train_acc 0.9933035714285714\n",
      "\n",
      "Epoch 84. Loss: 0.02543738303046198, Train_acc 0.9927262931034483\n",
      "\n",
      "Epoch 84. Loss: 0.02559212040866111, Train_acc 0.9924479166666667\n",
      "\n",
      "Epoch 84. Loss: 0.02649328694013978, Train_acc 0.9919354838709677\n",
      "\n",
      "Epoch 84. Loss: 0.02523253524543248, Train_acc 0.991943359375\n",
      "\n",
      "Epoch 84. Loss: 0.02540405539490046, Train_acc 0.9919507575757576\n",
      "\n",
      "Epoch 84. Loss: 0.02382637979373868, Train_acc 0.9921875\n",
      "\n",
      "Epoch 84. Loss: 0.021810928056148017, Train_acc 0.9924107142857143\n",
      "\n",
      "Epoch 84. Loss: 0.02070199270427882, Train_acc 0.9926215277777778\n",
      "\n",
      "Epoch 84. Loss: 0.019008719703233177, Train_acc 0.9928209459459459\n",
      "\n",
      "Epoch 84. Loss: 0.018812409443267526, Train_acc 0.9928042763157895\n",
      "\n",
      "Epoch 84. Loss: 0.017391016563870022, Train_acc 0.992988782051282\n",
      "\n",
      "Epoch 84. Loss: 0.01599525258583353, Train_acc 0.9931640625\n",
      "\n",
      "Epoch 84. Loss: 0.014789403945364292, Train_acc 0.9933307926829268\n",
      "\n",
      "Epoch 84. Loss: 0.0164675904543618, Train_acc 0.9933035714285714\n",
      "\n",
      "Epoch 84. Loss: 0.01536772702840742, Train_acc 0.9934593023255814\n",
      "\n",
      "Epoch 84. Loss: 0.014028825215245276, Train_acc 0.9936079545454546\n",
      "\n",
      "Epoch 84. Loss: 0.01314750047184079, Train_acc 0.99375\n",
      "\n",
      "Epoch 84. Loss: 0.011894786449994586, Train_acc 0.9938858695652174\n",
      "\n",
      "Epoch 84. Loss: 0.011990345668994732, Train_acc 0.9938497340425532\n",
      "\n",
      "Epoch 84. Loss: 0.012238312760475292, Train_acc 0.9938151041666666\n",
      "\n",
      "Epoch 84. Loss: 0.011254355464599741, Train_acc 0.9939413265306123\n",
      "\n",
      "Epoch 84. Loss: 0.010605835773100447, Train_acc 0.9940625\n",
      "\n",
      "Epoch 84. Loss: 0.01008117925678193, Train_acc 0.9941789215686274\n",
      "\n",
      "Epoch 84. Loss: 0.009611996564011271, Train_acc 0.9942908653846154\n",
      "\n",
      "Epoch 84. Loss: 0.009187002294353094, Train_acc 0.9943985849056604\n",
      "\n",
      "Epoch 84. Loss: 0.008802737612806064, Train_acc 0.9945023148148148\n",
      "\n",
      "Epoch 84. Loss: 0.009628049644186173, Train_acc 0.9944602272727273\n",
      "\n",
      "Epoch 84. Loss: 0.008899120965842075, Train_acc 0.9945591517857143\n",
      "\n",
      "Epoch 84. Loss: 0.010456490274587572, Train_acc 0.9943804824561403\n",
      "\n",
      "Epoch 84. Loss: 0.010052876962410778, Train_acc 0.9943426724137931\n",
      "\n",
      "Epoch 84. Loss: 0.009114008875526372, Train_acc 0.9944385593220338\n",
      "\n",
      "Epoch 84. Loss: 0.010254423006031558, Train_acc 0.9942708333333333\n",
      "\n",
      "Epoch 84. Loss: 0.012549151271868031, Train_acc 0.9942366803278688\n",
      "\n",
      "Epoch 84. Loss: 0.01134960909250821, Train_acc 0.9943296370967742\n",
      "\n",
      "Epoch 84. Loss: 0.01027843109034847, Train_acc 0.9944196428571429\n",
      "\n",
      "Epoch 84. Loss: 0.009259463288271258, Train_acc 0.9945068359375\n",
      "\n",
      "Epoch 84. Loss: 0.008490328071982113, Train_acc 0.9945913461538461\n",
      "\n",
      "Epoch 84. Loss: 0.0077225163954604695, Train_acc 0.9946732954545454\n",
      "\n",
      "Epoch 84. Loss: 0.010170987580249521, Train_acc 0.9946361940298507\n",
      "\n",
      "Epoch 84. Loss: 0.013073745072510672, Train_acc 0.9946001838235294\n",
      "\n",
      "Epoch 84. Loss: 0.011772398478228025, Train_acc 0.9946784420289855\n",
      "\n",
      "Epoch 84. Loss: 0.01087768813910023, Train_acc 0.9947544642857142\n",
      "\n",
      "Epoch 84. Loss: 0.00995713596515598, Train_acc 0.9948283450704225\n",
      "\n",
      "Epoch 84. Loss: 0.009012922743324492, Train_acc 0.9949001736111112\n",
      "\n",
      "Epoch 84. Loss: 0.012199380337623406, Train_acc 0.9948630136986302\n",
      "\n",
      "Epoch 84. Loss: 0.011267935862625523, Train_acc 0.9949324324324325\n",
      "\n",
      "Epoch 84. Loss: 0.01092603365449746, Train_acc 0.995\n",
      "\n",
      "Epoch 84. Loss: 0.012576511478739734, Train_acc 0.9949629934210527\n",
      "\n",
      "Epoch 84. Loss: 0.011448346380856862, Train_acc 0.9950284090909091\n",
      "\n",
      "Epoch 84. Loss: 0.010803573711112645, Train_acc 0.9950921474358975\n",
      "\n",
      "Epoch 84. Loss: 0.011732046537156857, Train_acc 0.9950553797468354\n",
      "\n",
      "Epoch 84. Loss: 0.018440560012360774, Train_acc 0.994921875\n",
      "\n",
      "Epoch 84. Loss: 0.016694230087034728, Train_acc 0.9949845679012346\n",
      "\n",
      "Epoch 84. Loss: 0.015119605669784838, Train_acc 0.995045731707317\n",
      "\n",
      "Epoch 84. Loss: 0.014123709940381314, Train_acc 0.995105421686747\n",
      "\n",
      "Epoch 84. Loss: 0.012827722090975165, Train_acc 0.9951636904761905\n",
      "\n",
      "Epoch 84. Loss: 0.012401938386406648, Train_acc 0.9952205882352941\n",
      "\n",
      "Epoch 84. Loss: 0.011321395053286387, Train_acc 0.9952761627906976\n",
      "\n",
      "Epoch 84. Loss: 0.01024961345807302, Train_acc 0.9953304597701149\n",
      "\n",
      "Epoch 84. Loss: 0.01016821682899226, Train_acc 0.9953835227272727\n",
      "\n",
      "Epoch 84. Loss: 0.012032506164452695, Train_acc 0.9953476123595506\n",
      "\n",
      "Epoch 84. Loss: 0.011203224588818486, Train_acc 0.9953993055555556\n",
      "\n",
      "Epoch 84. Loss: 0.010587634122196259, Train_acc 0.9954498626373627\n",
      "\n",
      "Epoch 84. Loss: 0.010907125022998532, Train_acc 0.9954144021739131\n",
      "\n",
      "Epoch 84. Loss: 0.010164462598144484, Train_acc 0.9954637096774194\n",
      "\n",
      "Epoch 84. Loss: 0.009642030344438082, Train_acc 0.9955119680851063\n",
      "\n",
      "Epoch 84. Loss: 0.009327058004392558, Train_acc 0.9955592105263158\n",
      "\n",
      "Epoch 84. Loss: 0.008528559733434804, Train_acc 0.99560546875\n",
      "\n",
      "Epoch 84. Loss: 0.007804342725634683, Train_acc 0.9956507731958762\n",
      "\n",
      "Epoch 84. Loss: 0.007132828409326919, Train_acc 0.9956951530612245\n",
      "\n",
      "Epoch 84. Loss: 0.007101880356537862, Train_acc 0.9957386363636364\n",
      "\n",
      "Epoch 84. Loss: 0.0064801667256493695, Train_acc 0.99578125\n",
      "\n",
      "[Epoch 84 Batch 100] Loss: 0.006281672917157948 Training: accuracy=0.995823\n",
      "Epoch 84. Loss: 0.006281672917157948, Train_acc 0.9958230198019802\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84. Loss: 0.0056676193752270366, Train_acc 0.9958639705882353\n",
      "\n",
      "Epoch 84. Loss: 0.005183859198935905, Train_acc 0.9959041262135923\n",
      "\n",
      "Epoch 84. Loss: 0.00471018648330323, Train_acc 0.9959435096153846\n",
      "\n",
      "Epoch 84. Loss: 0.0042987759722079525, Train_acc 0.9959821428571428\n",
      "\n",
      "Epoch 84. Loss: 0.004050611458280446, Train_acc 0.9960200471698113\n",
      "\n",
      "Epoch 84. Loss: 0.0037180678145740287, Train_acc 0.9960572429906542\n",
      "\n",
      "Epoch 84. Loss: 0.004548993543981361, Train_acc 0.9960214120370371\n",
      "\n",
      "Epoch 84. Loss: 0.004780127492501302, Train_acc 0.9959862385321101\n",
      "\n",
      "Epoch 84. Loss: 0.004360483412375492, Train_acc 0.9960227272727272\n",
      "\n",
      "Epoch 84. Loss: 0.006433633036402264, Train_acc 0.9959881756756757\n",
      "\n",
      "Epoch 84. Loss: 0.006602172445792615, Train_acc 0.9959542410714286\n",
      "\n",
      "Epoch 84. Loss: 0.006452114941437834, Train_acc 0.9959900442477876\n",
      "\n",
      "Epoch 84. Loss: 0.005902157414741258, Train_acc 0.9960252192982456\n",
      "\n",
      "Epoch 84. Loss: 0.005439407603103167, Train_acc 0.9960597826086957\n",
      "\n",
      "Epoch 84. Loss: 0.0054342410500272335, Train_acc 0.99609375\n",
      "\n",
      "Epoch 84. Loss: 0.005329962733574887, Train_acc 0.9961271367521367\n",
      "\n",
      "Epoch 84. Loss: 0.004997328102272612, Train_acc 0.9961599576271186\n",
      "\n",
      "Epoch 84. Loss: 0.004576241106255527, Train_acc 0.9961922268907563\n",
      "\n",
      "Epoch 84. Loss: 0.004157383091161148, Train_acc 0.9962239583333333\n",
      "\n",
      "Epoch 84. Loss: 0.0039057114562328125, Train_acc 0.9962551652892562\n",
      "\n",
      "Epoch 84. Loss: 0.0035533008660234553, Train_acc 0.9962858606557377\n",
      "\n",
      "Epoch 84. Loss: 0.0033878793965972254, Train_acc 0.9963160569105691\n",
      "\n",
      "Epoch 84. Loss: 0.0030992025951993574, Train_acc 0.9963457661290323\n",
      "\n",
      "Epoch 84. Loss: 0.0028065081624206183, Train_acc 0.996375\n",
      "\n",
      "Epoch 84. Loss: 0.00255581806325313, Train_acc 0.9964037698412699\n",
      "\n",
      "Epoch 84. Loss: 0.002335926691670536, Train_acc 0.9964320866141733\n",
      "\n",
      "Epoch 84. Loss: 0.0026425079144352546, Train_acc 0.9964599609375\n",
      "\n",
      "Epoch 84. Loss: 0.002383390541736392, Train_acc 0.9964874031007752\n",
      "\n",
      "Epoch 84. Loss: 0.004441628881571389, Train_acc 0.9964543269230769\n",
      "\n",
      "Epoch 84. Loss: 0.0040240473716022344, Train_acc 0.996481393129771\n",
      "\n",
      "Epoch 84. Loss: 0.0037590197573247647, Train_acc 0.9965080492424242\n",
      "\n",
      "Epoch 84. Loss: 0.003610312480119744, Train_acc 0.9965343045112782\n",
      "\n",
      "Epoch 84. Loss: 0.003308273922281679, Train_acc 0.9965601679104478\n",
      "\n",
      "Epoch 84. Loss: 0.003005659567929923, Train_acc 0.9965856481481481\n",
      "\n",
      "Epoch 84. Loss: 0.002715288358438215, Train_acc 0.9966107536764706\n",
      "\n",
      "Epoch 84. Loss: 0.0026174736858418897, Train_acc 0.9966354927007299\n",
      "\n",
      "Epoch 84. Loss: 0.002434613815496756, Train_acc 0.9966598731884058\n",
      "\n",
      "Epoch 84. Loss: 0.0022189409226070884, Train_acc 0.9966839028776978\n",
      "\n",
      "Epoch 84. Loss: 0.0019989374406387006, Train_acc 0.9967075892857142\n",
      "\n",
      "Epoch 84. Loss: 0.0018046620484357338, Train_acc 0.9967309397163121\n",
      "\n",
      "Epoch 84. Loss: 0.0016303970163926622, Train_acc 0.9967539612676056\n",
      "\n",
      "Epoch 84. Loss: 0.002404981404173238, Train_acc 0.996722027972028\n",
      "\n",
      "Epoch 84. Loss: 0.0022373944824959605, Train_acc 0.9967447916666666\n",
      "\n",
      "Epoch 84. Loss: 0.0020573472644933254, Train_acc 0.9967672413793104\n",
      "\n",
      "Epoch 84. Loss: 0.002045532093793737, Train_acc 0.9967893835616438\n",
      "\n",
      "Epoch 84. Loss: 0.0018664282167298381, Train_acc 0.9968112244897959\n",
      "\n",
      "Epoch 84. Loss: 0.0019060871182167039, Train_acc 0.9968327702702703\n",
      "\n",
      "Epoch 84. Loss: 0.0017272811643397124, Train_acc 0.9968540268456376\n",
      "\n",
      "Epoch 84. Loss: 0.001584208972205473, Train_acc 0.996875\n",
      "\n",
      "Epoch 84. Loss: 0.0027254969703701913, Train_acc 0.9968439569536424\n",
      "\n",
      "Epoch 84. Loss: 0.0024628353914079135, Train_acc 0.9968647203947368\n",
      "\n",
      "Epoch 84. Loss: 0.0023459340714326858, Train_acc 0.9968852124183006\n",
      "\n",
      "Epoch 84. Loss: 0.0021783811573027542, Train_acc 0.9969054383116883\n",
      "\n",
      "Epoch 84. Loss: 0.0019708194331217476, Train_acc 0.9969254032258065\n",
      "\n",
      "Epoch 84. Loss: 0.001782374819111137, Train_acc 0.9969451121794872\n",
      "\n",
      "Epoch 84. Loss: 0.002746990556262113, Train_acc 0.9969148089171974\n",
      "\n",
      "Epoch 84. Loss: 0.002511015808887305, Train_acc 0.996934335443038\n",
      "\n",
      "Epoch 84. Loss: 0.002363635972379466, Train_acc 0.9969536163522013\n",
      "\n",
      "Epoch 84. Loss: 0.0022181236140702545, Train_acc 0.99697265625\n",
      "\n",
      "Epoch 84. Loss: 0.002038992404198591, Train_acc 0.9969914596273292\n",
      "\n",
      "Epoch 84. Loss: 0.0018606830443122484, Train_acc 0.9970100308641975\n",
      "\n",
      "Epoch 84. Loss: 0.0017064638182494193, Train_acc 0.9970283742331288\n",
      "\n",
      "Epoch 84. Loss: 0.001538522679665985, Train_acc 0.997046493902439\n",
      "\n",
      "Epoch 84. Loss: 0.00361237277602491, Train_acc 0.9970170454545455\n",
      "\n",
      "Epoch 84. Loss: 0.0032664957390723167, Train_acc 0.997035015060241\n",
      "\n",
      "Epoch 84. Loss: 0.0032330499576998534, Train_acc 0.9970527694610778\n",
      "\n",
      "Epoch 84. Loss: 0.003523649892581056, Train_acc 0.9970238095238095\n",
      "\n",
      "Epoch 84. Loss: 0.003394853264575497, Train_acc 0.9970414201183432\n",
      "\n",
      "Epoch 84. Loss: 0.003297189197378125, Train_acc 0.9970588235294118\n",
      "\n",
      "Epoch 84. Loss: 0.003719397493246287, Train_acc 0.99703033625731\n",
      "\n",
      "Epoch 84. Loss: 0.006153067745008847, Train_acc 0.9969567587209303\n",
      "\n",
      "Epoch 84. Loss: 0.010950702396546705, Train_acc 0.9968840317919075\n",
      "\n",
      "Epoch 84. Loss: 0.012299449228508685, Train_acc 0.9968121408045977\n",
      "\n",
      "Epoch 84. Loss: 0.01111309914575692, Train_acc 0.9968303571428572\n",
      "\n",
      "Epoch 84. Loss: 0.010037258715463885, Train_acc 0.9968483664772727\n",
      "\n",
      "Epoch 84. Loss: 0.009118174716589862, Train_acc 0.9968661723163842\n",
      "\n",
      "Epoch 84. Loss: 0.013694251511774672, Train_acc 0.9968398876404494\n",
      "\n",
      "Epoch 84. Loss: 0.019684045703067376, Train_acc 0.9967266061452514\n",
      "\n",
      "Epoch 84. Loss: 0.02379100883679449, Train_acc 0.9966145833333333\n",
      "\n",
      "Epoch 84. Loss: 0.021676597745062646, Train_acc 0.9966332872928176\n",
      "\n",
      "Epoch 84. Loss: 0.025705720708526735, Train_acc 0.9965659340659341\n",
      "\n",
      "Epoch 84. Loss: 0.02554927365549585, Train_acc 0.9965420081967213\n",
      "\n",
      "Epoch 84. Loss: 0.02387753206030888, Train_acc 0.9965183423913043\n",
      "\n",
      "Epoch 84. Loss: 0.021758314682495856, Train_acc 0.9965371621621621\n",
      "\n",
      "Epoch 84. Loss: 0.021072808788078067, Train_acc 0.9965137768817204\n",
      "\n",
      "Epoch 84. Loss: 0.020254694233110878, Train_acc 0.9964906417112299\n",
      "\n",
      "Epoch 84. Loss: 0.024788067021761537, Train_acc 0.9963846409574468\n",
      "\n",
      "Epoch 84. Loss: 0.023158244479114593, Train_acc 0.9963624338624338\n",
      "\n",
      "Epoch 84. Loss: 0.02113652580965142, Train_acc 0.9963815789473685\n",
      "\n",
      "Epoch 84. Loss: 0.019936557578193372, Train_acc 0.9964005235602095\n",
      "\n",
      "Epoch 84. Loss: 0.019691180557442213, Train_acc 0.9963785807291666\n",
      "\n",
      "Epoch 84. Loss: 0.018004582976564026, Train_acc 0.9963973445595855\n",
      "\n",
      "Epoch 84. Loss: 0.02086094356053852, Train_acc 0.9963353737113402\n",
      "\n",
      "Epoch 84. Loss: 0.019018723843757357, Train_acc 0.9963541666666667\n",
      "\n",
      "Epoch 84. Loss: 0.01759561245062713, Train_acc 0.99636\n",
      "\n",
      "Epoch 85. Loss: 0.017409856157768643, Train_acc 0.9921875\n",
      "\n",
      "Epoch 85. Loss: 0.01790605600530107, Train_acc 0.9921875\n",
      "\n",
      "Epoch 85. Loss: 0.017998984746821517, Train_acc 0.9921875\n",
      "\n",
      "Epoch 85. Loss: 0.01741071645261746, Train_acc 0.9921875\n",
      "\n",
      "Epoch 85. Loss: 0.016155873934628678, Train_acc 0.99375\n",
      "\n",
      "Epoch 85. Loss: 0.014715107627859365, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 85. Loss: 0.01709285588397144, Train_acc 0.9944196428571429\n",
      "\n",
      "Epoch 85. Loss: 0.01570590159744226, Train_acc 0.9951171875\n",
      "\n",
      "Epoch 85. Loss: 0.015252111652793316, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 85. Loss: 0.014312390580149138, Train_acc 0.99609375\n",
      "\n",
      "Epoch 85. Loss: 0.013165597972084563, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 85. Loss: 0.012741218938061133, Train_acc 0.99609375\n",
      "\n",
      "Epoch 85. Loss: 0.01166155996851939, Train_acc 0.9963942307692307\n",
      "\n",
      "Epoch 85. Loss: 0.011272928029443187, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 85. Loss: 0.010571990929301407, Train_acc 0.996875\n",
      "\n",
      "Epoch 85. Loss: 0.00975820600648, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 85. Loss: 0.009063766430811054, Train_acc 0.9972426470588235\n",
      "\n",
      "Epoch 85. Loss: 0.008239231662364796, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 85. Loss: 0.007924757031868693, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 85. Loss: 0.0073805010534263825, Train_acc 0.99765625\n",
      "\n",
      "Epoch 85. Loss: 0.007616628330970154, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 85. Loss: 0.0068861152955967675, Train_acc 0.9975142045454546\n",
      "\n",
      "Epoch 85. Loss: 0.006261522309381082, Train_acc 0.9976222826086957\n",
      "\n",
      "Epoch 85. Loss: 0.005704434149146436, Train_acc 0.9977213541666666\n",
      "\n",
      "Epoch 85. Loss: 0.005430825776768051, Train_acc 0.9978125\n",
      "\n",
      "Epoch 85. Loss: 0.005732125414382508, Train_acc 0.9978966346153846\n",
      "\n",
      "Epoch 85. Loss: 0.005271767457530132, Train_acc 0.9979745370370371\n",
      "\n",
      "Epoch 85. Loss: 0.00496706667821577, Train_acc 0.998046875\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85. Loss: 0.004555767796931154, Train_acc 0.998114224137931\n",
      "\n",
      "Epoch 85. Loss: 0.004661881208045024, Train_acc 0.9981770833333333\n",
      "\n",
      "Epoch 85. Loss: 0.004836041339149539, Train_acc 0.9982358870967742\n",
      "\n",
      "Epoch 85. Loss: 0.004764224974060474, Train_acc 0.998291015625\n",
      "\n",
      "Epoch 85. Loss: 0.004340556108844132, Train_acc 0.998342803030303\n",
      "\n",
      "Epoch 85. Loss: 0.005006448244802819, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 85. Loss: 0.0046919772709929945, Train_acc 0.9982142857142857\n",
      "\n",
      "Epoch 85. Loss: 0.004631523610847354, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 85. Loss: 0.004795435209599578, Train_acc 0.9983108108108109\n",
      "\n",
      "Epoch 85. Loss: 0.00589863025950859, Train_acc 0.9981496710526315\n",
      "\n",
      "Epoch 85. Loss: 0.005549153487711877, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 85. Loss: 0.005393596336987373, Train_acc 0.9982421875\n",
      "\n",
      "Epoch 85. Loss: 0.0052891294210375165, Train_acc 0.9982850609756098\n",
      "\n",
      "Epoch 85. Loss: 0.005154514894564821, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 85. Loss: 0.0047010312401714535, Train_acc 0.9983648255813954\n",
      "\n",
      "Epoch 85. Loss: 0.0044199644798901035, Train_acc 0.9984019886363636\n",
      "\n",
      "Epoch 85. Loss: 0.004710773611801835, Train_acc 0.9984375\n",
      "\n",
      "Epoch 85. Loss: 0.006143151396278714, Train_acc 0.9983016304347826\n",
      "\n",
      "Epoch 85. Loss: 0.006888619183389105, Train_acc 0.9981715425531915\n",
      "\n",
      "Epoch 85. Loss: 0.006459286435630403, Train_acc 0.9982096354166666\n",
      "\n",
      "Epoch 85. Loss: 0.0059613864395944615, Train_acc 0.9982461734693877\n",
      "\n",
      "Epoch 85. Loss: 0.005401339627497011, Train_acc 0.99828125\n",
      "\n",
      "Epoch 85. Loss: 0.006862508540325713, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 85. Loss: 0.006241108925151096, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 85. Loss: 0.005912156461707294, Train_acc 0.9982311320754716\n",
      "\n",
      "Epoch 85. Loss: 0.013246749245254583, Train_acc 0.9979745370370371\n",
      "\n",
      "Epoch 85. Loss: 0.012126282813961851, Train_acc 0.9980113636363637\n",
      "\n",
      "Epoch 85. Loss: 0.011475712875186398, Train_acc 0.998046875\n",
      "\n",
      "Epoch 85. Loss: 0.011503653216057117, Train_acc 0.9979440789473685\n",
      "\n",
      "Epoch 85. Loss: 0.011115591719919231, Train_acc 0.9978448275862069\n",
      "\n",
      "Epoch 85. Loss: 0.010386547358116914, Train_acc 0.9978813559322034\n",
      "\n",
      "Epoch 85. Loss: 0.010360608040196964, Train_acc 0.9977864583333333\n",
      "\n",
      "Epoch 85. Loss: 0.013199411665412726, Train_acc 0.9975665983606558\n",
      "\n",
      "Epoch 85. Loss: 0.01222960387506748, Train_acc 0.9976058467741935\n",
      "\n",
      "Epoch 85. Loss: 0.011302702552127822, Train_acc 0.9976438492063492\n",
      "\n",
      "Epoch 85. Loss: 0.010934717263100729, Train_acc 0.99755859375\n",
      "\n",
      "Epoch 85. Loss: 0.009870538376253525, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 85. Loss: 0.010447067294253421, Train_acc 0.9975142045454546\n",
      "\n",
      "Epoch 85. Loss: 0.009487082304231982, Train_acc 0.9975513059701493\n",
      "\n",
      "Epoch 85. Loss: 0.008572382842661585, Train_acc 0.9975873161764706\n",
      "\n",
      "Epoch 85. Loss: 0.007756911188997496, Train_acc 0.9976222826086957\n",
      "\n",
      "Epoch 85. Loss: 0.007559838538814486, Train_acc 0.99765625\n",
      "\n",
      "Epoch 85. Loss: 0.01013147694955668, Train_acc 0.9974691901408451\n",
      "\n",
      "Epoch 85. Loss: 0.009157275517394627, Train_acc 0.9975043402777778\n",
      "\n",
      "Epoch 85. Loss: 0.008837173455605344, Train_acc 0.9975385273972602\n",
      "\n",
      "Epoch 85. Loss: 0.008606155981033536, Train_acc 0.9974662162162162\n",
      "\n",
      "Epoch 85. Loss: 0.007775228612481722, Train_acc 0.9975\n",
      "\n",
      "Epoch 85. Loss: 0.007061426737014952, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 85. Loss: 0.007966301126573535, Train_acc 0.997463474025974\n",
      "\n",
      "Epoch 85. Loss: 0.010488836124504256, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 85. Loss: 0.009466385818683599, Train_acc 0.9974287974683544\n",
      "\n",
      "Epoch 85. Loss: 0.008877964655940379, Train_acc 0.9974609375\n",
      "\n",
      "Epoch 85. Loss: 0.008157382921100836, Train_acc 0.9974922839506173\n",
      "\n",
      "Epoch 85. Loss: 0.007475349942773891, Train_acc 0.9975228658536586\n",
      "\n",
      "Epoch 85. Loss: 0.007633389713552874, Train_acc 0.9974585843373494\n",
      "\n",
      "Epoch 85. Loss: 0.009134026630688264, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 85. Loss: 0.008303363456772465, Train_acc 0.9974264705882353\n",
      "\n",
      "Epoch 85. Loss: 0.007482468322390998, Train_acc 0.9974563953488372\n",
      "\n",
      "Epoch 85. Loss: 0.006749687709490021, Train_acc 0.9974856321839081\n",
      "\n",
      "Epoch 85. Loss: 0.006119373056205342, Train_acc 0.9975142045454546\n",
      "\n",
      "Epoch 85. Loss: 0.006135628426816073, Train_acc 0.9975421348314607\n",
      "\n",
      "Epoch 85. Loss: 0.008086301733326322, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 85. Loss: 0.007388285033219075, Train_acc 0.9974244505494505\n",
      "\n",
      "Epoch 85. Loss: 0.006666564943055152, Train_acc 0.997452445652174\n",
      "\n",
      "Epoch 85. Loss: 0.006068942047742611, Train_acc 0.9974798387096774\n",
      "\n",
      "Epoch 85. Loss: 0.005494600937174728, Train_acc 0.9975066489361702\n",
      "\n",
      "Epoch 85. Loss: 0.005246264626449618, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 85. Loss: 0.004859433834693974, Train_acc 0.99755859375\n",
      "\n",
      "Epoch 85. Loss: 0.0045292404381041046, Train_acc 0.9975837628865979\n",
      "\n",
      "Epoch 85. Loss: 0.008862423338377862, Train_acc 0.9975286989795918\n",
      "\n",
      "Epoch 85. Loss: 0.009758841190830817, Train_acc 0.9974747474747475\n",
      "\n",
      "Epoch 85. Loss: 0.00898053971708949, Train_acc 0.9975\n",
      "\n",
      "[Epoch 85 Batch 100] Loss: 0.0081168230790169 Training: accuracy=0.997525\n",
      "Epoch 85. Loss: 0.0081168230790169, Train_acc 0.9975247524752475\n",
      "\n",
      "Epoch 85. Loss: 0.00748633016008326, Train_acc 0.9975490196078431\n",
      "\n",
      "Epoch 85. Loss: 0.007102282783983844, Train_acc 0.9975728155339806\n",
      "\n",
      "Epoch 85. Loss: 0.006504647330320207, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 85. Loss: 0.00805082293231159, Train_acc 0.9975446428571428\n",
      "\n",
      "Epoch 85. Loss: 0.00796306777748945, Train_acc 0.9975678066037735\n",
      "\n",
      "Epoch 85. Loss: 0.007338003863611662, Train_acc 0.9975905373831776\n",
      "\n",
      "Epoch 85. Loss: 0.008232773363338868, Train_acc 0.9975405092592593\n",
      "\n",
      "Epoch 85. Loss: 0.00744578733943131, Train_acc 0.9975630733944955\n",
      "\n",
      "Epoch 85. Loss: 0.007007742953543899, Train_acc 0.9975852272727272\n",
      "\n",
      "Epoch 85. Loss: 0.01123027431867573, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 85. Loss: 0.010126146565060794, Train_acc 0.9974190848214286\n",
      "\n",
      "Epoch 85. Loss: 0.009515519043965024, Train_acc 0.997441924778761\n",
      "\n",
      "Epoch 85. Loss: 0.009019024248343303, Train_acc 0.9974643640350878\n",
      "\n",
      "Epoch 85. Loss: 0.008146374211557889, Train_acc 0.9974864130434783\n",
      "\n",
      "Epoch 85. Loss: 0.00812079006285803, Train_acc 0.9975080818965517\n",
      "\n",
      "Epoch 85. Loss: 0.007682460025858908, Train_acc 0.9975293803418803\n",
      "\n",
      "Epoch 85. Loss: 0.00860753187618735, Train_acc 0.9974841101694916\n",
      "\n",
      "Epoch 85. Loss: 0.007884506291419261, Train_acc 0.9975052521008403\n",
      "\n",
      "Epoch 85. Loss: 0.007492190506327147, Train_acc 0.9975260416666667\n",
      "\n",
      "Epoch 85. Loss: 0.006792788639447908, Train_acc 0.9975464876033058\n",
      "\n",
      "Epoch 85. Loss: 0.0061770154744298636, Train_acc 0.9975665983606558\n",
      "\n",
      "Epoch 85. Loss: 0.005712752720482175, Train_acc 0.9975863821138211\n",
      "\n",
      "Epoch 85. Loss: 0.0051885829904688, Train_acc 0.9976058467741935\n",
      "\n",
      "Epoch 85. Loss: 0.004780090642390036, Train_acc 0.997625\n",
      "\n",
      "Epoch 85. Loss: 0.0054204054369783854, Train_acc 0.9976438492063492\n",
      "\n",
      "Epoch 85. Loss: 0.00599458172791509, Train_acc 0.9976008858267716\n",
      "\n",
      "Epoch 85. Loss: 0.005431201571397258, Train_acc 0.99761962890625\n",
      "\n",
      "Epoch 85. Loss: 0.005358108555530553, Train_acc 0.9976380813953488\n",
      "\n",
      "Epoch 85. Loss: 0.004902922760923248, Train_acc 0.99765625\n",
      "\n",
      "Epoch 85. Loss: 0.004463803703356869, Train_acc 0.9976741412213741\n",
      "\n",
      "Epoch 85. Loss: 0.0040415313716543125, Train_acc 0.9976917613636364\n",
      "\n",
      "Epoch 85. Loss: 0.0037049807806759988, Train_acc 0.9977091165413534\n",
      "\n",
      "Epoch 85. Loss: 0.003430659581623219, Train_acc 0.9977262126865671\n",
      "\n",
      "Epoch 85. Loss: 0.0034067476950824945, Train_acc 0.9977430555555555\n",
      "\n",
      "Epoch 85. Loss: 0.0032262195000640178, Train_acc 0.9977596507352942\n",
      "\n",
      "Epoch 85. Loss: 0.0029390699621856175, Train_acc 0.997776003649635\n",
      "\n",
      "Epoch 85. Loss: 0.0026854788317389007, Train_acc 0.9977921195652174\n",
      "\n",
      "Epoch 85. Loss: 0.002466356877884124, Train_acc 0.9978080035971223\n",
      "\n",
      "Epoch 85. Loss: 0.002254984520305712, Train_acc 0.9978236607142857\n",
      "\n",
      "Epoch 85. Loss: 0.002039848839265609, Train_acc 0.9978390957446809\n",
      "\n",
      "Epoch 85. Loss: 0.0019254275127515237, Train_acc 0.9978543133802817\n",
      "\n",
      "Epoch 85. Loss: 0.001773461490701366, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 85. Loss: 0.0016160921933944332, Train_acc 0.9978841145833334\n",
      "\n",
      "Epoch 85. Loss: 0.0020138035077031232, Train_acc 0.9978987068965517\n",
      "\n",
      "Epoch 85. Loss: 0.002087094747819821, Train_acc 0.9979130993150684\n",
      "\n",
      "Epoch 85. Loss: 0.0019547053128447264, Train_acc 0.9979272959183674\n",
      "\n",
      "Epoch 85. Loss: 0.0020184532862126347, Train_acc 0.9979413006756757\n",
      "\n",
      "Epoch 85. Loss: 0.0023860998841720386, Train_acc 0.9979551174496645\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85. Loss: 0.0024700115133909194, Train_acc 0.99796875\n",
      "\n",
      "Epoch 85. Loss: 0.004358677380644185, Train_acc 0.9979304635761589\n",
      "\n",
      "Epoch 85. Loss: 0.0041493457330655185, Train_acc 0.9979440789473685\n",
      "\n",
      "Epoch 85. Loss: 0.003777496310296048, Train_acc 0.9979575163398693\n",
      "\n",
      "Epoch 85. Loss: 0.00454305093785142, Train_acc 0.9979200487012987\n",
      "\n",
      "Epoch 85. Loss: 0.004110420632215818, Train_acc 0.9979334677419355\n",
      "\n",
      "Epoch 85. Loss: 0.003802463998867554, Train_acc 0.9979467147435898\n",
      "\n",
      "Epoch 85. Loss: 0.0056548056815327544, Train_acc 0.9979100318471338\n",
      "\n",
      "Epoch 85. Loss: 0.005104680774541654, Train_acc 0.9979232594936709\n",
      "\n",
      "Epoch 85. Loss: 0.004618213264005891, Train_acc 0.9979363207547169\n",
      "\n",
      "Epoch 85. Loss: 0.004329918288014095, Train_acc 0.99794921875\n",
      "\n",
      "Epoch 85. Loss: 0.003910262994115604, Train_acc 0.9979619565217391\n",
      "\n",
      "Epoch 85. Loss: 0.003528814429885709, Train_acc 0.9979745370370371\n",
      "\n",
      "Epoch 85. Loss: 0.0032605269721268687, Train_acc 0.9979869631901841\n",
      "\n",
      "Epoch 85. Loss: 0.0031422612354414826, Train_acc 0.9979992378048781\n",
      "\n",
      "Epoch 85. Loss: 0.0029565613874091654, Train_acc 0.9980113636363637\n",
      "\n",
      "Epoch 85. Loss: 0.002714446413047816, Train_acc 0.998023343373494\n",
      "\n",
      "Epoch 85. Loss: 0.0037842521243045086, Train_acc 0.9979883982035929\n",
      "\n",
      "Epoch 85. Loss: 0.0034376468165628034, Train_acc 0.9980003720238095\n",
      "\n",
      "Epoch 85. Loss: 0.004020202948502772, Train_acc 0.9980122041420119\n",
      "\n",
      "Epoch 85. Loss: 0.0036409650171738955, Train_acc 0.9980238970588236\n",
      "\n",
      "Epoch 85. Loss: 0.00332500339012541, Train_acc 0.9980354532163743\n",
      "\n",
      "Epoch 85. Loss: 0.006876974631499031, Train_acc 0.9979560319767442\n",
      "\n",
      "Epoch 85. Loss: 0.006227799289379965, Train_acc 0.9979678468208093\n",
      "\n",
      "Epoch 85. Loss: 0.006798261601139114, Train_acc 0.9979346264367817\n",
      "\n",
      "Epoch 85. Loss: 0.006330286204323774, Train_acc 0.9979464285714286\n",
      "\n",
      "Epoch 85. Loss: 0.0061373876872708845, Train_acc 0.9979580965909091\n",
      "\n",
      "Epoch 85. Loss: 0.008283482924972515, Train_acc 0.9979254943502824\n",
      "\n",
      "Epoch 85. Loss: 0.007653354209325797, Train_acc 0.9979371488764045\n",
      "\n",
      "Epoch 85. Loss: 0.006906656315348208, Train_acc 0.9979486731843575\n",
      "\n",
      "Epoch 85. Loss: 0.006312572571732843, Train_acc 0.9979600694444445\n",
      "\n",
      "Epoch 85. Loss: 0.0058018104928306445, Train_acc 0.9979713397790055\n",
      "\n",
      "Epoch 85. Loss: 0.005486495558141622, Train_acc 0.9979824862637363\n",
      "\n",
      "Epoch 85. Loss: 0.004975413896069113, Train_acc 0.9979935109289617\n",
      "\n",
      "Epoch 85. Loss: 0.004661838202949777, Train_acc 0.9980044157608695\n",
      "\n",
      "Epoch 85. Loss: 0.00444512254531063, Train_acc 0.9980152027027027\n",
      "\n",
      "Epoch 85. Loss: 0.004301867811693645, Train_acc 0.998025873655914\n",
      "\n",
      "Epoch 85. Loss: 0.004017000088152793, Train_acc 0.9980364304812834\n",
      "\n",
      "Epoch 85. Loss: 0.009804618825665868, Train_acc 0.9980053191489362\n",
      "\n",
      "Epoch 85. Loss: 0.008854523655698344, Train_acc 0.998015873015873\n",
      "\n",
      "Epoch 85. Loss: 0.008008498502451571, Train_acc 0.9980263157894737\n",
      "\n",
      "Epoch 85. Loss: 0.007411782686199301, Train_acc 0.9980366492146597\n",
      "\n",
      "Epoch 85. Loss: 0.009098204555468756, Train_acc 0.9979654947916666\n",
      "\n",
      "Epoch 85. Loss: 0.008222178495780304, Train_acc 0.9979760362694301\n",
      "\n",
      "Epoch 85. Loss: 0.007680935079028316, Train_acc 0.9979864690721649\n",
      "\n",
      "Epoch 85. Loss: 0.0072179641040072805, Train_acc 0.9979967948717948\n",
      "\n",
      "Epoch 85. Loss: 0.006521448520564449, Train_acc 0.998\n",
      "\n",
      "Epoch 86. Loss: 0.005988058903379064, Train_acc 1.0\n",
      "\n",
      "Epoch 86. Loss: 0.005411054951460388, Train_acc 1.0\n",
      "\n",
      "Epoch 86. Loss: 0.004957525536427998, Train_acc 1.0\n",
      "\n",
      "Epoch 86. Loss: 0.004759033523322735, Train_acc 1.0\n",
      "\n",
      "Epoch 86. Loss: 0.004410609919325198, Train_acc 1.0\n",
      "\n",
      "Epoch 86. Loss: 0.0040299268725848365, Train_acc 1.0\n",
      "\n",
      "Epoch 86. Loss: 0.003966193439141169, Train_acc 1.0\n",
      "\n",
      "Epoch 86. Loss: 0.004096024949021866, Train_acc 1.0\n",
      "\n",
      "Epoch 86. Loss: 0.0038552427267851503, Train_acc 1.0\n",
      "\n",
      "Epoch 86. Loss: 0.0034845475789545277, Train_acc 1.0\n",
      "\n",
      "Epoch 86. Loss: 0.004170816695240584, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 86. Loss: 0.003855301701301289, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 86. Loss: 0.004133219283766108, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 86. Loss: 0.0067493729027627925, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 86. Loss: 0.006094060220589699, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 86. Loss: 0.005526404737624939, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 86. Loss: 0.005034556973563208, Train_acc 0.9990808823529411\n",
      "\n",
      "Epoch 86. Loss: 0.004565128048689208, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 86. Loss: 0.00414150752570834, Train_acc 0.9991776315789473\n",
      "\n",
      "Epoch 86. Loss: 0.0037933476132223564, Train_acc 0.99921875\n",
      "\n",
      "Epoch 86. Loss: 0.0034443208999081305, Train_acc 0.9992559523809523\n",
      "\n",
      "Epoch 86. Loss: 0.003246129481082605, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 86. Loss: 0.0030316917490791797, Train_acc 0.9993206521739131\n",
      "\n",
      "Epoch 86. Loss: 0.002945095794848936, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 86. Loss: 0.0027583559649570323, Train_acc 0.999375\n",
      "\n",
      "Epoch 86. Loss: 0.0025713235941238885, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 86. Loss: 0.0024551033554076566, Train_acc 0.9994212962962963\n",
      "\n",
      "Epoch 86. Loss: 0.002422610660502262, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 86. Loss: 0.002841392439328683, Train_acc 0.9994612068965517\n",
      "\n",
      "Epoch 86. Loss: 0.002583838901323388, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 86. Loss: 0.0023683706435572525, Train_acc 0.9994959677419355\n",
      "\n",
      "Epoch 86. Loss: 0.0021401921884963253, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 86. Loss: 0.0019392803773683838, Train_acc 0.9995265151515151\n",
      "\n",
      "Epoch 86. Loss: 0.002730973534918058, Train_acc 0.9993106617647058\n",
      "\n",
      "Epoch 86. Loss: 0.002476668278824798, Train_acc 0.9993303571428571\n",
      "\n",
      "Epoch 86. Loss: 0.0031703837994797633, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 86. Loss: 0.0028908474163805192, Train_acc 0.9991554054054054\n",
      "\n",
      "Epoch 86. Loss: 0.002618379725020468, Train_acc 0.9991776315789473\n",
      "\n",
      "Epoch 86. Loss: 0.004328700564504868, Train_acc 0.9989983974358975\n",
      "\n",
      "Epoch 86. Loss: 0.004002238827024733, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 86. Loss: 0.00361457770878155, Train_acc 0.999047256097561\n",
      "\n",
      "Epoch 86. Loss: 0.0032609837921652083, Train_acc 0.9990699404761905\n",
      "\n",
      "Epoch 86. Loss: 0.0032195413871952488, Train_acc 0.9990915697674418\n",
      "\n",
      "Epoch 86. Loss: 0.0036066837770654496, Train_acc 0.9991122159090909\n",
      "\n",
      "Epoch 86. Loss: 0.0032610992292894225, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 86. Loss: 0.00307436489614844, Train_acc 0.9991508152173914\n",
      "\n",
      "Epoch 86. Loss: 0.003978201983597872, Train_acc 0.9990026595744681\n",
      "\n",
      "Epoch 86. Loss: 0.003604690232847741, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 86. Loss: 0.003252350238282817, Train_acc 0.9990433673469388\n",
      "\n",
      "Epoch 86. Loss: 0.0029324937060053358, Train_acc 0.9990625\n",
      "\n",
      "Epoch 86. Loss: 0.0026625045794567283, Train_acc 0.9990808823529411\n",
      "\n",
      "Epoch 86. Loss: 0.0024023641884082913, Train_acc 0.9990985576923077\n",
      "\n",
      "Epoch 86. Loss: 0.002166284722058492, Train_acc 0.9991155660377359\n",
      "\n",
      "Epoch 86. Loss: 0.001955593102392532, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 86. Loss: 0.001784166803328133, Train_acc 0.9991477272727273\n",
      "\n",
      "Epoch 86. Loss: 0.0022089047506015924, Train_acc 0.9991629464285714\n",
      "\n",
      "Epoch 86. Loss: 0.002763249328693279, Train_acc 0.9990405701754386\n",
      "\n",
      "Epoch 86. Loss: 0.003468511194849487, Train_acc 0.9989224137931034\n",
      "\n",
      "Epoch 86. Loss: 0.0031280703977494472, Train_acc 0.9989406779661016\n",
      "\n",
      "Epoch 86. Loss: 0.0028202354883839443, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 86. Loss: 0.0025537667523987746, Train_acc 0.9989754098360656\n",
      "\n",
      "Epoch 86. Loss: 0.002337543390423148, Train_acc 0.998991935483871\n",
      "\n",
      "Epoch 86. Loss: 0.0021183644359380805, Train_acc 0.9990079365079365\n",
      "\n",
      "Epoch 86. Loss: 0.0019224258578678568, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 86. Loss: 0.0019185947416523637, Train_acc 0.9990384615384615\n",
      "\n",
      "Epoch 86. Loss: 0.001767654673943069, Train_acc 0.9990530303030303\n",
      "\n",
      "Epoch 86. Loss: 0.0016484078633799968, Train_acc 0.9990671641791045\n",
      "\n",
      "Epoch 86. Loss: 0.0015831755188567775, Train_acc 0.9990808823529411\n",
      "\n",
      "Epoch 86. Loss: 0.001435018478709022, Train_acc 0.9990942028985508\n",
      "\n",
      "Epoch 86. Loss: 0.0019161205952264904, Train_acc 0.9989955357142857\n",
      "\n",
      "Epoch 86. Loss: 0.0017944573046455269, Train_acc 0.9990096830985915\n",
      "\n",
      "Epoch 86. Loss: 0.0017150478190204042, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 86. Loss: 0.001702633864337552, Train_acc 0.9990368150684932\n",
      "\n",
      "Epoch 86. Loss: 0.0017446162151062625, Train_acc 0.999049831081081\n",
      "\n",
      "Epoch 86. Loss: 0.0016185419818287316, Train_acc 0.9990625\n",
      "\n",
      "Epoch 86. Loss: 0.0014723310270327342, Train_acc 0.9990748355263158\n",
      "\n",
      "Epoch 86. Loss: 0.001327760546830254, Train_acc 0.9990868506493507\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86. Loss: 0.0013588647504801667, Train_acc 0.9990985576923077\n",
      "\n",
      "Epoch 86. Loss: 0.0012797934926812456, Train_acc 0.9991099683544303\n",
      "\n",
      "Epoch 86. Loss: 0.0013492592789767332, Train_acc 0.99912109375\n",
      "\n",
      "Epoch 86. Loss: 0.0012671033920083773, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 86. Loss: 0.0011482362942814323, Train_acc 0.9991425304878049\n",
      "\n",
      "Epoch 86. Loss: 0.00445937290760155, Train_acc 0.999058734939759\n",
      "\n",
      "Epoch 86. Loss: 0.004982934221377452, Train_acc 0.9989769345238095\n",
      "\n",
      "Epoch 86. Loss: 0.004500584803065714, Train_acc 0.9989889705882353\n",
      "\n",
      "Epoch 86. Loss: 0.004065776651338129, Train_acc 0.999000726744186\n",
      "\n",
      "Epoch 86. Loss: 0.003798582515517225, Train_acc 0.9990122126436781\n",
      "\n",
      "Epoch 86. Loss: 0.0037450708001324686, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 86. Loss: 0.003387147805943655, Train_acc 0.9990344101123596\n",
      "\n",
      "Epoch 86. Loss: 0.00343102248104325, Train_acc 0.9990451388888889\n",
      "\n",
      "Epoch 86. Loss: 0.003169869855774889, Train_acc 0.9990556318681318\n",
      "\n",
      "Epoch 86. Loss: 0.002868999669285595, Train_acc 0.9990658967391305\n",
      "\n",
      "Epoch 86. Loss: 0.003428776603339892, Train_acc 0.999075940860215\n",
      "\n",
      "Epoch 86. Loss: 0.004250353444128139, Train_acc 0.9990026595744681\n",
      "\n",
      "Epoch 86. Loss: 0.006823064045765015, Train_acc 0.9988486842105263\n",
      "\n",
      "Epoch 86. Loss: 0.006308321745965344, Train_acc 0.9988606770833334\n",
      "\n",
      "Epoch 86. Loss: 0.0056891018323740215, Train_acc 0.9988724226804123\n",
      "\n",
      "Epoch 86. Loss: 0.005128546963048653, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 86. Loss: 0.004655685251710163, Train_acc 0.998895202020202\n",
      "\n",
      "Epoch 86. Loss: 0.004222776410614189, Train_acc 0.99890625\n",
      "\n",
      "[Epoch 86 Batch 100] Loss: 0.003977590280984851 Training: accuracy=0.998917\n",
      "Epoch 86. Loss: 0.003977590280984851, Train_acc 0.9989170792079208\n",
      "\n",
      "Epoch 86. Loss: 0.00416239913467915, Train_acc 0.9989276960784313\n",
      "\n",
      "Epoch 86. Loss: 0.005348642948249142, Train_acc 0.9988622572815534\n",
      "\n",
      "Epoch 86. Loss: 0.004901060464708129, Train_acc 0.9988731971153846\n",
      "\n",
      "Epoch 86. Loss: 0.004421468471666095, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 86. Loss: 0.005462231356066391, Train_acc 0.9988207547169812\n",
      "\n",
      "Epoch 86. Loss: 0.004923337794605595, Train_acc 0.9988317757009346\n",
      "\n",
      "Epoch 86. Loss: 0.004441536883472608, Train_acc 0.9988425925925926\n",
      "\n",
      "Epoch 86. Loss: 0.0046863242268197595, Train_acc 0.9988532110091743\n",
      "\n",
      "Epoch 86. Loss: 0.004244312312425817, Train_acc 0.9988636363636364\n",
      "\n",
      "Epoch 86. Loss: 0.003980307774220387, Train_acc 0.9988738738738738\n",
      "\n",
      "Epoch 86. Loss: 0.007268914428181481, Train_acc 0.9987444196428571\n",
      "\n",
      "Epoch 86. Loss: 0.00656188796054707, Train_acc 0.9987555309734514\n",
      "\n",
      "Epoch 86. Loss: 0.005930669319701666, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 86. Loss: 0.005360466663983721, Train_acc 0.9987771739130434\n",
      "\n",
      "Epoch 86. Loss: 0.005253675233525566, Train_acc 0.9987877155172413\n",
      "\n",
      "Epoch 86. Loss: 0.0070145287971519225, Train_acc 0.9987313034188035\n",
      "\n",
      "Epoch 86. Loss: 0.009674061881973398, Train_acc 0.9986758474576272\n",
      "\n",
      "Epoch 86. Loss: 0.009141164427227424, Train_acc 0.998686974789916\n",
      "\n",
      "Epoch 86. Loss: 0.008311889288264868, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 86. Loss: 0.007495149206361569, Train_acc 0.9987086776859504\n",
      "\n",
      "Epoch 86. Loss: 0.007018227560437975, Train_acc 0.998719262295082\n",
      "\n",
      "Epoch 86. Loss: 0.007008354753062657, Train_acc 0.998729674796748\n",
      "\n",
      "Epoch 86. Loss: 0.00647665848183754, Train_acc 0.9987399193548387\n",
      "\n",
      "Epoch 86. Loss: 0.006108513248657789, Train_acc 0.99875\n",
      "\n",
      "Epoch 86. Loss: 0.005677635482780432, Train_acc 0.9987599206349206\n",
      "\n",
      "Epoch 86. Loss: 0.0060432373651852864, Train_acc 0.9987081692913385\n",
      "\n",
      "Epoch 86. Loss: 0.012142934873907923, Train_acc 0.99859619140625\n",
      "\n",
      "Epoch 86. Loss: 0.010966469168733612, Train_acc 0.9986070736434108\n",
      "\n",
      "Epoch 86. Loss: 0.013782656329933751, Train_acc 0.9985576923076923\n",
      "\n",
      "Epoch 86. Loss: 0.012474792234172477, Train_acc 0.9985687022900763\n",
      "\n",
      "Epoch 86. Loss: 0.011563270353514003, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 86. Loss: 0.010908342991684123, Train_acc 0.9985902255639098\n",
      "\n",
      "Epoch 86. Loss: 0.010191345345822792, Train_acc 0.9986007462686567\n",
      "\n",
      "Epoch 86. Loss: 0.009495624822167594, Train_acc 0.9986111111111111\n",
      "\n",
      "Epoch 86. Loss: 0.008644883581359421, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 86. Loss: 0.007803042188449638, Train_acc 0.9986313868613139\n",
      "\n",
      "Epoch 86. Loss: 0.007038350498264078, Train_acc 0.998641304347826\n",
      "\n",
      "Epoch 86. Loss: 0.006417161950852388, Train_acc 0.9986510791366906\n",
      "\n",
      "Epoch 86. Loss: 0.010485823881077095, Train_acc 0.9985491071428572\n",
      "\n",
      "Epoch 86. Loss: 0.009466176771502414, Train_acc 0.9985593971631206\n",
      "\n",
      "Epoch 86. Loss: 0.01131661266241734, Train_acc 0.9985145246478874\n",
      "\n",
      "Epoch 86. Loss: 0.011274887239077073, Train_acc 0.9984702797202797\n",
      "\n",
      "Epoch 86. Loss: 0.015404218985264046, Train_acc 0.9983723958333334\n",
      "\n",
      "Epoch 86. Loss: 0.01640826274778653, Train_acc 0.9983297413793103\n",
      "\n",
      "Epoch 86. Loss: 0.014828353141743323, Train_acc 0.9983411815068494\n",
      "\n",
      "Epoch 86. Loss: 0.013568693030996663, Train_acc 0.9983524659863946\n",
      "\n",
      "Epoch 86. Loss: 0.016188390072396586, Train_acc 0.9983108108108109\n",
      "\n",
      "Epoch 86. Loss: 0.015225702417607179, Train_acc 0.9983221476510067\n",
      "\n",
      "Epoch 86. Loss: 0.01469200918172157, Train_acc 0.99828125\n",
      "\n",
      "Epoch 86. Loss: 0.01339264124474099, Train_acc 0.9982926324503312\n",
      "\n",
      "Epoch 86. Loss: 0.012070235553349126, Train_acc 0.998303865131579\n",
      "\n",
      "Epoch 86. Loss: 0.012743352414338353, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 86. Loss: 0.011612545285580513, Train_acc 0.9982751623376623\n",
      "\n",
      "Epoch 86. Loss: 0.01053582544610802, Train_acc 0.9982862903225806\n",
      "\n",
      "Epoch 86. Loss: 0.010104158510141705, Train_acc 0.9982972756410257\n",
      "\n",
      "Epoch 86. Loss: 0.010286620752698006, Train_acc 0.9982583598726115\n",
      "\n",
      "Epoch 86. Loss: 0.012330807593481978, Train_acc 0.9982199367088608\n",
      "\n",
      "Epoch 86. Loss: 0.013109128040388739, Train_acc 0.9981328616352201\n",
      "\n",
      "Epoch 86. Loss: 0.01339614237455921, Train_acc 0.998095703125\n",
      "\n",
      "Epoch 86. Loss: 0.012980274588838785, Train_acc 0.9980590062111802\n",
      "\n",
      "Epoch 86. Loss: 0.01239124833767912, Train_acc 0.998022762345679\n",
      "\n",
      "Epoch 86. Loss: 0.01131637863122196, Train_acc 0.9980348926380368\n",
      "\n",
      "Epoch 86. Loss: 0.01025917312764246, Train_acc 0.998046875\n",
      "\n",
      "Epoch 86. Loss: 0.01230589108553337, Train_acc 0.9979640151515151\n",
      "\n",
      "Epoch 86. Loss: 0.011464992441342534, Train_acc 0.9979762801204819\n",
      "\n",
      "Epoch 86. Loss: 0.010379963461544375, Train_acc 0.9979883982035929\n",
      "\n",
      "Epoch 86. Loss: 0.00956741004272067, Train_acc 0.9980003720238095\n",
      "\n",
      "Epoch 86. Loss: 0.008636809883596497, Train_acc 0.9980122041420119\n",
      "\n",
      "Epoch 86. Loss: 0.007954224872550663, Train_acc 0.9980238970588236\n",
      "\n",
      "Epoch 86. Loss: 0.007326514977815417, Train_acc 0.9980354532163743\n",
      "\n",
      "Epoch 86. Loss: 0.014811540208997729, Train_acc 0.9979560319767442\n",
      "\n",
      "Epoch 86. Loss: 0.013496667873331071, Train_acc 0.9979678468208093\n",
      "\n",
      "Epoch 86. Loss: 0.015539395718099024, Train_acc 0.9979346264367817\n",
      "\n",
      "Epoch 86. Loss: 0.014346990889858913, Train_acc 0.9979464285714286\n",
      "\n",
      "Epoch 86. Loss: 0.01309401895877872, Train_acc 0.9979580965909091\n",
      "\n",
      "Epoch 86. Loss: 0.012258265279476233, Train_acc 0.9979696327683616\n",
      "\n",
      "Epoch 86. Loss: 0.013458347793887009, Train_acc 0.9979371488764045\n",
      "\n",
      "Epoch 86. Loss: 0.014687451177659587, Train_acc 0.9978613826815642\n",
      "\n",
      "Epoch 86. Loss: 0.01339384192197587, Train_acc 0.9978732638888889\n",
      "\n",
      "Epoch 86. Loss: 0.01335600878121614, Train_acc 0.9978418508287292\n",
      "\n",
      "Epoch 86. Loss: 0.012481657003138896, Train_acc 0.9978537087912088\n",
      "\n",
      "Epoch 86. Loss: 0.012579818108476195, Train_acc 0.9978227459016393\n",
      "\n",
      "Epoch 86. Loss: 0.011612052942854457, Train_acc 0.9978345788043478\n",
      "\n",
      "Epoch 86. Loss: 0.012134277649708654, Train_acc 0.997804054054054\n",
      "\n",
      "Epoch 86. Loss: 0.01148276322043365, Train_acc 0.9978158602150538\n",
      "\n",
      "Epoch 86. Loss: 0.010614296153543227, Train_acc 0.9978275401069518\n",
      "\n",
      "Epoch 86. Loss: 0.010297493255830854, Train_acc 0.9978390957446809\n",
      "\n",
      "Epoch 86. Loss: 0.013276151075986372, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 86. Loss: 0.013448480800563704, Train_acc 0.9977384868421053\n",
      "\n",
      "Epoch 86. Loss: 0.012418192996963512, Train_acc 0.9977503272251309\n",
      "\n",
      "Epoch 86. Loss: 0.011522548277312205, Train_acc 0.9977620442708334\n",
      "\n",
      "Epoch 86. Loss: 0.011982349868834334, Train_acc 0.997773639896373\n",
      "\n",
      "Epoch 86. Loss: 0.011010793022412346, Train_acc 0.9977851159793815\n",
      "\n",
      "Epoch 86. Loss: 0.010627192896990436, Train_acc 0.9977564102564103\n",
      "\n",
      "Epoch 86. Loss: 0.010297002165292316, Train_acc 0.99776\n",
      "\n",
      "Epoch 87. Loss: 0.00952524186393584, Train_acc 1.0\n",
      "\n",
      "Epoch 87. Loss: 0.009316868489348576, Train_acc 0.99609375\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87. Loss: 0.008740830914256292, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 87. Loss: 0.007977345370440023, Train_acc 0.998046875\n",
      "\n",
      "Epoch 87. Loss: 0.007462248934303227, Train_acc 0.9984375\n",
      "\n",
      "Epoch 87. Loss: 0.007013585957395586, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 87. Loss: 0.006373833465210395, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 87. Loss: 0.006633968664078531, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 87. Loss: 0.006084495156401651, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 87. Loss: 0.005925253438408009, Train_acc 0.99921875\n",
      "\n",
      "Epoch 87. Loss: 0.006163331112970262, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 87. Loss: 0.005736611424517794, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 87. Loss: 0.005283050207036433, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 87. Loss: 0.0052945002159366285, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 87. Loss: 0.00804269955225789, Train_acc 0.9984375\n",
      "\n",
      "Epoch 87. Loss: 0.007556875956629248, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 87. Loss: 0.006908463159177034, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 87. Loss: 0.00629004427484646, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 87. Loss: 0.0057199362795268705, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 87. Loss: 0.005346934155140687, Train_acc 0.998828125\n",
      "\n",
      "Epoch 87. Loss: 0.006329070543212625, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 87. Loss: 0.010653737349775077, Train_acc 0.9982244318181818\n",
      "\n",
      "Epoch 87. Loss: 0.009640267467524834, Train_acc 0.9983016304347826\n",
      "\n",
      "Epoch 87. Loss: 0.008689749439757019, Train_acc 0.9983723958333334\n",
      "\n",
      "Epoch 87. Loss: 0.007899958201165229, Train_acc 0.9984375\n",
      "\n",
      "Epoch 87. Loss: 0.0072662394848639345, Train_acc 0.9984975961538461\n",
      "\n",
      "Epoch 87. Loss: 0.008107004234836212, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 87. Loss: 0.008229254058431725, Train_acc 0.998046875\n",
      "\n",
      "Epoch 87. Loss: 0.007454303083660915, Train_acc 0.998114224137931\n",
      "\n",
      "Epoch 87. Loss: 0.00682467090965156, Train_acc 0.9981770833333333\n",
      "\n",
      "Epoch 87. Loss: 0.007811637531645694, Train_acc 0.9979838709677419\n",
      "\n",
      "Epoch 87. Loss: 0.007051023253929331, Train_acc 0.998046875\n",
      "\n",
      "Epoch 87. Loss: 0.0063793657408249054, Train_acc 0.9981060606060606\n",
      "\n",
      "Epoch 87. Loss: 0.005872846966017783, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 87. Loss: 0.0053019698536054425, Train_acc 0.9982142857142857\n",
      "\n",
      "Epoch 87. Loss: 0.005126759995019985, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 87. Loss: 0.00535731382243027, Train_acc 0.9980996621621622\n",
      "\n",
      "Epoch 87. Loss: 0.008445631269265919, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 87. Loss: 0.008024725151717402, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 87. Loss: 0.0072337325449714895, Train_acc 0.99765625\n",
      "\n",
      "Epoch 87. Loss: 0.007398976906621144, Train_acc 0.9975228658536586\n",
      "\n",
      "Epoch 87. Loss: 0.006823958201337922, Train_acc 0.9975818452380952\n",
      "\n",
      "Epoch 87. Loss: 0.014363430806811812, Train_acc 0.9969113372093024\n",
      "\n",
      "Epoch 87. Loss: 0.014009437387868312, Train_acc 0.9968039772727273\n",
      "\n",
      "Epoch 87. Loss: 0.01397501087622453, Train_acc 0.9967013888888889\n",
      "\n",
      "Epoch 87. Loss: 0.012603301681733176, Train_acc 0.9967730978260869\n",
      "\n",
      "Epoch 87. Loss: 0.011380809164885248, Train_acc 0.996841755319149\n",
      "\n",
      "Epoch 87. Loss: 0.016273384645739405, Train_acc 0.99658203125\n",
      "\n",
      "Epoch 87. Loss: 0.014669325141890757, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 87. Loss: 0.013301977693319839, Train_acc 0.99671875\n",
      "\n",
      "Epoch 87. Loss: 0.014582067366791239, Train_acc 0.9964767156862745\n",
      "\n",
      "Epoch 87. Loss: 0.014367081924246971, Train_acc 0.9963942307692307\n",
      "\n",
      "Epoch 87. Loss: 0.01305709008668413, Train_acc 0.9964622641509434\n",
      "\n",
      "Epoch 87. Loss: 0.01209199189043388, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 87. Loss: 0.01390916973855804, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 87. Loss: 0.01254900833358003, Train_acc 0.9965122767857143\n",
      "\n",
      "Epoch 87. Loss: 0.01393164395144254, Train_acc 0.9964364035087719\n",
      "\n",
      "Epoch 87. Loss: 0.013622577496773036, Train_acc 0.9963631465517241\n",
      "\n",
      "Epoch 87. Loss: 0.012438139250101328, Train_acc 0.9964247881355932\n",
      "\n",
      "Epoch 87. Loss: 0.01989550301154406, Train_acc 0.9963541666666667\n",
      "\n",
      "Epoch 87. Loss: 0.017940199437981034, Train_acc 0.9964139344262295\n",
      "\n",
      "Epoch 87. Loss: 0.01652321782495396, Train_acc 0.9964717741935484\n",
      "\n",
      "Epoch 87. Loss: 0.019769669921271354, Train_acc 0.9964037698412699\n",
      "\n",
      "Epoch 87. Loss: 0.020679479368989784, Train_acc 0.996337890625\n",
      "\n",
      "Epoch 87. Loss: 0.01972368378874521, Train_acc 0.9962740384615385\n",
      "\n",
      "Epoch 87. Loss: 0.021843876863451545, Train_acc 0.99609375\n",
      "\n",
      "Epoch 87. Loss: 0.01975878399604417, Train_acc 0.996152052238806\n",
      "\n",
      "Epoch 87. Loss: 0.018436153783594283, Train_acc 0.9962086397058824\n",
      "\n",
      "Epoch 87. Loss: 0.01694384056797896, Train_acc 0.9962635869565217\n",
      "\n",
      "Epoch 87. Loss: 0.02138544325653858, Train_acc 0.99609375\n",
      "\n",
      "Epoch 87. Loss: 0.022173930112637404, Train_acc 0.9959286971830986\n",
      "\n",
      "Epoch 87. Loss: 0.0208182079232788, Train_acc 0.9959852430555556\n",
      "\n",
      "Epoch 87. Loss: 0.01885315817143523, Train_acc 0.9960402397260274\n",
      "\n",
      "Epoch 87. Loss: 0.017467999829763204, Train_acc 0.99609375\n",
      "\n",
      "Epoch 87. Loss: 0.018652249871713548, Train_acc 0.9960416666666667\n",
      "\n",
      "Epoch 87. Loss: 0.017052930704375472, Train_acc 0.99609375\n",
      "\n",
      "Epoch 87. Loss: 0.01794140155162248, Train_acc 0.9959415584415584\n",
      "\n",
      "Epoch 87. Loss: 0.016912720635943113, Train_acc 0.9959935897435898\n",
      "\n",
      "Epoch 87. Loss: 0.01625231900624558, Train_acc 0.9960443037974683\n",
      "\n",
      "Epoch 87. Loss: 0.014781458292711899, Train_acc 0.99609375\n",
      "\n",
      "Epoch 87. Loss: 0.013948486549534612, Train_acc 0.996141975308642\n",
      "\n",
      "Epoch 87. Loss: 0.014187051961909128, Train_acc 0.99609375\n",
      "\n",
      "Epoch 87. Loss: 0.012914551243359948, Train_acc 0.9961408132530121\n",
      "\n",
      "Epoch 87. Loss: 0.011701018446933572, Train_acc 0.9961867559523809\n",
      "\n",
      "Epoch 87. Loss: 0.010667004832887362, Train_acc 0.9962316176470588\n",
      "\n",
      "Epoch 87. Loss: 0.010194915815529565, Train_acc 0.9962754360465116\n",
      "\n",
      "Epoch 87. Loss: 0.009354543758522576, Train_acc 0.9963182471264368\n",
      "\n",
      "Epoch 87. Loss: 0.008455764551337307, Train_acc 0.9963600852272727\n",
      "\n",
      "Epoch 87. Loss: 0.008055219284631978, Train_acc 0.9964009831460674\n",
      "\n",
      "Epoch 87. Loss: 0.007948317809645687, Train_acc 0.9964409722222223\n",
      "\n",
      "Epoch 87. Loss: 0.0071902612330341535, Train_acc 0.9964800824175825\n",
      "\n",
      "Epoch 87. Loss: 0.006739180898531454, Train_acc 0.9965183423913043\n",
      "\n",
      "Epoch 87. Loss: 0.006276475965259234, Train_acc 0.9965557795698925\n",
      "\n",
      "Epoch 87. Loss: 0.007124803099880599, Train_acc 0.9965093085106383\n",
      "\n",
      "Epoch 87. Loss: 0.006433528881225254, Train_acc 0.9965460526315789\n",
      "\n",
      "Epoch 87. Loss: 0.005840398924998135, Train_acc 0.99658203125\n",
      "\n",
      "Epoch 87. Loss: 0.005654665068866333, Train_acc 0.9966172680412371\n",
      "\n",
      "Epoch 87. Loss: 0.00519434900175618, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 87. Loss: 0.005292682391101899, Train_acc 0.9966856060606061\n",
      "\n",
      "Epoch 87. Loss: 0.00642455220224987, Train_acc 0.996640625\n",
      "\n",
      "[Epoch 87 Batch 100] Loss: 0.005821837421412852 Training: accuracy=0.996674\n",
      "Epoch 87. Loss: 0.005821837421412852, Train_acc 0.9966738861386139\n",
      "\n",
      "Epoch 87. Loss: 0.005273928631757725, Train_acc 0.9967064950980392\n",
      "\n",
      "Epoch 87. Loss: 0.0048318176519483585, Train_acc 0.9967384708737864\n",
      "\n",
      "Epoch 87. Loss: 0.004385685551869297, Train_acc 0.9967698317307693\n",
      "\n",
      "Epoch 87. Loss: 0.004005725231076709, Train_acc 0.9968005952380953\n",
      "\n",
      "Epoch 87. Loss: 0.0036261514054059182, Train_acc 0.9968307783018868\n",
      "\n",
      "Epoch 87. Loss: 0.003549253527751791, Train_acc 0.9968603971962616\n",
      "\n",
      "Epoch 87. Loss: 0.003262912189638222, Train_acc 0.9968894675925926\n",
      "\n",
      "Epoch 87. Loss: 0.0030224510887158855, Train_acc 0.996918004587156\n",
      "\n",
      "Epoch 87. Loss: 0.002754271568105298, Train_acc 0.9969460227272727\n",
      "\n",
      "Epoch 87. Loss: 0.0026010421287229754, Train_acc 0.996973536036036\n",
      "\n",
      "Epoch 87. Loss: 0.0024830853078852085, Train_acc 0.9970005580357143\n",
      "\n",
      "Epoch 87. Loss: 0.0022549794935017254, Train_acc 0.9970271017699115\n",
      "\n",
      "Epoch 87. Loss: 0.002072871670817607, Train_acc 0.9970531798245614\n",
      "\n",
      "Epoch 87. Loss: 0.0018826382831832976, Train_acc 0.9970788043478261\n",
      "\n",
      "Epoch 87. Loss: 0.0016991157802573559, Train_acc 0.9971039870689655\n",
      "\n",
      "Epoch 87. Loss: 0.0015555761434348718, Train_acc 0.9971287393162394\n",
      "\n",
      "Epoch 87. Loss: 0.0014283305258121159, Train_acc 0.9971530720338984\n",
      "\n",
      "Epoch 87. Loss: 0.0014248705018817841, Train_acc 0.9971769957983193\n",
      "\n",
      "Epoch 87. Loss: 0.0013200995945268385, Train_acc 0.9972005208333333\n",
      "\n",
      "Epoch 87. Loss: 0.001212100804517993, Train_acc 0.9972236570247934\n",
      "\n",
      "Epoch 87. Loss: 0.0011596496352865506, Train_acc 0.9972464139344263\n",
      "\n",
      "Epoch 87. Loss: 0.0017208706896138974, Train_acc 0.9972052845528455\n",
      "\n",
      "Epoch 87. Loss: 0.0016009775570787002, Train_acc 0.9972278225806451\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87. Loss: 0.00145771371011033, Train_acc 0.99725\n",
      "\n",
      "Epoch 87. Loss: 0.0013422394353359058, Train_acc 0.9972718253968254\n",
      "\n",
      "Epoch 87. Loss: 0.0013779051206894918, Train_acc 0.9972933070866141\n",
      "\n",
      "Epoch 87. Loss: 0.0013536732032236342, Train_acc 0.997314453125\n",
      "\n",
      "Epoch 87. Loss: 0.0012969788393437313, Train_acc 0.9973352713178295\n",
      "\n",
      "Epoch 87. Loss: 0.0011937461656580744, Train_acc 0.9973557692307692\n",
      "\n",
      "Epoch 87. Loss: 0.0012735442181825976, Train_acc 0.9973759541984732\n",
      "\n",
      "Epoch 87. Loss: 0.001321126844359965, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 87. Loss: 0.0020274761438729147, Train_acc 0.9973566729323309\n",
      "\n",
      "Epoch 87. Loss: 0.0018386209621021814, Train_acc 0.9973763992537313\n",
      "\n",
      "Epoch 87. Loss: 0.001702638857944876, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 87. Loss: 0.0016771157483092577, Train_acc 0.9974149816176471\n",
      "\n",
      "Epoch 87. Loss: 0.0015282276680891743, Train_acc 0.9974338503649635\n",
      "\n",
      "Epoch 87. Loss: 0.0017271994309864967, Train_acc 0.997452445652174\n",
      "\n",
      "Epoch 87. Loss: 0.002149764719135391, Train_acc 0.9974145683453237\n",
      "\n",
      "Epoch 87. Loss: 0.0033189016968251713, Train_acc 0.9973772321428571\n",
      "\n",
      "Epoch 87. Loss: 0.00303277788552286, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 87. Loss: 0.0027802864673820895, Train_acc 0.9974141725352113\n",
      "\n",
      "Epoch 87. Loss: 0.0025076218726929975, Train_acc 0.9974322552447552\n",
      "\n",
      "Epoch 87. Loss: 0.0023418008909923092, Train_acc 0.9974500868055556\n",
      "\n",
      "Epoch 87. Loss: 0.0021159513368038617, Train_acc 0.9974676724137931\n",
      "\n",
      "Epoch 87. Loss: 0.0019077773707627925, Train_acc 0.9974850171232876\n",
      "\n",
      "Epoch 87. Loss: 0.002317899669038028, Train_acc 0.9975021258503401\n",
      "\n",
      "Epoch 87. Loss: 0.0034736146560252644, Train_acc 0.9974662162162162\n",
      "\n",
      "Epoch 87. Loss: 0.0032611351371466465, Train_acc 0.99748322147651\n",
      "\n",
      "Epoch 87. Loss: 0.0029842100654945687, Train_acc 0.9975\n",
      "\n",
      "Epoch 87. Loss: 0.002702387468219705, Train_acc 0.9975165562913907\n",
      "\n",
      "Epoch 87. Loss: 0.0026860387803547747, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 87. Loss: 0.002577686250598714, Train_acc 0.9975490196078431\n",
      "\n",
      "Epoch 87. Loss: 0.0023306045127923845, Train_acc 0.997564935064935\n",
      "\n",
      "Epoch 87. Loss: 0.0021177073233104252, Train_acc 0.9975806451612903\n",
      "\n",
      "Epoch 87. Loss: 0.0019171713731207833, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 87. Loss: 0.0017597631699273037, Train_acc 0.9976114649681529\n",
      "\n",
      "Epoch 87. Loss: 0.001608640304694128, Train_acc 0.997626582278481\n",
      "\n",
      "Epoch 87. Loss: 0.0017089492757152486, Train_acc 0.9976415094339622\n",
      "\n",
      "Epoch 87. Loss: 0.0015519136460493068, Train_acc 0.99765625\n",
      "\n",
      "Epoch 87. Loss: 0.0014421927062557318, Train_acc 0.9976708074534162\n",
      "\n",
      "Epoch 87. Loss: 0.0015376659941646021, Train_acc 0.9976851851851852\n",
      "\n",
      "Epoch 87. Loss: 0.0021693871918594147, Train_acc 0.9976514570552147\n",
      "\n",
      "Epoch 87. Loss: 0.0022265831560962174, Train_acc 0.9976657774390244\n",
      "\n",
      "Epoch 87. Loss: 0.0022168515374725558, Train_acc 0.9976799242424242\n",
      "\n",
      "Epoch 87. Loss: 0.0020060711917301525, Train_acc 0.9976939006024096\n",
      "\n",
      "Epoch 87. Loss: 0.0018082239902545408, Train_acc 0.9977077095808383\n",
      "\n",
      "Epoch 87. Loss: 0.0016455121307604218, Train_acc 0.9977213541666666\n",
      "\n",
      "Epoch 87. Loss: 0.0017318851100533638, Train_acc 0.9977348372781065\n",
      "\n",
      "Epoch 87. Loss: 0.001596031912438968, Train_acc 0.9977481617647059\n",
      "\n",
      "Epoch 87. Loss: 0.0016995588737930948, Train_acc 0.9977613304093568\n",
      "\n",
      "Epoch 87. Loss: 0.0018288842175414647, Train_acc 0.9977743459302325\n",
      "\n",
      "Epoch 87. Loss: 0.002228066025362356, Train_acc 0.997787210982659\n",
      "\n",
      "Epoch 87. Loss: 0.002009381368138484, Train_acc 0.9977999281609196\n",
      "\n",
      "Epoch 87. Loss: 0.0018123149630030087, Train_acc 0.9978125\n",
      "\n",
      "Epoch 87. Loss: 0.0016483141479628244, Train_acc 0.9978249289772727\n",
      "\n",
      "Epoch 87. Loss: 0.0015246772785044722, Train_acc 0.9978372175141242\n",
      "\n",
      "Epoch 87. Loss: 0.001383477703975023, Train_acc 0.9978493679775281\n",
      "\n",
      "Epoch 87. Loss: 0.001291270110287262, Train_acc 0.9978613826815642\n",
      "\n",
      "Epoch 87. Loss: 0.0014382842007529672, Train_acc 0.9978732638888889\n",
      "\n",
      "Epoch 87. Loss: 0.0016663288334684313, Train_acc 0.9978850138121547\n",
      "\n",
      "Epoch 87. Loss: 0.0027321548805841873, Train_acc 0.9978537087912088\n",
      "\n",
      "Epoch 87. Loss: 0.002462635106784125, Train_acc 0.99786543715847\n",
      "\n",
      "Epoch 87. Loss: 0.0029416025898087203, Train_acc 0.9978345788043478\n",
      "\n",
      "Epoch 87. Loss: 0.002654171540972689, Train_acc 0.9978462837837838\n",
      "\n",
      "Epoch 87. Loss: 0.002415179704503729, Train_acc 0.9978578629032258\n",
      "\n",
      "Epoch 87. Loss: 0.0025040954957543443, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 87. Loss: 0.0022965499017837537, Train_acc 0.9978806515957447\n",
      "\n",
      "Epoch 87. Loss: 0.0020706742840967867, Train_acc 0.9978918650793651\n",
      "\n",
      "Epoch 87. Loss: 0.0020468336059193872, Train_acc 0.9979029605263158\n",
      "\n",
      "Epoch 87. Loss: 0.0025407050405628438, Train_acc 0.9978730366492147\n",
      "\n",
      "Epoch 87. Loss: 0.00229397882045591, Train_acc 0.9978841145833334\n",
      "\n",
      "Epoch 87. Loss: 0.00252380809057907, Train_acc 0.9978950777202072\n",
      "\n",
      "Epoch 87. Loss: 0.007009999521396956, Train_acc 0.9978656572164949\n",
      "\n",
      "Epoch 87. Loss: 0.006340249842134775, Train_acc 0.9978766025641026\n",
      "\n",
      "Epoch 87. Loss: 0.006010770273486669, Train_acc 0.99788\n",
      "\n",
      "Epoch 88. Loss: 0.0069775990148901006, Train_acc 0.9921875\n",
      "\n",
      "Epoch 88. Loss: 0.0062836008820768485, Train_acc 0.99609375\n",
      "\n",
      "Epoch 88. Loss: 0.005674706314614307, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 88. Loss: 0.005108949387448857, Train_acc 0.998046875\n",
      "\n",
      "Epoch 88. Loss: 0.00461649059606969, Train_acc 0.9984375\n",
      "\n",
      "Epoch 88. Loss: 0.004164793440675078, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 88. Loss: 0.0038250077713898613, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 88. Loss: 0.0034804166251697507, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 88. Loss: 0.0031552844764438674, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 88. Loss: 0.002939404028540618, Train_acc 0.99921875\n",
      "\n",
      "Epoch 88. Loss: 0.00266685445794867, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 88. Loss: 0.002628900323080181, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 88. Loss: 0.0035641042564217677, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 88. Loss: 0.004808401898196736, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 88. Loss: 0.004547995074862003, Train_acc 0.9984375\n",
      "\n",
      "Epoch 88. Loss: 0.0043597282837171195, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 88. Loss: 0.004535139249220983, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 88. Loss: 0.004539026571993973, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 88. Loss: 0.005508634823875081, Train_acc 0.9983552631578947\n",
      "\n",
      "Epoch 88. Loss: 0.005211972182787763, Train_acc 0.9984375\n",
      "\n",
      "Epoch 88. Loss: 0.004745511987819723, Train_acc 0.9985119047619048\n",
      "\n",
      "Epoch 88. Loss: 0.00429551920071605, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 88. Loss: 0.0038746403836468104, Train_acc 0.998641304347826\n",
      "\n",
      "Epoch 88. Loss: 0.003835249961906008, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 88. Loss: 0.0035691191774174565, Train_acc 0.99875\n",
      "\n",
      "Epoch 88. Loss: 0.0034982080171538886, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 88. Loss: 0.0031553062014754076, Train_acc 0.9988425925925926\n",
      "\n",
      "Epoch 88. Loss: 0.002922769787205052, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 88. Loss: 0.0027198543212852257, Train_acc 0.9989224137931034\n",
      "\n",
      "Epoch 88. Loss: 0.0024688292990494264, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 88. Loss: 0.006211231599781081, Train_acc 0.9987399193548387\n",
      "\n",
      "Epoch 88. Loss: 0.005596635163685389, Train_acc 0.998779296875\n",
      "\n",
      "Epoch 88. Loss: 0.005199874727079905, Train_acc 0.9988162878787878\n",
      "\n",
      "Epoch 88. Loss: 0.00469043317867783, Train_acc 0.9988511029411765\n",
      "\n",
      "Epoch 88. Loss: 0.004226730512651882, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 88. Loss: 0.0038291513107858205, Train_acc 0.9989149305555556\n",
      "\n",
      "Epoch 88. Loss: 0.0035055576558538173, Train_acc 0.9989442567567568\n",
      "\n",
      "Epoch 88. Loss: 0.0032847154157983863, Train_acc 0.9989720394736842\n",
      "\n",
      "Epoch 88. Loss: 0.0029689385183199776, Train_acc 0.9989983974358975\n",
      "\n",
      "Epoch 88. Loss: 0.002696279475585814, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 88. Loss: 0.0029355214330519996, Train_acc 0.999047256097561\n",
      "\n",
      "Epoch 88. Loss: 0.00275039235048435, Train_acc 0.9990699404761905\n",
      "\n",
      "Epoch 88. Loss: 0.007033756532903986, Train_acc 0.9989098837209303\n",
      "\n",
      "Epoch 88. Loss: 0.0064890880484981634, Train_acc 0.9989346590909091\n",
      "\n",
      "Epoch 88. Loss: 0.005847802715550099, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 88. Loss: 0.0052885505545588445, Train_acc 0.9989809782608695\n",
      "\n",
      "Epoch 88. Loss: 0.004776180727946481, Train_acc 0.9990026595744681\n",
      "\n",
      "Epoch 88. Loss: 0.004737491026447166, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 88. Loss: 0.00429218785344056, Train_acc 0.9990433673469388\n",
      "\n",
      "Epoch 88. Loss: 0.0039630235319337995, Train_acc 0.9990625\n",
      "\n",
      "Epoch 88. Loss: 0.0050415161104501865, Train_acc 0.9987745098039216\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88. Loss: 0.004801455497503422, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 88. Loss: 0.005342577421450742, Train_acc 0.9986733490566038\n",
      "\n",
      "Epoch 88. Loss: 0.004849103624893131, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 88. Loss: 0.004371753878762933, Train_acc 0.998721590909091\n",
      "\n",
      "Epoch 88. Loss: 0.004121318376134883, Train_acc 0.9987444196428571\n",
      "\n",
      "Epoch 88. Loss: 0.004039063322756635, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 88. Loss: 0.003654661939640426, Train_acc 0.9987877155172413\n",
      "\n",
      "Epoch 88. Loss: 0.0035765243828814477, Train_acc 0.9988082627118644\n",
      "\n",
      "Epoch 88. Loss: 0.003314343893909864, Train_acc 0.998828125\n",
      "\n",
      "Epoch 88. Loss: 0.00304582355167627, Train_acc 0.9988473360655737\n",
      "\n",
      "Epoch 88. Loss: 0.002778032253718127, Train_acc 0.9988659274193549\n",
      "\n",
      "Epoch 88. Loss: 0.002721762962000742, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 88. Loss: 0.003347514248064614, Train_acc 0.998779296875\n",
      "\n",
      "Epoch 88. Loss: 0.0030662999596675847, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 88. Loss: 0.0027640729814386125, Train_acc 0.9988162878787878\n",
      "\n",
      "Epoch 88. Loss: 0.002502302709764906, Train_acc 0.9988339552238806\n",
      "\n",
      "Epoch 88. Loss: 0.002266067743259297, Train_acc 0.9988511029411765\n",
      "\n",
      "Epoch 88. Loss: 0.0020655057248746243, Train_acc 0.9988677536231884\n",
      "\n",
      "Epoch 88. Loss: 0.002112685582654913, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 88. Loss: 0.002689157877073204, Train_acc 0.9987896126760564\n",
      "\n",
      "Epoch 88. Loss: 0.002447353110702052, Train_acc 0.9988064236111112\n",
      "\n",
      "Epoch 88. Loss: 0.0022193317103679903, Train_acc 0.9988227739726028\n",
      "\n",
      "Epoch 88. Loss: 0.0024043852937188086, Train_acc 0.9988386824324325\n",
      "\n",
      "Epoch 88. Loss: 0.0023360789830691817, Train_acc 0.9988541666666667\n",
      "\n",
      "Epoch 88. Loss: 0.0024195838369986894, Train_acc 0.9988692434210527\n",
      "\n",
      "Epoch 88. Loss: 0.003568127962028517, Train_acc 0.9987824675324676\n",
      "\n",
      "Epoch 88. Loss: 0.0032560793832806054, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 88. Loss: 0.002999552867359725, Train_acc 0.9988132911392406\n",
      "\n",
      "Epoch 88. Loss: 0.002719236315726242, Train_acc 0.998828125\n",
      "\n",
      "Epoch 88. Loss: 0.0024688212646929936, Train_acc 0.9988425925925926\n",
      "\n",
      "Epoch 88. Loss: 0.0023044065647696123, Train_acc 0.9988567073170732\n",
      "\n",
      "Epoch 88. Loss: 0.0020848987716624683, Train_acc 0.9988704819277109\n",
      "\n",
      "Epoch 88. Loss: 0.0033612447874119475, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 88. Loss: 0.0038041010946515733, Train_acc 0.9988970588235294\n",
      "\n",
      "Epoch 88. Loss: 0.005542670938415843, Train_acc 0.9988190406976745\n",
      "\n",
      "Epoch 88. Loss: 0.005005710903016642, Train_acc 0.9988326149425287\n",
      "\n",
      "Epoch 88. Loss: 0.004516307001210144, Train_acc 0.9988458806818182\n",
      "\n",
      "Epoch 88. Loss: 0.0040948492665784575, Train_acc 0.9988588483146067\n",
      "\n",
      "Epoch 88. Loss: 0.007248734523030849, Train_acc 0.9987847222222223\n",
      "\n",
      "Epoch 88. Loss: 0.007783041601633488, Train_acc 0.9987122252747253\n",
      "\n",
      "Epoch 88. Loss: 0.007104313275353276, Train_acc 0.9987262228260869\n",
      "\n",
      "Epoch 88. Loss: 0.0063997107683943745, Train_acc 0.9987399193548387\n",
      "\n",
      "Epoch 88. Loss: 0.005831504446384865, Train_acc 0.9987533244680851\n",
      "\n",
      "Epoch 88. Loss: 0.0053491226270169535, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 88. Loss: 0.004826417041953719, Train_acc 0.998779296875\n",
      "\n",
      "Epoch 88. Loss: 0.0043499651848032264, Train_acc 0.998791881443299\n",
      "\n",
      "Epoch 88. Loss: 0.004365783228241282, Train_acc 0.9988042091836735\n",
      "\n",
      "Epoch 88. Loss: 0.00582737311908264, Train_acc 0.9987373737373737\n",
      "\n",
      "Epoch 88. Loss: 0.009910671429532699, Train_acc 0.99859375\n",
      "\n",
      "[Epoch 88 Batch 100] Loss: 0.009798316728351653 Training: accuracy=0.998530\n",
      "Epoch 88. Loss: 0.009798316728351653, Train_acc 0.9985303217821783\n",
      "\n",
      "Epoch 88. Loss: 0.008891540798057816, Train_acc 0.9985447303921569\n",
      "\n",
      "Epoch 88. Loss: 0.00805494660624239, Train_acc 0.998558859223301\n",
      "\n",
      "Epoch 88. Loss: 0.00726264717851382, Train_acc 0.9985727163461539\n",
      "\n",
      "Epoch 88. Loss: 0.011945704394647195, Train_acc 0.9983630952380952\n",
      "\n",
      "Epoch 88. Loss: 0.01075810197171496, Train_acc 0.9983785377358491\n",
      "\n",
      "Epoch 88. Loss: 0.009684340794438376, Train_acc 0.998393691588785\n",
      "\n",
      "Epoch 88. Loss: 0.012117868637640108, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 88. Loss: 0.012031621426879312, Train_acc 0.9982798165137615\n",
      "\n",
      "Epoch 88. Loss: 0.010847246001746866, Train_acc 0.9982954545454545\n",
      "\n",
      "Epoch 88. Loss: 0.015529039815592718, Train_acc 0.9982404279279279\n",
      "\n",
      "Epoch 88. Loss: 0.01611084582554813, Train_acc 0.9981863839285714\n",
      "\n",
      "Epoch 88. Loss: 0.014591317155506602, Train_acc 0.9982024336283186\n",
      "\n",
      "Epoch 88. Loss: 0.013188651743023224, Train_acc 0.9982182017543859\n",
      "\n",
      "Epoch 88. Loss: 0.011950953735075038, Train_acc 0.9982336956521739\n",
      "\n",
      "Epoch 88. Loss: 0.011272524181599892, Train_acc 0.9982489224137931\n",
      "\n",
      "Epoch 88. Loss: 0.010437839579071531, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 88. Loss: 0.012449589574175414, Train_acc 0.998146186440678\n",
      "\n",
      "Epoch 88. Loss: 0.011384136256001744, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 88. Loss: 0.010429315716368574, Train_acc 0.9981770833333333\n",
      "\n",
      "Epoch 88. Loss: 0.00968550858770396, Train_acc 0.9981921487603306\n",
      "\n",
      "Epoch 88. Loss: 0.008760574076763377, Train_acc 0.9982069672131147\n",
      "\n",
      "Epoch 88. Loss: 0.007929779379860426, Train_acc 0.9982215447154471\n",
      "\n",
      "Epoch 88. Loss: 0.007436786496754764, Train_acc 0.9982358870967742\n",
      "\n",
      "Epoch 88. Loss: 0.0069385602864917625, Train_acc 0.99825\n",
      "\n",
      "Epoch 88. Loss: 0.006722897328582094, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 88. Loss: 0.006383139161524194, Train_acc 0.9982775590551181\n",
      "\n",
      "Epoch 88. Loss: 0.0060051600798282185, Train_acc 0.998291015625\n",
      "\n",
      "Epoch 88. Loss: 0.006261330455331191, Train_acc 0.9983042635658915\n",
      "\n",
      "Epoch 88. Loss: 0.005735416915637122, Train_acc 0.9983173076923076\n",
      "\n",
      "Epoch 88. Loss: 0.005270837113128036, Train_acc 0.9983301526717557\n",
      "\n",
      "Epoch 88. Loss: 0.007980348197995958, Train_acc 0.9982836174242424\n",
      "\n",
      "Epoch 88. Loss: 0.009096800784807804, Train_acc 0.9981790413533834\n",
      "\n",
      "Epoch 88. Loss: 0.008715772601328555, Train_acc 0.9981926305970149\n",
      "\n",
      "Epoch 88. Loss: 0.008076937136675951, Train_acc 0.9982060185185185\n",
      "\n",
      "Epoch 88. Loss: 0.007502324592434798, Train_acc 0.9982192095588235\n",
      "\n",
      "Epoch 88. Loss: 0.0070002672941506805, Train_acc 0.9982322080291971\n",
      "\n",
      "Epoch 88. Loss: 0.010235765386017046, Train_acc 0.9981884057971014\n",
      "\n",
      "Epoch 88. Loss: 0.009262089739605977, Train_acc 0.9982014388489209\n",
      "\n",
      "Epoch 88. Loss: 0.00910357136088478, Train_acc 0.9981584821428572\n",
      "\n",
      "Epoch 88. Loss: 0.008260303257178076, Train_acc 0.9981715425531915\n",
      "\n",
      "Epoch 88. Loss: 0.008100642103273398, Train_acc 0.9981294014084507\n",
      "\n",
      "Epoch 88. Loss: 0.011190759395049864, Train_acc 0.9980878496503497\n",
      "\n",
      "Epoch 88. Loss: 0.010189931992727686, Train_acc 0.9981011284722222\n",
      "\n",
      "Epoch 88. Loss: 0.010996472414468083, Train_acc 0.9980603448275862\n",
      "\n",
      "Epoch 88. Loss: 0.010267999827013333, Train_acc 0.9980736301369864\n",
      "\n",
      "Epoch 88. Loss: 0.009317771428525525, Train_acc 0.9980867346938775\n",
      "\n",
      "Epoch 88. Loss: 0.008439113642416963, Train_acc 0.9980996621621622\n",
      "\n",
      "Epoch 88. Loss: 0.007741842323743614, Train_acc 0.9981124161073825\n",
      "\n",
      "Epoch 88. Loss: 0.007000396594437939, Train_acc 0.998125\n",
      "\n",
      "Epoch 88. Loss: 0.006387566155504122, Train_acc 0.9981374172185431\n",
      "\n",
      "Epoch 88. Loss: 0.0059449291240968715, Train_acc 0.9981496710526315\n",
      "\n",
      "Epoch 88. Loss: 0.006241363507819034, Train_acc 0.9981107026143791\n",
      "\n",
      "Epoch 88. Loss: 0.005795151445473901, Train_acc 0.9981229707792207\n",
      "\n",
      "Epoch 88. Loss: 0.00540236719891191, Train_acc 0.9981350806451613\n",
      "\n",
      "Epoch 88. Loss: 0.0067035526494213385, Train_acc 0.9980969551282052\n",
      "\n",
      "Epoch 88. Loss: 0.007994066704216162, Train_acc 0.9980593152866242\n",
      "\n",
      "Epoch 88. Loss: 0.007253304519920105, Train_acc 0.9980715981012658\n",
      "\n",
      "Epoch 88. Loss: 0.006607108873056072, Train_acc 0.9980837264150944\n",
      "\n",
      "Epoch 88. Loss: 0.0059942571743853675, Train_acc 0.998095703125\n",
      "\n",
      "Epoch 88. Loss: 0.005588609975534182, Train_acc 0.9981075310559007\n",
      "\n",
      "Epoch 88. Loss: 0.007713079305253179, Train_acc 0.998070987654321\n",
      "\n",
      "Epoch 88. Loss: 0.007491541428203956, Train_acc 0.9980828220858896\n",
      "\n",
      "Epoch 88. Loss: 0.0071811056434383175, Train_acc 0.9980945121951219\n",
      "\n",
      "Epoch 88. Loss: 0.006485268883737677, Train_acc 0.9981060606060606\n",
      "\n",
      "Epoch 88. Loss: 0.006678288054018695, Train_acc 0.998070406626506\n",
      "\n",
      "Epoch 88. Loss: 0.007058118355169427, Train_acc 0.9980351796407185\n",
      "\n",
      "Epoch 88. Loss: 0.006716853020730196, Train_acc 0.998046875\n",
      "\n",
      "Epoch 88. Loss: 0.006471841654383462, Train_acc 0.9980584319526628\n",
      "\n",
      "Epoch 88. Loss: 0.009948988590720284, Train_acc 0.9980238970588236\n",
      "\n",
      "Epoch 88. Loss: 0.009095358257852187, Train_acc 0.9980354532163743\n",
      "\n",
      "Epoch 88. Loss: 0.008367406119730046, Train_acc 0.998046875\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88. Loss: 0.007893209944696103, Train_acc 0.9980581647398844\n",
      "\n",
      "Epoch 88. Loss: 0.008037702253935523, Train_acc 0.9980693247126436\n",
      "\n",
      "Epoch 88. Loss: 0.007333600563945878, Train_acc 0.9980803571428571\n",
      "\n",
      "Epoch 88. Loss: 0.006647726247475304, Train_acc 0.9980912642045454\n",
      "\n",
      "Epoch 88. Loss: 0.008268502667336844, Train_acc 0.9980137711864406\n",
      "\n",
      "Epoch 88. Loss: 0.007710098146644994, Train_acc 0.9980249297752809\n",
      "\n",
      "Epoch 88. Loss: 0.0070719697512480004, Train_acc 0.9980359636871509\n",
      "\n",
      "Epoch 88. Loss: 0.006402932324544591, Train_acc 0.998046875\n",
      "\n",
      "Epoch 88. Loss: 0.006047207079636457, Train_acc 0.9980576657458563\n",
      "\n",
      "Epoch 88. Loss: 0.005466624324678077, Train_acc 0.9980683379120879\n",
      "\n",
      "Epoch 88. Loss: 0.005083700996965492, Train_acc 0.9980788934426229\n",
      "\n",
      "Epoch 88. Loss: 0.004619068989331938, Train_acc 0.9980893342391305\n",
      "\n",
      "Epoch 88. Loss: 0.004189212066688017, Train_acc 0.9980996621621622\n",
      "\n",
      "Epoch 88. Loss: 0.0039502040576632706, Train_acc 0.9981098790322581\n",
      "\n",
      "Epoch 88. Loss: 0.0035786679488772574, Train_acc 0.9981199866310161\n",
      "\n",
      "Epoch 88. Loss: 0.0032835443558413765, Train_acc 0.9981299867021277\n",
      "\n",
      "Epoch 88. Loss: 0.003069021264317839, Train_acc 0.9981398809523809\n",
      "\n",
      "Epoch 88. Loss: 0.005114605316164978, Train_acc 0.9981085526315789\n",
      "\n",
      "Epoch 88. Loss: 0.0048494794425528245, Train_acc 0.9981184554973822\n",
      "\n",
      "Epoch 88. Loss: 0.004795800346776337, Train_acc 0.9981282552083334\n",
      "\n",
      "Epoch 88. Loss: 0.00488857032796248, Train_acc 0.9981379533678757\n",
      "\n",
      "Epoch 88. Loss: 0.004639033836898245, Train_acc 0.9981475515463918\n",
      "\n",
      "Epoch 88. Loss: 0.0043653309585209524, Train_acc 0.9981570512820512\n",
      "\n",
      "Epoch 88. Loss: 0.003983294255509378, Train_acc 0.99816\n",
      "\n",
      "Epoch 89. Loss: 0.0036830385569440434, Train_acc 1.0\n",
      "\n",
      "Epoch 89. Loss: 0.0033800436851530173, Train_acc 1.0\n",
      "\n",
      "Epoch 89. Loss: 0.003065359876923071, Train_acc 1.0\n",
      "\n",
      "Epoch 89. Loss: 0.0031580598046234013, Train_acc 1.0\n",
      "\n",
      "Epoch 89. Loss: 0.002847305679420869, Train_acc 1.0\n",
      "\n",
      "Epoch 89. Loss: 0.0025963991204846935, Train_acc 1.0\n",
      "\n",
      "Epoch 89. Loss: 0.0023563692558930325, Train_acc 1.0\n",
      "\n",
      "Epoch 89. Loss: 0.002208546741684989, Train_acc 1.0\n",
      "\n",
      "Epoch 89. Loss: 0.002066686440841749, Train_acc 1.0\n",
      "\n",
      "Epoch 89. Loss: 0.0018720942936899967, Train_acc 1.0\n",
      "\n",
      "Epoch 89. Loss: 0.0017592272348199225, Train_acc 1.0\n",
      "\n",
      "Epoch 89. Loss: 0.002227402547329122, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 89. Loss: 0.0022765252707118875, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 89. Loss: 0.002082103168382913, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 89. Loss: 0.001920985194992352, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 89. Loss: 0.0017444298642764569, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 89. Loss: 0.0015872398351807592, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 89. Loss: 0.00281413729877882, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 89. Loss: 0.00293700692668509, Train_acc 0.9991776315789473\n",
      "\n",
      "Epoch 89. Loss: 0.0026558274309300208, Train_acc 0.99921875\n",
      "\n",
      "Epoch 89. Loss: 0.002406814745615172, Train_acc 0.9992559523809523\n",
      "\n",
      "Epoch 89. Loss: 0.0025162020134630037, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 89. Loss: 0.00235572094031555, Train_acc 0.9993206521739131\n",
      "\n",
      "Epoch 89. Loss: 0.0021272112545422024, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 89. Loss: 0.0019331510322395948, Train_acc 0.999375\n",
      "\n",
      "Epoch 89. Loss: 0.0017478096000333157, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 89. Loss: 0.0015913174841786124, Train_acc 0.9994212962962963\n",
      "\n",
      "Epoch 89. Loss: 0.0014639516179194032, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 89. Loss: 0.0013408864402331207, Train_acc 0.9994612068965517\n",
      "\n",
      "Epoch 89. Loss: 0.0012155527180831417, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 89. Loss: 0.002175565914636921, Train_acc 0.9992439516129032\n",
      "\n",
      "Epoch 89. Loss: 0.0020104771964932124, Train_acc 0.999267578125\n",
      "\n",
      "Epoch 89. Loss: 0.0019573933625274577, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 89. Loss: 0.002381435322974951, Train_acc 0.9993106617647058\n",
      "\n",
      "Epoch 89. Loss: 0.002191691914746759, Train_acc 0.9993303571428571\n",
      "\n",
      "Epoch 89. Loss: 0.002032646126363067, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 89. Loss: 0.001864416797962834, Train_acc 0.9993665540540541\n",
      "\n",
      "Epoch 89. Loss: 0.0016872312378317749, Train_acc 0.9993832236842105\n",
      "\n",
      "Epoch 89. Loss: 0.002159448268019912, Train_acc 0.999198717948718\n",
      "\n",
      "Epoch 89. Loss: 0.001981357416881814, Train_acc 0.99921875\n",
      "\n",
      "Epoch 89. Loss: 0.0018559168270963677, Train_acc 0.9992378048780488\n",
      "\n",
      "Epoch 89. Loss: 0.0017205010153882874, Train_acc 0.9992559523809523\n",
      "\n",
      "Epoch 89. Loss: 0.0015750269194703406, Train_acc 0.9992732558139535\n",
      "\n",
      "Epoch 89. Loss: 0.004299240978085497, Train_acc 0.9991122159090909\n",
      "\n",
      "Epoch 89. Loss: 0.004105993536918014, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 89. Loss: 0.0037248521927476896, Train_acc 0.9991508152173914\n",
      "\n",
      "Epoch 89. Loss: 0.003416857319012446, Train_acc 0.9991688829787234\n",
      "\n",
      "Epoch 89. Loss: 0.004142432891817536, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 89. Loss: 0.010870180562280101, Train_acc 0.9987244897959183\n",
      "\n",
      "Epoch 89. Loss: 0.009901604839821145, Train_acc 0.99875\n",
      "\n",
      "Epoch 89. Loss: 0.00896269758661567, Train_acc 0.9987745098039216\n",
      "\n",
      "Epoch 89. Loss: 0.008068946777940653, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 89. Loss: 0.007485899532208617, Train_acc 0.9988207547169812\n",
      "\n",
      "Epoch 89. Loss: 0.007767340984377064, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 89. Loss: 0.008814013738721132, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 89. Loss: 0.008054604725649525, Train_acc 0.9986049107142857\n",
      "\n",
      "Epoch 89. Loss: 0.007291550897291066, Train_acc 0.9986293859649122\n",
      "\n",
      "Epoch 89. Loss: 0.0068106320865652815, Train_acc 0.9986530172413793\n",
      "\n",
      "Epoch 89. Loss: 0.006161615044506619, Train_acc 0.9986758474576272\n",
      "\n",
      "Epoch 89. Loss: 0.0055564832595183435, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 89. Loss: 0.005517601383003055, Train_acc 0.998719262295082\n",
      "\n",
      "Epoch 89. Loss: 0.005010466904641651, Train_acc 0.9987399193548387\n",
      "\n",
      "Epoch 89. Loss: 0.004750140882985112, Train_acc 0.9987599206349206\n",
      "\n",
      "Epoch 89. Loss: 0.004290730714432955, Train_acc 0.998779296875\n",
      "\n",
      "Epoch 89. Loss: 0.004152515294260585, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 89. Loss: 0.003797669265533362, Train_acc 0.9988162878787878\n",
      "\n",
      "Epoch 89. Loss: 0.0034965044334160904, Train_acc 0.9988339552238806\n",
      "\n",
      "Epoch 89. Loss: 0.0032952557021419067, Train_acc 0.9988511029411765\n",
      "\n",
      "Epoch 89. Loss: 0.0031144724752268068, Train_acc 0.9988677536231884\n",
      "\n",
      "Epoch 89. Loss: 0.0028710741568012572, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 89. Loss: 0.00261026630400842, Train_acc 0.998899647887324\n",
      "\n",
      "Epoch 89. Loss: 0.0023835496612848394, Train_acc 0.9989149305555556\n",
      "\n",
      "Epoch 89. Loss: 0.0022635401713776487, Train_acc 0.998929794520548\n",
      "\n",
      "Epoch 89. Loss: 0.00298845346745204, Train_acc 0.9988386824324325\n",
      "\n",
      "Epoch 89. Loss: 0.00271268185286128, Train_acc 0.9988541666666667\n",
      "\n",
      "Epoch 89. Loss: 0.0024487813575525524, Train_acc 0.9988692434210527\n",
      "\n",
      "Epoch 89. Loss: 0.003986088992368529, Train_acc 0.9987824675324676\n",
      "\n",
      "Epoch 89. Loss: 0.0036103488062628505, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 89. Loss: 0.003292117522807425, Train_acc 0.9988132911392406\n",
      "\n",
      "Epoch 89. Loss: 0.0029932103668204005, Train_acc 0.998828125\n",
      "\n",
      "Epoch 89. Loss: 0.0027005778458522645, Train_acc 0.9988425925925926\n",
      "\n",
      "Epoch 89. Loss: 0.003888414375347515, Train_acc 0.9986661585365854\n",
      "\n",
      "Epoch 89. Loss: 0.0035982044688129006, Train_acc 0.9986822289156626\n",
      "\n",
      "Epoch 89. Loss: 0.0032496752589557354, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 89. Loss: 0.0031645315615114974, Train_acc 0.9987132352941176\n",
      "\n",
      "Epoch 89. Loss: 0.002931642708710051, Train_acc 0.9987281976744186\n",
      "\n",
      "Epoch 89. Loss: 0.002708062698766559, Train_acc 0.998742816091954\n",
      "\n",
      "Epoch 89. Loss: 0.0031649140301272002, Train_acc 0.9986683238636364\n",
      "\n",
      "Epoch 89. Loss: 0.002916265361393591, Train_acc 0.9986832865168539\n",
      "\n",
      "Epoch 89. Loss: 0.00958170711954096, Train_acc 0.9986111111111111\n",
      "\n",
      "Epoch 89. Loss: 0.008736498769477687, Train_acc 0.9986263736263736\n",
      "\n",
      "Epoch 89. Loss: 0.008680082775374366, Train_acc 0.998641304347826\n",
      "\n",
      "Epoch 89. Loss: 0.007821609469305314, Train_acc 0.9986559139784946\n",
      "\n",
      "Epoch 89. Loss: 0.007229253541556005, Train_acc 0.9986702127659575\n",
      "\n",
      "Epoch 89. Loss: 0.006541795104725216, Train_acc 0.9986842105263158\n",
      "\n",
      "Epoch 89. Loss: 0.005894099180437607, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 89. Loss: 0.0059408546186573655, Train_acc 0.9986307989690721\n",
      "\n",
      "Epoch 89. Loss: 0.005367092029815899, Train_acc 0.9986447704081632\n",
      "\n",
      "Epoch 89. Loss: 0.00535150255738138, Train_acc 0.9986584595959596\n",
      "\n",
      "Epoch 89. Loss: 0.004822826212987316, Train_acc 0.998671875\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 89 Batch 100] Loss: 0.004355946935111388 Training: accuracy=0.998685\n",
      "Epoch 89. Loss: 0.004355946935111388, Train_acc 0.9986850247524752\n",
      "\n",
      "Epoch 89. Loss: 0.004040665323024933, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 89. Loss: 0.003657850759878295, Train_acc 0.9987105582524272\n",
      "\n",
      "Epoch 89. Loss: 0.009198614407468919, Train_acc 0.9985727163461539\n",
      "\n",
      "Epoch 89. Loss: 0.008302610980168471, Train_acc 0.9985863095238096\n",
      "\n",
      "Epoch 89. Loss: 0.007559361860181829, Train_acc 0.9985996462264151\n",
      "\n",
      "Epoch 89. Loss: 0.006842255742824546, Train_acc 0.9986127336448598\n",
      "\n",
      "Epoch 89. Loss: 0.006263695792683785, Train_acc 0.9986255787037037\n",
      "\n",
      "Epoch 89. Loss: 0.005702357104398005, Train_acc 0.9986381880733946\n",
      "\n",
      "Epoch 89. Loss: 0.005438895743841403, Train_acc 0.9986505681818182\n",
      "\n",
      "Epoch 89. Loss: 0.005781288680512732, Train_acc 0.9985923423423423\n",
      "\n",
      "Epoch 89. Loss: 0.005763509224723898, Train_acc 0.9986049107142857\n",
      "\n",
      "Epoch 89. Loss: 0.00589733251075845, Train_acc 0.9986172566371682\n",
      "\n",
      "Epoch 89. Loss: 0.00537606164361597, Train_acc 0.9986293859649122\n",
      "\n",
      "Epoch 89. Loss: 0.004953977627807656, Train_acc 0.998641304347826\n",
      "\n",
      "Epoch 89. Loss: 0.004561058747790425, Train_acc 0.9986530172413793\n",
      "\n",
      "Epoch 89. Loss: 0.004180326799677016, Train_acc 0.9986645299145299\n",
      "\n",
      "Epoch 89. Loss: 0.007829601830356898, Train_acc 0.9986096398305084\n",
      "\n",
      "Epoch 89. Loss: 0.008101246650767549, Train_acc 0.9985556722689075\n",
      "\n",
      "Epoch 89. Loss: 0.007333171068967446, Train_acc 0.9985677083333333\n",
      "\n",
      "Epoch 89. Loss: 0.0068770729064637996, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 89. Loss: 0.006228306180081032, Train_acc 0.9985911885245902\n",
      "\n",
      "Epoch 89. Loss: 0.005621618237376782, Train_acc 0.9986026422764228\n",
      "\n",
      "Epoch 89. Loss: 0.00508256356426687, Train_acc 0.9986139112903226\n",
      "\n",
      "Epoch 89. Loss: 0.004579601132027027, Train_acc 0.998625\n",
      "\n",
      "Epoch 89. Loss: 0.004189841200528339, Train_acc 0.9986359126984127\n",
      "\n",
      "Epoch 89. Loss: 0.0038955848986591064, Train_acc 0.9986466535433071\n",
      "\n",
      "Epoch 89. Loss: 0.004043049263926014, Train_acc 0.9986572265625\n",
      "\n",
      "Epoch 89. Loss: 0.0036527996220884827, Train_acc 0.9986676356589147\n",
      "\n",
      "Epoch 89. Loss: 0.0033512658845028078, Train_acc 0.9986778846153846\n",
      "\n",
      "Epoch 89. Loss: 0.0032714159313417196, Train_acc 0.9986879770992366\n",
      "\n",
      "Epoch 89. Loss: 0.0032320656797507454, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 89. Loss: 0.0029530434936164214, Train_acc 0.9987077067669173\n",
      "\n",
      "Epoch 89. Loss: 0.0031631559380035155, Train_acc 0.9987173507462687\n",
      "\n",
      "Epoch 89. Loss: 0.004269641026688267, Train_acc 0.9986111111111111\n",
      "\n",
      "Epoch 89. Loss: 0.004533872547968611, Train_acc 0.9985638786764706\n",
      "\n",
      "Epoch 89. Loss: 0.0042534317206548615, Train_acc 0.9985743613138686\n",
      "\n",
      "Epoch 89. Loss: 0.003880657487871003, Train_acc 0.9985846920289855\n",
      "\n",
      "Epoch 89. Loss: 0.004074138705070393, Train_acc 0.9985386690647482\n",
      "\n",
      "Epoch 89. Loss: 0.0036801455377439537, Train_acc 0.9985491071428572\n",
      "\n",
      "Epoch 89. Loss: 0.003355131200798218, Train_acc 0.9985593971631206\n",
      "\n",
      "Epoch 89. Loss: 0.0030961016782316843, Train_acc 0.9985695422535211\n",
      "\n",
      "Epoch 89. Loss: 0.0028738209239175124, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 89. Loss: 0.002666364801001642, Train_acc 0.9985894097222222\n",
      "\n",
      "Epoch 89. Loss: 0.0024055106575674935, Train_acc 0.9985991379310345\n",
      "\n",
      "Epoch 89. Loss: 0.009220652711575072, Train_acc 0.9984482020547946\n",
      "\n",
      "Epoch 89. Loss: 0.008336478843607425, Train_acc 0.9984587585034014\n",
      "\n",
      "Epoch 89. Loss: 0.007512407352741763, Train_acc 0.9984691722972973\n",
      "\n",
      "Epoch 89. Loss: 0.006829424587737357, Train_acc 0.9984794463087249\n",
      "\n",
      "Epoch 89. Loss: 0.009207909491226823, Train_acc 0.9983854166666667\n",
      "\n",
      "Epoch 89. Loss: 0.00869032813152589, Train_acc 0.9983961092715232\n",
      "\n",
      "Epoch 89. Loss: 0.00788585947704763, Train_acc 0.9984066611842105\n",
      "\n",
      "Epoch 89. Loss: 0.007116074755157836, Train_acc 0.9984170751633987\n",
      "\n",
      "Epoch 89. Loss: 0.006427923776643514, Train_acc 0.9984273538961039\n",
      "\n",
      "Epoch 89. Loss: 0.005899250382016933, Train_acc 0.9984375\n",
      "\n",
      "Epoch 89. Loss: 0.005489238238779458, Train_acc 0.9984475160256411\n",
      "\n",
      "Epoch 89. Loss: 0.00498135499515556, Train_acc 0.9984574044585988\n",
      "\n",
      "Epoch 89. Loss: 0.006928299813196862, Train_acc 0.9984177215189873\n",
      "\n",
      "Epoch 89. Loss: 0.006357769063466016, Train_acc 0.9984276729559748\n",
      "\n",
      "Epoch 89. Loss: 0.007330700099187992, Train_acc 0.998388671875\n",
      "\n",
      "Epoch 89. Loss: 0.00702403389488271, Train_acc 0.9983986801242236\n",
      "\n",
      "Epoch 89. Loss: 0.006595270190868776, Train_acc 0.9984085648148148\n",
      "\n",
      "Epoch 89. Loss: 0.00609094792750165, Train_acc 0.9984183282208589\n",
      "\n",
      "Epoch 89. Loss: 0.00575280139111744, Train_acc 0.9984279725609756\n",
      "\n",
      "Epoch 89. Loss: 0.005336076324272305, Train_acc 0.9984375\n",
      "\n",
      "Epoch 89. Loss: 0.0051722165130866915, Train_acc 0.9984469126506024\n",
      "\n",
      "Epoch 89. Loss: 0.008535583572086097, Train_acc 0.9983626497005988\n",
      "\n",
      "Epoch 89. Loss: 0.00880718926548636, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 89. Loss: 0.009310039244231667, Train_acc 0.9982895710059172\n",
      "\n",
      "Epoch 89. Loss: 0.008975408009860296, Train_acc 0.9982996323529412\n",
      "\n",
      "Epoch 89. Loss: 0.009859403661346477, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 89. Loss: 0.009017972847258485, Train_acc 0.9982739825581395\n",
      "\n",
      "Epoch 89. Loss: 0.008343174683319422, Train_acc 0.9982839595375722\n",
      "\n",
      "Epoch 89. Loss: 0.007703862052574955, Train_acc 0.9982938218390804\n",
      "\n",
      "Epoch 89. Loss: 0.0072086669997857835, Train_acc 0.9983035714285714\n",
      "\n",
      "Epoch 89. Loss: 0.006599473233951941, Train_acc 0.9983132102272727\n",
      "\n",
      "Epoch 89. Loss: 0.006551461280227138, Train_acc 0.9983227401129944\n",
      "\n",
      "Epoch 89. Loss: 0.006417920940003187, Train_acc 0.9983321629213483\n",
      "\n",
      "Epoch 89. Loss: 0.00601646995429521, Train_acc 0.9983414804469274\n",
      "\n",
      "Epoch 89. Loss: 0.005682065156744348, Train_acc 0.9983506944444445\n",
      "\n",
      "Epoch 89. Loss: 0.0052357203140301345, Train_acc 0.9983598066298343\n",
      "\n",
      "Epoch 89. Loss: 0.004798333048305021, Train_acc 0.9983688186813187\n",
      "\n",
      "Epoch 89. Loss: 0.004322371318356006, Train_acc 0.9983777322404371\n",
      "\n",
      "Epoch 89. Loss: 0.004090221926606424, Train_acc 0.9983865489130435\n",
      "\n",
      "Epoch 89. Loss: 0.003856026164102609, Train_acc 0.9983952702702703\n",
      "\n",
      "Epoch 89. Loss: 0.004198032301060606, Train_acc 0.9983618951612904\n",
      "\n",
      "Epoch 89. Loss: 0.0039003958451902117, Train_acc 0.9983706550802139\n",
      "\n",
      "Epoch 89. Loss: 0.005695241069628767, Train_acc 0.9983377659574468\n",
      "\n",
      "Epoch 89. Loss: 0.005899359919876431, Train_acc 0.9983052248677249\n",
      "\n",
      "Epoch 89. Loss: 0.005334766344372697, Train_acc 0.9983141447368421\n",
      "\n",
      "Epoch 89. Loss: 0.0048608968751025355, Train_acc 0.9983229712041884\n",
      "\n",
      "Epoch 89. Loss: 0.005804450203900829, Train_acc 0.998291015625\n",
      "\n",
      "Epoch 89. Loss: 0.005686035709761347, Train_acc 0.9982998704663213\n",
      "\n",
      "Epoch 89. Loss: 0.005323136662035673, Train_acc 0.9983086340206185\n",
      "\n",
      "Epoch 89. Loss: 0.004889384223619391, Train_acc 0.9983173076923076\n",
      "\n",
      "Epoch 89. Loss: 0.00465421450888302, Train_acc 0.99832\n",
      "\n",
      "Epoch 90. Loss: 0.00997068425496089, Train_acc 0.9921875\n",
      "\n",
      "Epoch 90. Loss: 0.009360525806997725, Train_acc 0.99609375\n",
      "\n",
      "Epoch 90. Loss: 0.008459462573048034, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 90. Loss: 0.008109804378747844, Train_acc 0.998046875\n",
      "\n",
      "Epoch 90. Loss: 0.00799154209096721, Train_acc 0.9984375\n",
      "\n",
      "Epoch 90. Loss: 0.007854489966477375, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 90. Loss: 0.008598771919380504, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 90. Loss: 0.008507700208935928, Train_acc 0.99609375\n",
      "\n",
      "Epoch 90. Loss: 0.007673686086874679, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 90. Loss: 0.006954843135808424, Train_acc 0.996875\n",
      "\n",
      "Epoch 90. Loss: 0.006308942389533981, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 90. Loss: 0.01210779862288779, Train_acc 0.99609375\n",
      "\n",
      "Epoch 90. Loss: 0.010935247852623278, Train_acc 0.9963942307692307\n",
      "\n",
      "Epoch 90. Loss: 0.009849489770853911, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 90. Loss: 0.009173191781922633, Train_acc 0.996875\n",
      "\n",
      "Epoch 90. Loss: 0.008500083031357337, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 90. Loss: 0.00788594586068482, Train_acc 0.9972426470588235\n",
      "\n",
      "Epoch 90. Loss: 0.007683007515198804, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 90. Loss: 0.011718868699723616, Train_acc 0.9962993421052632\n",
      "\n",
      "Epoch 90. Loss: 0.010720073438782216, Train_acc 0.996484375\n",
      "\n",
      "Epoch 90. Loss: 0.010171527216969777, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 90. Loss: 0.010050609771286413, Train_acc 0.9968039772727273\n",
      "\n",
      "Epoch 90. Loss: 0.01436331873882559, Train_acc 0.9962635869565217\n",
      "\n",
      "Epoch 90. Loss: 0.018117800406355383, Train_acc 0.9957682291666666\n",
      "\n",
      "Epoch 90. Loss: 0.016397678118356664, Train_acc 0.9959375\n",
      "\n",
      "Epoch 90. Loss: 0.01584988136864477, Train_acc 0.9957932692307693\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90. Loss: 0.017022923825175527, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 90. Loss: 0.015612009377285211, Train_acc 0.9958147321428571\n",
      "\n",
      "Epoch 90. Loss: 0.018419553230110738, Train_acc 0.9956896551724138\n",
      "\n",
      "Epoch 90. Loss: 0.016942092556793034, Train_acc 0.9958333333333333\n",
      "\n",
      "Epoch 90. Loss: 0.01544360749225784, Train_acc 0.9959677419354839\n",
      "\n",
      "Epoch 90. Loss: 0.014772220468231756, Train_acc 0.995849609375\n",
      "\n",
      "Epoch 90. Loss: 0.01616033786449616, Train_acc 0.9955018939393939\n",
      "\n",
      "Epoch 90. Loss: 0.017673055817906125, Train_acc 0.9951746323529411\n",
      "\n",
      "Epoch 90. Loss: 0.016117061670511124, Train_acc 0.9953125\n",
      "\n",
      "Epoch 90. Loss: 0.01492701403429135, Train_acc 0.9954427083333334\n",
      "\n",
      "Epoch 90. Loss: 0.014800937705159405, Train_acc 0.9955658783783784\n",
      "\n",
      "Epoch 90. Loss: 0.018169593125212387, Train_acc 0.9952713815789473\n",
      "\n",
      "Epoch 90. Loss: 0.01713294233870047, Train_acc 0.9953926282051282\n",
      "\n",
      "Epoch 90. Loss: 0.015682172036281562, Train_acc 0.9955078125\n",
      "\n",
      "Epoch 90. Loss: 0.015072667604188326, Train_acc 0.9954268292682927\n",
      "\n",
      "Epoch 90. Loss: 0.015431230557412091, Train_acc 0.9953497023809523\n",
      "\n",
      "Epoch 90. Loss: 0.014980476424798533, Train_acc 0.9952761627906976\n",
      "\n",
      "Epoch 90. Loss: 0.015227646634613125, Train_acc 0.9952059659090909\n",
      "\n",
      "Epoch 90. Loss: 0.013773627966092212, Train_acc 0.9953125\n",
      "\n",
      "Epoch 90. Loss: 0.012755321430851086, Train_acc 0.9954144021739131\n",
      "\n",
      "Epoch 90. Loss: 0.013816067286749837, Train_acc 0.995345744680851\n",
      "\n",
      "Epoch 90. Loss: 0.018015747107643032, Train_acc 0.9949544270833334\n",
      "\n",
      "Epoch 90. Loss: 0.016239866853295842, Train_acc 0.9950573979591837\n",
      "\n",
      "Epoch 90. Loss: 0.014752540754543167, Train_acc 0.99515625\n",
      "\n",
      "Epoch 90. Loss: 0.016074161433219693, Train_acc 0.9949448529411765\n",
      "\n",
      "Epoch 90. Loss: 0.02822572651777248, Train_acc 0.9944411057692307\n",
      "\n",
      "Epoch 90. Loss: 0.025477263953002517, Train_acc 0.9945459905660378\n",
      "\n",
      "Epoch 90. Loss: 0.023605383914600812, Train_acc 0.9946469907407407\n",
      "\n",
      "Epoch 90. Loss: 0.02149667470493853, Train_acc 0.9947443181818182\n",
      "\n",
      "Epoch 90. Loss: 0.027013631571879446, Train_acc 0.9944196428571429\n",
      "\n",
      "Epoch 90. Loss: 0.024829671236843282, Train_acc 0.9945175438596491\n",
      "\n",
      "Epoch 90. Loss: 0.02395436021951176, Train_acc 0.9944773706896551\n",
      "\n",
      "Epoch 90. Loss: 0.021648943992440068, Train_acc 0.9945709745762712\n",
      "\n",
      "Epoch 90. Loss: 0.020009145558909324, Train_acc 0.9946614583333333\n",
      "\n",
      "Epoch 90. Loss: 0.02285101078841306, Train_acc 0.9944928278688525\n",
      "\n",
      "Epoch 90. Loss: 0.021437230337201508, Train_acc 0.9945816532258065\n",
      "\n",
      "Epoch 90. Loss: 0.02102741480190064, Train_acc 0.9945436507936508\n",
      "\n",
      "Epoch 90. Loss: 0.020156009635941736, Train_acc 0.9945068359375\n",
      "\n",
      "Epoch 90. Loss: 0.01943225040654828, Train_acc 0.9944711538461538\n",
      "\n",
      "Epoch 90. Loss: 0.017945369515900225, Train_acc 0.9945549242424242\n",
      "\n",
      "Epoch 90. Loss: 0.016750362763852843, Train_acc 0.9946361940298507\n",
      "\n",
      "Epoch 90. Loss: 0.0164329954050937, Train_acc 0.9946001838235294\n",
      "\n",
      "Epoch 90. Loss: 0.01578011681702364, Train_acc 0.9945652173913043\n",
      "\n",
      "Epoch 90. Loss: 0.016763573393821375, Train_acc 0.99453125\n",
      "\n",
      "Epoch 90. Loss: 0.01530221836676418, Train_acc 0.9946082746478874\n",
      "\n",
      "Epoch 90. Loss: 0.013961996230611675, Train_acc 0.9946831597222222\n",
      "\n",
      "Epoch 90. Loss: 0.013972431858446722, Train_acc 0.9946489726027398\n",
      "\n",
      "Epoch 90. Loss: 0.012813802480198316, Train_acc 0.9947212837837838\n",
      "\n",
      "Epoch 90. Loss: 0.012792485563752686, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 90. Loss: 0.01164419411629972, Train_acc 0.994860197368421\n",
      "\n",
      "Epoch 90. Loss: 0.010683254880366063, Train_acc 0.994926948051948\n",
      "\n",
      "Epoch 90. Loss: 0.009983628218389155, Train_acc 0.9949919871794872\n",
      "\n",
      "Epoch 90. Loss: 0.0091223136345073, Train_acc 0.9950553797468354\n",
      "\n",
      "Epoch 90. Loss: 0.009364437975840965, Train_acc 0.99501953125\n",
      "\n",
      "Epoch 90. Loss: 0.00866285121685165, Train_acc 0.9950810185185185\n",
      "\n",
      "Epoch 90. Loss: 0.008697443362288754, Train_acc 0.995141006097561\n",
      "\n",
      "Epoch 90. Loss: 0.008094596983831895, Train_acc 0.9951995481927711\n",
      "\n",
      "Epoch 90. Loss: 0.007662037431232727, Train_acc 0.9952566964285714\n",
      "\n",
      "Epoch 90. Loss: 0.009673409948378143, Train_acc 0.9952205882352941\n",
      "\n",
      "Epoch 90. Loss: 0.008779964725760895, Train_acc 0.9952761627906976\n",
      "\n",
      "Epoch 90. Loss: 0.008512414857153545, Train_acc 0.9952406609195402\n",
      "\n",
      "Epoch 90. Loss: 0.007853830880325543, Train_acc 0.9952947443181818\n",
      "\n",
      "Epoch 90. Loss: 0.007105090201688415, Train_acc 0.9953476123595506\n",
      "\n",
      "Epoch 90. Loss: 0.006461598222666329, Train_acc 0.9953993055555556\n",
      "\n",
      "Epoch 90. Loss: 0.006115672723767173, Train_acc 0.9954498626373627\n",
      "\n",
      "Epoch 90. Loss: 0.00573213340422542, Train_acc 0.995499320652174\n",
      "\n",
      "Epoch 90. Loss: 0.008350797965356985, Train_acc 0.9953797043010753\n",
      "\n",
      "Epoch 90. Loss: 0.008058369751330566, Train_acc 0.9954288563829787\n",
      "\n",
      "Epoch 90. Loss: 0.00743308827209668, Train_acc 0.9954769736842105\n",
      "\n",
      "Epoch 90. Loss: 0.00689513812149939, Train_acc 0.9955240885416666\n",
      "\n",
      "Epoch 90. Loss: 0.006558638988043759, Train_acc 0.9955702319587629\n",
      "\n",
      "Epoch 90. Loss: 0.006014339664002562, Train_acc 0.9956154336734694\n",
      "\n",
      "Epoch 90. Loss: 0.005535921349081669, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 90. Loss: 0.005554942701193637, Train_acc 0.995703125\n",
      "\n",
      "[Epoch 90 Batch 100] Loss: 0.008022191820084703 Training: accuracy=0.995514\n",
      "Epoch 90. Loss: 0.008022191820084703, Train_acc 0.9955136138613861\n",
      "\n",
      "Epoch 90. Loss: 0.007952382499015021, Train_acc 0.9954810049019608\n",
      "\n",
      "Epoch 90. Loss: 0.0077469849220237336, Train_acc 0.9955248786407767\n",
      "\n",
      "Epoch 90. Loss: 0.006996773510921593, Train_acc 0.9955679086538461\n",
      "\n",
      "Epoch 90. Loss: 0.007998164851738748, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 90. Loss: 0.01062293658489621, Train_acc 0.9955041273584906\n",
      "\n",
      "Epoch 90. Loss: 0.009659384586301176, Train_acc 0.9955461448598131\n",
      "\n",
      "Epoch 90. Loss: 0.011620825251537617, Train_acc 0.9955150462962963\n",
      "\n",
      "Epoch 90. Loss: 0.010692294539673379, Train_acc 0.9955561926605505\n",
      "\n",
      "Epoch 90. Loss: 0.009776849853896276, Train_acc 0.9955965909090909\n",
      "\n",
      "Epoch 90. Loss: 0.00906331488917307, Train_acc 0.9956362612612613\n",
      "\n",
      "Epoch 90. Loss: 0.0112824743935171, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 90. Loss: 0.010573821068811705, Train_acc 0.995575221238938\n",
      "\n",
      "Epoch 90. Loss: 0.009762364024266564, Train_acc 0.9956140350877193\n",
      "\n",
      "Epoch 90. Loss: 0.01292505292088833, Train_acc 0.9955163043478261\n",
      "\n",
      "Epoch 90. Loss: 0.013216492821196139, Train_acc 0.9954876077586207\n",
      "\n",
      "Epoch 90. Loss: 0.01227197155621149, Train_acc 0.9955261752136753\n",
      "\n",
      "Epoch 90. Loss: 0.011734450199229996, Train_acc 0.9955640889830508\n",
      "\n",
      "Epoch 90. Loss: 0.013873575408479704, Train_acc 0.9954044117647058\n",
      "\n",
      "Epoch 90. Loss: 0.01341679910947782, Train_acc 0.9953776041666667\n",
      "\n",
      "Epoch 90. Loss: 0.012458172173469385, Train_acc 0.995415805785124\n",
      "\n",
      "Epoch 90. Loss: 0.01146817546051215, Train_acc 0.995453381147541\n",
      "\n",
      "Epoch 90. Loss: 0.010453014819165805, Train_acc 0.9954903455284553\n",
      "\n",
      "Epoch 90. Loss: 0.011967829501635498, Train_acc 0.9954637096774194\n",
      "\n",
      "Epoch 90. Loss: 0.011367796706563234, Train_acc 0.9955\n",
      "\n",
      "Epoch 90. Loss: 0.010818400926431418, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 90. Loss: 0.011877279346025348, Train_acc 0.9955093503937008\n",
      "\n",
      "Epoch 90. Loss: 0.012119360110017385, Train_acc 0.9954833984375\n",
      "\n",
      "Epoch 90. Loss: 0.011026545564847641, Train_acc 0.9955184108527132\n",
      "\n",
      "Epoch 90. Loss: 0.013171547681555856, Train_acc 0.9954927884615384\n",
      "\n",
      "Epoch 90. Loss: 0.012146222213513292, Train_acc 0.9955271946564885\n",
      "\n",
      "Epoch 90. Loss: 0.011987322210168813, Train_acc 0.9955018939393939\n",
      "\n",
      "Epoch 90. Loss: 0.01325088859846828, Train_acc 0.9954769736842105\n",
      "\n",
      "Epoch 90. Loss: 0.012634327787911633, Train_acc 0.9954524253731343\n",
      "\n",
      "Epoch 90. Loss: 0.011962848387291197, Train_acc 0.9954861111111111\n",
      "\n",
      "Epoch 90. Loss: 0.011429221725878267, Train_acc 0.9954618566176471\n",
      "\n",
      "Epoch 90. Loss: 0.010493081849590375, Train_acc 0.9954949817518248\n",
      "\n",
      "Epoch 90. Loss: 0.009501093082460032, Train_acc 0.9955276268115942\n",
      "\n",
      "Epoch 90. Loss: 0.008778638522810281, Train_acc 0.9955598021582733\n",
      "\n",
      "Epoch 90. Loss: 0.008055357163070775, Train_acc 0.9955915178571428\n",
      "\n",
      "Epoch 90. Loss: 0.007574173346089545, Train_acc 0.9956227836879432\n",
      "\n",
      "Epoch 90. Loss: 0.007397318942034743, Train_acc 0.9956536091549296\n",
      "\n",
      "Epoch 90. Loss: 0.007191294534296842, Train_acc 0.9956840034965035\n",
      "\n",
      "Epoch 90. Loss: 0.007622595819793092, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 90. Loss: 0.007824307070340467, Train_acc 0.9956896551724138\n",
      "\n",
      "Epoch 90. Loss: 0.010326436879783052, Train_acc 0.9956656678082192\n",
      "\n",
      "Epoch 90. Loss: 0.011347559516920906, Train_acc 0.9956420068027211\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90. Loss: 0.010264421379689585, Train_acc 0.9956714527027027\n",
      "\n",
      "Epoch 90. Loss: 0.009614270092993269, Train_acc 0.9957005033557047\n",
      "\n",
      "Epoch 90. Loss: 0.008839333525832108, Train_acc 0.9957291666666667\n",
      "\n",
      "Epoch 90. Loss: 0.008559054734813224, Train_acc 0.9957057119205298\n",
      "\n",
      "Epoch 90. Loss: 0.007719089775608637, Train_acc 0.9957339638157895\n",
      "\n",
      "Epoch 90. Loss: 0.007012836717072494, Train_acc 0.9957618464052288\n",
      "\n",
      "Epoch 90. Loss: 0.006453303402944684, Train_acc 0.9957893668831169\n",
      "\n",
      "Epoch 90. Loss: 0.006219537453756583, Train_acc 0.9958165322580645\n",
      "\n",
      "Epoch 90. Loss: 0.006321304981624352, Train_acc 0.9957932692307693\n",
      "\n",
      "Epoch 90. Loss: 0.005767609289080516, Train_acc 0.9958200636942676\n",
      "\n",
      "Epoch 90. Loss: 0.005368427418972358, Train_acc 0.9958465189873418\n",
      "\n",
      "Epoch 90. Loss: 0.006628143176411365, Train_acc 0.9958235062893082\n",
      "\n",
      "Epoch 90. Loss: 0.00601333711722473, Train_acc 0.995849609375\n",
      "\n",
      "Epoch 90. Loss: 0.005490201142959488, Train_acc 0.9958753881987578\n",
      "\n",
      "Epoch 90. Loss: 0.005122259753226661, Train_acc 0.9959008487654321\n",
      "\n",
      "Epoch 90. Loss: 0.00483670989273884, Train_acc 0.9959259969325154\n",
      "\n",
      "Epoch 90. Loss: 0.004474921321635528, Train_acc 0.9959508384146342\n",
      "\n",
      "Epoch 90. Loss: 0.004094239593422488, Train_acc 0.9959753787878788\n",
      "\n",
      "Epoch 90. Loss: 0.0037469355133744257, Train_acc 0.9959996234939759\n",
      "\n",
      "Epoch 90. Loss: 0.004365154574892418, Train_acc 0.9959767964071856\n",
      "\n",
      "Epoch 90. Loss: 0.003979845031172258, Train_acc 0.9960007440476191\n",
      "\n",
      "Epoch 90. Loss: 0.004192978941562971, Train_acc 0.9960244082840237\n",
      "\n",
      "Epoch 90. Loss: 0.0037964055190437217, Train_acc 0.9960477941176471\n",
      "\n",
      "Epoch 90. Loss: 0.005236462734635459, Train_acc 0.9960252192982456\n",
      "\n",
      "Epoch 90. Loss: 0.005370951251309323, Train_acc 0.9960029069767442\n",
      "\n",
      "Epoch 90. Loss: 0.006988073786605485, Train_acc 0.9959808526011561\n",
      "\n",
      "Epoch 90. Loss: 0.0064036475815705245, Train_acc 0.9960039511494253\n",
      "\n",
      "Epoch 90. Loss: 0.007492972361892324, Train_acc 0.9959375\n",
      "\n",
      "Epoch 90. Loss: 0.006789383744994054, Train_acc 0.9959605823863636\n",
      "\n",
      "Epoch 90. Loss: 0.006328155433356092, Train_acc 0.9959834039548022\n",
      "\n",
      "Epoch 90. Loss: 0.006185914847823374, Train_acc 0.9960059691011236\n",
      "\n",
      "Epoch 90. Loss: 0.0057371103252558935, Train_acc 0.9960282821229051\n",
      "\n",
      "Epoch 90. Loss: 0.0052309083748762935, Train_acc 0.9960503472222222\n",
      "\n",
      "Epoch 90. Loss: 0.004746105861528677, Train_acc 0.9960721685082873\n",
      "\n",
      "Epoch 90. Loss: 0.011690081589100327, Train_acc 0.9960508241758241\n",
      "\n",
      "Epoch 90. Loss: 0.010546378107737252, Train_acc 0.9960724043715847\n",
      "\n",
      "Epoch 90. Loss: 0.009565122974473908, Train_acc 0.99609375\n",
      "\n",
      "Epoch 90. Loss: 0.012360239895485646, Train_acc 0.9960726351351351\n",
      "\n",
      "Epoch 90. Loss: 0.011337842119308836, Train_acc 0.99609375\n",
      "\n",
      "Epoch 90. Loss: 0.010404748259735877, Train_acc 0.9961146390374331\n",
      "\n",
      "Epoch 90. Loss: 0.010830788162725664, Train_acc 0.99609375\n",
      "\n",
      "Epoch 90. Loss: 0.009760514685518478, Train_acc 0.996114417989418\n",
      "\n",
      "Epoch 90. Loss: 0.009476827883577588, Train_acc 0.9961348684210526\n",
      "\n",
      "Epoch 90. Loss: 0.014462986413111903, Train_acc 0.9961142015706806\n",
      "\n",
      "Epoch 90. Loss: 0.015969246132794573, Train_acc 0.99609375\n",
      "\n",
      "Epoch 90. Loss: 0.01938465826537331, Train_acc 0.9960330310880829\n",
      "\n",
      "Epoch 90. Loss: 0.01746146892593778, Train_acc 0.9960534793814433\n",
      "\n",
      "Epoch 90. Loss: 0.015995929618207904, Train_acc 0.9960737179487179\n",
      "\n",
      "Epoch 90. Loss: 0.014442975893939995, Train_acc 0.99608\n",
      "\n",
      "Epoch 91. Loss: 0.013338921034999606, Train_acc 1.0\n",
      "\n",
      "Epoch 91. Loss: 0.012222601950244234, Train_acc 1.0\n",
      "\n",
      "Epoch 91. Loss: 0.012974488009580487, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 91. Loss: 0.016516028138609393, Train_acc 0.994140625\n",
      "\n",
      "Epoch 91. Loss: 0.014980173703196643, Train_acc 0.9953125\n",
      "\n",
      "Epoch 91. Loss: 0.014149597736370263, Train_acc 0.99609375\n",
      "\n",
      "Epoch 91. Loss: 0.014277025679205385, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 91. Loss: 0.013251684591804022, Train_acc 0.99609375\n",
      "\n",
      "Epoch 91. Loss: 0.013502310576111742, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 91. Loss: 0.012354376146185996, Train_acc 0.996875\n",
      "\n",
      "Epoch 91. Loss: 0.011609057606970013, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 91. Loss: 0.010675382377436527, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 91. Loss: 0.009833016750646325, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 91. Loss: 0.009068047168790722, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 91. Loss: 0.008238808659531034, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 91. Loss: 0.007499581034206471, Train_acc 0.998046875\n",
      "\n",
      "Epoch 91. Loss: 0.006854844477040876, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 91. Loss: 0.006405444853764751, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 91. Loss: 0.0089960007339078, Train_acc 0.9971217105263158\n",
      "\n",
      "Epoch 91. Loss: 0.008209934470298094, Train_acc 0.997265625\n",
      "\n",
      "Epoch 91. Loss: 0.007852527975805584, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 91. Loss: 0.007216506908254012, Train_acc 0.9975142045454546\n",
      "\n",
      "Epoch 91. Loss: 0.0066910717743630865, Train_acc 0.9976222826086957\n",
      "\n",
      "Epoch 91. Loss: 0.006184437289245039, Train_acc 0.9977213541666666\n",
      "\n",
      "Epoch 91. Loss: 0.005967012027120986, Train_acc 0.9978125\n",
      "\n",
      "Epoch 91. Loss: 0.005494972611821948, Train_acc 0.9978966346153846\n",
      "\n",
      "Epoch 91. Loss: 0.00510286278886997, Train_acc 0.9979745370370371\n",
      "\n",
      "Epoch 91. Loss: 0.0051626472535437635, Train_acc 0.998046875\n",
      "\n",
      "Epoch 91. Loss: 0.0054008167710339686, Train_acc 0.998114224137931\n",
      "\n",
      "Epoch 91. Loss: 0.004989912887791007, Train_acc 0.9981770833333333\n",
      "\n",
      "Epoch 91. Loss: 0.004639594698477576, Train_acc 0.9982358870967742\n",
      "\n",
      "Epoch 91. Loss: 0.00427731763268601, Train_acc 0.998291015625\n",
      "\n",
      "Epoch 91. Loss: 0.004019363134235958, Train_acc 0.998342803030303\n",
      "\n",
      "Epoch 91. Loss: 0.003758668338661629, Train_acc 0.9983915441176471\n",
      "\n",
      "Epoch 91. Loss: 0.003460982041888897, Train_acc 0.9984375\n",
      "\n",
      "Epoch 91. Loss: 0.0036492321672291733, Train_acc 0.9984809027777778\n",
      "\n",
      "Epoch 91. Loss: 0.0038368706899658896, Train_acc 0.9985219594594594\n",
      "\n",
      "Epoch 91. Loss: 0.0037318449977659634, Train_acc 0.9985608552631579\n",
      "\n",
      "Epoch 91. Loss: 0.0033890992745830226, Train_acc 0.9985977564102564\n",
      "\n",
      "Epoch 91. Loss: 0.003316824136420215, Train_acc 0.9986328125\n",
      "\n",
      "Epoch 91. Loss: 0.003070042735956944, Train_acc 0.9986661585365854\n",
      "\n",
      "Epoch 91. Loss: 0.0028544389720614287, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 91. Loss: 0.0027090020780657707, Train_acc 0.9987281976744186\n",
      "\n",
      "Epoch 91. Loss: 0.002480489355414098, Train_acc 0.9987571022727273\n",
      "\n",
      "Epoch 91. Loss: 0.002326241029338377, Train_acc 0.9987847222222223\n",
      "\n",
      "Epoch 91. Loss: 0.0021248611951618307, Train_acc 0.9988111413043478\n",
      "\n",
      "Epoch 91. Loss: 0.0019726231246217116, Train_acc 0.9988364361702128\n",
      "\n",
      "Epoch 91. Loss: 0.0020721408368147036, Train_acc 0.9988606770833334\n",
      "\n",
      "Epoch 91. Loss: 0.001895863609770942, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 91. Loss: 0.0017209828191503025, Train_acc 0.99890625\n",
      "\n",
      "Epoch 91. Loss: 0.001578663823941161, Train_acc 0.9989276960784313\n",
      "\n",
      "Epoch 91. Loss: 0.001502070860165411, Train_acc 0.9989483173076923\n",
      "\n",
      "Epoch 91. Loss: 0.0013715824589288158, Train_acc 0.9989681603773585\n",
      "\n",
      "Epoch 91. Loss: 0.002533814968629711, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 91. Loss: 0.003491033330080539, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 91. Loss: 0.0031571184625494527, Train_acc 0.9986049107142857\n",
      "\n",
      "Epoch 91. Loss: 0.0030062381042220932, Train_acc 0.9986293859649122\n",
      "\n",
      "Epoch 91. Loss: 0.002721343445873502, Train_acc 0.9986530172413793\n",
      "\n",
      "Epoch 91. Loss: 0.002555755512111255, Train_acc 0.9986758474576272\n",
      "\n",
      "Epoch 91. Loss: 0.002340622521466719, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 91. Loss: 0.0030674386452377205, Train_acc 0.998719262295082\n",
      "\n",
      "Epoch 91. Loss: 0.002800028232136811, Train_acc 0.9987399193548387\n",
      "\n",
      "Epoch 91. Loss: 0.0027340794253195334, Train_acc 0.9987599206349206\n",
      "\n",
      "Epoch 91. Loss: 0.0025061759357975057, Train_acc 0.998779296875\n",
      "\n",
      "Epoch 91. Loss: 0.0022798598383775063, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 91. Loss: 0.002081242035088528, Train_acc 0.9988162878787878\n",
      "\n",
      "Epoch 91. Loss: 0.0019082593826318954, Train_acc 0.9988339552238806\n",
      "\n",
      "Epoch 91. Loss: 0.0017233606668148951, Train_acc 0.9988511029411765\n",
      "\n",
      "Epoch 91. Loss: 0.0015806603874928445, Train_acc 0.9988677536231884\n",
      "\n",
      "Epoch 91. Loss: 0.002254243149265649, Train_acc 0.9987723214285714\n",
      "\n",
      "Epoch 91. Loss: 0.00611462559155077, Train_acc 0.9986795774647887\n",
      "\n",
      "Epoch 91. Loss: 0.005550215142708199, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 91. Loss: 0.005361127939849654, Train_acc 0.9987157534246576\n",
      "\n",
      "Epoch 91. Loss: 0.004831151179199458, Train_acc 0.9987331081081081\n",
      "\n",
      "Epoch 91. Loss: 0.004752393785171247, Train_acc 0.99875\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91. Loss: 0.004344459366174821, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 91. Loss: 0.0039681778421787476, Train_acc 0.9987824675324676\n",
      "\n",
      "Epoch 91. Loss: 0.0035797302075504826, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 91. Loss: 0.0032231793343748677, Train_acc 0.9988132911392406\n",
      "\n",
      "Epoch 91. Loss: 0.0029064500050455786, Train_acc 0.998828125\n",
      "\n",
      "Epoch 91. Loss: 0.0027808876119593197, Train_acc 0.9988425925925926\n",
      "\n",
      "Epoch 91. Loss: 0.002516420593018442, Train_acc 0.9988567073170732\n",
      "\n",
      "Epoch 91. Loss: 0.002302647401810536, Train_acc 0.9988704819277109\n",
      "\n",
      "Epoch 91. Loss: 0.0021476551148798457, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 91. Loss: 0.0021069803352808704, Train_acc 0.9988970588235294\n",
      "\n",
      "Epoch 91. Loss: 0.001903185561534904, Train_acc 0.9989098837209303\n",
      "\n",
      "Epoch 91. Loss: 0.0018374764641073131, Train_acc 0.9989224137931034\n",
      "\n",
      "Epoch 91. Loss: 0.0017038725988146768, Train_acc 0.9989346590909091\n",
      "\n",
      "Epoch 91. Loss: 0.0015393315337688218, Train_acc 0.9989466292134831\n",
      "\n",
      "Epoch 91. Loss: 0.0014205168666585229, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 91. Loss: 0.0016181306767145344, Train_acc 0.9989697802197802\n",
      "\n",
      "Epoch 91. Loss: 0.0014670999866919468, Train_acc 0.9989809782608695\n",
      "\n",
      "Epoch 91. Loss: 0.0013526880191693901, Train_acc 0.998991935483871\n",
      "\n",
      "Epoch 91. Loss: 0.0012322059290882192, Train_acc 0.9990026595744681\n",
      "\n",
      "Epoch 91. Loss: 0.0011187694080602557, Train_acc 0.9990131578947369\n",
      "\n",
      "Epoch 91. Loss: 0.00100904720790467, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 91. Loss: 0.0009267951698889032, Train_acc 0.9990335051546392\n",
      "\n",
      "Epoch 91. Loss: 0.0008479187440330263, Train_acc 0.9990433673469388\n",
      "\n",
      "Epoch 91. Loss: 0.0007719320247144249, Train_acc 0.9990530303030303\n",
      "\n",
      "Epoch 91. Loss: 0.0007079111082235274, Train_acc 0.9990625\n",
      "\n",
      "[Epoch 91 Batch 100] Loss: 0.0006398695672316594 Training: accuracy=0.999072\n",
      "Epoch 91. Loss: 0.0006398695672316594, Train_acc 0.9990717821782178\n",
      "\n",
      "Epoch 91. Loss: 0.000595603571207981, Train_acc 0.9990808823529411\n",
      "\n",
      "Epoch 91. Loss: 0.0005767924475360609, Train_acc 0.9990898058252428\n",
      "\n",
      "Epoch 91. Loss: 0.0006105226706416484, Train_acc 0.9990985576923077\n",
      "\n",
      "Epoch 91. Loss: 0.0005720443341963024, Train_acc 0.9991071428571429\n",
      "\n",
      "Epoch 91. Loss: 0.000520756737520963, Train_acc 0.9991155660377359\n",
      "\n",
      "Epoch 91. Loss: 0.0005072453242358222, Train_acc 0.999123831775701\n",
      "\n",
      "Epoch 91. Loss: 0.0008045824642240991, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 91. Loss: 0.0007373013917705595, Train_acc 0.9991399082568807\n",
      "\n",
      "Epoch 91. Loss: 0.0007065649414329913, Train_acc 0.9991477272727273\n",
      "\n",
      "Epoch 91. Loss: 0.0006479870142320561, Train_acc 0.9991554054054054\n",
      "\n",
      "Epoch 91. Loss: 0.0021280111584168464, Train_acc 0.9990931919642857\n",
      "\n",
      "Epoch 91. Loss: 0.0019243172612230031, Train_acc 0.9991012168141593\n",
      "\n",
      "Epoch 91. Loss: 0.0017506776397752059, Train_acc 0.999109100877193\n",
      "\n",
      "Epoch 91. Loss: 0.001578108165156895, Train_acc 0.999116847826087\n",
      "\n",
      "Epoch 91. Loss: 0.0025039499306607734, Train_acc 0.9990571120689655\n",
      "\n",
      "Epoch 91. Loss: 0.002266774185516066, Train_acc 0.9990651709401709\n",
      "\n",
      "Epoch 91. Loss: 0.004273479453937077, Train_acc 0.9990068855932204\n",
      "\n",
      "Epoch 91. Loss: 0.0038492964336902177, Train_acc 0.999015231092437\n",
      "\n",
      "Epoch 91. Loss: 0.0034717227878347102, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 91. Loss: 0.009351074847177423, Train_acc 0.9989669421487604\n",
      "\n",
      "Epoch 91. Loss: 0.008536970600478283, Train_acc 0.9989754098360656\n",
      "\n",
      "Epoch 91. Loss: 0.007721106852374723, Train_acc 0.9989837398373984\n",
      "\n",
      "Epoch 91. Loss: 0.007940730284406767, Train_acc 0.998991935483871\n",
      "\n",
      "Epoch 91. Loss: 0.007380348395112777, Train_acc 0.999\n",
      "\n",
      "Epoch 91. Loss: 0.008805574358228109, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 91. Loss: 0.007972558297211612, Train_acc 0.9988927165354331\n",
      "\n",
      "Epoch 91. Loss: 0.007238446475653814, Train_acc 0.9989013671875\n",
      "\n",
      "Epoch 91. Loss: 0.006528308333794501, Train_acc 0.9989098837209303\n",
      "\n",
      "Epoch 91. Loss: 0.009385637127018178, Train_acc 0.998858173076923\n",
      "\n",
      "Epoch 91. Loss: 0.008952365317707841, Train_acc 0.9988668893129771\n",
      "\n",
      "Epoch 91. Loss: 0.014787350742905365, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 91. Loss: 0.013403824682285513, Train_acc 0.9987077067669173\n",
      "\n",
      "Epoch 91. Loss: 0.012081547248598766, Train_acc 0.9987173507462687\n",
      "\n",
      "Epoch 91. Loss: 0.01237133817887619, Train_acc 0.9986689814814815\n",
      "\n",
      "Epoch 91. Loss: 0.012023584823456243, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 91. Loss: 0.016126520288568886, Train_acc 0.9984603102189781\n",
      "\n",
      "Epoch 91. Loss: 0.015345570238753097, Train_acc 0.9984714673913043\n",
      "\n",
      "Epoch 91. Loss: 0.013893261652561818, Train_acc 0.9984824640287769\n",
      "\n",
      "Epoch 91. Loss: 0.01449225460860681, Train_acc 0.9984375\n",
      "\n",
      "Epoch 91. Loss: 0.013473868051158352, Train_acc 0.9984485815602837\n",
      "\n",
      "Epoch 91. Loss: 0.012975937865513829, Train_acc 0.9984595070422535\n",
      "\n",
      "Epoch 91. Loss: 0.013592379794125201, Train_acc 0.9984156468531469\n",
      "\n",
      "Epoch 91. Loss: 0.01510057431215445, Train_acc 0.9983723958333334\n",
      "\n",
      "Epoch 91. Loss: 0.014923497089037894, Train_acc 0.9983836206896551\n",
      "\n",
      "Epoch 91. Loss: 0.013596421700304388, Train_acc 0.998394691780822\n",
      "\n",
      "Epoch 91. Loss: 0.013573516693638836, Train_acc 0.9983524659863946\n",
      "\n",
      "Epoch 91. Loss: 0.012618251485237845, Train_acc 0.998363597972973\n",
      "\n",
      "Epoch 91. Loss: 0.01142145228004548, Train_acc 0.9983745805369127\n",
      "\n",
      "Epoch 91. Loss: 0.010351590047138272, Train_acc 0.9983854166666667\n",
      "\n",
      "Epoch 91. Loss: 0.013572830390802626, Train_acc 0.9982408940397351\n",
      "\n",
      "Epoch 91. Loss: 0.014854842698757295, Train_acc 0.9982010690789473\n",
      "\n",
      "Epoch 91. Loss: 0.017129540541336932, Train_acc 0.9981107026143791\n",
      "\n",
      "Epoch 91. Loss: 0.015525531717225313, Train_acc 0.9981229707792207\n",
      "\n",
      "Epoch 91. Loss: 0.015443524224833608, Train_acc 0.9980846774193548\n",
      "\n",
      "Epoch 91. Loss: 0.014331793303736413, Train_acc 0.9980969551282052\n",
      "\n",
      "Epoch 91. Loss: 0.013244555070838361, Train_acc 0.998109076433121\n",
      "\n",
      "Epoch 91. Loss: 0.013574999987936941, Train_acc 0.9980221518987342\n",
      "\n",
      "Epoch 91. Loss: 0.01316497570188963, Train_acc 0.9979854559748428\n",
      "\n",
      "Epoch 91. Loss: 0.012039620355476054, Train_acc 0.997998046875\n",
      "\n",
      "Epoch 91. Loss: 0.012246827994175952, Train_acc 0.9979619565217391\n",
      "\n",
      "Epoch 91. Loss: 0.013919560318638268, Train_acc 0.9978780864197531\n",
      "\n",
      "Epoch 91. Loss: 0.012845348219602747, Train_acc 0.9978911042944786\n",
      "\n",
      "Epoch 91. Loss: 0.012727104373749593, Train_acc 0.9978563262195121\n",
      "\n",
      "Epoch 91. Loss: 0.014436291007378548, Train_acc 0.9978219696969697\n",
      "\n",
      "Epoch 91. Loss: 0.014671723073582815, Train_acc 0.9977880271084337\n",
      "\n",
      "Epoch 91. Loss: 0.020889733009810122, Train_acc 0.9977077095808383\n",
      "\n",
      "Epoch 91. Loss: 0.02022260299170751, Train_acc 0.9977213541666666\n",
      "\n",
      "Epoch 91. Loss: 0.02043357189754908, Train_acc 0.9976886094674556\n",
      "\n",
      "Epoch 91. Loss: 0.018994001936259254, Train_acc 0.9977022058823529\n",
      "\n",
      "Epoch 91. Loss: 0.018198973551102626, Train_acc 0.9976699561403509\n",
      "\n",
      "Epoch 91. Loss: 0.016905435733608736, Train_acc 0.9976835029069767\n",
      "\n",
      "Epoch 91. Loss: 0.01861972032124907, Train_acc 0.9976517341040463\n",
      "\n",
      "Epoch 91. Loss: 0.02010938452006975, Train_acc 0.9976203304597702\n",
      "\n",
      "Epoch 91. Loss: 0.01831291820172905, Train_acc 0.9976339285714285\n",
      "\n",
      "Epoch 91. Loss: 0.016888813929090852, Train_acc 0.9976473721590909\n",
      "\n",
      "Epoch 91. Loss: 0.01560701484426554, Train_acc 0.997660663841808\n",
      "\n",
      "Epoch 91. Loss: 0.014222210089181626, Train_acc 0.9976738061797753\n",
      "\n",
      "Epoch 91. Loss: 0.016541755220128386, Train_acc 0.9975558659217877\n",
      "\n",
      "Epoch 91. Loss: 0.015202995277941188, Train_acc 0.9975694444444444\n",
      "\n",
      "Epoch 91. Loss: 0.014084311474114621, Train_acc 0.9975828729281768\n",
      "\n",
      "Epoch 91. Loss: 0.013311661000177234, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 91. Loss: 0.01239142887901512, Train_acc 0.9976092896174863\n",
      "\n",
      "Epoch 91. Loss: 0.011960139220457501, Train_acc 0.9976222826086957\n",
      "\n",
      "Epoch 91. Loss: 0.012294071662874127, Train_acc 0.9975929054054054\n",
      "\n",
      "Epoch 91. Loss: 0.013431157021329795, Train_acc 0.9975638440860215\n",
      "\n",
      "Epoch 91. Loss: 0.012840734873583313, Train_acc 0.9975350935828877\n",
      "\n",
      "Epoch 91. Loss: 0.012259083638149855, Train_acc 0.9975066489361702\n",
      "\n",
      "Epoch 91. Loss: 0.011572475632257781, Train_acc 0.9975198412698413\n",
      "\n",
      "Epoch 91. Loss: 0.010531327998469044, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 91. Loss: 0.009626010130901428, Train_acc 0.9975458115183246\n",
      "\n",
      "Epoch 91. Loss: 0.00882051557602074, Train_acc 0.99755859375\n",
      "\n",
      "Epoch 91. Loss: 0.009724278780534145, Train_acc 0.9975307642487047\n",
      "\n",
      "Epoch 91. Loss: 0.009070071299938212, Train_acc 0.9975434922680413\n",
      "\n",
      "Epoch 91. Loss: 0.008309714273796544, Train_acc 0.9975560897435898\n",
      "\n",
      "Epoch 91. Loss: 0.007611343716400324, Train_acc 0.99756\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92. Loss: 0.007117784676723891, Train_acc 1.0\n",
      "\n",
      "Epoch 92. Loss: 0.007237423762178313, Train_acc 0.99609375\n",
      "\n",
      "Epoch 92. Loss: 0.00982566860720148, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 92. Loss: 0.009251668023955497, Train_acc 0.99609375\n",
      "\n",
      "Epoch 92. Loss: 0.008502824485000228, Train_acc 0.996875\n",
      "\n",
      "Epoch 92. Loss: 0.008021906269256402, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 92. Loss: 0.007261483111123149, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 92. Loss: 0.006558201740718733, Train_acc 0.998046875\n",
      "\n",
      "Epoch 92. Loss: 0.006142400297629999, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 92. Loss: 0.005638493797167987, Train_acc 0.9984375\n",
      "\n",
      "Epoch 92. Loss: 0.005244614989911631, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 92. Loss: 0.004933508642856879, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 92. Loss: 0.004662382427613083, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 92. Loss: 0.00434191346709592, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 92. Loss: 0.004379372882869806, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 92. Loss: 0.004932132684165508, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 92. Loss: 0.0045792351873175235, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 92. Loss: 0.0041605856521518625, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 92. Loss: 0.006200175494276726, Train_acc 0.9979440789473685\n",
      "\n",
      "Epoch 92. Loss: 0.005858958787201265, Train_acc 0.998046875\n",
      "\n",
      "Epoch 92. Loss: 0.0068167803673253235, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 92. Loss: 0.0071270597790157, Train_acc 0.9975142045454546\n",
      "\n",
      "Epoch 92. Loss: 0.006708690081899631, Train_acc 0.9976222826086957\n",
      "\n",
      "Epoch 92. Loss: 0.006188743747929723, Train_acc 0.9977213541666666\n",
      "\n",
      "Epoch 92. Loss: 0.006278186198467009, Train_acc 0.9978125\n",
      "\n",
      "Epoch 92. Loss: 0.006308694267774219, Train_acc 0.9978966346153846\n",
      "\n",
      "Epoch 92. Loss: 0.0064091464980732754, Train_acc 0.9979745370370371\n",
      "\n",
      "Epoch 92. Loss: 0.006165982769813361, Train_acc 0.998046875\n",
      "\n",
      "Epoch 92. Loss: 0.005577316556508442, Train_acc 0.998114224137931\n",
      "\n",
      "Epoch 92. Loss: 0.005233503200271816, Train_acc 0.9981770833333333\n",
      "\n",
      "Epoch 92. Loss: 0.004848420510490171, Train_acc 0.9982358870967742\n",
      "\n",
      "Epoch 92. Loss: 0.004819444421871989, Train_acc 0.998291015625\n",
      "\n",
      "Epoch 92. Loss: 0.004359309904195098, Train_acc 0.998342803030303\n",
      "\n",
      "Epoch 92. Loss: 0.0050754135764395246, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 92. Loss: 0.004701941470157807, Train_acc 0.9982142857142857\n",
      "\n",
      "Epoch 92. Loss: 0.004493063678459857, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 92. Loss: 0.004093794827826203, Train_acc 0.9983108108108109\n",
      "\n",
      "Epoch 92. Loss: 0.0036996220178768836, Train_acc 0.9983552631578947\n",
      "\n",
      "Epoch 92. Loss: 0.0033615272065877144, Train_acc 0.9983974358974359\n",
      "\n",
      "Epoch 92. Loss: 0.00409248640649431, Train_acc 0.9982421875\n",
      "\n",
      "Epoch 92. Loss: 0.0037144263560641233, Train_acc 0.9982850609756098\n",
      "\n",
      "Epoch 92. Loss: 0.0064115358866812374, Train_acc 0.9981398809523809\n",
      "\n",
      "Epoch 92. Loss: 0.006814584614565514, Train_acc 0.9980014534883721\n",
      "\n",
      "Epoch 92. Loss: 0.006320954288785645, Train_acc 0.998046875\n",
      "\n",
      "Epoch 92. Loss: 0.00738924675501435, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 92. Loss: 0.007635304573777757, Train_acc 0.9977921195652174\n",
      "\n",
      "Epoch 92. Loss: 0.0069051998773210724, Train_acc 0.9978390957446809\n",
      "\n",
      "Epoch 92. Loss: 0.006475892192892148, Train_acc 0.9978841145833334\n",
      "\n",
      "Epoch 92. Loss: 0.006013577073534054, Train_acc 0.9979272959183674\n",
      "\n",
      "Epoch 92. Loss: 0.005631198309483876, Train_acc 0.99796875\n",
      "\n",
      "Epoch 92. Loss: 0.010408365195354298, Train_acc 0.9977022058823529\n",
      "\n",
      "Epoch 92. Loss: 0.009438233498247392, Train_acc 0.9977463942307693\n",
      "\n",
      "Epoch 92. Loss: 0.01314360559598678, Train_acc 0.9973466981132075\n",
      "\n",
      "Epoch 92. Loss: 0.012090099828237954, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 92. Loss: 0.018849488774056435, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 92. Loss: 0.018021773651196244, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 92. Loss: 0.016270463233353138, Train_acc 0.9971217105263158\n",
      "\n",
      "Epoch 92. Loss: 0.016793475656355715, Train_acc 0.9970366379310345\n",
      "\n",
      "Epoch 92. Loss: 0.0272278311329889, Train_acc 0.9964247881355932\n",
      "\n",
      "Epoch 92. Loss: 0.02483418600900987, Train_acc 0.996484375\n",
      "\n",
      "Epoch 92. Loss: 0.022645654426498883, Train_acc 0.9965420081967213\n",
      "\n",
      "Epoch 92. Loss: 0.022229134534135764, Train_acc 0.9964717741935484\n",
      "\n",
      "Epoch 92. Loss: 0.0329228292354959, Train_acc 0.996155753968254\n",
      "\n",
      "Epoch 92. Loss: 0.031968187580914895, Train_acc 0.99609375\n",
      "\n",
      "Epoch 92. Loss: 0.02983862239755237, Train_acc 0.9960336538461538\n",
      "\n",
      "Epoch 92. Loss: 0.027292154547679817, Train_acc 0.99609375\n",
      "\n",
      "Epoch 92. Loss: 0.02478600665873295, Train_acc 0.996152052238806\n",
      "\n",
      "Epoch 92. Loss: 0.02546672001432782, Train_acc 0.9959788602941176\n",
      "\n",
      "Epoch 92. Loss: 0.02432073686228459, Train_acc 0.9960371376811594\n",
      "\n",
      "Epoch 92. Loss: 0.024221717122551188, Train_acc 0.9959821428571428\n",
      "\n",
      "Epoch 92. Loss: 0.02370131821485435, Train_acc 0.9959286971830986\n",
      "\n",
      "Epoch 92. Loss: 0.025697864020336345, Train_acc 0.9957682291666666\n",
      "\n",
      "Epoch 92. Loss: 0.027589592568101295, Train_acc 0.9955051369863014\n",
      "\n",
      "Epoch 92. Loss: 0.026354635043759768, Train_acc 0.9954603040540541\n",
      "\n",
      "Epoch 92. Loss: 0.02560167099578943, Train_acc 0.9954166666666666\n",
      "\n",
      "Epoch 92. Loss: 0.024088116009924707, Train_acc 0.9954769736842105\n",
      "\n",
      "Epoch 92. Loss: 0.022103148707280067, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 92. Loss: 0.023109526269313254, Train_acc 0.9953926282051282\n",
      "\n",
      "Epoch 92. Loss: 0.02342327274323394, Train_acc 0.9953520569620253\n",
      "\n",
      "Epoch 92. Loss: 0.022171752005287027, Train_acc 0.9953125\n",
      "\n",
      "Epoch 92. Loss: 0.020059116227076665, Train_acc 0.9953703703703703\n",
      "\n",
      "Epoch 92. Loss: 0.018198424965087667, Train_acc 0.9954268292682927\n",
      "\n",
      "Epoch 92. Loss: 0.016613418110037532, Train_acc 0.9954819277108434\n",
      "\n",
      "Epoch 92. Loss: 0.015323229066945334, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 92. Loss: 0.013972693737708528, Train_acc 0.9955882352941177\n",
      "\n",
      "Epoch 92. Loss: 0.012906673801232576, Train_acc 0.9956395348837209\n",
      "\n",
      "Epoch 92. Loss: 0.0118371762542032, Train_acc 0.9956896551724138\n",
      "\n",
      "Epoch 92. Loss: 0.010848045116269838, Train_acc 0.9957386363636364\n",
      "\n",
      "Epoch 92. Loss: 0.010564400232378469, Train_acc 0.9957865168539326\n",
      "\n",
      "Epoch 92. Loss: 0.01156201673437103, Train_acc 0.9957465277777777\n",
      "\n",
      "Epoch 92. Loss: 0.012266641709705692, Train_acc 0.9957074175824175\n",
      "\n",
      "Epoch 92. Loss: 0.011476112268269511, Train_acc 0.9957540760869565\n",
      "\n",
      "Epoch 92. Loss: 0.010497160486340926, Train_acc 0.9957997311827957\n",
      "\n",
      "Epoch 92. Loss: 0.009965029845649367, Train_acc 0.995844414893617\n",
      "\n",
      "Epoch 92. Loss: 0.009139968108305512, Train_acc 0.9958881578947368\n",
      "\n",
      "Epoch 92. Loss: 0.008446952747295063, Train_acc 0.9959309895833334\n",
      "\n",
      "Epoch 92. Loss: 0.008953399681588795, Train_acc 0.9958923969072165\n",
      "\n",
      "Epoch 92. Loss: 0.008191177933103548, Train_acc 0.9959343112244898\n",
      "\n",
      "Epoch 92. Loss: 0.007738387678879536, Train_acc 0.9959753787878788\n",
      "\n",
      "Epoch 92. Loss: 0.010228583822981748, Train_acc 0.9959375\n",
      "\n",
      "[Epoch 92 Batch 100] Loss: 0.010791195394399376 Training: accuracy=0.995900\n",
      "Epoch 92. Loss: 0.010791195394399376, Train_acc 0.9959003712871287\n",
      "\n",
      "Epoch 92. Loss: 0.01055230716553564, Train_acc 0.9959405637254902\n",
      "\n",
      "Epoch 92. Loss: 0.00975995630863817, Train_acc 0.9959799757281553\n",
      "\n",
      "Epoch 92. Loss: 0.009035715516747637, Train_acc 0.9960186298076923\n",
      "\n",
      "Epoch 92. Loss: 0.008222486230393816, Train_acc 0.9960565476190476\n",
      "\n",
      "Epoch 92. Loss: 0.00819043174996427, Train_acc 0.99609375\n",
      "\n",
      "Epoch 92. Loss: 0.007400024293594745, Train_acc 0.9961302570093458\n",
      "\n",
      "Epoch 92. Loss: 0.008080445997774471, Train_acc 0.99609375\n",
      "\n",
      "Epoch 92. Loss: 0.007534238316067936, Train_acc 0.9961295871559633\n",
      "\n",
      "Epoch 92. Loss: 0.006816814397695406, Train_acc 0.9961647727272728\n",
      "\n",
      "Epoch 92. Loss: 0.00645685128655828, Train_acc 0.9961993243243243\n",
      "\n",
      "Epoch 92. Loss: 0.00584583710292657, Train_acc 0.9962332589285714\n",
      "\n",
      "Epoch 92. Loss: 0.005365575677093981, Train_acc 0.996266592920354\n",
      "\n",
      "Epoch 92. Loss: 0.0049830712847408224, Train_acc 0.9962993421052632\n",
      "\n",
      "Epoch 92. Loss: 0.004513019071644797, Train_acc 0.9963315217391304\n",
      "\n",
      "Epoch 92. Loss: 0.004199858425894011, Train_acc 0.9963631465517241\n",
      "\n",
      "Epoch 92. Loss: 0.004024016374801364, Train_acc 0.9963942307692307\n",
      "\n",
      "Epoch 92. Loss: 0.003696264258005261, Train_acc 0.9964247881355932\n",
      "\n",
      "Epoch 92. Loss: 0.003347293123359716, Train_acc 0.9964548319327731\n",
      "\n",
      "Epoch 92. Loss: 0.0030345997398742723, Train_acc 0.996484375\n",
      "\n",
      "Epoch 92. Loss: 0.002789959183495747, Train_acc 0.9965134297520661\n",
      "\n",
      "Epoch 92. Loss: 0.002652409906792498, Train_acc 0.9965420081967213\n",
      "\n",
      "Epoch 92. Loss: 0.002412246327668933, Train_acc 0.9965701219512195\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92. Loss: 0.0032328837501142994, Train_acc 0.9965347782258065\n",
      "\n",
      "Epoch 92. Loss: 0.00349211641137015, Train_acc 0.9965625\n",
      "\n",
      "Epoch 92. Loss: 0.0032244515611309817, Train_acc 0.9965897817460317\n",
      "\n",
      "Epoch 92. Loss: 0.002986733854593323, Train_acc 0.9966166338582677\n",
      "\n",
      "Epoch 92. Loss: 0.002974707098817664, Train_acc 0.99664306640625\n",
      "\n",
      "Epoch 92. Loss: 0.008241263296022271, Train_acc 0.9965479651162791\n",
      "\n",
      "Epoch 92. Loss: 0.008795616845769514, Train_acc 0.9965144230769231\n",
      "\n",
      "Epoch 92. Loss: 0.008020621743205484, Train_acc 0.9965410305343512\n",
      "\n",
      "Epoch 92. Loss: 0.008218741899493303, Train_acc 0.9965080492424242\n",
      "\n",
      "Epoch 92. Loss: 0.007472590660985976, Train_acc 0.9965343045112782\n",
      "\n",
      "Epoch 92. Loss: 0.007073700696881118, Train_acc 0.9965601679104478\n",
      "\n",
      "Epoch 92. Loss: 0.007122103273709568, Train_acc 0.9965856481481481\n",
      "\n",
      "Epoch 92. Loss: 0.008797630615389306, Train_acc 0.9964958639705882\n",
      "\n",
      "Epoch 92. Loss: 0.008258318481465542, Train_acc 0.9965214416058394\n",
      "\n",
      "Epoch 92. Loss: 0.0075493583730566775, Train_acc 0.9965466485507246\n",
      "\n",
      "Epoch 92. Loss: 0.007318590065989638, Train_acc 0.9965714928057554\n",
      "\n",
      "Epoch 92. Loss: 0.006789302869613836, Train_acc 0.9965959821428572\n",
      "\n",
      "Epoch 92. Loss: 0.007000191418655995, Train_acc 0.9966201241134752\n",
      "\n",
      "Epoch 92. Loss: 0.006365832439153596, Train_acc 0.996643926056338\n",
      "\n",
      "Epoch 92. Loss: 0.006584209744861011, Train_acc 0.9966127622377622\n",
      "\n",
      "Epoch 92. Loss: 0.007118947657701628, Train_acc 0.9966362847222222\n",
      "\n",
      "Epoch 92. Loss: 0.006994858438751629, Train_acc 0.9966594827586207\n",
      "\n",
      "Epoch 92. Loss: 0.0065129363469614366, Train_acc 0.9966823630136986\n",
      "\n",
      "Epoch 92. Loss: 0.0058773313357998085, Train_acc 0.9967049319727891\n",
      "\n",
      "Epoch 92. Loss: 0.005685431158057078, Train_acc 0.9967271959459459\n",
      "\n",
      "Epoch 92. Loss: 0.005962622631053231, Train_acc 0.9966967281879194\n",
      "\n",
      "Epoch 92. Loss: 0.007156744757407995, Train_acc 0.9966666666666667\n",
      "\n",
      "Epoch 92. Loss: 0.006472365947789074, Train_acc 0.9966887417218543\n",
      "\n",
      "Epoch 92. Loss: 0.005939244715531427, Train_acc 0.9967105263157895\n",
      "\n",
      "Epoch 92. Loss: 0.005921416877427481, Train_acc 0.9966809640522876\n",
      "\n",
      "Epoch 92. Loss: 0.005658295855643257, Train_acc 0.9967025162337663\n",
      "\n",
      "Epoch 92. Loss: 0.00652049157907537, Train_acc 0.9966733870967742\n",
      "\n",
      "Epoch 92. Loss: 0.006022450823191298, Train_acc 0.9966947115384616\n",
      "\n",
      "Epoch 92. Loss: 0.005423104730859611, Train_acc 0.9967157643312102\n",
      "\n",
      "Epoch 92. Loss: 0.0049061361678509096, Train_acc 0.9967365506329114\n",
      "\n",
      "Epoch 92. Loss: 0.0044859181743995705, Train_acc 0.9967570754716981\n",
      "\n",
      "Epoch 92. Loss: 0.004078659305563281, Train_acc 0.99677734375\n",
      "\n",
      "Epoch 92. Loss: 0.003965851454070845, Train_acc 0.9967973602484472\n",
      "\n",
      "Epoch 92. Loss: 0.003751971483329659, Train_acc 0.9968171296296297\n",
      "\n",
      "Epoch 92. Loss: 0.0033835129005678334, Train_acc 0.9968366564417178\n",
      "\n",
      "Epoch 92. Loss: 0.003200634261169389, Train_acc 0.9968559451219512\n",
      "\n",
      "Epoch 92. Loss: 0.0028853180601550693, Train_acc 0.996875\n",
      "\n",
      "Epoch 92. Loss: 0.0026403378197531603, Train_acc 0.9968938253012049\n",
      "\n",
      "Epoch 92. Loss: 0.0077188628091496864, Train_acc 0.9968656437125748\n",
      "\n",
      "Epoch 92. Loss: 0.00699686132600711, Train_acc 0.9968843005952381\n",
      "\n",
      "Epoch 92. Loss: 0.006512451524115857, Train_acc 0.9969027366863905\n",
      "\n",
      "Epoch 92. Loss: 0.0061434352029060635, Train_acc 0.996920955882353\n",
      "\n",
      "Epoch 92. Loss: 0.007095514785828767, Train_acc 0.9968932748538012\n",
      "\n",
      "Epoch 92. Loss: 0.007614146070107143, Train_acc 0.9968659156976745\n",
      "\n",
      "Epoch 92. Loss: 0.007962990720353414, Train_acc 0.9968388728323699\n",
      "\n",
      "Epoch 92. Loss: 0.0077223654487269125, Train_acc 0.9968570402298851\n",
      "\n",
      "Epoch 92. Loss: 0.007246986996624202, Train_acc 0.996875\n",
      "\n",
      "Epoch 92. Loss: 0.0065277864303578135, Train_acc 0.9968927556818182\n",
      "\n",
      "Epoch 92. Loss: 0.00590807383654021, Train_acc 0.9969103107344632\n",
      "\n",
      "Epoch 92. Loss: 0.005320092193079847, Train_acc 0.9969276685393258\n",
      "\n",
      "Epoch 92. Loss: 0.005022406457663647, Train_acc 0.9969448324022346\n",
      "\n",
      "Epoch 92. Loss: 0.006700444113136296, Train_acc 0.996875\n",
      "\n",
      "Epoch 92. Loss: 0.006087705208020402, Train_acc 0.9968922651933702\n",
      "\n",
      "Epoch 92. Loss: 0.005884638358494931, Train_acc 0.9969093406593407\n",
      "\n",
      "Epoch 92. Loss: 0.005370811790616849, Train_acc 0.9969262295081968\n",
      "\n",
      "Epoch 92. Loss: 0.004860579465586578, Train_acc 0.9969429347826086\n",
      "\n",
      "Epoch 92. Loss: 0.0044189882254864, Train_acc 0.9969594594594594\n",
      "\n",
      "Epoch 92. Loss: 0.00492634859841453, Train_acc 0.9969338037634409\n",
      "\n",
      "Epoch 92. Loss: 0.0047103739592706, Train_acc 0.9969502005347594\n",
      "\n",
      "Epoch 92. Loss: 0.004271173068857178, Train_acc 0.9969664228723404\n",
      "\n",
      "Epoch 92. Loss: 0.003872516098005647, Train_acc 0.9969824735449735\n",
      "\n",
      "Epoch 92. Loss: 0.0036393462784474265, Train_acc 0.9969983552631579\n",
      "\n",
      "Epoch 92. Loss: 0.003319810751773395, Train_acc 0.9970140706806283\n",
      "\n",
      "Epoch 92. Loss: 0.0031368211603253885, Train_acc 0.9970296223958334\n",
      "\n",
      "Epoch 92. Loss: 0.002920898147229684, Train_acc 0.9970450129533679\n",
      "\n",
      "Epoch 92. Loss: 0.002648404689521677, Train_acc 0.9970602448453608\n",
      "\n",
      "Epoch 92. Loss: 0.002417165017747733, Train_acc 0.9970753205128206\n",
      "\n",
      "Epoch 92. Loss: 0.0022010223923101084, Train_acc 0.99708\n",
      "\n",
      "Epoch 93. Loss: 0.0031270298346555885, Train_acc 0.9921875\n",
      "\n",
      "Epoch 93. Loss: 0.0034659337685713164, Train_acc 0.99609375\n",
      "\n",
      "Epoch 93. Loss: 0.0033438951167055063, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 93. Loss: 0.0033651217936430658, Train_acc 0.998046875\n",
      "\n",
      "Epoch 93. Loss: 0.003065220830188702, Train_acc 0.9984375\n",
      "\n",
      "Epoch 93. Loss: 0.0027599860336015936, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 93. Loss: 0.002530376313734344, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 93. Loss: 0.0022970824488219434, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 93. Loss: 0.002120620511592193, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 93. Loss: 0.001955082126675111, Train_acc 0.99921875\n",
      "\n",
      "Epoch 93. Loss: 0.0017783176961372043, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 93. Loss: 0.0016041488822378736, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 93. Loss: 0.0014726519121122455, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 93. Loss: 0.0013674353909032802, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 93. Loss: 0.0012730019818968856, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 93. Loss: 0.0011999012185240343, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 93. Loss: 0.0012148426246811053, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 93. Loss: 0.004982468674078802, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 93. Loss: 0.004506555610315792, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 93. Loss: 0.004666713314950578, Train_acc 0.9984375\n",
      "\n",
      "Epoch 93. Loss: 0.004200653901222466, Train_acc 0.9985119047619048\n",
      "\n",
      "Epoch 93. Loss: 0.0038235468591583835, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 93. Loss: 0.0038619604528248074, Train_acc 0.998641304347826\n",
      "\n",
      "Epoch 93. Loss: 0.008854489787247757, Train_acc 0.9983723958333334\n",
      "\n",
      "Epoch 93. Loss: 0.007976166986184103, Train_acc 0.9984375\n",
      "\n",
      "Epoch 93. Loss: 0.007205398626459308, Train_acc 0.9984975961538461\n",
      "\n",
      "Epoch 93. Loss: 0.00649927513522735, Train_acc 0.9985532407407407\n",
      "\n",
      "Epoch 93. Loss: 0.005857753411845002, Train_acc 0.9986049107142857\n",
      "\n",
      "Epoch 93. Loss: 0.005279987926470589, Train_acc 0.9986530172413793\n",
      "\n",
      "Epoch 93. Loss: 0.008433489017356055, Train_acc 0.9984375\n",
      "\n",
      "Epoch 93. Loss: 0.007602575424219828, Train_acc 0.9984879032258065\n",
      "\n",
      "Epoch 93. Loss: 0.0069758795623569144, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 93. Loss: 0.006283528654147397, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 93. Loss: 0.009986210210653435, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 93. Loss: 0.009031534192423335, Train_acc 0.9982142857142857\n",
      "\n",
      "Epoch 93. Loss: 0.008212316214397455, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 93. Loss: 0.0074927406987927, Train_acc 0.9983108108108109\n",
      "\n",
      "Epoch 93. Loss: 0.006965976332512346, Train_acc 0.9983552631578947\n",
      "\n",
      "Epoch 93. Loss: 0.00836676668365614, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 93. Loss: 0.0075465814563466585, Train_acc 0.9982421875\n",
      "\n",
      "Epoch 93. Loss: 0.006905322986759258, Train_acc 0.9982850609756098\n",
      "\n",
      "Epoch 93. Loss: 0.006333372301143419, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 93. Loss: 0.006104942601202736, Train_acc 0.9983648255813954\n",
      "\n",
      "Epoch 93. Loss: 0.00710534731264008, Train_acc 0.9982244318181818\n",
      "\n",
      "Epoch 93. Loss: 0.009731775638894078, Train_acc 0.9980902777777778\n",
      "\n",
      "Epoch 93. Loss: 0.009255766005011651, Train_acc 0.9981317934782609\n",
      "\n",
      "Epoch 93. Loss: 0.008743241723128188, Train_acc 0.9981715425531915\n",
      "\n",
      "Epoch 93. Loss: 0.007900254634598371, Train_acc 0.9982096354166666\n",
      "\n",
      "Epoch 93. Loss: 0.007850893111225495, Train_acc 0.9982461734693877\n",
      "\n",
      "Epoch 93. Loss: 0.009495994504865882, Train_acc 0.99796875\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93. Loss: 0.011465593999543975, Train_acc 0.9977022058823529\n",
      "\n",
      "Epoch 93. Loss: 0.011465626892524233, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 93. Loss: 0.010338531409128738, Train_acc 0.9976415094339622\n",
      "\n",
      "Epoch 93. Loss: 0.009321624785496167, Train_acc 0.9976851851851852\n",
      "\n",
      "Epoch 93. Loss: 0.008705683108270202, Train_acc 0.9977272727272727\n",
      "\n",
      "Epoch 93. Loss: 0.009927363371342451, Train_acc 0.9974888392857143\n",
      "\n",
      "Epoch 93. Loss: 0.00951016426875296, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 93. Loss: 0.008587008787433978, Train_acc 0.9975754310344828\n",
      "\n",
      "Epoch 93. Loss: 0.008202554965681442, Train_acc 0.9976165254237288\n",
      "\n",
      "Epoch 93. Loss: 0.007637139034718223, Train_acc 0.99765625\n",
      "\n",
      "Epoch 93. Loss: 0.0073077146313637025, Train_acc 0.9976946721311475\n",
      "\n",
      "Epoch 93. Loss: 0.006675573674772638, Train_acc 0.9977318548387096\n",
      "\n",
      "Epoch 93. Loss: 0.006043062589868977, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 93. Loss: 0.005513519088749654, Train_acc 0.997802734375\n",
      "\n",
      "Epoch 93. Loss: 0.007676439768366129, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 93. Loss: 0.007427928498797516, Train_acc 0.9976325757575758\n",
      "\n",
      "Epoch 93. Loss: 0.007145586465817302, Train_acc 0.9976679104477612\n",
      "\n",
      "Epoch 93. Loss: 0.0071157940112247554, Train_acc 0.9977022058823529\n",
      "\n",
      "Epoch 93. Loss: 0.007116354281770691, Train_acc 0.9976222826086957\n",
      "\n",
      "Epoch 93. Loss: 0.006458513879044731, Train_acc 0.99765625\n",
      "\n",
      "Epoch 93. Loss: 0.006062881835301709, Train_acc 0.9976892605633803\n",
      "\n",
      "Epoch 93. Loss: 0.005968698971420519, Train_acc 0.9977213541666666\n",
      "\n",
      "Epoch 93. Loss: 0.005714465932391578, Train_acc 0.9977525684931506\n",
      "\n",
      "Epoch 93. Loss: 0.005773858787574614, Train_acc 0.9976773648648649\n",
      "\n",
      "Epoch 93. Loss: 0.006616045440994124, Train_acc 0.9976041666666666\n",
      "\n",
      "Epoch 93. Loss: 0.005968412144139339, Train_acc 0.9976356907894737\n",
      "\n",
      "Epoch 93. Loss: 0.005390451854924888, Train_acc 0.9976663961038961\n",
      "\n",
      "Epoch 93. Loss: 0.004908754614835707, Train_acc 0.9976963141025641\n",
      "\n",
      "Epoch 93. Loss: 0.004537883815664704, Train_acc 0.9977254746835443\n",
      "\n",
      "Epoch 93. Loss: 0.009355886355786314, Train_acc 0.9974609375\n",
      "\n",
      "Epoch 93. Loss: 0.008531526134087555, Train_acc 0.9974922839506173\n",
      "\n",
      "Epoch 93. Loss: 0.008064988105974119, Train_acc 0.9975228658536586\n",
      "\n",
      "Epoch 93. Loss: 0.007271758223536667, Train_acc 0.9975527108433735\n",
      "\n",
      "Epoch 93. Loss: 0.006757328514721743, Train_acc 0.9975818452380952\n",
      "\n",
      "Epoch 93. Loss: 0.006935623865842895, Train_acc 0.9975183823529412\n",
      "\n",
      "Epoch 93. Loss: 0.007414759116488763, Train_acc 0.9974563953488372\n",
      "\n",
      "Epoch 93. Loss: 0.006771408725002171, Train_acc 0.9974856321839081\n",
      "\n",
      "Epoch 93. Loss: 0.006126379563836391, Train_acc 0.9975142045454546\n",
      "\n",
      "Epoch 93. Loss: 0.006019533631066801, Train_acc 0.9975421348314607\n",
      "\n",
      "Epoch 93. Loss: 0.0062300282703581355, Train_acc 0.9974826388888889\n",
      "\n",
      "Epoch 93. Loss: 0.010000304995782038, Train_acc 0.9972527472527473\n",
      "\n",
      "Epoch 93. Loss: 0.009022130262157493, Train_acc 0.9972826086956522\n",
      "\n",
      "Epoch 93. Loss: 0.008135506717277809, Train_acc 0.9973118279569892\n",
      "\n",
      "Epoch 93. Loss: 0.01099103804640166, Train_acc 0.9970910904255319\n",
      "\n",
      "Epoch 93. Loss: 0.013698471631516744, Train_acc 0.9969572368421052\n",
      "\n",
      "Epoch 93. Loss: 0.012915389169075843, Train_acc 0.9969889322916666\n",
      "\n",
      "Epoch 93. Loss: 0.012126088721366604, Train_acc 0.9970199742268041\n",
      "\n",
      "Epoch 93. Loss: 0.011763929724227082, Train_acc 0.9969706632653061\n",
      "\n",
      "Epoch 93. Loss: 0.010593295770481428, Train_acc 0.9970012626262627\n",
      "\n",
      "Epoch 93. Loss: 0.009700263885773152, Train_acc 0.99703125\n",
      "\n",
      "[Epoch 93 Batch 100] Loss: 0.009044850253679093 Training: accuracy=0.997061\n",
      "Epoch 93. Loss: 0.009044850253679093, Train_acc 0.9970606435643564\n",
      "\n",
      "Epoch 93. Loss: 0.013466285363093976, Train_acc 0.9970128676470589\n",
      "\n",
      "Epoch 93. Loss: 0.012955038088788956, Train_acc 0.9970418689320388\n",
      "\n",
      "Epoch 93. Loss: 0.013170261312929126, Train_acc 0.9969951923076923\n",
      "\n",
      "Epoch 93. Loss: 0.012003166870429217, Train_acc 0.9970238095238095\n",
      "\n",
      "Epoch 93. Loss: 0.010960567449506313, Train_acc 0.9970518867924528\n",
      "\n",
      "Epoch 93. Loss: 0.009994203822479718, Train_acc 0.9970794392523364\n",
      "\n",
      "Epoch 93. Loss: 0.009096569977793312, Train_acc 0.9971064814814815\n",
      "\n",
      "Epoch 93. Loss: 0.008355186065742268, Train_acc 0.9971330275229358\n",
      "\n",
      "Epoch 93. Loss: 0.007830887104832138, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 93. Loss: 0.007132527898654793, Train_acc 0.9971846846846847\n",
      "\n",
      "Epoch 93. Loss: 0.007013260353421081, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 93. Loss: 0.006948861403076269, Train_acc 0.9972345132743363\n",
      "\n",
      "Epoch 93. Loss: 0.006422859738484101, Train_acc 0.9972587719298246\n",
      "\n",
      "Epoch 93. Loss: 0.005908194794604995, Train_acc 0.9972826086956522\n",
      "\n",
      "Epoch 93. Loss: 0.005520843872591691, Train_acc 0.9973060344827587\n",
      "\n",
      "Epoch 93. Loss: 0.005260958101412508, Train_acc 0.9973290598290598\n",
      "\n",
      "Epoch 93. Loss: 0.0055378131317146305, Train_acc 0.9973516949152542\n",
      "\n",
      "Epoch 93. Loss: 0.010347993500266762, Train_acc 0.9973082983193278\n",
      "\n",
      "Epoch 93. Loss: 0.01215599335184779, Train_acc 0.997265625\n",
      "\n",
      "Epoch 93. Loss: 0.01103030419487546, Train_acc 0.9972882231404959\n",
      "\n",
      "Epoch 93. Loss: 0.00994968720274734, Train_acc 0.9973104508196722\n",
      "\n",
      "Epoch 93. Loss: 0.010246071365453906, Train_acc 0.9972688008130082\n",
      "\n",
      "Epoch 93. Loss: 0.009360411026141591, Train_acc 0.9972908266129032\n",
      "\n",
      "Epoch 93. Loss: 0.00846316021889363, Train_acc 0.9973125\n",
      "\n",
      "Epoch 93. Loss: 0.0076606090645912825, Train_acc 0.9973338293650794\n",
      "\n",
      "Epoch 93. Loss: 0.007103038104221839, Train_acc 0.9973548228346457\n",
      "\n",
      "Epoch 93. Loss: 0.0064447669018728605, Train_acc 0.99737548828125\n",
      "\n",
      "Epoch 93. Loss: 0.006107032477506078, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 93. Loss: 0.006389512468559811, Train_acc 0.9973557692307692\n",
      "\n",
      "Epoch 93. Loss: 0.005878957589358034, Train_acc 0.9973759541984732\n",
      "\n",
      "Epoch 93. Loss: 0.005332572070829891, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 93. Loss: 0.004807303232198963, Train_acc 0.9974154135338346\n",
      "\n",
      "Epoch 93. Loss: 0.004389899444725521, Train_acc 0.9974347014925373\n",
      "\n",
      "Epoch 93. Loss: 0.004076541725788779, Train_acc 0.9974537037037037\n",
      "\n",
      "Epoch 93. Loss: 0.0036986925560603817, Train_acc 0.9974724264705882\n",
      "\n",
      "Epoch 93. Loss: 0.0034298041042904806, Train_acc 0.9974908759124088\n",
      "\n",
      "Epoch 93. Loss: 0.003109445557033822, Train_acc 0.9975090579710145\n",
      "\n",
      "Epoch 93. Loss: 0.005029365205796783, Train_acc 0.997470773381295\n",
      "\n",
      "Epoch 93. Loss: 0.005832125705360376, Train_acc 0.9974330357142858\n",
      "\n",
      "Epoch 93. Loss: 0.005329020176691788, Train_acc 0.9974512411347518\n",
      "\n",
      "Epoch 93. Loss: 0.004959986577917318, Train_acc 0.9974691901408451\n",
      "\n",
      "Epoch 93. Loss: 0.0046217221595995246, Train_acc 0.9974868881118881\n",
      "\n",
      "Epoch 93. Loss: 0.008402671984865006, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 93. Loss: 0.00831996333706415, Train_acc 0.9974137931034482\n",
      "\n",
      "Epoch 93. Loss: 0.007601396947388676, Train_acc 0.997431506849315\n",
      "\n",
      "Epoch 93. Loss: 0.009624041096226717, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 93. Loss: 0.010507870369425128, Train_acc 0.9973606418918919\n",
      "\n",
      "Epoch 93. Loss: 0.00948006599875156, Train_acc 0.997378355704698\n",
      "\n",
      "Epoch 93. Loss: 0.008931984586106514, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 93. Loss: 0.00813073683929006, Train_acc 0.9974130794701986\n",
      "\n",
      "Epoch 93. Loss: 0.008828500456972956, Train_acc 0.9973787006578947\n",
      "\n",
      "Epoch 93. Loss: 0.008280393518944716, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 93. Loss: 0.00752884190894899, Train_acc 0.9974127435064936\n",
      "\n",
      "Epoch 93. Loss: 0.007825601845542228, Train_acc 0.9973790322580646\n",
      "\n",
      "Epoch 93. Loss: 0.0075647108252879704, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 93. Loss: 0.0069195502061578686, Train_acc 0.9974124203821656\n",
      "\n",
      "Epoch 93. Loss: 0.0063295744603104635, Train_acc 0.9974287974683544\n",
      "\n",
      "Epoch 93. Loss: 0.0058658827036077305, Train_acc 0.9974449685534591\n",
      "\n",
      "Epoch 93. Loss: 0.005508392801683056, Train_acc 0.9974609375\n",
      "\n",
      "Epoch 93. Loss: 0.005690079471812464, Train_acc 0.9974767080745341\n",
      "\n",
      "Epoch 93. Loss: 0.005164447076098979, Train_acc 0.9974922839506173\n",
      "\n",
      "Epoch 93. Loss: 0.004717035024517948, Train_acc 0.9975076687116564\n",
      "\n",
      "Epoch 93. Loss: 0.004345620620984591, Train_acc 0.9975228658536586\n",
      "\n",
      "Epoch 93. Loss: 0.00410584632846453, Train_acc 0.9975378787878788\n",
      "\n",
      "Epoch 93. Loss: 0.004475085887322469, Train_acc 0.9975056475903614\n",
      "\n",
      "Epoch 93. Loss: 0.004240729957715848, Train_acc 0.9975205838323353\n",
      "\n",
      "Epoch 93. Loss: 0.005127917703148287, Train_acc 0.9974888392857143\n",
      "\n",
      "Epoch 93. Loss: 0.0047607556796728625, Train_acc 0.9975036982248521\n",
      "\n",
      "Epoch 93. Loss: 0.004607089062593196, Train_acc 0.9975183823529412\n",
      "\n",
      "Epoch 93. Loss: 0.004320940635687991, Train_acc 0.9975328947368421\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93. Loss: 0.0039228034372007555, Train_acc 0.997547238372093\n",
      "\n",
      "Epoch 93. Loss: 0.0036009962727018333, Train_acc 0.9975614161849711\n",
      "\n",
      "Epoch 93. Loss: 0.004772920604293478, Train_acc 0.9975305316091954\n",
      "\n",
      "Epoch 93. Loss: 0.005137864433149933, Train_acc 0.9975446428571428\n",
      "\n",
      "Epoch 93. Loss: 0.006776427417177355, Train_acc 0.9975142045454546\n",
      "\n",
      "Epoch 93. Loss: 0.0067518537692830526, Train_acc 0.9974841101694916\n",
      "\n",
      "Epoch 93. Loss: 0.007677402164274951, Train_acc 0.9974543539325843\n",
      "\n",
      "Epoch 93. Loss: 0.011658280550600142, Train_acc 0.9974249301675978\n",
      "\n",
      "Epoch 93. Loss: 0.010541191574460462, Train_acc 0.9974392361111111\n",
      "\n",
      "Epoch 93. Loss: 0.01029047848793226, Train_acc 0.9974102209944752\n",
      "\n",
      "Epoch 93. Loss: 0.009705393228045322, Train_acc 0.9974244505494505\n",
      "\n",
      "Epoch 93. Loss: 0.008807557968736411, Train_acc 0.9974385245901639\n",
      "\n",
      "Epoch 93. Loss: 0.008571844149849465, Train_acc 0.997452445652174\n",
      "\n",
      "Epoch 93. Loss: 0.007776115697578327, Train_acc 0.9974662162162162\n",
      "\n",
      "Epoch 93. Loss: 0.007529243349542383, Train_acc 0.9974798387096774\n",
      "\n",
      "Epoch 93. Loss: 0.007036574151115266, Train_acc 0.9974933155080213\n",
      "\n",
      "Epoch 93. Loss: 0.007066487118002755, Train_acc 0.9974650930851063\n",
      "\n",
      "Epoch 93. Loss: 0.008505150201377555, Train_acc 0.9974371693121693\n",
      "\n",
      "Epoch 93. Loss: 0.009839686324409203, Train_acc 0.9974095394736842\n",
      "\n",
      "Epoch 93. Loss: 0.009268650661598047, Train_acc 0.9974231020942408\n",
      "\n",
      "Epoch 93. Loss: 0.00922381158979869, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 93. Loss: 0.008949339392219209, Train_acc 0.9973688471502591\n",
      "\n",
      "Epoch 93. Loss: 0.009080383928806385, Train_acc 0.9973421391752577\n",
      "\n",
      "Epoch 93. Loss: 0.008822723992264988, Train_acc 0.9973557692307692\n",
      "\n",
      "Epoch 93. Loss: 0.007996894147380118, Train_acc 0.99736\n",
      "\n",
      "Epoch 94. Loss: 0.007766313559681706, Train_acc 1.0\n",
      "\n",
      "Epoch 94. Loss: 0.007014393212595686, Train_acc 1.0\n",
      "\n",
      "Epoch 94. Loss: 0.006327616965734531, Train_acc 1.0\n",
      "\n",
      "Epoch 94. Loss: 0.005933807589230152, Train_acc 1.0\n",
      "\n",
      "Epoch 94. Loss: 0.005924265129223953, Train_acc 1.0\n",
      "\n",
      "Epoch 94. Loss: 0.005659166929443619, Train_acc 1.0\n",
      "\n",
      "Epoch 94. Loss: 0.006022002174544281, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 94. Loss: 0.009755762330372286, Train_acc 0.998046875\n",
      "\n",
      "Epoch 94. Loss: 0.00967526271493359, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 94. Loss: 0.010675083297948154, Train_acc 0.99765625\n",
      "\n",
      "Epoch 94. Loss: 0.009666050663703782, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 94. Loss: 0.008760917980428355, Train_acc 0.998046875\n",
      "\n",
      "Epoch 94. Loss: 0.013652289330025748, Train_acc 0.9969951923076923\n",
      "\n",
      "Epoch 94. Loss: 0.012292991921015505, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 94. Loss: 0.01166011855091863, Train_acc 0.996875\n",
      "\n",
      "Epoch 94. Loss: 0.010555487954828559, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 94. Loss: 0.009888799885143417, Train_acc 0.9972426470588235\n",
      "\n",
      "Epoch 94. Loss: 0.01120249668439887, Train_acc 0.9969618055555556\n",
      "\n",
      "Epoch 94. Loss: 0.01358991367829438, Train_acc 0.9962993421052632\n",
      "\n",
      "Epoch 94. Loss: 0.014500946580284202, Train_acc 0.99609375\n",
      "\n",
      "Epoch 94. Loss: 0.013175416910328742, Train_acc 0.9962797619047619\n",
      "\n",
      "Epoch 94. Loss: 0.014798477447341331, Train_acc 0.99609375\n",
      "\n",
      "Epoch 94. Loss: 0.01625201101420264, Train_acc 0.9959239130434783\n",
      "\n",
      "Epoch 94. Loss: 0.015168084208902184, Train_acc 0.99609375\n",
      "\n",
      "Epoch 94. Loss: 0.01858035676604789, Train_acc 0.995625\n",
      "\n",
      "Epoch 94. Loss: 0.01762956571587576, Train_acc 0.9954927884615384\n",
      "\n",
      "Epoch 94. Loss: 0.01615297672644544, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 94. Loss: 0.017800987161653833, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 94. Loss: 0.01642761806171322, Train_acc 0.9956896551724138\n",
      "\n",
      "Epoch 94. Loss: 0.015115016185122884, Train_acc 0.9958333333333333\n",
      "\n",
      "Epoch 94. Loss: 0.013975212065096042, Train_acc 0.9959677419354839\n",
      "\n",
      "Epoch 94. Loss: 0.012608045868535273, Train_acc 0.99609375\n",
      "\n",
      "Epoch 94. Loss: 0.011399327708558232, Train_acc 0.9962121212121212\n",
      "\n",
      "Epoch 94. Loss: 0.010328975112452126, Train_acc 0.9963235294117647\n",
      "\n",
      "Epoch 94. Loss: 0.00938261777122082, Train_acc 0.9964285714285714\n",
      "\n",
      "Epoch 94. Loss: 0.0087289765548044, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 94. Loss: 0.009904005273103735, Train_acc 0.996410472972973\n",
      "\n",
      "Epoch 94. Loss: 0.013648671487498303, Train_acc 0.9962993421052632\n",
      "\n",
      "Epoch 94. Loss: 0.012461639697520899, Train_acc 0.9963942307692307\n",
      "\n",
      "Epoch 94. Loss: 0.011579922041820557, Train_acc 0.996484375\n",
      "\n",
      "Epoch 94. Loss: 0.010570813066760068, Train_acc 0.9965701219512195\n",
      "\n",
      "Epoch 94. Loss: 0.010253331896960167, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 94. Loss: 0.009291171586427328, Train_acc 0.9967296511627907\n",
      "\n",
      "Epoch 94. Loss: 0.008538372231346283, Train_acc 0.9968039772727273\n",
      "\n",
      "Epoch 94. Loss: 0.007792163743925315, Train_acc 0.996875\n",
      "\n",
      "Epoch 94. Loss: 0.007288767770098647, Train_acc 0.9969429347826086\n",
      "\n",
      "Epoch 94. Loss: 0.0069888247830423725, Train_acc 0.9970079787234043\n",
      "\n",
      "Epoch 94. Loss: 0.007398036609538169, Train_acc 0.9969075520833334\n",
      "\n",
      "Epoch 94. Loss: 0.00709181268776754, Train_acc 0.9969706632653061\n",
      "\n",
      "Epoch 94. Loss: 0.00681901136575907, Train_acc 0.99703125\n",
      "\n",
      "Epoch 94. Loss: 0.006536068703580823, Train_acc 0.9970894607843137\n",
      "\n",
      "Epoch 94. Loss: 0.006049915518066818, Train_acc 0.9971454326923077\n",
      "\n",
      "Epoch 94. Loss: 0.005863205335171403, Train_acc 0.9971992924528302\n",
      "\n",
      "Epoch 94. Loss: 0.005735848017005368, Train_acc 0.9972511574074074\n",
      "\n",
      "Epoch 94. Loss: 0.0052472187283164945, Train_acc 0.9973011363636364\n",
      "\n",
      "Epoch 94. Loss: 0.004852874448935093, Train_acc 0.9973493303571429\n",
      "\n",
      "Epoch 94. Loss: 0.005809236537849816, Train_acc 0.9972587719298246\n",
      "\n",
      "Epoch 94. Loss: 0.00582936365397505, Train_acc 0.9973060344827587\n",
      "\n",
      "Epoch 94. Loss: 0.0063261308766162285, Train_acc 0.997219279661017\n",
      "\n",
      "Epoch 94. Loss: 0.005785436544742962, Train_acc 0.997265625\n",
      "\n",
      "Epoch 94. Loss: 0.005217897214456191, Train_acc 0.9973104508196722\n",
      "\n",
      "Epoch 94. Loss: 0.0063037401300344974, Train_acc 0.9972278225806451\n",
      "\n",
      "Epoch 94. Loss: 0.006139355695546339, Train_acc 0.9972718253968254\n",
      "\n",
      "Epoch 94. Loss: 0.005581987890832725, Train_acc 0.997314453125\n",
      "\n",
      "Epoch 94. Loss: 0.005099339805081282, Train_acc 0.9973557692307692\n",
      "\n",
      "Epoch 94. Loss: 0.00478333291239422, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 94. Loss: 0.004535473809147312, Train_acc 0.9974347014925373\n",
      "\n",
      "Epoch 94. Loss: 0.004189850614391507, Train_acc 0.9974724264705882\n",
      "\n",
      "Epoch 94. Loss: 0.0038249042880589435, Train_acc 0.9975090579710145\n",
      "\n",
      "Epoch 94. Loss: 0.0053394859062482125, Train_acc 0.9974330357142858\n",
      "\n",
      "Epoch 94. Loss: 0.004849686353772436, Train_acc 0.9974691901408451\n",
      "\n",
      "Epoch 94. Loss: 0.004673703819694716, Train_acc 0.9975043402777778\n",
      "\n",
      "Epoch 94. Loss: 0.004342088825325756, Train_acc 0.9975385273972602\n",
      "\n",
      "Epoch 94. Loss: 0.00398576451721393, Train_acc 0.9975717905405406\n",
      "\n",
      "Epoch 94. Loss: 0.005235347018086341, Train_acc 0.9975\n",
      "\n",
      "Epoch 94. Loss: 0.004723509723449303, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 94. Loss: 0.00478051263049652, Train_acc 0.997564935064935\n",
      "\n",
      "Epoch 94. Loss: 0.0043781817693933234, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 94. Loss: 0.004358474156805073, Train_acc 0.997626582278481\n",
      "\n",
      "Epoch 94. Loss: 0.00398149115907612, Train_acc 0.99765625\n",
      "\n",
      "Epoch 94. Loss: 0.0036385933602672443, Train_acc 0.9976851851851852\n",
      "\n",
      "Epoch 94. Loss: 0.0032849384834900274, Train_acc 0.9977134146341463\n",
      "\n",
      "Epoch 94. Loss: 0.0031153591164307095, Train_acc 0.9977409638554217\n",
      "\n",
      "Epoch 94. Loss: 0.002826572958922204, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 94. Loss: 0.0031193701029978544, Train_acc 0.9977941176470588\n",
      "\n",
      "Epoch 94. Loss: 0.006882524052366229, Train_acc 0.9977289244186046\n",
      "\n",
      "Epoch 94. Loss: 0.0062045965889612475, Train_acc 0.9977550287356322\n",
      "\n",
      "Epoch 94. Loss: 0.005645133564485131, Train_acc 0.9977805397727273\n",
      "\n",
      "Epoch 94. Loss: 0.008998741590630726, Train_acc 0.9977176966292135\n",
      "\n",
      "Epoch 94. Loss: 0.008583848493458375, Train_acc 0.9977430555555555\n",
      "\n",
      "Epoch 94. Loss: 0.008020940771768879, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 94. Loss: 0.0072743976821914086, Train_acc 0.9977921195652174\n",
      "\n",
      "Epoch 94. Loss: 0.00684945018235577, Train_acc 0.9978158602150538\n",
      "\n",
      "Epoch 94. Loss: 0.0063227291628530575, Train_acc 0.9978390957446809\n",
      "\n",
      "Epoch 94. Loss: 0.0069177644975314395, Train_acc 0.9977796052631579\n",
      "\n",
      "Epoch 94. Loss: 0.006393106153815675, Train_acc 0.997802734375\n",
      "\n",
      "Epoch 94. Loss: 0.007532294761725981, Train_acc 0.9977448453608248\n",
      "\n",
      "Epoch 94. Loss: 0.0070738461797360055, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 94. Loss: 0.006454760255061699, Train_acc 0.9977904040404041\n",
      "\n",
      "Epoch 94. Loss: 0.0059110934797463825, Train_acc 0.9978125\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 94 Batch 100] Loss: 0.006205243678111256 Training: accuracy=0.997757\n",
      "Epoch 94. Loss: 0.006205243678111256, Train_acc 0.997756806930693\n",
      "\n",
      "Epoch 94. Loss: 0.005719418135722806, Train_acc 0.9977787990196079\n",
      "\n",
      "Epoch 94. Loss: 0.005196690369763148, Train_acc 0.9978003640776699\n",
      "\n",
      "Epoch 94. Loss: 0.004723931093354193, Train_acc 0.9978215144230769\n",
      "\n",
      "Epoch 94. Loss: 0.004319244349389897, Train_acc 0.9978422619047619\n",
      "\n",
      "Epoch 94. Loss: 0.00438138868232634, Train_acc 0.9978626179245284\n",
      "\n",
      "Epoch 94. Loss: 0.004092243020769802, Train_acc 0.997882593457944\n",
      "\n",
      "Epoch 94. Loss: 0.003758550172751186, Train_acc 0.9979021990740741\n",
      "\n",
      "Epoch 94. Loss: 0.0036538264400109988, Train_acc 0.9979214449541285\n",
      "\n",
      "Epoch 94. Loss: 0.0036331044646437773, Train_acc 0.9979403409090909\n",
      "\n",
      "Epoch 94. Loss: 0.0038794420596065353, Train_acc 0.9979588963963963\n",
      "\n",
      "Epoch 94. Loss: 0.004467209963003001, Train_acc 0.9979073660714286\n",
      "\n",
      "Epoch 94. Loss: 0.004097082623261244, Train_acc 0.9979258849557522\n",
      "\n",
      "Epoch 94. Loss: 0.0041745894328517, Train_acc 0.9979440789473685\n",
      "\n",
      "Epoch 94. Loss: 0.0037916986136680274, Train_acc 0.9979619565217391\n",
      "\n",
      "Epoch 94. Loss: 0.0034473200591265797, Train_acc 0.997979525862069\n",
      "\n",
      "Epoch 94. Loss: 0.0033979072285616075, Train_acc 0.9979967948717948\n",
      "\n",
      "Epoch 94. Loss: 0.003134602833158032, Train_acc 0.9980137711864406\n",
      "\n",
      "Epoch 94. Loss: 0.002905108974996587, Train_acc 0.9980304621848739\n",
      "\n",
      "Epoch 94. Loss: 0.002761554551551533, Train_acc 0.998046875\n",
      "\n",
      "Epoch 94. Loss: 0.0024998392107152385, Train_acc 0.9980630165289256\n",
      "\n",
      "Epoch 94. Loss: 0.005219483862107704, Train_acc 0.9980148565573771\n",
      "\n",
      "Epoch 94. Loss: 0.004926295867370704, Train_acc 0.9980309959349594\n",
      "\n",
      "Epoch 94. Loss: 0.0045228723498758425, Train_acc 0.998046875\n",
      "\n",
      "Epoch 94. Loss: 0.004328135644092568, Train_acc 0.9980625\n",
      "\n",
      "Epoch 94. Loss: 0.0039860714610262145, Train_acc 0.998077876984127\n",
      "\n",
      "Epoch 94. Loss: 0.004464211107269832, Train_acc 0.9980314960629921\n",
      "\n",
      "Epoch 94. Loss: 0.004282860489875891, Train_acc 0.998046875\n",
      "\n",
      "Epoch 94. Loss: 0.004219789468593137, Train_acc 0.998062015503876\n",
      "\n",
      "Epoch 94. Loss: 0.004057592662808362, Train_acc 0.9980769230769231\n",
      "\n",
      "Epoch 94. Loss: 0.004236298382404801, Train_acc 0.9980916030534351\n",
      "\n",
      "Epoch 94. Loss: 0.0043010856275618285, Train_acc 0.9981060606060606\n",
      "\n",
      "Epoch 94. Loss: 0.0040788493344807815, Train_acc 0.9981203007518797\n",
      "\n",
      "Epoch 94. Loss: 0.003744790143616425, Train_acc 0.9981343283582089\n",
      "\n",
      "Epoch 94. Loss: 0.0038213422236717588, Train_acc 0.9981481481481481\n",
      "\n",
      "Epoch 94. Loss: 0.0034674876782215917, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 94. Loss: 0.003162233283398728, Train_acc 0.9981751824817519\n",
      "\n",
      "Epoch 94. Loss: 0.003379592178638143, Train_acc 0.9981884057971014\n",
      "\n",
      "Epoch 94. Loss: 0.0030570216591496472, Train_acc 0.9982014388489209\n",
      "\n",
      "Epoch 94. Loss: 0.008203716586411525, Train_acc 0.998046875\n",
      "\n",
      "Epoch 94. Loss: 0.007389389372078291, Train_acc 0.9980607269503546\n",
      "\n",
      "Epoch 94. Loss: 0.006690965149653519, Train_acc 0.9980743838028169\n",
      "\n",
      "Epoch 94. Loss: 0.006040978537184151, Train_acc 0.9980878496503497\n",
      "\n",
      "Epoch 94. Loss: 0.005609636573991613, Train_acc 0.9981011284722222\n",
      "\n",
      "Epoch 94. Loss: 0.005259604627491328, Train_acc 0.998114224137931\n",
      "\n",
      "Epoch 94. Loss: 0.005379294994862043, Train_acc 0.998127140410959\n",
      "\n",
      "Epoch 94. Loss: 0.005201396548799721, Train_acc 0.9981398809523809\n",
      "\n",
      "Epoch 94. Loss: 0.0046994131642998805, Train_acc 0.9981524493243243\n",
      "\n",
      "Epoch 94. Loss: 0.005548369713582535, Train_acc 0.9981124161073825\n",
      "\n",
      "Epoch 94. Loss: 0.010469506080113, Train_acc 0.9980208333333334\n",
      "\n",
      "Epoch 94. Loss: 0.00946926716073012, Train_acc 0.9980339403973509\n",
      "\n",
      "Epoch 94. Loss: 0.008534393704363699, Train_acc 0.998046875\n",
      "\n",
      "Epoch 94. Loss: 0.007687081868943605, Train_acc 0.9980596405228758\n",
      "\n",
      "Epoch 94. Loss: 0.007013825642855048, Train_acc 0.9980722402597403\n",
      "\n",
      "Epoch 94. Loss: 0.006393490738775057, Train_acc 0.9980846774193548\n",
      "\n",
      "Epoch 94. Loss: 0.007636651738380541, Train_acc 0.9979967948717948\n",
      "\n",
      "Epoch 94. Loss: 0.009135040575768187, Train_acc 0.9979100318471338\n",
      "\n",
      "Epoch 94. Loss: 0.008425963802379937, Train_acc 0.9979232594936709\n",
      "\n",
      "Epoch 94. Loss: 0.008668178941973363, Train_acc 0.9978871855345912\n",
      "\n",
      "Epoch 94. Loss: 0.008066027393677814, Train_acc 0.997900390625\n",
      "\n",
      "Epoch 94. Loss: 0.007314928668327093, Train_acc 0.9979134316770186\n",
      "\n",
      "Epoch 94. Loss: 0.00661548206413489, Train_acc 0.9979263117283951\n",
      "\n",
      "Epoch 94. Loss: 0.006301968568344724, Train_acc 0.9979390337423313\n",
      "\n",
      "Epoch 94. Loss: 0.005697211384264398, Train_acc 0.9979516006097561\n",
      "\n",
      "Epoch 94. Loss: 0.0067558630640695404, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 94. Loss: 0.006798042781834893, Train_acc 0.9979292168674698\n",
      "\n",
      "Epoch 94. Loss: 0.006446581376323186, Train_acc 0.9979416167664671\n",
      "\n",
      "Epoch 94. Loss: 0.005920725971013233, Train_acc 0.9979538690476191\n",
      "\n",
      "Epoch 94. Loss: 0.005340400547178396, Train_acc 0.997965976331361\n",
      "\n",
      "Epoch 94. Loss: 0.005032945174701639, Train_acc 0.9979779411764705\n",
      "\n",
      "Epoch 94. Loss: 0.0045487658784524754, Train_acc 0.9979897660818714\n",
      "\n",
      "Epoch 94. Loss: 0.004842965075886502, Train_acc 0.9979560319767442\n",
      "\n",
      "Epoch 94. Loss: 0.004370282386357993, Train_acc 0.9979678468208093\n",
      "\n",
      "Epoch 94. Loss: 0.004463118205620715, Train_acc 0.997979525862069\n",
      "\n",
      "Epoch 94. Loss: 0.004312765728261056, Train_acc 0.9979910714285715\n",
      "\n",
      "Epoch 94. Loss: 0.004351951969408377, Train_acc 0.9980024857954546\n",
      "\n",
      "Epoch 94. Loss: 0.003980383613178179, Train_acc 0.9980137711864406\n",
      "\n",
      "Epoch 94. Loss: 0.003593897481849681, Train_acc 0.9980249297752809\n",
      "\n",
      "Epoch 94. Loss: 0.0033573713467337702, Train_acc 0.9980359636871509\n",
      "\n",
      "Epoch 94. Loss: 0.0030424738847124664, Train_acc 0.998046875\n",
      "\n",
      "Epoch 94. Loss: 0.0027551896696436933, Train_acc 0.9980576657458563\n",
      "\n",
      "Epoch 94. Loss: 0.0024858405764929567, Train_acc 0.9980683379120879\n",
      "\n",
      "Epoch 94. Loss: 0.0023104929321436985, Train_acc 0.9980788934426229\n",
      "\n",
      "Epoch 94. Loss: 0.0021899428621578727, Train_acc 0.9980893342391305\n",
      "\n",
      "Epoch 94. Loss: 0.0033064714809341892, Train_acc 0.9980574324324324\n",
      "\n",
      "Epoch 94. Loss: 0.0033841828322485386, Train_acc 0.998067876344086\n",
      "\n",
      "Epoch 94. Loss: 0.003078751019638245, Train_acc 0.9980782085561497\n",
      "\n",
      "Epoch 94. Loss: 0.0027810602676322737, Train_acc 0.9980884308510638\n",
      "\n",
      "Epoch 94. Loss: 0.0025995153253704916, Train_acc 0.998098544973545\n",
      "\n",
      "Epoch 94. Loss: 0.0024753396928136598, Train_acc 0.9981085526315789\n",
      "\n",
      "Epoch 94. Loss: 0.002366731263327603, Train_acc 0.9981184554973822\n",
      "\n",
      "Epoch 94. Loss: 0.002204876570490081, Train_acc 0.9981282552083334\n",
      "\n",
      "Epoch 94. Loss: 0.0020604063432604035, Train_acc 0.9981379533678757\n",
      "\n",
      "Epoch 94. Loss: 0.002066843741270002, Train_acc 0.9981475515463918\n",
      "\n",
      "Epoch 94. Loss: 0.0038882960675347715, Train_acc 0.9981169871794872\n",
      "\n",
      "Epoch 94. Loss: 0.003499581497070411, Train_acc 0.99812\n",
      "\n",
      "Epoch 95. Loss: 0.0033251767679219417, Train_acc 1.0\n",
      "\n",
      "Epoch 95. Loss: 0.0031215783382019377, Train_acc 1.0\n",
      "\n",
      "Epoch 95. Loss: 0.0028107565477330735, Train_acc 1.0\n",
      "\n",
      "Epoch 95. Loss: 0.002531712042011384, Train_acc 1.0\n",
      "\n",
      "Epoch 95. Loss: 0.002280188750168995, Train_acc 1.0\n",
      "\n",
      "Epoch 95. Loss: 0.0020554090085182462, Train_acc 1.0\n",
      "\n",
      "Epoch 95. Loss: 0.001869405060853038, Train_acc 1.0\n",
      "\n",
      "Epoch 95. Loss: 0.0017060918737916788, Train_acc 1.0\n",
      "\n",
      "Epoch 95. Loss: 0.0015765628071306177, Train_acc 1.0\n",
      "\n",
      "Epoch 95. Loss: 0.0014933532050448383, Train_acc 1.0\n",
      "\n",
      "Epoch 95. Loss: 0.0019737633549002757, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 95. Loss: 0.0018292463334291088, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 95. Loss: 0.0017189161352732546, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 95. Loss: 0.0015659052534049392, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 95. Loss: 0.0014274069772935302, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 95. Loss: 0.0013004961672709635, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 95. Loss: 0.001172423540277388, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 95. Loss: 0.0011542001474408267, Train_acc 0.9995659722222222\n",
      "\n",
      "Epoch 95. Loss: 0.0010888967657617888, Train_acc 0.9995888157894737\n",
      "\n",
      "Epoch 95. Loss: 0.0009926758978167434, Train_acc 0.999609375\n",
      "\n",
      "Epoch 95. Loss: 0.0008973074049538271, Train_acc 0.9996279761904762\n",
      "\n",
      "Epoch 95. Loss: 0.000854395618164396, Train_acc 0.9996448863636364\n",
      "\n",
      "Epoch 95. Loss: 0.001309908021724691, Train_acc 0.9996603260869565\n",
      "\n",
      "Epoch 95. Loss: 0.0011906033460791327, Train_acc 0.9996744791666666\n",
      "\n",
      "Epoch 95. Loss: 0.002468725151970573, Train_acc 0.999375\n",
      "\n",
      "Epoch 95. Loss: 0.0022272686733569988, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 95. Loss: 0.002047135139658641, Train_acc 0.9994212962962963\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95. Loss: 0.0018459792822933824, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 95. Loss: 0.0016634363706213228, Train_acc 0.9994612068965517\n",
      "\n",
      "Epoch 95. Loss: 0.0015062319802448538, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 95. Loss: 0.00142872259854499, Train_acc 0.9994959677419355\n",
      "\n",
      "Epoch 95. Loss: 0.0023442834504475312, Train_acc 0.999267578125\n",
      "\n",
      "Epoch 95. Loss: 0.0021364575023771182, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 95. Loss: 0.0019343537652290446, Train_acc 0.9993106617647058\n",
      "\n",
      "Epoch 95. Loss: 0.0021358215586510226, Train_acc 0.9993303571428571\n",
      "\n",
      "Epoch 95. Loss: 0.004598295541957044, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 95. Loss: 0.004239022318051031, Train_acc 0.9991554054054054\n",
      "\n",
      "Epoch 95. Loss: 0.003889838664498869, Train_acc 0.9991776315789473\n",
      "\n",
      "Epoch 95. Loss: 0.0035296371505048737, Train_acc 0.999198717948718\n",
      "\n",
      "Epoch 95. Loss: 0.0032158258086649135, Train_acc 0.99921875\n",
      "\n",
      "Epoch 95. Loss: 0.004595484959442099, Train_acc 0.999047256097561\n",
      "\n",
      "Epoch 95. Loss: 0.004188315215068248, Train_acc 0.9990699404761905\n",
      "\n",
      "Epoch 95. Loss: 0.003878242891899216, Train_acc 0.9990915697674418\n",
      "\n",
      "Epoch 95. Loss: 0.003790539258156539, Train_acc 0.9991122159090909\n",
      "\n",
      "Epoch 95. Loss: 0.0034923492367816603, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 95. Loss: 0.00317783367525996, Train_acc 0.9991508152173914\n",
      "\n",
      "Epoch 95. Loss: 0.002863774917730389, Train_acc 0.9991688829787234\n",
      "\n",
      "Epoch 95. Loss: 0.002677932300903229, Train_acc 0.9991861979166666\n",
      "\n",
      "Epoch 95. Loss: 0.002721734039474572, Train_acc 0.9992028061224489\n",
      "\n",
      "Epoch 95. Loss: 0.0025255794099434126, Train_acc 0.99921875\n",
      "\n",
      "Epoch 95. Loss: 0.0023456523188487956, Train_acc 0.999234068627451\n",
      "\n",
      "Epoch 95. Loss: 0.002217411458845699, Train_acc 0.9992487980769231\n",
      "\n",
      "Epoch 95. Loss: 0.0020041237686274425, Train_acc 0.9992629716981132\n",
      "\n",
      "Epoch 95. Loss: 0.0018834879188919494, Train_acc 0.9992766203703703\n",
      "\n",
      "Epoch 95. Loss: 0.0019009133364648607, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 95. Loss: 0.003991994576384812, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 95. Loss: 0.0036044320023197046, Train_acc 0.9990405701754386\n",
      "\n",
      "Epoch 95. Loss: 0.003306892843348215, Train_acc 0.9990571120689655\n",
      "\n",
      "Epoch 95. Loss: 0.0029869370924311997, Train_acc 0.999073093220339\n",
      "\n",
      "Epoch 95. Loss: 0.002716693139979895, Train_acc 0.9990885416666667\n",
      "\n",
      "Epoch 95. Loss: 0.0024484832360544425, Train_acc 0.9991034836065574\n",
      "\n",
      "Epoch 95. Loss: 0.0023124359737365205, Train_acc 0.9991179435483871\n",
      "\n",
      "Epoch 95. Loss: 0.0021065947583790504, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 95. Loss: 0.0019119000650469071, Train_acc 0.9991455078125\n",
      "\n",
      "Epoch 95. Loss: 0.0017480272310406587, Train_acc 0.9991586538461539\n",
      "\n",
      "Epoch 95. Loss: 0.0020953117895064315, Train_acc 0.9991714015151515\n",
      "\n",
      "Epoch 95. Loss: 0.0020394454826060736, Train_acc 0.9991837686567164\n",
      "\n",
      "Epoch 95. Loss: 0.0018523533938664993, Train_acc 0.9991957720588235\n",
      "\n",
      "Epoch 95. Loss: 0.0018260030594100477, Train_acc 0.9992074275362319\n",
      "\n",
      "Epoch 95. Loss: 0.003655835120078617, Train_acc 0.9991071428571429\n",
      "\n",
      "Epoch 95. Loss: 0.004668353091058159, Train_acc 0.9990096830985915\n",
      "\n",
      "Epoch 95. Loss: 0.004276149002147785, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 95. Loss: 0.0038539314713196353, Train_acc 0.9990368150684932\n",
      "\n",
      "Epoch 95. Loss: 0.0034780977654291076, Train_acc 0.999049831081081\n",
      "\n",
      "Epoch 95. Loss: 0.0034035253895744275, Train_acc 0.9990625\n",
      "\n",
      "Epoch 95. Loss: 0.0030665435751335564, Train_acc 0.9990748355263158\n",
      "\n",
      "Epoch 95. Loss: 0.002812073660376898, Train_acc 0.9990868506493507\n",
      "\n",
      "Epoch 95. Loss: 0.009642419397070914, Train_acc 0.9989983974358975\n",
      "\n",
      "Epoch 95. Loss: 0.008818016531472572, Train_acc 0.9990110759493671\n",
      "\n",
      "Epoch 95. Loss: 0.00818713923367575, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 95. Loss: 0.007381718269500943, Train_acc 0.9990354938271605\n",
      "\n",
      "Epoch 95. Loss: 0.008658922347289752, Train_acc 0.9988567073170732\n",
      "\n",
      "Epoch 95. Loss: 0.007861659523377133, Train_acc 0.9988704819277109\n",
      "\n",
      "Epoch 95. Loss: 0.007368137941386682, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 95. Loss: 0.007060119868629916, Train_acc 0.9988970588235294\n",
      "\n",
      "Epoch 95. Loss: 0.006438392883270228, Train_acc 0.9989098837209303\n",
      "\n",
      "Epoch 95. Loss: 0.005808166560938185, Train_acc 0.9989224137931034\n",
      "\n",
      "Epoch 95. Loss: 0.005228308285795854, Train_acc 0.9989346590909091\n",
      "\n",
      "Epoch 95. Loss: 0.00513379480475772, Train_acc 0.9989466292134831\n",
      "\n",
      "Epoch 95. Loss: 0.0046327806425346535, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 95. Loss: 0.0042274367679621516, Train_acc 0.9989697802197802\n",
      "\n",
      "Epoch 95. Loss: 0.0048866342748223905, Train_acc 0.9988960597826086\n",
      "\n",
      "Epoch 95. Loss: 0.004924922473283335, Train_acc 0.9989079301075269\n",
      "\n",
      "Epoch 95. Loss: 0.004906601892383448, Train_acc 0.9989195478723404\n",
      "\n",
      "Epoch 95. Loss: 0.004779218136344747, Train_acc 0.9989309210526316\n",
      "\n",
      "Epoch 95. Loss: 0.004339738885510173, Train_acc 0.9989420572916666\n",
      "\n",
      "Epoch 95. Loss: 0.003982612345787025, Train_acc 0.9989529639175257\n",
      "\n",
      "Epoch 95. Loss: 0.0036616788827863065, Train_acc 0.9989636479591837\n",
      "\n",
      "Epoch 95. Loss: 0.003298191348517175, Train_acc 0.9989741161616161\n",
      "\n",
      "Epoch 95. Loss: 0.0029740145554500086, Train_acc 0.998984375\n",
      "\n",
      "[Epoch 95 Batch 100] Loss: 0.002678625787305573 Training: accuracy=0.998994\n",
      "Epoch 95. Loss: 0.002678625787305573, Train_acc 0.9989944306930693\n",
      "\n",
      "Epoch 95. Loss: 0.00254340941068477, Train_acc 0.9990042892156863\n",
      "\n",
      "Epoch 95. Loss: 0.0023151076579947835, Train_acc 0.9990139563106796\n",
      "\n",
      "Epoch 95. Loss: 0.0022204466303871184, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 95. Loss: 0.0028777125976103047, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 95. Loss: 0.0026105784420206025, Train_acc 0.9989681603773585\n",
      "\n",
      "Epoch 95. Loss: 0.0023522511268317487, Train_acc 0.9989778037383178\n",
      "\n",
      "Epoch 95. Loss: 0.0021222647745713728, Train_acc 0.9989872685185185\n",
      "\n",
      "Epoch 95. Loss: 0.0020352597744700434, Train_acc 0.9989965596330275\n",
      "\n",
      "Epoch 95. Loss: 0.0018415661266927735, Train_acc 0.9990056818181818\n",
      "\n",
      "Epoch 95. Loss: 0.0017691336243437067, Train_acc 0.9990146396396397\n",
      "\n",
      "Epoch 95. Loss: 0.0033133982571142617, Train_acc 0.9989536830357143\n",
      "\n",
      "Epoch 95. Loss: 0.0030038647528589325, Train_acc 0.9989629424778761\n",
      "\n",
      "Epoch 95. Loss: 0.008036282003769329, Train_acc 0.9989035087719298\n",
      "\n",
      "Epoch 95. Loss: 0.0072382068946428724, Train_acc 0.9989130434782608\n",
      "\n",
      "Epoch 95. Loss: 0.0065158658371887454, Train_acc 0.9989224137931034\n",
      "\n",
      "Epoch 95. Loss: 0.0059882627237272425, Train_acc 0.9989316239316239\n",
      "\n",
      "Epoch 95. Loss: 0.005533686990951642, Train_acc 0.9989406779661016\n",
      "\n",
      "Epoch 95. Loss: 0.005238488639517258, Train_acc 0.9989495798319328\n",
      "\n",
      "Epoch 95. Loss: 0.004778425598860425, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 95. Loss: 0.004436835787754336, Train_acc 0.9989669421487604\n",
      "\n",
      "Epoch 95. Loss: 0.005041196603680622, Train_acc 0.9989113729508197\n",
      "\n",
      "Epoch 95. Loss: 0.006074561246429359, Train_acc 0.9988567073170732\n",
      "\n",
      "Epoch 95. Loss: 0.00567240694115562, Train_acc 0.9988659274193549\n",
      "\n",
      "Epoch 95. Loss: 0.005328158003203596, Train_acc 0.998875\n",
      "\n",
      "Epoch 95. Loss: 0.004871005864001833, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 95. Loss: 0.006626623542062213, Train_acc 0.9988312007874016\n",
      "\n",
      "Epoch 95. Loss: 0.006461464999349508, Train_acc 0.99884033203125\n",
      "\n",
      "Epoch 95. Loss: 0.0069736249676927275, Train_acc 0.9987887596899225\n",
      "\n",
      "Epoch 95. Loss: 0.006286513066292599, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 95. Loss: 0.005662515936909605, Train_acc 0.9988072519083969\n",
      "\n",
      "Epoch 95. Loss: 0.006499421756224474, Train_acc 0.9987571022727273\n",
      "\n",
      "Epoch 95. Loss: 0.00590760846908798, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 95. Loss: 0.006117089710914287, Train_acc 0.9987173507462687\n",
      "\n",
      "Epoch 95. Loss: 0.005582092173762494, Train_acc 0.9987268518518518\n",
      "\n",
      "Epoch 95. Loss: 0.005032516981675456, Train_acc 0.9987362132352942\n",
      "\n",
      "Epoch 95. Loss: 0.007343612952990143, Train_acc 0.9986884124087592\n",
      "\n",
      "Epoch 95. Loss: 0.006620616281478942, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 95. Loss: 0.005971635262245654, Train_acc 0.9987072841726619\n",
      "\n",
      "Epoch 95. Loss: 0.005638265036858368, Train_acc 0.9987165178571429\n",
      "\n",
      "Epoch 95. Loss: 0.005281420621447785, Train_acc 0.9987256205673759\n",
      "\n",
      "Epoch 95. Loss: 0.00794429591879817, Train_acc 0.9986795774647887\n",
      "\n",
      "Epoch 95. Loss: 0.018258015169968354, Train_acc 0.9985249125874126\n",
      "\n",
      "Epoch 95. Loss: 0.01819404052579714, Train_acc 0.9984809027777778\n",
      "\n",
      "Epoch 95. Loss: 0.016443783018355636, Train_acc 0.9984913793103448\n",
      "\n",
      "Epoch 95. Loss: 0.018545582717685465, Train_acc 0.998394691780822\n",
      "\n",
      "Epoch 95. Loss: 0.0169089334392803, Train_acc 0.998405612244898\n",
      "\n",
      "Epoch 95. Loss: 0.015330576144334564, Train_acc 0.9984163851351351\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95. Loss: 0.013993600022950968, Train_acc 0.9984270134228188\n",
      "\n",
      "Epoch 95. Loss: 0.012682839868751199, Train_acc 0.9984375\n",
      "\n",
      "Epoch 95. Loss: 0.01603040588344964, Train_acc 0.9983443708609272\n",
      "\n",
      "Epoch 95. Loss: 0.01494682405840605, Train_acc 0.9983552631578947\n",
      "\n",
      "Epoch 95. Loss: 0.013927803435113276, Train_acc 0.9983660130718954\n",
      "\n",
      "Epoch 95. Loss: 0.014740321373808008, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 95. Loss: 0.01334249090513486, Train_acc 0.998336693548387\n",
      "\n",
      "Epoch 95. Loss: 0.012325495080151244, Train_acc 0.9983473557692307\n",
      "\n",
      "Epoch 95. Loss: 0.01468716413914986, Train_acc 0.9982085987261147\n",
      "\n",
      "Epoch 95. Loss: 0.013576587635038743, Train_acc 0.9982199367088608\n",
      "\n",
      "Epoch 95. Loss: 0.012770559800647303, Train_acc 0.9982311320754716\n",
      "\n",
      "Epoch 95. Loss: 0.015786449384375754, Train_acc 0.99814453125\n",
      "\n",
      "Epoch 95. Loss: 0.015554723200217793, Train_acc 0.9981075310559007\n",
      "\n",
      "Epoch 95. Loss: 0.014077878894503484, Train_acc 0.9981192129629629\n",
      "\n",
      "Epoch 95. Loss: 0.013993456518288467, Train_acc 0.9980828220858896\n",
      "\n",
      "Epoch 95. Loss: 0.013004190449985279, Train_acc 0.9980945121951219\n",
      "\n",
      "Epoch 95. Loss: 0.011985460162227523, Train_acc 0.9981060606060606\n",
      "\n",
      "Epoch 95. Loss: 0.011105069537146543, Train_acc 0.9981174698795181\n",
      "\n",
      "Epoch 95. Loss: 0.01014721300072624, Train_acc 0.9981287425149701\n",
      "\n",
      "Epoch 95. Loss: 0.009196954252035055, Train_acc 0.9981398809523809\n",
      "\n",
      "Epoch 95. Loss: 0.0096891898572838, Train_acc 0.9981046597633136\n",
      "\n",
      "Epoch 95. Loss: 0.010446384131347748, Train_acc 0.9980238970588236\n",
      "\n",
      "Epoch 95. Loss: 0.009489365366760816, Train_acc 0.9980354532163743\n",
      "\n",
      "Epoch 95. Loss: 0.008650212203857833, Train_acc 0.998046875\n",
      "\n",
      "Epoch 95. Loss: 0.011059166832623661, Train_acc 0.9979678468208093\n",
      "\n",
      "Epoch 95. Loss: 0.012204237440697357, Train_acc 0.9978897270114943\n",
      "\n",
      "Epoch 95. Loss: 0.012639256150548464, Train_acc 0.9978571428571429\n",
      "\n",
      "Epoch 95. Loss: 0.011632412306763058, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 95. Loss: 0.010563773420411565, Train_acc 0.9978813559322034\n",
      "\n",
      "Epoch 95. Loss: 0.009564652288500116, Train_acc 0.9978932584269663\n",
      "\n",
      "Epoch 95. Loss: 0.008785191713610571, Train_acc 0.9979050279329609\n",
      "\n",
      "Epoch 95. Loss: 0.007948612064156412, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 95. Loss: 0.0072152550978885404, Train_acc 0.9979281767955801\n",
      "\n",
      "Epoch 95. Loss: 0.006668872714498011, Train_acc 0.9979395604395604\n",
      "\n",
      "Epoch 95. Loss: 0.007470359650664063, Train_acc 0.9979081284153005\n",
      "\n",
      "Epoch 95. Loss: 0.007147984846975683, Train_acc 0.9979194972826086\n",
      "\n",
      "Epoch 95. Loss: 0.007010805289041648, Train_acc 0.9979307432432433\n",
      "\n",
      "Epoch 95. Loss: 0.007106386099837705, Train_acc 0.9979418682795699\n",
      "\n",
      "Epoch 95. Loss: 0.010203416995330887, Train_acc 0.9978275401069518\n",
      "\n",
      "Epoch 95. Loss: 0.010769302042237732, Train_acc 0.997797539893617\n",
      "\n",
      "Epoch 95. Loss: 0.011373191528241467, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 95. Loss: 0.01026809252762404, Train_acc 0.9977796052631579\n",
      "\n",
      "Epoch 95. Loss: 0.009780603609653774, Train_acc 0.9977912303664922\n",
      "\n",
      "Epoch 95. Loss: 0.008856849727393654, Train_acc 0.997802734375\n",
      "\n",
      "Epoch 95. Loss: 0.008366927069674254, Train_acc 0.9978141191709845\n",
      "\n",
      "Epoch 95. Loss: 0.00768667213130771, Train_acc 0.9978253865979382\n",
      "\n",
      "Epoch 95. Loss: 0.010104963946420957, Train_acc 0.9977964743589743\n",
      "\n",
      "Epoch 95. Loss: 0.009291283415961872, Train_acc 0.9978\n",
      "\n",
      "Epoch 96. Loss: 0.008676664663590739, Train_acc 1.0\n",
      "\n",
      "Epoch 96. Loss: 0.0083889090622852, Train_acc 1.0\n",
      "\n",
      "Epoch 96. Loss: 0.009966752739732541, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 96. Loss: 0.009874058831022749, Train_acc 0.99609375\n",
      "\n",
      "Epoch 96. Loss: 0.009581772932368431, Train_acc 0.996875\n",
      "\n",
      "Epoch 96. Loss: 0.008730287545825912, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 96. Loss: 0.00831841145283509, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 96. Loss: 0.00770554552556451, Train_acc 0.998046875\n",
      "\n",
      "Epoch 96. Loss: 0.00702550399050229, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 96. Loss: 0.007909059265957294, Train_acc 0.996875\n",
      "\n",
      "Epoch 96. Loss: 0.007176657318014444, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 96. Loss: 0.006489914257643744, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 96. Loss: 0.005951037011430972, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 96. Loss: 0.005366022144384552, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 96. Loss: 0.005098586542943748, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 96. Loss: 0.004663256512021689, Train_acc 0.998046875\n",
      "\n",
      "Epoch 96. Loss: 0.0046254782916030305, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 96. Loss: 0.004214508934345486, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 96. Loss: 0.0038748736115038177, Train_acc 0.9983552631578947\n",
      "\n",
      "Epoch 96. Loss: 0.003719622454090993, Train_acc 0.9984375\n",
      "\n",
      "Epoch 96. Loss: 0.003367504320784767, Train_acc 0.9985119047619048\n",
      "\n",
      "Epoch 96. Loss: 0.0030668693004917216, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 96. Loss: 0.002862868076666842, Train_acc 0.998641304347826\n",
      "\n",
      "Epoch 96. Loss: 0.0026061573411202653, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 96. Loss: 0.0023597610138840204, Train_acc 0.99875\n",
      "\n",
      "Epoch 96. Loss: 0.00213307182837904, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 96. Loss: 0.0019890575771257775, Train_acc 0.9988425925925926\n",
      "\n",
      "Epoch 96. Loss: 0.001974093464495286, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 96. Loss: 0.001808189846884723, Train_acc 0.9989224137931034\n",
      "\n",
      "Epoch 96. Loss: 0.001694025019322573, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 96. Loss: 0.0016062299432085356, Train_acc 0.998991935483871\n",
      "\n",
      "Epoch 96. Loss: 0.001632973660794771, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 96. Loss: 0.0014807935541341186, Train_acc 0.9990530303030303\n",
      "\n",
      "Epoch 96. Loss: 0.001428410637523113, Train_acc 0.9990808823529411\n",
      "\n",
      "Epoch 96. Loss: 0.0013084258246417746, Train_acc 0.9991071428571429\n",
      "\n",
      "Epoch 96. Loss: 0.0011995512616053286, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 96. Loss: 0.0011126111772897151, Train_acc 0.9991554054054054\n",
      "\n",
      "Epoch 96. Loss: 0.0011016247579038717, Train_acc 0.9991776315789473\n",
      "\n",
      "Epoch 96. Loss: 0.00106371496266102, Train_acc 0.999198717948718\n",
      "\n",
      "Epoch 96. Loss: 0.0009594553318280257, Train_acc 0.99921875\n",
      "\n",
      "Epoch 96. Loss: 0.0008776470919737542, Train_acc 0.9992378048780488\n",
      "\n",
      "Epoch 96. Loss: 0.000954250118627935, Train_acc 0.9992559523809523\n",
      "\n",
      "Epoch 96. Loss: 0.0008672722927387783, Train_acc 0.9992732558139535\n",
      "\n",
      "Epoch 96. Loss: 0.0008805090725971367, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 96. Loss: 0.0023699250779050385, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 96. Loss: 0.0021443036171177295, Train_acc 0.9991508152173914\n",
      "\n",
      "Epoch 96. Loss: 0.0019380183676301125, Train_acc 0.9991688829787234\n",
      "\n",
      "Epoch 96. Loss: 0.001757282320111239, Train_acc 0.9991861979166666\n",
      "\n",
      "Epoch 96. Loss: 0.0015860443802218878, Train_acc 0.9992028061224489\n",
      "\n",
      "Epoch 96. Loss: 0.0021021594453490893, Train_acc 0.9990625\n",
      "\n",
      "Epoch 96. Loss: 0.004624204398569804, Train_acc 0.9989276960784313\n",
      "\n",
      "Epoch 96. Loss: 0.004166397874447631, Train_acc 0.9989483173076923\n",
      "\n",
      "Epoch 96. Loss: 0.003756889296716275, Train_acc 0.9989681603773585\n",
      "\n",
      "Epoch 96. Loss: 0.003414207943757055, Train_acc 0.9989872685185185\n",
      "\n",
      "Epoch 96. Loss: 0.003121836195737581, Train_acc 0.9990056818181818\n",
      "\n",
      "Epoch 96. Loss: 0.0028206203983271888, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 96. Loss: 0.0025464060492164436, Train_acc 0.9990405701754386\n",
      "\n",
      "Epoch 96. Loss: 0.00265400608381002, Train_acc 0.9990571120689655\n",
      "\n",
      "Epoch 96. Loss: 0.0027188377920571165, Train_acc 0.999073093220339\n",
      "\n",
      "Epoch 96. Loss: 0.0025143070868246134, Train_acc 0.9990885416666667\n",
      "\n",
      "Epoch 96. Loss: 0.002328555766495753, Train_acc 0.9991034836065574\n",
      "\n",
      "Epoch 96. Loss: 0.0028261567413830953, Train_acc 0.998991935483871\n",
      "\n",
      "Epoch 96. Loss: 0.003634146344812888, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 96. Loss: 0.0035534971696008846, Train_acc 0.9989013671875\n",
      "\n",
      "Epoch 96. Loss: 0.0033066030398192646, Train_acc 0.9989182692307692\n",
      "\n",
      "Epoch 96. Loss: 0.0029827755054144967, Train_acc 0.9989346590909091\n",
      "\n",
      "Epoch 96. Loss: 0.002693690903219073, Train_acc 0.9989505597014925\n",
      "\n",
      "Epoch 96. Loss: 0.0024484764933289864, Train_acc 0.9989659926470589\n",
      "\n",
      "Epoch 96. Loss: 0.004438958740207713, Train_acc 0.9988677536231884\n",
      "\n",
      "Epoch 96. Loss: 0.0040280511441493725, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 96. Loss: 0.004135354733481827, Train_acc 0.998899647887324\n",
      "\n",
      "Epoch 96. Loss: 0.0037630079876158668, Train_acc 0.9989149305555556\n",
      "\n",
      "Epoch 96. Loss: 0.003748579373875919, Train_acc 0.998929794520548\n",
      "\n",
      "Epoch 96. Loss: 0.003404054411927123, Train_acc 0.9989442567567568\n",
      "\n",
      "Epoch 96. Loss: 0.0030822712618341565, Train_acc 0.9989583333333333\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96. Loss: 0.002781534330926491, Train_acc 0.9989720394736842\n",
      "\n",
      "Epoch 96. Loss: 0.002598859331483829, Train_acc 0.9989853896103896\n",
      "\n",
      "Epoch 96. Loss: 0.0024521971126237703, Train_acc 0.9989983974358975\n",
      "\n",
      "Epoch 96. Loss: 0.0071965109002446416, Train_acc 0.9988132911392406\n",
      "\n",
      "Epoch 96. Loss: 0.006571755532797525, Train_acc 0.998828125\n",
      "\n",
      "Epoch 96. Loss: 0.0060221218694013505, Train_acc 0.9988425925925926\n",
      "\n",
      "Epoch 96. Loss: 0.00545257538811878, Train_acc 0.9988567073170732\n",
      "\n",
      "Epoch 96. Loss: 0.005416009266360244, Train_acc 0.9988704819277109\n",
      "\n",
      "Epoch 96. Loss: 0.005110447203383124, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 96. Loss: 0.004786890814038614, Train_acc 0.9988970588235294\n",
      "\n",
      "Epoch 96. Loss: 0.005606570268570631, Train_acc 0.9989098837209303\n",
      "\n",
      "Epoch 96. Loss: 0.005218909716143533, Train_acc 0.9989224137931034\n",
      "\n",
      "Epoch 96. Loss: 0.004754098521417893, Train_acc 0.9989346590909091\n",
      "\n",
      "Epoch 96. Loss: 0.004300801841147856, Train_acc 0.9989466292134831\n",
      "\n",
      "Epoch 96. Loss: 0.004237262375856742, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 96. Loss: 0.00381962129447222, Train_acc 0.9989697802197802\n",
      "\n",
      "Epoch 96. Loss: 0.003465300917992609, Train_acc 0.9989809782608695\n",
      "\n",
      "Epoch 96. Loss: 0.003217416769410328, Train_acc 0.998991935483871\n",
      "\n",
      "Epoch 96. Loss: 0.0029498795156826726, Train_acc 0.9990026595744681\n",
      "\n",
      "Epoch 96. Loss: 0.002694767100572972, Train_acc 0.9990131578947369\n",
      "\n",
      "Epoch 96. Loss: 0.002438555063695622, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 96. Loss: 0.002200487600525633, Train_acc 0.9990335051546392\n",
      "\n",
      "Epoch 96. Loss: 0.001996874463292769, Train_acc 0.9990433673469388\n",
      "\n",
      "Epoch 96. Loss: 0.007627688781976234, Train_acc 0.9989741161616161\n",
      "\n",
      "Epoch 96. Loss: 0.007921816053890763, Train_acc 0.99890625\n",
      "\n",
      "[Epoch 96 Batch 100] Loss: 0.011802999206993204 Training: accuracy=0.998840\n",
      "Epoch 96. Loss: 0.011802999206993204, Train_acc 0.9988397277227723\n",
      "\n",
      "Epoch 96. Loss: 0.01108018942872872, Train_acc 0.9988511029411765\n",
      "\n",
      "Epoch 96. Loss: 0.01011892645780167, Train_acc 0.9988622572815534\n",
      "\n",
      "Epoch 96. Loss: 0.010230859272693881, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 96. Loss: 0.01098764682830747, Train_acc 0.9986607142857142\n",
      "\n",
      "Epoch 96. Loss: 0.010152631906983638, Train_acc 0.9986733490566038\n",
      "\n",
      "Epoch 96. Loss: 0.009701360205174134, Train_acc 0.9986857476635514\n",
      "\n",
      "Epoch 96. Loss: 0.009305297659510952, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 96. Loss: 0.009841000524915381, Train_acc 0.9986381880733946\n",
      "\n",
      "Epoch 96. Loss: 0.012618424434444718, Train_acc 0.9984375\n",
      "\n",
      "Epoch 96. Loss: 0.012803600692583393, Train_acc 0.9983811936936937\n",
      "\n",
      "Epoch 96. Loss: 0.013894737889319603, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 96. Loss: 0.013160662990763733, Train_acc 0.9983407079646017\n",
      "\n",
      "Epoch 96. Loss: 0.012168329494331732, Train_acc 0.9983552631578947\n",
      "\n",
      "Epoch 96. Loss: 0.011803732789726067, Train_acc 0.9983016304347826\n",
      "\n",
      "Epoch 96. Loss: 0.011240099433887906, Train_acc 0.9983162715517241\n",
      "\n",
      "Epoch 96. Loss: 0.01195339279368124, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 96. Loss: 0.011075011410888447, Train_acc 0.9982123940677966\n",
      "\n",
      "Epoch 96. Loss: 0.010139541533154769, Train_acc 0.9982274159663865\n",
      "\n",
      "Epoch 96. Loss: 0.00914942900782919, Train_acc 0.9982421875\n",
      "\n",
      "Epoch 96. Loss: 0.009278234869504833, Train_acc 0.9981921487603306\n",
      "\n",
      "Epoch 96. Loss: 0.008842876878617583, Train_acc 0.9982069672131147\n",
      "\n",
      "Epoch 96. Loss: 0.00840011939792786, Train_acc 0.9982215447154471\n",
      "\n",
      "Epoch 96. Loss: 0.007964612796654886, Train_acc 0.9982358870967742\n",
      "\n",
      "Epoch 96. Loss: 0.007606655903682636, Train_acc 0.99825\n",
      "\n",
      "Epoch 96. Loss: 0.006987901219264144, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 96. Loss: 0.006348666498431987, Train_acc 0.9982775590551181\n",
      "\n",
      "Epoch 96. Loss: 0.007590396209987485, Train_acc 0.9981689453125\n",
      "\n",
      "Epoch 96. Loss: 0.006900046559055508, Train_acc 0.9981831395348837\n",
      "\n",
      "Epoch 96. Loss: 0.006240230858283738, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 96. Loss: 0.006074277663192898, Train_acc 0.9982108778625954\n",
      "\n",
      "Epoch 96. Loss: 0.0054884738813767014, Train_acc 0.9982244318181818\n",
      "\n",
      "Epoch 96. Loss: 0.005005174204222113, Train_acc 0.9982377819548872\n",
      "\n",
      "Epoch 96. Loss: 0.008570783949951902, Train_acc 0.9981926305970149\n",
      "\n",
      "Epoch 96. Loss: 0.007760019394222789, Train_acc 0.9982060185185185\n",
      "\n",
      "Epoch 96. Loss: 0.00748169207085421, Train_acc 0.9982192095588235\n",
      "\n",
      "Epoch 96. Loss: 0.00782523911603615, Train_acc 0.9981751824817519\n",
      "\n",
      "Epoch 96. Loss: 0.007550177881047059, Train_acc 0.9981884057971014\n",
      "\n",
      "Epoch 96. Loss: 0.00680407312355743, Train_acc 0.9982014388489209\n",
      "\n",
      "Epoch 96. Loss: 0.006260745236823464, Train_acc 0.9982142857142857\n",
      "\n",
      "Epoch 96. Loss: 0.005682563187826914, Train_acc 0.99822695035461\n",
      "\n",
      "Epoch 96. Loss: 0.0062526855487965724, Train_acc 0.9981844190140845\n",
      "\n",
      "Epoch 96. Loss: 0.005710706714267792, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 96. Loss: 0.005157561007618207, Train_acc 0.9982096354166666\n",
      "\n",
      "Epoch 96. Loss: 0.004728434809800355, Train_acc 0.9982219827586207\n",
      "\n",
      "Epoch 96. Loss: 0.004310090835770699, Train_acc 0.9982341609589042\n",
      "\n",
      "Epoch 96. Loss: 0.004048110466492831, Train_acc 0.9982461734693877\n",
      "\n",
      "Epoch 96. Loss: 0.0037375853356821026, Train_acc 0.9982580236486487\n",
      "\n",
      "Epoch 96. Loss: 0.005047990126648786, Train_acc 0.9982172818791947\n",
      "\n",
      "Epoch 96. Loss: 0.0070292811035268694, Train_acc 0.9981770833333333\n",
      "\n",
      "Epoch 96. Loss: 0.006388263418021339, Train_acc 0.9981891556291391\n",
      "\n",
      "Epoch 96. Loss: 0.006917724342265014, Train_acc 0.9981496710526315\n",
      "\n",
      "Epoch 96. Loss: 0.007317636309073822, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 96. Loss: 0.008091790175145677, Train_acc 0.9981229707792207\n",
      "\n",
      "Epoch 96. Loss: 0.007515777682771515, Train_acc 0.9981350806451613\n",
      "\n",
      "Epoch 96. Loss: 0.007819136375645009, Train_acc 0.9980969551282052\n",
      "\n",
      "Epoch 96. Loss: 0.0072221413056187695, Train_acc 0.998109076433121\n",
      "\n",
      "Epoch 96. Loss: 0.00902590626926418, Train_acc 0.9980221518987342\n",
      "\n",
      "Epoch 96. Loss: 0.008829057407315337, Train_acc 0.9980345911949685\n",
      "\n",
      "Epoch 96. Loss: 0.00823839156353691, Train_acc 0.998046875\n",
      "\n",
      "Epoch 96. Loss: 0.008423434780754614, Train_acc 0.9980104813664596\n",
      "\n",
      "Epoch 96. Loss: 0.0077926302824628075, Train_acc 0.998022762345679\n",
      "\n",
      "Epoch 96. Loss: 0.010612562064010952, Train_acc 0.9979869631901841\n",
      "\n",
      "Epoch 96. Loss: 0.014089890730690112, Train_acc 0.9979039634146342\n",
      "\n",
      "Epoch 96. Loss: 0.012842378416861132, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 96. Loss: 0.013579098827426167, Train_acc 0.9978821536144579\n",
      "\n",
      "Epoch 96. Loss: 0.01231564916336271, Train_acc 0.9978948353293413\n",
      "\n",
      "Epoch 96. Loss: 0.012481549137059447, Train_acc 0.9978608630952381\n",
      "\n",
      "Epoch 96. Loss: 0.012661141253164646, Train_acc 0.9978272928994083\n",
      "\n",
      "Epoch 96. Loss: 0.011935312499092136, Train_acc 0.9978400735294117\n",
      "\n",
      "Epoch 96. Loss: 0.01137971323123823, Train_acc 0.9978527046783626\n",
      "\n",
      "Epoch 96. Loss: 0.010364727116987113, Train_acc 0.9978651889534884\n",
      "\n",
      "Epoch 96. Loss: 0.009513276675595348, Train_acc 0.9978775289017341\n",
      "\n",
      "Epoch 96. Loss: 0.008964986954707061, Train_acc 0.9978897270114943\n",
      "\n",
      "Epoch 96. Loss: 0.00809758525902408, Train_acc 0.9979017857142857\n",
      "\n",
      "Epoch 96. Loss: 0.007291020764281764, Train_acc 0.9979137073863636\n",
      "\n",
      "Epoch 96. Loss: 0.0066405187508422866, Train_acc 0.9979254943502824\n",
      "\n",
      "Epoch 96. Loss: 0.006146191055189854, Train_acc 0.9979371488764045\n",
      "\n",
      "Epoch 96. Loss: 0.008510976056407053, Train_acc 0.9978613826815642\n",
      "\n",
      "Epoch 96. Loss: 0.008648750706896326, Train_acc 0.9978298611111112\n",
      "\n",
      "Epoch 96. Loss: 0.009365695364223547, Train_acc 0.9977986878453039\n",
      "\n",
      "Epoch 96. Loss: 0.008487107247178221, Train_acc 0.997810782967033\n",
      "\n",
      "Epoch 96. Loss: 0.011925009837804257, Train_acc 0.9977800546448088\n",
      "\n",
      "Epoch 96. Loss: 0.010963407771676497, Train_acc 0.9977921195652174\n",
      "\n",
      "Epoch 96. Loss: 0.009942530898576721, Train_acc 0.997804054054054\n",
      "\n",
      "Epoch 96. Loss: 0.013528724886470209, Train_acc 0.9977318548387096\n",
      "\n",
      "Epoch 96. Loss: 0.013310220243775699, Train_acc 0.9977022058823529\n",
      "\n",
      "Epoch 96. Loss: 0.022082564743379225, Train_acc 0.9976313164893617\n",
      "\n",
      "Epoch 96. Loss: 0.019946882610943812, Train_acc 0.9976438492063492\n",
      "\n",
      "Epoch 96. Loss: 0.018002692813528537, Train_acc 0.99765625\n",
      "\n",
      "Epoch 96. Loss: 0.016837130390721225, Train_acc 0.9976276178010471\n",
      "\n",
      "Epoch 96. Loss: 0.021079712721512614, Train_acc 0.9975992838541666\n",
      "\n",
      "Epoch 96. Loss: 0.02072766057056716, Train_acc 0.997571243523316\n",
      "\n",
      "Epoch 96. Loss: 0.019115806521348932, Train_acc 0.9975837628865979\n",
      "\n",
      "Epoch 96. Loss: 0.020756571428215007, Train_acc 0.9975560897435898\n",
      "\n",
      "Epoch 96. Loss: 0.018697620537456668, Train_acc 0.99756\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97. Loss: 0.020259982591787098, Train_acc 0.984375\n",
      "\n",
      "Epoch 97. Loss: 0.018925929904060765, Train_acc 0.9921875\n",
      "\n",
      "Epoch 97. Loss: 0.01715375649181578, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 97. Loss: 0.01569394609478927, Train_acc 0.99609375\n",
      "\n",
      "Epoch 97. Loss: 0.01472605864984825, Train_acc 0.996875\n",
      "\n",
      "Epoch 97. Loss: 0.014638018205312206, Train_acc 0.99609375\n",
      "\n",
      "Epoch 97. Loss: 0.013774259556797725, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 97. Loss: 0.012518787405163868, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 97. Loss: 0.012238393221441648, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 97. Loss: 0.01176775046100653, Train_acc 0.996875\n",
      "\n",
      "Epoch 97. Loss: 0.011072727534864279, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 97. Loss: 0.010233569092998445, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 97. Loss: 0.009773354213267154, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 97. Loss: 0.0105914678998258, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 97. Loss: 0.011203238978457417, Train_acc 0.9963541666666667\n",
      "\n",
      "Epoch 97. Loss: 0.01021495027690482, Train_acc 0.99658203125\n",
      "\n",
      "Epoch 97. Loss: 0.009451411066720055, Train_acc 0.9967830882352942\n",
      "\n",
      "Epoch 97. Loss: 0.008768006667809934, Train_acc 0.9969618055555556\n",
      "\n",
      "Epoch 97. Loss: 0.00853578911638312, Train_acc 0.9971217105263158\n",
      "\n",
      "Epoch 97. Loss: 0.00795058505385565, Train_acc 0.997265625\n",
      "\n",
      "Epoch 97. Loss: 0.0071870261567735065, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 97. Loss: 0.006602543911187655, Train_acc 0.9975142045454546\n",
      "\n",
      "Epoch 97. Loss: 0.006028147455551525, Train_acc 0.9976222826086957\n",
      "\n",
      "Epoch 97. Loss: 0.005602510077728301, Train_acc 0.9977213541666666\n",
      "\n",
      "Epoch 97. Loss: 0.005402897345698003, Train_acc 0.9978125\n",
      "\n",
      "Epoch 97. Loss: 0.005340036811092011, Train_acc 0.9978966346153846\n",
      "\n",
      "Epoch 97. Loss: 0.0048656117442922395, Train_acc 0.9979745370370371\n",
      "\n",
      "Epoch 97. Loss: 0.004409108266721437, Train_acc 0.998046875\n",
      "\n",
      "Epoch 97. Loss: 0.004078213411635402, Train_acc 0.998114224137931\n",
      "\n",
      "Epoch 97. Loss: 0.004835867021739104, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 97. Loss: 0.004926298241027849, Train_acc 0.9979838709677419\n",
      "\n",
      "Epoch 97. Loss: 0.004574567592237434, Train_acc 0.998046875\n",
      "\n",
      "Epoch 97. Loss: 0.004174760195147507, Train_acc 0.9981060606060606\n",
      "\n",
      "Epoch 97. Loss: 0.003786986642778155, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 97. Loss: 0.0034514637787381444, Train_acc 0.9982142857142857\n",
      "\n",
      "Epoch 97. Loss: 0.0031647284859111576, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 97. Loss: 0.003117393076638043, Train_acc 0.9983108108108109\n",
      "\n",
      "Epoch 97. Loss: 0.0029709246548925284, Train_acc 0.9983552631578947\n",
      "\n",
      "Epoch 97. Loss: 0.005199982088170747, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 97. Loss: 0.004725240661676794, Train_acc 0.9982421875\n",
      "\n",
      "Epoch 97. Loss: 0.004303026536216054, Train_acc 0.9982850609756098\n",
      "\n",
      "Epoch 97. Loss: 0.004077688865871471, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 97. Loss: 0.00377340418984256, Train_acc 0.9983648255813954\n",
      "\n",
      "Epoch 97. Loss: 0.00345969533803101, Train_acc 0.9984019886363636\n",
      "\n",
      "Epoch 97. Loss: 0.0031243167419732006, Train_acc 0.9984375\n",
      "\n",
      "Epoch 97. Loss: 0.0036592366188317885, Train_acc 0.9983016304347826\n",
      "\n",
      "Epoch 97. Loss: 0.004848088660647006, Train_acc 0.9981715425531915\n",
      "\n",
      "Epoch 97. Loss: 0.0043831248642012014, Train_acc 0.9982096354166666\n",
      "\n",
      "Epoch 97. Loss: 0.005823813041538405, Train_acc 0.9980867346938775\n",
      "\n",
      "Epoch 97. Loss: 0.005747890355131395, Train_acc 0.998125\n",
      "\n",
      "Epoch 97. Loss: 0.005548586344033212, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 97. Loss: 0.005094797396564243, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 97. Loss: 0.004678025522313647, Train_acc 0.9982311320754716\n",
      "\n",
      "Epoch 97. Loss: 0.004227658466638855, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 97. Loss: 0.003838598575113399, Train_acc 0.9982954545454545\n",
      "\n",
      "Epoch 97. Loss: 0.003678362236434087, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 97. Loss: 0.0033587974891982134, Train_acc 0.9983552631578947\n",
      "\n",
      "Epoch 97. Loss: 0.0030773995928452154, Train_acc 0.9983836206896551\n",
      "\n",
      "Epoch 97. Loss: 0.0027887324475903354, Train_acc 0.9984110169491526\n",
      "\n",
      "Epoch 97. Loss: 0.002563721848122094, Train_acc 0.9984375\n",
      "\n",
      "Epoch 97. Loss: 0.002717804802663756, Train_acc 0.9984631147540983\n",
      "\n",
      "Epoch 97. Loss: 0.0024680308287305082, Train_acc 0.9984879032258065\n",
      "\n",
      "Epoch 97. Loss: 0.0022279462668929667, Train_acc 0.9985119047619048\n",
      "\n",
      "Epoch 97. Loss: 0.0020645731229324642, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 97. Loss: 0.0021547596992170367, Train_acc 0.9985576923076923\n",
      "\n",
      "Epoch 97. Loss: 0.0019605244760141647, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 97. Loss: 0.001771152555125192, Train_acc 0.9986007462686567\n",
      "\n",
      "Epoch 97. Loss: 0.0016489119025507436, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 97. Loss: 0.0016190060474668918, Train_acc 0.998641304347826\n",
      "\n",
      "Epoch 97. Loss: 0.001559158571368752, Train_acc 0.9986607142857142\n",
      "\n",
      "Epoch 97. Loss: 0.0016715496699270293, Train_acc 0.9986795774647887\n",
      "\n",
      "Epoch 97. Loss: 0.001642514753476383, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 97. Loss: 0.0017513880586346403, Train_acc 0.9987157534246576\n",
      "\n",
      "Epoch 97. Loss: 0.001618676144512519, Train_acc 0.9987331081081081\n",
      "\n",
      "Epoch 97. Loss: 0.0017146346143323407, Train_acc 0.99875\n",
      "\n",
      "Epoch 97. Loss: 0.0038306888271663984, Train_acc 0.9986636513157895\n",
      "\n",
      "Epoch 97. Loss: 0.0046171413060391905, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 97. Loss: 0.00420373424000669, Train_acc 0.9985977564102564\n",
      "\n",
      "Epoch 97. Loss: 0.0037999152799518157, Train_acc 0.9986155063291139\n",
      "\n",
      "Epoch 97. Loss: 0.0034454305061296002, Train_acc 0.9986328125\n",
      "\n",
      "Epoch 97. Loss: 0.003114501333916705, Train_acc 0.9986496913580247\n",
      "\n",
      "Epoch 97. Loss: 0.0028896164347577283, Train_acc 0.9986661585365854\n",
      "\n",
      "Epoch 97. Loss: 0.00363975616096093, Train_acc 0.9985881024096386\n",
      "\n",
      "Epoch 97. Loss: 0.003413149262561355, Train_acc 0.9986049107142857\n",
      "\n",
      "Epoch 97. Loss: 0.004715773280048925, Train_acc 0.9985294117647059\n",
      "\n",
      "Epoch 97. Loss: 0.004362344686371439, Train_acc 0.998546511627907\n",
      "\n",
      "Epoch 97. Loss: 0.004399541436149794, Train_acc 0.9985632183908046\n",
      "\n",
      "Epoch 97. Loss: 0.003988686565331699, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 97. Loss: 0.0037644784354802204, Train_acc 0.9985955056179775\n",
      "\n",
      "Epoch 97. Loss: 0.004266844827261826, Train_acc 0.9986111111111111\n",
      "\n",
      "Epoch 97. Loss: 0.003906799652887667, Train_acc 0.9986263736263736\n",
      "\n",
      "Epoch 97. Loss: 0.003992468087714867, Train_acc 0.998641304347826\n",
      "\n",
      "Epoch 97. Loss: 0.003890844779171309, Train_acc 0.9986559139784946\n",
      "\n",
      "Epoch 97. Loss: 0.0035556391864823653, Train_acc 0.9986702127659575\n",
      "\n",
      "Epoch 97. Loss: 0.009469753741306723, Train_acc 0.9986019736842106\n",
      "\n",
      "Epoch 97. Loss: 0.008550167027413244, Train_acc 0.9986165364583334\n",
      "\n",
      "Epoch 97. Loss: 0.007858217550038751, Train_acc 0.9986307989690721\n",
      "\n",
      "Epoch 97. Loss: 0.007094964517523235, Train_acc 0.9986447704081632\n",
      "\n",
      "Epoch 97. Loss: 0.006821982728349613, Train_acc 0.9986584595959596\n",
      "\n",
      "Epoch 97. Loss: 0.00616129995694491, Train_acc 0.998671875\n",
      "\n",
      "[Epoch 97 Batch 100] Loss: 0.005956969930402034 Training: accuracy=0.998685\n",
      "Epoch 97. Loss: 0.005956969930402034, Train_acc 0.9986850247524752\n",
      "\n",
      "Epoch 97. Loss: 0.006382249465887183, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 97. Loss: 0.005943684549492092, Train_acc 0.9986347087378641\n",
      "\n",
      "Epoch 97. Loss: 0.005402595382656, Train_acc 0.9986478365384616\n",
      "\n",
      "Epoch 97. Loss: 0.004886187794053767, Train_acc 0.9986607142857142\n",
      "\n",
      "Epoch 97. Loss: 0.004580582899464709, Train_acc 0.9986733490566038\n",
      "\n",
      "Epoch 97. Loss: 0.004399288579550573, Train_acc 0.9986857476635514\n",
      "\n",
      "Epoch 97. Loss: 0.004036275510991087, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 97. Loss: 0.003716447026379678, Train_acc 0.9987098623853211\n",
      "\n",
      "Epoch 97. Loss: 0.0033757617649518533, Train_acc 0.998721590909091\n",
      "\n",
      "Epoch 97. Loss: 0.003470275071822085, Train_acc 0.9987331081081081\n",
      "\n",
      "Epoch 97. Loss: 0.0031379593937750708, Train_acc 0.9987444196428571\n",
      "\n",
      "Epoch 97. Loss: 0.0028691353160412805, Train_acc 0.9987555309734514\n",
      "\n",
      "Epoch 97. Loss: 0.0027742303244714466, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 97. Loss: 0.004688859559516119, Train_acc 0.9987092391304347\n",
      "\n",
      "Epoch 97. Loss: 0.007248404020744569, Train_acc 0.9985856681034483\n",
      "\n",
      "Epoch 97. Loss: 0.006596547695939324, Train_acc 0.9985977564102564\n",
      "\n",
      "Epoch 97. Loss: 0.0060042354996565715, Train_acc 0.9986096398305084\n",
      "\n",
      "Epoch 97. Loss: 0.00544029578977648, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 97. Loss: 0.006536101747278782, Train_acc 0.9985026041666667\n",
      "\n",
      "Epoch 97. Loss: 0.006123862770176899, Train_acc 0.9985149793388429\n",
      "\n",
      "Epoch 97. Loss: 0.006121049330288444, Train_acc 0.9985271516393442\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97. Loss: 0.005521928659398671, Train_acc 0.9985391260162602\n",
      "\n",
      "Epoch 97. Loss: 0.0051617074531191435, Train_acc 0.9985509072580645\n",
      "\n",
      "Epoch 97. Loss: 0.0046671954539254205, Train_acc 0.9985625\n",
      "\n",
      "Epoch 97. Loss: 0.008357359341994068, Train_acc 0.9985119047619048\n",
      "\n",
      "Epoch 97. Loss: 0.007543068280049167, Train_acc 0.9985236220472441\n",
      "\n",
      "Epoch 97. Loss: 0.006839955514733569, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 97. Loss: 0.0061871464638244295, Train_acc 0.998546511627907\n",
      "\n",
      "Epoch 97. Loss: 0.005655126406559529, Train_acc 0.9985576923076923\n",
      "\n",
      "Epoch 97. Loss: 0.005447740846738979, Train_acc 0.9985687022900763\n",
      "\n",
      "Epoch 97. Loss: 0.004941383832819885, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 97. Loss: 0.0048264090118580695, Train_acc 0.9985902255639098\n",
      "\n",
      "Epoch 97. Loss: 0.004373514443110925, Train_acc 0.9986007462686567\n",
      "\n",
      "Epoch 97. Loss: 0.004283336026494058, Train_acc 0.9986111111111111\n",
      "\n",
      "Epoch 97. Loss: 0.006115667460582572, Train_acc 0.9985064338235294\n",
      "\n",
      "Epoch 97. Loss: 0.005720520360109435, Train_acc 0.9985173357664233\n",
      "\n",
      "Epoch 97. Loss: 0.005156663302825752, Train_acc 0.9985280797101449\n",
      "\n",
      "Epoch 97. Loss: 0.004654983442546323, Train_acc 0.9985386690647482\n",
      "\n",
      "Epoch 97. Loss: 0.0042196530579221795, Train_acc 0.9985491071428572\n",
      "\n",
      "Epoch 97. Loss: 0.0038715927095194207, Train_acc 0.9985593971631206\n",
      "\n",
      "Epoch 97. Loss: 0.0036453344541918825, Train_acc 0.9985695422535211\n",
      "\n",
      "Epoch 97. Loss: 0.0033210747205565058, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 97. Loss: 0.0038099772718563395, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 97. Loss: 0.004013057612584357, Train_acc 0.9985452586206897\n",
      "\n",
      "Epoch 97. Loss: 0.0036387599033099335, Train_acc 0.9985552226027398\n",
      "\n",
      "Epoch 97. Loss: 0.003298036862849504, Train_acc 0.9985650510204082\n",
      "\n",
      "Epoch 97. Loss: 0.002974224942575547, Train_acc 0.9985747466216216\n",
      "\n",
      "Epoch 97. Loss: 0.0026957340563830237, Train_acc 0.9985843120805369\n",
      "\n",
      "Epoch 97. Loss: 0.002430643401700225, Train_acc 0.99859375\n",
      "\n",
      "Epoch 97. Loss: 0.003323316137931913, Train_acc 0.9985513245033113\n",
      "\n",
      "Epoch 97. Loss: 0.0035324213360478016, Train_acc 0.9985608552631579\n",
      "\n",
      "Epoch 97. Loss: 0.0034053955000397144, Train_acc 0.9985702614379085\n",
      "\n",
      "Epoch 97. Loss: 0.0030715492402330334, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 97. Loss: 0.002880444000793871, Train_acc 0.9985887096774193\n",
      "\n",
      "Epoch 97. Loss: 0.0026275173768476037, Train_acc 0.9985977564102564\n",
      "\n",
      "Epoch 97. Loss: 0.0029548444512553862, Train_acc 0.9986066878980892\n",
      "\n",
      "Epoch 97. Loss: 0.002765525319757419, Train_acc 0.9986155063291139\n",
      "\n",
      "Epoch 97. Loss: 0.0025430900392020704, Train_acc 0.998624213836478\n",
      "\n",
      "Epoch 97. Loss: 0.0023384601737467168, Train_acc 0.9986328125\n",
      "\n",
      "Epoch 97. Loss: 0.002107431815341479, Train_acc 0.998641304347826\n",
      "\n",
      "Epoch 97. Loss: 0.001971980982436195, Train_acc 0.9986496913580247\n",
      "\n",
      "Epoch 97. Loss: 0.0018370088585903093, Train_acc 0.9986579754601227\n",
      "\n",
      "Epoch 97. Loss: 0.0016604797902917258, Train_acc 0.9986661585365854\n",
      "\n",
      "Epoch 97. Loss: 0.0037140117388858255, Train_acc 0.998626893939394\n",
      "\n",
      "Epoch 97. Loss: 0.0037380142742598527, Train_acc 0.9986351656626506\n",
      "\n",
      "Epoch 97. Loss: 0.003368727835010974, Train_acc 0.9986433383233533\n",
      "\n",
      "Epoch 97. Loss: 0.0032083573966397243, Train_acc 0.9986514136904762\n",
      "\n",
      "Epoch 97. Loss: 0.0029561825173913003, Train_acc 0.9986593934911243\n",
      "\n",
      "Epoch 97. Loss: 0.002693879466942122, Train_acc 0.9986672794117647\n",
      "\n",
      "Epoch 97. Loss: 0.0028548633188228345, Train_acc 0.9986750730994152\n",
      "\n",
      "Epoch 97. Loss: 0.002582954153768878, Train_acc 0.9986827761627907\n",
      "\n",
      "Epoch 97. Loss: 0.0023958889140640893, Train_acc 0.9986903901734104\n",
      "\n",
      "Epoch 97. Loss: 0.005845376774128246, Train_acc 0.9986530172413793\n",
      "\n",
      "Epoch 97. Loss: 0.005262164834491337, Train_acc 0.9986607142857142\n",
      "\n",
      "Epoch 97. Loss: 0.004741004265558764, Train_acc 0.9986683238636364\n",
      "\n",
      "Epoch 97. Loss: 0.004271148563917203, Train_acc 0.9986758474576272\n",
      "\n",
      "Epoch 97. Loss: 0.003914081551726809, Train_acc 0.9986832865168539\n",
      "\n",
      "Epoch 97. Loss: 0.004208034424271719, Train_acc 0.9986469972067039\n",
      "\n",
      "Epoch 97. Loss: 0.004707969168531778, Train_acc 0.9986111111111111\n",
      "\n",
      "Epoch 97. Loss: 0.0042524307977241165, Train_acc 0.9986187845303868\n",
      "\n",
      "Epoch 97. Loss: 0.003840622034449001, Train_acc 0.9986263736263736\n",
      "\n",
      "Epoch 97. Loss: 0.003462282040247787, Train_acc 0.9986338797814208\n",
      "\n",
      "Epoch 97. Loss: 0.0034707368861774824, Train_acc 0.998641304347826\n",
      "\n",
      "Epoch 97. Loss: 0.0031794234824454983, Train_acc 0.9986486486486487\n",
      "\n",
      "Epoch 97. Loss: 0.0028686239286940685, Train_acc 0.9986559139784946\n",
      "\n",
      "Epoch 97. Loss: 0.0026385679055092983, Train_acc 0.9986631016042781\n",
      "\n",
      "Epoch 97. Loss: 0.002397858239697267, Train_acc 0.9986702127659575\n",
      "\n",
      "Epoch 97. Loss: 0.0021654621896914908, Train_acc 0.9986772486772487\n",
      "\n",
      "Epoch 97. Loss: 0.002024052165659273, Train_acc 0.9986842105263158\n",
      "\n",
      "Epoch 97. Loss: 0.004768514929156307, Train_acc 0.9986501963350786\n",
      "\n",
      "Epoch 97. Loss: 0.004385495576796282, Train_acc 0.9986572265625\n",
      "\n",
      "Epoch 97. Loss: 0.005623296851102128, Train_acc 0.9986237046632125\n",
      "\n",
      "Epoch 97. Loss: 0.006249697428211821, Train_acc 0.9985905283505154\n",
      "\n",
      "Epoch 97. Loss: 0.005735670893373567, Train_acc 0.9985977564102564\n",
      "\n",
      "Epoch 97. Loss: 0.0051662100041762965, Train_acc 0.9986\n",
      "\n",
      "Epoch 98. Loss: 0.005406143309312103, Train_acc 0.9921875\n",
      "\n",
      "Epoch 98. Loss: 0.005122302388745878, Train_acc 0.99609375\n",
      "\n",
      "Epoch 98. Loss: 0.004611871308106662, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 98. Loss: 0.0042276320449334956, Train_acc 0.998046875\n",
      "\n",
      "Epoch 98. Loss: 0.0038190640009147744, Train_acc 0.9984375\n",
      "\n",
      "Epoch 98. Loss: 0.0035074807323361478, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 98. Loss: 0.0032954232494953315, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 98. Loss: 0.004130686906807695, Train_acc 0.998046875\n",
      "\n",
      "Epoch 98. Loss: 0.003961380887143082, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 98. Loss: 0.003944006241287827, Train_acc 0.9984375\n",
      "\n",
      "Epoch 98. Loss: 0.0037139949946189284, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 98. Loss: 0.003360310183303988, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 98. Loss: 0.003093511030901166, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 98. Loss: 0.002829789070361801, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 98. Loss: 0.00256408633241755, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 98. Loss: 0.002968541078192313, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 98. Loss: 0.0026946282073393715, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 98. Loss: 0.0025111427351044344, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 98. Loss: 0.0023153778935259637, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 98. Loss: 0.002091068212179897, Train_acc 0.998828125\n",
      "\n",
      "Epoch 98. Loss: 0.0025084815049814207, Train_acc 0.9985119047619048\n",
      "\n",
      "Epoch 98. Loss: 0.002538400265356632, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 98. Loss: 0.00230766219587019, Train_acc 0.998641304347826\n",
      "\n",
      "Epoch 98. Loss: 0.002079554188826054, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 98. Loss: 0.00204544987253401, Train_acc 0.99875\n",
      "\n",
      "Epoch 98. Loss: 0.005900232651579857, Train_acc 0.9984975961538461\n",
      "\n",
      "Epoch 98. Loss: 0.00537081638458049, Train_acc 0.9985532407407407\n",
      "\n",
      "Epoch 98. Loss: 0.005089692550742707, Train_acc 0.9986049107142857\n",
      "\n",
      "Epoch 98. Loss: 0.004597781477070245, Train_acc 0.9986530172413793\n",
      "\n",
      "Epoch 98. Loss: 0.004152029562474728, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 98. Loss: 0.004268044527752496, Train_acc 0.9987399193548387\n",
      "\n",
      "Epoch 98. Loss: 0.00393270346641351, Train_acc 0.998779296875\n",
      "\n",
      "Epoch 98. Loss: 0.0035722593301443094, Train_acc 0.9988162878787878\n",
      "\n",
      "Epoch 98. Loss: 0.0033382010637364834, Train_acc 0.9988511029411765\n",
      "\n",
      "Epoch 98. Loss: 0.003678517964807932, Train_acc 0.9986607142857142\n",
      "\n",
      "Epoch 98. Loss: 0.003608858753214286, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 98. Loss: 0.003337464269447332, Train_acc 0.9987331081081081\n",
      "\n",
      "Epoch 98. Loss: 0.003429672564370637, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 98. Loss: 0.0036129420506684825, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 98. Loss: 0.0038067444122787276, Train_acc 0.998828125\n",
      "\n",
      "Epoch 98. Loss: 0.003455675953177523, Train_acc 0.9988567073170732\n",
      "\n",
      "Epoch 98. Loss: 0.0031715850774254603, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 98. Loss: 0.002857679475709233, Train_acc 0.9989098837209303\n",
      "\n",
      "Epoch 98. Loss: 0.0025903033241767956, Train_acc 0.9989346590909091\n",
      "\n",
      "Epoch 98. Loss: 0.0023818396107883845, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 98. Loss: 0.002199763341198706, Train_acc 0.9989809782608695\n",
      "\n",
      "Epoch 98. Loss: 0.0028138113320919965, Train_acc 0.9988364361702128\n",
      "\n",
      "Epoch 98. Loss: 0.0025956661984334675, Train_acc 0.9988606770833334\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98. Loss: 0.0023700438126092664, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 98. Loss: 0.002847547456323997, Train_acc 0.99875\n",
      "\n",
      "Epoch 98. Loss: 0.006814517564803269, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 98. Loss: 0.0061437857284240525, Train_acc 0.9986478365384616\n",
      "\n",
      "Epoch 98. Loss: 0.005535246505923933, Train_acc 0.9986733490566038\n",
      "\n",
      "Epoch 98. Loss: 0.005114268336076617, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 98. Loss: 0.004987761313509118, Train_acc 0.998721590909091\n",
      "\n",
      "Epoch 98. Loss: 0.004599468351713871, Train_acc 0.9987444196428571\n",
      "\n",
      "Epoch 98. Loss: 0.004344860938060632, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 98. Loss: 0.008233558961929396, Train_acc 0.9985183189655172\n",
      "\n",
      "Epoch 98. Loss: 0.012707590457065269, Train_acc 0.998146186440678\n",
      "\n",
      "Epoch 98. Loss: 0.01152576510949324, Train_acc 0.9981770833333333\n",
      "\n",
      "Epoch 98. Loss: 0.010415174037564125, Train_acc 0.9982069672131147\n",
      "\n",
      "Epoch 98. Loss: 0.009397147933169633, Train_acc 0.9982358870967742\n",
      "\n",
      "Epoch 98. Loss: 0.008495334365585309, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 98. Loss: 0.01649516842837828, Train_acc 0.998046875\n",
      "\n",
      "Epoch 98. Loss: 0.01876142454513041, Train_acc 0.9979567307692307\n",
      "\n",
      "Epoch 98. Loss: 0.016925298317902748, Train_acc 0.9979876893939394\n",
      "\n",
      "Epoch 98. Loss: 0.01631716482234013, Train_acc 0.9979011194029851\n",
      "\n",
      "Epoch 98. Loss: 0.014924777706119522, Train_acc 0.9979319852941176\n",
      "\n",
      "Epoch 98. Loss: 0.013483409061578085, Train_acc 0.9979619565217391\n",
      "\n",
      "Epoch 98. Loss: 0.01333257371146724, Train_acc 0.9978794642857143\n",
      "\n",
      "Epoch 98. Loss: 0.01221221554000746, Train_acc 0.9979093309859155\n",
      "\n",
      "Epoch 98. Loss: 0.011324476106192805, Train_acc 0.9979383680555556\n",
      "\n",
      "Epoch 98. Loss: 0.010345053083353761, Train_acc 0.997966609589041\n",
      "\n",
      "Epoch 98. Loss: 0.010271786107111148, Train_acc 0.9978885135135135\n",
      "\n",
      "Epoch 98. Loss: 0.011155832852561628, Train_acc 0.9977083333333333\n",
      "\n",
      "Epoch 98. Loss: 0.01090483207610788, Train_acc 0.9977384868421053\n",
      "\n",
      "Epoch 98. Loss: 0.012502678535350044, Train_acc 0.9976663961038961\n",
      "\n",
      "Epoch 98. Loss: 0.011323448434601691, Train_acc 0.9976963141025641\n",
      "\n",
      "Epoch 98. Loss: 0.010222668109718011, Train_acc 0.9977254746835443\n",
      "\n",
      "Epoch 98. Loss: 0.009296968495052052, Train_acc 0.99775390625\n",
      "\n",
      "Epoch 98. Loss: 0.008850861963436896, Train_acc 0.9977816358024691\n",
      "\n",
      "Epoch 98. Loss: 0.01199357863677075, Train_acc 0.9977134146341463\n",
      "\n",
      "Epoch 98. Loss: 0.010859991273898905, Train_acc 0.9977409638554217\n",
      "\n",
      "Epoch 98. Loss: 0.009986866386750958, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 98. Loss: 0.009504757604691048, Train_acc 0.9977941176470588\n",
      "\n",
      "Epoch 98. Loss: 0.00993857587727248, Train_acc 0.9977289244186046\n",
      "\n",
      "Epoch 98. Loss: 0.0089889143070974, Train_acc 0.9977550287356322\n",
      "\n",
      "Epoch 98. Loss: 0.008416332019953256, Train_acc 0.9977805397727273\n",
      "\n",
      "Epoch 98. Loss: 0.0076770277927115495, Train_acc 0.9978054775280899\n",
      "\n",
      "Epoch 98. Loss: 0.007453595979642415, Train_acc 0.9978298611111112\n",
      "\n",
      "Epoch 98. Loss: 0.006845165887648503, Train_acc 0.9978537087912088\n",
      "\n",
      "Epoch 98. Loss: 0.006315427764977938, Train_acc 0.9978770380434783\n",
      "\n",
      "Epoch 98. Loss: 0.005692313489794628, Train_acc 0.9978998655913979\n",
      "\n",
      "Epoch 98. Loss: 0.005319273366947379, Train_acc 0.9979222074468085\n",
      "\n",
      "Epoch 98. Loss: 0.004862582808027631, Train_acc 0.9979440789473685\n",
      "\n",
      "Epoch 98. Loss: 0.004980686800813644, Train_acc 0.9978841145833334\n",
      "\n",
      "Epoch 98. Loss: 0.005130870041670772, Train_acc 0.9978253865979382\n",
      "\n",
      "Epoch 98. Loss: 0.004685131536354756, Train_acc 0.9978475765306123\n",
      "\n",
      "Epoch 98. Loss: 0.004237140018898464, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 98. Loss: 0.005560367561124161, Train_acc 0.9978125\n",
      "\n",
      "[Epoch 98 Batch 100] Loss: 0.005456357855790015 Training: accuracy=0.997834\n",
      "Epoch 98. Loss: 0.005456357855790015, Train_acc 0.9978341584158416\n",
      "\n",
      "Epoch 98. Loss: 0.004918485529354475, Train_acc 0.9978553921568627\n",
      "\n",
      "Epoch 98. Loss: 0.004446874595592742, Train_acc 0.997876213592233\n",
      "\n",
      "Epoch 98. Loss: 0.006463508042910985, Train_acc 0.9978215144230769\n",
      "\n",
      "Epoch 98. Loss: 0.005878731275573858, Train_acc 0.9978422619047619\n",
      "\n",
      "Epoch 98. Loss: 0.0053096229678499226, Train_acc 0.9978626179245284\n",
      "\n",
      "Epoch 98. Loss: 0.00483201696209267, Train_acc 0.997882593457944\n",
      "\n",
      "Epoch 98. Loss: 0.004445948636465417, Train_acc 0.9979021990740741\n",
      "\n",
      "Epoch 98. Loss: 0.004017391170836818, Train_acc 0.9979214449541285\n",
      "\n",
      "Epoch 98. Loss: 0.0038656317453330744, Train_acc 0.9979403409090909\n",
      "\n",
      "Epoch 98. Loss: 0.0037254279787015307, Train_acc 0.9979588963963963\n",
      "\n",
      "Epoch 98. Loss: 0.003398527239662086, Train_acc 0.9979771205357143\n",
      "\n",
      "Epoch 98. Loss: 0.003321413000585146, Train_acc 0.9979950221238938\n",
      "\n",
      "Epoch 98. Loss: 0.0030061643873621215, Train_acc 0.9980126096491229\n",
      "\n",
      "Epoch 98. Loss: 0.0027109881592147682, Train_acc 0.9980298913043478\n",
      "\n",
      "Epoch 98. Loss: 0.0024557546809207656, Train_acc 0.998046875\n",
      "\n",
      "Epoch 98. Loss: 0.002234654419566096, Train_acc 0.9980635683760684\n",
      "\n",
      "Epoch 98. Loss: 0.0034961071063085505, Train_acc 0.9980137711864406\n",
      "\n",
      "Epoch 98. Loss: 0.0035506240828935007, Train_acc 0.9980304621848739\n",
      "\n",
      "Epoch 98. Loss: 0.0032017746162660934, Train_acc 0.998046875\n",
      "\n",
      "Epoch 98. Loss: 0.003035940250713201, Train_acc 0.9980630165289256\n",
      "\n",
      "Epoch 98. Loss: 0.0029555996135996925, Train_acc 0.9980788934426229\n",
      "\n",
      "Epoch 98. Loss: 0.00299532001661901, Train_acc 0.9980945121951219\n",
      "\n",
      "Epoch 98. Loss: 0.0027132624771770888, Train_acc 0.9981098790322581\n",
      "\n",
      "Epoch 98. Loss: 0.0024638384524024066, Train_acc 0.998125\n",
      "\n",
      "Epoch 98. Loss: 0.0029768373393747097, Train_acc 0.998077876984127\n",
      "\n",
      "Epoch 98. Loss: 0.002925252662113269, Train_acc 0.9980930118110236\n",
      "\n",
      "Epoch 98. Loss: 0.005512328740368152, Train_acc 0.99798583984375\n",
      "\n",
      "Epoch 98. Loss: 0.004971895765941329, Train_acc 0.9980014534883721\n",
      "\n",
      "Epoch 98. Loss: 0.004536673098908503, Train_acc 0.9980168269230769\n",
      "\n",
      "Epoch 98. Loss: 0.00451505191931722, Train_acc 0.998031965648855\n",
      "\n",
      "Epoch 98. Loss: 0.004081106395434715, Train_acc 0.998046875\n",
      "\n",
      "Epoch 98. Loss: 0.003924316412280242, Train_acc 0.998061560150376\n",
      "\n",
      "Epoch 98. Loss: 0.003540814175482309, Train_acc 0.9980760261194029\n",
      "\n",
      "Epoch 98. Loss: 0.003190882038291602, Train_acc 0.9980902777777778\n",
      "\n",
      "Epoch 98. Loss: 0.002898977676492796, Train_acc 0.9981043198529411\n",
      "\n",
      "Epoch 98. Loss: 0.0026364019329504955, Train_acc 0.9981181569343066\n",
      "\n",
      "Epoch 98. Loss: 0.00249636760517494, Train_acc 0.9981317934782609\n",
      "\n",
      "Epoch 98. Loss: 0.0024925600506174816, Train_acc 0.9981452338129496\n",
      "\n",
      "Epoch 98. Loss: 0.0023109387864001024, Train_acc 0.9981584821428572\n",
      "\n",
      "Epoch 98. Loss: 0.0021005459690540407, Train_acc 0.9981715425531915\n",
      "\n",
      "Epoch 98. Loss: 0.001942396063066218, Train_acc 0.9981844190140845\n",
      "\n",
      "Epoch 98. Loss: 0.0018068026658319177, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 98. Loss: 0.001646869545003011, Train_acc 0.9982096354166666\n",
      "\n",
      "Epoch 98. Loss: 0.0016118132050404557, Train_acc 0.9982219827586207\n",
      "\n",
      "Epoch 98. Loss: 0.0014852014783813456, Train_acc 0.9982341609589042\n",
      "\n",
      "Epoch 98. Loss: 0.0013462307564289908, Train_acc 0.9982461734693877\n",
      "\n",
      "Epoch 98. Loss: 0.0012229621626165862, Train_acc 0.9982580236486487\n",
      "\n",
      "Epoch 98. Loss: 0.0011287576852867622, Train_acc 0.9982697147651006\n",
      "\n",
      "Epoch 98. Loss: 0.001027675352018274, Train_acc 0.99828125\n",
      "\n",
      "Epoch 98. Loss: 0.0029823977558504316, Train_acc 0.9982408940397351\n",
      "\n",
      "Epoch 98. Loss: 0.002710097322132731, Train_acc 0.9982524671052632\n",
      "\n",
      "Epoch 98. Loss: 0.0024425172526030873, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 98. Loss: 0.0023853736924616216, Train_acc 0.9982751623376623\n",
      "\n",
      "Epoch 98. Loss: 0.0022239173932641944, Train_acc 0.9982862903225806\n",
      "\n",
      "Epoch 98. Loss: 0.0020104822558974283, Train_acc 0.9982972756410257\n",
      "\n",
      "Epoch 98. Loss: 0.0018676180181654595, Train_acc 0.9983081210191083\n",
      "\n",
      "Epoch 98. Loss: 0.0020963726748006615, Train_acc 0.998318829113924\n",
      "\n",
      "Epoch 98. Loss: 0.0025808703318813807, Train_acc 0.9982802672955975\n",
      "\n",
      "Epoch 98. Loss: 0.0023435471122112304, Train_acc 0.998291015625\n",
      "\n",
      "Epoch 98. Loss: 0.0021179887288830315, Train_acc 0.9983016304347826\n",
      "\n",
      "Epoch 98. Loss: 0.0031843760729451448, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 98. Loss: 0.0035185783594655516, Train_acc 0.9982266104294478\n",
      "\n",
      "Epoch 98. Loss: 0.0033480611243485677, Train_acc 0.9982374237804879\n",
      "\n",
      "Epoch 98. Loss: 0.0030228581772948336, Train_acc 0.9982481060606061\n",
      "\n",
      "Epoch 98. Loss: 0.0027476635000749333, Train_acc 0.9982586596385542\n",
      "\n",
      "Epoch 98. Loss: 0.00264086895294284, Train_acc 0.9982690868263473\n",
      "\n",
      "Epoch 98. Loss: 0.002396552247477261, Train_acc 0.9982793898809523\n",
      "\n",
      "Epoch 98. Loss: 0.00235205615718456, Train_acc 0.9982895710059172\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98. Loss: 0.0034776950828071707, Train_acc 0.9982536764705883\n",
      "\n",
      "Epoch 98. Loss: 0.0031387991330714734, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 98. Loss: 0.00283917087950502, Train_acc 0.9982739825581395\n",
      "\n",
      "Epoch 98. Loss: 0.005876648115857192, Train_acc 0.9982388005780347\n",
      "\n",
      "Epoch 98. Loss: 0.0056590213023442765, Train_acc 0.9982489224137931\n",
      "\n",
      "Epoch 98. Loss: 0.005129557499625347, Train_acc 0.9982589285714286\n",
      "\n",
      "Epoch 98. Loss: 0.0068636765548629125, Train_acc 0.9982244318181818\n",
      "\n",
      "Epoch 98. Loss: 0.009032464143846263, Train_acc 0.998146186440678\n",
      "\n",
      "Epoch 98. Loss: 0.008414371425775138, Train_acc 0.9981566011235955\n",
      "\n",
      "Epoch 98. Loss: 0.009054966336370212, Train_acc 0.9981232541899442\n",
      "\n",
      "Epoch 98. Loss: 0.009407132736635836, Train_acc 0.998046875\n",
      "\n",
      "Epoch 98. Loss: 0.008517173842453329, Train_acc 0.9980576657458563\n",
      "\n",
      "Epoch 98. Loss: 0.008412111642983586, Train_acc 0.9980683379120879\n",
      "\n",
      "Epoch 98. Loss: 0.00867019508900675, Train_acc 0.9980362021857924\n",
      "\n",
      "Epoch 98. Loss: 0.009625459816656407, Train_acc 0.9979619565217391\n",
      "\n",
      "Epoch 98. Loss: 0.010755786581279543, Train_acc 0.9979307432432433\n",
      "\n",
      "Epoch 98. Loss: 0.009935061086066104, Train_acc 0.9979418682795699\n",
      "\n",
      "Epoch 98. Loss: 0.009512686404300514, Train_acc 0.9979528743315508\n",
      "\n",
      "Epoch 98. Loss: 0.009226512187909588, Train_acc 0.9979222074468085\n",
      "\n",
      "Epoch 98. Loss: 0.008318011199099798, Train_acc 0.997933201058201\n",
      "\n",
      "Epoch 98. Loss: 0.007496432328883288, Train_acc 0.9979440789473685\n",
      "\n",
      "Epoch 98. Loss: 0.007393119745028148, Train_acc 0.997913939790576\n",
      "\n",
      "Epoch 98. Loss: 0.006836097121303198, Train_acc 0.9979248046875\n",
      "\n",
      "Epoch 98. Loss: 0.006878662670834288, Train_acc 0.9979355569948186\n",
      "\n",
      "Epoch 98. Loss: 0.006692815779313527, Train_acc 0.9979461984536082\n",
      "\n",
      "Epoch 98. Loss: 0.006472650124056711, Train_acc 0.9979567307692307\n",
      "\n",
      "Epoch 98. Loss: 0.006464387788704253, Train_acc 0.99796\n",
      "\n",
      "Epoch 99. Loss: 0.0058336841660276695, Train_acc 1.0\n",
      "\n",
      "Epoch 99. Loss: 0.006501967096108405, Train_acc 0.99609375\n",
      "\n",
      "Epoch 99. Loss: 0.005888441562119015, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 99. Loss: 0.005391662123225976, Train_acc 0.998046875\n",
      "\n",
      "Epoch 99. Loss: 0.005059402585333152, Train_acc 0.9984375\n",
      "\n",
      "Epoch 99. Loss: 0.004614451347657797, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 99. Loss: 0.0044113754910547354, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 99. Loss: 0.004115302969704016, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 99. Loss: 0.003788623062709669, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 99. Loss: 0.005253402082270116, Train_acc 0.99765625\n",
      "\n",
      "Epoch 99. Loss: 0.00504006229398763, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 99. Loss: 0.007977614842874847, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 99. Loss: 0.007202956325539501, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 99. Loss: 0.0071087948203640144, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 99. Loss: 0.006405208403173339, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 99. Loss: 0.006725032384070682, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 99. Loss: 0.006422948683312173, Train_acc 0.9972426470588235\n",
      "\n",
      "Epoch 99. Loss: 0.005816675224304394, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 99. Loss: 0.005245532942087565, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 99. Loss: 0.007692578526381655, Train_acc 0.996875\n",
      "\n",
      "Epoch 99. Loss: 0.0069899053018188505, Train_acc 0.9970238095238095\n",
      "\n",
      "Epoch 99. Loss: 0.006300784768939269, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 99. Loss: 0.009940698852193581, Train_acc 0.9969429347826086\n",
      "\n",
      "Epoch 99. Loss: 0.018679436394618953, Train_acc 0.9964192708333334\n",
      "\n",
      "Epoch 99. Loss: 0.01769640305553109, Train_acc 0.99625\n",
      "\n",
      "Epoch 99. Loss: 0.016681159926184092, Train_acc 0.99609375\n",
      "\n",
      "Epoch 99. Loss: 0.01524677924068547, Train_acc 0.9962384259259259\n",
      "\n",
      "Epoch 99. Loss: 0.013727820332442813, Train_acc 0.9963727678571429\n",
      "\n",
      "Epoch 99. Loss: 0.01270167698056557, Train_acc 0.9964978448275862\n",
      "\n",
      "Epoch 99. Loss: 0.011453395275700986, Train_acc 0.9966145833333333\n",
      "\n",
      "Epoch 99. Loss: 0.01066439806566736, Train_acc 0.9967237903225806\n",
      "\n",
      "Epoch 99. Loss: 0.010378029437551806, Train_acc 0.996826171875\n",
      "\n",
      "Epoch 99. Loss: 0.00949369663793809, Train_acc 0.9969223484848485\n",
      "\n",
      "Epoch 99. Loss: 0.00924528262584478, Train_acc 0.9970128676470589\n",
      "\n",
      "Epoch 99. Loss: 0.009170155475906166, Train_acc 0.996875\n",
      "\n",
      "Epoch 99. Loss: 0.008477295069356232, Train_acc 0.9969618055555556\n",
      "\n",
      "Epoch 99. Loss: 0.008396672684067012, Train_acc 0.9968327702702703\n",
      "\n",
      "Epoch 99. Loss: 0.007752076866094936, Train_acc 0.9969161184210527\n",
      "\n",
      "Epoch 99. Loss: 0.00698926745782614, Train_acc 0.9969951923076923\n",
      "\n",
      "Epoch 99. Loss: 0.008721109768125299, Train_acc 0.996875\n",
      "\n",
      "Epoch 99. Loss: 0.007917128826964617, Train_acc 0.9969512195121951\n",
      "\n",
      "Epoch 99. Loss: 0.008500678010990071, Train_acc 0.9968377976190477\n",
      "\n",
      "Epoch 99. Loss: 0.00862305235255645, Train_acc 0.9967296511627907\n",
      "\n",
      "Epoch 99. Loss: 0.007816812765396489, Train_acc 0.9968039772727273\n",
      "\n",
      "Epoch 99. Loss: 0.00710768335678147, Train_acc 0.996875\n",
      "\n",
      "Epoch 99. Loss: 0.007844171396207512, Train_acc 0.9967730978260869\n",
      "\n",
      "Epoch 99. Loss: 0.00706194876252835, Train_acc 0.996841755319149\n",
      "\n",
      "Epoch 99. Loss: 0.006945321122877822, Train_acc 0.9969075520833334\n",
      "\n",
      "Epoch 99. Loss: 0.006268119360827939, Train_acc 0.9969706632653061\n",
      "\n",
      "Epoch 99. Loss: 0.005712087800717535, Train_acc 0.99703125\n",
      "\n",
      "Epoch 99. Loss: 0.0052065042176670726, Train_acc 0.9970894607843137\n",
      "\n",
      "Epoch 99. Loss: 0.004708798341972178, Train_acc 0.9971454326923077\n",
      "\n",
      "Epoch 99. Loss: 0.004721204748844397, Train_acc 0.9971992924528302\n",
      "\n",
      "Epoch 99. Loss: 0.0057188263150411475, Train_acc 0.9971064814814815\n",
      "\n",
      "Epoch 99. Loss: 0.005181149130255293, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 99. Loss: 0.005155060594699065, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 99. Loss: 0.004710039612096203, Train_acc 0.9972587719298246\n",
      "\n",
      "Epoch 99. Loss: 0.004328861503660667, Train_acc 0.9973060344827587\n",
      "\n",
      "Epoch 99. Loss: 0.004190760647976388, Train_acc 0.9973516949152542\n",
      "\n",
      "Epoch 99. Loss: 0.004688075169823161, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 99. Loss: 0.006940375403971902, Train_acc 0.9973104508196722\n",
      "\n",
      "Epoch 99. Loss: 0.00642086322042623, Train_acc 0.9973538306451613\n",
      "\n",
      "Epoch 99. Loss: 0.010156894519328583, Train_acc 0.9972718253968254\n",
      "\n",
      "Epoch 99. Loss: 0.010693067873477497, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 99. Loss: 0.010264783429318271, Train_acc 0.9969951923076923\n",
      "\n",
      "Epoch 99. Loss: 0.00929986237699637, Train_acc 0.9970407196969697\n",
      "\n",
      "Epoch 99. Loss: 0.008494751315994703, Train_acc 0.9970848880597015\n",
      "\n",
      "Epoch 99. Loss: 0.013415176789477744, Train_acc 0.9970128676470589\n",
      "\n",
      "Epoch 99. Loss: 0.01359805507184441, Train_acc 0.9969429347826086\n",
      "\n",
      "Epoch 99. Loss: 0.012318402299541236, Train_acc 0.9969866071428571\n",
      "\n",
      "Epoch 99. Loss: 0.011297746937244835, Train_acc 0.9970290492957746\n",
      "\n",
      "Epoch 99. Loss: 0.010537311959209773, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 99. Loss: 0.009667665855330437, Train_acc 0.9971104452054794\n",
      "\n",
      "Epoch 99. Loss: 0.009025583627999316, Train_acc 0.9971494932432432\n",
      "\n",
      "Epoch 99. Loss: 0.008709960956734857, Train_acc 0.9971875\n",
      "\n",
      "Epoch 99. Loss: 0.007923603188887187, Train_acc 0.9972245065789473\n",
      "\n",
      "Epoch 99. Loss: 0.00722446965670134, Train_acc 0.997260551948052\n",
      "\n",
      "Epoch 99. Loss: 0.00698488047715019, Train_acc 0.9972956730769231\n",
      "\n",
      "Epoch 99. Loss: 0.0069536419339119564, Train_acc 0.9972310126582279\n",
      "\n",
      "Epoch 99. Loss: 0.0068393422814136, Train_acc 0.997265625\n",
      "\n",
      "Epoch 99. Loss: 0.00626934478812369, Train_acc 0.9972993827160493\n",
      "\n",
      "Epoch 99. Loss: 0.006017311324622801, Train_acc 0.9973323170731707\n",
      "\n",
      "Epoch 99. Loss: 0.00555278896684638, Train_acc 0.9973644578313253\n",
      "\n",
      "Epoch 99. Loss: 0.0050827696832770825, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 99. Loss: 0.0046631205725711335, Train_acc 0.9974264705882353\n",
      "\n",
      "Epoch 99. Loss: 0.005223292978677906, Train_acc 0.9973655523255814\n",
      "\n",
      "Epoch 99. Loss: 0.004734702019780695, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 99. Loss: 0.0074851937820522366, Train_acc 0.9973366477272727\n",
      "\n",
      "Epoch 99. Loss: 0.00689725627850816, Train_acc 0.9973665730337079\n",
      "\n",
      "Epoch 99. Loss: 0.006283895760656077, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 99. Loss: 0.005730252574463795, Train_acc 0.9974244505494505\n",
      "\n",
      "Epoch 99. Loss: 0.00555764577924917, Train_acc 0.997452445652174\n",
      "\n",
      "Epoch 99. Loss: 0.0052622490278829035, Train_acc 0.9974798387096774\n",
      "\n",
      "Epoch 99. Loss: 0.004842328508465639, Train_acc 0.9975066489361702\n",
      "\n",
      "Epoch 99. Loss: 0.0048471376118980215, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 99. Loss: 0.004897737076990817, Train_acc 0.99755859375\n",
      "\n",
      "Epoch 99. Loss: 0.005543811273079825, Train_acc 0.9975032216494846\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99. Loss: 0.005191862909534615, Train_acc 0.9975286989795918\n",
      "\n",
      "Epoch 99. Loss: 0.004729291840128116, Train_acc 0.9975536616161617\n",
      "\n",
      "Epoch 99. Loss: 0.004290993271961559, Train_acc 0.997578125\n",
      "\n",
      "[Epoch 99 Batch 100] Loss: 0.00387145904379148 Training: accuracy=0.997602\n",
      "Epoch 99. Loss: 0.00387145904379148, Train_acc 0.9976021039603961\n",
      "\n",
      "Epoch 99. Loss: 0.004752415647450615, Train_acc 0.9975490196078431\n",
      "\n",
      "Epoch 99. Loss: 0.004363774969130558, Train_acc 0.9975728155339806\n",
      "\n",
      "Epoch 99. Loss: 0.004052421602319749, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 99. Loss: 0.003939540434258645, Train_acc 0.9976190476190476\n",
      "\n",
      "Epoch 99. Loss: 0.0036077027660257805, Train_acc 0.9976415094339622\n",
      "\n",
      "Epoch 99. Loss: 0.003356698563879477, Train_acc 0.9976635514018691\n",
      "\n",
      "Epoch 99. Loss: 0.003499141731055749, Train_acc 0.9976851851851852\n",
      "\n",
      "Epoch 99. Loss: 0.0031847766179260665, Train_acc 0.9977064220183486\n",
      "\n",
      "Epoch 99. Loss: 0.0029311531810444196, Train_acc 0.9977272727272727\n",
      "\n",
      "Epoch 99. Loss: 0.002694618677938575, Train_acc 0.9977477477477478\n",
      "\n",
      "Epoch 99. Loss: 0.002430005814616625, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 99. Loss: 0.002701024979488323, Train_acc 0.9977876106194691\n",
      "\n",
      "Epoch 99. Loss: 0.0024927831562988638, Train_acc 0.9978070175438597\n",
      "\n",
      "Epoch 99. Loss: 0.0022627166487721143, Train_acc 0.9978260869565218\n",
      "\n",
      "Epoch 99. Loss: 0.002053914692004177, Train_acc 0.9978448275862069\n",
      "\n",
      "Epoch 99. Loss: 0.0019622891996611534, Train_acc 0.9978632478632479\n",
      "\n",
      "Epoch 99. Loss: 0.0018067969461099248, Train_acc 0.9978813559322034\n",
      "\n",
      "Epoch 99. Loss: 0.0016479093499130852, Train_acc 0.9978991596638656\n",
      "\n",
      "Epoch 99. Loss: 0.0018264354877603217, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 99. Loss: 0.001671547912844911, Train_acc 0.9979338842975206\n",
      "\n",
      "Epoch 99. Loss: 0.001539341399895343, Train_acc 0.9979508196721312\n",
      "\n",
      "Epoch 99. Loss: 0.0013870683479324031, Train_acc 0.9979674796747967\n",
      "\n",
      "Epoch 99. Loss: 0.0012653193372575981, Train_acc 0.9979838709677419\n",
      "\n",
      "Epoch 99. Loss: 0.001143213200837723, Train_acc 0.998\n",
      "\n",
      "Epoch 99. Loss: 0.0017826897974494264, Train_acc 0.9979538690476191\n",
      "\n",
      "Epoch 99. Loss: 0.0016175318997847699, Train_acc 0.9979699803149606\n",
      "\n",
      "Epoch 99. Loss: 0.0015077733140976873, Train_acc 0.99798583984375\n",
      "\n",
      "Epoch 99. Loss: 0.0016891397923342866, Train_acc 0.9980014534883721\n",
      "\n",
      "Epoch 99. Loss: 0.0015406355421415515, Train_acc 0.9980168269230769\n",
      "\n",
      "Epoch 99. Loss: 0.0020243788467948034, Train_acc 0.9979723282442748\n",
      "\n",
      "Epoch 99. Loss: 0.0018749742297288236, Train_acc 0.9979876893939394\n",
      "\n",
      "Epoch 99. Loss: 0.0017078692714044077, Train_acc 0.9980028195488722\n",
      "\n",
      "Epoch 99. Loss: 0.0015709138184023907, Train_acc 0.9980177238805971\n",
      "\n",
      "Epoch 99. Loss: 0.0016144558152615736, Train_acc 0.9980324074074074\n",
      "\n",
      "Epoch 99. Loss: 0.0014817379262873271, Train_acc 0.998046875\n",
      "\n",
      "Epoch 99. Loss: 0.0016534637290011708, Train_acc 0.9980611313868614\n",
      "\n",
      "Epoch 99. Loss: 0.0014965770072452751, Train_acc 0.9980751811594203\n",
      "\n",
      "Epoch 99. Loss: 0.0013746113101620252, Train_acc 0.9980890287769785\n",
      "\n",
      "Epoch 99. Loss: 0.0013011107360180118, Train_acc 0.9981026785714285\n",
      "\n",
      "Epoch 99. Loss: 0.0011967447711398512, Train_acc 0.9981161347517731\n",
      "\n",
      "Epoch 99. Loss: 0.004977301715019671, Train_acc 0.9980743838028169\n",
      "\n",
      "Epoch 99. Loss: 0.004492248082126207, Train_acc 0.9980878496503497\n",
      "\n",
      "Epoch 99. Loss: 0.0040439092732749305, Train_acc 0.9981011284722222\n",
      "\n",
      "Epoch 99. Loss: 0.003648873819541479, Train_acc 0.998114224137931\n",
      "\n",
      "Epoch 99. Loss: 0.003343516850132759, Train_acc 0.998127140410959\n",
      "\n",
      "Epoch 99. Loss: 0.00301421988892558, Train_acc 0.9981398809523809\n",
      "\n",
      "Epoch 99. Loss: 0.0037733955917179838, Train_acc 0.9980996621621622\n",
      "\n",
      "Epoch 99. Loss: 0.003414450440653455, Train_acc 0.9981124161073825\n",
      "\n",
      "Epoch 99. Loss: 0.003157764598442577, Train_acc 0.998125\n",
      "\n",
      "Epoch 99. Loss: 0.00416453110773575, Train_acc 0.9980856788079471\n",
      "\n",
      "Epoch 99. Loss: 0.003769040588186991, Train_acc 0.9980982730263158\n",
      "\n",
      "Epoch 99. Loss: 0.00354238404128788, Train_acc 0.9981107026143791\n",
      "\n",
      "Epoch 99. Loss: 0.0031981010796696373, Train_acc 0.9981229707792207\n",
      "\n",
      "Epoch 99. Loss: 0.0029050281368743266, Train_acc 0.9981350806451613\n",
      "\n",
      "Epoch 99. Loss: 0.0026201689931975073, Train_acc 0.9981470352564102\n",
      "\n",
      "Epoch 99. Loss: 0.0023628618838146534, Train_acc 0.9981588375796179\n",
      "\n",
      "Epoch 99. Loss: 0.005363691659726668, Train_acc 0.9980715981012658\n",
      "\n",
      "Epoch 99. Loss: 0.0048293799650374804, Train_acc 0.9980837264150944\n",
      "\n",
      "Epoch 99. Loss: 0.004499455101046302, Train_acc 0.998095703125\n",
      "\n",
      "Epoch 99. Loss: 0.004085832978699547, Train_acc 0.9981075310559007\n",
      "\n",
      "Epoch 99. Loss: 0.004304117178169437, Train_acc 0.998070987654321\n",
      "\n",
      "Epoch 99. Loss: 0.004327304723335101, Train_acc 0.9980828220858896\n",
      "\n",
      "Epoch 99. Loss: 0.00599910175425362, Train_acc 0.998046875\n",
      "\n",
      "Epoch 99. Loss: 0.005426714931592805, Train_acc 0.9980587121212121\n",
      "\n",
      "Epoch 99. Loss: 0.005503674605934736, Train_acc 0.998023343373494\n",
      "\n",
      "Epoch 99. Loss: 0.006172445182754621, Train_acc 0.9979883982035929\n",
      "\n",
      "Epoch 99. Loss: 0.011813981918770693, Train_acc 0.9979073660714286\n",
      "\n",
      "Epoch 99. Loss: 0.01064070106460478, Train_acc 0.9979197485207101\n",
      "\n",
      "Epoch 99. Loss: 0.009927562896881934, Train_acc 0.9979319852941176\n",
      "\n",
      "Epoch 99. Loss: 0.008985955931474882, Train_acc 0.9979440789473685\n",
      "\n",
      "Epoch 99. Loss: 0.00908499764373611, Train_acc 0.9979106104651163\n",
      "\n",
      "Epoch 99. Loss: 0.015688603880739605, Train_acc 0.9977420520231214\n",
      "\n",
      "Epoch 99. Loss: 0.014472296235362943, Train_acc 0.9977550287356322\n",
      "\n",
      "Epoch 99. Loss: 0.01325686793448799, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 99. Loss: 0.011976025347461759, Train_acc 0.9977805397727273\n",
      "\n",
      "Epoch 99. Loss: 0.010995046161830837, Train_acc 0.9977930790960452\n",
      "\n",
      "Epoch 99. Loss: 0.011071612153846395, Train_acc 0.9977615870786517\n",
      "\n",
      "Epoch 99. Loss: 0.010189955239950156, Train_acc 0.997774092178771\n",
      "\n",
      "Epoch 99. Loss: 0.01064761133234966, Train_acc 0.9977430555555555\n",
      "\n",
      "Epoch 99. Loss: 0.011531320076357736, Train_acc 0.997712361878453\n",
      "\n",
      "Epoch 99. Loss: 0.011402290488336754, Train_acc 0.9976820054945055\n",
      "\n",
      "Epoch 99. Loss: 0.012155340954709893, Train_acc 0.997651980874317\n",
      "\n",
      "Epoch 99. Loss: 0.015092665861590665, Train_acc 0.9976222826086957\n",
      "\n",
      "Epoch 99. Loss: 0.016154341692218747, Train_acc 0.9975929054054054\n",
      "\n",
      "Epoch 99. Loss: 0.016361140909334628, Train_acc 0.9975638440860215\n",
      "\n",
      "Epoch 99. Loss: 0.014812285451394491, Train_acc 0.997576871657754\n",
      "\n",
      "Epoch 99. Loss: 0.01339551957987257, Train_acc 0.9975897606382979\n",
      "\n",
      "Epoch 99. Loss: 0.013151147183410896, Train_acc 0.9975611772486772\n",
      "\n",
      "Epoch 99. Loss: 0.012110740540518678, Train_acc 0.9975740131578947\n",
      "\n",
      "Epoch 99. Loss: 0.010931224302431144, Train_acc 0.9975867146596858\n",
      "\n",
      "Epoch 99. Loss: 0.010588600299266159, Train_acc 0.99755859375\n",
      "\n",
      "Epoch 99. Loss: 0.01192981107071684, Train_acc 0.9975307642487047\n",
      "\n",
      "Epoch 99. Loss: 0.01174897625031155, Train_acc 0.9975032216494846\n",
      "\n",
      "Epoch 99. Loss: 0.011678194506306187, Train_acc 0.9974759615384615\n",
      "\n",
      "Epoch 99. Loss: 0.01580038339198119, Train_acc 0.99744\n",
      "\n",
      "Epoch 100. Loss: 0.014270612042057021, Train_acc 1.0\n",
      "\n",
      "Epoch 100. Loss: 0.012887990017906954, Train_acc 1.0\n",
      "\n",
      "Epoch 100. Loss: 0.01169623630686578, Train_acc 1.0\n",
      "\n",
      "Epoch 100. Loss: 0.011717655412351879, Train_acc 0.998046875\n",
      "\n",
      "Epoch 100. Loss: 0.013102285401817376, Train_acc 0.996875\n",
      "\n",
      "Epoch 100. Loss: 0.018651768419262364, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 100. Loss: 0.01718637613485747, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 100. Loss: 0.015550622540146797, Train_acc 0.99609375\n",
      "\n",
      "Epoch 100. Loss: 0.01414138907988878, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 100. Loss: 0.0134667515885831, Train_acc 0.996875\n",
      "\n",
      "Epoch 100. Loss: 0.013657935217648841, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 100. Loss: 0.012718961430159298, Train_acc 0.9967447916666666\n",
      "\n",
      "Epoch 100. Loss: 0.01261363873338737, Train_acc 0.9963942307692307\n",
      "\n",
      "Epoch 100. Loss: 0.01198028914144073, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 100. Loss: 0.011448830983881064, Train_acc 0.996875\n",
      "\n",
      "Epoch 100. Loss: 0.010461798889534689, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 100. Loss: 0.009736865381498948, Train_acc 0.9972426470588235\n",
      "\n",
      "Epoch 100. Loss: 0.008791029349361382, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 100. Loss: 0.008587554562444557, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 100. Loss: 0.008638506335784557, Train_acc 0.997265625\n",
      "\n",
      "Epoch 100. Loss: 0.007921546296830085, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 100. Loss: 0.007314675441191441, Train_acc 0.9975142045454546\n",
      "\n",
      "Epoch 100. Loss: 0.006909149936562042, Train_acc 0.9976222826086957\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100. Loss: 0.006472085304238135, Train_acc 0.9977213541666666\n",
      "\n",
      "Epoch 100. Loss: 0.0069018476751545686, Train_acc 0.9975\n",
      "\n",
      "Epoch 100. Loss: 0.0067370280255764385, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 100. Loss: 0.006533493925323158, Train_acc 0.9976851851851852\n",
      "\n",
      "Epoch 100. Loss: 0.005922838926569062, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 100. Loss: 0.005406777837821487, Train_acc 0.9978448275862069\n",
      "\n",
      "Epoch 100. Loss: 0.005800480346931795, Train_acc 0.99765625\n",
      "\n",
      "Epoch 100. Loss: 0.00529289075686748, Train_acc 0.9977318548387096\n",
      "\n",
      "Epoch 100. Loss: 0.004776474174424508, Train_acc 0.997802734375\n",
      "\n",
      "Epoch 100. Loss: 0.005396176206974237, Train_acc 0.9976325757575758\n",
      "\n",
      "Epoch 100. Loss: 0.004895958091753281, Train_acc 0.9977022058823529\n",
      "\n",
      "Epoch 100. Loss: 0.004468538367189518, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 100. Loss: 0.004964809197280602, Train_acc 0.9976128472222222\n",
      "\n",
      "Epoch 100. Loss: 0.0045314503763523376, Train_acc 0.9976773648648649\n",
      "\n",
      "Epoch 100. Loss: 0.004107551242432595, Train_acc 0.9977384868421053\n",
      "\n",
      "Epoch 100. Loss: 0.0037580413575291046, Train_acc 0.9977964743589743\n",
      "\n",
      "Epoch 100. Loss: 0.0033971870111051605, Train_acc 0.9978515625\n",
      "\n",
      "Epoch 100. Loss: 0.003094565452189042, Train_acc 0.9979039634146342\n",
      "\n",
      "Epoch 100. Loss: 0.002800212543512473, Train_acc 0.9979538690476191\n",
      "\n",
      "Epoch 100. Loss: 0.004014712284927151, Train_acc 0.9978197674418605\n",
      "\n",
      "Epoch 100. Loss: 0.003653513932938313, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 100. Loss: 0.003543967188267352, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 100. Loss: 0.00321628449997744, Train_acc 0.9979619565217391\n",
      "\n",
      "Epoch 100. Loss: 0.002937906798401693, Train_acc 0.9980053191489362\n",
      "\n",
      "Epoch 100. Loss: 0.002649397067169357, Train_acc 0.998046875\n",
      "\n",
      "Epoch 100. Loss: 0.0023888236848083636, Train_acc 0.9980867346938775\n",
      "\n",
      "Epoch 100. Loss: 0.0025696083069653066, Train_acc 0.998125\n",
      "\n",
      "Epoch 100. Loss: 0.0023319829669202047, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 100. Loss: 0.002128163770534144, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 100. Loss: 0.0020216212294713078, Train_acc 0.9982311320754716\n",
      "\n",
      "Epoch 100. Loss: 0.0019219254746406155, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 100. Loss: 0.0018625739386858532, Train_acc 0.9982954545454545\n",
      "\n",
      "Epoch 100. Loss: 0.001932017630369841, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 100. Loss: 0.0017783458249085804, Train_acc 0.9983552631578947\n",
      "\n",
      "Epoch 100. Loss: 0.0037291292667073306, Train_acc 0.9982489224137931\n",
      "\n",
      "Epoch 100. Loss: 0.003427540090344381, Train_acc 0.9982786016949152\n",
      "\n",
      "Epoch 100. Loss: 0.004042019353802829, Train_acc 0.9981770833333333\n",
      "\n",
      "Epoch 100. Loss: 0.00522613833680376, Train_acc 0.9980788934426229\n",
      "\n",
      "Epoch 100. Loss: 0.005420292894553763, Train_acc 0.9979838709677419\n",
      "\n",
      "Epoch 100. Loss: 0.004887388109966328, Train_acc 0.998015873015873\n",
      "\n",
      "Epoch 100. Loss: 0.004431052135920191, Train_acc 0.998046875\n",
      "\n",
      "Epoch 100. Loss: 0.0040589326025413704, Train_acc 0.9980769230769231\n",
      "\n",
      "Epoch 100. Loss: 0.005365269748988799, Train_acc 0.9979876893939394\n",
      "\n",
      "Epoch 100. Loss: 0.004855335304865735, Train_acc 0.9980177238805971\n",
      "\n",
      "Epoch 100. Loss: 0.004379976972637528, Train_acc 0.998046875\n",
      "\n",
      "Epoch 100. Loss: 0.003965561300106379, Train_acc 0.9980751811594203\n",
      "\n",
      "Epoch 100. Loss: 0.003579712219027832, Train_acc 0.9981026785714285\n",
      "\n",
      "Epoch 100. Loss: 0.003225546689301733, Train_acc 0.9981294014084507\n",
      "\n",
      "Epoch 100. Loss: 0.0029100965578795447, Train_acc 0.9981553819444444\n",
      "\n",
      "Epoch 100. Loss: 0.004310637104759304, Train_acc 0.9980736301369864\n",
      "\n",
      "Epoch 100. Loss: 0.003882514568999771, Train_acc 0.9980996621621622\n",
      "\n",
      "Epoch 100. Loss: 0.003500720578324468, Train_acc 0.998125\n",
      "\n",
      "Epoch 100. Loss: 0.006710846246384088, Train_acc 0.9979440789473685\n",
      "\n",
      "Epoch 100. Loss: 0.006376521345468614, Train_acc 0.9979707792207793\n",
      "\n",
      "Epoch 100. Loss: 0.00574054271118634, Train_acc 0.9979967948717948\n",
      "\n",
      "Epoch 100. Loss: 0.005296593831212459, Train_acc 0.9980221518987342\n",
      "\n",
      "Epoch 100. Loss: 0.006223118853924696, Train_acc 0.99794921875\n",
      "\n",
      "Epoch 100. Loss: 0.008044075677416943, Train_acc 0.9977816358024691\n",
      "\n",
      "Epoch 100. Loss: 0.007253922129736593, Train_acc 0.9978086890243902\n",
      "\n",
      "Epoch 100. Loss: 0.0072463827401991945, Train_acc 0.9977409638554217\n",
      "\n",
      "Epoch 100. Loss: 0.006541620278174282, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 100. Loss: 0.006717099678201617, Train_acc 0.9977022058823529\n",
      "\n",
      "Epoch 100. Loss: 0.008550502149775454, Train_acc 0.9974563953488372\n",
      "\n",
      "Epoch 100. Loss: 0.008488035944266465, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 100. Loss: 0.007816077468243254, Train_acc 0.9974254261363636\n",
      "\n",
      "Epoch 100. Loss: 0.007070731732108753, Train_acc 0.9974543539325843\n",
      "\n",
      "Epoch 100. Loss: 0.00639688209185304, Train_acc 0.9974826388888889\n",
      "\n",
      "Epoch 100. Loss: 0.011357494313919263, Train_acc 0.9974244505494505\n",
      "\n",
      "Epoch 100. Loss: 0.012383035937908635, Train_acc 0.9973675271739131\n",
      "\n",
      "Epoch 100. Loss: 0.011281966776740562, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 100. Loss: 0.013127044613145601, Train_acc 0.9973404255319149\n",
      "\n",
      "Epoch 100. Loss: 0.01411409913001908, Train_acc 0.9972861842105263\n",
      "\n",
      "Epoch 100. Loss: 0.018330781804011344, Train_acc 0.9971516927083334\n",
      "\n",
      "Epoch 100. Loss: 0.01827181650384016, Train_acc 0.9971005154639175\n",
      "\n",
      "Epoch 100. Loss: 0.016489215597453505, Train_acc 0.9971301020408163\n",
      "\n",
      "Epoch 100. Loss: 0.014904887713487334, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 100. Loss: 0.013658502640198517, Train_acc 0.9971875\n",
      "\n",
      "[Epoch 100 Batch 100] Loss: 0.01477082705515997 Training: accuracy=0.997138\n",
      "Epoch 100. Loss: 0.01477082705515997, Train_acc 0.997137995049505\n",
      "\n",
      "Epoch 100. Loss: 0.013352211209271488, Train_acc 0.9971660539215687\n",
      "\n",
      "Epoch 100. Loss: 0.012096201029092793, Train_acc 0.9971935679611651\n",
      "\n",
      "Epoch 100. Loss: 0.015348998886350444, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 100. Loss: 0.014899970176372217, Train_acc 0.9970238095238095\n",
      "\n",
      "Epoch 100. Loss: 0.014681467264193256, Train_acc 0.9969781839622641\n",
      "\n",
      "Epoch 100. Loss: 0.013346696442762427, Train_acc 0.9970064252336449\n",
      "\n",
      "Epoch 100. Loss: 0.016008765962480975, Train_acc 0.9969618055555556\n",
      "\n",
      "Epoch 100. Loss: 0.014524131985929882, Train_acc 0.9969896788990825\n",
      "\n",
      "Epoch 100. Loss: 0.013309597897837111, Train_acc 0.9970170454545455\n",
      "\n",
      "Epoch 100. Loss: 0.012891631975003674, Train_acc 0.996973536036036\n",
      "\n",
      "Epoch 100. Loss: 0.01172800955880382, Train_acc 0.9970005580357143\n",
      "\n",
      "Epoch 100. Loss: 0.0116515006292644, Train_acc 0.9969579646017699\n",
      "\n",
      "Epoch 100. Loss: 0.011469934307227985, Train_acc 0.996984649122807\n",
      "\n",
      "Epoch 100. Loss: 0.010869693537971785, Train_acc 0.9970108695652173\n",
      "\n",
      "Epoch 100. Loss: 0.011331845735390256, Train_acc 0.9969692887931034\n",
      "\n",
      "Epoch 100. Loss: 0.010291030235387476, Train_acc 0.9969951923076923\n",
      "\n",
      "Epoch 100. Loss: 0.010714220365700954, Train_acc 0.9969544491525424\n",
      "\n",
      "Epoch 100. Loss: 0.010998581597940177, Train_acc 0.9969143907563025\n",
      "\n",
      "Epoch 100. Loss: 0.011305828727545784, Train_acc 0.996875\n",
      "\n",
      "Epoch 100. Loss: 0.01051531275154273, Train_acc 0.996900826446281\n",
      "\n",
      "Epoch 100. Loss: 0.010355350640038731, Train_acc 0.9968621926229508\n",
      "\n",
      "Epoch 100. Loss: 0.010090328590902762, Train_acc 0.9968241869918699\n",
      "\n",
      "Epoch 100. Loss: 0.00937965683951951, Train_acc 0.9968497983870968\n",
      "\n",
      "Epoch 100. Loss: 0.008696836940035016, Train_acc 0.996875\n",
      "\n",
      "Epoch 100. Loss: 0.008261961865351906, Train_acc 0.9968998015873016\n",
      "\n",
      "Epoch 100. Loss: 0.007447742031651324, Train_acc 0.9969242125984252\n",
      "\n",
      "Epoch 100. Loss: 0.00886773662862562, Train_acc 0.996826171875\n",
      "\n",
      "Epoch 100. Loss: 0.008153208538084175, Train_acc 0.9968507751937985\n",
      "\n",
      "Epoch 100. Loss: 0.007486838434283983, Train_acc 0.996875\n",
      "\n",
      "Epoch 100. Loss: 0.006801594876012997, Train_acc 0.9968988549618321\n",
      "\n",
      "Epoch 100. Loss: 0.006535970512266573, Train_acc 0.9969223484848485\n",
      "\n",
      "Epoch 100. Loss: 0.006019452677114115, Train_acc 0.9969454887218046\n",
      "\n",
      "Epoch 100. Loss: 0.005497129889955346, Train_acc 0.9969682835820896\n",
      "\n",
      "Epoch 100. Loss: 0.006013451560703121, Train_acc 0.9969328703703704\n",
      "\n",
      "Epoch 100. Loss: 0.005443713147046524, Train_acc 0.9969554227941176\n",
      "\n",
      "Epoch 100. Loss: 0.005110514359975479, Train_acc 0.9969776459854015\n",
      "\n",
      "Epoch 100. Loss: 0.005102978608955104, Train_acc 0.9969995471014492\n",
      "\n",
      "Epoch 100. Loss: 0.004695037988453352, Train_acc 0.9970211330935251\n",
      "\n",
      "Epoch 100. Loss: 0.004258859292021091, Train_acc 0.9970424107142857\n",
      "\n",
      "Epoch 100. Loss: 0.003889705680717404, Train_acc 0.9970633865248227\n",
      "\n",
      "Epoch 100. Loss: 0.0035708247208436953, Train_acc 0.9970840669014085\n",
      "\n",
      "Epoch 100. Loss: 0.0032389873158407403, Train_acc 0.997104458041958\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100. Loss: 0.0030428830264893642, Train_acc 0.9971245659722222\n",
      "\n",
      "Epoch 100. Loss: 0.002880306163777781, Train_acc 0.9971443965517242\n",
      "\n",
      "Epoch 100. Loss: 0.002717080129846816, Train_acc 0.997163955479452\n",
      "\n",
      "Epoch 100. Loss: 0.002487610127654196, Train_acc 0.9971832482993197\n",
      "\n",
      "Epoch 100. Loss: 0.0022837160397613985, Train_acc 0.9972022804054054\n",
      "\n",
      "Epoch 100. Loss: 0.002096963160720947, Train_acc 0.9972210570469798\n",
      "\n",
      "Epoch 100. Loss: 0.0040431828649230145, Train_acc 0.9971875\n",
      "\n",
      "Epoch 100. Loss: 0.0037482640028308934, Train_acc 0.9972061258278145\n",
      "\n",
      "Epoch 100. Loss: 0.0036704751146117843, Train_acc 0.9972245065789473\n",
      "\n",
      "Epoch 100. Loss: 0.0033501210611396283, Train_acc 0.9972426470588235\n",
      "\n",
      "Epoch 100. Loss: 0.0035281436880379843, Train_acc 0.997260551948052\n",
      "\n",
      "Epoch 100. Loss: 0.003383344011414045, Train_acc 0.9972782258064516\n",
      "\n",
      "Epoch 100. Loss: 0.00331643796342581, Train_acc 0.9972956730769231\n",
      "\n",
      "Epoch 100. Loss: 0.006424045500558342, Train_acc 0.9972133757961783\n",
      "\n",
      "Epoch 100. Loss: 0.005815778244780988, Train_acc 0.9972310126582279\n",
      "\n",
      "Epoch 100. Loss: 0.00568283447667732, Train_acc 0.997248427672956\n",
      "\n",
      "Epoch 100. Loss: 0.005414411566061743, Train_acc 0.997265625\n",
      "\n",
      "Epoch 100. Loss: 0.004943860658208699, Train_acc 0.9972826086956522\n",
      "\n",
      "Epoch 100. Loss: 0.006854953956484947, Train_acc 0.9972511574074074\n",
      "\n",
      "Epoch 100. Loss: 0.009063337825429577, Train_acc 0.9972200920245399\n",
      "\n",
      "Epoch 100. Loss: 0.008210761518575672, Train_acc 0.9972370426829268\n",
      "\n",
      "Epoch 100. Loss: 0.007538440329438082, Train_acc 0.9972537878787879\n",
      "\n",
      "Epoch 100. Loss: 0.006820414075047156, Train_acc 0.9972703313253012\n",
      "\n",
      "Epoch 100. Loss: 0.006692562777957661, Train_acc 0.9972866766467066\n",
      "\n",
      "Epoch 100. Loss: 0.006093305356795797, Train_acc 0.9973028273809523\n",
      "\n",
      "Epoch 100. Loss: 0.005534672913789191, Train_acc 0.9973187869822485\n",
      "\n",
      "Epoch 100. Loss: 0.005234589251434301, Train_acc 0.9973345588235294\n",
      "\n",
      "Epoch 100. Loss: 0.00475068244934387, Train_acc 0.9973501461988304\n",
      "\n",
      "Epoch 100. Loss: 0.004346794490295414, Train_acc 0.9973655523255814\n",
      "\n",
      "Epoch 100. Loss: 0.003951628729800371, Train_acc 0.9973807803468208\n",
      "\n",
      "Epoch 100. Loss: 0.0037678689100742228, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 100. Loss: 0.004728363354212036, Train_acc 0.9973660714285715\n",
      "\n",
      "Epoch 100. Loss: 0.005032159288635245, Train_acc 0.9973810369318182\n",
      "\n",
      "Epoch 100. Loss: 0.0048480283039752155, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 100. Loss: 0.004462854974924193, Train_acc 0.9974104634831461\n",
      "\n",
      "Epoch 100. Loss: 0.004142396640423983, Train_acc 0.9974249301675978\n",
      "\n",
      "Epoch 100. Loss: 0.003926444493213937, Train_acc 0.9974392361111111\n",
      "\n",
      "Epoch 100. Loss: 0.00360994353986388, Train_acc 0.9974533839779005\n",
      "\n",
      "Epoch 100. Loss: 0.0033062902162106834, Train_acc 0.9974673763736264\n",
      "\n",
      "Epoch 100. Loss: 0.003083529722583175, Train_acc 0.9974812158469946\n",
      "\n",
      "Epoch 100. Loss: 0.002905184818260563, Train_acc 0.9974949048913043\n",
      "\n",
      "Epoch 100. Loss: 0.0032630231242949, Train_acc 0.9974662162162162\n",
      "\n",
      "Epoch 100. Loss: 0.0030290557349669993, Train_acc 0.9974798387096774\n",
      "\n",
      "Epoch 100. Loss: 0.002849509913357919, Train_acc 0.9974933155080213\n",
      "\n",
      "Epoch 100. Loss: 0.003366214944690012, Train_acc 0.9974650930851063\n",
      "\n",
      "Epoch 100. Loss: 0.0031169025085109863, Train_acc 0.9974785052910053\n",
      "\n",
      "Epoch 100. Loss: 0.002814450110305926, Train_acc 0.9974917763157894\n",
      "\n",
      "Epoch 100. Loss: 0.003205403886267168, Train_acc 0.9974640052356021\n",
      "\n",
      "Epoch 100. Loss: 0.002903384057756027, Train_acc 0.9974772135416666\n",
      "\n",
      "Epoch 100. Loss: 0.002818234781318093, Train_acc 0.9974902849740933\n",
      "\n",
      "Epoch 100. Loss: 0.0025868976538511524, Train_acc 0.9975032216494846\n",
      "\n",
      "Epoch 100. Loss: 0.0023304072194589177, Train_acc 0.9975160256410256\n",
      "\n",
      "Epoch 100. Loss: 0.002121913232734546, Train_acc 0.99752\n",
      "\n",
      "Epoch 101. Loss: 0.0021919239185727345, Train_acc 1.0\n",
      "\n",
      "Epoch 101. Loss: 0.002398738030118648, Train_acc 1.0\n",
      "\n",
      "Epoch 101. Loss: 0.0022827550540510454, Train_acc 1.0\n",
      "\n",
      "Epoch 101. Loss: 0.0021047218287678334, Train_acc 1.0\n",
      "\n",
      "Epoch 101. Loss: 0.0018956257062816622, Train_acc 1.0\n",
      "\n",
      "Epoch 101. Loss: 0.0017427976586723182, Train_acc 1.0\n",
      "\n",
      "Epoch 101. Loss: 0.001613468788049342, Train_acc 1.0\n",
      "\n",
      "Epoch 101. Loss: 0.0015066759334899978, Train_acc 1.0\n",
      "\n",
      "Epoch 101. Loss: 0.001374924967009302, Train_acc 1.0\n",
      "\n",
      "Epoch 101. Loss: 0.0012482435348753233, Train_acc 1.0\n",
      "\n",
      "Epoch 101. Loss: 0.001233515502829024, Train_acc 1.0\n",
      "\n",
      "Epoch 101. Loss: 0.0011666212858128567, Train_acc 1.0\n",
      "\n",
      "Epoch 101. Loss: 0.0012509673234180826, Train_acc 1.0\n",
      "\n",
      "Epoch 101. Loss: 0.0011302440775210942, Train_acc 1.0\n",
      "\n",
      "Epoch 101. Loss: 0.0012192030471064406, Train_acc 1.0\n",
      "\n",
      "Epoch 101. Loss: 0.0011108262622857323, Train_acc 1.0\n",
      "\n",
      "Epoch 101. Loss: 0.0016716668431762665, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 101. Loss: 0.002270070132595641, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 101. Loss: 0.002052829446611506, Train_acc 0.9991776315789473\n",
      "\n",
      "Epoch 101. Loss: 0.0018482667934233996, Train_acc 0.99921875\n",
      "\n",
      "Epoch 101. Loss: 0.0016678264673293244, Train_acc 0.9992559523809523\n",
      "\n",
      "Epoch 101. Loss: 0.001661018391448165, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 101. Loss: 0.0015742293215338036, Train_acc 0.9993206521739131\n",
      "\n",
      "Epoch 101. Loss: 0.0020735332526156587, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 101. Loss: 0.0022216132740577412, Train_acc 0.9990625\n",
      "\n",
      "Epoch 101. Loss: 0.002002439058308661, Train_acc 0.9990985576923077\n",
      "\n",
      "Epoch 101. Loss: 0.0018026653433215658, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 101. Loss: 0.0016472843855570218, Train_acc 0.9991629464285714\n",
      "\n",
      "Epoch 101. Loss: 0.001575889800875675, Train_acc 0.9991918103448276\n",
      "\n",
      "Epoch 101. Loss: 0.0014215070326288415, Train_acc 0.99921875\n",
      "\n",
      "Epoch 101. Loss: 0.00128496982161477, Train_acc 0.9992439516129032\n",
      "\n",
      "Epoch 101. Loss: 0.0011854872338390332, Train_acc 0.999267578125\n",
      "\n",
      "Epoch 101. Loss: 0.001091140900796218, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 101. Loss: 0.0010083798693546475, Train_acc 0.9993106617647058\n",
      "\n",
      "Epoch 101. Loss: 0.0009812691259991069, Train_acc 0.9993303571428571\n",
      "\n",
      "Epoch 101. Loss: 0.0009221008540519049, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 101. Loss: 0.0008355532732012078, Train_acc 0.9993665540540541\n",
      "\n",
      "Epoch 101. Loss: 0.0007561174388319362, Train_acc 0.9993832236842105\n",
      "\n",
      "Epoch 101. Loss: 0.0007046669441150971, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 101. Loss: 0.0019054610588569061, Train_acc 0.99921875\n",
      "\n",
      "Epoch 101. Loss: 0.0017282811897883072, Train_acc 0.9992378048780488\n",
      "\n",
      "Epoch 101. Loss: 0.0015766559709071818, Train_acc 0.9992559523809523\n",
      "\n",
      "Epoch 101. Loss: 0.0014220617421537233, Train_acc 0.9992732558139535\n",
      "\n",
      "Epoch 101. Loss: 0.0013210554305461057, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 101. Loss: 0.0012549170370583541, Train_acc 0.9993055555555556\n",
      "\n",
      "Epoch 101. Loss: 0.0011930597992667385, Train_acc 0.9993206521739131\n",
      "\n",
      "Epoch 101. Loss: 0.0026638636221226007, Train_acc 0.9991688829787234\n",
      "\n",
      "Epoch 101. Loss: 0.0024192101538573867, Train_acc 0.9991861979166666\n",
      "\n",
      "Epoch 101. Loss: 0.0022033807253864926, Train_acc 0.9992028061224489\n",
      "\n",
      "Epoch 101. Loss: 0.0020152903343677916, Train_acc 0.99921875\n",
      "\n",
      "Epoch 101. Loss: 0.0019258056348769722, Train_acc 0.999234068627451\n",
      "\n",
      "Epoch 101. Loss: 0.0017559452007348188, Train_acc 0.9992487980769231\n",
      "\n",
      "Epoch 101. Loss: 0.0033445477694393558, Train_acc 0.9991155660377359\n",
      "\n",
      "Epoch 101. Loss: 0.0034888211546201735, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 101. Loss: 0.0031457079113008093, Train_acc 0.9991477272727273\n",
      "\n",
      "Epoch 101. Loss: 0.0030275130741356177, Train_acc 0.9991629464285714\n",
      "\n",
      "Epoch 101. Loss: 0.002770314342915642, Train_acc 0.9991776315789473\n",
      "\n",
      "Epoch 101. Loss: 0.0026132689910512816, Train_acc 0.9991918103448276\n",
      "\n",
      "Epoch 101. Loss: 0.0024245849209824934, Train_acc 0.9992055084745762\n",
      "\n",
      "Epoch 101. Loss: 0.007313076790374493, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 101. Loss: 0.011612857850970604, Train_acc 0.9988473360655737\n",
      "\n",
      "Epoch 101. Loss: 0.010468670739434666, Train_acc 0.9988659274193549\n",
      "\n",
      "Epoch 101. Loss: 0.009441165544585704, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 101. Loss: 0.00857717301699004, Train_acc 0.9989013671875\n",
      "\n",
      "Epoch 101. Loss: 0.008306717695690526, Train_acc 0.9989182692307692\n",
      "\n",
      "Epoch 101. Loss: 0.007724358107914627, Train_acc 0.9989346590909091\n",
      "\n",
      "Epoch 101. Loss: 0.00781472532788226, Train_acc 0.9988339552238806\n",
      "\n",
      "Epoch 101. Loss: 0.007125979123969903, Train_acc 0.9988511029411765\n",
      "\n",
      "Epoch 101. Loss: 0.006472430916150687, Train_acc 0.9988677536231884\n",
      "\n",
      "Epoch 101. Loss: 0.006382302287835131, Train_acc 0.9988839285714286\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101. Loss: 0.005744831031470753, Train_acc 0.998899647887324\n",
      "\n",
      "Epoch 101. Loss: 0.005234143059023551, Train_acc 0.9989149305555556\n",
      "\n",
      "Epoch 101. Loss: 0.004718493355317598, Train_acc 0.998929794520548\n",
      "\n",
      "Epoch 101. Loss: 0.0044178076281058964, Train_acc 0.9989442567567568\n",
      "\n",
      "Epoch 101. Loss: 0.004007304388089278, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 101. Loss: 0.0036444931931944257, Train_acc 0.9989720394736842\n",
      "\n",
      "Epoch 101. Loss: 0.003373060431968933, Train_acc 0.9989853896103896\n",
      "\n",
      "Epoch 101. Loss: 0.0030385825527690768, Train_acc 0.9989983974358975\n",
      "\n",
      "Epoch 101. Loss: 0.002860651531095021, Train_acc 0.9990110759493671\n",
      "\n",
      "Epoch 101. Loss: 0.0025869338279415153, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 101. Loss: 0.0025360372078447628, Train_acc 0.9990354938271605\n",
      "\n",
      "Epoch 101. Loss: 0.0029676771215673466, Train_acc 0.999047256097561\n",
      "\n",
      "Epoch 101. Loss: 0.0027691619736136064, Train_acc 0.999058734939759\n",
      "\n",
      "Epoch 101. Loss: 0.0045131760888261555, Train_acc 0.9989769345238095\n",
      "\n",
      "Epoch 101. Loss: 0.004302656751204696, Train_acc 0.9989889705882353\n",
      "\n",
      "Epoch 101. Loss: 0.0038859129456346856, Train_acc 0.999000726744186\n",
      "\n",
      "Epoch 101. Loss: 0.007159465671270993, Train_acc 0.998742816091954\n",
      "\n",
      "Epoch 101. Loss: 0.006666762992611444, Train_acc 0.9987571022727273\n",
      "\n",
      "Epoch 101. Loss: 0.006424198793504462, Train_acc 0.9987710674157303\n",
      "\n",
      "Epoch 101. Loss: 0.006268596171632849, Train_acc 0.9987847222222223\n",
      "\n",
      "Epoch 101. Loss: 0.005895229963142076, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 101. Loss: 0.007921712916503905, Train_acc 0.9987262228260869\n",
      "\n",
      "Epoch 101. Loss: 0.00907852168060293, Train_acc 0.9986559139784946\n",
      "\n",
      "Epoch 101. Loss: 0.010053091669174586, Train_acc 0.9985871010638298\n",
      "\n",
      "Epoch 101. Loss: 0.009103105985213864, Train_acc 0.9986019736842106\n",
      "\n",
      "Epoch 101. Loss: 0.00849602111816962, Train_acc 0.9986165364583334\n",
      "\n",
      "Epoch 101. Loss: 0.008009064328809613, Train_acc 0.9986307989690721\n",
      "\n",
      "Epoch 101. Loss: 0.00733628466898057, Train_acc 0.9986447704081632\n",
      "\n",
      "Epoch 101. Loss: 0.009372089164023278, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 101. Loss: 0.008555484961068342, Train_acc 0.99859375\n",
      "\n",
      "[Epoch 101 Batch 100] Loss: 0.007775098969761172 Training: accuracy=0.998608\n",
      "Epoch 101. Loss: 0.007775098969761172, Train_acc 0.9986076732673267\n",
      "\n",
      "Epoch 101. Loss: 0.010015221736035026, Train_acc 0.9984681372549019\n",
      "\n",
      "Epoch 101. Loss: 0.009030411693468434, Train_acc 0.9984830097087378\n",
      "\n",
      "Epoch 101. Loss: 0.008936637314869234, Train_acc 0.9984224759615384\n",
      "\n",
      "Epoch 101. Loss: 0.008589047776353302, Train_acc 0.9984375\n",
      "\n",
      "Epoch 101. Loss: 0.008514812256418414, Train_acc 0.9983785377358491\n",
      "\n",
      "Epoch 101. Loss: 0.007753935690412147, Train_acc 0.998393691588785\n",
      "\n",
      "Epoch 101. Loss: 0.008496382037421367, Train_acc 0.9983362268518519\n",
      "\n",
      "Epoch 101. Loss: 0.007652958950124904, Train_acc 0.9983514908256881\n",
      "\n",
      "Epoch 101. Loss: 0.0069697608630115305, Train_acc 0.9983664772727273\n",
      "\n",
      "Epoch 101. Loss: 0.00692363899918686, Train_acc 0.9983811936936937\n",
      "\n",
      "Epoch 101. Loss: 0.0071680677038933995, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 101. Loss: 0.0073884727264201195, Train_acc 0.9982715707964602\n",
      "\n",
      "Epoch 101. Loss: 0.006981277408689757, Train_acc 0.9982867324561403\n",
      "\n",
      "Epoch 101. Loss: 0.006385753580639958, Train_acc 0.9983016304347826\n",
      "\n",
      "Epoch 101. Loss: 0.0061302453070523144, Train_acc 0.9983162715517241\n",
      "\n",
      "Epoch 101. Loss: 0.006497389264223737, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 101. Loss: 0.011164810079918291, Train_acc 0.9982123940677966\n",
      "\n",
      "Epoch 101. Loss: 0.010059871181058742, Train_acc 0.9982274159663865\n",
      "\n",
      "Epoch 101. Loss: 0.009087677841810084, Train_acc 0.9982421875\n",
      "\n",
      "Epoch 101. Loss: 0.008296056910055307, Train_acc 0.9982567148760331\n",
      "\n",
      "Epoch 101. Loss: 0.008350308286724175, Train_acc 0.9982710040983607\n",
      "\n",
      "Epoch 101. Loss: 0.008595506125758007, Train_acc 0.9982215447154471\n",
      "\n",
      "Epoch 101. Loss: 0.011217577553453966, Train_acc 0.9981728830645161\n",
      "\n",
      "Epoch 101. Loss: 0.013849331405755512, Train_acc 0.9980625\n",
      "\n",
      "Epoch 101. Loss: 0.012508470963981716, Train_acc 0.998077876984127\n",
      "\n",
      "Epoch 101. Loss: 0.013644031421733172, Train_acc 0.9980314960629921\n",
      "\n",
      "Epoch 101. Loss: 0.012398195980988983, Train_acc 0.998046875\n",
      "\n",
      "Epoch 101. Loss: 0.011243254596128056, Train_acc 0.998062015503876\n",
      "\n",
      "Epoch 101. Loss: 0.010138297994708298, Train_acc 0.9980769230769231\n",
      "\n",
      "Epoch 101. Loss: 0.01003607159758384, Train_acc 0.998031965648855\n",
      "\n",
      "Epoch 101. Loss: 0.009371965649245159, Train_acc 0.998046875\n",
      "\n",
      "Epoch 101. Loss: 0.008523354258264653, Train_acc 0.998061560150376\n",
      "\n",
      "Epoch 101. Loss: 0.009859544367604452, Train_acc 0.9980177238805971\n",
      "\n",
      "Epoch 101. Loss: 0.008975275873925982, Train_acc 0.9980324074074074\n",
      "\n",
      "Epoch 101. Loss: 0.009319298136043576, Train_acc 0.9979894301470589\n",
      "\n",
      "Epoch 101. Loss: 0.010107865334577585, Train_acc 0.9979470802919708\n",
      "\n",
      "Epoch 101. Loss: 0.009414497213425242, Train_acc 0.9979619565217391\n",
      "\n",
      "Epoch 101. Loss: 0.008500772685732247, Train_acc 0.997976618705036\n",
      "\n",
      "Epoch 101. Loss: 0.007741473000113638, Train_acc 0.9979910714285715\n",
      "\n",
      "Epoch 101. Loss: 0.007104970380319182, Train_acc 0.9980053191489362\n",
      "\n",
      "Epoch 101. Loss: 0.03219639125286313, Train_acc 0.9979643485915493\n",
      "\n",
      "Epoch 101. Loss: 0.029221511220615556, Train_acc 0.997978583916084\n",
      "\n",
      "Epoch 101. Loss: 0.02632532020309399, Train_acc 0.9979926215277778\n",
      "\n",
      "Epoch 101. Loss: 0.02472472619174865, Train_acc 0.9979525862068965\n",
      "\n",
      "Epoch 101. Loss: 0.022708029569243914, Train_acc 0.997966609589041\n",
      "\n",
      "Epoch 101. Loss: 0.020779608311330255, Train_acc 0.9979804421768708\n",
      "\n",
      "Epoch 101. Loss: 0.019543939341969768, Train_acc 0.9979413006756757\n",
      "\n",
      "Epoch 101. Loss: 0.021407192730785146, Train_acc 0.9979026845637584\n",
      "\n",
      "Epoch 101. Loss: 0.019594432485779287, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 101. Loss: 0.01954803514273181, Train_acc 0.9978787251655629\n",
      "\n",
      "Epoch 101. Loss: 0.01762006224602988, Train_acc 0.9978926809210527\n",
      "\n",
      "Epoch 101. Loss: 0.016434062037189577, Train_acc 0.997906454248366\n",
      "\n",
      "Epoch 101. Loss: 0.014983740353758433, Train_acc 0.9979200487012987\n",
      "\n",
      "Epoch 101. Loss: 0.013559599828914075, Train_acc 0.9979334677419355\n",
      "\n",
      "Epoch 101. Loss: 0.012736100431259216, Train_acc 0.9979467147435898\n",
      "\n",
      "Epoch 101. Loss: 0.011604995477885672, Train_acc 0.9979597929936306\n",
      "\n",
      "Epoch 101. Loss: 0.010556409820674958, Train_acc 0.9979727056962026\n",
      "\n",
      "Epoch 101. Loss: 0.01006512838617781, Train_acc 0.9979854559748428\n",
      "\n",
      "Epoch 101. Loss: 0.00919192549162718, Train_acc 0.997998046875\n",
      "\n",
      "Epoch 101. Loss: 0.00841882012002792, Train_acc 0.9980104813664596\n",
      "\n",
      "Epoch 101. Loss: 0.007619198831446479, Train_acc 0.998022762345679\n",
      "\n",
      "Epoch 101. Loss: 0.006917213840062181, Train_acc 0.9980348926380368\n",
      "\n",
      "Epoch 101. Loss: 0.006262780996680976, Train_acc 0.998046875\n",
      "\n",
      "Epoch 101. Loss: 0.005710243080155824, Train_acc 0.9980587121212121\n",
      "\n",
      "Epoch 101. Loss: 0.0054522544968248375, Train_acc 0.998070406626506\n",
      "\n",
      "Epoch 101. Loss: 0.00524355959566274, Train_acc 0.9980819610778443\n",
      "\n",
      "Epoch 101. Loss: 0.004764224584260631, Train_acc 0.9980933779761905\n",
      "\n",
      "Epoch 101. Loss: 0.0047058234694830016, Train_acc 0.9981046597633136\n",
      "\n",
      "Epoch 101. Loss: 0.004383002398992161, Train_acc 0.9981158088235295\n",
      "\n",
      "Epoch 101. Loss: 0.0043811703952413026, Train_acc 0.9981268274853801\n",
      "\n",
      "Epoch 101. Loss: 0.004521207141035309, Train_acc 0.9981377180232558\n",
      "\n",
      "Epoch 101. Loss: 0.004460652947488585, Train_acc 0.9981484826589595\n",
      "\n",
      "Epoch 101. Loss: 0.004199564451221966, Train_acc 0.9981591235632183\n",
      "\n",
      "Epoch 101. Loss: 0.0038333511452419405, Train_acc 0.9981696428571428\n",
      "\n",
      "Epoch 101. Loss: 0.0036147481465266212, Train_acc 0.9981800426136364\n",
      "\n",
      "Epoch 101. Loss: 0.003288589782395309, Train_acc 0.998190324858757\n",
      "\n",
      "Epoch 101. Loss: 0.0030000725461432824, Train_acc 0.9982004915730337\n",
      "\n",
      "Epoch 101. Loss: 0.0035607112860729837, Train_acc 0.9981668994413407\n",
      "\n",
      "Epoch 101. Loss: 0.0034357971911699067, Train_acc 0.9981770833333333\n",
      "\n",
      "Epoch 101. Loss: 0.004146268897360906, Train_acc 0.9981439917127072\n",
      "\n",
      "Epoch 101. Loss: 0.0037724087208342656, Train_acc 0.9981541895604396\n",
      "\n",
      "Epoch 101. Loss: 0.003440692499819102, Train_acc 0.9981642759562842\n",
      "\n",
      "Epoch 101. Loss: 0.003125327720442781, Train_acc 0.9981742527173914\n",
      "\n",
      "Epoch 101. Loss: 0.0028226600889990987, Train_acc 0.9981841216216216\n",
      "\n",
      "Epoch 101. Loss: 0.0025595162527700934, Train_acc 0.9981938844086021\n",
      "\n",
      "Epoch 101. Loss: 0.0023644009463734037, Train_acc 0.9982035427807486\n",
      "\n",
      "Epoch 101. Loss: 0.0023845811293867177, Train_acc 0.9982130984042553\n",
      "\n",
      "Epoch 101. Loss: 0.0021603400018851337, Train_acc 0.9982225529100529\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101. Loss: 0.001956824075769052, Train_acc 0.9982319078947368\n",
      "\n",
      "Epoch 101. Loss: 0.001997952272302507, Train_acc 0.998241164921466\n",
      "\n",
      "Epoch 101. Loss: 0.001817565666373665, Train_acc 0.9982503255208334\n",
      "\n",
      "Epoch 101. Loss: 0.002751872731807317, Train_acc 0.9982189119170984\n",
      "\n",
      "Epoch 101. Loss: 0.0024830778690590393, Train_acc 0.9982280927835051\n",
      "\n",
      "Epoch 101. Loss: 0.0022482070645613015, Train_acc 0.9982371794871795\n",
      "\n",
      "Epoch 101. Loss: 0.0020426755125481297, Train_acc 0.99824\n",
      "\n",
      "Epoch 102. Loss: 0.0019656123641088675, Train_acc 1.0\n",
      "\n",
      "Epoch 102. Loss: 0.0018562301908188375, Train_acc 1.0\n",
      "\n",
      "Epoch 102. Loss: 0.0022451869601088745, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 102. Loss: 0.0020421738454876343, Train_acc 0.998046875\n",
      "\n",
      "Epoch 102. Loss: 0.001852671932418447, Train_acc 0.9984375\n",
      "\n",
      "Epoch 102. Loss: 0.0017189946896300926, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 102. Loss: 0.0017162752632431282, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 102. Loss: 0.0017777038537679995, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 102. Loss: 0.0016449855692954854, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 102. Loss: 0.001490598769367078, Train_acc 0.99921875\n",
      "\n",
      "Epoch 102. Loss: 0.0013525763607876147, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 102. Loss: 0.0012209989364481185, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 102. Loss: 0.0011430245650573415, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 102. Loss: 0.0012957730826226332, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 102. Loss: 0.002384836112989854, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 102. Loss: 0.002191956440324445, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 102. Loss: 0.0019909501344442977, Train_acc 0.9990808823529411\n",
      "\n",
      "Epoch 102. Loss: 0.001798652748429346, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 102. Loss: 0.005925601175573678, Train_acc 0.9979440789473685\n",
      "\n",
      "Epoch 102. Loss: 0.005358208077355589, Train_acc 0.998046875\n",
      "\n",
      "Epoch 102. Loss: 0.004889624638404875, Train_acc 0.9981398809523809\n",
      "\n",
      "Epoch 102. Loss: 0.004721655794535365, Train_acc 0.9982244318181818\n",
      "\n",
      "Epoch 102. Loss: 0.0077332312004753535, Train_acc 0.9979619565217391\n",
      "\n",
      "Epoch 102. Loss: 0.015243225169508628, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 102. Loss: 0.013745187506369142, Train_acc 0.9975\n",
      "\n",
      "Epoch 102. Loss: 0.01243544792186444, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 102. Loss: 0.011217047151170447, Train_acc 0.9976851851851852\n",
      "\n",
      "Epoch 102. Loss: 0.010116148924517988, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 102. Loss: 0.009244434433766477, Train_acc 0.9978448275862069\n",
      "\n",
      "Epoch 102. Loss: 0.011755482760895736, Train_acc 0.99765625\n",
      "\n",
      "Epoch 102. Loss: 0.011650966062691314, Train_acc 0.9974798387096774\n",
      "\n",
      "Epoch 102. Loss: 0.012561573643576953, Train_acc 0.997314453125\n",
      "\n",
      "Epoch 102. Loss: 0.011922872249715197, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 102. Loss: 0.01075236573191859, Train_acc 0.9974724264705882\n",
      "\n",
      "Epoch 102. Loss: 0.009955333791649737, Train_acc 0.9975446428571428\n",
      "\n",
      "Epoch 102. Loss: 0.009456779284009098, Train_acc 0.9976128472222222\n",
      "\n",
      "Epoch 102. Loss: 0.00979136358370968, Train_acc 0.9974662162162162\n",
      "\n",
      "Epoch 102. Loss: 0.009145020748896195, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 102. Loss: 0.009727037449827308, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 102. Loss: 0.009271255312622054, Train_acc 0.9974609375\n",
      "\n",
      "Epoch 102. Loss: 0.00933480926894587, Train_acc 0.9973323170731707\n",
      "\n",
      "Epoch 102. Loss: 0.00856436855906345, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 102. Loss: 0.007836472425810375, Train_acc 0.9974563953488372\n",
      "\n",
      "Epoch 102. Loss: 0.007219117171218436, Train_acc 0.9975142045454546\n",
      "\n",
      "Epoch 102. Loss: 0.006553314158399053, Train_acc 0.9975694444444444\n",
      "\n",
      "Epoch 102. Loss: 0.005998397907629592, Train_acc 0.9976222826086957\n",
      "\n",
      "Epoch 102. Loss: 0.005653471536351725, Train_acc 0.9976728723404256\n",
      "\n",
      "Epoch 102. Loss: 0.005111379826091645, Train_acc 0.9977213541666666\n",
      "\n",
      "Epoch 102. Loss: 0.004994647268077359, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 102. Loss: 0.0077814470055287705, Train_acc 0.99765625\n",
      "\n",
      "Epoch 102. Loss: 0.007126293800275978, Train_acc 0.9977022058823529\n",
      "\n",
      "Epoch 102. Loss: 0.006552717527953348, Train_acc 0.9977463942307693\n",
      "\n",
      "Epoch 102. Loss: 0.00608318333612686, Train_acc 0.9977889150943396\n",
      "\n",
      "Epoch 102. Loss: 0.005754406455860783, Train_acc 0.9978298611111112\n",
      "\n",
      "Epoch 102. Loss: 0.006851869072353467, Train_acc 0.9977272727272727\n",
      "\n",
      "Epoch 102. Loss: 0.0062193786315640435, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 102. Loss: 0.005614562959318962, Train_acc 0.9978070175438597\n",
      "\n",
      "Epoch 102. Loss: 0.005071293575735094, Train_acc 0.9978448275862069\n",
      "\n",
      "Epoch 102. Loss: 0.004645744676370503, Train_acc 0.9978813559322034\n",
      "\n",
      "Epoch 102. Loss: 0.005007098639737739, Train_acc 0.9977864583333333\n",
      "\n",
      "Epoch 102. Loss: 0.004564388018326766, Train_acc 0.9978227459016393\n",
      "\n",
      "Epoch 102. Loss: 0.004321414171362049, Train_acc 0.9978578629032258\n",
      "\n",
      "Epoch 102. Loss: 0.003983073439361492, Train_acc 0.9978918650793651\n",
      "\n",
      "Epoch 102. Loss: 0.003610765766622839, Train_acc 0.9979248046875\n",
      "\n",
      "Epoch 102. Loss: 0.0033050319629361192, Train_acc 0.9979567307692307\n",
      "\n",
      "Epoch 102. Loss: 0.002993698126808923, Train_acc 0.9979876893939394\n",
      "\n",
      "Epoch 102. Loss: 0.002743693660913666, Train_acc 0.9980177238805971\n",
      "\n",
      "Epoch 102. Loss: 0.0025134830682026314, Train_acc 0.998046875\n",
      "\n",
      "Epoch 102. Loss: 0.0034602340355706484, Train_acc 0.9979619565217391\n",
      "\n",
      "Epoch 102. Loss: 0.003193260890514085, Train_acc 0.9979910714285715\n",
      "\n",
      "Epoch 102. Loss: 0.0029080583849266286, Train_acc 0.9980193661971831\n",
      "\n",
      "Epoch 102. Loss: 0.0026350766882665, Train_acc 0.998046875\n",
      "\n",
      "Epoch 102. Loss: 0.0023978648832302875, Train_acc 0.9980736301369864\n",
      "\n",
      "Epoch 102. Loss: 0.0027214854788805472, Train_acc 0.9980996621621622\n",
      "\n",
      "Epoch 102. Loss: 0.002490888589061276, Train_acc 0.998125\n",
      "\n",
      "Epoch 102. Loss: 0.0022555766860484117, Train_acc 0.9981496710526315\n",
      "\n",
      "Epoch 102. Loss: 0.0022696875944217174, Train_acc 0.9981737012987013\n",
      "\n",
      "Epoch 102. Loss: 0.002156755710290831, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 102. Loss: 0.002154445791860189, Train_acc 0.9982199367088608\n",
      "\n",
      "Epoch 102. Loss: 0.002002334873038321, Train_acc 0.9982421875\n",
      "\n",
      "Epoch 102. Loss: 0.0020265128034646415, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 102. Loss: 0.0019305184702913555, Train_acc 0.9982850609756098\n",
      "\n",
      "Epoch 102. Loss: 0.002410974429175907, Train_acc 0.9983057228915663\n",
      "\n",
      "Epoch 102. Loss: 0.002192896879236798, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 102. Loss: 0.001986132176090092, Train_acc 0.9983455882352941\n",
      "\n",
      "Epoch 102. Loss: 0.0022028304328341576, Train_acc 0.9983648255813954\n",
      "\n",
      "Epoch 102. Loss: 0.0019865721160640492, Train_acc 0.9983836206896551\n",
      "\n",
      "Epoch 102. Loss: 0.0017929696235343693, Train_acc 0.9984019886363636\n",
      "\n",
      "Epoch 102. Loss: 0.0016222425496313704, Train_acc 0.9984199438202247\n",
      "\n",
      "Epoch 102. Loss: 0.0023917688120067477, Train_acc 0.9983506944444445\n",
      "\n",
      "Epoch 102. Loss: 0.002647217815845641, Train_acc 0.9983688186813187\n",
      "\n",
      "Epoch 102. Loss: 0.0024337634327823814, Train_acc 0.9983865489130435\n",
      "\n",
      "Epoch 102. Loss: 0.0022264763223940787, Train_acc 0.9984038978494624\n",
      "\n",
      "Epoch 102. Loss: 0.0020299314733130923, Train_acc 0.9984208776595744\n",
      "\n",
      "Epoch 102. Loss: 0.0019747972865357868, Train_acc 0.9984375\n",
      "\n",
      "Epoch 102. Loss: 0.002070419719841022, Train_acc 0.9984537760416666\n",
      "\n",
      "Epoch 102. Loss: 0.0019546405906182723, Train_acc 0.9984697164948454\n",
      "\n",
      "Epoch 102. Loss: 0.001770228676975389, Train_acc 0.9984853316326531\n",
      "\n",
      "Epoch 102. Loss: 0.0016030262362085235, Train_acc 0.9985006313131313\n",
      "\n",
      "Epoch 102. Loss: 0.0016027657625337646, Train_acc 0.998515625\n",
      "\n",
      "[Epoch 102 Batch 100] Loss: 0.0014540613276553152 Training: accuracy=0.998530\n",
      "Epoch 102. Loss: 0.0014540613276553152, Train_acc 0.9985303217821783\n",
      "\n",
      "Epoch 102. Loss: 0.0014312631249875126, Train_acc 0.9985447303921569\n",
      "\n",
      "Epoch 102. Loss: 0.0013363885332161828, Train_acc 0.998558859223301\n",
      "\n",
      "Epoch 102. Loss: 0.0012079825937216225, Train_acc 0.9985727163461539\n",
      "\n",
      "Epoch 102. Loss: 0.0011028524105796732, Train_acc 0.9985863095238096\n",
      "\n",
      "Epoch 102. Loss: 0.0010345521603429258, Train_acc 0.9985996462264151\n",
      "\n",
      "Epoch 102. Loss: 0.0009384781595636422, Train_acc 0.9986127336448598\n",
      "\n",
      "Epoch 102. Loss: 0.0008665333392570032, Train_acc 0.9986255787037037\n",
      "\n",
      "Epoch 102. Loss: 0.0016210856655850662, Train_acc 0.9985665137614679\n",
      "\n",
      "Epoch 102. Loss: 0.0014950530198244443, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 102. Loss: 0.0013731987112757808, Train_acc 0.9985923423423423\n",
      "\n",
      "Epoch 102. Loss: 0.0012852755201177074, Train_acc 0.9986049107142857\n",
      "\n",
      "Epoch 102. Loss: 0.0012042712490608564, Train_acc 0.9986172566371682\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102. Loss: 0.0010872631963182947, Train_acc 0.9986293859649122\n",
      "\n",
      "Epoch 102. Loss: 0.0010019770027832951, Train_acc 0.998641304347826\n",
      "\n",
      "Epoch 102. Loss: 0.001590030736399004, Train_acc 0.9985856681034483\n",
      "\n",
      "Epoch 102. Loss: 0.0014861856962604604, Train_acc 0.9985977564102564\n",
      "\n",
      "Epoch 102. Loss: 0.0013628585939527258, Train_acc 0.9986096398305084\n",
      "\n",
      "Epoch 102. Loss: 0.0012318261600366214, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 102. Loss: 0.001128513276237784, Train_acc 0.9986328125\n",
      "\n",
      "Epoch 102. Loss: 0.0010354375459344096, Train_acc 0.9986441115702479\n",
      "\n",
      "Epoch 102. Loss: 0.0009441940305183894, Train_acc 0.9986552254098361\n",
      "\n",
      "Epoch 102. Loss: 0.0008553445021684555, Train_acc 0.9986661585365854\n",
      "\n",
      "Epoch 102. Loss: 0.0010450540336929789, Train_acc 0.9986769153225806\n",
      "\n",
      "Epoch 102. Loss: 0.0009615937410941822, Train_acc 0.9986875\n",
      "\n",
      "Epoch 102. Loss: 0.0008730564622753354, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 102. Loss: 0.0008512019838044935, Train_acc 0.9987081692913385\n",
      "\n",
      "Epoch 102. Loss: 0.0007709497052029611, Train_acc 0.99871826171875\n",
      "\n",
      "Epoch 102. Loss: 0.0007166468800014823, Train_acc 0.9987281976744186\n",
      "\n",
      "Epoch 102. Loss: 0.000677707848639256, Train_acc 0.9987379807692308\n",
      "\n",
      "Epoch 102. Loss: 0.004852561033687859, Train_acc 0.9986879770992366\n",
      "\n",
      "Epoch 102. Loss: 0.004377879055509106, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 102. Loss: 0.003952358993661935, Train_acc 0.9987077067669173\n",
      "\n",
      "Epoch 102. Loss: 0.0035628025481934974, Train_acc 0.9987173507462687\n",
      "\n",
      "Epoch 102. Loss: 0.0032812534444818463, Train_acc 0.9987268518518518\n",
      "\n",
      "Epoch 102. Loss: 0.002955594840658757, Train_acc 0.9987362132352942\n",
      "\n",
      "Epoch 102. Loss: 0.007453372716617335, Train_acc 0.9985743613138686\n",
      "\n",
      "Epoch 102. Loss: 0.006714087666534613, Train_acc 0.9985846920289855\n",
      "\n",
      "Epoch 102. Loss: 0.006045550645409107, Train_acc 0.9985948741007195\n",
      "\n",
      "Epoch 102. Loss: 0.005497068859988224, Train_acc 0.9986049107142857\n",
      "\n",
      "Epoch 102. Loss: 0.007588241500723753, Train_acc 0.9985593971631206\n",
      "\n",
      "Epoch 102. Loss: 0.006926263501351381, Train_acc 0.9985695422535211\n",
      "\n",
      "Epoch 102. Loss: 0.006617214670312677, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 102. Loss: 0.009493775046347625, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 102. Loss: 0.008591562464292985, Train_acc 0.9985452586206897\n",
      "\n",
      "Epoch 102. Loss: 0.00959988958786977, Train_acc 0.9985017123287672\n",
      "\n",
      "Epoch 102. Loss: 0.008665212003421137, Train_acc 0.9985119047619048\n",
      "\n",
      "Epoch 102. Loss: 0.007828678374257958, Train_acc 0.9985219594594594\n",
      "\n",
      "Epoch 102. Loss: 0.007289642498247871, Train_acc 0.9985318791946308\n",
      "\n",
      "Epoch 102. Loss: 0.0066559961395235056, Train_acc 0.9985416666666667\n",
      "\n",
      "Epoch 102. Loss: 0.006206351999985087, Train_acc 0.9985513245033113\n",
      "\n",
      "Epoch 102. Loss: 0.005640325329885848, Train_acc 0.9985608552631579\n",
      "\n",
      "Epoch 102. Loss: 0.005103233176654697, Train_acc 0.9985702614379085\n",
      "\n",
      "Epoch 102. Loss: 0.005184269239621867, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 102. Loss: 0.004758167844044797, Train_acc 0.9985887096774193\n",
      "\n",
      "Epoch 102. Loss: 0.004476891865754991, Train_acc 0.9985977564102564\n",
      "\n",
      "Epoch 102. Loss: 0.0076572934482319974, Train_acc 0.9985569267515924\n",
      "\n",
      "Epoch 102. Loss: 0.007333032517328008, Train_acc 0.9985660601265823\n",
      "\n",
      "Epoch 102. Loss: 0.006790806599470208, Train_acc 0.9985750786163522\n",
      "\n",
      "Epoch 102. Loss: 0.007681115305136647, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 102. Loss: 0.007015248930344886, Train_acc 0.9985442546583851\n",
      "\n",
      "Epoch 102. Loss: 0.0063910873039200065, Train_acc 0.9985532407407407\n",
      "\n",
      "Epoch 102. Loss: 0.005790551294478475, Train_acc 0.9985621165644172\n",
      "\n",
      "Epoch 102. Loss: 0.005390458994553416, Train_acc 0.9985708841463414\n",
      "\n",
      "Epoch 102. Loss: 0.0049051943195127816, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 102. Loss: 0.004486968889727522, Train_acc 0.9985881024096386\n",
      "\n",
      "Epoch 102. Loss: 0.004238491197022195, Train_acc 0.9985965568862275\n",
      "\n",
      "Epoch 102. Loss: 0.0038333515707717272, Train_acc 0.9986049107142857\n",
      "\n",
      "Epoch 102. Loss: 0.008533855263954336, Train_acc 0.9984744822485208\n",
      "\n",
      "Epoch 102. Loss: 0.00836682150623137, Train_acc 0.998483455882353\n",
      "\n",
      "Epoch 102. Loss: 0.0077177479436294815, Train_acc 0.9984923245614035\n",
      "\n",
      "Epoch 102. Loss: 0.009429334549930387, Train_acc 0.9984556686046512\n",
      "\n",
      "Epoch 102. Loss: 0.008523510085301125, Train_acc 0.9984645953757225\n",
      "\n",
      "Epoch 102. Loss: 0.0076892135215795255, Train_acc 0.9984734195402298\n",
      "\n",
      "Epoch 102. Loss: 0.006984161642945965, Train_acc 0.9984821428571429\n",
      "\n",
      "Epoch 102. Loss: 0.006664638119234585, Train_acc 0.9984907670454546\n",
      "\n",
      "Epoch 102. Loss: 0.006019592613589192, Train_acc 0.9984992937853108\n",
      "\n",
      "Epoch 102. Loss: 0.005468483937333309, Train_acc 0.9985077247191011\n",
      "\n",
      "Epoch 102. Loss: 0.00494152618108622, Train_acc 0.9985160614525139\n",
      "\n",
      "Epoch 102. Loss: 0.004637235893421755, Train_acc 0.9985243055555556\n",
      "\n",
      "Epoch 102. Loss: 0.004245816964068311, Train_acc 0.9985324585635359\n",
      "\n",
      "Epoch 102. Loss: 0.0056353283359035534, Train_acc 0.9984975961538461\n",
      "\n",
      "Epoch 102. Loss: 0.00510284227247701, Train_acc 0.998505806010929\n",
      "\n",
      "Epoch 102. Loss: 0.005429910730859631, Train_acc 0.9984714673913043\n",
      "\n",
      "Epoch 102. Loss: 0.005084991177617902, Train_acc 0.9984797297297298\n",
      "\n",
      "Epoch 102. Loss: 0.004947275418668444, Train_acc 0.9984879032258065\n",
      "\n",
      "Epoch 102. Loss: 0.004526299392976125, Train_acc 0.9984959893048129\n",
      "\n",
      "Epoch 102. Loss: 0.01404888375621834, Train_acc 0.9984208776595744\n",
      "\n",
      "Epoch 102. Loss: 0.012982679891967462, Train_acc 0.9984292328042328\n",
      "\n",
      "Epoch 102. Loss: 0.01206887233895095, Train_acc 0.9984375\n",
      "\n",
      "Epoch 102. Loss: 0.011034151805996435, Train_acc 0.9984456806282722\n",
      "\n",
      "Epoch 102. Loss: 0.011437856832348887, Train_acc 0.9984130859375\n",
      "\n",
      "Epoch 102. Loss: 0.010382229690007344, Train_acc 0.9984213082901554\n",
      "\n",
      "Epoch 102. Loss: 0.009545518639573732, Train_acc 0.9984294458762887\n",
      "\n",
      "Epoch 102. Loss: 0.009082870544468713, Train_acc 0.9984375\n",
      "\n",
      "Epoch 102. Loss: 0.008312021346777993, Train_acc 0.99844\n",
      "\n",
      "Epoch 103. Loss: 0.00749996138637858, Train_acc 1.0\n",
      "\n",
      "Epoch 103. Loss: 0.007036069707987583, Train_acc 1.0\n",
      "\n",
      "Epoch 103. Loss: 0.0064640804681379, Train_acc 1.0\n",
      "\n",
      "Epoch 103. Loss: 0.005948930871306961, Train_acc 1.0\n",
      "\n",
      "Epoch 103. Loss: 0.005404829078955894, Train_acc 1.0\n",
      "\n",
      "Epoch 103. Loss: 0.004968029742857169, Train_acc 1.0\n",
      "\n",
      "Epoch 103. Loss: 0.004509089408445672, Train_acc 1.0\n",
      "\n",
      "Epoch 103. Loss: 0.004177961647420361, Train_acc 1.0\n",
      "\n",
      "Epoch 103. Loss: 0.004620472382672937, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 103. Loss: 0.006336291506440919, Train_acc 0.9984375\n",
      "\n",
      "Epoch 103. Loss: 0.0058668355383625454, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 103. Loss: 0.005412183583585991, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 103. Loss: 0.004949367516046604, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 103. Loss: 0.004480978917697079, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 103. Loss: 0.004077848510354987, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 103. Loss: 0.0038083478554653207, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 103. Loss: 0.003857118110618032, Train_acc 0.9990808823529411\n",
      "\n",
      "Epoch 103. Loss: 0.003655063728271607, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 103. Loss: 0.004394552684377447, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 103. Loss: 0.005717930303410426, Train_acc 0.9984375\n",
      "\n",
      "Epoch 103. Loss: 0.0072366202456316964, Train_acc 0.9981398809523809\n",
      "\n",
      "Epoch 103. Loss: 0.006803923137416985, Train_acc 0.9982244318181818\n",
      "\n",
      "Epoch 103. Loss: 0.006905682716456544, Train_acc 0.9979619565217391\n",
      "\n",
      "Epoch 103. Loss: 0.007433975041229271, Train_acc 0.9977213541666666\n",
      "\n",
      "Epoch 103. Loss: 0.006706419005227268, Train_acc 0.9978125\n",
      "\n",
      "Epoch 103. Loss: 0.006098397255561216, Train_acc 0.9978966346153846\n",
      "\n",
      "Epoch 103. Loss: 0.005501775651608225, Train_acc 0.9979745370370371\n",
      "\n",
      "Epoch 103. Loss: 0.004985513571702823, Train_acc 0.998046875\n",
      "\n",
      "Epoch 103. Loss: 0.004583694720595376, Train_acc 0.998114224137931\n",
      "\n",
      "Epoch 103. Loss: 0.004156277672812458, Train_acc 0.9981770833333333\n",
      "\n",
      "Epoch 103. Loss: 0.004375663960827991, Train_acc 0.9982358870967742\n",
      "\n",
      "Epoch 103. Loss: 0.004479842690992599, Train_acc 0.998291015625\n",
      "\n",
      "Epoch 103. Loss: 0.004038260832401938, Train_acc 0.998342803030303\n",
      "\n",
      "Epoch 103. Loss: 0.004190567645033742, Train_acc 0.9983915441176471\n",
      "\n",
      "Epoch 103. Loss: 0.004151580805980156, Train_acc 0.9984375\n",
      "\n",
      "Epoch 103. Loss: 0.0037496038996725073, Train_acc 0.9984809027777778\n",
      "\n",
      "Epoch 103. Loss: 0.004262107124049854, Train_acc 0.9983108108108109\n",
      "\n",
      "Epoch 103. Loss: 0.004122421131203525, Train_acc 0.9983552631578947\n",
      "\n",
      "Epoch 103. Loss: 0.009414685504737454, Train_acc 0.9981971153846154\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103. Loss: 0.008481509806990008, Train_acc 0.9982421875\n",
      "\n",
      "Epoch 103. Loss: 0.009678483036708277, Train_acc 0.9980945121951219\n",
      "\n",
      "Epoch 103. Loss: 0.008718711229343326, Train_acc 0.9981398809523809\n",
      "\n",
      "Epoch 103. Loss: 0.011293692149680058, Train_acc 0.9978197674418605\n",
      "\n",
      "Epoch 103. Loss: 0.010191627874870554, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 103. Loss: 0.009224556816977893, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 103. Loss: 0.008391868931733193, Train_acc 0.9979619565217391\n",
      "\n",
      "Epoch 103. Loss: 0.007560053712851664, Train_acc 0.9980053191489362\n",
      "\n",
      "Epoch 103. Loss: 0.006825351286081398, Train_acc 0.998046875\n",
      "\n",
      "Epoch 103. Loss: 0.006175475661104552, Train_acc 0.9980867346938775\n",
      "\n",
      "Epoch 103. Loss: 0.005568990786913602, Train_acc 0.998125\n",
      "\n",
      "Epoch 103. Loss: 0.0050536883404402305, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 103. Loss: 0.004645492434904579, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 103. Loss: 0.004190942918313089, Train_acc 0.9982311320754716\n",
      "\n",
      "Epoch 103. Loss: 0.004630819637375364, Train_acc 0.9981192129629629\n",
      "\n",
      "Epoch 103. Loss: 0.005722438592133483, Train_acc 0.9980113636363637\n",
      "\n",
      "Epoch 103. Loss: 0.005164056776772121, Train_acc 0.998046875\n",
      "\n",
      "Epoch 103. Loss: 0.004668333386963021, Train_acc 0.9980811403508771\n",
      "\n",
      "Epoch 103. Loss: 0.004216071997116781, Train_acc 0.998114224137931\n",
      "\n",
      "Epoch 103. Loss: 0.004283888593939641, Train_acc 0.998146186440678\n",
      "\n",
      "Epoch 103. Loss: 0.00470773802828285, Train_acc 0.998046875\n",
      "\n",
      "Epoch 103. Loss: 0.004253514696354822, Train_acc 0.9980788934426229\n",
      "\n",
      "Epoch 103. Loss: 0.0048864960350350935, Train_acc 0.9979838709677419\n",
      "\n",
      "Epoch 103. Loss: 0.00443713020562624, Train_acc 0.998015873015873\n",
      "\n",
      "Epoch 103. Loss: 0.004102774699947939, Train_acc 0.998046875\n",
      "\n",
      "Epoch 103. Loss: 0.003707672862096073, Train_acc 0.9980769230769231\n",
      "\n",
      "Epoch 103. Loss: 0.0035034927116409913, Train_acc 0.9981060606060606\n",
      "\n",
      "Epoch 103. Loss: 0.0031842189885082596, Train_acc 0.9981343283582089\n",
      "\n",
      "Epoch 103. Loss: 0.0029350434027264494, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 103. Loss: 0.0027286283344369363, Train_acc 0.9981884057971014\n",
      "\n",
      "Epoch 103. Loss: 0.0024997570612260685, Train_acc 0.9982142857142857\n",
      "\n",
      "Epoch 103. Loss: 0.0024439262210670695, Train_acc 0.9982394366197183\n",
      "\n",
      "Epoch 103. Loss: 0.0022134384690988664, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 103. Loss: 0.0021928637644367164, Train_acc 0.9982876712328768\n",
      "\n",
      "Epoch 103. Loss: 0.0027453352086141774, Train_acc 0.9982052364864865\n",
      "\n",
      "Epoch 103. Loss: 0.0025953211457933546, Train_acc 0.9982291666666666\n",
      "\n",
      "Epoch 103. Loss: 0.006638973182863495, Train_acc 0.998046875\n",
      "\n",
      "Epoch 103. Loss: 0.0060873576508550355, Train_acc 0.9980722402597403\n",
      "\n",
      "Epoch 103. Loss: 0.00931531289278762, Train_acc 0.9979967948717948\n",
      "\n",
      "Epoch 103. Loss: 0.009309019568347602, Train_acc 0.9979232594936709\n",
      "\n",
      "Epoch 103. Loss: 0.008499634660195859, Train_acc 0.99794921875\n",
      "\n",
      "Epoch 103. Loss: 0.00820342409520884, Train_acc 0.9978780864197531\n",
      "\n",
      "Epoch 103. Loss: 0.007424723423022386, Train_acc 0.9979039634146342\n",
      "\n",
      "Epoch 103. Loss: 0.0070716856642052735, Train_acc 0.9979292168674698\n",
      "\n",
      "Epoch 103. Loss: 0.007004753497852553, Train_acc 0.9979538690476191\n",
      "\n",
      "Epoch 103. Loss: 0.008153406826508346, Train_acc 0.9978860294117647\n",
      "\n",
      "Epoch 103. Loss: 0.0076462236474624, Train_acc 0.9979106104651163\n",
      "\n",
      "Epoch 103. Loss: 0.007044851419836646, Train_acc 0.9979346264367817\n",
      "\n",
      "Epoch 103. Loss: 0.009840334627786607, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 103. Loss: 0.010853591716670392, Train_acc 0.9978054775280899\n",
      "\n",
      "Epoch 103. Loss: 0.009818648091869487, Train_acc 0.9978298611111112\n",
      "\n",
      "Epoch 103. Loss: 0.009214863204621017, Train_acc 0.9978537087912088\n",
      "\n",
      "Epoch 103. Loss: 0.008419550208110575, Train_acc 0.9978770380434783\n",
      "\n",
      "Epoch 103. Loss: 0.008145505448751717, Train_acc 0.9978998655913979\n",
      "\n",
      "Epoch 103. Loss: 0.007578209173074129, Train_acc 0.9979222074468085\n",
      "\n",
      "Epoch 103. Loss: 0.007361309906593647, Train_acc 0.9979440789473685\n",
      "\n",
      "Epoch 103. Loss: 0.006774005159755815, Train_acc 0.9979654947916666\n",
      "\n",
      "Epoch 103. Loss: 0.00831945630760813, Train_acc 0.9978253865979382\n",
      "\n",
      "Epoch 103. Loss: 0.008121474107147671, Train_acc 0.9978475765306123\n",
      "\n",
      "Epoch 103. Loss: 0.0073818244370536515, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 103. Loss: 0.00973593431705682, Train_acc 0.9978125\n",
      "\n",
      "[Epoch 103 Batch 100] Loss: 0.009126551784339087 Training: accuracy=0.997834\n",
      "Epoch 103. Loss: 0.009126551784339087, Train_acc 0.9978341584158416\n",
      "\n",
      "Epoch 103. Loss: 0.012656444985207203, Train_acc 0.9977022058823529\n",
      "\n",
      "Epoch 103. Loss: 0.011574484912114994, Train_acc 0.9977245145631068\n",
      "\n",
      "Epoch 103. Loss: 0.0107883957561621, Train_acc 0.9977463942307693\n",
      "\n",
      "Epoch 103. Loss: 0.011482948775896633, Train_acc 0.9976934523809524\n",
      "\n",
      "Epoch 103. Loss: 0.011122954755254868, Train_acc 0.9977152122641509\n",
      "\n",
      "Epoch 103. Loss: 0.011185889741833464, Train_acc 0.9976635514018691\n",
      "\n",
      "Epoch 103. Loss: 0.010149729142676329, Train_acc 0.9976851851851852\n",
      "\n",
      "Epoch 103. Loss: 0.010325229647091509, Train_acc 0.997634747706422\n",
      "\n",
      "Epoch 103. Loss: 0.009981336931733621, Train_acc 0.99765625\n",
      "\n",
      "Epoch 103. Loss: 0.009605806722058356, Train_acc 0.9976773648648649\n",
      "\n",
      "Epoch 103. Loss: 0.008709445089484527, Train_acc 0.9976981026785714\n",
      "\n",
      "Epoch 103. Loss: 0.009812916732178874, Train_acc 0.9976493362831859\n",
      "\n",
      "Epoch 103. Loss: 0.009763421211105659, Train_acc 0.9976014254385965\n",
      "\n",
      "Epoch 103. Loss: 0.008905149185772605, Train_acc 0.9976222826086957\n",
      "\n",
      "Epoch 103. Loss: 0.00809103800379786, Train_acc 0.9976427801724138\n",
      "\n",
      "Epoch 103. Loss: 0.00735839883105467, Train_acc 0.9976629273504274\n",
      "\n",
      "Epoch 103. Loss: 0.006740842316596302, Train_acc 0.9976827330508474\n",
      "\n",
      "Epoch 103. Loss: 0.006143351246730097, Train_acc 0.9977022058823529\n",
      "\n",
      "Epoch 103. Loss: 0.005734223412184962, Train_acc 0.9977213541666666\n",
      "\n",
      "Epoch 103. Loss: 0.005269951052256568, Train_acc 0.9977401859504132\n",
      "\n",
      "Epoch 103. Loss: 0.004781606089991162, Train_acc 0.9977587090163934\n",
      "\n",
      "Epoch 103. Loss: 0.004547201399919537, Train_acc 0.997776930894309\n",
      "\n",
      "Epoch 103. Loss: 0.004126521001076755, Train_acc 0.9977948588709677\n",
      "\n",
      "Epoch 103. Loss: 0.0037221702702037664, Train_acc 0.9978125\n",
      "\n",
      "Epoch 103. Loss: 0.003442407532735214, Train_acc 0.9978298611111112\n",
      "\n",
      "Epoch 103. Loss: 0.0031180859998198264, Train_acc 0.9978469488188977\n",
      "\n",
      "Epoch 103. Loss: 0.00680411515194165, Train_acc 0.997802734375\n",
      "\n",
      "Epoch 103. Loss: 0.006619579868909603, Train_acc 0.9978197674418605\n",
      "\n",
      "Epoch 103. Loss: 0.0059706704883612785, Train_acc 0.9978365384615384\n",
      "\n",
      "Epoch 103. Loss: 0.005503776444688821, Train_acc 0.9978530534351145\n",
      "\n",
      "Epoch 103. Loss: 0.005164080148327694, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 103. Loss: 0.004899064501722168, Train_acc 0.9978853383458647\n",
      "\n",
      "Epoch 103. Loss: 0.004511970627191971, Train_acc 0.9979011194029851\n",
      "\n",
      "Epoch 103. Loss: 0.005430704927042106, Train_acc 0.9978587962962963\n",
      "\n",
      "Epoch 103. Loss: 0.004920661554272454, Train_acc 0.9978745404411765\n",
      "\n",
      "Epoch 103. Loss: 0.005646277779074444, Train_acc 0.9978330291970803\n",
      "\n",
      "Epoch 103. Loss: 0.005571594313888491, Train_acc 0.997848731884058\n",
      "\n",
      "Epoch 103. Loss: 0.0050352590224374, Train_acc 0.9978642086330936\n",
      "\n",
      "Epoch 103. Loss: 0.004653819428158879, Train_acc 0.9978794642857143\n",
      "\n",
      "Epoch 103. Loss: 0.004196979738978815, Train_acc 0.9978945035460993\n",
      "\n",
      "Epoch 103. Loss: 0.003821994419279453, Train_acc 0.9979093309859155\n",
      "\n",
      "Epoch 103. Loss: 0.0035241252818773005, Train_acc 0.997923951048951\n",
      "\n",
      "Epoch 103. Loss: 0.003562337194896026, Train_acc 0.9979383680555556\n",
      "\n",
      "Epoch 103. Loss: 0.003235336387171999, Train_acc 0.9979525862068965\n",
      "\n",
      "Epoch 103. Loss: 0.0029348245855691556, Train_acc 0.997966609589041\n",
      "\n",
      "Epoch 103. Loss: 0.002721602738151478, Train_acc 0.9979804421768708\n",
      "\n",
      "Epoch 103. Loss: 0.0026665406948323794, Train_acc 0.9979940878378378\n",
      "\n",
      "Epoch 103. Loss: 0.0026215021661441695, Train_acc 0.9980075503355704\n",
      "\n",
      "Epoch 103. Loss: 0.0026122408367190812, Train_acc 0.9980208333333334\n",
      "\n",
      "Epoch 103. Loss: 0.003846955966829722, Train_acc 0.9979822019867549\n",
      "\n",
      "Epoch 103. Loss: 0.0038519767252768265, Train_acc 0.9979954769736842\n",
      "\n",
      "Epoch 103. Loss: 0.003530536627866195, Train_acc 0.9980085784313726\n",
      "\n",
      "Epoch 103. Loss: 0.003184267907604549, Train_acc 0.9980215097402597\n",
      "\n",
      "Epoch 103. Loss: 0.0028809558448562164, Train_acc 0.9980342741935484\n",
      "\n",
      "Epoch 103. Loss: 0.002670189329979417, Train_acc 0.998046875\n",
      "\n",
      "Epoch 103. Loss: 0.002410801125923352, Train_acc 0.9980593152866242\n",
      "\n",
      "Epoch 103. Loss: 0.004091291128122411, Train_acc 0.9980221518987342\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103. Loss: 0.0036892090327352352, Train_acc 0.9980345911949685\n",
      "\n",
      "Epoch 103. Loss: 0.003345928377084217, Train_acc 0.998046875\n",
      "\n",
      "Epoch 103. Loss: 0.005173450256442083, Train_acc 0.9980104813664596\n",
      "\n",
      "Epoch 103. Loss: 0.004659150581584, Train_acc 0.998022762345679\n",
      "\n",
      "Epoch 103. Loss: 0.004204284624583878, Train_acc 0.9980348926380368\n",
      "\n",
      "Epoch 103. Loss: 0.003788649264687452, Train_acc 0.998046875\n",
      "\n",
      "Epoch 103. Loss: 0.003464129362037021, Train_acc 0.9980587121212121\n",
      "\n",
      "Epoch 103. Loss: 0.0031587018514182682, Train_acc 0.998070406626506\n",
      "\n",
      "Epoch 103. Loss: 0.003479506223157631, Train_acc 0.9980351796407185\n",
      "\n",
      "Epoch 103. Loss: 0.003170495143561031, Train_acc 0.998046875\n",
      "\n",
      "Epoch 103. Loss: 0.002919938882894187, Train_acc 0.9980584319526628\n",
      "\n",
      "Epoch 103. Loss: 0.002750343109367969, Train_acc 0.9980698529411764\n",
      "\n",
      "Epoch 103. Loss: 0.0025013861564833068, Train_acc 0.9980811403508771\n",
      "\n",
      "Epoch 103. Loss: 0.0022570317517876734, Train_acc 0.9980922965116279\n",
      "\n",
      "Epoch 103. Loss: 0.0020443879470032366, Train_acc 0.998103323699422\n",
      "\n",
      "Epoch 103. Loss: 0.0018777116167927007, Train_acc 0.998114224137931\n",
      "\n",
      "Epoch 103. Loss: 0.0017200899163492818, Train_acc 0.998125\n",
      "\n",
      "Epoch 103. Loss: 0.006142141330803182, Train_acc 0.9980912642045454\n",
      "\n",
      "Epoch 103. Loss: 0.0055367765695295825, Train_acc 0.9981020480225988\n",
      "\n",
      "Epoch 103. Loss: 0.007614737484196612, Train_acc 0.9980688202247191\n",
      "\n",
      "Epoch 103. Loss: 0.006904225189011728, Train_acc 0.9980796089385475\n",
      "\n",
      "Epoch 103. Loss: 0.006593615434114428, Train_acc 0.9980902777777778\n",
      "\n",
      "Epoch 103. Loss: 0.007116681520531439, Train_acc 0.9980576657458563\n",
      "\n",
      "Epoch 103. Loss: 0.006422390549689782, Train_acc 0.9980683379120879\n",
      "\n",
      "Epoch 103. Loss: 0.00585346332186632, Train_acc 0.9980788934426229\n",
      "\n",
      "Epoch 103. Loss: 0.006148386695928925, Train_acc 0.998046875\n",
      "\n",
      "Epoch 103. Loss: 0.006380686583919127, Train_acc 0.9980152027027027\n",
      "\n",
      "Epoch 103. Loss: 0.005833240670283034, Train_acc 0.998025873655914\n",
      "\n",
      "Epoch 103. Loss: 0.008887092237758095, Train_acc 0.9979946524064172\n",
      "\n",
      "Epoch 103. Loss: 0.009253115827668417, Train_acc 0.9979637632978723\n",
      "\n",
      "Epoch 103. Loss: 0.00909344159982685, Train_acc 0.9979745370370371\n",
      "\n",
      "Epoch 103. Loss: 0.01051608930607513, Train_acc 0.9979440789473685\n",
      "\n",
      "Epoch 103. Loss: 0.010579900836168606, Train_acc 0.9979548429319371\n",
      "\n",
      "Epoch 103. Loss: 0.013286022301213932, Train_acc 0.9979248046875\n",
      "\n",
      "Epoch 103. Loss: 0.011987271159858549, Train_acc 0.9979355569948186\n",
      "\n",
      "Epoch 103. Loss: 0.011038964530427197, Train_acc 0.9979461984536082\n",
      "\n",
      "Epoch 103. Loss: 0.014397472999035363, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 103. Loss: 0.014629614937191348, Train_acc 0.99792\n",
      "\n",
      "Epoch 104. Loss: 0.013683623712854214, Train_acc 1.0\n",
      "\n",
      "Epoch 104. Loss: 0.012817516108912195, Train_acc 1.0\n",
      "\n",
      "Epoch 104. Loss: 0.011628753611202806, Train_acc 1.0\n",
      "\n",
      "Epoch 104. Loss: 0.010749855662701223, Train_acc 1.0\n",
      "\n",
      "Epoch 104. Loss: 0.009708623805134545, Train_acc 1.0\n",
      "\n",
      "Epoch 104. Loss: 0.008867154097882555, Train_acc 1.0\n",
      "\n",
      "Epoch 104. Loss: 0.008071332057728003, Train_acc 1.0\n",
      "\n",
      "Epoch 104. Loss: 0.007881479780373244, Train_acc 1.0\n",
      "\n",
      "Epoch 104. Loss: 0.00715915705908777, Train_acc 1.0\n",
      "\n",
      "Epoch 104. Loss: 0.006506564873768612, Train_acc 1.0\n",
      "\n",
      "Epoch 104. Loss: 0.006103941823338322, Train_acc 1.0\n",
      "\n",
      "Epoch 104. Loss: 0.005499153286133015, Train_acc 1.0\n",
      "\n",
      "Epoch 104. Loss: 0.007229729920548622, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 104. Loss: 0.006566219185689024, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 104. Loss: 0.006819027800767659, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 104. Loss: 0.006558954030119513, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 104. Loss: 0.0059712811838364315, Train_acc 0.9990808823529411\n",
      "\n",
      "Epoch 104. Loss: 0.0056133565865033016, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 104. Loss: 0.005457275375685675, Train_acc 0.9991776315789473\n",
      "\n",
      "Epoch 104. Loss: 0.005019737346436009, Train_acc 0.99921875\n",
      "\n",
      "Epoch 104. Loss: 0.004764391147463404, Train_acc 0.9992559523809523\n",
      "\n",
      "Epoch 104. Loss: 0.0051854405895193365, Train_acc 0.9989346590909091\n",
      "\n",
      "Epoch 104. Loss: 0.0046880422416382605, Train_acc 0.9989809782608695\n",
      "\n",
      "Epoch 104. Loss: 0.00552133975995066, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 104. Loss: 0.005964290147922774, Train_acc 0.99875\n",
      "\n",
      "Epoch 104. Loss: 0.0054829291338718, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 104. Loss: 0.009668329820185548, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 104. Loss: 0.008870453002437634, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 104. Loss: 0.008074207485550359, Train_acc 0.9983836206896551\n",
      "\n",
      "Epoch 104. Loss: 0.007445300692320212, Train_acc 0.9984375\n",
      "\n",
      "Epoch 104. Loss: 0.006852913527787039, Train_acc 0.9984879032258065\n",
      "\n",
      "Epoch 104. Loss: 0.006205638116399103, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 104. Loss: 0.005647735847083542, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 104. Loss: 0.008729970428092313, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 104. Loss: 0.007956507076819719, Train_acc 0.9982142857142857\n",
      "\n",
      "Epoch 104. Loss: 0.007342697323020531, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 104. Loss: 0.006655602181591078, Train_acc 0.9983108108108109\n",
      "\n",
      "Epoch 104. Loss: 0.006109491382867084, Train_acc 0.9983552631578947\n",
      "\n",
      "Epoch 104. Loss: 0.00559100949115752, Train_acc 0.9983974358974359\n",
      "\n",
      "Epoch 104. Loss: 0.005110796569970538, Train_acc 0.9984375\n",
      "\n",
      "Epoch 104. Loss: 0.00475679911022987, Train_acc 0.9984756097560976\n",
      "\n",
      "Epoch 104. Loss: 0.004365002562029118, Train_acc 0.9985119047619048\n",
      "\n",
      "Epoch 104. Loss: 0.004420124256467481, Train_acc 0.998546511627907\n",
      "\n",
      "Epoch 104. Loss: 0.0039892447444623644, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 104. Loss: 0.003862513984061116, Train_acc 0.9986111111111111\n",
      "\n",
      "Epoch 104. Loss: 0.0048651361180694404, Train_acc 0.9984714673913043\n",
      "\n",
      "Epoch 104. Loss: 0.00451321673251851, Train_acc 0.9985039893617021\n",
      "\n",
      "Epoch 104. Loss: 0.005408816234984966, Train_acc 0.9983723958333334\n",
      "\n",
      "Epoch 104. Loss: 0.004945841200044577, Train_acc 0.998405612244898\n",
      "\n",
      "Epoch 104. Loss: 0.004469542024275466, Train_acc 0.9984375\n",
      "\n",
      "Epoch 104. Loss: 0.004044791521184307, Train_acc 0.9984681372549019\n",
      "\n",
      "Epoch 104. Loss: 0.003665964045762602, Train_acc 0.9984975961538461\n",
      "\n",
      "Epoch 104. Loss: 0.0033753331846967344, Train_acc 0.9985259433962265\n",
      "\n",
      "Epoch 104. Loss: 0.0031420307530179623, Train_acc 0.9985532407407407\n",
      "\n",
      "Epoch 104. Loss: 0.0028695020491756873, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 104. Loss: 0.0026189061955812164, Train_acc 0.9986049107142857\n",
      "\n",
      "Epoch 104. Loss: 0.0023702639030366655, Train_acc 0.9986293859649122\n",
      "\n",
      "Epoch 104. Loss: 0.002152023320793783, Train_acc 0.9986530172413793\n",
      "\n",
      "Epoch 104. Loss: 0.0021482747524824816, Train_acc 0.9986758474576272\n",
      "\n",
      "Epoch 104. Loss: 0.0019612703703486543, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 104. Loss: 0.001785947758316796, Train_acc 0.998719262295082\n",
      "\n",
      "Epoch 104. Loss: 0.0016181819342662666, Train_acc 0.9987399193548387\n",
      "\n",
      "Epoch 104. Loss: 0.0014762629755973985, Train_acc 0.9987599206349206\n",
      "\n",
      "Epoch 104. Loss: 0.001336411647746066, Train_acc 0.998779296875\n",
      "\n",
      "Epoch 104. Loss: 0.0012293424169664605, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 104. Loss: 0.0011141180906411932, Train_acc 0.9988162878787878\n",
      "\n",
      "Epoch 104. Loss: 0.0012829743062302702, Train_acc 0.9988339552238806\n",
      "\n",
      "Epoch 104. Loss: 0.0011825132953656302, Train_acc 0.9988511029411765\n",
      "\n",
      "Epoch 104. Loss: 0.0012218124437175025, Train_acc 0.9988677536231884\n",
      "\n",
      "Epoch 104. Loss: 0.0015310890597410648, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 104. Loss: 0.0013907843665141, Train_acc 0.998899647887324\n",
      "\n",
      "Epoch 104. Loss: 0.0013368884469311506, Train_acc 0.9989149305555556\n",
      "\n",
      "Epoch 104. Loss: 0.0012119033071905307, Train_acc 0.998929794520548\n",
      "\n",
      "Epoch 104. Loss: 0.0013256252424949347, Train_acc 0.9989442567567568\n",
      "\n",
      "Epoch 104. Loss: 0.0011995024325887284, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 104. Loss: 0.0010814287864916096, Train_acc 0.9989720394736842\n",
      "\n",
      "Epoch 104. Loss: 0.001032374262307069, Train_acc 0.9989853896103896\n",
      "\n",
      "Epoch 104. Loss: 0.00096094005844949, Train_acc 0.9989983974358975\n",
      "\n",
      "Epoch 104. Loss: 0.0010504365228142588, Train_acc 0.9990110759493671\n",
      "\n",
      "Epoch 104. Loss: 0.000948659394969018, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 104. Loss: 0.0009005306827117622, Train_acc 0.9990354938271605\n",
      "\n",
      "Epoch 104. Loss: 0.0008574491216946426, Train_acc 0.999047256097561\n",
      "\n",
      "Epoch 104. Loss: 0.000794101775297004, Train_acc 0.999058734939759\n",
      "\n",
      "Epoch 104. Loss: 0.0007238906193551504, Train_acc 0.9990699404761905\n",
      "\n",
      "Epoch 104. Loss: 0.0006979286338692531, Train_acc 0.9990808823529411\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104. Loss: 0.0006335298249426671, Train_acc 0.9990915697674418\n",
      "\n",
      "Epoch 104. Loss: 0.0038649755742522947, Train_acc 0.9990122126436781\n",
      "\n",
      "Epoch 104. Loss: 0.0034791528876799557, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 104. Loss: 0.0031979012904531402, Train_acc 0.9990344101123596\n",
      "\n",
      "Epoch 104. Loss: 0.002889440580474723, Train_acc 0.9990451388888889\n",
      "\n",
      "Epoch 104. Loss: 0.0051259721436507, Train_acc 0.9989697802197802\n",
      "\n",
      "Epoch 104. Loss: 0.010757205273366556, Train_acc 0.9988960597826086\n",
      "\n",
      "Epoch 104. Loss: 0.009683452901659484, Train_acc 0.9989079301075269\n",
      "\n",
      "Epoch 104. Loss: 0.008720298762051484, Train_acc 0.9989195478723404\n",
      "\n",
      "Epoch 104. Loss: 0.00792511570498449, Train_acc 0.9989309210526316\n",
      "\n",
      "Epoch 104. Loss: 0.009202241686389766, Train_acc 0.9988606770833334\n",
      "\n",
      "Epoch 104. Loss: 0.012166023064320613, Train_acc 0.998791881443299\n",
      "\n",
      "Epoch 104. Loss: 0.010967678562801998, Train_acc 0.9988042091836735\n",
      "\n",
      "Epoch 104. Loss: 0.009969173491990049, Train_acc 0.9988162878787878\n",
      "\n",
      "Epoch 104. Loss: 0.010097974423464072, Train_acc 0.99875\n",
      "\n",
      "[Epoch 104 Batch 100] Loss: 0.01006471210023397 Training: accuracy=0.998685\n",
      "Epoch 104. Loss: 0.01006471210023397, Train_acc 0.9986850247524752\n",
      "\n",
      "Epoch 104. Loss: 0.009587828717833464, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 104. Loss: 0.00867951671929795, Train_acc 0.9987105582524272\n",
      "\n",
      "Epoch 104. Loss: 0.007873171593300745, Train_acc 0.9987229567307693\n",
      "\n",
      "Epoch 104. Loss: 0.007196486265892308, Train_acc 0.998735119047619\n",
      "\n",
      "Epoch 104. Loss: 0.006612087097556461, Train_acc 0.9987470518867925\n",
      "\n",
      "Epoch 104. Loss: 0.005975505705708104, Train_acc 0.998758761682243\n",
      "\n",
      "Epoch 104. Loss: 0.005609320319436941, Train_acc 0.9987702546296297\n",
      "\n",
      "Epoch 104. Loss: 0.00530013234640773, Train_acc 0.9987815366972477\n",
      "\n",
      "Epoch 104. Loss: 0.007237827773919247, Train_acc 0.998721590909091\n",
      "\n",
      "Epoch 104. Loss: 0.00782040288316954, Train_acc 0.9986627252252253\n",
      "\n",
      "Epoch 104. Loss: 0.007472250927770872, Train_acc 0.9986746651785714\n",
      "\n",
      "Epoch 104. Loss: 0.007154935138778155, Train_acc 0.9986863938053098\n",
      "\n",
      "Epoch 104. Loss: 0.006744969329668222, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 104. Loss: 0.0062908245285747694, Train_acc 0.9987092391304347\n",
      "\n",
      "Epoch 104. Loss: 0.007753441914355598, Train_acc 0.9986530172413793\n",
      "\n",
      "Epoch 104. Loss: 0.006984318006023214, Train_acc 0.9986645299145299\n",
      "\n",
      "Epoch 104. Loss: 0.006493041612827282, Train_acc 0.9986758474576272\n",
      "\n",
      "Epoch 104. Loss: 0.008878450198283941, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 104. Loss: 0.007992817877565351, Train_acc 0.9986328125\n",
      "\n",
      "Epoch 104. Loss: 0.0076316849906753245, Train_acc 0.9986441115702479\n",
      "\n",
      "Epoch 104. Loss: 0.006969566446145095, Train_acc 0.9986552254098361\n",
      "\n",
      "Epoch 104. Loss: 0.006534767676643774, Train_acc 0.9986661585365854\n",
      "\n",
      "Epoch 104. Loss: 0.007328109841870289, Train_acc 0.9986139112903226\n",
      "\n",
      "Epoch 104. Loss: 0.006710006436588187, Train_acc 0.998625\n",
      "\n",
      "Epoch 104. Loss: 0.00624804913089289, Train_acc 0.9986359126984127\n",
      "\n",
      "Epoch 104. Loss: 0.005659781250960093, Train_acc 0.9986466535433071\n",
      "\n",
      "Epoch 104. Loss: 0.005182240894727598, Train_acc 0.9986572265625\n",
      "\n",
      "Epoch 104. Loss: 0.005255214461722396, Train_acc 0.9986676356589147\n",
      "\n",
      "Epoch 104. Loss: 0.0052802347629115785, Train_acc 0.9986778846153846\n",
      "\n",
      "Epoch 104. Loss: 0.005203863852591438, Train_acc 0.9986879770992366\n",
      "\n",
      "Epoch 104. Loss: 0.004823325063042602, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 104. Loss: 0.004385515747910971, Train_acc 0.9987077067669173\n",
      "\n",
      "Epoch 104. Loss: 0.004008963527631373, Train_acc 0.9987173507462687\n",
      "\n",
      "Epoch 104. Loss: 0.003630569587189282, Train_acc 0.9987268518518518\n",
      "\n",
      "Epoch 104. Loss: 0.0035475541554734038, Train_acc 0.9987362132352942\n",
      "\n",
      "Epoch 104. Loss: 0.0032710701508197122, Train_acc 0.9987454379562044\n",
      "\n",
      "Epoch 104. Loss: 0.002979734636289814, Train_acc 0.9987545289855072\n",
      "\n",
      "Epoch 104. Loss: 0.002827494098399972, Train_acc 0.9987634892086331\n",
      "\n",
      "Epoch 104. Loss: 0.0025592809750313865, Train_acc 0.9987723214285714\n",
      "\n",
      "Epoch 104. Loss: 0.0027341125719555, Train_acc 0.9987810283687943\n",
      "\n",
      "Epoch 104. Loss: 0.002468802926216318, Train_acc 0.9987896126760564\n",
      "\n",
      "Epoch 104. Loss: 0.0027240904154096192, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 104. Loss: 0.002459062821226714, Train_acc 0.9988064236111112\n",
      "\n",
      "Epoch 104. Loss: 0.0022747642084444894, Train_acc 0.9988146551724137\n",
      "\n",
      "Epoch 104. Loss: 0.0022220807134272456, Train_acc 0.9988227739726028\n",
      "\n",
      "Epoch 104. Loss: 0.002436141575201911, Train_acc 0.9988307823129252\n",
      "\n",
      "Epoch 104. Loss: 0.0023419378452297114, Train_acc 0.9988386824324325\n",
      "\n",
      "Epoch 104. Loss: 0.002125240788812211, Train_acc 0.9988464765100671\n",
      "\n",
      "Epoch 104. Loss: 0.001921045452045817, Train_acc 0.9988541666666667\n",
      "\n",
      "Epoch 104. Loss: 0.0018169229853897562, Train_acc 0.9988617549668874\n",
      "\n",
      "Epoch 104. Loss: 0.0035749852474405708, Train_acc 0.9988178453947368\n",
      "\n",
      "Epoch 104. Loss: 0.0032725985160320407, Train_acc 0.9988255718954249\n",
      "\n",
      "Epoch 104. Loss: 0.003166813575515098, Train_acc 0.998833198051948\n",
      "\n",
      "Epoch 104. Loss: 0.00292572838147859, Train_acc 0.9988407258064517\n",
      "\n",
      "Epoch 104. Loss: 0.002693167164429696, Train_acc 0.998848157051282\n",
      "\n",
      "Epoch 104. Loss: 0.002469797544064452, Train_acc 0.9988554936305732\n",
      "\n",
      "Epoch 104. Loss: 0.00232591914514735, Train_acc 0.9988627373417721\n",
      "\n",
      "Epoch 104. Loss: 0.0021434323211185005, Train_acc 0.9988698899371069\n",
      "\n",
      "Epoch 104. Loss: 0.0021414816259299396, Train_acc 0.998876953125\n",
      "\n",
      "Epoch 104. Loss: 0.0019335385578786014, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 104. Loss: 0.0019340490653364075, Train_acc 0.9988908179012346\n",
      "\n",
      "Epoch 104. Loss: 0.004438739487908621, Train_acc 0.9988496932515337\n",
      "\n",
      "Epoch 104. Loss: 0.004014426088234918, Train_acc 0.9988567073170732\n",
      "\n",
      "Epoch 104. Loss: 0.003626656214487824, Train_acc 0.9988636363636364\n",
      "\n",
      "Epoch 104. Loss: 0.0033569151539249178, Train_acc 0.9988704819277109\n",
      "\n",
      "Epoch 104. Loss: 0.0030266139655196794, Train_acc 0.998877245508982\n",
      "\n",
      "Epoch 104. Loss: 0.0032998813780889627, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 104. Loss: 0.003160168565719937, Train_acc 0.9988905325443787\n",
      "\n",
      "Epoch 104. Loss: 0.0029271457112983153, Train_acc 0.9988970588235294\n",
      "\n",
      "Epoch 104. Loss: 0.002743954965981569, Train_acc 0.9989035087719298\n",
      "\n",
      "Epoch 104. Loss: 0.0024808489012424525, Train_acc 0.9989098837209303\n",
      "\n",
      "Epoch 104. Loss: 0.0022512574479189892, Train_acc 0.9989161849710982\n",
      "\n",
      "Epoch 104. Loss: 0.0034889860549754542, Train_acc 0.9988775143678161\n",
      "\n",
      "Epoch 104. Loss: 0.00314508838976912, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 104. Loss: 0.002834594867673331, Train_acc 0.9988902698863636\n",
      "\n",
      "Epoch 104. Loss: 0.002582552316868623, Train_acc 0.9988965395480226\n",
      "\n",
      "Epoch 104. Loss: 0.002458201923184979, Train_acc 0.9989027387640449\n",
      "\n",
      "Epoch 104. Loss: 0.0023317221040696397, Train_acc 0.9989088687150838\n",
      "\n",
      "Epoch 104. Loss: 0.002149216461066499, Train_acc 0.9989149305555556\n",
      "\n",
      "Epoch 104. Loss: 0.0020866403056017412, Train_acc 0.9989209254143646\n",
      "\n",
      "Epoch 104. Loss: 0.0020366251082083752, Train_acc 0.9989268543956044\n",
      "\n",
      "Epoch 104. Loss: 0.003068542576062188, Train_acc 0.9988900273224044\n",
      "\n",
      "Epoch 104. Loss: 0.002779469757693266, Train_acc 0.9988960597826086\n",
      "\n",
      "Epoch 104. Loss: 0.0031923964942251934, Train_acc 0.9988597972972973\n",
      "\n",
      "Epoch 104. Loss: 0.0028876847726539783, Train_acc 0.9988659274193549\n",
      "\n",
      "Epoch 104. Loss: 0.0026009420980665434, Train_acc 0.9988719919786097\n",
      "\n",
      "Epoch 104. Loss: 0.002362592084679493, Train_acc 0.9988779920212766\n",
      "\n",
      "Epoch 104. Loss: 0.0021451450654394453, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 104. Loss: 0.002173827917108866, Train_acc 0.9988898026315789\n",
      "\n",
      "Epoch 104. Loss: 0.002054753534030854, Train_acc 0.9988956151832461\n",
      "\n",
      "Epoch 104. Loss: 0.0022063401311176473, Train_acc 0.9989013671875\n",
      "\n",
      "Epoch 104. Loss: 0.0026065858165506234, Train_acc 0.9989070595854922\n",
      "\n",
      "Epoch 104. Loss: 0.002351858332516776, Train_acc 0.998912693298969\n",
      "\n",
      "Epoch 104. Loss: 0.0021372481710710987, Train_acc 0.9989182692307692\n",
      "\n",
      "Epoch 104. Loss: 0.001925655842189459, Train_acc 0.99892\n",
      "\n",
      "Epoch 105. Loss: 0.0017350907046637866, Train_acc 1.0\n",
      "\n",
      "Epoch 105. Loss: 0.0015631122986828798, Train_acc 1.0\n",
      "\n",
      "Epoch 105. Loss: 0.0016374725807776019, Train_acc 1.0\n",
      "\n",
      "Epoch 105. Loss: 0.0014785175492365067, Train_acc 1.0\n",
      "\n",
      "Epoch 105. Loss: 0.0015217113351634658, Train_acc 1.0\n",
      "\n",
      "Epoch 105. Loss: 0.0013872549625536478, Train_acc 1.0\n",
      "\n",
      "Epoch 105. Loss: 0.0013317643492118127, Train_acc 1.0\n",
      "\n",
      "Epoch 105. Loss: 0.0012092055460692181, Train_acc 1.0\n",
      "\n",
      "Epoch 105. Loss: 0.001179989100680268, Train_acc 1.0\n",
      "\n",
      "Epoch 105. Loss: 0.0010701738013833254, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105. Loss: 0.0009939765191356754, Train_acc 1.0\n",
      "\n",
      "Epoch 105. Loss: 0.0010444514985223487, Train_acc 1.0\n",
      "\n",
      "Epoch 105. Loss: 0.0009419500850945505, Train_acc 1.0\n",
      "\n",
      "Epoch 105. Loss: 0.0008496163327540179, Train_acc 1.0\n",
      "\n",
      "Epoch 105. Loss: 0.0016061147039275068, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 105. Loss: 0.0014553521705777449, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 105. Loss: 0.0013123025732541863, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 105. Loss: 0.0011965403964568483, Train_acc 0.9995659722222222\n",
      "\n",
      "Epoch 105. Loss: 0.0011503990876983233, Train_acc 0.9995888157894737\n",
      "\n",
      "Epoch 105. Loss: 0.0010628468067411523, Train_acc 0.999609375\n",
      "\n",
      "Epoch 105. Loss: 0.0023656090367702195, Train_acc 0.9992559523809523\n",
      "\n",
      "Epoch 105. Loss: 0.0021656802280911104, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 105. Loss: 0.0019527389390965983, Train_acc 0.9993206521739131\n",
      "\n",
      "Epoch 105. Loss: 0.0017586581614458848, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 105. Loss: 0.0015838675114661065, Train_acc 0.999375\n",
      "\n",
      "Epoch 105. Loss: 0.0014268193655355018, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 105. Loss: 0.0013158677491701685, Train_acc 0.9994212962962963\n",
      "\n",
      "Epoch 105. Loss: 0.0012266664628852867, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 105. Loss: 0.0011494618478634102, Train_acc 0.9994612068965517\n",
      "\n",
      "Epoch 105. Loss: 0.0010430621884276081, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 105. Loss: 0.0012042625314303882, Train_acc 0.9994959677419355\n",
      "\n",
      "Epoch 105. Loss: 0.001217806832739739, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 105. Loss: 0.0011377790081352622, Train_acc 0.9995265151515151\n",
      "\n",
      "Epoch 105. Loss: 0.0011571270569727388, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 105. Loss: 0.001064382192053175, Train_acc 0.9995535714285714\n",
      "\n",
      "Epoch 105. Loss: 0.0009604465120939096, Train_acc 0.9995659722222222\n",
      "\n",
      "Epoch 105. Loss: 0.0008676937704092238, Train_acc 0.9995777027027027\n",
      "\n",
      "Epoch 105. Loss: 0.0007843752920256216, Train_acc 0.9995888157894737\n",
      "\n",
      "Epoch 105. Loss: 0.0007070192121410672, Train_acc 0.9995993589743589\n",
      "\n",
      "Epoch 105. Loss: 0.0011285498632142817, Train_acc 0.999609375\n",
      "\n",
      "Epoch 105. Loss: 0.0010304727295226306, Train_acc 0.9996189024390244\n",
      "\n",
      "Epoch 105. Loss: 0.0009397826592199498, Train_acc 0.9996279761904762\n",
      "\n",
      "Epoch 105. Loss: 0.0008714248706884304, Train_acc 0.9996366279069767\n",
      "\n",
      "Epoch 105. Loss: 0.0007893902597512477, Train_acc 0.9996448863636364\n",
      "\n",
      "Epoch 105. Loss: 0.0007265684257660291, Train_acc 0.9996527777777777\n",
      "\n",
      "Epoch 105. Loss: 0.0006662585922223909, Train_acc 0.9996603260869565\n",
      "\n",
      "Epoch 105. Loss: 0.0006023011273362213, Train_acc 0.9996675531914894\n",
      "\n",
      "Epoch 105. Loss: 0.0005437916570698614, Train_acc 0.9996744791666666\n",
      "\n",
      "Epoch 105. Loss: 0.0018783851164992506, Train_acc 0.9995216836734694\n",
      "\n",
      "Epoch 105. Loss: 0.0016921118037581185, Train_acc 0.99953125\n",
      "\n",
      "Epoch 105. Loss: 0.0015330410309217452, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 105. Loss: 0.001381021955076493, Train_acc 0.9995492788461539\n",
      "\n",
      "Epoch 105. Loss: 0.0012602437040536588, Train_acc 0.9995577830188679\n",
      "\n",
      "Epoch 105. Loss: 0.0011349868425846986, Train_acc 0.9995659722222222\n",
      "\n",
      "Epoch 105. Loss: 0.0015622444062639079, Train_acc 0.9995738636363637\n",
      "\n",
      "Epoch 105. Loss: 0.0014065962952405807, Train_acc 0.9995814732142857\n",
      "\n",
      "Epoch 105. Loss: 0.001617518737460428, Train_acc 0.9995888157894737\n",
      "\n",
      "Epoch 105. Loss: 0.0014562114589216125, Train_acc 0.9995959051724138\n",
      "\n",
      "Epoch 105. Loss: 0.0013380002452563252, Train_acc 0.9996027542372882\n",
      "\n",
      "Epoch 105. Loss: 0.004054769446578415, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 105. Loss: 0.0036687357975255883, Train_acc 0.9994877049180327\n",
      "\n",
      "Epoch 105. Loss: 0.006431975551236698, Train_acc 0.9993699596774194\n",
      "\n",
      "Epoch 105. Loss: 0.0057900301937844475, Train_acc 0.9993799603174603\n",
      "\n",
      "Epoch 105. Loss: 0.005214458505466713, Train_acc 0.9993896484375\n",
      "\n",
      "Epoch 105. Loss: 0.0047009716088582554, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 105. Loss: 0.004249104540218515, Train_acc 0.9994081439393939\n",
      "\n",
      "Epoch 105. Loss: 0.003825642653141991, Train_acc 0.9994169776119403\n",
      "\n",
      "Epoch 105. Loss: 0.0059032895307253985, Train_acc 0.9993106617647058\n",
      "\n",
      "Epoch 105. Loss: 0.005334103919671917, Train_acc 0.9993206521739131\n",
      "\n",
      "Epoch 105. Loss: 0.004856321785974006, Train_acc 0.9993303571428571\n",
      "\n",
      "Epoch 105. Loss: 0.005370788957143575, Train_acc 0.9992297535211268\n",
      "\n",
      "Epoch 105. Loss: 0.004846119160574079, Train_acc 0.9992404513888888\n",
      "\n",
      "Epoch 105. Loss: 0.007553055830408394, Train_acc 0.9991438356164384\n",
      "\n",
      "Epoch 105. Loss: 0.007621676800497705, Train_acc 0.999049831081081\n",
      "\n",
      "Epoch 105. Loss: 0.006926972078843416, Train_acc 0.9990625\n",
      "\n",
      "Epoch 105. Loss: 0.00625235299755443, Train_acc 0.9990748355263158\n",
      "\n",
      "Epoch 105. Loss: 0.005668651433728976, Train_acc 0.9990868506493507\n",
      "\n",
      "Epoch 105. Loss: 0.00643097936833755, Train_acc 0.9989983974358975\n",
      "\n",
      "Epoch 105. Loss: 0.00798771843813231, Train_acc 0.9989121835443038\n",
      "\n",
      "Epoch 105. Loss: 0.00859000126721594, Train_acc 0.998828125\n",
      "\n",
      "Epoch 105. Loss: 0.0078828293396537, Train_acc 0.9988425925925926\n",
      "\n",
      "Epoch 105. Loss: 0.007370742315516278, Train_acc 0.9988567073170732\n",
      "\n",
      "Epoch 105. Loss: 0.006865995906560484, Train_acc 0.9988704819277109\n",
      "\n",
      "Epoch 105. Loss: 0.006568909689279375, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 105. Loss: 0.007067821327887754, Train_acc 0.9988051470588235\n",
      "\n",
      "Epoch 105. Loss: 0.0067496099536130845, Train_acc 0.9988190406976745\n",
      "\n",
      "Epoch 105. Loss: 0.006288771450140478, Train_acc 0.9988326149425287\n",
      "\n",
      "Epoch 105. Loss: 0.0058090175360754745, Train_acc 0.9988458806818182\n",
      "\n",
      "Epoch 105. Loss: 0.006189509552298393, Train_acc 0.9987710674157303\n",
      "\n",
      "Epoch 105. Loss: 0.006538895190428263, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 105. Loss: 0.0061796658428793245, Train_acc 0.9987122252747253\n",
      "\n",
      "Epoch 105. Loss: 0.005588569605801598, Train_acc 0.9987262228260869\n",
      "\n",
      "Epoch 105. Loss: 0.005150733636576619, Train_acc 0.9987399193548387\n",
      "\n",
      "Epoch 105. Loss: 0.009103324931942242, Train_acc 0.9985871010638298\n",
      "\n",
      "Epoch 105. Loss: 0.008217746009071828, Train_acc 0.9986019736842106\n",
      "\n",
      "Epoch 105. Loss: 0.007441962587814364, Train_acc 0.9986165364583334\n",
      "\n",
      "Epoch 105. Loss: 0.01203816703973487, Train_acc 0.9985502577319587\n",
      "\n",
      "Epoch 105. Loss: 0.010883549621911199, Train_acc 0.9985650510204082\n",
      "\n",
      "Epoch 105. Loss: 0.010324617363850491, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 105. Loss: 0.009379864781933473, Train_acc 0.99859375\n",
      "\n",
      "[Epoch 105 Batch 100] Loss: 0.008543486504670184 Training: accuracy=0.998608\n",
      "Epoch 105. Loss: 0.008543486504670184, Train_acc 0.9986076732673267\n",
      "\n",
      "Epoch 105. Loss: 0.010975514077171266, Train_acc 0.9985447303921569\n",
      "\n",
      "Epoch 105. Loss: 0.01101724277632646, Train_acc 0.9984830097087378\n",
      "\n",
      "Epoch 105. Loss: 0.011134366335992922, Train_acc 0.9984224759615384\n",
      "\n",
      "Epoch 105. Loss: 0.010660087724052289, Train_acc 0.9984375\n",
      "\n",
      "Epoch 105. Loss: 0.010166844709908146, Train_acc 0.9983785377358491\n",
      "\n",
      "Epoch 105. Loss: 0.009226427018714484, Train_acc 0.998393691588785\n",
      "\n",
      "Epoch 105. Loss: 0.008529318863032046, Train_acc 0.9984085648148148\n",
      "\n",
      "Epoch 105. Loss: 0.010612942608187601, Train_acc 0.9982798165137615\n",
      "\n",
      "Epoch 105. Loss: 0.009669256902961438, Train_acc 0.9982954545454545\n",
      "\n",
      "Epoch 105. Loss: 0.00888882400639296, Train_acc 0.9983108108108109\n",
      "\n",
      "Epoch 105. Loss: 0.008390207557618086, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 105. Loss: 0.010332367094224212, Train_acc 0.9982024336283186\n",
      "\n",
      "Epoch 105. Loss: 0.00932820902298288, Train_acc 0.9982182017543859\n",
      "\n",
      "Epoch 105. Loss: 0.010573118137094944, Train_acc 0.9980978260869565\n",
      "\n",
      "Epoch 105. Loss: 0.010159170430621716, Train_acc 0.998114224137931\n",
      "\n",
      "Epoch 105. Loss: 0.009259796975788067, Train_acc 0.9981303418803419\n",
      "\n",
      "Epoch 105. Loss: 0.014013175075116686, Train_acc 0.9980137711864406\n",
      "\n",
      "Epoch 105. Loss: 0.01354300356346035, Train_acc 0.9979648109243697\n",
      "\n",
      "Epoch 105. Loss: 0.012374431943801766, Train_acc 0.9979817708333333\n",
      "\n",
      "Epoch 105. Loss: 0.012138939847863668, Train_acc 0.9979338842975206\n",
      "\n",
      "Epoch 105. Loss: 0.011140728855788965, Train_acc 0.9979508196721312\n",
      "\n",
      "Epoch 105. Loss: 0.011996788038009638, Train_acc 0.9979039634146342\n",
      "\n",
      "Epoch 105. Loss: 0.014324365335578532, Train_acc 0.9977948588709677\n",
      "\n",
      "Epoch 105. Loss: 0.012912437939559873, Train_acc 0.9978125\n",
      "\n",
      "Epoch 105. Loss: 0.011639719285207184, Train_acc 0.9978298611111112\n",
      "\n",
      "Epoch 105. Loss: 0.010503917553724446, Train_acc 0.9978469488188977\n",
      "\n",
      "Epoch 105. Loss: 0.009698611017273305, Train_acc 0.99786376953125\n",
      "\n",
      "Epoch 105. Loss: 0.009748165361171757, Train_acc 0.9978803294573644\n",
      "\n",
      "Epoch 105. Loss: 0.009536221828313884, Train_acc 0.9978966346153846\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105. Loss: 0.009043472630905106, Train_acc 0.9979126908396947\n",
      "\n",
      "Epoch 105. Loss: 0.009721748082155281, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 105. Loss: 0.011785996115190649, Train_acc 0.9978265977443609\n",
      "\n",
      "Epoch 105. Loss: 0.012740193931147037, Train_acc 0.9977845149253731\n",
      "\n",
      "Epoch 105. Loss: 0.011584438651585201, Train_acc 0.997800925925926\n",
      "\n",
      "Epoch 105. Loss: 0.010683722848996777, Train_acc 0.9978170955882353\n",
      "\n",
      "Epoch 105. Loss: 0.009671200407289944, Train_acc 0.9978330291970803\n",
      "\n",
      "Epoch 105. Loss: 0.00893236585337086, Train_acc 0.997848731884058\n",
      "\n",
      "Epoch 105. Loss: 0.008644663238553674, Train_acc 0.9978642086330936\n",
      "\n",
      "Epoch 105. Loss: 0.007901623892846826, Train_acc 0.9978794642857143\n",
      "\n",
      "Epoch 105. Loss: 0.007122706344714946, Train_acc 0.9978945035460993\n",
      "\n",
      "Epoch 105. Loss: 0.00716066996767329, Train_acc 0.9978543133802817\n",
      "\n",
      "Epoch 105. Loss: 0.006472247331576781, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 105. Loss: 0.005853736146509412, Train_acc 0.9978841145833334\n",
      "\n",
      "Epoch 105. Loss: 0.00527466387567783, Train_acc 0.9978987068965517\n",
      "\n",
      "Epoch 105. Loss: 0.006399891981642228, Train_acc 0.9978060787671232\n",
      "\n",
      "Epoch 105. Loss: 0.0058031070472619965, Train_acc 0.9978210034013606\n",
      "\n",
      "Epoch 105. Loss: 0.005232515561623652, Train_acc 0.9978357263513513\n",
      "\n",
      "Epoch 105. Loss: 0.0047939573919135595, Train_acc 0.9978502516778524\n",
      "\n",
      "Epoch 105. Loss: 0.005728767345430695, Train_acc 0.9978125\n",
      "\n",
      "Epoch 105. Loss: 0.010088049051239112, Train_acc 0.9977235099337748\n",
      "\n",
      "Epoch 105. Loss: 0.010092338519162554, Train_acc 0.9976870888157895\n",
      "\n",
      "Epoch 105. Loss: 0.009446117955252487, Train_acc 0.9977022058823529\n",
      "\n",
      "Epoch 105. Loss: 0.019105254421655796, Train_acc 0.997564935064935\n",
      "\n",
      "Epoch 105. Loss: 0.019283712895236428, Train_acc 0.9975302419354839\n",
      "\n",
      "Epoch 105. Loss: 0.017384827883784783, Train_acc 0.9975460737179487\n",
      "\n",
      "Epoch 105. Loss: 0.01567807660594119, Train_acc 0.9975617038216561\n",
      "\n",
      "Epoch 105. Loss: 0.014185904125457182, Train_acc 0.9975771360759493\n",
      "\n",
      "Epoch 105. Loss: 0.013068569184915878, Train_acc 0.9975923742138365\n",
      "\n",
      "Epoch 105. Loss: 0.014891424013593786, Train_acc 0.997509765625\n",
      "\n",
      "Epoch 105. Loss: 0.01360737060111224, Train_acc 0.9975252329192547\n",
      "\n",
      "Epoch 105. Loss: 0.012761352384625013, Train_acc 0.9975405092592593\n",
      "\n",
      "Epoch 105. Loss: 0.011688401533809126, Train_acc 0.9975555981595092\n",
      "\n",
      "Epoch 105. Loss: 0.010938041121047872, Train_acc 0.9975705030487805\n",
      "\n",
      "Epoch 105. Loss: 0.009859635985336129, Train_acc 0.9975852272727272\n",
      "\n",
      "Epoch 105. Loss: 0.011714761307634197, Train_acc 0.9975527108433735\n",
      "\n",
      "Epoch 105. Loss: 0.013320862368462041, Train_acc 0.9974270209580839\n",
      "\n",
      "Epoch 105. Loss: 0.014407721488819322, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 105. Loss: 0.013893031362425506, Train_acc 0.9974112426035503\n",
      "\n",
      "Epoch 105. Loss: 0.014206170805154343, Train_acc 0.9973805147058824\n",
      "\n",
      "Epoch 105. Loss: 0.013537900687329263, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 105. Loss: 0.01281252937338259, Train_acc 0.9974109738372093\n",
      "\n",
      "Epoch 105. Loss: 0.011598521237947475, Train_acc 0.9974259393063584\n",
      "\n",
      "Epoch 105. Loss: 0.01234509648267442, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 105. Loss: 0.013666242522454387, Train_acc 0.9973660714285715\n",
      "\n",
      "Epoch 105. Loss: 0.012532493920026236, Train_acc 0.9973810369318182\n",
      "\n",
      "Epoch 105. Loss: 0.011403644474094822, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 105. Loss: 0.011793960645865543, Train_acc 0.9973226825842697\n",
      "\n",
      "Epoch 105. Loss: 0.010838960445922145, Train_acc 0.9973376396648045\n",
      "\n",
      "Epoch 105. Loss: 0.011560845601858076, Train_acc 0.997265625\n",
      "\n",
      "Epoch 105. Loss: 0.010620120772318282, Train_acc 0.9972807320441989\n",
      "\n",
      "Epoch 105. Loss: 0.00972505760309509, Train_acc 0.9972956730769231\n",
      "\n",
      "Epoch 105. Loss: 0.009034643560021326, Train_acc 0.9973104508196722\n",
      "\n",
      "Epoch 105. Loss: 0.008497016913997417, Train_acc 0.9973250679347826\n",
      "\n",
      "Epoch 105. Loss: 0.008020430473438459, Train_acc 0.997339527027027\n",
      "\n",
      "Epoch 105. Loss: 0.007332950824623458, Train_acc 0.9973538306451613\n",
      "\n",
      "Epoch 105. Loss: 0.006629879336673903, Train_acc 0.9973679812834224\n",
      "\n",
      "Epoch 105. Loss: 0.008490546102332075, Train_acc 0.9973404255319149\n",
      "\n",
      "Epoch 105. Loss: 0.007964721217571497, Train_acc 0.9973544973544973\n",
      "\n",
      "Epoch 105. Loss: 0.008199065233605026, Train_acc 0.997327302631579\n",
      "\n",
      "Epoch 105. Loss: 0.007605739760327565, Train_acc 0.9973412958115183\n",
      "\n",
      "Epoch 105. Loss: 0.008253857116039003, Train_acc 0.997314453125\n",
      "\n",
      "Epoch 105. Loss: 0.007697291774982576, Train_acc 0.9973283678756477\n",
      "\n",
      "Epoch 105. Loss: 0.007374706398040978, Train_acc 0.9973421391752577\n",
      "\n",
      "Epoch 105. Loss: 0.006750416107817824, Train_acc 0.9973557692307692\n",
      "\n",
      "Epoch 105. Loss: 0.006082315621629182, Train_acc 0.99736\n",
      "\n",
      "Epoch 106. Loss: 0.006147115028221748, Train_acc 0.9921875\n",
      "\n",
      "Epoch 106. Loss: 0.00595105099721492, Train_acc 0.99609375\n",
      "\n",
      "Epoch 106. Loss: 0.005475939803030259, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 106. Loss: 0.005090147613545804, Train_acc 0.998046875\n",
      "\n",
      "Epoch 106. Loss: 0.004778154073001935, Train_acc 0.9984375\n",
      "\n",
      "Epoch 106. Loss: 0.004307406433430328, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 106. Loss: 0.003962053285433663, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 106. Loss: 0.0036043056973377808, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 106. Loss: 0.0034860748065093108, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 106. Loss: 0.0031845190112549616, Train_acc 0.99921875\n",
      "\n",
      "Epoch 106. Loss: 0.0029556107954465047, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 106. Loss: 0.003331280577818992, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 106. Loss: 0.0032722606374833963, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 106. Loss: 0.0029574971540787653, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 106. Loss: 0.002688259217958719, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 106. Loss: 0.003210238665778402, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 106. Loss: 0.002899828445937163, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 106. Loss: 0.0028296564019703206, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 106. Loss: 0.0028048870467677713, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 106. Loss: 0.0025708763706165927, Train_acc 0.998828125\n",
      "\n",
      "Epoch 106. Loss: 0.0074318972743283255, Train_acc 0.9985119047619048\n",
      "\n",
      "Epoch 106. Loss: 0.006697215597709764, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 106. Loss: 0.006035508706067241, Train_acc 0.998641304347826\n",
      "\n",
      "Epoch 106. Loss: 0.0059260972907193635, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 106. Loss: 0.005355284526222032, Train_acc 0.99875\n",
      "\n",
      "Epoch 106. Loss: 0.004827950481164417, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 106. Loss: 0.004390958441881875, Train_acc 0.9988425925925926\n",
      "\n",
      "Epoch 106. Loss: 0.005027851605643517, Train_acc 0.9986049107142857\n",
      "\n",
      "Epoch 106. Loss: 0.0046066220544376405, Train_acc 0.9986530172413793\n",
      "\n",
      "Epoch 106. Loss: 0.004677772466549137, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 106. Loss: 0.004337049772907518, Train_acc 0.9987399193548387\n",
      "\n",
      "Epoch 106. Loss: 0.003926847908223471, Train_acc 0.998779296875\n",
      "\n",
      "Epoch 106. Loss: 0.004365327909581185, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 106. Loss: 0.0039558548269957566, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 106. Loss: 0.003716340020462745, Train_acc 0.9986607142857142\n",
      "\n",
      "Epoch 106. Loss: 0.003379602652004248, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 106. Loss: 0.003135051986307326, Train_acc 0.9987331081081081\n",
      "\n",
      "Epoch 106. Loss: 0.0028330862585466414, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 106. Loss: 0.002561203192624809, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 106. Loss: 0.002326670710907995, Train_acc 0.998828125\n",
      "\n",
      "Epoch 106. Loss: 0.0028320401326566514, Train_acc 0.9986661585365854\n",
      "\n",
      "Epoch 106. Loss: 0.0026314191987383733, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 106. Loss: 0.0033499052423478694, Train_acc 0.998546511627907\n",
      "\n",
      "Epoch 106. Loss: 0.004660202030680316, Train_acc 0.9984019886363636\n",
      "\n",
      "Epoch 106. Loss: 0.004347715359896485, Train_acc 0.9984375\n",
      "\n",
      "Epoch 106. Loss: 0.003944082108155137, Train_acc 0.9984714673913043\n",
      "\n",
      "Epoch 106. Loss: 0.003700614790557545, Train_acc 0.9985039893617021\n",
      "\n",
      "Epoch 106. Loss: 0.0035039173905934886, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 106. Loss: 0.0051466338197785014, Train_acc 0.998405612244898\n",
      "\n",
      "Epoch 106. Loss: 0.004745507483927673, Train_acc 0.9984375\n",
      "\n",
      "Epoch 106. Loss: 0.004326708271809234, Train_acc 0.9984681372549019\n",
      "\n",
      "Epoch 106. Loss: 0.004709365282691551, Train_acc 0.9983473557692307\n",
      "\n",
      "Epoch 106. Loss: 0.004328648015314295, Train_acc 0.9983785377358491\n",
      "\n",
      "Epoch 106. Loss: 0.003906289789710003, Train_acc 0.9984085648148148\n",
      "\n",
      "Epoch 106. Loss: 0.0036053585368098842, Train_acc 0.9984375\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106. Loss: 0.003514193791280868, Train_acc 0.9984654017857143\n",
      "\n",
      "Epoch 106. Loss: 0.0033300878281755887, Train_acc 0.9984923245614035\n",
      "\n",
      "Epoch 106. Loss: 0.003584262235867707, Train_acc 0.9983836206896551\n",
      "\n",
      "Epoch 106. Loss: 0.0034265669470200494, Train_acc 0.9984110169491526\n",
      "\n",
      "Epoch 106. Loss: 0.0032698885950970254, Train_acc 0.9984375\n",
      "\n",
      "Epoch 106. Loss: 0.0030566973424876573, Train_acc 0.9984631147540983\n",
      "\n",
      "Epoch 106. Loss: 0.0028286939796011755, Train_acc 0.9984879032258065\n",
      "\n",
      "Epoch 106. Loss: 0.0026881891697415213, Train_acc 0.9985119047619048\n",
      "\n",
      "Epoch 106. Loss: 0.0024405932141354086, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 106. Loss: 0.0060009933155486354, Train_acc 0.9984375\n",
      "\n",
      "Epoch 106. Loss: 0.005492558360662404, Train_acc 0.9984611742424242\n",
      "\n",
      "Epoch 106. Loss: 0.011482581747084568, Train_acc 0.9982509328358209\n",
      "\n",
      "Epoch 106. Loss: 0.010338656317096271, Train_acc 0.9982766544117647\n",
      "\n",
      "Epoch 106. Loss: 0.009340616659578183, Train_acc 0.9983016304347826\n",
      "\n",
      "Epoch 106. Loss: 0.00841683014825684, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 106. Loss: 0.010154537018499096, Train_acc 0.9981294014084507\n",
      "\n",
      "Epoch 106. Loss: 0.009148396636255196, Train_acc 0.9981553819444444\n",
      "\n",
      "Epoch 106. Loss: 0.008240066675864445, Train_acc 0.9981806506849316\n",
      "\n",
      "Epoch 106. Loss: 0.0075521251421252975, Train_acc 0.9982052364864865\n",
      "\n",
      "Epoch 106. Loss: 0.00683534492870205, Train_acc 0.9982291666666666\n",
      "\n",
      "Epoch 106. Loss: 0.006201188623227477, Train_acc 0.9982524671052632\n",
      "\n",
      "Epoch 106. Loss: 0.006541446805880488, Train_acc 0.9981737012987013\n",
      "\n",
      "Epoch 106. Loss: 0.006023936145892907, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 106. Loss: 0.0078546944693248, Train_acc 0.9981210443037974\n",
      "\n",
      "Epoch 106. Loss: 0.007463584486218142, Train_acc 0.99814453125\n",
      "\n",
      "Epoch 106. Loss: 0.006853343325507803, Train_acc 0.9981674382716049\n",
      "\n",
      "Epoch 106. Loss: 0.006947281515734341, Train_acc 0.9980945121951219\n",
      "\n",
      "Epoch 106. Loss: 0.007058741388741386, Train_acc 0.998023343373494\n",
      "\n",
      "Epoch 106. Loss: 0.010114475030919837, Train_acc 0.9979538690476191\n",
      "\n",
      "Epoch 106. Loss: 0.009617725463260049, Train_acc 0.9979779411764705\n",
      "\n",
      "Epoch 106. Loss: 0.008765396823628695, Train_acc 0.9980014534883721\n",
      "\n",
      "Epoch 106. Loss: 0.007907118298940542, Train_acc 0.9980244252873564\n",
      "\n",
      "Epoch 106. Loss: 0.007726121193169966, Train_acc 0.9979580965909091\n",
      "\n",
      "Epoch 106. Loss: 0.006977359137588123, Train_acc 0.9979810393258427\n",
      "\n",
      "Epoch 106. Loss: 0.008638592711079161, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 106. Loss: 0.010815497734535969, Train_acc 0.9978537087912088\n",
      "\n",
      "Epoch 106. Loss: 0.0097921148766332, Train_acc 0.9978770380434783\n",
      "\n",
      "Epoch 106. Loss: 0.008932327767469267, Train_acc 0.9978998655913979\n",
      "\n",
      "Epoch 106. Loss: 0.008176395174718899, Train_acc 0.9979222074468085\n",
      "\n",
      "Epoch 106. Loss: 0.008700427526405754, Train_acc 0.9978618421052632\n",
      "\n",
      "Epoch 106. Loss: 0.008825737265501591, Train_acc 0.997802734375\n",
      "\n",
      "Epoch 106. Loss: 0.008335116185847674, Train_acc 0.9978253865979382\n",
      "\n",
      "Epoch 106. Loss: 0.007608070069439341, Train_acc 0.9978475765306123\n",
      "\n",
      "Epoch 106. Loss: 0.007775700772303757, Train_acc 0.9977904040404041\n",
      "\n",
      "Epoch 106. Loss: 0.007104308860952482, Train_acc 0.9978125\n",
      "\n",
      "[Epoch 106 Batch 100] Loss: 0.012551237828244114 Training: accuracy=0.997757\n",
      "Epoch 106. Loss: 0.012551237828244114, Train_acc 0.997756806930693\n",
      "\n",
      "Epoch 106. Loss: 0.011355559410751769, Train_acc 0.9977787990196079\n",
      "\n",
      "Epoch 106. Loss: 0.010403684344437787, Train_acc 0.9978003640776699\n",
      "\n",
      "Epoch 106. Loss: 0.009430941779990855, Train_acc 0.9978215144230769\n",
      "\n",
      "Epoch 106. Loss: 0.009183666264635203, Train_acc 0.9978422619047619\n",
      "\n",
      "Epoch 106. Loss: 0.00853630903586466, Train_acc 0.9978626179245284\n",
      "\n",
      "Epoch 106. Loss: 0.008012964139652719, Train_acc 0.997882593457944\n",
      "\n",
      "Epoch 106. Loss: 0.007367379772813591, Train_acc 0.9979021990740741\n",
      "\n",
      "Epoch 106. Loss: 0.0068122035971148074, Train_acc 0.9979214449541285\n",
      "\n",
      "Epoch 106. Loss: 0.006557806696968966, Train_acc 0.9979403409090909\n",
      "\n",
      "Epoch 106. Loss: 0.006983081243763292, Train_acc 0.9978885135135135\n",
      "\n",
      "Epoch 106. Loss: 0.006451000718061558, Train_acc 0.9979073660714286\n",
      "\n",
      "Epoch 106. Loss: 0.006881624786065011, Train_acc 0.9978567477876106\n",
      "\n",
      "Epoch 106. Loss: 0.006279347129059722, Train_acc 0.9978755482456141\n",
      "\n",
      "Epoch 106. Loss: 0.0058766511044438694, Train_acc 0.9978940217391304\n",
      "\n",
      "Epoch 106. Loss: 0.005450237722422422, Train_acc 0.9979121767241379\n",
      "\n",
      "Epoch 106. Loss: 0.005395955707856186, Train_acc 0.9979300213675214\n",
      "\n",
      "Epoch 106. Loss: 0.004938423084401564, Train_acc 0.997947563559322\n",
      "\n",
      "Epoch 106. Loss: 0.004592974408805498, Train_acc 0.9979648109243697\n",
      "\n",
      "Epoch 106. Loss: 0.004183041313538815, Train_acc 0.9979817708333333\n",
      "\n",
      "Epoch 106. Loss: 0.0040816141933946596, Train_acc 0.9979984504132231\n",
      "\n",
      "Epoch 106. Loss: 0.0045329666528775205, Train_acc 0.9980148565573771\n",
      "\n",
      "Epoch 106. Loss: 0.004851440101668887, Train_acc 0.9980309959349594\n",
      "\n",
      "Epoch 106. Loss: 0.00449623117867245, Train_acc 0.998046875\n",
      "\n",
      "Epoch 106. Loss: 0.004052732523184581, Train_acc 0.9980625\n",
      "\n",
      "Epoch 106. Loss: 0.007827118756683078, Train_acc 0.998015873015873\n",
      "\n",
      "Epoch 106. Loss: 0.008899420773069329, Train_acc 0.9979699803149606\n",
      "\n",
      "Epoch 106. Loss: 0.00804754952115664, Train_acc 0.99798583984375\n",
      "\n",
      "Epoch 106. Loss: 0.007323760587181292, Train_acc 0.9980014534883721\n",
      "\n",
      "Epoch 106. Loss: 0.006833366440867461, Train_acc 0.9980168269230769\n",
      "\n",
      "Epoch 106. Loss: 0.00941588265043653, Train_acc 0.9979723282442748\n",
      "\n",
      "Epoch 106. Loss: 0.01041370547421715, Train_acc 0.9979285037878788\n",
      "\n",
      "Epoch 106. Loss: 0.00946756398136377, Train_acc 0.9979440789473685\n",
      "\n",
      "Epoch 106. Loss: 0.00856924217787349, Train_acc 0.9979594216417911\n",
      "\n",
      "Epoch 106. Loss: 0.007721700423844952, Train_acc 0.9979745370370371\n",
      "\n",
      "Epoch 106. Loss: 0.007230452776637642, Train_acc 0.9979894301470589\n",
      "\n",
      "Epoch 106. Loss: 0.006539785521998527, Train_acc 0.998004105839416\n",
      "\n",
      "Epoch 106. Loss: 0.007656706787146202, Train_acc 0.9979619565217391\n",
      "\n",
      "Epoch 106. Loss: 0.0069882447880852865, Train_acc 0.997976618705036\n",
      "\n",
      "Epoch 106. Loss: 0.006419006639426081, Train_acc 0.9979910714285715\n",
      "\n",
      "Epoch 106. Loss: 0.005955977919564511, Train_acc 0.9980053191489362\n",
      "\n",
      "Epoch 106. Loss: 0.0055001877113722555, Train_acc 0.9980193661971831\n",
      "\n",
      "Epoch 106. Loss: 0.005173077017065238, Train_acc 0.9980332167832168\n",
      "\n",
      "Epoch 106. Loss: 0.004909381793622391, Train_acc 0.998046875\n",
      "\n",
      "Epoch 106. Loss: 0.004429739908074818, Train_acc 0.9980603448275862\n",
      "\n",
      "Epoch 106. Loss: 0.004123423092875316, Train_acc 0.9980736301369864\n",
      "\n",
      "Epoch 106. Loss: 0.003767268562997596, Train_acc 0.9980867346938775\n",
      "\n",
      "Epoch 106. Loss: 0.003427177294155404, Train_acc 0.9980996621621622\n",
      "\n",
      "Epoch 106. Loss: 0.003295644641945164, Train_acc 0.9981124161073825\n",
      "\n",
      "Epoch 106. Loss: 0.003000859703345434, Train_acc 0.998125\n",
      "\n",
      "Epoch 106. Loss: 0.003607396142831447, Train_acc 0.9980856788079471\n",
      "\n",
      "Epoch 106. Loss: 0.0032552824891660943, Train_acc 0.9980982730263158\n",
      "\n",
      "Epoch 106. Loss: 0.0036640405764777366, Train_acc 0.9980596405228758\n",
      "\n",
      "Epoch 106. Loss: 0.003401070985121182, Train_acc 0.9980722402597403\n",
      "\n",
      "Epoch 106. Loss: 0.0030754163060274396, Train_acc 0.9980846774193548\n",
      "\n",
      "Epoch 106. Loss: 0.002815863998927102, Train_acc 0.9980969551282052\n",
      "\n",
      "Epoch 106. Loss: 0.0028196657325229874, Train_acc 0.998109076433121\n",
      "\n",
      "Epoch 106. Loss: 0.0025485894255466534, Train_acc 0.9981210443037974\n",
      "\n",
      "Epoch 106. Loss: 0.00818969975465184, Train_acc 0.9980837264150944\n",
      "\n",
      "Epoch 106. Loss: 0.0073774441194569195, Train_acc 0.998095703125\n",
      "\n",
      "Epoch 106. Loss: 0.006798733758977961, Train_acc 0.9981075310559007\n",
      "\n",
      "Epoch 106. Loss: 0.006177267940742742, Train_acc 0.9981192129629629\n",
      "\n",
      "Epoch 106. Loss: 0.005569542045724208, Train_acc 0.9981307515337423\n",
      "\n",
      "Epoch 106. Loss: 0.005107392026361583, Train_acc 0.9981421493902439\n",
      "\n",
      "Epoch 106. Loss: 0.004687535174648918, Train_acc 0.9981534090909091\n",
      "\n",
      "Epoch 106. Loss: 0.004229426944877505, Train_acc 0.9981645331325302\n",
      "\n",
      "Epoch 106. Loss: 0.0038100966141880657, Train_acc 0.9981755239520959\n",
      "\n",
      "Epoch 106. Loss: 0.0035330079652565217, Train_acc 0.9981863839285714\n",
      "\n",
      "Epoch 106. Loss: 0.003495383216197565, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 106. Loss: 0.0032245637652231975, Train_acc 0.9982077205882353\n",
      "\n",
      "Epoch 106. Loss: 0.002965576416801249, Train_acc 0.9982182017543859\n",
      "\n",
      "Epoch 106. Loss: 0.0027013738323131593, Train_acc 0.9982285610465116\n",
      "\n",
      "Epoch 106. Loss: 0.0027078620478626545, Train_acc 0.9982388005780347\n",
      "\n",
      "Epoch 106. Loss: 0.0024472240788186244, Train_acc 0.9982489224137931\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106. Loss: 0.0023091362198020206, Train_acc 0.9982589285714286\n",
      "\n",
      "Epoch 106. Loss: 0.0024454914712004534, Train_acc 0.9982688210227273\n",
      "\n",
      "Epoch 106. Loss: 0.0022040347479476093, Train_acc 0.9982786016949152\n",
      "\n",
      "Epoch 106. Loss: 0.0019973127160953187, Train_acc 0.9982882724719101\n",
      "\n",
      "Epoch 106. Loss: 0.0018163888723270254, Train_acc 0.9982978351955307\n",
      "\n",
      "Epoch 106. Loss: 0.0016472460377534397, Train_acc 0.9983072916666667\n",
      "\n",
      "Epoch 106. Loss: 0.0015100252929970027, Train_acc 0.9983166436464088\n",
      "\n",
      "Epoch 106. Loss: 0.0013613161786429002, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 106. Loss: 0.0012841246952554806, Train_acc 0.9983350409836066\n",
      "\n",
      "Epoch 106. Loss: 0.0012015493355219788, Train_acc 0.9983440896739131\n",
      "\n",
      "Epoch 106. Loss: 0.002646398169579377, Train_acc 0.9983108108108109\n",
      "\n",
      "Epoch 106. Loss: 0.002574015136687997, Train_acc 0.9983198924731183\n",
      "\n",
      "Epoch 106. Loss: 0.002319196311485843, Train_acc 0.9983288770053476\n",
      "\n",
      "Epoch 106. Loss: 0.00211715104925725, Train_acc 0.9983377659574468\n",
      "\n",
      "Epoch 106. Loss: 0.0023362690269776564, Train_acc 0.9983465608465608\n",
      "\n",
      "Epoch 106. Loss: 0.002106636902951658, Train_acc 0.9983552631578947\n",
      "\n",
      "Epoch 106. Loss: 0.0021078664442644663, Train_acc 0.9983638743455497\n",
      "\n",
      "Epoch 106. Loss: 0.001959327910609199, Train_acc 0.9983723958333334\n",
      "\n",
      "Epoch 106. Loss: 0.0018295514440131069, Train_acc 0.998380829015544\n",
      "\n",
      "Epoch 106. Loss: 0.0029847951737575424, Train_acc 0.9983489046391752\n",
      "\n",
      "Epoch 106. Loss: 0.002719495277477557, Train_acc 0.9983573717948718\n",
      "\n",
      "Epoch 106. Loss: 0.0031523262501119862, Train_acc 0.99836\n",
      "\n",
      "Epoch 107. Loss: 0.003202546046929892, Train_acc 1.0\n",
      "\n",
      "Epoch 107. Loss: 0.007533707535347941, Train_acc 0.99609375\n",
      "\n",
      "Epoch 107. Loss: 0.006787911471329479, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 107. Loss: 0.006136157494562915, Train_acc 0.998046875\n",
      "\n",
      "Epoch 107. Loss: 0.0064461733647686705, Train_acc 0.996875\n",
      "\n",
      "Epoch 107. Loss: 0.005961501635011505, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 107. Loss: 0.006886912207510893, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 107. Loss: 0.006286829216758303, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 107. Loss: 0.005781741170995586, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 107. Loss: 0.006577901430201369, Train_acc 0.99609375\n",
      "\n",
      "Epoch 107. Loss: 0.005958857618301143, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 107. Loss: 0.007472199558492628, Train_acc 0.99609375\n",
      "\n",
      "Epoch 107. Loss: 0.006819181268713513, Train_acc 0.9963942307692307\n",
      "\n",
      "Epoch 107. Loss: 0.006188629877557581, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 107. Loss: 0.005615083986903183, Train_acc 0.996875\n",
      "\n",
      "Epoch 107. Loss: 0.005062994771546968, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 107. Loss: 0.004571261170728108, Train_acc 0.9972426470588235\n",
      "\n",
      "Epoch 107. Loss: 0.004560613424232394, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 107. Loss: 0.004161695660114996, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 107. Loss: 0.0039545160207173635, Train_acc 0.99765625\n",
      "\n",
      "Epoch 107. Loss: 0.00366576347324071, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 107. Loss: 0.003324313979059504, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 107. Loss: 0.003012357978622098, Train_acc 0.9979619565217391\n",
      "\n",
      "Epoch 107. Loss: 0.0027304124673418516, Train_acc 0.998046875\n",
      "\n",
      "Epoch 107. Loss: 0.002502849200773409, Train_acc 0.998125\n",
      "\n",
      "Epoch 107. Loss: 0.0022750921123026353, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 107. Loss: 0.002082751425554659, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 107. Loss: 0.0018949072039940338, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 107. Loss: 0.0020606905741380197, Train_acc 0.9983836206896551\n",
      "\n",
      "Epoch 107. Loss: 0.0019698965271907933, Train_acc 0.9984375\n",
      "\n",
      "Epoch 107. Loss: 0.0018030830559343073, Train_acc 0.9984879032258065\n",
      "\n",
      "Epoch 107. Loss: 0.0016877915783525981, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 107. Loss: 0.0015365800571953336, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 107. Loss: 0.0013874048177108147, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 107. Loss: 0.0013839888122265023, Train_acc 0.9986607142857142\n",
      "\n",
      "Epoch 107. Loss: 0.0014622051310465766, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 107. Loss: 0.0013197356178366107, Train_acc 0.9987331081081081\n",
      "\n",
      "Epoch 107. Loss: 0.0043651564014556676, Train_acc 0.9983552631578947\n",
      "\n",
      "Epoch 107. Loss: 0.003990152300698549, Train_acc 0.9983974358974359\n",
      "\n",
      "Epoch 107. Loss: 0.0036228995301768843, Train_acc 0.9984375\n",
      "\n",
      "Epoch 107. Loss: 0.00338543368245548, Train_acc 0.9984756097560976\n",
      "\n",
      "Epoch 107. Loss: 0.003769483569550985, Train_acc 0.9985119047619048\n",
      "\n",
      "Epoch 107. Loss: 0.011153449627716965, Train_acc 0.9981831395348837\n",
      "\n",
      "Epoch 107. Loss: 0.011293946776950024, Train_acc 0.998046875\n",
      "\n",
      "Epoch 107. Loss: 0.010372329583575127, Train_acc 0.9980902777777778\n",
      "\n",
      "Epoch 107. Loss: 0.009989736115166365, Train_acc 0.9979619565217391\n",
      "\n",
      "Epoch 107. Loss: 0.009129888836592125, Train_acc 0.9980053191489362\n",
      "\n",
      "Epoch 107. Loss: 0.014050509355112631, Train_acc 0.99755859375\n",
      "\n",
      "Epoch 107. Loss: 0.01793977132884686, Train_acc 0.9972895408163265\n",
      "\n",
      "Epoch 107. Loss: 0.0164323896960365, Train_acc 0.99734375\n",
      "\n",
      "Epoch 107. Loss: 0.017049694691236073, Train_acc 0.9972426470588235\n",
      "\n",
      "Epoch 107. Loss: 0.02380035710406475, Train_acc 0.9965444711538461\n",
      "\n",
      "Epoch 107. Loss: 0.026697476733376142, Train_acc 0.9960200471698113\n",
      "\n",
      "Epoch 107. Loss: 0.02459452275885602, Train_acc 0.99609375\n",
      "\n",
      "Epoch 107. Loss: 0.022314346737464165, Train_acc 0.9961647727272728\n",
      "\n",
      "Epoch 107. Loss: 0.028120981371521858, Train_acc 0.9958147321428571\n",
      "\n",
      "Epoch 107. Loss: 0.03093045060287706, Train_acc 0.9954769736842105\n",
      "\n",
      "Epoch 107. Loss: 0.028417829519815373, Train_acc 0.9955549568965517\n",
      "\n",
      "Epoch 107. Loss: 0.025878691899082477, Train_acc 0.9956302966101694\n",
      "\n",
      "Epoch 107. Loss: 0.023643851124876512, Train_acc 0.995703125\n",
      "\n",
      "Epoch 107. Loss: 0.02278009844002167, Train_acc 0.9956454918032787\n",
      "\n",
      "Epoch 107. Loss: 0.02110573463598227, Train_acc 0.9957157258064516\n",
      "\n",
      "Epoch 107. Loss: 0.020800356384748243, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 107. Loss: 0.01889585735645952, Train_acc 0.9957275390625\n",
      "\n",
      "Epoch 107. Loss: 0.018045176853958327, Train_acc 0.9957932692307693\n",
      "\n",
      "Epoch 107. Loss: 0.016880510140782796, Train_acc 0.9958570075757576\n",
      "\n",
      "Epoch 107. Loss: 0.016927267214053455, Train_acc 0.9958022388059702\n",
      "\n",
      "Epoch 107. Loss: 0.018220156520956977, Train_acc 0.9957490808823529\n",
      "\n",
      "Epoch 107. Loss: 0.021655607304293716, Train_acc 0.9954710144927537\n",
      "\n",
      "Epoch 107. Loss: 0.02028332227660907, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 107. Loss: 0.018887922272327776, Train_acc 0.9955985915492958\n",
      "\n",
      "Epoch 107. Loss: 0.017468085699745926, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 107. Loss: 0.015790384058775527, Train_acc 0.9957191780821918\n",
      "\n",
      "Epoch 107. Loss: 0.014286328039911709, Train_acc 0.995777027027027\n",
      "\n",
      "Epoch 107. Loss: 0.0134726364492005, Train_acc 0.9958333333333333\n",
      "\n",
      "Epoch 107. Loss: 0.012198646039746781, Train_acc 0.9958881578947368\n",
      "\n",
      "Epoch 107. Loss: 0.011084638283721429, Train_acc 0.9959415584415584\n",
      "\n",
      "Epoch 107. Loss: 0.010191612184260925, Train_acc 0.9959935897435898\n",
      "\n",
      "Epoch 107. Loss: 0.009991492266399837, Train_acc 0.9959454113924051\n",
      "\n",
      "Epoch 107. Loss: 0.012086126224645832, Train_acc 0.995703125\n",
      "\n",
      "Epoch 107. Loss: 0.013968383610053831, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 107. Loss: 0.012606908777925946, Train_acc 0.9957126524390244\n",
      "\n",
      "Epoch 107. Loss: 0.01148617195765547, Train_acc 0.9957643072289156\n",
      "\n",
      "Epoch 107. Loss: 0.010621222230355788, Train_acc 0.9958147321428571\n",
      "\n",
      "Epoch 107. Loss: 0.010965131109262272, Train_acc 0.9957720588235294\n",
      "\n",
      "Epoch 107. Loss: 0.009906675366119085, Train_acc 0.9958212209302325\n",
      "\n",
      "Epoch 107. Loss: 0.009851953955044334, Train_acc 0.9958692528735632\n",
      "\n",
      "Epoch 107. Loss: 0.01194769489456712, Train_acc 0.9958274147727273\n",
      "\n",
      "Epoch 107. Loss: 0.010975688591431072, Train_acc 0.995874297752809\n",
      "\n",
      "Epoch 107. Loss: 0.010004282124840906, Train_acc 0.9959201388888889\n",
      "\n",
      "Epoch 107. Loss: 0.009167426461711101, Train_acc 0.9959649725274725\n",
      "\n",
      "Epoch 107. Loss: 0.008734649502993738, Train_acc 0.9960088315217391\n",
      "\n",
      "Epoch 107. Loss: 0.008239039536948009, Train_acc 0.996051747311828\n",
      "\n",
      "Epoch 107. Loss: 0.007666666439147297, Train_acc 0.99609375\n",
      "\n",
      "Epoch 107. Loss: 0.008192572990183385, Train_acc 0.9960526315789474\n",
      "\n",
      "Epoch 107. Loss: 0.007423205238682571, Train_acc 0.99609375\n",
      "\n",
      "Epoch 107. Loss: 0.007838786244037041, Train_acc 0.9960534793814433\n",
      "\n",
      "Epoch 107. Loss: 0.0072076172108357746, Train_acc 0.99609375\n",
      "\n",
      "Epoch 107. Loss: 0.006782316039866709, Train_acc 0.9961332070707071\n",
      "\n",
      "Epoch 107. Loss: 0.006174706341495591, Train_acc 0.996171875\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 107 Batch 100] Loss: 0.005791419981795977 Training: accuracy=0.996210\n",
      "Epoch 107. Loss: 0.005791419981795977, Train_acc 0.9962097772277227\n",
      "\n",
      "Epoch 107. Loss: 0.005483757675926474, Train_acc 0.9962469362745098\n",
      "\n",
      "Epoch 107. Loss: 0.006198089544094134, Train_acc 0.9962075242718447\n",
      "\n",
      "Epoch 107. Loss: 0.005763370124764617, Train_acc 0.9962439903846154\n",
      "\n",
      "Epoch 107. Loss: 0.00524471267837722, Train_acc 0.9962797619047619\n",
      "\n",
      "Epoch 107. Loss: 0.0058463702182034154, Train_acc 0.9962411556603774\n",
      "\n",
      "Epoch 107. Loss: 0.010145827196245745, Train_acc 0.9962032710280374\n",
      "\n",
      "Epoch 107. Loss: 0.009154339696133641, Train_acc 0.9962384259259259\n",
      "\n",
      "Epoch 107. Loss: 0.0084299572045523, Train_acc 0.9962729357798165\n",
      "\n",
      "Epoch 107. Loss: 0.010028404241941995, Train_acc 0.9962357954545454\n",
      "\n",
      "Epoch 107. Loss: 0.009998531226345267, Train_acc 0.9961993243243243\n",
      "\n",
      "Epoch 107. Loss: 0.009122044817234606, Train_acc 0.9962332589285714\n",
      "\n",
      "Epoch 107. Loss: 0.008884178415500103, Train_acc 0.996266592920354\n",
      "\n",
      "Epoch 107. Loss: 0.008874402328338903, Train_acc 0.9962308114035088\n",
      "\n",
      "Epoch 107. Loss: 0.008279447419239593, Train_acc 0.9962635869565217\n",
      "\n",
      "Epoch 107. Loss: 0.007799895062373738, Train_acc 0.9962957974137931\n",
      "\n",
      "Epoch 107. Loss: 0.00849502300485372, Train_acc 0.9962606837606838\n",
      "\n",
      "Epoch 107. Loss: 0.00778452604686677, Train_acc 0.996292372881356\n",
      "\n",
      "Epoch 107. Loss: 0.009909356829602655, Train_acc 0.9961265756302521\n",
      "\n",
      "Epoch 107. Loss: 0.009672462697323385, Train_acc 0.99609375\n",
      "\n",
      "Epoch 107. Loss: 0.00960953381403943, Train_acc 0.9960614669421488\n",
      "\n",
      "Epoch 107. Loss: 0.008661342693666217, Train_acc 0.99609375\n",
      "\n",
      "Epoch 107. Loss: 0.007832857034604637, Train_acc 0.9961255081300813\n",
      "\n",
      "Epoch 107. Loss: 0.0111301425653704, Train_acc 0.9960307459677419\n",
      "\n",
      "Epoch 107. Loss: 0.010033473546797194, Train_acc 0.9960625\n",
      "\n",
      "Epoch 107. Loss: 0.009389024221780142, Train_acc 0.99609375\n",
      "\n",
      "Epoch 107. Loss: 0.00845644422987425, Train_acc 0.9961245078740157\n",
      "\n",
      "Epoch 107. Loss: 0.007642778257602367, Train_acc 0.99615478515625\n",
      "\n",
      "Epoch 107. Loss: 0.006893359695161652, Train_acc 0.9961845930232558\n",
      "\n",
      "Epoch 107. Loss: 0.006766013709189241, Train_acc 0.9962139423076923\n",
      "\n",
      "Epoch 107. Loss: 0.006142084328394826, Train_acc 0.9962428435114504\n",
      "\n",
      "Epoch 107. Loss: 0.006401601011808243, Train_acc 0.9962713068181818\n",
      "\n",
      "Epoch 107. Loss: 0.009314983405401284, Train_acc 0.9961818609022557\n",
      "\n",
      "Epoch 107. Loss: 0.008502258704994596, Train_acc 0.996210354477612\n",
      "\n",
      "Epoch 107. Loss: 0.0083782153139065, Train_acc 0.9962384259259259\n",
      "\n",
      "Epoch 107. Loss: 0.01036313583489212, Train_acc 0.9962086397058824\n",
      "\n",
      "Epoch 107. Loss: 0.01107350768181043, Train_acc 0.9961792883211679\n",
      "\n",
      "Epoch 107. Loss: 0.011389525702885006, Train_acc 0.9961503623188406\n",
      "\n",
      "Epoch 107. Loss: 0.010445399575344815, Train_acc 0.9961780575539568\n",
      "\n",
      "Epoch 107. Loss: 0.009502855214006836, Train_acc 0.9962053571428572\n",
      "\n",
      "Epoch 107. Loss: 0.009282006492489996, Train_acc 0.9961768617021277\n",
      "\n",
      "Epoch 107. Loss: 0.009287224452442904, Train_acc 0.9961487676056338\n",
      "\n",
      "Epoch 107. Loss: 0.008402957296224405, Train_acc 0.9961756993006993\n",
      "\n",
      "Epoch 107. Loss: 0.008136195014061305, Train_acc 0.9962022569444444\n",
      "\n",
      "Epoch 107. Loss: 0.0073961899032221196, Train_acc 0.9962284482758621\n",
      "\n",
      "Epoch 107. Loss: 0.007081149559097823, Train_acc 0.9962542808219178\n",
      "\n",
      "Epoch 107. Loss: 0.006595785589182976, Train_acc 0.9962797619047619\n",
      "\n",
      "Epoch 107. Loss: 0.006407416019884887, Train_acc 0.9963048986486487\n",
      "\n",
      "Epoch 107. Loss: 0.006063919428630003, Train_acc 0.9963296979865772\n",
      "\n",
      "Epoch 107. Loss: 0.005524764790523421, Train_acc 0.9963541666666667\n",
      "\n",
      "Epoch 107. Loss: 0.005795785618026589, Train_acc 0.9963265728476821\n",
      "\n",
      "Epoch 107. Loss: 0.005359494561712772, Train_acc 0.996350740131579\n",
      "\n",
      "Epoch 107. Loss: 0.004849357086136376, Train_acc 0.996374591503268\n",
      "\n",
      "Epoch 107. Loss: 0.004427618517638983, Train_acc 0.9963981331168831\n",
      "\n",
      "Epoch 107. Loss: 0.004644530513133177, Train_acc 0.996421370967742\n",
      "\n",
      "Epoch 107. Loss: 0.004947058994617077, Train_acc 0.9964443108974359\n",
      "\n",
      "Epoch 107. Loss: 0.004546476349685502, Train_acc 0.9964669585987261\n",
      "\n",
      "Epoch 107. Loss: 0.005064805809069197, Train_acc 0.9964398734177216\n",
      "\n",
      "Epoch 107. Loss: 0.010829329159923066, Train_acc 0.9963639937106918\n",
      "\n",
      "Epoch 107. Loss: 0.010154751297445003, Train_acc 0.99638671875\n",
      "\n",
      "Epoch 107. Loss: 0.009159805811798635, Train_acc 0.9964091614906833\n",
      "\n",
      "Epoch 107. Loss: 0.008286986205365342, Train_acc 0.9964313271604939\n",
      "\n",
      "Epoch 107. Loss: 0.007638905979926363, Train_acc 0.9964532208588958\n",
      "\n",
      "Epoch 107. Loss: 0.007073131721676864, Train_acc 0.9964748475609756\n",
      "\n",
      "Epoch 107. Loss: 0.00798664709609283, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 107. Loss: 0.007282938546075222, Train_acc 0.9964702560240963\n",
      "\n",
      "Epoch 107. Loss: 0.006799933078408656, Train_acc 0.9964913922155688\n",
      "\n",
      "Epoch 107. Loss: 0.007025724176335709, Train_acc 0.9965122767857143\n",
      "\n",
      "Epoch 107. Loss: 0.006383890038419182, Train_acc 0.9965329142011834\n",
      "\n",
      "Epoch 107. Loss: 0.005849618998505993, Train_acc 0.9965533088235294\n",
      "\n",
      "Epoch 107. Loss: 0.006133825626079729, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 107. Loss: 0.005532528632068132, Train_acc 0.9965479651162791\n",
      "\n",
      "Epoch 107. Loss: 0.005186394621856655, Train_acc 0.9965679190751445\n",
      "\n",
      "Epoch 107. Loss: 0.004680676483321507, Train_acc 0.9965876436781609\n",
      "\n",
      "Epoch 107. Loss: 0.00435898426853119, Train_acc 0.9966071428571428\n",
      "\n",
      "Epoch 107. Loss: 0.004040159620206792, Train_acc 0.9966264204545454\n",
      "\n",
      "Epoch 107. Loss: 0.005229768458629762, Train_acc 0.9965572033898306\n",
      "\n",
      "Epoch 107. Loss: 0.0061107883336768585, Train_acc 0.996532654494382\n",
      "\n",
      "Epoch 107. Loss: 0.005548904543120507, Train_acc 0.9965520251396648\n",
      "\n",
      "Epoch 107. Loss: 0.005188184158689241, Train_acc 0.9965711805555556\n",
      "\n",
      "Epoch 107. Loss: 0.004743618624861353, Train_acc 0.9965901243093923\n",
      "\n",
      "Epoch 107. Loss: 0.004365239181236459, Train_acc 0.9966088598901099\n",
      "\n",
      "Epoch 107. Loss: 0.003969290094768062, Train_acc 0.9966273907103825\n",
      "\n",
      "Epoch 107. Loss: 0.0036542555098023756, Train_acc 0.9966457201086957\n",
      "\n",
      "Epoch 107. Loss: 0.00350005808641345, Train_acc 0.9966638513513514\n",
      "\n",
      "Epoch 107. Loss: 0.0035582612999066478, Train_acc 0.9966817876344086\n",
      "\n",
      "Epoch 107. Loss: 0.003220087894552702, Train_acc 0.9966995320855615\n",
      "\n",
      "Epoch 107. Loss: 0.0030378558620844072, Train_acc 0.9967170877659575\n",
      "\n",
      "Epoch 107. Loss: 0.002957524526830058, Train_acc 0.9967344576719577\n",
      "\n",
      "Epoch 107. Loss: 0.006552885847135372, Train_acc 0.9967105263157895\n",
      "\n",
      "Epoch 107. Loss: 0.005931926368405323, Train_acc 0.9967277486910995\n",
      "\n",
      "Epoch 107. Loss: 0.0054002692990756645, Train_acc 0.9967447916666666\n",
      "\n",
      "Epoch 107. Loss: 0.005671597743921573, Train_acc 0.9967211787564767\n",
      "\n",
      "Epoch 107. Loss: 0.005824221704059627, Train_acc 0.9966978092783505\n",
      "\n",
      "Epoch 107. Loss: 0.005521264571983027, Train_acc 0.9967147435897435\n",
      "\n",
      "Epoch 107. Loss: 0.005003696823797068, Train_acc 0.99672\n",
      "\n",
      "Epoch 108. Loss: 0.004521847347921396, Train_acc 1.0\n",
      "\n",
      "Epoch 108. Loss: 0.004077248616759678, Train_acc 1.0\n",
      "\n",
      "Epoch 108. Loss: 0.0037027746718329493, Train_acc 1.0\n",
      "\n",
      "Epoch 108. Loss: 0.00886401722859165, Train_acc 0.998046875\n",
      "\n",
      "Epoch 108. Loss: 0.007988881898999335, Train_acc 0.9984375\n",
      "\n",
      "Epoch 108. Loss: 0.00719721267632038, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 108. Loss: 0.006703666960922396, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 108. Loss: 0.006214559759105011, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 108. Loss: 0.005632142252743779, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 108. Loss: 0.0051177532188032915, Train_acc 0.99921875\n",
      "\n",
      "Epoch 108. Loss: 0.004744495238033818, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 108. Loss: 0.004298762556874352, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 108. Loss: 0.003944430019599435, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 108. Loss: 0.003920916966625068, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 108. Loss: 0.0036684108380665007, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 108. Loss: 0.003343802960009504, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 108. Loss: 0.003095992118296664, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 108. Loss: 0.0033756420964100725, Train_acc 0.9995659722222222\n",
      "\n",
      "Epoch 108. Loss: 0.004381540875503311, Train_acc 0.9991776315789473\n",
      "\n",
      "Epoch 108. Loss: 0.003951261229460718, Train_acc 0.99921875\n",
      "\n",
      "Epoch 108. Loss: 0.0035706076745148476, Train_acc 0.9992559523809523\n",
      "\n",
      "Epoch 108. Loss: 0.0032355998514683676, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 108. Loss: 0.0029164320272391632, Train_acc 0.9993206521739131\n",
      "\n",
      "Epoch 108. Loss: 0.0026375790004849594, Train_acc 0.9993489583333334\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108. Loss: 0.0024660814420621245, Train_acc 0.999375\n",
      "\n",
      "Epoch 108. Loss: 0.002244800277668147, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 108. Loss: 0.002521725744188943, Train_acc 0.9994212962962963\n",
      "\n",
      "Epoch 108. Loss: 0.0023584023678431976, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 108. Loss: 0.002248396255687332, Train_acc 0.9994612068965517\n",
      "\n",
      "Epoch 108. Loss: 0.002352359250179341, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 108. Loss: 0.002632292835779259, Train_acc 0.9994959677419355\n",
      "\n",
      "Epoch 108. Loss: 0.0025659194166889215, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 108. Loss: 0.0023710959430237495, Train_acc 0.9995265151515151\n",
      "\n",
      "Epoch 108. Loss: 0.0023379822908595103, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 108. Loss: 0.0022830016515408363, Train_acc 0.9995535714285714\n",
      "\n",
      "Epoch 108. Loss: 0.0020699184401481627, Train_acc 0.9995659722222222\n",
      "\n",
      "Epoch 108. Loss: 0.0018732143265349612, Train_acc 0.9995777027027027\n",
      "\n",
      "Epoch 108. Loss: 0.0016878541882830187, Train_acc 0.9995888157894737\n",
      "\n",
      "Epoch 108. Loss: 0.001775276238374173, Train_acc 0.9995993589743589\n",
      "\n",
      "Epoch 108. Loss: 0.0017902525017654235, Train_acc 0.999609375\n",
      "\n",
      "Epoch 108. Loss: 0.0016458290953883456, Train_acc 0.9996189024390244\n",
      "\n",
      "Epoch 108. Loss: 0.0027473124502106544, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 108. Loss: 0.0024924987084217255, Train_acc 0.9994549418604651\n",
      "\n",
      "Epoch 108. Loss: 0.0022771362463697314, Train_acc 0.9994673295454546\n",
      "\n",
      "Epoch 108. Loss: 0.0027277738638279902, Train_acc 0.9993055555555556\n",
      "\n",
      "Epoch 108. Loss: 0.0024591621137916336, Train_acc 0.9993206521739131\n",
      "\n",
      "Epoch 108. Loss: 0.002226168305815097, Train_acc 0.9993351063829787\n",
      "\n",
      "Epoch 108. Loss: 0.0021018907804928747, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 108. Loss: 0.002423138950435149, Train_acc 0.9993622448979592\n",
      "\n",
      "Epoch 108. Loss: 0.0022470810779380746, Train_acc 0.999375\n",
      "\n",
      "Epoch 108. Loss: 0.0020431318316455026, Train_acc 0.9993872549019608\n",
      "\n",
      "Epoch 108. Loss: 0.0021581249214943058, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 108. Loss: 0.0059498601506116225, Train_acc 0.9992629716981132\n",
      "\n",
      "Epoch 108. Loss: 0.0053574947917829265, Train_acc 0.9992766203703703\n",
      "\n",
      "Epoch 108. Loss: 0.004861230051558977, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 108. Loss: 0.0048910269236193, Train_acc 0.9993024553571429\n",
      "\n",
      "Epoch 108. Loss: 0.00452906921569266, Train_acc 0.9993146929824561\n",
      "\n",
      "Epoch 108. Loss: 0.004332213743228538, Train_acc 0.9993265086206896\n",
      "\n",
      "Epoch 108. Loss: 0.004438359036995909, Train_acc 0.9993379237288136\n",
      "\n",
      "Epoch 108. Loss: 0.004165206458564647, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 108. Loss: 0.008096757477279944, Train_acc 0.9992315573770492\n",
      "\n",
      "Epoch 108. Loss: 0.00731683590547292, Train_acc 0.9992439516129032\n",
      "\n",
      "Epoch 108. Loss: 0.006620061914269874, Train_acc 0.9992559523809523\n",
      "\n",
      "Epoch 108. Loss: 0.006027255493066236, Train_acc 0.999267578125\n",
      "\n",
      "Epoch 108. Loss: 0.005493510434082768, Train_acc 0.9992788461538461\n",
      "\n",
      "Epoch 108. Loss: 0.004971377944843431, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 108. Loss: 0.004496712205929776, Train_acc 0.9993003731343284\n",
      "\n",
      "Epoch 108. Loss: 0.004687533405980366, Train_acc 0.9991957720588235\n",
      "\n",
      "Epoch 108. Loss: 0.004233790770483634, Train_acc 0.9992074275362319\n",
      "\n",
      "Epoch 108. Loss: 0.004164581212122102, Train_acc 0.99921875\n",
      "\n",
      "Epoch 108. Loss: 0.003798492548950114, Train_acc 0.9992297535211268\n",
      "\n",
      "Epoch 108. Loss: 0.003497540594464256, Train_acc 0.9992404513888888\n",
      "\n",
      "Epoch 108. Loss: 0.003503026655570311, Train_acc 0.9992508561643836\n",
      "\n",
      "Epoch 108. Loss: 0.003189919866952502, Train_acc 0.9992609797297297\n",
      "\n",
      "Epoch 108. Loss: 0.0028932889498256846, Train_acc 0.9992708333333333\n",
      "\n",
      "Epoch 108. Loss: 0.0026134274646794774, Train_acc 0.999280427631579\n",
      "\n",
      "Epoch 108. Loss: 0.0023528435103688148, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 108. Loss: 0.003337463768356458, Train_acc 0.999198717948718\n",
      "\n",
      "Epoch 108. Loss: 0.0031862878154516956, Train_acc 0.9992088607594937\n",
      "\n",
      "Epoch 108. Loss: 0.0028830811594863157, Train_acc 0.99921875\n",
      "\n",
      "Epoch 108. Loss: 0.002603764461682117, Train_acc 0.9992283950617284\n",
      "\n",
      "Epoch 108. Loss: 0.0024778413908720398, Train_acc 0.9992378048780488\n",
      "\n",
      "Epoch 108. Loss: 0.002996163946721588, Train_acc 0.9991528614457831\n",
      "\n",
      "Epoch 108. Loss: 0.0028904442089053703, Train_acc 0.9991629464285714\n",
      "\n",
      "Epoch 108. Loss: 0.0026302014130272534, Train_acc 0.999172794117647\n",
      "\n",
      "Epoch 108. Loss: 0.005748084128312892, Train_acc 0.9990915697674418\n",
      "\n",
      "Epoch 108. Loss: 0.005233542396729926, Train_acc 0.9991020114942529\n",
      "\n",
      "Epoch 108. Loss: 0.004721946876540557, Train_acc 0.9991122159090909\n",
      "\n",
      "Epoch 108. Loss: 0.004291898860217057, Train_acc 0.999122191011236\n",
      "\n",
      "Epoch 108. Loss: 0.0038933073620159974, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 108. Loss: 0.003572153571020176, Train_acc 0.9991414835164835\n",
      "\n",
      "Epoch 108. Loss: 0.007175429558250854, Train_acc 0.9989809782608695\n",
      "\n",
      "Epoch 108. Loss: 0.006525251422704949, Train_acc 0.998991935483871\n",
      "\n",
      "Epoch 108. Loss: 0.005906431280967245, Train_acc 0.9990026595744681\n",
      "\n",
      "Epoch 108. Loss: 0.005361044638334572, Train_acc 0.9990131578947369\n",
      "\n",
      "Epoch 108. Loss: 0.004844605133610038, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 108. Loss: 0.004889167693862678, Train_acc 0.9990335051546392\n",
      "\n",
      "Epoch 108. Loss: 0.004524977962677355, Train_acc 0.9990433673469388\n",
      "\n",
      "Epoch 108. Loss: 0.0041194203724940195, Train_acc 0.9990530303030303\n",
      "\n",
      "Epoch 108. Loss: 0.005519692739589177, Train_acc 0.998984375\n",
      "\n",
      "[Epoch 108 Batch 100] Loss: 0.0057609400293914936 Training: accuracy=0.998917\n",
      "Epoch 108. Loss: 0.0057609400293914936, Train_acc 0.9989170792079208\n",
      "\n",
      "Epoch 108. Loss: 0.007838839878888887, Train_acc 0.9987745098039216\n",
      "\n",
      "Epoch 108. Loss: 0.007153970533182736, Train_acc 0.9987864077669902\n",
      "\n",
      "Epoch 108. Loss: 0.008567528084132536, Train_acc 0.9987229567307693\n",
      "\n",
      "Epoch 108. Loss: 0.008013189150025067, Train_acc 0.998735119047619\n",
      "\n",
      "Epoch 108. Loss: 0.007435682789054172, Train_acc 0.9987470518867925\n",
      "\n",
      "Epoch 108. Loss: 0.007106079292058936, Train_acc 0.998758761682243\n",
      "\n",
      "Epoch 108. Loss: 0.011068765340828887, Train_acc 0.9986255787037037\n",
      "\n",
      "Epoch 108. Loss: 0.010705044453815215, Train_acc 0.9986381880733946\n",
      "\n",
      "Epoch 108. Loss: 0.009673296630668052, Train_acc 0.9986505681818182\n",
      "\n",
      "Epoch 108. Loss: 0.015469958681125112, Train_acc 0.9984515765765766\n",
      "\n",
      "Epoch 108. Loss: 0.014034079456541986, Train_acc 0.9984654017857143\n",
      "\n",
      "Epoch 108. Loss: 0.012688061569533766, Train_acc 0.9984789823008849\n",
      "\n",
      "Epoch 108. Loss: 0.011672017546767314, Train_acc 0.9984923245614035\n",
      "\n",
      "Epoch 108. Loss: 0.012906040874666859, Train_acc 0.9983695652173913\n",
      "\n",
      "Epoch 108. Loss: 0.01492926243920346, Train_acc 0.9983162715517241\n",
      "\n",
      "Epoch 108. Loss: 0.014301816499047458, Train_acc 0.9983306623931624\n",
      "\n",
      "Epoch 108. Loss: 0.012896392857800667, Train_acc 0.9983448093220338\n",
      "\n",
      "Epoch 108. Loss: 0.012464028458241294, Train_acc 0.9982930672268907\n",
      "\n",
      "Epoch 108. Loss: 0.012002318153181974, Train_acc 0.9983072916666667\n",
      "\n",
      "Epoch 108. Loss: 0.016143266379296157, Train_acc 0.9981921487603306\n",
      "\n",
      "Epoch 108. Loss: 0.017332967239134946, Train_acc 0.9981429303278688\n",
      "\n",
      "Epoch 108. Loss: 0.01600581879989514, Train_acc 0.9981580284552846\n",
      "\n",
      "Epoch 108. Loss: 0.014594874824892367, Train_acc 0.9981728830645161\n",
      "\n",
      "Epoch 108. Loss: 0.016050537269542413, Train_acc 0.998125\n",
      "\n",
      "Epoch 108. Loss: 0.020943486548569618, Train_acc 0.998015873015873\n",
      "\n",
      "Epoch 108. Loss: 0.019015897184445102, Train_acc 0.9980314960629921\n",
      "\n",
      "Epoch 108. Loss: 0.017207339711059158, Train_acc 0.998046875\n",
      "\n",
      "Epoch 108. Loss: 0.01557788719170379, Train_acc 0.998062015503876\n",
      "\n",
      "Epoch 108. Loss: 0.015589439968166537, Train_acc 0.9980168269230769\n",
      "\n",
      "Epoch 108. Loss: 0.014253459717986989, Train_acc 0.998031965648855\n",
      "\n",
      "Epoch 108. Loss: 0.013030937409318693, Train_acc 0.998046875\n",
      "\n",
      "Epoch 108. Loss: 0.012125654008314496, Train_acc 0.998061560150376\n",
      "\n",
      "Epoch 108. Loss: 0.012359230096333162, Train_acc 0.9980177238805971\n",
      "\n",
      "Epoch 108. Loss: 0.015486724712127092, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 108. Loss: 0.015390720438367405, Train_acc 0.9978745404411765\n",
      "\n",
      "Epoch 108. Loss: 0.015930255700415025, Train_acc 0.9978330291970803\n",
      "\n",
      "Epoch 108. Loss: 0.015150776627748297, Train_acc 0.997848731884058\n",
      "\n",
      "Epoch 108. Loss: 0.014109537078221816, Train_acc 0.9978642086330936\n",
      "\n",
      "Epoch 108. Loss: 0.01517432450349347, Train_acc 0.9978236607142857\n",
      "\n",
      "Epoch 108. Loss: 0.013936390991615201, Train_acc 0.9978390957446809\n",
      "\n",
      "Epoch 108. Loss: 0.013374619926309835, Train_acc 0.9978543133802817\n",
      "\n",
      "Epoch 108. Loss: 0.012543363790478932, Train_acc 0.9978693181818182\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108. Loss: 0.011463215745925869, Train_acc 0.9978841145833334\n",
      "\n",
      "Epoch 108. Loss: 0.010349891337605535, Train_acc 0.9978987068965517\n",
      "\n",
      "Epoch 108. Loss: 0.014323144483136135, Train_acc 0.9978060787671232\n",
      "\n",
      "Epoch 108. Loss: 0.013017474538147746, Train_acc 0.9978210034013606\n",
      "\n",
      "Epoch 108. Loss: 0.011811928573546826, Train_acc 0.9978357263513513\n",
      "\n",
      "Epoch 108. Loss: 0.010777557020416575, Train_acc 0.9978502516778524\n",
      "\n",
      "Epoch 108. Loss: 0.010112222712514446, Train_acc 0.9978645833333334\n",
      "\n",
      "Epoch 108. Loss: 0.009384570889199655, Train_acc 0.9978787251655629\n",
      "\n",
      "Epoch 108. Loss: 0.008921975258387518, Train_acc 0.9978926809210527\n",
      "\n",
      "Epoch 108. Loss: 0.008202582948246502, Train_acc 0.997906454248366\n",
      "\n",
      "Epoch 108. Loss: 0.008667140583251926, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 108. Loss: 0.008612911221434188, Train_acc 0.9978326612903226\n",
      "\n",
      "Epoch 108. Loss: 0.008020484079017799, Train_acc 0.9978465544871795\n",
      "\n",
      "Epoch 108. Loss: 0.007652058344269896, Train_acc 0.997860270700637\n",
      "\n",
      "Epoch 108. Loss: 0.006985919760109578, Train_acc 0.9978738132911392\n",
      "\n",
      "Epoch 108. Loss: 0.006431593015309358, Train_acc 0.9978871855345912\n",
      "\n",
      "Epoch 108. Loss: 0.00624811297649102, Train_acc 0.997900390625\n",
      "\n",
      "Epoch 108. Loss: 0.006073656633069724, Train_acc 0.9979134316770186\n",
      "\n",
      "Epoch 108. Loss: 0.005720574302959988, Train_acc 0.9979263117283951\n",
      "\n",
      "Epoch 108. Loss: 0.005530557523247793, Train_acc 0.9979390337423313\n",
      "\n",
      "Epoch 108. Loss: 0.005007361116445724, Train_acc 0.9979516006097561\n",
      "\n",
      "Epoch 108. Loss: 0.00493696914309561, Train_acc 0.9979640151515151\n",
      "\n",
      "Epoch 108. Loss: 0.004516208348763434, Train_acc 0.9979762801204819\n",
      "\n",
      "Epoch 108. Loss: 0.004075387362565379, Train_acc 0.9979883982035929\n",
      "\n",
      "Epoch 108. Loss: 0.003683249904814875, Train_acc 0.9980003720238095\n",
      "\n",
      "Epoch 108. Loss: 0.0034025804886495463, Train_acc 0.9980122041420119\n",
      "\n",
      "Epoch 108. Loss: 0.0033543133476473743, Train_acc 0.9980238970588236\n",
      "\n",
      "Epoch 108. Loss: 0.0030444308861190396, Train_acc 0.9980354532163743\n",
      "\n",
      "Epoch 108. Loss: 0.0027487624845193275, Train_acc 0.998046875\n",
      "\n",
      "Epoch 108. Loss: 0.0025077907870137126, Train_acc 0.9980581647398844\n",
      "\n",
      "Epoch 108. Loss: 0.0022918795320183497, Train_acc 0.9980693247126436\n",
      "\n",
      "Epoch 108. Loss: 0.0020673335008035733, Train_acc 0.9980803571428571\n",
      "\n",
      "Epoch 108. Loss: 0.001874034308604636, Train_acc 0.9980912642045454\n",
      "\n",
      "Epoch 108. Loss: 0.001775533650148426, Train_acc 0.9981020480225988\n",
      "\n",
      "Epoch 108. Loss: 0.0016149159976168292, Train_acc 0.9981127106741573\n",
      "\n",
      "Epoch 108. Loss: 0.0014714653443070934, Train_acc 0.9981232541899442\n",
      "\n",
      "Epoch 108. Loss: 0.001687244367296042, Train_acc 0.9981336805555555\n",
      "\n",
      "Epoch 108. Loss: 0.0015641371230844037, Train_acc 0.9981439917127072\n",
      "\n",
      "Epoch 108. Loss: 0.0014212889331617245, Train_acc 0.9981541895604396\n",
      "\n",
      "Epoch 108. Loss: 0.0012910849174628273, Train_acc 0.9981642759562842\n",
      "\n",
      "Epoch 108. Loss: 0.001175806597963798, Train_acc 0.9981742527173914\n",
      "\n",
      "Epoch 108. Loss: 0.00106559985054377, Train_acc 0.9981841216216216\n",
      "\n",
      "Epoch 108. Loss: 0.0009618333411766058, Train_acc 0.9981938844086021\n",
      "\n",
      "Epoch 108. Loss: 0.0008686942542641981, Train_acc 0.9982035427807486\n",
      "\n",
      "Epoch 108. Loss: 0.0008128777544617315, Train_acc 0.9982130984042553\n",
      "\n",
      "Epoch 108. Loss: 0.0007779040860368753, Train_acc 0.9982225529100529\n",
      "\n",
      "Epoch 108. Loss: 0.000801890377900059, Train_acc 0.9982319078947368\n",
      "\n",
      "Epoch 108. Loss: 0.0009725132615426675, Train_acc 0.998241164921466\n",
      "\n",
      "Epoch 108. Loss: 0.0008812844943434108, Train_acc 0.9982503255208334\n",
      "\n",
      "Epoch 108. Loss: 0.0008198226449333974, Train_acc 0.9982593911917098\n",
      "\n",
      "Epoch 108. Loss: 0.0007725239856304242, Train_acc 0.9982683634020618\n",
      "\n",
      "Epoch 108. Loss: 0.0007878671524330092, Train_acc 0.9982772435897436\n",
      "\n",
      "Epoch 108. Loss: 0.0007769217162772966, Train_acc 0.99828\n",
      "\n",
      "Epoch 109. Loss: 0.0007064556415814118, Train_acc 1.0\n",
      "\n",
      "Epoch 109. Loss: 0.0014862155283336005, Train_acc 0.99609375\n",
      "\n",
      "Epoch 109. Loss: 0.0013511209542281363, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 109. Loss: 0.0012214908868691749, Train_acc 0.998046875\n",
      "\n",
      "Epoch 109. Loss: 0.001106539174726612, Train_acc 0.9984375\n",
      "\n",
      "Epoch 109. Loss: 0.0010228060268504232, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 109. Loss: 0.0009384846223231496, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 109. Loss: 0.0008475460756562313, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 109. Loss: 0.0007668635345307388, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 109. Loss: 0.0007095947357998325, Train_acc 0.99921875\n",
      "\n",
      "Epoch 109. Loss: 0.0006494270098469306, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 109. Loss: 0.0005918220808295238, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 109. Loss: 0.0005949396078922148, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 109. Loss: 0.0005436726284022242, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 109. Loss: 0.0004973565095211664, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 109. Loss: 0.000450628977916264, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 109. Loss: 0.0004077475222662287, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 109. Loss: 0.00037598565953495813, Train_acc 0.9995659722222222\n",
      "\n",
      "Epoch 109. Loss: 0.0003419338158729654, Train_acc 0.9995888157894737\n",
      "\n",
      "Epoch 109. Loss: 0.0003212366720926447, Train_acc 0.999609375\n",
      "\n",
      "Epoch 109. Loss: 0.0005351852161861971, Train_acc 0.9996279761904762\n",
      "\n",
      "Epoch 109. Loss: 0.0004838176055177268, Train_acc 0.9996448863636364\n",
      "\n",
      "Epoch 109. Loss: 0.0004399046650092116, Train_acc 0.9996603260869565\n",
      "\n",
      "Epoch 109. Loss: 0.00041463179446644136, Train_acc 0.9996744791666666\n",
      "\n",
      "Epoch 109. Loss: 0.00038071560059991746, Train_acc 0.9996875\n",
      "\n",
      "Epoch 109. Loss: 0.00040856307565427367, Train_acc 0.9996995192307693\n",
      "\n",
      "Epoch 109. Loss: 0.000373700578643929, Train_acc 0.9997106481481481\n",
      "\n",
      "Epoch 109. Loss: 0.0003414317928882679, Train_acc 0.9997209821428571\n",
      "\n",
      "Epoch 109. Loss: 0.0003117733756296291, Train_acc 0.9997306034482759\n",
      "\n",
      "Epoch 109. Loss: 0.0002959848004704114, Train_acc 0.9997395833333333\n",
      "\n",
      "Epoch 109. Loss: 0.0003023410295881686, Train_acc 0.9997479838709677\n",
      "\n",
      "Epoch 109. Loss: 0.0003396634771228156, Train_acc 0.999755859375\n",
      "\n",
      "Epoch 109. Loss: 0.00031526068593359637, Train_acc 0.9997632575757576\n",
      "\n",
      "Epoch 109. Loss: 0.0002976850335182136, Train_acc 0.9997702205882353\n",
      "\n",
      "Epoch 109. Loss: 0.00027563408165528727, Train_acc 0.9997767857142857\n",
      "\n",
      "Epoch 109. Loss: 0.0006428145407082529, Train_acc 0.9997829861111112\n",
      "\n",
      "Epoch 109. Loss: 0.0005818197858488854, Train_acc 0.9997888513513513\n",
      "\n",
      "Epoch 109. Loss: 0.0005879565740814475, Train_acc 0.9997944078947368\n",
      "\n",
      "Epoch 109. Loss: 0.0005295605269538132, Train_acc 0.9997996794871795\n",
      "\n",
      "Epoch 109. Loss: 0.00047934705662302173, Train_acc 0.9998046875\n",
      "\n",
      "Epoch 109. Loss: 0.0004374454083949711, Train_acc 0.9998094512195121\n",
      "\n",
      "Epoch 109. Loss: 0.00042668729451428826, Train_acc 0.9998139880952381\n",
      "\n",
      "Epoch 109. Loss: 0.0003842981359580047, Train_acc 0.9998183139534884\n",
      "\n",
      "Epoch 109. Loss: 0.0003556436638215214, Train_acc 0.9998224431818182\n",
      "\n",
      "Epoch 109. Loss: 0.00032267791988939225, Train_acc 0.9998263888888889\n",
      "\n",
      "Epoch 109. Loss: 0.0002956833327065974, Train_acc 0.9998301630434783\n",
      "\n",
      "Epoch 109. Loss: 0.00029528686882751315, Train_acc 0.9998337765957447\n",
      "\n",
      "Epoch 109. Loss: 0.0002670822427033958, Train_acc 0.9998372395833334\n",
      "\n",
      "Epoch 109. Loss: 0.00024780766642142033, Train_acc 0.9998405612244898\n",
      "\n",
      "Epoch 109. Loss: 0.0002252019232529611, Train_acc 0.99984375\n",
      "\n",
      "Epoch 109. Loss: 0.00021263456064183099, Train_acc 0.9998468137254902\n",
      "\n",
      "Epoch 109. Loss: 0.00027784550575548635, Train_acc 0.9998497596153846\n",
      "\n",
      "Epoch 109. Loss: 0.0002527397357636025, Train_acc 0.9998525943396226\n",
      "\n",
      "Epoch 109. Loss: 0.0038076969817173478, Train_acc 0.9997106481481481\n",
      "\n",
      "Epoch 109. Loss: 0.003435674379398936, Train_acc 0.9997159090909091\n",
      "\n",
      "Epoch 109. Loss: 0.003119806602318113, Train_acc 0.9997209821428571\n",
      "\n",
      "Epoch 109. Loss: 0.0028365579885712487, Train_acc 0.9997258771929824\n",
      "\n",
      "Epoch 109. Loss: 0.0027735753019128345, Train_acc 0.9997306034482759\n",
      "\n",
      "Epoch 109. Loss: 0.0029929070484913086, Train_acc 0.9997351694915254\n",
      "\n",
      "Epoch 109. Loss: 0.002706231496451481, Train_acc 0.9997395833333333\n",
      "\n",
      "Epoch 109. Loss: 0.0030257416878356194, Train_acc 0.9996157786885246\n",
      "\n",
      "Epoch 109. Loss: 0.002788977298386871, Train_acc 0.9996219758064516\n",
      "\n",
      "Epoch 109. Loss: 0.0025477519159373455, Train_acc 0.9996279761904762\n",
      "\n",
      "Epoch 109. Loss: 0.0037152480430773034, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 109. Loss: 0.003413042398726222, Train_acc 0.9995192307692308\n",
      "\n",
      "Epoch 109. Loss: 0.0030808601229571422, Train_acc 0.9995265151515151\n",
      "\n",
      "Epoch 109. Loss: 0.003896517428682725, Train_acc 0.9994169776119403\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109. Loss: 0.0035204800560692524, Train_acc 0.9994255514705882\n",
      "\n",
      "Epoch 109. Loss: 0.0031836604754985117, Train_acc 0.9994338768115942\n",
      "\n",
      "Epoch 109. Loss: 0.002867037169500085, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 109. Loss: 0.0029075413224001756, Train_acc 0.999449823943662\n",
      "\n",
      "Epoch 109. Loss: 0.002620158315945792, Train_acc 0.9994574652777778\n",
      "\n",
      "Epoch 109. Loss: 0.002889490139111097, Train_acc 0.999464897260274\n",
      "\n",
      "Epoch 109. Loss: 0.003510720535329773, Train_acc 0.9993665540540541\n",
      "\n",
      "Epoch 109. Loss: 0.0031786064753945194, Train_acc 0.999375\n",
      "\n",
      "Epoch 109. Loss: 0.002915779756802591, Train_acc 0.9993832236842105\n",
      "\n",
      "Epoch 109. Loss: 0.0027058799874562223, Train_acc 0.9993912337662337\n",
      "\n",
      "Epoch 109. Loss: 0.0036165088060597953, Train_acc 0.9992988782051282\n",
      "\n",
      "Epoch 109. Loss: 0.0033347315429594704, Train_acc 0.999307753164557\n",
      "\n",
      "Epoch 109. Loss: 0.003005657038643954, Train_acc 0.99931640625\n",
      "\n",
      "Epoch 109. Loss: 0.0028865757783807797, Train_acc 0.9993248456790124\n",
      "\n",
      "Epoch 109. Loss: 0.004190786208262218, Train_acc 0.9992378048780488\n",
      "\n",
      "Epoch 109. Loss: 0.004941717613980329, Train_acc 0.9991528614457831\n",
      "\n",
      "Epoch 109. Loss: 0.00449022429164066, Train_acc 0.9991629464285714\n",
      "\n",
      "Epoch 109. Loss: 0.0042531906710637874, Train_acc 0.999172794117647\n",
      "\n",
      "Epoch 109. Loss: 0.005075235420904154, Train_acc 0.9990915697674418\n",
      "\n",
      "Epoch 109. Loss: 0.0048267298697158055, Train_acc 0.9991020114942529\n",
      "\n",
      "Epoch 109. Loss: 0.004563255920854898, Train_acc 0.9991122159090909\n",
      "\n",
      "Epoch 109. Loss: 0.005176158400488817, Train_acc 0.9990344101123596\n",
      "\n",
      "Epoch 109. Loss: 0.010417193906408183, Train_acc 0.9988715277777778\n",
      "\n",
      "Epoch 109. Loss: 0.010075134837464958, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 109. Loss: 0.009102079573025005, Train_acc 0.9988111413043478\n",
      "\n",
      "Epoch 109. Loss: 0.008309872409458931, Train_acc 0.9988239247311828\n",
      "\n",
      "Epoch 109. Loss: 0.0075215739568935125, Train_acc 0.9988364361702128\n",
      "\n",
      "Epoch 109. Loss: 0.02003656857259866, Train_acc 0.9984375\n",
      "\n",
      "Epoch 109. Loss: 0.01836862698407736, Train_acc 0.9984537760416666\n",
      "\n",
      "Epoch 109. Loss: 0.016683164029878527, Train_acc 0.9984697164948454\n",
      "\n",
      "Epoch 109. Loss: 0.01505239153907603, Train_acc 0.9984853316326531\n",
      "\n",
      "Epoch 109. Loss: 0.01362437624443015, Train_acc 0.9985006313131313\n",
      "\n",
      "Epoch 109. Loss: 0.025343954134360917, Train_acc 0.998125\n",
      "\n",
      "[Epoch 109 Batch 100] Loss: 0.022933155401275426 Training: accuracy=0.998144\n",
      "Epoch 109. Loss: 0.022933155401275426, Train_acc 0.9981435643564357\n",
      "\n",
      "Epoch 109. Loss: 0.020727063418204746, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 109. Loss: 0.020003645674087252, Train_acc 0.9981796116504854\n",
      "\n",
      "Epoch 109. Loss: 0.01991343488308577, Train_acc 0.9981219951923077\n",
      "\n",
      "Epoch 109. Loss: 0.018358347941304337, Train_acc 0.9981398809523809\n",
      "\n",
      "Epoch 109. Loss: 0.0205840544809685, Train_acc 0.9980837264150944\n",
      "\n",
      "Epoch 109. Loss: 0.02125889061329834, Train_acc 0.9980286214953271\n",
      "\n",
      "Epoch 109. Loss: 0.019283462394965346, Train_acc 0.998046875\n",
      "\n",
      "Epoch 109. Loss: 0.02122322700592219, Train_acc 0.997993119266055\n",
      "\n",
      "Epoch 109. Loss: 0.019625435191071086, Train_acc 0.9980113636363637\n",
      "\n",
      "Epoch 109. Loss: 0.017734106492455128, Train_acc 0.9980292792792793\n",
      "\n",
      "Epoch 109. Loss: 0.016281622827050382, Train_acc 0.998046875\n",
      "\n",
      "Epoch 109. Loss: 0.015510586232689584, Train_acc 0.9980641592920354\n",
      "\n",
      "Epoch 109. Loss: 0.014449942752269714, Train_acc 0.9980811403508771\n",
      "\n",
      "Epoch 109. Loss: 0.01377489780892236, Train_acc 0.9980978260869565\n",
      "\n",
      "Epoch 109. Loss: 0.012986284595811096, Train_acc 0.998114224137931\n",
      "\n",
      "Epoch 109. Loss: 0.012181519733742232, Train_acc 0.9981303418803419\n",
      "\n",
      "Epoch 109. Loss: 0.01213643001038613, Train_acc 0.9980799788135594\n",
      "\n",
      "Epoch 109. Loss: 0.01119960222540452, Train_acc 0.9980961134453782\n",
      "\n",
      "Epoch 109. Loss: 0.010856603541804736, Train_acc 0.9981119791666667\n",
      "\n",
      "Epoch 109. Loss: 0.01166887428656225, Train_acc 0.9980630165289256\n",
      "\n",
      "Epoch 109. Loss: 0.011889246222034138, Train_acc 0.9980148565573771\n",
      "\n",
      "Epoch 109. Loss: 0.010827186197963395, Train_acc 0.9980309959349594\n",
      "\n",
      "Epoch 109. Loss: 0.009772366574071307, Train_acc 0.998046875\n",
      "\n",
      "Epoch 109. Loss: 0.01007069669574123, Train_acc 0.998\n",
      "\n",
      "Epoch 109. Loss: 0.009560749321367933, Train_acc 0.998015873015873\n",
      "\n",
      "Epoch 109. Loss: 0.008783058925642753, Train_acc 0.9980314960629921\n",
      "\n",
      "Epoch 109. Loss: 0.008219586396596597, Train_acc 0.998046875\n",
      "\n",
      "Epoch 109. Loss: 0.009528413341386705, Train_acc 0.9980014534883721\n",
      "\n",
      "Epoch 109. Loss: 0.008697890400798847, Train_acc 0.9980168269230769\n",
      "\n",
      "Epoch 109. Loss: 0.00786447170750728, Train_acc 0.998031965648855\n",
      "\n",
      "Epoch 109. Loss: 0.0071218429583019905, Train_acc 0.998046875\n",
      "\n",
      "Epoch 109. Loss: 0.00793662833372118, Train_acc 0.9980028195488722\n",
      "\n",
      "Epoch 109. Loss: 0.007496699323052424, Train_acc 0.9980177238805971\n",
      "\n",
      "Epoch 109. Loss: 0.006801814057028376, Train_acc 0.9980324074074074\n",
      "\n",
      "Epoch 109. Loss: 0.00622436833464749, Train_acc 0.998046875\n",
      "\n",
      "Epoch 109. Loss: 0.005696051717272973, Train_acc 0.9980611313868614\n",
      "\n",
      "Epoch 109. Loss: 0.005816376781512716, Train_acc 0.9980185688405797\n",
      "\n",
      "Epoch 109. Loss: 0.007051104784950094, Train_acc 0.9979204136690647\n",
      "\n",
      "Epoch 109. Loss: 0.0063584443459582494, Train_acc 0.9979352678571428\n",
      "\n",
      "Epoch 109. Loss: 0.005849404881567255, Train_acc 0.9979499113475178\n",
      "\n",
      "Epoch 109. Loss: 0.0056683315897022146, Train_acc 0.9979643485915493\n",
      "\n",
      "Epoch 109. Loss: 0.006255794344607096, Train_acc 0.997923951048951\n",
      "\n",
      "Epoch 109. Loss: 0.008821760515805872, Train_acc 0.9978298611111112\n",
      "\n",
      "Epoch 109. Loss: 0.007962741136475764, Train_acc 0.9978448275862069\n",
      "\n",
      "Epoch 109. Loss: 0.007427246796644654, Train_acc 0.9978595890410958\n",
      "\n",
      "Epoch 109. Loss: 0.006739504980346793, Train_acc 0.997874149659864\n",
      "\n",
      "Epoch 109. Loss: 0.006742664969907315, Train_acc 0.9978885135135135\n",
      "\n",
      "Epoch 109. Loss: 0.00641620305373172, Train_acc 0.9979026845637584\n",
      "\n",
      "Epoch 109. Loss: 0.009666169633214773, Train_acc 0.9978645833333334\n",
      "\n",
      "Epoch 109. Loss: 0.009659854370872767, Train_acc 0.9978787251655629\n",
      "\n",
      "Epoch 109. Loss: 0.010349577000904612, Train_acc 0.9978412828947368\n",
      "\n",
      "Epoch 109. Loss: 0.009480719576051264, Train_acc 0.9978553921568627\n",
      "\n",
      "Epoch 109. Loss: 0.008829549366961804, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 109. Loss: 0.010552181488034922, Train_acc 0.9978326612903226\n",
      "\n",
      "Epoch 109. Loss: 0.00955888738467124, Train_acc 0.9978465544871795\n",
      "\n",
      "Epoch 109. Loss: 0.00885215130005473, Train_acc 0.997860270700637\n",
      "\n",
      "Epoch 109. Loss: 0.008165778662003822, Train_acc 0.9978738132911392\n",
      "\n",
      "Epoch 109. Loss: 0.007892834830496681, Train_acc 0.9978871855345912\n",
      "\n",
      "Epoch 109. Loss: 0.00837509434734044, Train_acc 0.9978515625\n",
      "\n",
      "Epoch 109. Loss: 0.00856904003081552, Train_acc 0.9978163819875776\n",
      "\n",
      "Epoch 109. Loss: 0.011441813600580381, Train_acc 0.9977816358024691\n",
      "\n",
      "Epoch 109. Loss: 0.010320325265470581, Train_acc 0.997795245398773\n",
      "\n",
      "Epoch 109. Loss: 0.009427694696781877, Train_acc 0.9978086890243902\n",
      "\n",
      "Epoch 109. Loss: 0.00853456104742729, Train_acc 0.9978219696969697\n",
      "\n",
      "Epoch 109. Loss: 0.007903212757309467, Train_acc 0.9978350903614458\n",
      "\n",
      "Epoch 109. Loss: 0.008205305108189752, Train_acc 0.9978012724550899\n",
      "\n",
      "Epoch 109. Loss: 0.007582155890771899, Train_acc 0.9978143601190477\n",
      "\n",
      "Epoch 109. Loss: 0.007075479190246005, Train_acc 0.9978272928994083\n",
      "\n",
      "Epoch 109. Loss: 0.00660761381803817, Train_acc 0.9978400735294117\n",
      "\n",
      "Epoch 109. Loss: 0.006349710730780957, Train_acc 0.9978527046783626\n",
      "\n",
      "Epoch 109. Loss: 0.005869379193752079, Train_acc 0.9978651889534884\n",
      "\n",
      "Epoch 109. Loss: 0.0067591116103551405, Train_acc 0.9978323699421965\n",
      "\n",
      "Epoch 109. Loss: 0.006450604131640936, Train_acc 0.9978448275862069\n",
      "\n",
      "Epoch 109. Loss: 0.006794392691542458, Train_acc 0.9978125\n",
      "\n",
      "Epoch 109. Loss: 0.00626936297996916, Train_acc 0.9978249289772727\n",
      "\n",
      "Epoch 109. Loss: 0.005769075096852282, Train_acc 0.9978372175141242\n",
      "\n",
      "Epoch 109. Loss: 0.005501825265175134, Train_acc 0.9978493679775281\n",
      "\n",
      "Epoch 109. Loss: 0.005639118799942162, Train_acc 0.9978177374301676\n",
      "\n",
      "Epoch 109. Loss: 0.005564276255110586, Train_acc 0.9978298611111112\n",
      "\n",
      "Epoch 109. Loss: 0.005503330446651296, Train_acc 0.9978418508287292\n",
      "\n",
      "Epoch 109. Loss: 0.008096947208676382, Train_acc 0.997810782967033\n",
      "\n",
      "Epoch 109. Loss: 0.00756339691878138, Train_acc 0.9978227459016393\n",
      "\n",
      "Epoch 109. Loss: 0.006839756137120974, Train_acc 0.9978345788043478\n",
      "\n",
      "Epoch 109. Loss: 0.006173526726638639, Train_acc 0.9978462837837838\n",
      "\n",
      "Epoch 109. Loss: 0.005990861368529825, Train_acc 0.9978578629032258\n",
      "\n",
      "Epoch 109. Loss: 0.005725617796982373, Train_acc 0.9978693181818182\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109. Loss: 0.005512562596400122, Train_acc 0.9978806515957447\n",
      "\n",
      "Epoch 109. Loss: 0.00516667851754982, Train_acc 0.9978918650793651\n",
      "\n",
      "Epoch 109. Loss: 0.006055391332050789, Train_acc 0.9978618421052632\n",
      "\n",
      "Epoch 109. Loss: 0.005548149932193574, Train_acc 0.9978730366492147\n",
      "\n",
      "Epoch 109. Loss: 0.0050619884943283195, Train_acc 0.9978841145833334\n",
      "\n",
      "Epoch 109. Loss: 0.004598947761645907, Train_acc 0.9978950777202072\n",
      "\n",
      "Epoch 109. Loss: 0.004153378346307067, Train_acc 0.9979059278350515\n",
      "\n",
      "Epoch 109. Loss: 0.003817945252818306, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 109. Loss: 0.0034409898458009746, Train_acc 0.99792\n",
      "\n",
      "Epoch 110. Loss: 0.0032433602070028296, Train_acc 1.0\n",
      "\n",
      "Epoch 110. Loss: 0.0029977523876359804, Train_acc 1.0\n",
      "\n",
      "Epoch 110. Loss: 0.0032631995668081118, Train_acc 1.0\n",
      "\n",
      "Epoch 110. Loss: 0.002945440900578626, Train_acc 1.0\n",
      "\n",
      "Epoch 110. Loss: 0.002765969165195103, Train_acc 1.0\n",
      "\n",
      "Epoch 110. Loss: 0.00393041986870385, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 110. Loss: 0.0035467856237242196, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 110. Loss: 0.00323780135573741, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 110. Loss: 0.003121494907059933, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 110. Loss: 0.0028129177853046393, Train_acc 0.99921875\n",
      "\n",
      "Epoch 110. Loss: 0.0025418476009038643, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 110. Loss: 0.002350160068731835, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 110. Loss: 0.0021427226595141717, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 110. Loss: 0.002437826099877795, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 110. Loss: 0.002197092086298932, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 110. Loss: 0.0022789363961803937, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 110. Loss: 0.002188956949890824, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 110. Loss: 0.0020107266576773718, Train_acc 0.9995659722222222\n",
      "\n",
      "Epoch 110. Loss: 0.0018153857977776158, Train_acc 0.9995888157894737\n",
      "\n",
      "Epoch 110. Loss: 0.0016713469680328752, Train_acc 0.999609375\n",
      "\n",
      "Epoch 110. Loss: 0.001517266317078136, Train_acc 0.9996279761904762\n",
      "\n",
      "Epoch 110. Loss: 0.0013668902518058988, Train_acc 0.9996448863636364\n",
      "\n",
      "Epoch 110. Loss: 0.001241611079220843, Train_acc 0.9996603260869565\n",
      "\n",
      "Epoch 110. Loss: 0.0013215590458466456, Train_acc 0.9996744791666666\n",
      "\n",
      "Epoch 110. Loss: 0.0012128659421531199, Train_acc 0.9996875\n",
      "\n",
      "Epoch 110. Loss: 0.001103294192669422, Train_acc 0.9996995192307693\n",
      "\n",
      "Epoch 110. Loss: 0.0013098268136018192, Train_acc 0.9997106481481481\n",
      "\n",
      "Epoch 110. Loss: 0.0012141751230366836, Train_acc 0.9997209821428571\n",
      "\n",
      "Epoch 110. Loss: 0.0010999354338688773, Train_acc 0.9997306034482759\n",
      "\n",
      "Epoch 110. Loss: 0.0010075782922353965, Train_acc 0.9997395833333333\n",
      "\n",
      "Epoch 110. Loss: 0.0009119170846922796, Train_acc 0.9997479838709677\n",
      "\n",
      "Epoch 110. Loss: 0.0008220323093774619, Train_acc 0.999755859375\n",
      "\n",
      "Epoch 110. Loss: 0.0009131968013309869, Train_acc 0.9997632575757576\n",
      "\n",
      "Epoch 110. Loss: 0.0010779028425169082, Train_acc 0.9997702205882353\n",
      "\n",
      "Epoch 110. Loss: 0.0010289509632131091, Train_acc 0.9997767857142857\n",
      "\n",
      "Epoch 110. Loss: 0.0010087730741522281, Train_acc 0.9997829861111112\n",
      "\n",
      "Epoch 110. Loss: 0.00090905739392469, Train_acc 0.9997888513513513\n",
      "\n",
      "Epoch 110. Loss: 0.0008289357238412321, Train_acc 0.9997944078947368\n",
      "\n",
      "Epoch 110. Loss: 0.0007468561690421802, Train_acc 0.9997996794871795\n",
      "\n",
      "Epoch 110. Loss: 0.000736110072761497, Train_acc 0.9998046875\n",
      "\n",
      "Epoch 110. Loss: 0.0006948453740659471, Train_acc 0.9998094512195121\n",
      "\n",
      "Epoch 110. Loss: 0.0006338811394586499, Train_acc 0.9998139880952381\n",
      "\n",
      "Epoch 110. Loss: 0.0006337825004415366, Train_acc 0.9998183139534884\n",
      "\n",
      "Epoch 110. Loss: 0.0005860101026380794, Train_acc 0.9998224431818182\n",
      "\n",
      "Epoch 110. Loss: 0.0005363333366952229, Train_acc 0.9998263888888889\n",
      "\n",
      "Epoch 110. Loss: 0.0004887999530676717, Train_acc 0.9998301630434783\n",
      "\n",
      "Epoch 110. Loss: 0.00044680122959911504, Train_acc 0.9998337765957447\n",
      "\n",
      "Epoch 110. Loss: 0.0005365434689556034, Train_acc 0.9998372395833334\n",
      "\n",
      "Epoch 110. Loss: 0.000506339872510181, Train_acc 0.9998405612244898\n",
      "\n",
      "Epoch 110. Loss: 0.00046293732347149245, Train_acc 0.99984375\n",
      "\n",
      "Epoch 110. Loss: 0.00041982612190583025, Train_acc 0.9998468137254902\n",
      "\n",
      "Epoch 110. Loss: 0.00037934340299362553, Train_acc 0.9998497596153846\n",
      "\n",
      "Epoch 110. Loss: 0.0003513120979373048, Train_acc 0.9998525943396226\n",
      "\n",
      "Epoch 110. Loss: 0.0003225926249746433, Train_acc 0.9998553240740741\n",
      "\n",
      "Epoch 110. Loss: 0.0002933121275190956, Train_acc 0.9998579545454546\n",
      "\n",
      "Epoch 110. Loss: 0.0002812716925268125, Train_acc 0.9998604910714286\n",
      "\n",
      "Epoch 110. Loss: 0.00026140784579885767, Train_acc 0.9998629385964912\n",
      "\n",
      "Epoch 110. Loss: 0.00023615864724247116, Train_acc 0.9998653017241379\n",
      "\n",
      "Epoch 110. Loss: 0.0006929304217725557, Train_acc 0.9998675847457628\n",
      "\n",
      "Epoch 110. Loss: 0.0006298552609048672, Train_acc 0.9998697916666667\n",
      "\n",
      "Epoch 110. Loss: 0.0005756962688453394, Train_acc 0.9998719262295082\n",
      "\n",
      "Epoch 110. Loss: 0.0008236341603118835, Train_acc 0.9998739919354839\n",
      "\n",
      "Epoch 110. Loss: 0.0009143143319914036, Train_acc 0.9998759920634921\n",
      "\n",
      "Epoch 110. Loss: 0.0008597944487702215, Train_acc 0.9998779296875\n",
      "\n",
      "Epoch 110. Loss: 0.00077938971674312, Train_acc 0.9998798076923077\n",
      "\n",
      "Epoch 110. Loss: 0.0007793218560575888, Train_acc 0.9998816287878788\n",
      "\n",
      "Epoch 110. Loss: 0.0007025901512531743, Train_acc 0.999883395522388\n",
      "\n",
      "Epoch 110. Loss: 0.0006334697235410089, Train_acc 0.9998851102941176\n",
      "\n",
      "Epoch 110. Loss: 0.0005972577482586062, Train_acc 0.9998867753623188\n",
      "\n",
      "Epoch 110. Loss: 0.0005700138389244636, Train_acc 0.9998883928571428\n",
      "\n",
      "Epoch 110. Loss: 0.0005197427121871581, Train_acc 0.9998899647887324\n",
      "\n",
      "Epoch 110. Loss: 0.0004753914493916943, Train_acc 0.9998914930555556\n",
      "\n",
      "Epoch 110. Loss: 0.0004291210764825413, Train_acc 0.9998929794520548\n",
      "\n",
      "Epoch 110. Loss: 0.0003877456456254345, Train_acc 0.9998944256756757\n",
      "\n",
      "Epoch 110. Loss: 0.0012217664579895517, Train_acc 0.9997916666666666\n",
      "\n",
      "Epoch 110. Loss: 0.0011006009030894246, Train_acc 0.9997944078947368\n",
      "\n",
      "Epoch 110. Loss: 0.0010216109154851712, Train_acc 0.999797077922078\n",
      "\n",
      "Epoch 110. Loss: 0.0009232788220969699, Train_acc 0.9997996794871795\n",
      "\n",
      "Epoch 110. Loss: 0.004088478514784086, Train_acc 0.9997033227848101\n",
      "\n",
      "Epoch 110. Loss: 0.003682718581172328, Train_acc 0.99970703125\n",
      "\n",
      "Epoch 110. Loss: 0.0033521911082454036, Train_acc 0.9997106481481481\n",
      "\n",
      "Epoch 110. Loss: 0.0031528316465836027, Train_acc 0.9997141768292683\n",
      "\n",
      "Epoch 110. Loss: 0.002841599561229433, Train_acc 0.9997176204819277\n",
      "\n",
      "Epoch 110. Loss: 0.0025581778902046127, Train_acc 0.9997209821428571\n",
      "\n",
      "Epoch 110. Loss: 0.002314418862242294, Train_acc 0.9997242647058824\n",
      "\n",
      "Epoch 110. Loss: 0.0021283313609470065, Train_acc 0.9997274709302325\n",
      "\n",
      "Epoch 110. Loss: 0.001923092492515386, Train_acc 0.9997306034482759\n",
      "\n",
      "Epoch 110. Loss: 0.0017891262719135353, Train_acc 0.9997336647727273\n",
      "\n",
      "Epoch 110. Loss: 0.001642904644518796, Train_acc 0.9997366573033708\n",
      "\n",
      "Epoch 110. Loss: 0.0014848258950024053, Train_acc 0.9997395833333333\n",
      "\n",
      "Epoch 110. Loss: 0.001562764540631402, Train_acc 0.999742445054945\n",
      "\n",
      "Epoch 110. Loss: 0.0015328513537590162, Train_acc 0.9997452445652174\n",
      "\n",
      "Epoch 110. Loss: 0.0015617879900666585, Train_acc 0.9997479838709677\n",
      "\n",
      "Epoch 110. Loss: 0.0014967765266913184, Train_acc 0.999750664893617\n",
      "\n",
      "Epoch 110. Loss: 0.0019221235086218722, Train_acc 0.999671052631579\n",
      "\n",
      "Epoch 110. Loss: 0.0017819530615963378, Train_acc 0.9996744791666666\n",
      "\n",
      "Epoch 110. Loss: 0.0016055157939614169, Train_acc 0.9996778350515464\n",
      "\n",
      "Epoch 110. Loss: 0.0014658822492808533, Train_acc 0.9996811224489796\n",
      "\n",
      "Epoch 110. Loss: 0.0013450251283131927, Train_acc 0.9996843434343434\n",
      "\n",
      "Epoch 110. Loss: 0.0012286873550766684, Train_acc 0.9996875\n",
      "\n",
      "[Epoch 110 Batch 100] Loss: 0.0011177836684758606 Training: accuracy=0.999691\n",
      "Epoch 110. Loss: 0.0011177836684758606, Train_acc 0.999690594059406\n",
      "\n",
      "Epoch 110. Loss: 0.0010149312245126476, Train_acc 0.9996936274509803\n",
      "\n",
      "Epoch 110. Loss: 0.0009153999659885186, Train_acc 0.9996966019417476\n",
      "\n",
      "Epoch 110. Loss: 0.0023032242490472693, Train_acc 0.9996243990384616\n",
      "\n",
      "Epoch 110. Loss: 0.002086392465282922, Train_acc 0.9996279761904762\n",
      "\n",
      "Epoch 110. Loss: 0.0018814251573662899, Train_acc 0.9996314858490566\n",
      "\n",
      "Epoch 110. Loss: 0.0016970497661378192, Train_acc 0.999634929906542\n",
      "\n",
      "Epoch 110. Loss: 0.0015307754333705509, Train_acc 0.9996383101851852\n",
      "\n",
      "Epoch 110. Loss: 0.0015784667063183312, Train_acc 0.999641628440367\n",
      "\n",
      "Epoch 110. Loss: 0.0015829046939769438, Train_acc 0.9996448863636364\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110. Loss: 0.0014305577258892069, Train_acc 0.9996480855855856\n",
      "\n",
      "Epoch 110. Loss: 0.006325522713121225, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 110. Loss: 0.006473017033344314, Train_acc 0.9994469026548672\n",
      "\n",
      "Epoch 110. Loss: 0.005849826430365977, Train_acc 0.9994517543859649\n",
      "\n",
      "Epoch 110. Loss: 0.007312191809790317, Train_acc 0.9993885869565218\n",
      "\n",
      "Epoch 110. Loss: 0.006594207349784119, Train_acc 0.9993938577586207\n",
      "\n",
      "Epoch 110. Loss: 0.005938201517845519, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 110. Loss: 0.005345564383199795, Train_acc 0.9994041313559322\n",
      "\n",
      "Epoch 110. Loss: 0.004831725080219325, Train_acc 0.9994091386554622\n",
      "\n",
      "Epoch 110. Loss: 0.004413901533122286, Train_acc 0.9994140625\n",
      "\n",
      "Epoch 110. Loss: 0.004164731213653468, Train_acc 0.9994189049586777\n",
      "\n",
      "Epoch 110. Loss: 0.003800317406036153, Train_acc 0.9994236680327869\n",
      "\n",
      "Epoch 110. Loss: 0.0034850601051026834, Train_acc 0.9994283536585366\n",
      "\n",
      "Epoch 110. Loss: 0.009388690921107614, Train_acc 0.9993069556451613\n",
      "\n",
      "Epoch 110. Loss: 0.009711716233885006, Train_acc 0.9993125\n",
      "\n",
      "Epoch 110. Loss: 0.008810368518184765, Train_acc 0.9993179563492064\n",
      "\n",
      "Epoch 110. Loss: 0.01641912148012323, Train_acc 0.9992002952755905\n",
      "\n",
      "Epoch 110. Loss: 0.01501299750701579, Train_acc 0.99920654296875\n",
      "\n",
      "Epoch 110. Loss: 0.014313004160487586, Train_acc 0.9991521317829457\n",
      "\n",
      "Epoch 110. Loss: 0.015058224904147328, Train_acc 0.9990985576923077\n",
      "\n",
      "Epoch 110. Loss: 0.013681017176530549, Train_acc 0.9991054389312977\n",
      "\n",
      "Epoch 110. Loss: 0.012349647665231412, Train_acc 0.9991122159090909\n",
      "\n",
      "Epoch 110. Loss: 0.016620790109821246, Train_acc 0.9990014097744361\n",
      "\n",
      "Epoch 110. Loss: 0.019134647529531795, Train_acc 0.9988339552238806\n",
      "\n",
      "Epoch 110. Loss: 0.021572587830909443, Train_acc 0.9987847222222223\n",
      "\n",
      "Epoch 110. Loss: 0.02003063836634608, Train_acc 0.9987936580882353\n",
      "\n",
      "Epoch 110. Loss: 0.018539037329916224, Train_acc 0.9988024635036497\n",
      "\n",
      "Epoch 110. Loss: 0.01676792758591054, Train_acc 0.9988111413043478\n",
      "\n",
      "Epoch 110. Loss: 0.015140993885664223, Train_acc 0.9988196942446043\n",
      "\n",
      "Epoch 110. Loss: 0.015720599473239255, Train_acc 0.9987165178571429\n",
      "\n",
      "Epoch 110. Loss: 0.017180961964179224, Train_acc 0.998614804964539\n",
      "\n",
      "Epoch 110. Loss: 0.016757032641901804, Train_acc 0.9985695422535211\n",
      "\n",
      "Epoch 110. Loss: 0.01641231227141699, Train_acc 0.9985249125874126\n",
      "\n",
      "Epoch 110. Loss: 0.017543515472609527, Train_acc 0.9984809027777778\n",
      "\n",
      "Epoch 110. Loss: 0.016139643055050428, Train_acc 0.9984913793103448\n",
      "\n",
      "Epoch 110. Loss: 0.017470746483071616, Train_acc 0.998394691780822\n",
      "\n",
      "Epoch 110. Loss: 0.01927794113367555, Train_acc 0.9982993197278912\n",
      "\n",
      "Epoch 110. Loss: 0.018266991719839788, Train_acc 0.9983108108108109\n",
      "\n",
      "Epoch 110. Loss: 0.017657481140855986, Train_acc 0.9982697147651006\n",
      "\n",
      "Epoch 110. Loss: 0.01604849408071998, Train_acc 0.99828125\n",
      "\n",
      "Epoch 110. Loss: 0.01472594884784606, Train_acc 0.9982926324503312\n",
      "\n",
      "Epoch 110. Loss: 0.013384537208746406, Train_acc 0.998303865131579\n",
      "\n",
      "Epoch 110. Loss: 0.012336661346558211, Train_acc 0.9983149509803921\n",
      "\n",
      "Epoch 110. Loss: 0.012894310551408064, Train_acc 0.9982751623376623\n",
      "\n",
      "Epoch 110. Loss: 0.014272255150249422, Train_acc 0.9981350806451613\n",
      "\n",
      "Epoch 110. Loss: 0.014128800714258094, Train_acc 0.9980969551282052\n",
      "\n",
      "Epoch 110. Loss: 0.016296594054320816, Train_acc 0.9980095541401274\n",
      "\n",
      "Epoch 110. Loss: 0.015032743720697789, Train_acc 0.9980221518987342\n",
      "\n",
      "Epoch 110. Loss: 0.01369365021460497, Train_acc 0.9980345911949685\n",
      "\n",
      "Epoch 110. Loss: 0.01704262500888029, Train_acc 0.997900390625\n",
      "\n",
      "Epoch 110. Loss: 0.018676063545518394, Train_acc 0.9978163819875776\n",
      "\n",
      "Epoch 110. Loss: 0.017799321452951378, Train_acc 0.9978298611111112\n",
      "\n",
      "Epoch 110. Loss: 0.016996624501951885, Train_acc 0.9978431748466258\n",
      "\n",
      "Epoch 110. Loss: 0.015491011387307213, Train_acc 0.9978563262195121\n",
      "\n",
      "Epoch 110. Loss: 0.014009687446850182, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 110. Loss: 0.013243714829502382, Train_acc 0.9978821536144579\n",
      "\n",
      "Epoch 110. Loss: 0.012419829625458609, Train_acc 0.9978948353293413\n",
      "\n",
      "Epoch 110. Loss: 0.011315381563481174, Train_acc 0.9979073660714286\n",
      "\n",
      "Epoch 110. Loss: 0.010237145466083125, Train_acc 0.9979197485207101\n",
      "\n",
      "Epoch 110. Loss: 0.009572549672587664, Train_acc 0.9979319852941176\n",
      "\n",
      "Epoch 110. Loss: 0.012722135941681818, Train_acc 0.9978527046783626\n",
      "\n",
      "Epoch 110. Loss: 0.012868073960838517, Train_acc 0.9978651889534884\n",
      "\n",
      "Epoch 110. Loss: 0.01160202607381613, Train_acc 0.9978775289017341\n",
      "\n",
      "Epoch 110. Loss: 0.01102218052813355, Train_acc 0.9978897270114943\n",
      "\n",
      "Epoch 110. Loss: 0.009937519851442764, Train_acc 0.9979017857142857\n",
      "\n",
      "Epoch 110. Loss: 0.014089676385924153, Train_acc 0.9977805397727273\n",
      "\n",
      "Epoch 110. Loss: 0.012922713709969757, Train_acc 0.9977930790960452\n",
      "\n",
      "Epoch 110. Loss: 0.011722811744292697, Train_acc 0.9978054775280899\n",
      "\n",
      "Epoch 110. Loss: 0.010592005472400148, Train_acc 0.9978177374301676\n",
      "\n",
      "Epoch 110. Loss: 0.009601689367022015, Train_acc 0.9978298611111112\n",
      "\n",
      "Epoch 110. Loss: 0.008651810748779552, Train_acc 0.9978418508287292\n",
      "\n",
      "Epoch 110. Loss: 0.007826289871118615, Train_acc 0.9978537087912088\n",
      "\n",
      "Epoch 110. Loss: 0.007204468907072082, Train_acc 0.99786543715847\n",
      "\n",
      "Epoch 110. Loss: 0.006619788125816525, Train_acc 0.9978770380434783\n",
      "\n",
      "Epoch 110. Loss: 0.0062016759431334206, Train_acc 0.9978885135135135\n",
      "\n",
      "Epoch 110. Loss: 0.005656650219003949, Train_acc 0.9978998655913979\n",
      "\n",
      "Epoch 110. Loss: 0.005427003448358708, Train_acc 0.9979110962566845\n",
      "\n",
      "Epoch 110. Loss: 0.005000523918630064, Train_acc 0.9979222074468085\n",
      "\n",
      "Epoch 110. Loss: 0.0047885962585089035, Train_acc 0.997933201058201\n",
      "\n",
      "Epoch 110. Loss: 0.0043846073191704535, Train_acc 0.9979440789473685\n",
      "\n",
      "Epoch 110. Loss: 0.004077975297690229, Train_acc 0.9979548429319371\n",
      "\n",
      "Epoch 110. Loss: 0.0052356376973278496, Train_acc 0.9979248046875\n",
      "\n",
      "Epoch 110. Loss: 0.004762765355490864, Train_acc 0.9979355569948186\n",
      "\n",
      "Epoch 110. Loss: 0.004313602972850102, Train_acc 0.9979461984536082\n",
      "\n",
      "Epoch 110. Loss: 0.003939810413096009, Train_acc 0.9979567307692307\n",
      "\n",
      "Epoch 110. Loss: 0.0035812030229761377, Train_acc 0.99796\n",
      "\n",
      "Epoch 111. Loss: 0.003344786883708314, Train_acc 1.0\n",
      "\n",
      "Epoch 111. Loss: 0.0032228001742286767, Train_acc 1.0\n",
      "\n",
      "Epoch 111. Loss: 0.002932198113382268, Train_acc 1.0\n",
      "\n",
      "Epoch 111. Loss: 0.0026677251711098404, Train_acc 1.0\n",
      "\n",
      "Epoch 111. Loss: 0.0024838103920150297, Train_acc 1.0\n",
      "\n",
      "Epoch 111. Loss: 0.002299315793871075, Train_acc 1.0\n",
      "\n",
      "Epoch 111. Loss: 0.0021091442902263463, Train_acc 1.0\n",
      "\n",
      "Epoch 111. Loss: 0.001920603604035117, Train_acc 1.0\n",
      "\n",
      "Epoch 111. Loss: 0.0017432183131737412, Train_acc 1.0\n",
      "\n",
      "Epoch 111. Loss: 0.0015725240309420168, Train_acc 1.0\n",
      "\n",
      "Epoch 111. Loss: 0.0025849748767360695, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 111. Loss: 0.0023425883542878426, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 111. Loss: 0.0021894163993864952, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 111. Loss: 0.002183295891019973, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 111. Loss: 0.002375834669098204, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 111. Loss: 0.006585275517784011, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 111. Loss: 0.006157655940770315, Train_acc 0.9990808823529411\n",
      "\n",
      "Epoch 111. Loss: 0.005546393496523554, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 111. Loss: 0.006490172448215117, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 111. Loss: 0.005894867672919241, Train_acc 0.998828125\n",
      "\n",
      "Epoch 111. Loss: 0.005424827822133012, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 111. Loss: 0.006044821132496691, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 111. Loss: 0.005467317859716405, Train_acc 0.998641304347826\n",
      "\n",
      "Epoch 111. Loss: 0.005127229439999631, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 111. Loss: 0.004625675918941416, Train_acc 0.99875\n",
      "\n",
      "Epoch 111. Loss: 0.004575890049890921, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 111. Loss: 0.004163892952011894, Train_acc 0.9988425925925926\n",
      "\n",
      "Epoch 111. Loss: 0.004021560085854117, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 111. Loss: 0.007100563436485395, Train_acc 0.9986530172413793\n",
      "\n",
      "Epoch 111. Loss: 0.006413738832597233, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 111. Loss: 0.005969208636782435, Train_acc 0.9987399193548387\n",
      "\n",
      "Epoch 111. Loss: 0.005486332133920671, Train_acc 0.998779296875\n",
      "\n",
      "Epoch 111. Loss: 0.004995695031519247, Train_acc 0.9988162878787878\n",
      "\n",
      "Epoch 111. Loss: 0.004586773634201001, Train_acc 0.9988511029411765\n",
      "\n",
      "Epoch 111. Loss: 0.0041445184476309295, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 111. Loss: 0.004055616229590768, Train_acc 0.9989149305555556\n",
      "\n",
      "Epoch 111. Loss: 0.004604074257448609, Train_acc 0.9987331081081081\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111. Loss: 0.004178365169253092, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 111. Loss: 0.0039991956151599955, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 111. Loss: 0.005291886846459681, Train_acc 0.9986328125\n",
      "\n",
      "Epoch 111. Loss: 0.0048960161385380695, Train_acc 0.9986661585365854\n",
      "\n",
      "Epoch 111. Loss: 0.004427601509352283, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 111. Loss: 0.004432141388335606, Train_acc 0.9987281976744186\n",
      "\n",
      "Epoch 111. Loss: 0.004093558977529062, Train_acc 0.9987571022727273\n",
      "\n",
      "Epoch 111. Loss: 0.0076524948094648, Train_acc 0.9984375\n",
      "\n",
      "Epoch 111. Loss: 0.006929792547136304, Train_acc 0.9984714673913043\n",
      "\n",
      "Epoch 111. Loss: 0.006246151874881114, Train_acc 0.9985039893617021\n",
      "\n",
      "Epoch 111. Loss: 0.005632157409998384, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 111. Loss: 0.005802128392662948, Train_acc 0.998405612244898\n",
      "\n",
      "Epoch 111. Loss: 0.005230097771549451, Train_acc 0.9984375\n",
      "\n",
      "Epoch 111. Loss: 0.005318984667611921, Train_acc 0.9984681372549019\n",
      "\n",
      "Epoch 111. Loss: 0.005696611822533135, Train_acc 0.9983473557692307\n",
      "\n",
      "Epoch 111. Loss: 0.007204920921523146, Train_acc 0.9982311320754716\n",
      "\n",
      "Epoch 111. Loss: 0.006560192927808335, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 111. Loss: 0.0061573919775776, Train_acc 0.9982954545454545\n",
      "\n",
      "Epoch 111. Loss: 0.0056037889456175514, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 111. Loss: 0.005511853431724556, Train_acc 0.9983552631578947\n",
      "\n",
      "Epoch 111. Loss: 0.006478168723788602, Train_acc 0.9982489224137931\n",
      "\n",
      "Epoch 111. Loss: 0.009405043936795065, Train_acc 0.998146186440678\n",
      "\n",
      "Epoch 111. Loss: 0.008513776489621986, Train_acc 0.9981770833333333\n",
      "\n",
      "Epoch 111. Loss: 0.007745183039117163, Train_acc 0.9982069672131147\n",
      "\n",
      "Epoch 111. Loss: 0.0072325828646048656, Train_acc 0.9982358870967742\n",
      "\n",
      "Epoch 111. Loss: 0.008342628782191105, Train_acc 0.9981398809523809\n",
      "\n",
      "Epoch 111. Loss: 0.00956783266830286, Train_acc 0.998046875\n",
      "\n",
      "Epoch 111. Loss: 0.009171198067154055, Train_acc 0.9980769230769231\n",
      "\n",
      "Epoch 111. Loss: 0.008582172027604787, Train_acc 0.9981060606060606\n",
      "\n",
      "Epoch 111. Loss: 0.009181413652488896, Train_acc 0.9980177238805971\n",
      "\n",
      "Epoch 111. Loss: 0.009098032729616142, Train_acc 0.998046875\n",
      "\n",
      "Epoch 111. Loss: 0.008419507539010385, Train_acc 0.9980751811594203\n",
      "\n",
      "Epoch 111. Loss: 0.007650010130747115, Train_acc 0.9981026785714285\n",
      "\n",
      "Epoch 111. Loss: 0.007078271671911886, Train_acc 0.9981294014084507\n",
      "\n",
      "Epoch 111. Loss: 0.010408779142601023, Train_acc 0.998046875\n",
      "\n",
      "Epoch 111. Loss: 0.010303777132155951, Train_acc 0.9980736301369864\n",
      "\n",
      "Epoch 111. Loss: 0.00942832460326474, Train_acc 0.9980996621621622\n",
      "\n",
      "Epoch 111. Loss: 0.012866344499491344, Train_acc 0.9980208333333334\n",
      "\n",
      "Epoch 111. Loss: 0.011690573012443802, Train_acc 0.998046875\n",
      "\n",
      "Epoch 111. Loss: 0.01099966216924407, Train_acc 0.9980722402597403\n",
      "\n",
      "Epoch 111. Loss: 0.009925562048576897, Train_acc 0.9980969551282052\n",
      "\n",
      "Epoch 111. Loss: 0.009080355801561586, Train_acc 0.9981210443037974\n",
      "\n",
      "Epoch 111. Loss: 0.009134242703061502, Train_acc 0.998046875\n",
      "\n",
      "Epoch 111. Loss: 0.00826570900449022, Train_acc 0.998070987654321\n",
      "\n",
      "Epoch 111. Loss: 0.007598368187268356, Train_acc 0.9980945121951219\n",
      "\n",
      "Epoch 111. Loss: 0.006993709057698947, Train_acc 0.9981174698795181\n",
      "\n",
      "Epoch 111. Loss: 0.006706048760679635, Train_acc 0.9981398809523809\n",
      "\n",
      "Epoch 111. Loss: 0.007406202541024035, Train_acc 0.9980698529411764\n",
      "\n",
      "Epoch 111. Loss: 0.009385134356824053, Train_acc 0.9978197674418605\n",
      "\n",
      "Epoch 111. Loss: 0.008474217350714089, Train_acc 0.9978448275862069\n",
      "\n",
      "Epoch 111. Loss: 0.009652846712260856, Train_acc 0.9977805397727273\n",
      "\n",
      "Epoch 111. Loss: 0.009009819908117724, Train_acc 0.9978054775280899\n",
      "\n",
      "Epoch 111. Loss: 0.009100570078798062, Train_acc 0.9977430555555555\n",
      "\n",
      "Epoch 111. Loss: 0.00833293025546112, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 111. Loss: 0.007586212929885134, Train_acc 0.9977921195652174\n",
      "\n",
      "Epoch 111. Loss: 0.006843344911680114, Train_acc 0.9978158602150538\n",
      "\n",
      "Epoch 111. Loss: 0.006555810787673734, Train_acc 0.9978390957446809\n",
      "\n",
      "Epoch 111. Loss: 0.005943383442619913, Train_acc 0.9978618421052632\n",
      "\n",
      "Epoch 111. Loss: 0.007324075364106423, Train_acc 0.997802734375\n",
      "\n",
      "Epoch 111. Loss: 0.006704271257866347, Train_acc 0.9978253865979382\n",
      "\n",
      "Epoch 111. Loss: 0.006048687936899687, Train_acc 0.9978475765306123\n",
      "\n",
      "Epoch 111. Loss: 0.005464070429542214, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 111. Loss: 0.008153447932128802, Train_acc 0.9978125\n",
      "\n",
      "[Epoch 111 Batch 100] Loss: 0.007355631776461106 Training: accuracy=0.997834\n",
      "Epoch 111. Loss: 0.007355631776461106, Train_acc 0.9978341584158416\n",
      "\n",
      "Epoch 111. Loss: 0.006893421297237964, Train_acc 0.9978553921568627\n",
      "\n",
      "Epoch 111. Loss: 0.008044482471018157, Train_acc 0.9978003640776699\n",
      "\n",
      "Epoch 111. Loss: 0.007246561787444266, Train_acc 0.9978215144230769\n",
      "\n",
      "Epoch 111. Loss: 0.0065507313200423465, Train_acc 0.9978422619047619\n",
      "\n",
      "Epoch 111. Loss: 0.006793508656792881, Train_acc 0.9978626179245284\n",
      "\n",
      "Epoch 111. Loss: 0.006160586904831342, Train_acc 0.997882593457944\n",
      "\n",
      "Epoch 111. Loss: 0.006543893775058637, Train_acc 0.9979021990740741\n",
      "\n",
      "Epoch 111. Loss: 0.006224177260216639, Train_acc 0.9979214449541285\n",
      "\n",
      "Epoch 111. Loss: 0.006447706743940621, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 111. Loss: 0.005972023003148207, Train_acc 0.9978885135135135\n",
      "\n",
      "Epoch 111. Loss: 0.005432152000845673, Train_acc 0.9979073660714286\n",
      "\n",
      "Epoch 111. Loss: 0.005040853999433996, Train_acc 0.9979258849557522\n",
      "\n",
      "Epoch 111. Loss: 0.005547132707278206, Train_acc 0.9978755482456141\n",
      "\n",
      "Epoch 111. Loss: 0.004999248374608265, Train_acc 0.9978940217391304\n",
      "\n",
      "Epoch 111. Loss: 0.004626035410019404, Train_acc 0.9979121767241379\n",
      "\n",
      "Epoch 111. Loss: 0.004401571819687766, Train_acc 0.9979300213675214\n",
      "\n",
      "Epoch 111. Loss: 0.003982531469058886, Train_acc 0.997947563559322\n",
      "\n",
      "Epoch 111. Loss: 0.003739951742675359, Train_acc 0.9979648109243697\n",
      "\n",
      "Epoch 111. Loss: 0.003673253250556995, Train_acc 0.9979817708333333\n",
      "\n",
      "Epoch 111. Loss: 0.003782102214861938, Train_acc 0.9979984504132231\n",
      "\n",
      "Epoch 111. Loss: 0.0057806640841684, Train_acc 0.9979508196721312\n",
      "\n",
      "Epoch 111. Loss: 0.0052066381277920595, Train_acc 0.9979674796747967\n",
      "\n",
      "Epoch 111. Loss: 0.0051600675640805175, Train_acc 0.9979838709677419\n",
      "\n",
      "Epoch 111. Loss: 0.0046633076044005775, Train_acc 0.998\n",
      "\n",
      "Epoch 111. Loss: 0.004203932404781163, Train_acc 0.998015873015873\n",
      "\n",
      "Epoch 111. Loss: 0.006002909171818, Train_acc 0.9979084645669292\n",
      "\n",
      "Epoch 111. Loss: 0.005488233353578271, Train_acc 0.9979248046875\n",
      "\n",
      "Epoch 111. Loss: 0.005263367549002071, Train_acc 0.9979408914728682\n",
      "\n",
      "Epoch 111. Loss: 0.007140095611292034, Train_acc 0.9978966346153846\n",
      "\n",
      "Epoch 111. Loss: 0.007943926059345522, Train_acc 0.9978530534351145\n",
      "\n",
      "Epoch 111. Loss: 0.0071680766053749375, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 111. Loss: 0.006478332867444784, Train_acc 0.9978853383458647\n",
      "\n",
      "Epoch 111. Loss: 0.010617532631952671, Train_acc 0.9977845149253731\n",
      "\n",
      "Epoch 111. Loss: 0.010837344982802071, Train_acc 0.9977430555555555\n",
      "\n",
      "Epoch 111. Loss: 0.010003718908164679, Train_acc 0.9977596507352942\n",
      "\n",
      "Epoch 111. Loss: 0.009193772832874607, Train_acc 0.997776003649635\n",
      "\n",
      "Epoch 111. Loss: 0.008320018394068988, Train_acc 0.9977921195652174\n",
      "\n",
      "Epoch 111. Loss: 0.007510910768569509, Train_acc 0.9978080035971223\n",
      "\n",
      "Epoch 111. Loss: 0.0067691078401432, Train_acc 0.9978236607142857\n",
      "\n",
      "Epoch 111. Loss: 0.006198997101015648, Train_acc 0.9978390957446809\n",
      "\n",
      "Epoch 111. Loss: 0.006227323700481773, Train_acc 0.9978543133802817\n",
      "\n",
      "Epoch 111. Loss: 0.00562939999430846, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 111. Loss: 0.005162521942865961, Train_acc 0.9978841145833334\n",
      "\n",
      "Epoch 111. Loss: 0.006138982115905386, Train_acc 0.9977909482758621\n",
      "\n",
      "Epoch 111. Loss: 0.005703775835383745, Train_acc 0.9978060787671232\n",
      "\n",
      "Epoch 111. Loss: 0.005221109996554311, Train_acc 0.9978210034013606\n",
      "\n",
      "Epoch 111. Loss: 0.00479439791888406, Train_acc 0.9978357263513513\n",
      "\n",
      "Epoch 111. Loss: 0.004336085863540822, Train_acc 0.9978502516778524\n",
      "\n",
      "Epoch 111. Loss: 0.004002047138963866, Train_acc 0.9978645833333334\n",
      "\n",
      "Epoch 111. Loss: 0.004117027954433616, Train_acc 0.9978787251655629\n",
      "\n",
      "Epoch 111. Loss: 0.0038191997164183163, Train_acc 0.9978926809210527\n",
      "\n",
      "Epoch 111. Loss: 0.006294526180955169, Train_acc 0.9978553921568627\n",
      "\n",
      "Epoch 111. Loss: 0.007648563404082416, Train_acc 0.9978185876623377\n",
      "\n",
      "Epoch 111. Loss: 0.007369676677911722, Train_acc 0.9978326612903226\n",
      "\n",
      "Epoch 111. Loss: 0.006658857835538754, Train_acc 0.9978465544871795\n",
      "\n",
      "Epoch 111. Loss: 0.006443319415933701, Train_acc 0.997860270700637\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111. Loss: 0.0059603007399023885, Train_acc 0.9978738132911392\n",
      "\n",
      "Epoch 111. Loss: 0.005539044534551172, Train_acc 0.9978871855345912\n",
      "\n",
      "Epoch 111. Loss: 0.005308883011873426, Train_acc 0.997900390625\n",
      "\n",
      "Epoch 111. Loss: 0.004812281246496763, Train_acc 0.9979134316770186\n",
      "\n",
      "Epoch 111. Loss: 0.00440355804529319, Train_acc 0.9979263117283951\n",
      "\n",
      "Epoch 111. Loss: 0.004649709912835328, Train_acc 0.9979390337423313\n",
      "\n",
      "Epoch 111. Loss: 0.004192150669635336, Train_acc 0.9979516006097561\n",
      "\n",
      "Epoch 111. Loss: 0.004171254724121989, Train_acc 0.9979640151515151\n",
      "\n",
      "Epoch 111. Loss: 0.0038856407420361653, Train_acc 0.9979762801204819\n",
      "\n",
      "Epoch 111. Loss: 0.004197945473702963, Train_acc 0.9979416167664671\n",
      "\n",
      "Epoch 111. Loss: 0.0037983495667462492, Train_acc 0.9979538690476191\n",
      "\n",
      "Epoch 111. Loss: 0.0037279929386348975, Train_acc 0.997965976331361\n",
      "\n",
      "Epoch 111. Loss: 0.0034121198756713977, Train_acc 0.9979779411764705\n",
      "\n",
      "Epoch 111. Loss: 0.003279875230145691, Train_acc 0.9979897660818714\n",
      "\n",
      "Epoch 111. Loss: 0.0029733443518850473, Train_acc 0.9980014534883721\n",
      "\n",
      "Epoch 111. Loss: 0.00280719303432464, Train_acc 0.9980130057803468\n",
      "\n",
      "Epoch 111. Loss: 0.0029646085222216787, Train_acc 0.9980244252873564\n",
      "\n",
      "Epoch 111. Loss: 0.0027051832022952148, Train_acc 0.9980357142857142\n",
      "\n",
      "Epoch 111. Loss: 0.0024462903227405273, Train_acc 0.998046875\n",
      "\n",
      "Epoch 111. Loss: 0.002294390523904624, Train_acc 0.9980579096045198\n",
      "\n",
      "Epoch 111. Loss: 0.0020799360413757155, Train_acc 0.9980688202247191\n",
      "\n",
      "Epoch 111. Loss: 0.0018999183196416966, Train_acc 0.9980796089385475\n",
      "\n",
      "Epoch 111. Loss: 0.0017420507311213587, Train_acc 0.9980902777777778\n",
      "\n",
      "Epoch 111. Loss: 0.0016011035800504528, Train_acc 0.9981008287292817\n",
      "\n",
      "Epoch 111. Loss: 0.001484651447376863, Train_acc 0.9981112637362637\n",
      "\n",
      "Epoch 111. Loss: 0.0014452643974680506, Train_acc 0.9981215846994536\n",
      "\n",
      "Epoch 111. Loss: 0.0013344782670211468, Train_acc 0.9981317934782609\n",
      "\n",
      "Epoch 111. Loss: 0.0012038029879874604, Train_acc 0.9981418918918918\n",
      "\n",
      "Epoch 111. Loss: 0.0011227226071781249, Train_acc 0.9981518817204301\n",
      "\n",
      "Epoch 111. Loss: 0.0010156429995035081, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 111. Loss: 0.0013380996697933928, Train_acc 0.9981715425531915\n",
      "\n",
      "Epoch 111. Loss: 0.001335068498387914, Train_acc 0.998181216931217\n",
      "\n",
      "Epoch 111. Loss: 0.0012068106618875936, Train_acc 0.9981907894736842\n",
      "\n",
      "Epoch 111. Loss: 0.0011017481866861217, Train_acc 0.9982002617801047\n",
      "\n",
      "Epoch 111. Loss: 0.0009977441891608238, Train_acc 0.9982096354166666\n",
      "\n",
      "Epoch 111. Loss: 0.0009107495386846826, Train_acc 0.9982189119170984\n",
      "\n",
      "Epoch 111. Loss: 0.0008273907211313533, Train_acc 0.9982280927835051\n",
      "\n",
      "Epoch 111. Loss: 0.0007477020975221454, Train_acc 0.9982371794871795\n",
      "\n",
      "Epoch 111. Loss: 0.0006793798355868541, Train_acc 0.99824\n",
      "\n",
      "Epoch 112. Loss: 0.0006791402022043839, Train_acc 1.0\n",
      "\n",
      "Epoch 112. Loss: 0.0006924546235427239, Train_acc 1.0\n",
      "\n",
      "Epoch 112. Loss: 0.0007646447783038001, Train_acc 1.0\n",
      "\n",
      "Epoch 112. Loss: 0.0007050002626573649, Train_acc 1.0\n",
      "\n",
      "Epoch 112. Loss: 0.0006783532973160765, Train_acc 1.0\n",
      "\n",
      "Epoch 112. Loss: 0.0006180978419481968, Train_acc 1.0\n",
      "\n",
      "Epoch 112. Loss: 0.0005611383056864408, Train_acc 1.0\n",
      "\n",
      "Epoch 112. Loss: 0.0005092440026632982, Train_acc 1.0\n",
      "\n",
      "Epoch 112. Loss: 0.00046979034311620113, Train_acc 1.0\n",
      "\n",
      "Epoch 112. Loss: 0.00042887058660728676, Train_acc 1.0\n",
      "\n",
      "Epoch 112. Loss: 0.0019486550775648023, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 112. Loss: 0.001769271019180923, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 112. Loss: 0.0018656512602764153, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 112. Loss: 0.0020738116078464195, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 112. Loss: 0.0018682031995736748, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 112. Loss: 0.001688343305142211, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 112. Loss: 0.0015830753084751102, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 112. Loss: 0.0014265872119559532, Train_acc 0.9995659722222222\n",
      "\n",
      "Epoch 112. Loss: 0.002154529951097997, Train_acc 0.9991776315789473\n",
      "\n",
      "Epoch 112. Loss: 0.0019431359639034, Train_acc 0.99921875\n",
      "\n",
      "Epoch 112. Loss: 0.0017546452345371679, Train_acc 0.9992559523809523\n",
      "\n",
      "Epoch 112. Loss: 0.0015864647479209694, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 112. Loss: 0.001433511024566764, Train_acc 0.9993206521739131\n",
      "\n",
      "Epoch 112. Loss: 0.0022799516730179856, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 112. Loss: 0.002059786157156448, Train_acc 0.9990625\n",
      "\n",
      "Epoch 112. Loss: 0.0020266036301773076, Train_acc 0.9990985576923077\n",
      "\n",
      "Epoch 112. Loss: 0.0026165040866960245, Train_acc 0.9988425925925926\n",
      "\n",
      "Epoch 112. Loss: 0.0024137615247137837, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 112. Loss: 0.0027913250327319646, Train_acc 0.9986530172413793\n",
      "\n",
      "Epoch 112. Loss: 0.00266021089751295, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 112. Loss: 0.002432998642267854, Train_acc 0.9987399193548387\n",
      "\n",
      "Epoch 112. Loss: 0.0022366536000691245, Train_acc 0.998779296875\n",
      "\n",
      "Epoch 112. Loss: 0.002147698369412636, Train_acc 0.9988162878787878\n",
      "\n",
      "Epoch 112. Loss: 0.0019459316116920249, Train_acc 0.9988511029411765\n",
      "\n",
      "Epoch 112. Loss: 0.0018822972591088238, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 112. Loss: 0.0017033082241950446, Train_acc 0.9989149305555556\n",
      "\n",
      "Epoch 112. Loss: 0.005359629123968305, Train_acc 0.9987331081081081\n",
      "\n",
      "Epoch 112. Loss: 0.004848410136885872, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 112. Loss: 0.004553237179752377, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 112. Loss: 0.004104108715586122, Train_acc 0.998828125\n",
      "\n",
      "Epoch 112. Loss: 0.003722958133766396, Train_acc 0.9988567073170732\n",
      "\n",
      "Epoch 112. Loss: 0.005517363428606996, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 112. Loss: 0.005003168422242657, Train_acc 0.9987281976744186\n",
      "\n",
      "Epoch 112. Loss: 0.004707143985415091, Train_acc 0.9987571022727273\n",
      "\n",
      "Epoch 112. Loss: 0.0042642391146926265, Train_acc 0.9987847222222223\n",
      "\n",
      "Epoch 112. Loss: 0.0042791904848851125, Train_acc 0.9988111413043478\n",
      "\n",
      "Epoch 112. Loss: 0.0038914192275475586, Train_acc 0.9988364361702128\n",
      "\n",
      "Epoch 112. Loss: 0.0040758870741371325, Train_acc 0.9988606770833334\n",
      "\n",
      "Epoch 112. Loss: 0.004052835869846703, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 112. Loss: 0.003658467753055173, Train_acc 0.99890625\n",
      "\n",
      "Epoch 112. Loss: 0.0033092340233405854, Train_acc 0.9989276960784313\n",
      "\n",
      "Epoch 112. Loss: 0.0032038556212914374, Train_acc 0.9989483173076923\n",
      "\n",
      "Epoch 112. Loss: 0.0030052848982385443, Train_acc 0.9989681603773585\n",
      "\n",
      "Epoch 112. Loss: 0.0027372340422094597, Train_acc 0.9989872685185185\n",
      "\n",
      "Epoch 112. Loss: 0.0025065510355655016, Train_acc 0.9990056818181818\n",
      "\n",
      "Epoch 112. Loss: 0.002259547338959618, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 112. Loss: 0.0020531985969016904, Train_acc 0.9990405701754386\n",
      "\n",
      "Epoch 112. Loss: 0.001910431145992424, Train_acc 0.9990571120689655\n",
      "\n",
      "Epoch 112. Loss: 0.0017623130002681951, Train_acc 0.999073093220339\n",
      "\n",
      "Epoch 112. Loss: 0.0016856965332573241, Train_acc 0.9990885416666667\n",
      "\n",
      "Epoch 112. Loss: 0.0015857251612908917, Train_acc 0.9991034836065574\n",
      "\n",
      "Epoch 112. Loss: 0.0014785924664162645, Train_acc 0.9991179435483871\n",
      "\n",
      "Epoch 112. Loss: 0.001332011118220189, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 112. Loss: 0.001420981290656536, Train_acc 0.9991455078125\n",
      "\n",
      "Epoch 112. Loss: 0.0013023270828272037, Train_acc 0.9991586538461539\n",
      "\n",
      "Epoch 112. Loss: 0.0013922088328968108, Train_acc 0.9991714015151515\n",
      "\n",
      "Epoch 112. Loss: 0.001263532445642566, Train_acc 0.9991837686567164\n",
      "\n",
      "Epoch 112. Loss: 0.001404361608047678, Train_acc 0.9991957720588235\n",
      "\n",
      "Epoch 112. Loss: 0.0012669031874661969, Train_acc 0.9992074275362319\n",
      "\n",
      "Epoch 112. Loss: 0.0011424794330168924, Train_acc 0.99921875\n",
      "\n",
      "Epoch 112. Loss: 0.00103365221201539, Train_acc 0.9992297535211268\n",
      "\n",
      "Epoch 112. Loss: 0.0028654695026203393, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 112. Loss: 0.0025928092937208174, Train_acc 0.9991438356164384\n",
      "\n",
      "Epoch 112. Loss: 0.0023358821533716267, Train_acc 0.9991554054054054\n",
      "\n",
      "Epoch 112. Loss: 0.0021375007893510802, Train_acc 0.9991666666666666\n",
      "\n",
      "Epoch 112. Loss: 0.0027660486257852445, Train_acc 0.9990748355263158\n",
      "\n",
      "Epoch 112. Loss: 0.003570091246674776, Train_acc 0.9989853896103896\n",
      "\n",
      "Epoch 112. Loss: 0.0036099453534427168, Train_acc 0.9989983974358975\n",
      "\n",
      "Epoch 112. Loss: 0.0032716419862223014, Train_acc 0.9990110759493671\n",
      "\n",
      "Epoch 112. Loss: 0.003091151744951666, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 112. Loss: 0.005472617989030357, Train_acc 0.9988425925925926\n",
      "\n",
      "Epoch 112. Loss: 0.005060317753289827, Train_acc 0.9988567073170732\n",
      "\n",
      "Epoch 112. Loss: 0.00476552202179404, Train_acc 0.9988704819277109\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112. Loss: 0.0043559070988036415, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 112. Loss: 0.007250863751489272, Train_acc 0.9988051470588235\n",
      "\n",
      "Epoch 112. Loss: 0.010293323642657712, Train_acc 0.998546511627907\n",
      "\n",
      "Epoch 112. Loss: 0.009739075128716095, Train_acc 0.9985632183908046\n",
      "\n",
      "Epoch 112. Loss: 0.008778897963408463, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 112. Loss: 0.007938558799327426, Train_acc 0.9985955056179775\n",
      "\n",
      "Epoch 112. Loss: 0.0074720121171409, Train_acc 0.9986111111111111\n",
      "\n",
      "Epoch 112. Loss: 0.0076756923716963035, Train_acc 0.9986263736263736\n",
      "\n",
      "Epoch 112. Loss: 0.0070755165977247686, Train_acc 0.998641304347826\n",
      "\n",
      "Epoch 112. Loss: 0.008247138827708495, Train_acc 0.9985719086021505\n",
      "\n",
      "Epoch 112. Loss: 0.007531405146122395, Train_acc 0.9985871010638298\n",
      "\n",
      "Epoch 112. Loss: 0.007260152491733807, Train_acc 0.9986019736842106\n",
      "\n",
      "Epoch 112. Loss: 0.006734892414969543, Train_acc 0.9986165364583334\n",
      "\n",
      "Epoch 112. Loss: 0.006145285127669429, Train_acc 0.9986307989690721\n",
      "\n",
      "Epoch 112. Loss: 0.005693273871005942, Train_acc 0.9986447704081632\n",
      "\n",
      "Epoch 112. Loss: 0.005680381314556035, Train_acc 0.9986584595959596\n",
      "\n",
      "Epoch 112. Loss: 0.019763442030489655, Train_acc 0.9984375\n",
      "\n",
      "[Epoch 112 Batch 100] Loss: 0.018245596266260933 Training: accuracy=0.998453\n",
      "Epoch 112. Loss: 0.018245596266260933, Train_acc 0.9984529702970297\n",
      "\n",
      "Epoch 112. Loss: 0.02835140250009703, Train_acc 0.9982383578431373\n",
      "\n",
      "Epoch 112. Loss: 0.025838154736041195, Train_acc 0.9982554611650486\n",
      "\n",
      "Epoch 112. Loss: 0.02634096262563393, Train_acc 0.9981219951923077\n",
      "\n",
      "Epoch 112. Loss: 0.026076541217051077, Train_acc 0.9980654761904761\n",
      "\n",
      "Epoch 112. Loss: 0.02374308811221909, Train_acc 0.9980837264150944\n",
      "\n",
      "Epoch 112. Loss: 0.02322048345888607, Train_acc 0.9980286214953271\n",
      "\n",
      "Epoch 112. Loss: 0.024573001858755522, Train_acc 0.9979021990740741\n",
      "\n",
      "Epoch 112. Loss: 0.02715016552552394, Train_acc 0.9977064220183486\n",
      "\n",
      "Epoch 112. Loss: 0.024500083245057796, Train_acc 0.9977272727272727\n",
      "\n",
      "Epoch 112. Loss: 0.022096051539555357, Train_acc 0.9977477477477478\n",
      "\n",
      "Epoch 112. Loss: 0.020929487063504903, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 112. Loss: 0.020262844630942627, Train_acc 0.9977876106194691\n",
      "\n",
      "Epoch 112. Loss: 0.02427803816097905, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 112. Loss: 0.024961016774457067, Train_acc 0.9974864130434783\n",
      "\n",
      "Epoch 112. Loss: 0.0228279642875028, Train_acc 0.9975080818965517\n",
      "\n",
      "Epoch 112. Loss: 0.020651989347341568, Train_acc 0.9975293803418803\n",
      "\n",
      "Epoch 112. Loss: 0.02098449435079358, Train_acc 0.9974841101694916\n",
      "\n",
      "Epoch 112. Loss: 0.02299548938492771, Train_acc 0.9973082983193278\n",
      "\n",
      "Epoch 112. Loss: 0.025309163000760995, Train_acc 0.9972005208333333\n",
      "\n",
      "Epoch 112. Loss: 0.02340318389229046, Train_acc 0.9972236570247934\n",
      "\n",
      "Epoch 112. Loss: 0.024009446635771398, Train_acc 0.9971823770491803\n",
      "\n",
      "Epoch 112. Loss: 0.023011243084009234, Train_acc 0.997141768292683\n",
      "\n",
      "Epoch 112. Loss: 0.021588673358204136, Train_acc 0.9971648185483871\n",
      "\n",
      "Epoch 112. Loss: 0.019686972124912296, Train_acc 0.9971875\n",
      "\n",
      "Epoch 112. Loss: 0.018047520120252333, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 112. Loss: 0.018326860531546918, Train_acc 0.9971702755905512\n",
      "\n",
      "Epoch 112. Loss: 0.016812287517639916, Train_acc 0.9971923828125\n",
      "\n",
      "Epoch 112. Loss: 0.016192410549449553, Train_acc 0.9972141472868217\n",
      "\n",
      "Epoch 112. Loss: 0.015790768148834376, Train_acc 0.9971754807692308\n",
      "\n",
      "Epoch 112. Loss: 0.017392579629124584, Train_acc 0.9970777671755725\n",
      "\n",
      "Epoch 112. Loss: 0.016774998938233896, Train_acc 0.9970407196969697\n",
      "\n",
      "Epoch 112. Loss: 0.01558662295507602, Train_acc 0.997062969924812\n",
      "\n",
      "Epoch 112. Loss: 0.014785664729406347, Train_acc 0.9970848880597015\n",
      "\n",
      "Epoch 112. Loss: 0.013864215606865205, Train_acc 0.9971064814814815\n",
      "\n",
      "Epoch 112. Loss: 0.013041999227032289, Train_acc 0.9971277573529411\n",
      "\n",
      "Epoch 112. Loss: 0.011872410794977301, Train_acc 0.9971487226277372\n",
      "\n",
      "Epoch 112. Loss: 0.011810296792582232, Train_acc 0.9971127717391305\n",
      "\n",
      "Epoch 112. Loss: 0.012716627361293637, Train_acc 0.9970773381294964\n",
      "\n",
      "Epoch 112. Loss: 0.011709083143844607, Train_acc 0.9970982142857143\n",
      "\n",
      "Epoch 112. Loss: 0.010680880479528965, Train_acc 0.9971187943262412\n",
      "\n",
      "Epoch 112. Loss: 0.009657380873536582, Train_acc 0.9971390845070423\n",
      "\n",
      "Epoch 112. Loss: 0.008775160063563376, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 112. Loss: 0.008761630147032668, Train_acc 0.9971245659722222\n",
      "\n",
      "Epoch 112. Loss: 0.009363415522276815, Train_acc 0.9970905172413793\n",
      "\n",
      "Epoch 112. Loss: 0.008545916271939388, Train_acc 0.9971104452054794\n",
      "\n",
      "Epoch 112. Loss: 0.009469554529548745, Train_acc 0.9970769557823129\n",
      "\n",
      "Epoch 112. Loss: 0.008966204363594408, Train_acc 0.997096706081081\n",
      "\n",
      "Epoch 112. Loss: 0.00820358377178233, Train_acc 0.9971161912751678\n",
      "\n",
      "Epoch 112. Loss: 0.007464227926410104, Train_acc 0.9971354166666667\n",
      "\n",
      "Epoch 112. Loss: 0.006745235301889285, Train_acc 0.9971543874172185\n",
      "\n",
      "Epoch 112. Loss: 0.006869357666674827, Train_acc 0.9971731085526315\n",
      "\n",
      "Epoch 112. Loss: 0.006359760677582986, Train_acc 0.9971915849673203\n",
      "\n",
      "Epoch 112. Loss: 0.0060237025163474385, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 112. Loss: 0.005496952485453952, Train_acc 0.9972278225806451\n",
      "\n",
      "Epoch 112. Loss: 0.0050233666639359605, Train_acc 0.997245592948718\n",
      "\n",
      "Epoch 112. Loss: 0.004753415701836212, Train_acc 0.9972631369426752\n",
      "\n",
      "Epoch 112. Loss: 0.004335255469268066, Train_acc 0.9972804588607594\n",
      "\n",
      "Epoch 112. Loss: 0.003998073513917701, Train_acc 0.9972975628930818\n",
      "\n",
      "Epoch 112. Loss: 0.004167025324504891, Train_acc 0.997314453125\n",
      "\n",
      "Epoch 112. Loss: 0.0038268562968161576, Train_acc 0.9973311335403726\n",
      "\n",
      "Epoch 112. Loss: 0.003534010000802893, Train_acc 0.9973476080246914\n",
      "\n",
      "Epoch 112. Loss: 0.0033575209415207673, Train_acc 0.9973638803680982\n",
      "\n",
      "Epoch 112. Loss: 0.003189516015239093, Train_acc 0.9973799542682927\n",
      "\n",
      "Epoch 112. Loss: 0.0029250691069681494, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 112. Loss: 0.0026723542862272156, Train_acc 0.9974115210843374\n",
      "\n",
      "Epoch 112. Loss: 0.0025456994391056206, Train_acc 0.9974270209580839\n",
      "\n",
      "Epoch 112. Loss: 0.0023918854195540224, Train_acc 0.9974423363095238\n",
      "\n",
      "Epoch 112. Loss: 0.0022295967646612297, Train_acc 0.9974574704142012\n",
      "\n",
      "Epoch 112. Loss: 0.002035993595197483, Train_acc 0.9974724264705882\n",
      "\n",
      "Epoch 112. Loss: 0.00187661280287774, Train_acc 0.9974872076023392\n",
      "\n",
      "Epoch 112. Loss: 0.0018909986489576542, Train_acc 0.9975018168604651\n",
      "\n",
      "Epoch 112. Loss: 0.0022154646969046394, Train_acc 0.9975162572254336\n",
      "\n",
      "Epoch 112. Loss: 0.0020522426177708385, Train_acc 0.9975305316091954\n",
      "\n",
      "Epoch 112. Loss: 0.00207025032353235, Train_acc 0.9975446428571428\n",
      "\n",
      "Epoch 112. Loss: 0.0021862525936901514, Train_acc 0.99755859375\n",
      "\n",
      "Epoch 112. Loss: 0.00224216432581305, Train_acc 0.9975723870056498\n",
      "\n",
      "Epoch 112. Loss: 0.0021206885824125365, Train_acc 0.9975860252808989\n",
      "\n",
      "Epoch 112. Loss: 0.0019418262226544789, Train_acc 0.9975995111731844\n",
      "\n",
      "Epoch 112. Loss: 0.0024274701505747113, Train_acc 0.9975694444444444\n",
      "\n",
      "Epoch 112. Loss: 0.002246306159734056, Train_acc 0.9975828729281768\n",
      "\n",
      "Epoch 112. Loss: 0.0021233469814935257, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 112. Loss: 0.0019665536957833704, Train_acc 0.9976092896174863\n",
      "\n",
      "Epoch 112. Loss: 0.0017957314652846564, Train_acc 0.9976222826086957\n",
      "\n",
      "Epoch 112. Loss: 0.00735380498790559, Train_acc 0.9975929054054054\n",
      "\n",
      "Epoch 112. Loss: 0.00669048341964245, Train_acc 0.9976058467741935\n",
      "\n",
      "Epoch 112. Loss: 0.006190313569646122, Train_acc 0.9976186497326203\n",
      "\n",
      "Epoch 112. Loss: 0.00559098673990313, Train_acc 0.9976313164893617\n",
      "\n",
      "Epoch 112. Loss: 0.005178297644068543, Train_acc 0.9976438492063492\n",
      "\n",
      "Epoch 112. Loss: 0.004776501335949967, Train_acc 0.99765625\n",
      "\n",
      "Epoch 112. Loss: 0.004358195018601808, Train_acc 0.9976685209424084\n",
      "\n",
      "Epoch 112. Loss: 0.004002334850848744, Train_acc 0.9976806640625\n",
      "\n",
      "Epoch 112. Loss: 0.0036213961590739786, Train_acc 0.9976926813471503\n",
      "\n",
      "Epoch 112. Loss: 0.0035320738475244674, Train_acc 0.997704574742268\n",
      "\n",
      "Epoch 112. Loss: 0.003301193808661082, Train_acc 0.9977163461538462\n",
      "\n",
      "Epoch 112. Loss: 0.0030783892263102643, Train_acc 0.99772\n",
      "\n",
      "Epoch 113. Loss: 0.0027802191651368504, Train_acc 1.0\n",
      "\n",
      "Epoch 113. Loss: 0.0025361225593317476, Train_acc 1.0\n",
      "\n",
      "Epoch 113. Loss: 0.002358439275035613, Train_acc 1.0\n",
      "\n",
      "Epoch 113. Loss: 0.002365386602536756, Train_acc 1.0\n",
      "\n",
      "Epoch 113. Loss: 0.002804904172723816, Train_acc 0.9984375\n",
      "\n",
      "Epoch 113. Loss: 0.0025475947424970693, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 113. Loss: 0.002634213653448459, Train_acc 0.9988839285714286\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113. Loss: 0.003887681323805365, Train_acc 0.998046875\n",
      "\n",
      "Epoch 113. Loss: 0.003762162390330952, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 113. Loss: 0.003520065472890009, Train_acc 0.9984375\n",
      "\n",
      "Epoch 113. Loss: 0.0035473073779738575, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 113. Loss: 0.005232681021916565, Train_acc 0.998046875\n",
      "\n",
      "Epoch 113. Loss: 0.004995703015843955, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 113. Loss: 0.004708113327208097, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 113. Loss: 0.004466186950355412, Train_acc 0.9984375\n",
      "\n",
      "Epoch 113. Loss: 0.004058599076382495, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 113. Loss: 0.0038812254021351137, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 113. Loss: 0.004928687809388453, Train_acc 0.9978298611111112\n",
      "\n",
      "Epoch 113. Loss: 0.004924395321441246, Train_acc 0.9979440789473685\n",
      "\n",
      "Epoch 113. Loss: 0.00449922155177896, Train_acc 0.998046875\n",
      "\n",
      "Epoch 113. Loss: 0.004131083500132454, Train_acc 0.9981398809523809\n",
      "\n",
      "Epoch 113. Loss: 0.0037293975908490114, Train_acc 0.9982244318181818\n",
      "\n",
      "Epoch 113. Loss: 0.003699044933968672, Train_acc 0.9983016304347826\n",
      "\n",
      "Epoch 113. Loss: 0.003365449261862536, Train_acc 0.9983723958333334\n",
      "\n",
      "Epoch 113. Loss: 0.0032236844334849715, Train_acc 0.9984375\n",
      "\n",
      "Epoch 113. Loss: 0.003089721801923126, Train_acc 0.9984975961538461\n",
      "\n",
      "Epoch 113. Loss: 0.004058323587220677, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 113. Loss: 0.005938980908908041, Train_acc 0.998046875\n",
      "\n",
      "Epoch 113. Loss: 0.006535223288879625, Train_acc 0.9978448275862069\n",
      "\n",
      "Epoch 113. Loss: 0.005912008353163487, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 113. Loss: 0.00533896782056298, Train_acc 0.9979838709677419\n",
      "\n",
      "Epoch 113. Loss: 0.0048166426123569155, Train_acc 0.998046875\n",
      "\n",
      "Epoch 113. Loss: 0.0043438933789866655, Train_acc 0.9981060606060606\n",
      "\n",
      "Epoch 113. Loss: 0.006415900215518846, Train_acc 0.9977022058823529\n",
      "\n",
      "Epoch 113. Loss: 0.005814930869975947, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 113. Loss: 0.011784144705986318, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 113. Loss: 0.01104596250485361, Train_acc 0.9974662162162162\n",
      "\n",
      "Epoch 113. Loss: 0.010069253945273731, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 113. Loss: 0.009325141750989176, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 113. Loss: 0.008465559772671298, Train_acc 0.99765625\n",
      "\n",
      "Epoch 113. Loss: 0.0076687892618032116, Train_acc 0.9977134146341463\n",
      "\n",
      "Epoch 113. Loss: 0.007116113782726391, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 113. Loss: 0.006774597841846345, Train_acc 0.9978197674418605\n",
      "\n",
      "Epoch 113. Loss: 0.006413684635621963, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 113. Loss: 0.006545064128276102, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 113. Loss: 0.010941563719662779, Train_acc 0.9977921195652174\n",
      "\n",
      "Epoch 113. Loss: 0.009971842835365462, Train_acc 0.9978390957446809\n",
      "\n",
      "Epoch 113. Loss: 0.00927985952535456, Train_acc 0.9978841145833334\n",
      "\n",
      "Epoch 113. Loss: 0.014513179626219144, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 113. Loss: 0.013077733993419972, Train_acc 0.9978125\n",
      "\n",
      "Epoch 113. Loss: 0.011848932080150964, Train_acc 0.9978553921568627\n",
      "\n",
      "Epoch 113. Loss: 0.01070613685275807, Train_acc 0.9978966346153846\n",
      "\n",
      "Epoch 113. Loss: 0.009829202185894049, Train_acc 0.9979363207547169\n",
      "\n",
      "Epoch 113. Loss: 0.008973552936401214, Train_acc 0.9979745370370371\n",
      "\n",
      "Epoch 113. Loss: 0.008597675513404231, Train_acc 0.9980113636363637\n",
      "\n",
      "Epoch 113. Loss: 0.007815308673661684, Train_acc 0.998046875\n",
      "\n",
      "Epoch 113. Loss: 0.007152584298832775, Train_acc 0.9980811403508771\n",
      "\n",
      "Epoch 113. Loss: 0.0065387567460613505, Train_acc 0.998114224137931\n",
      "\n",
      "Epoch 113. Loss: 0.008692727550573086, Train_acc 0.9978813559322034\n",
      "\n",
      "Epoch 113. Loss: 0.009924539199209454, Train_acc 0.99765625\n",
      "\n",
      "Epoch 113. Loss: 0.009869598727586486, Train_acc 0.9976946721311475\n",
      "\n",
      "Epoch 113. Loss: 0.010925641139891104, Train_acc 0.9974798387096774\n",
      "\n",
      "Epoch 113. Loss: 0.009933451305911412, Train_acc 0.9975198412698413\n",
      "\n",
      "Epoch 113. Loss: 0.009006576815333265, Train_acc 0.99755859375\n",
      "\n",
      "Epoch 113. Loss: 0.008732482461186915, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 113. Loss: 0.00789050796891615, Train_acc 0.9976325757575758\n",
      "\n",
      "Epoch 113. Loss: 0.007207168384406256, Train_acc 0.9976679104477612\n",
      "\n",
      "Epoch 113. Loss: 0.006635288895808864, Train_acc 0.9977022058823529\n",
      "\n",
      "Epoch 113. Loss: 0.006026692333703377, Train_acc 0.9977355072463768\n",
      "\n",
      "Epoch 113. Loss: 0.005592359387939547, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 113. Loss: 0.0058492472886133556, Train_acc 0.9977992957746479\n",
      "\n",
      "Epoch 113. Loss: 0.005369439518481942, Train_acc 0.9978298611111112\n",
      "\n",
      "Epoch 113. Loss: 0.0050399038979683395, Train_acc 0.9978595890410958\n",
      "\n",
      "Epoch 113. Loss: 0.004633942426899738, Train_acc 0.9978885135135135\n",
      "\n",
      "Epoch 113. Loss: 0.006582417166226805, Train_acc 0.9978125\n",
      "\n",
      "Epoch 113. Loss: 0.005951232364009091, Train_acc 0.9978412828947368\n",
      "\n",
      "Epoch 113. Loss: 0.005698142861221971, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 113. Loss: 0.005172932773874097, Train_acc 0.9978966346153846\n",
      "\n",
      "Epoch 113. Loss: 0.005566002004634642, Train_acc 0.9978243670886076\n",
      "\n",
      "Epoch 113. Loss: 0.005042994274743508, Train_acc 0.9978515625\n",
      "\n",
      "Epoch 113. Loss: 0.004780813454544345, Train_acc 0.9978780864197531\n",
      "\n",
      "Epoch 113. Loss: 0.004396954363209724, Train_acc 0.9979039634146342\n",
      "\n",
      "Epoch 113. Loss: 0.003974721137851301, Train_acc 0.9979292168674698\n",
      "\n",
      "Epoch 113. Loss: 0.003581879188105725, Train_acc 0.9979538690476191\n",
      "\n",
      "Epoch 113. Loss: 0.0032517489509245865, Train_acc 0.9979779411764705\n",
      "\n",
      "Epoch 113. Loss: 0.0030653293032946688, Train_acc 0.9980014534883721\n",
      "\n",
      "Epoch 113. Loss: 0.0027671323939480264, Train_acc 0.9980244252873564\n",
      "\n",
      "Epoch 113. Loss: 0.002548317761891071, Train_acc 0.998046875\n",
      "\n",
      "Epoch 113. Loss: 0.0024097322841231386, Train_acc 0.9980688202247191\n",
      "\n",
      "Epoch 113. Loss: 0.002213366880822423, Train_acc 0.9980902777777778\n",
      "\n",
      "Epoch 113. Loss: 0.0027924317239000586, Train_acc 0.9980254120879121\n",
      "\n",
      "Epoch 113. Loss: 0.002533253391428685, Train_acc 0.998046875\n",
      "\n",
      "Epoch 113. Loss: 0.0022865096317954735, Train_acc 0.998067876344086\n",
      "\n",
      "Epoch 113. Loss: 0.0021207174592408127, Train_acc 0.9980884308510638\n",
      "\n",
      "Epoch 113. Loss: 0.0019177457971605364, Train_acc 0.9981085526315789\n",
      "\n",
      "Epoch 113. Loss: 0.0017313701489792108, Train_acc 0.9981282552083334\n",
      "\n",
      "Epoch 113. Loss: 0.0015700492535945312, Train_acc 0.9981475515463918\n",
      "\n",
      "Epoch 113. Loss: 0.0014199566873297912, Train_acc 0.9981664540816326\n",
      "\n",
      "Epoch 113. Loss: 0.001504589147036, Train_acc 0.9981849747474747\n",
      "\n",
      "Epoch 113. Loss: 0.001381899931559465, Train_acc 0.998203125\n",
      "\n",
      "[Epoch 113 Batch 100] Loss: 0.001261729892262557 Training: accuracy=0.998221\n",
      "Epoch 113. Loss: 0.001261729892262557, Train_acc 0.9982209158415841\n",
      "\n",
      "Epoch 113. Loss: 0.0012126493119373818, Train_acc 0.9982383578431373\n",
      "\n",
      "Epoch 113. Loss: 0.0010993645986679854, Train_acc 0.9982554611650486\n",
      "\n",
      "Epoch 113. Loss: 0.0010162043845963773, Train_acc 0.9982722355769231\n",
      "\n",
      "Epoch 113. Loss: 0.000980308142747712, Train_acc 0.9982886904761905\n",
      "\n",
      "Epoch 113. Loss: 0.0016544815785702156, Train_acc 0.9982311320754716\n",
      "\n",
      "Epoch 113. Loss: 0.004702477400334128, Train_acc 0.9981746495327103\n",
      "\n",
      "Epoch 113. Loss: 0.004245392571937469, Train_acc 0.9981915509259259\n",
      "\n",
      "Epoch 113. Loss: 0.003826950356949233, Train_acc 0.9982081422018348\n",
      "\n",
      "Epoch 113. Loss: 0.003877891265754875, Train_acc 0.9982244318181818\n",
      "\n",
      "Epoch 113. Loss: 0.003510958024120217, Train_acc 0.9982404279279279\n",
      "\n",
      "Epoch 113. Loss: 0.0033146169623598926, Train_acc 0.9982561383928571\n",
      "\n",
      "Epoch 113. Loss: 0.0029903528085600912, Train_acc 0.9982715707964602\n",
      "\n",
      "Epoch 113. Loss: 0.0027921099715495033, Train_acc 0.9982867324561403\n",
      "\n",
      "Epoch 113. Loss: 0.003075141765451186, Train_acc 0.9983016304347826\n",
      "\n",
      "Epoch 113. Loss: 0.002921024845414537, Train_acc 0.9983162715517241\n",
      "\n",
      "Epoch 113. Loss: 0.0026580363514770292, Train_acc 0.9983306623931624\n",
      "\n",
      "Epoch 113. Loss: 0.002410169436143642, Train_acc 0.9983448093220338\n",
      "\n",
      "Epoch 113. Loss: 0.0022035549256136013, Train_acc 0.998358718487395\n",
      "\n",
      "Epoch 113. Loss: 0.002015036410047933, Train_acc 0.9983723958333334\n",
      "\n",
      "Epoch 113. Loss: 0.002728052235502891, Train_acc 0.9983212809917356\n",
      "\n",
      "Epoch 113. Loss: 0.002834494276889168, Train_acc 0.9983350409836066\n",
      "\n",
      "Epoch 113. Loss: 0.0027015397786033183, Train_acc 0.9983485772357723\n",
      "\n",
      "Epoch 113. Loss: 0.002481273444869998, Train_acc 0.9983618951612904\n",
      "\n",
      "Epoch 113. Loss: 0.002684009137641385, Train_acc 0.998375\n",
      "\n",
      "Epoch 113. Loss: 0.0025197584464916544, Train_acc 0.9983878968253969\n",
      "\n",
      "Epoch 113. Loss: 0.002275221220765095, Train_acc 0.9984005905511811\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113. Loss: 0.0021191895673787573, Train_acc 0.9984130859375\n",
      "\n",
      "Epoch 113. Loss: 0.0019225571705784035, Train_acc 0.9984253875968992\n",
      "\n",
      "Epoch 113. Loss: 0.0017368803263739876, Train_acc 0.9984375\n",
      "\n",
      "Epoch 113. Loss: 0.0015728751759645236, Train_acc 0.998449427480916\n",
      "\n",
      "Epoch 113. Loss: 0.0014224777188354839, Train_acc 0.9984611742424242\n",
      "\n",
      "Epoch 113. Loss: 0.002681147715430329, Train_acc 0.9984140037593985\n",
      "\n",
      "Epoch 113. Loss: 0.002478274930772963, Train_acc 0.9984258395522388\n",
      "\n",
      "Epoch 113. Loss: 0.002275938823085717, Train_acc 0.9984375\n",
      "\n",
      "Epoch 113. Loss: 0.0020568716042185893, Train_acc 0.9984489889705882\n",
      "\n",
      "Epoch 113. Loss: 0.001860631727606735, Train_acc 0.9984603102189781\n",
      "\n",
      "Epoch 113. Loss: 0.0016904179246569559, Train_acc 0.9984714673913043\n",
      "\n",
      "Epoch 113. Loss: 0.0015251098669661293, Train_acc 0.9984824640287769\n",
      "\n",
      "Epoch 113. Loss: 0.0013867083765295783, Train_acc 0.9984933035714286\n",
      "\n",
      "Epoch 113. Loss: 0.001272626809346353, Train_acc 0.9985039893617021\n",
      "\n",
      "Epoch 113. Loss: 0.0016803005881467535, Train_acc 0.9985145246478874\n",
      "\n",
      "Epoch 113. Loss: 0.0015237436216408119, Train_acc 0.9985249125874126\n",
      "\n",
      "Epoch 113. Loss: 0.0013873755032993613, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 113. Loss: 0.0012573297391757527, Train_acc 0.9985452586206897\n",
      "\n",
      "Epoch 113. Loss: 0.001157199521326288, Train_acc 0.9985552226027398\n",
      "\n",
      "Epoch 113. Loss: 0.0010527118389468955, Train_acc 0.9985650510204082\n",
      "\n",
      "Epoch 113. Loss: 0.0009612164991791457, Train_acc 0.9985747466216216\n",
      "\n",
      "Epoch 113. Loss: 0.0008760854131577158, Train_acc 0.9985843120805369\n",
      "\n",
      "Epoch 113. Loss: 0.0007968008583908746, Train_acc 0.99859375\n",
      "\n",
      "Epoch 113. Loss: 0.0007295037626503456, Train_acc 0.9986030629139073\n",
      "\n",
      "Epoch 113. Loss: 0.0006640283894615626, Train_acc 0.9986122532894737\n",
      "\n",
      "Epoch 113. Loss: 0.0011003063048044374, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 113. Loss: 0.001028242916275258, Train_acc 0.998630275974026\n",
      "\n",
      "Epoch 113. Loss: 0.0009413440689610573, Train_acc 0.9986391129032258\n",
      "\n",
      "Epoch 113. Loss: 0.0008559914023904547, Train_acc 0.9986478365384616\n",
      "\n",
      "Epoch 113. Loss: 0.0007794085167771581, Train_acc 0.998656449044586\n",
      "\n",
      "Epoch 113. Loss: 0.0007036021382061498, Train_acc 0.9986649525316456\n",
      "\n",
      "Epoch 113. Loss: 0.000642688593377121, Train_acc 0.9986733490566038\n",
      "\n",
      "Epoch 113. Loss: 0.0005798858756056065, Train_acc 0.998681640625\n",
      "\n",
      "Epoch 113. Loss: 0.0005371752434350931, Train_acc 0.9986898291925466\n",
      "\n",
      "Epoch 113. Loss: 0.0004999542576836207, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 113. Loss: 0.0004903194215433664, Train_acc 0.9987059049079755\n",
      "\n",
      "Epoch 113. Loss: 0.000443060225534464, Train_acc 0.9987137957317073\n",
      "\n",
      "Epoch 113. Loss: 0.0004062416282997039, Train_acc 0.998721590909091\n",
      "\n",
      "Epoch 113. Loss: 0.0005023645719138241, Train_acc 0.9987292921686747\n",
      "\n",
      "Epoch 113. Loss: 0.0004577247049217166, Train_acc 0.9987369011976048\n",
      "\n",
      "Epoch 113. Loss: 0.00041488866158359935, Train_acc 0.9987444196428571\n",
      "\n",
      "Epoch 113. Loss: 0.0009121301373663577, Train_acc 0.998751849112426\n",
      "\n",
      "Epoch 113. Loss: 0.0010192418933650583, Train_acc 0.9987591911764706\n",
      "\n",
      "Epoch 113. Loss: 0.0009264742522138266, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 113. Loss: 0.000946616021092049, Train_acc 0.9987736191860465\n",
      "\n",
      "Epoch 113. Loss: 0.0008767536473958746, Train_acc 0.9987807080924855\n",
      "\n",
      "Epoch 113. Loss: 0.0011292012915929308, Train_acc 0.9987877155172413\n",
      "\n",
      "Epoch 113. Loss: 0.001025969801399237, Train_acc 0.9987946428571428\n",
      "\n",
      "Epoch 113. Loss: 0.0009772459381083036, Train_acc 0.9988014914772727\n",
      "\n",
      "Epoch 113. Loss: 0.0009132772590712652, Train_acc 0.9988082627118644\n",
      "\n",
      "Epoch 113. Loss: 0.0008337337694311149, Train_acc 0.9988149578651685\n",
      "\n",
      "Epoch 113. Loss: 0.0007895744425360343, Train_acc 0.9988215782122905\n",
      "\n",
      "Epoch 113. Loss: 0.0007348843250900341, Train_acc 0.998828125\n",
      "\n",
      "Epoch 113. Loss: 0.0006909007097930313, Train_acc 0.9988345994475138\n",
      "\n",
      "Epoch 113. Loss: 0.0006775272330292107, Train_acc 0.9988410027472527\n",
      "\n",
      "Epoch 113. Loss: 0.0037141291371567287, Train_acc 0.9988046448087432\n",
      "\n",
      "Epoch 113. Loss: 0.0033490152120329354, Train_acc 0.9988111413043478\n",
      "\n",
      "Epoch 113. Loss: 0.0031188913571041, Train_acc 0.9988175675675676\n",
      "\n",
      "Epoch 113. Loss: 0.002809416443065333, Train_acc 0.9988239247311828\n",
      "\n",
      "Epoch 113. Loss: 0.0025307617366469295, Train_acc 0.9988302139037433\n",
      "\n",
      "Epoch 113. Loss: 0.002297267571808783, Train_acc 0.9988364361702128\n",
      "\n",
      "Epoch 113. Loss: 0.0020684813773048922, Train_acc 0.9988425925925926\n",
      "\n",
      "Epoch 113. Loss: 0.001937115554725424, Train_acc 0.9988486842105263\n",
      "\n",
      "Epoch 113. Loss: 0.0025319147763090987, Train_acc 0.9988138089005235\n",
      "\n",
      "Epoch 113. Loss: 0.006104952945480137, Train_acc 0.998779296875\n",
      "\n",
      "Epoch 113. Loss: 0.005617222811563512, Train_acc 0.9987856217616581\n",
      "\n",
      "Epoch 113. Loss: 0.005099661809627295, Train_acc 0.998791881443299\n",
      "\n",
      "Epoch 113. Loss: 0.004759546491249573, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 113. Loss: 0.004535009146513795, Train_acc 0.9988\n",
      "\n",
      "Epoch 114. Loss: 0.004149178002077121, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.0038967965966517737, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.0035262473504070945, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.003220909302552373, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.003011285782805679, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.002735302337783886, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.002508743614169937, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.002272731756783987, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.0020611042459311585, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.0019130555498248338, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.0021492591872196796, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.0021791082871524753, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.002299736962883317, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.0021030520474276484, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.0019391331446680315, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.001823210598678549, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.001646416926285707, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.0014843380096467814, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.0013523426050968451, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.0012516326004850104, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.001133527200493612, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.001109372784784494, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.0010991057839127405, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.0011300258122092803, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.0010199195590667024, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.0009290711367893975, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.0008642150836184631, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.0010067563198427865, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.0009065946301268066, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.0008212553422284465, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.0007405142806765086, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.0007774461656701547, Train_acc 1.0\n",
      "\n",
      "Epoch 114. Loss: 0.001509235536297439, Train_acc 0.9997632575757576\n",
      "\n",
      "Epoch 114. Loss: 0.0013654552377289323, Train_acc 0.9997702205882353\n",
      "\n",
      "Epoch 114. Loss: 0.0012343157508271753, Train_acc 0.9997767857142857\n",
      "\n",
      "Epoch 114. Loss: 0.0018154083295879799, Train_acc 0.9995659722222222\n",
      "\n",
      "Epoch 114. Loss: 0.0016741994189842899, Train_acc 0.9995777027027027\n",
      "\n",
      "Epoch 114. Loss: 0.0015198995682568649, Train_acc 0.9995888157894737\n",
      "\n",
      "Epoch 114. Loss: 0.0014819354156453577, Train_acc 0.9995993589743589\n",
      "\n",
      "Epoch 114. Loss: 0.0013362712985359553, Train_acc 0.999609375\n",
      "\n",
      "Epoch 114. Loss: 0.001293739780833908, Train_acc 0.9996189024390244\n",
      "\n",
      "Epoch 114. Loss: 0.001193598158632931, Train_acc 0.9996279761904762\n",
      "\n",
      "Epoch 114. Loss: 0.003517962654657856, Train_acc 0.9994549418604651\n",
      "\n",
      "Epoch 114. Loss: 0.003167348072738818, Train_acc 0.9994673295454546\n",
      "\n",
      "Epoch 114. Loss: 0.002858780842935822, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 114. Loss: 0.0025746996113085426, Train_acc 0.9994904891304348\n",
      "\n",
      "Epoch 114. Loss: 0.0023454292362636636, Train_acc 0.999501329787234\n",
      "\n",
      "Epoch 114. Loss: 0.003666768055025307, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 114. Loss: 0.003357041881074221, Train_acc 0.9993622448979592\n",
      "\n",
      "Epoch 114. Loss: 0.003039094754835705, Train_acc 0.999375\n",
      "\n",
      "Epoch 114. Loss: 0.002871143567217058, Train_acc 0.9993872549019608\n",
      "\n",
      "Epoch 114. Loss: 0.0026140621341732887, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 114. Loss: 0.011745949331295587, Train_acc 0.9991155660377359\n",
      "\n",
      "Epoch 114. Loss: 0.010924136339348939, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 114. Loss: 0.010096847052474964, Train_acc 0.9991477272727273\n",
      "\n",
      "Epoch 114. Loss: 0.009259798190273477, Train_acc 0.9991629464285714\n",
      "\n",
      "Epoch 114. Loss: 0.009157258494595557, Train_acc 0.9991776315789473\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114. Loss: 0.011156240939110402, Train_acc 0.9990571120689655\n",
      "\n",
      "Epoch 114. Loss: 0.025533196186134116, Train_acc 0.9985434322033898\n",
      "\n",
      "Epoch 114. Loss: 0.023079265426755455, Train_acc 0.9985677083333333\n",
      "\n",
      "Epoch 114. Loss: 0.02223944310128138, Train_acc 0.9984631147540983\n",
      "\n",
      "Epoch 114. Loss: 0.025077220592911058, Train_acc 0.9983618951612904\n",
      "\n",
      "Epoch 114. Loss: 0.03089669730724247, Train_acc 0.9978918650793651\n",
      "\n",
      "Epoch 114. Loss: 0.03683788376863019, Train_acc 0.9974365234375\n",
      "\n",
      "Epoch 114. Loss: 0.03399122176601186, Train_acc 0.9973557692307692\n",
      "\n",
      "Epoch 114. Loss: 0.032630824496153246, Train_acc 0.9972774621212122\n",
      "\n",
      "Epoch 114. Loss: 0.029871948214071915, Train_acc 0.9973180970149254\n",
      "\n",
      "Epoch 114. Loss: 0.02837023757922464, Train_acc 0.9972426470588235\n",
      "\n",
      "Epoch 114. Loss: 0.027595520560692074, Train_acc 0.9971693840579711\n",
      "\n",
      "Epoch 114. Loss: 0.029310120384171894, Train_acc 0.9969866071428571\n",
      "\n",
      "Epoch 114. Loss: 0.029139807364590726, Train_acc 0.996919014084507\n",
      "\n",
      "Epoch 114. Loss: 0.02650857218038091, Train_acc 0.9969618055555556\n",
      "\n",
      "Epoch 114. Loss: 0.025835203919688306, Train_acc 0.9967893835616438\n",
      "\n",
      "Epoch 114. Loss: 0.0243164415304775, Train_acc 0.9967271959459459\n",
      "\n",
      "Epoch 114. Loss: 0.023749573765240457, Train_acc 0.9966666666666667\n",
      "\n",
      "Epoch 114. Loss: 0.024999248598255825, Train_acc 0.9965049342105263\n",
      "\n",
      "Epoch 114. Loss: 0.02370512626102994, Train_acc 0.9965503246753247\n",
      "\n",
      "Epoch 114. Loss: 0.022300289998484525, Train_acc 0.9964943910256411\n",
      "\n",
      "Epoch 114. Loss: 0.02062272946613986, Train_acc 0.9965387658227848\n",
      "\n",
      "Epoch 114. Loss: 0.01975537318507992, Train_acc 0.99658203125\n",
      "\n",
      "Epoch 114. Loss: 0.01824230402130034, Train_acc 0.9966242283950617\n",
      "\n",
      "Epoch 114. Loss: 0.01706405744367671, Train_acc 0.9966653963414634\n",
      "\n",
      "Epoch 114. Loss: 0.018934955585722613, Train_acc 0.9965173192771084\n",
      "\n",
      "Epoch 114. Loss: 0.018661643912247856, Train_acc 0.9963727678571429\n",
      "\n",
      "Epoch 114. Loss: 0.01756773052351359, Train_acc 0.9964154411764706\n",
      "\n",
      "Epoch 114. Loss: 0.018320691691965017, Train_acc 0.9963662790697675\n",
      "\n",
      "Epoch 114. Loss: 0.01764710882943584, Train_acc 0.9963182471264368\n",
      "\n",
      "Epoch 114. Loss: 0.016047394825667565, Train_acc 0.9963600852272727\n",
      "\n",
      "Epoch 114. Loss: 0.01450321518723332, Train_acc 0.9964009831460674\n",
      "\n",
      "Epoch 114. Loss: 0.014901479385890036, Train_acc 0.9963541666666667\n",
      "\n",
      "Epoch 114. Loss: 0.014069740837899566, Train_acc 0.9963942307692307\n",
      "\n",
      "Epoch 114. Loss: 0.01706970135815834, Train_acc 0.9962635869565217\n",
      "\n",
      "Epoch 114. Loss: 0.016767672676872267, Train_acc 0.9962197580645161\n",
      "\n",
      "Epoch 114. Loss: 0.015165339171532368, Train_acc 0.9962599734042553\n",
      "\n",
      "Epoch 114. Loss: 0.01391378873890064, Train_acc 0.9962993421052632\n",
      "\n",
      "Epoch 114. Loss: 0.012807110146928626, Train_acc 0.996337890625\n",
      "\n",
      "Epoch 114. Loss: 0.012100064222141025, Train_acc 0.9963756443298969\n",
      "\n",
      "Epoch 114. Loss: 0.0117165346867954, Train_acc 0.9964126275510204\n",
      "\n",
      "Epoch 114. Loss: 0.010901071730072672, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 114. Loss: 0.011833467873467842, Train_acc 0.99640625\n",
      "\n",
      "[Epoch 114 Batch 100] Loss: 0.011169978921145653 Training: accuracy=0.996442\n",
      "Epoch 114. Loss: 0.011169978921145653, Train_acc 0.9964418316831684\n",
      "\n",
      "Epoch 114. Loss: 0.010414290788349918, Train_acc 0.9964767156862745\n",
      "\n",
      "Epoch 114. Loss: 0.011426689501921009, Train_acc 0.9963592233009708\n",
      "\n",
      "Epoch 114. Loss: 0.010548155578101877, Train_acc 0.9963942307692307\n",
      "\n",
      "Epoch 114. Loss: 0.009521612182599675, Train_acc 0.9964285714285714\n",
      "\n",
      "Epoch 114. Loss: 0.009053581868418191, Train_acc 0.9964622641509434\n",
      "\n",
      "Epoch 114. Loss: 0.008364804422683838, Train_acc 0.9964953271028038\n",
      "\n",
      "Epoch 114. Loss: 0.00911973986997663, Train_acc 0.9964554398148148\n",
      "\n",
      "Epoch 114. Loss: 0.008930356670315198, Train_acc 0.9964162844036697\n",
      "\n",
      "Epoch 114. Loss: 0.012132092299069582, Train_acc 0.9963068181818182\n",
      "\n",
      "Epoch 114. Loss: 0.010979965001088934, Train_acc 0.9963400900900901\n",
      "\n",
      "Epoch 114. Loss: 0.010131366162516971, Train_acc 0.9963727678571429\n",
      "\n",
      "Epoch 114. Loss: 0.011349984653906495, Train_acc 0.9963357300884956\n",
      "\n",
      "Epoch 114. Loss: 0.010264827912619163, Train_acc 0.9963678728070176\n",
      "\n",
      "Epoch 114. Loss: 0.00946178519292514, Train_acc 0.9963994565217391\n",
      "\n",
      "Epoch 114. Loss: 0.009567091746454004, Train_acc 0.9964304956896551\n",
      "\n",
      "Epoch 114. Loss: 0.008977791329837946, Train_acc 0.9964610042735043\n",
      "\n",
      "Epoch 114. Loss: 0.008212222481791326, Train_acc 0.9964909957627118\n",
      "\n",
      "Epoch 114. Loss: 0.010416880689582957, Train_acc 0.9964548319327731\n",
      "\n",
      "Epoch 114. Loss: 0.009632252203133762, Train_acc 0.996484375\n",
      "\n",
      "Epoch 114. Loss: 0.009327751626110428, Train_acc 0.9965134297520661\n",
      "\n",
      "Epoch 114. Loss: 0.008524563410649914, Train_acc 0.9965420081967213\n",
      "\n",
      "Epoch 114. Loss: 0.007858297963458495, Train_acc 0.9965701219512195\n",
      "\n",
      "Epoch 114. Loss: 0.007258965244924156, Train_acc 0.9965977822580645\n",
      "\n",
      "Epoch 114. Loss: 0.006555184240982609, Train_acc 0.996625\n",
      "\n",
      "Epoch 114. Loss: 0.00636114490703852, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 114. Loss: 0.00574564603314797, Train_acc 0.9966781496062992\n",
      "\n",
      "Epoch 114. Loss: 0.005209773124332166, Train_acc 0.9967041015625\n",
      "\n",
      "Epoch 114. Loss: 0.00473039465309767, Train_acc 0.9967296511627907\n",
      "\n",
      "Epoch 114. Loss: 0.006229387526168717, Train_acc 0.9966947115384616\n",
      "\n",
      "Epoch 114. Loss: 0.005648499373138064, Train_acc 0.9967199427480916\n",
      "\n",
      "Epoch 114. Loss: 0.005598574800229175, Train_acc 0.9967447916666666\n",
      "\n",
      "Epoch 114. Loss: 0.005115255580533909, Train_acc 0.9967692669172933\n",
      "\n",
      "Epoch 114. Loss: 0.006008575550785096, Train_acc 0.9967350746268657\n",
      "\n",
      "Epoch 114. Loss: 0.005411334010944226, Train_acc 0.9967592592592592\n",
      "\n",
      "Epoch 114. Loss: 0.004962792956331783, Train_acc 0.9967830882352942\n",
      "\n",
      "Epoch 114. Loss: 0.008414703723936748, Train_acc 0.9966925182481752\n",
      "\n",
      "Epoch 114. Loss: 0.007838586431428318, Train_acc 0.9967164855072463\n",
      "\n",
      "Epoch 114. Loss: 0.007236601454873703, Train_acc 0.9967401079136691\n",
      "\n",
      "Epoch 114. Loss: 0.006873419514061352, Train_acc 0.9967633928571429\n",
      "\n",
      "Epoch 114. Loss: 0.006206714436906284, Train_acc 0.9967863475177305\n",
      "\n",
      "Epoch 114. Loss: 0.005618218674769437, Train_acc 0.9968089788732394\n",
      "\n",
      "Epoch 114. Loss: 0.005073575679368823, Train_acc 0.9968312937062938\n",
      "\n",
      "Epoch 114. Loss: 0.0046170017926495215, Train_acc 0.9968532986111112\n",
      "\n",
      "Epoch 114. Loss: 0.004258383201552267, Train_acc 0.996875\n",
      "\n",
      "Epoch 114. Loss: 0.003902922361402886, Train_acc 0.996896404109589\n",
      "\n",
      "Epoch 114. Loss: 0.003685522093658158, Train_acc 0.9969175170068028\n",
      "\n",
      "Epoch 114. Loss: 0.0037197138589929128, Train_acc 0.9969383445945946\n",
      "\n",
      "Epoch 114. Loss: 0.004053815928606146, Train_acc 0.9969588926174496\n",
      "\n",
      "Epoch 114. Loss: 0.003684011798149566, Train_acc 0.9969791666666666\n",
      "\n",
      "Epoch 114. Loss: 0.0034020504034165027, Train_acc 0.9969991721854304\n",
      "\n",
      "Epoch 114. Loss: 0.0030882503487672046, Train_acc 0.9970189144736842\n",
      "\n",
      "Epoch 114. Loss: 0.004858463635862377, Train_acc 0.9969873366013072\n",
      "\n",
      "Epoch 114. Loss: 0.004386722717283002, Train_acc 0.9970068993506493\n",
      "\n",
      "Epoch 114. Loss: 0.004000749537166132, Train_acc 0.9970262096774194\n",
      "\n",
      "Epoch 114. Loss: 0.00489524323014871, Train_acc 0.9970452724358975\n",
      "\n",
      "Epoch 114. Loss: 0.004704404650607309, Train_acc 0.9970640923566879\n",
      "\n",
      "Epoch 114. Loss: 0.004272388773820789, Train_acc 0.9970826740506329\n",
      "\n",
      "Epoch 114. Loss: 0.00412643958195626, Train_acc 0.9971010220125787\n",
      "\n",
      "Epoch 114. Loss: 0.0037256158782005876, Train_acc 0.997119140625\n",
      "\n",
      "Epoch 114. Loss: 0.0033566199530810953, Train_acc 0.9971370341614907\n",
      "\n",
      "Epoch 114. Loss: 0.0030577911631497375, Train_acc 0.9971547067901234\n",
      "\n",
      "Epoch 114. Loss: 0.002800939974690166, Train_acc 0.9971721625766872\n",
      "\n",
      "Epoch 114. Loss: 0.002573151858620811, Train_acc 0.9971894054878049\n",
      "\n",
      "Epoch 114. Loss: 0.00231837399581155, Train_acc 0.9972064393939394\n",
      "\n",
      "Epoch 114. Loss: 0.0021267724264684837, Train_acc 0.9972232680722891\n",
      "\n",
      "Epoch 114. Loss: 0.0019437476971524378, Train_acc 0.9972398952095808\n",
      "\n",
      "Epoch 114. Loss: 0.0018537129070261794, Train_acc 0.9972563244047619\n",
      "\n",
      "Epoch 114. Loss: 0.0019908677275910685, Train_acc 0.9972725591715976\n",
      "\n",
      "Epoch 114. Loss: 0.0017946771221116484, Train_acc 0.9972886029411765\n",
      "\n",
      "Epoch 114. Loss: 0.001626486033891336, Train_acc 0.9973044590643275\n",
      "\n",
      "Epoch 114. Loss: 0.0014688129696977866, Train_acc 0.9973201308139535\n",
      "\n",
      "Epoch 114. Loss: 0.0013274347363129188, Train_acc 0.9973356213872833\n",
      "\n",
      "Epoch 114. Loss: 0.001209920338188422, Train_acc 0.997350933908046\n",
      "\n",
      "Epoch 114. Loss: 0.001114091869084183, Train_acc 0.9973660714285715\n",
      "\n",
      "Epoch 114. Loss: 0.0010091365882743783, Train_acc 0.9973810369318182\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114. Loss: 0.0009610343618439335, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 114. Loss: 0.001068772943459156, Train_acc 0.9974104634831461\n",
      "\n",
      "Epoch 114. Loss: 0.000984781379254083, Train_acc 0.9974249301675978\n",
      "\n",
      "Epoch 114. Loss: 0.0010680803530489684, Train_acc 0.9974392361111111\n",
      "\n",
      "Epoch 114. Loss: 0.000979113070587839, Train_acc 0.9974533839779005\n",
      "\n",
      "Epoch 114. Loss: 0.0009046283679862546, Train_acc 0.9974673763736264\n",
      "\n",
      "Epoch 114. Loss: 0.000865074795433631, Train_acc 0.9974812158469946\n",
      "\n",
      "Epoch 114. Loss: 0.0007791660293857601, Train_acc 0.9974949048913043\n",
      "\n",
      "Epoch 114. Loss: 0.0007062919506551496, Train_acc 0.9975084459459459\n",
      "\n",
      "Epoch 114. Loss: 0.0006371525610256293, Train_acc 0.9975218413978495\n",
      "\n",
      "Epoch 114. Loss: 0.0005956239392284653, Train_acc 0.9975350935828877\n",
      "\n",
      "Epoch 114. Loss: 0.0005519479846653656, Train_acc 0.997548204787234\n",
      "\n",
      "Epoch 114. Loss: 0.000512351224061048, Train_acc 0.9975611772486772\n",
      "\n",
      "Epoch 114. Loss: 0.0005515423140644545, Train_acc 0.9975740131578947\n",
      "\n",
      "Epoch 114. Loss: 0.0005095963613456799, Train_acc 0.9975867146596858\n",
      "\n",
      "Epoch 114. Loss: 0.0004619218884679173, Train_acc 0.9975992838541666\n",
      "\n",
      "Epoch 114. Loss: 0.0004313885790409143, Train_acc 0.9976117227979274\n",
      "\n",
      "Epoch 114. Loss: 0.0003917513004769045, Train_acc 0.9976240335051546\n",
      "\n",
      "Epoch 114. Loss: 0.000363830847221519, Train_acc 0.9976362179487179\n",
      "\n",
      "Epoch 114. Loss: 0.00035081938108968476, Train_acc 0.99764\n",
      "\n",
      "Epoch 115. Loss: 0.000323270770860799, Train_acc 1.0\n",
      "\n",
      "Epoch 115. Loss: 0.00029162571512042945, Train_acc 1.0\n",
      "\n",
      "Epoch 115. Loss: 0.0002636722162242796, Train_acc 1.0\n",
      "\n",
      "Epoch 115. Loss: 0.0002378613797591759, Train_acc 1.0\n",
      "\n",
      "Epoch 115. Loss: 0.00026394194861463906, Train_acc 1.0\n",
      "\n",
      "Epoch 115. Loss: 0.00031318838792111455, Train_acc 1.0\n",
      "\n",
      "Epoch 115. Loss: 0.008934155035588736, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 115. Loss: 0.008134782524016362, Train_acc 0.998046875\n",
      "\n",
      "Epoch 115. Loss: 0.0073284980298253585, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 115. Loss: 0.0067838433967461614, Train_acc 0.9984375\n",
      "\n",
      "Epoch 115. Loss: 0.006183623150500768, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 115. Loss: 0.0055971872543381426, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 115. Loss: 0.005826242683984646, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 115. Loss: 0.008248021082870195, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 115. Loss: 0.008952554577701118, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 115. Loss: 0.008626885762017512, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 115. Loss: 0.007839636887138228, Train_acc 0.9972426470588235\n",
      "\n",
      "Epoch 115. Loss: 0.007062329646082721, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 115. Loss: 0.009029239829896691, Train_acc 0.9967105263157895\n",
      "\n",
      "Epoch 115. Loss: 0.010129142179952982, Train_acc 0.996484375\n",
      "\n",
      "Epoch 115. Loss: 0.009778267834216587, Train_acc 0.9962797619047619\n",
      "\n",
      "Epoch 115. Loss: 0.009296784015265314, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 115. Loss: 0.008374301880699602, Train_acc 0.9966032608695652\n",
      "\n",
      "Epoch 115. Loss: 0.00757997448881913, Train_acc 0.9967447916666666\n",
      "\n",
      "Epoch 115. Loss: 0.006873241469867814, Train_acc 0.996875\n",
      "\n",
      "Epoch 115. Loss: 0.00619884817512564, Train_acc 0.9969951923076923\n",
      "\n",
      "Epoch 115. Loss: 0.005726960747626264, Train_acc 0.9971064814814815\n",
      "\n",
      "Epoch 115. Loss: 0.005335211557074791, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 115. Loss: 0.0049033896972867, Train_acc 0.9973060344827587\n",
      "\n",
      "Epoch 115. Loss: 0.004441146925196691, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 115. Loss: 0.0040896234790342096, Train_acc 0.9974798387096774\n",
      "\n",
      "Epoch 115. Loss: 0.00379826363312665, Train_acc 0.99755859375\n",
      "\n",
      "Epoch 115. Loss: 0.004045162135101528, Train_acc 0.9976325757575758\n",
      "\n",
      "Epoch 115. Loss: 0.0036918769403246083, Train_acc 0.9977022058823529\n",
      "\n",
      "Epoch 115. Loss: 0.005042408790345225, Train_acc 0.9975446428571428\n",
      "\n",
      "Epoch 115. Loss: 0.004575364044363633, Train_acc 0.9976128472222222\n",
      "\n",
      "Epoch 115. Loss: 0.004136157686368675, Train_acc 0.9976773648648649\n",
      "\n",
      "Epoch 115. Loss: 0.0038664617213996213, Train_acc 0.9977384868421053\n",
      "\n",
      "Epoch 115. Loss: 0.0035231085797265437, Train_acc 0.9977964743589743\n",
      "\n",
      "Epoch 115. Loss: 0.0031846783527671968, Train_acc 0.9978515625\n",
      "\n",
      "Epoch 115. Loss: 0.002905944661719919, Train_acc 0.9979039634146342\n",
      "\n",
      "Epoch 115. Loss: 0.0028339384024649744, Train_acc 0.9979538690476191\n",
      "\n",
      "Epoch 115. Loss: 0.003284883285341551, Train_acc 0.9980014534883721\n",
      "\n",
      "Epoch 115. Loss: 0.002971564292336604, Train_acc 0.998046875\n",
      "\n",
      "Epoch 115. Loss: 0.0026893689258006377, Train_acc 0.9980902777777778\n",
      "\n",
      "Epoch 115. Loss: 0.002428448440302897, Train_acc 0.9981317934782609\n",
      "\n",
      "Epoch 115. Loss: 0.002251853809694489, Train_acc 0.9981715425531915\n",
      "\n",
      "Epoch 115. Loss: 0.0020382457047432552, Train_acc 0.9982096354166666\n",
      "\n",
      "Epoch 115. Loss: 0.0018463593698167888, Train_acc 0.9982461734693877\n",
      "\n",
      "Epoch 115. Loss: 0.0017014557115090196, Train_acc 0.99828125\n",
      "\n",
      "Epoch 115. Loss: 0.00161778352290189, Train_acc 0.9983149509803921\n",
      "\n",
      "Epoch 115. Loss: 0.0014737435201728148, Train_acc 0.9983473557692307\n",
      "\n",
      "Epoch 115. Loss: 0.0017706959973207536, Train_acc 0.9983785377358491\n",
      "\n",
      "Epoch 115. Loss: 0.0016792735398480823, Train_acc 0.9984085648148148\n",
      "\n",
      "Epoch 115. Loss: 0.001532496480787429, Train_acc 0.9984375\n",
      "\n",
      "Epoch 115. Loss: 0.001382902373494671, Train_acc 0.9984654017857143\n",
      "\n",
      "Epoch 115. Loss: 0.0012488982161474066, Train_acc 0.9984923245614035\n",
      "\n",
      "Epoch 115. Loss: 0.0011745198501616869, Train_acc 0.9985183189655172\n",
      "\n",
      "Epoch 115. Loss: 0.0010599330044677572, Train_acc 0.9985434322033898\n",
      "\n",
      "Epoch 115. Loss: 0.0010829294172874733, Train_acc 0.9985677083333333\n",
      "\n",
      "Epoch 115. Loss: 0.0009825900692989656, Train_acc 0.9985911885245902\n",
      "\n",
      "Epoch 115. Loss: 0.001012418789722046, Train_acc 0.9986139112903226\n",
      "\n",
      "Epoch 115. Loss: 0.000983423549342174, Train_acc 0.9986359126984127\n",
      "\n",
      "Epoch 115. Loss: 0.0011180397552174497, Train_acc 0.9986572265625\n",
      "\n",
      "Epoch 115. Loss: 0.0010125315392175952, Train_acc 0.9986778846153846\n",
      "\n",
      "Epoch 115. Loss: 0.000940829006116209, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 115. Loss: 0.0008570098579878853, Train_acc 0.9987173507462687\n",
      "\n",
      "Epoch 115. Loss: 0.0008505412100737017, Train_acc 0.9987362132352942\n",
      "\n",
      "Epoch 115. Loss: 0.0007664374201711636, Train_acc 0.9987545289855072\n",
      "\n",
      "Epoch 115. Loss: 0.0007452593449640979, Train_acc 0.9987723214285714\n",
      "\n",
      "Epoch 115. Loss: 0.0007056505651663208, Train_acc 0.9987896126760564\n",
      "\n",
      "Epoch 115. Loss: 0.0007288319733491955, Train_acc 0.9988064236111112\n",
      "\n",
      "Epoch 115. Loss: 0.0007069088089821265, Train_acc 0.9988227739726028\n",
      "\n",
      "Epoch 115. Loss: 0.0007274577089700126, Train_acc 0.9988386824324325\n",
      "\n",
      "Epoch 115. Loss: 0.0006799630820342249, Train_acc 0.9988541666666667\n",
      "\n",
      "Epoch 115. Loss: 0.0006302763922936108, Train_acc 0.9988692434210527\n",
      "\n",
      "Epoch 115. Loss: 0.0005769640031172271, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 115. Loss: 0.0005289979373738075, Train_acc 0.9988982371794872\n",
      "\n",
      "Epoch 115. Loss: 0.0005020296158280139, Train_acc 0.9989121835443038\n",
      "\n",
      "Epoch 115. Loss: 0.0004541301591250317, Train_acc 0.99892578125\n",
      "\n",
      "Epoch 115. Loss: 0.0004401929911487639, Train_acc 0.9989390432098766\n",
      "\n",
      "Epoch 115. Loss: 0.00041929362069841535, Train_acc 0.998951981707317\n",
      "\n",
      "Epoch 115. Loss: 0.00038080546898453275, Train_acc 0.9989646084337349\n",
      "\n",
      "Epoch 115. Loss: 0.0003558649712088191, Train_acc 0.9989769345238095\n",
      "\n",
      "Epoch 115. Loss: 0.000322362150824157, Train_acc 0.9989889705882353\n",
      "\n",
      "Epoch 115. Loss: 0.0003071326091844068, Train_acc 0.999000726744186\n",
      "\n",
      "Epoch 115. Loss: 0.00028507798739219053, Train_acc 0.9990122126436781\n",
      "\n",
      "Epoch 115. Loss: 0.000672778386947015, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 115. Loss: 0.0006178405971042245, Train_acc 0.9990344101123596\n",
      "\n",
      "Epoch 115. Loss: 0.0005934247701273721, Train_acc 0.9990451388888889\n",
      "\n",
      "Epoch 115. Loss: 0.0005350867332425068, Train_acc 0.9990556318681318\n",
      "\n",
      "Epoch 115. Loss: 0.0004823143675929986, Train_acc 0.9990658967391305\n",
      "\n",
      "Epoch 115. Loss: 0.00043687046733861, Train_acc 0.999075940860215\n",
      "\n",
      "Epoch 115. Loss: 0.00042452245434439033, Train_acc 0.9990857712765957\n",
      "\n",
      "Epoch 115. Loss: 0.0004870746871559249, Train_acc 0.9990953947368421\n",
      "\n",
      "Epoch 115. Loss: 0.00044048301088966333, Train_acc 0.9991048177083334\n",
      "\n",
      "Epoch 115. Loss: 0.0004744450942597455, Train_acc 0.9991140463917526\n",
      "\n",
      "Epoch 115. Loss: 0.00043218161962784823, Train_acc 0.9991230867346939\n",
      "\n",
      "Epoch 115. Loss: 0.0003913954941551266, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 115. Loss: 0.0003724980051578547, Train_acc 0.999140625\n",
      "\n",
      "[Epoch 115 Batch 100] Loss: 0.0017110467131669642 Training: accuracy=0.999072\n",
      "Epoch 115. Loss: 0.0017110467131669642, Train_acc 0.9990717821782178\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115. Loss: 0.007665375784850299, Train_acc 0.9990042892156863\n",
      "\n",
      "Epoch 115. Loss: 0.006911419333886385, Train_acc 0.9990139563106796\n",
      "\n",
      "Epoch 115. Loss: 0.006237688350883712, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 115. Loss: 0.00561739415008159, Train_acc 0.9990327380952381\n",
      "\n",
      "Epoch 115. Loss: 0.005976004653379305, Train_acc 0.9989681603773585\n",
      "\n",
      "Epoch 115. Loss: 0.005462255973207563, Train_acc 0.9989778037383178\n",
      "\n",
      "Epoch 115. Loss: 0.010135599433112989, Train_acc 0.9989149305555556\n",
      "\n",
      "Epoch 115. Loss: 0.018683135621603297, Train_acc 0.9987815366972477\n",
      "\n",
      "Epoch 115. Loss: 0.016832216478853235, Train_acc 0.9987926136363636\n",
      "\n",
      "Epoch 115. Loss: 0.015160239647382457, Train_acc 0.998803490990991\n",
      "\n",
      "Epoch 115. Loss: 0.014590910481411779, Train_acc 0.9987444196428571\n",
      "\n",
      "Epoch 115. Loss: 0.013183468103612421, Train_acc 0.9987555309734514\n",
      "\n",
      "Epoch 115. Loss: 0.012596058686633372, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 115. Loss: 0.01136105723698352, Train_acc 0.9987092391304347\n",
      "\n",
      "Epoch 115. Loss: 0.010307115340313295, Train_acc 0.9987203663793104\n",
      "\n",
      "Epoch 115. Loss: 0.009308007003849131, Train_acc 0.9987313034188035\n",
      "\n",
      "Epoch 115. Loss: 0.00854724876238589, Train_acc 0.9987420550847458\n",
      "\n",
      "Epoch 115. Loss: 0.007793034267309467, Train_acc 0.9987526260504201\n",
      "\n",
      "Epoch 115. Loss: 0.007419956750988805, Train_acc 0.9987630208333333\n",
      "\n",
      "Epoch 115. Loss: 0.006930987589272718, Train_acc 0.9987732438016529\n",
      "\n",
      "Epoch 115. Loss: 0.006321493448321099, Train_acc 0.9987832991803278\n",
      "\n",
      "Epoch 115. Loss: 0.006035141241777606, Train_acc 0.9987931910569106\n",
      "\n",
      "Epoch 115. Loss: 0.005633959554638267, Train_acc 0.9988029233870968\n",
      "\n",
      "Epoch 115. Loss: 0.0052895626590452795, Train_acc 0.9988125\n",
      "\n",
      "Epoch 115. Loss: 0.005736986726445157, Train_acc 0.9987599206349206\n",
      "\n",
      "Epoch 115. Loss: 0.0051815023397564055, Train_acc 0.99876968503937\n",
      "\n",
      "Epoch 115. Loss: 0.004728909322074875, Train_acc 0.998779296875\n",
      "\n",
      "Epoch 115. Loss: 0.0043404404704121425, Train_acc 0.9987887596899225\n",
      "\n",
      "Epoch 115. Loss: 0.0041694694626120635, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 115. Loss: 0.004252094841848723, Train_acc 0.9988072519083969\n",
      "\n",
      "Epoch 115. Loss: 0.003999997385942262, Train_acc 0.9988162878787878\n",
      "\n",
      "Epoch 115. Loss: 0.004053120864796628, Train_acc 0.9988251879699248\n",
      "\n",
      "Epoch 115. Loss: 0.006096956181557169, Train_acc 0.9987756529850746\n",
      "\n",
      "Epoch 115. Loss: 0.005497535833725652, Train_acc 0.9987847222222223\n",
      "\n",
      "Epoch 115. Loss: 0.005818832049378147, Train_acc 0.9987362132352942\n",
      "\n",
      "Epoch 115. Loss: 0.005321300802215985, Train_acc 0.9987454379562044\n",
      "\n",
      "Epoch 115. Loss: 0.0048312101893654555, Train_acc 0.9987545289855072\n",
      "\n",
      "Epoch 115. Loss: 0.004797128817784586, Train_acc 0.9987634892086331\n",
      "\n",
      "Epoch 115. Loss: 0.004388214269041909, Train_acc 0.9987723214285714\n",
      "\n",
      "Epoch 115. Loss: 0.003976511805909218, Train_acc 0.9987810283687943\n",
      "\n",
      "Epoch 115. Loss: 0.0037203739729440286, Train_acc 0.9987896126760564\n",
      "\n",
      "Epoch 115. Loss: 0.0034698671285099754, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 115. Loss: 0.0031391384556363794, Train_acc 0.9988064236111112\n",
      "\n",
      "Epoch 115. Loss: 0.002949650959138939, Train_acc 0.9988146551724137\n",
      "\n",
      "Epoch 115. Loss: 0.0028029687618150137, Train_acc 0.9988227739726028\n",
      "\n",
      "Epoch 115. Loss: 0.002700017031127258, Train_acc 0.9988307823129252\n",
      "\n",
      "Epoch 115. Loss: 0.004431368495011965, Train_acc 0.9987858952702703\n",
      "\n",
      "Epoch 115. Loss: 0.003990112929480621, Train_acc 0.998794043624161\n",
      "\n",
      "Epoch 115. Loss: 0.00361103004788035, Train_acc 0.9988020833333333\n",
      "\n",
      "Epoch 115. Loss: 0.0032616078232455712, Train_acc 0.9988100165562914\n",
      "\n",
      "Epoch 115. Loss: 0.004829298946982186, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 115. Loss: 0.004361571801920924, Train_acc 0.9987745098039216\n",
      "\n",
      "Epoch 115. Loss: 0.00395416449139955, Train_acc 0.9987824675324676\n",
      "\n",
      "Epoch 115. Loss: 0.00356989862774708, Train_acc 0.9987903225806452\n",
      "\n",
      "Epoch 115. Loss: 0.0032460189821636514, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 115. Loss: 0.0029428733692689057, Train_acc 0.9988057324840764\n",
      "\n",
      "Epoch 115. Loss: 0.0033947245193532097, Train_acc 0.9988132911392406\n",
      "\n",
      "Epoch 115. Loss: 0.003517254933388024, Train_acc 0.9988207547169812\n",
      "\n",
      "Epoch 115. Loss: 0.0032349898059704806, Train_acc 0.998828125\n",
      "\n",
      "Epoch 115. Loss: 0.004607360874671242, Train_acc 0.9987868788819876\n",
      "\n",
      "Epoch 115. Loss: 0.005226253683172317, Train_acc 0.9987461419753086\n",
      "\n",
      "Epoch 115. Loss: 0.0061255711561167105, Train_acc 0.9987059049079755\n",
      "\n",
      "Epoch 115. Loss: 0.006154552615796673, Train_acc 0.9987137957317073\n",
      "\n",
      "Epoch 115. Loss: 0.00837121316830678, Train_acc 0.9986742424242424\n",
      "\n",
      "Epoch 115. Loss: 0.007892330225359172, Train_acc 0.9986822289156626\n",
      "\n",
      "Epoch 115. Loss: 0.007129206691504213, Train_acc 0.9986901197604791\n",
      "\n",
      "Epoch 115. Loss: 0.006419627763093207, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 115. Loss: 0.005834011219088236, Train_acc 0.9987056213017751\n",
      "\n",
      "Epoch 115. Loss: 0.006082565582225323, Train_acc 0.9986672794117647\n",
      "\n",
      "Epoch 115. Loss: 0.007159389328744651, Train_acc 0.9986293859649122\n",
      "\n",
      "Epoch 115. Loss: 0.006509032571609295, Train_acc 0.9986373546511628\n",
      "\n",
      "Epoch 115. Loss: 0.007901309482123385, Train_acc 0.9986000722543352\n",
      "\n",
      "Epoch 115. Loss: 0.009158212514399824, Train_acc 0.9985632183908046\n",
      "\n",
      "Epoch 115. Loss: 0.009162820157420043, Train_acc 0.9985714285714286\n",
      "\n",
      "Epoch 115. Loss: 0.008625630527670446, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 115. Loss: 0.008155916706042227, Train_acc 0.998587570621469\n",
      "\n",
      "Epoch 115. Loss: 0.007472422176323894, Train_acc 0.9985955056179775\n",
      "\n",
      "Epoch 115. Loss: 0.0069769471609719665, Train_acc 0.9986033519553073\n",
      "\n",
      "Epoch 115. Loss: 0.006359223205145723, Train_acc 0.9986111111111111\n",
      "\n",
      "Epoch 115. Loss: 0.005927259946395332, Train_acc 0.9986187845303868\n",
      "\n",
      "Epoch 115. Loss: 0.009005484185692109, Train_acc 0.9985834478021978\n",
      "\n",
      "Epoch 115. Loss: 0.01139356690830866, Train_acc 0.9985484972677595\n",
      "\n",
      "Epoch 115. Loss: 0.010711812863679643, Train_acc 0.9985563858695652\n",
      "\n",
      "Epoch 115. Loss: 0.009699125724690632, Train_acc 0.9985641891891892\n",
      "\n",
      "Epoch 115. Loss: 0.008814109456400552, Train_acc 0.9985719086021505\n",
      "\n",
      "Epoch 115. Loss: 0.007989172817381153, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 115. Loss: 0.0074604405498760315, Train_acc 0.9985871010638298\n",
      "\n",
      "Epoch 115. Loss: 0.0067653569120268405, Train_acc 0.9985945767195767\n",
      "\n",
      "Epoch 115. Loss: 0.00649229847235385, Train_acc 0.9986019736842106\n",
      "\n",
      "Epoch 115. Loss: 0.006063626998375983, Train_acc 0.9986092931937173\n",
      "\n",
      "Epoch 115. Loss: 0.005629895135725556, Train_acc 0.9986165364583334\n",
      "\n",
      "Epoch 115. Loss: 0.005429917746005968, Train_acc 0.9986237046632125\n",
      "\n",
      "Epoch 115. Loss: 0.005869048374043569, Train_acc 0.9985905283505154\n",
      "\n",
      "Epoch 115. Loss: 0.010923569682669637, Train_acc 0.998477564102564\n",
      "\n",
      "Epoch 115. Loss: 0.011226027153520581, Train_acc 0.99848\n",
      "\n",
      "Epoch 116. Loss: 0.010184522448000726, Train_acc 1.0\n",
      "\n",
      "Epoch 116. Loss: 0.009291254835107104, Train_acc 1.0\n",
      "\n",
      "Epoch 116. Loss: 0.00845129076392115, Train_acc 1.0\n",
      "\n",
      "Epoch 116. Loss: 0.007773557153070667, Train_acc 1.0\n",
      "\n",
      "Epoch 116. Loss: 0.007838830158911375, Train_acc 0.9984375\n",
      "\n",
      "Epoch 116. Loss: 0.007628663828196133, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 116. Loss: 0.008629777722259169, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 116. Loss: 0.011918875896364277, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 116. Loss: 0.01113333622039541, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 116. Loss: 0.01056977279153035, Train_acc 0.99765625\n",
      "\n",
      "Epoch 116. Loss: 0.014581834529339366, Train_acc 0.9957386363636364\n",
      "\n",
      "Epoch 116. Loss: 0.01381384217582562, Train_acc 0.99609375\n",
      "\n",
      "Epoch 116. Loss: 0.01287432069414036, Train_acc 0.9963942307692307\n",
      "\n",
      "Epoch 116. Loss: 0.011783244578538923, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 116. Loss: 0.010816672699301174, Train_acc 0.996875\n",
      "\n",
      "Epoch 116. Loss: 0.009974465646206196, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 116. Loss: 0.009831021020882298, Train_acc 0.9967830882352942\n",
      "\n",
      "Epoch 116. Loss: 0.00915525117746559, Train_acc 0.9969618055555556\n",
      "\n",
      "Epoch 116. Loss: 0.01223472439555735, Train_acc 0.9958881578947368\n",
      "\n",
      "Epoch 116. Loss: 0.01126402428817073, Train_acc 0.99609375\n",
      "\n",
      "Epoch 116. Loss: 0.010559735387828822, Train_acc 0.9962797619047619\n",
      "\n",
      "Epoch 116. Loss: 0.010853181576967427, Train_acc 0.99609375\n",
      "\n",
      "Epoch 116. Loss: 0.014541738745188881, Train_acc 0.9959239130434783\n",
      "\n",
      "Epoch 116. Loss: 0.016076168954327258, Train_acc 0.9954427083333334\n",
      "\n",
      "Epoch 116. Loss: 0.014487787774339197, Train_acc 0.995625\n",
      "\n",
      "Epoch 116. Loss: 0.013362391598978531, Train_acc 0.9957932692307693\n",
      "\n",
      "Epoch 116. Loss: 0.012045282140912522, Train_acc 0.9959490740740741\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116. Loss: 0.01260417317498497, Train_acc 0.9958147321428571\n",
      "\n",
      "Epoch 116. Loss: 0.017010432766217935, Train_acc 0.9951508620689655\n",
      "\n",
      "Epoch 116. Loss: 0.016938589136009468, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 116. Loss: 0.016096552308087098, Train_acc 0.9947076612903226\n",
      "\n",
      "Epoch 116. Loss: 0.014681690155395461, Train_acc 0.994873046875\n",
      "\n",
      "Epoch 116. Loss: 0.013707194468166166, Train_acc 0.9950284090909091\n",
      "\n",
      "Epoch 116. Loss: 0.012538984479526342, Train_acc 0.9951746323529411\n",
      "\n",
      "Epoch 116. Loss: 0.012666324767785963, Train_acc 0.9950892857142857\n",
      "\n",
      "Epoch 116. Loss: 0.01148972556096035, Train_acc 0.9952256944444444\n",
      "\n",
      "Epoch 116. Loss: 0.01076213791312323, Train_acc 0.9953547297297297\n",
      "\n",
      "Epoch 116. Loss: 0.010944866327269787, Train_acc 0.9952713815789473\n",
      "\n",
      "Epoch 116. Loss: 0.010423725899598522, Train_acc 0.9953926282051282\n",
      "\n",
      "Epoch 116. Loss: 0.009652744014076762, Train_acc 0.9955078125\n",
      "\n",
      "Epoch 116. Loss: 0.009032681228455042, Train_acc 0.9956173780487805\n",
      "\n",
      "Epoch 116. Loss: 0.009804480202558162, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 116. Loss: 0.00921749231448399, Train_acc 0.9956395348837209\n",
      "\n",
      "Epoch 116. Loss: 0.011861549978530053, Train_acc 0.9953835227272727\n",
      "\n",
      "Epoch 116. Loss: 0.010970015407980064, Train_acc 0.9954861111111111\n",
      "\n",
      "Epoch 116. Loss: 0.009903561105020678, Train_acc 0.9955842391304348\n",
      "\n",
      "Epoch 116. Loss: 0.008932611524709802, Train_acc 0.9956781914893617\n",
      "\n",
      "Epoch 116. Loss: 0.0087216186173845, Train_acc 0.9957682291666666\n",
      "\n",
      "Epoch 116. Loss: 0.007879696008019627, Train_acc 0.9958545918367347\n",
      "\n",
      "Epoch 116. Loss: 0.00732124147265671, Train_acc 0.9959375\n",
      "\n",
      "Epoch 116. Loss: 0.006708379327799543, Train_acc 0.9960171568627451\n",
      "\n",
      "Epoch 116. Loss: 0.006076808105538448, Train_acc 0.99609375\n",
      "\n",
      "Epoch 116. Loss: 0.005632067569442982, Train_acc 0.9961674528301887\n",
      "\n",
      "Epoch 116. Loss: 0.0052254125516996335, Train_acc 0.9962384259259259\n",
      "\n",
      "Epoch 116. Loss: 0.004801502408434649, Train_acc 0.9963068181818182\n",
      "\n",
      "Epoch 116. Loss: 0.004458657252672792, Train_acc 0.9963727678571429\n",
      "\n",
      "Epoch 116. Loss: 0.005656589282646908, Train_acc 0.9962993421052632\n",
      "\n",
      "Epoch 116. Loss: 0.005125260321839086, Train_acc 0.9963631465517241\n",
      "\n",
      "Epoch 116. Loss: 0.004907954954357534, Train_acc 0.9964247881355932\n",
      "\n",
      "Epoch 116. Loss: 0.004446868084437703, Train_acc 0.996484375\n",
      "\n",
      "Epoch 116. Loss: 0.004062837523654451, Train_acc 0.9965420081967213\n",
      "\n",
      "Epoch 116. Loss: 0.003730402342917338, Train_acc 0.9965977822580645\n",
      "\n",
      "Epoch 116. Loss: 0.003370499397250025, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 116. Loss: 0.004472215523509987, Train_acc 0.99658203125\n",
      "\n",
      "Epoch 116. Loss: 0.004073022613936342, Train_acc 0.9966346153846154\n",
      "\n",
      "Epoch 116. Loss: 0.0038832633827003927, Train_acc 0.9966856060606061\n",
      "\n",
      "Epoch 116. Loss: 0.0035874722193477834, Train_acc 0.9967350746268657\n",
      "\n",
      "Epoch 116. Loss: 0.003278592524972405, Train_acc 0.9967830882352942\n",
      "\n",
      "Epoch 116. Loss: 0.003153555911150735, Train_acc 0.9968297101449275\n",
      "\n",
      "Epoch 116. Loss: 0.0030533271734718933, Train_acc 0.996875\n",
      "\n",
      "Epoch 116. Loss: 0.003908776100409429, Train_acc 0.9968089788732394\n",
      "\n",
      "Epoch 116. Loss: 0.0036738009114704144, Train_acc 0.9968532986111112\n",
      "\n",
      "Epoch 116. Loss: 0.0033292682745615903, Train_acc 0.996896404109589\n",
      "\n",
      "Epoch 116. Loss: 0.003111891989355707, Train_acc 0.9969383445945946\n",
      "\n",
      "Epoch 116. Loss: 0.0029656020320650255, Train_acc 0.9969791666666666\n",
      "\n",
      "Epoch 116. Loss: 0.003751274982142119, Train_acc 0.9969161184210527\n",
      "\n",
      "Epoch 116. Loss: 0.0035535570303776875, Train_acc 0.9969561688311688\n",
      "\n",
      "Epoch 116. Loss: 0.004008215038792403, Train_acc 0.996895032051282\n",
      "\n",
      "Epoch 116. Loss: 0.005817457953527073, Train_acc 0.9968354430379747\n",
      "\n",
      "Epoch 116. Loss: 0.005255219931860566, Train_acc 0.996875\n",
      "\n",
      "Epoch 116. Loss: 0.004782436110909478, Train_acc 0.9969135802469136\n",
      "\n",
      "Epoch 116. Loss: 0.00434310793001416, Train_acc 0.9969512195121951\n",
      "\n",
      "Epoch 116. Loss: 0.003939335742655249, Train_acc 0.9969879518072289\n",
      "\n",
      "Epoch 116. Loss: 0.003618155330047326, Train_acc 0.9970238095238095\n",
      "\n",
      "Epoch 116. Loss: 0.0032700135056421198, Train_acc 0.9970588235294118\n",
      "\n",
      "Epoch 116. Loss: 0.0029462902308244015, Train_acc 0.997093023255814\n",
      "\n",
      "Epoch 116. Loss: 0.002692303621401914, Train_acc 0.9971264367816092\n",
      "\n",
      "Epoch 116. Loss: 0.0024579980828196807, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 116. Loss: 0.002256031588513196, Train_acc 0.9971910112359551\n",
      "\n",
      "Epoch 116. Loss: 0.0020500224525496352, Train_acc 0.9972222222222222\n",
      "\n",
      "Epoch 116. Loss: 0.0030980966637818505, Train_acc 0.9971668956043956\n",
      "\n",
      "Epoch 116. Loss: 0.004682305237676664, Train_acc 0.9970278532608695\n",
      "\n",
      "Epoch 116. Loss: 0.00431869895643082, Train_acc 0.997059811827957\n",
      "\n",
      "Epoch 116. Loss: 0.004981687688554109, Train_acc 0.9970079787234043\n",
      "\n",
      "Epoch 116. Loss: 0.004700928770728213, Train_acc 0.9970394736842105\n",
      "\n",
      "Epoch 116. Loss: 0.004251266814650232, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 116. Loss: 0.005445576725048841, Train_acc 0.9970199742268041\n",
      "\n",
      "Epoch 116. Loss: 0.004999505076033343, Train_acc 0.9970503826530612\n",
      "\n",
      "Epoch 116. Loss: 0.004943333127995553, Train_acc 0.9970801767676768\n",
      "\n",
      "Epoch 116. Loss: 0.005617092807352742, Train_acc 0.99703125\n",
      "\n",
      "[Epoch 116 Batch 100] Loss: 0.006620024637216509 Training: accuracy=0.996983\n",
      "Epoch 116. Loss: 0.006620024637216509, Train_acc 0.9969832920792079\n",
      "\n",
      "Epoch 116. Loss: 0.006176418248564763, Train_acc 0.9970128676470589\n",
      "\n",
      "Epoch 116. Loss: 0.00558251903173582, Train_acc 0.9970418689320388\n",
      "\n",
      "Epoch 116. Loss: 0.00567839508958688, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 116. Loss: 0.005146689240515319, Train_acc 0.9970982142857143\n",
      "\n",
      "Epoch 116. Loss: 0.0072276688585103345, Train_acc 0.9970518867924528\n",
      "\n",
      "Epoch 116. Loss: 0.008445004102833938, Train_acc 0.9969334112149533\n",
      "\n",
      "Epoch 116. Loss: 0.007818773037901109, Train_acc 0.9969618055555556\n",
      "\n",
      "Epoch 116. Loss: 0.0070828621900567434, Train_acc 0.9969896788990825\n",
      "\n",
      "Epoch 116. Loss: 0.006406461359358342, Train_acc 0.9970170454545455\n",
      "\n",
      "Epoch 116. Loss: 0.006290274397325378, Train_acc 0.997043918918919\n",
      "\n",
      "Epoch 116. Loss: 0.005883316518142993, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 116. Loss: 0.0064506081942693975, Train_acc 0.9970271017699115\n",
      "\n",
      "Epoch 116. Loss: 0.007435126814601713, Train_acc 0.996984649122807\n",
      "\n",
      "Epoch 116. Loss: 0.007999889240435862, Train_acc 0.9969429347826086\n",
      "\n",
      "Epoch 116. Loss: 0.013308310972844455, Train_acc 0.9967672413793104\n",
      "\n",
      "Epoch 116. Loss: 0.012061962969374933, Train_acc 0.9967948717948718\n",
      "\n",
      "Epoch 116. Loss: 0.011091072073002707, Train_acc 0.996822033898305\n",
      "\n",
      "Epoch 116. Loss: 0.016027598420161056, Train_acc 0.9967174369747899\n",
      "\n",
      "Epoch 116. Loss: 0.017565113013426704, Train_acc 0.9966796875\n",
      "\n",
      "Epoch 116. Loss: 0.019076793302989226, Train_acc 0.9965779958677686\n",
      "\n",
      "Epoch 116. Loss: 0.01818369007995387, Train_acc 0.9965420081967213\n",
      "\n",
      "Epoch 116. Loss: 0.017423192503070773, Train_acc 0.9965066056910569\n",
      "\n",
      "Epoch 116. Loss: 0.016457738679214663, Train_acc 0.9964717741935484\n",
      "\n",
      "Epoch 116. Loss: 0.02200004208227785, Train_acc 0.996375\n",
      "\n",
      "Epoch 116. Loss: 0.020348107192806525, Train_acc 0.9964037698412699\n",
      "\n",
      "Epoch 116. Loss: 0.01906561987375509, Train_acc 0.9964320866141733\n",
      "\n",
      "Epoch 116. Loss: 0.03245128217436634, Train_acc 0.99627685546875\n",
      "\n",
      "Epoch 116. Loss: 0.03068276506079223, Train_acc 0.9962451550387597\n",
      "\n",
      "Epoch 116. Loss: 0.029643501815912004, Train_acc 0.9961538461538462\n",
      "\n",
      "Epoch 116. Loss: 0.0268741424089374, Train_acc 0.9961832061068703\n",
      "\n",
      "Epoch 116. Loss: 0.024259742088380627, Train_acc 0.9962121212121212\n",
      "\n",
      "Epoch 116. Loss: 0.02309715351813719, Train_acc 0.9961818609022557\n",
      "\n",
      "Epoch 116. Loss: 0.022597866480234437, Train_acc 0.996152052238806\n",
      "\n",
      "Epoch 116. Loss: 0.02651860018791244, Train_acc 0.9961226851851852\n",
      "\n",
      "Epoch 116. Loss: 0.028066832872225216, Train_acc 0.9959788602941176\n",
      "\n",
      "Epoch 116. Loss: 0.029048076169484887, Train_acc 0.9958941605839416\n",
      "\n",
      "Epoch 116. Loss: 0.02622333566976923, Train_acc 0.9959239130434783\n",
      "\n",
      "Epoch 116. Loss: 0.02433483055427675, Train_acc 0.9959532374100719\n",
      "\n",
      "Epoch 116. Loss: 0.02852847800727193, Train_acc 0.9958705357142857\n",
      "\n",
      "Epoch 116. Loss: 0.026342763295699696, Train_acc 0.9958998226950354\n",
      "\n",
      "Epoch 116. Loss: 0.025356038882669393, Train_acc 0.9958736795774648\n",
      "\n",
      "Epoch 116. Loss: 0.023675238243642375, Train_acc 0.995902534965035\n",
      "\n",
      "Epoch 116. Loss: 0.022169665103616946, Train_acc 0.9959309895833334\n",
      "\n",
      "Epoch 116. Loss: 0.020996361860301464, Train_acc 0.9959590517241379\n",
      "\n",
      "Epoch 116. Loss: 0.019669132487028573, Train_acc 0.9959867294520548\n",
      "\n",
      "Epoch 116. Loss: 0.018042688117183507, Train_acc 0.9960140306122449\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116. Loss: 0.01985419314720386, Train_acc 0.9959353885135135\n",
      "\n",
      "Epoch 116. Loss: 0.027353744402094073, Train_acc 0.9958053691275168\n",
      "\n",
      "Epoch 116. Loss: 0.026335983599332025, Train_acc 0.99578125\n",
      "\n",
      "Epoch 116. Loss: 0.02617666754881178, Train_acc 0.9957057119205298\n",
      "\n",
      "Epoch 116. Loss: 0.02506572593384655, Train_acc 0.9956825657894737\n",
      "\n",
      "Epoch 116. Loss: 0.025277658603790446, Train_acc 0.9956086601307189\n",
      "\n",
      "Epoch 116. Loss: 0.023716702899071317, Train_acc 0.9955864448051948\n",
      "\n",
      "Epoch 116. Loss: 0.021540042685441144, Train_acc 0.9956149193548387\n",
      "\n",
      "Epoch 116. Loss: 0.019482762744783506, Train_acc 0.9956430288461539\n",
      "\n",
      "Epoch 116. Loss: 0.017734997892313434, Train_acc 0.9956707802547771\n",
      "\n",
      "Epoch 116. Loss: 0.01771296065950385, Train_acc 0.9956487341772152\n",
      "\n",
      "Epoch 116. Loss: 0.017207564896231813, Train_acc 0.9956761006289309\n",
      "\n",
      "Epoch 116. Loss: 0.016431568289595178, Train_acc 0.995654296875\n",
      "\n",
      "Epoch 116. Loss: 0.017381191715416907, Train_acc 0.9956327639751553\n",
      "\n",
      "Epoch 116. Loss: 0.015788474675477386, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 116. Loss: 0.014439799787106373, Train_acc 0.9956863496932515\n",
      "\n",
      "Epoch 116. Loss: 0.013061537031728932, Train_acc 0.9957126524390244\n",
      "\n",
      "Epoch 116. Loss: 0.01269194207808278, Train_acc 0.9956912878787879\n",
      "\n",
      "Epoch 116. Loss: 0.011543256482873725, Train_acc 0.9957172439759037\n",
      "\n",
      "Epoch 116. Loss: 0.011348493251706095, Train_acc 0.9956961077844312\n",
      "\n",
      "Epoch 116. Loss: 0.010387617113874046, Train_acc 0.9957217261904762\n",
      "\n",
      "Epoch 116. Loss: 0.01007802230508836, Train_acc 0.9957470414201184\n",
      "\n",
      "Epoch 116. Loss: 0.01005676085777621, Train_acc 0.9957261029411765\n",
      "\n",
      "Epoch 116. Loss: 0.009315625016823774, Train_acc 0.9957510964912281\n",
      "\n",
      "Epoch 116. Loss: 0.008418279830401719, Train_acc 0.9957757994186046\n",
      "\n",
      "Epoch 116. Loss: 0.008038149705188496, Train_acc 0.9958002167630058\n",
      "\n",
      "Epoch 116. Loss: 0.007890786811179242, Train_acc 0.9957794540229885\n",
      "\n",
      "Epoch 116. Loss: 0.007455445841036429, Train_acc 0.9958035714285715\n",
      "\n",
      "Epoch 116. Loss: 0.006899643307066431, Train_acc 0.9958274147727273\n",
      "\n",
      "Epoch 116. Loss: 0.008348615309718076, Train_acc 0.9957627118644068\n",
      "\n",
      "Epoch 116. Loss: 0.007999514916425489, Train_acc 0.9957865168539326\n",
      "\n",
      "Epoch 116. Loss: 0.007292017993731537, Train_acc 0.9958100558659218\n",
      "\n",
      "Epoch 116. Loss: 0.007519243314030682, Train_acc 0.9957899305555555\n",
      "\n",
      "Epoch 116. Loss: 0.006977899445217473, Train_acc 0.9958131906077348\n",
      "\n",
      "Epoch 116. Loss: 0.00650071313623037, Train_acc 0.995836195054945\n",
      "\n",
      "Epoch 116. Loss: 0.007584702430457885, Train_acc 0.9957735655737705\n",
      "\n",
      "Epoch 116. Loss: 0.006903786270375713, Train_acc 0.9957965353260869\n",
      "\n",
      "Epoch 116. Loss: 0.008727624133428036, Train_acc 0.9957347972972973\n",
      "\n",
      "Epoch 116. Loss: 0.00795854306834945, Train_acc 0.9957577284946236\n",
      "\n",
      "Epoch 116. Loss: 0.007290566615325292, Train_acc 0.9957804144385026\n",
      "\n",
      "Epoch 116. Loss: 0.006600517462687192, Train_acc 0.9958028590425532\n",
      "\n",
      "Epoch 116. Loss: 0.0062039039505241795, Train_acc 0.9958250661375662\n",
      "\n",
      "Epoch 116. Loss: 0.0057044008321882915, Train_acc 0.9958470394736842\n",
      "\n",
      "Epoch 116. Loss: 0.005198078524733779, Train_acc 0.9958687827225131\n",
      "\n",
      "Epoch 116. Loss: 0.0047944383670562776, Train_acc 0.9958902994791666\n",
      "\n",
      "Epoch 116. Loss: 0.004342341097717853, Train_acc 0.9959115932642487\n",
      "\n",
      "Epoch 116. Loss: 0.0040252822689938895, Train_acc 0.9959326675257731\n",
      "\n",
      "Epoch 116. Loss: 0.003659316479984598, Train_acc 0.9959535256410257\n",
      "\n",
      "Epoch 116. Loss: 0.0033336082028744087, Train_acc 0.99596\n",
      "\n",
      "Epoch 117. Loss: 0.0030387701671851395, Train_acc 1.0\n",
      "\n",
      "Epoch 117. Loss: 0.002794733699250166, Train_acc 1.0\n",
      "\n",
      "Epoch 117. Loss: 0.0033356621990394096, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 117. Loss: 0.0030458365712174996, Train_acc 0.998046875\n",
      "\n",
      "Epoch 117. Loss: 0.002796348036757191, Train_acc 0.9984375\n",
      "\n",
      "Epoch 117. Loss: 0.0025446589813789694, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 117. Loss: 0.005985637473418799, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 117. Loss: 0.005398083846292279, Train_acc 0.998046875\n",
      "\n",
      "Epoch 117. Loss: 0.004898123803502439, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 117. Loss: 0.0045411654149698786, Train_acc 0.9984375\n",
      "\n",
      "Epoch 117. Loss: 0.004211400972846827, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 117. Loss: 0.004560167739132358, Train_acc 0.998046875\n",
      "\n",
      "Epoch 117. Loss: 0.004154564236165715, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 117. Loss: 0.004184720472227007, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 117. Loss: 0.003798556950992207, Train_acc 0.9984375\n",
      "\n",
      "Epoch 117. Loss: 0.004514758216416115, Train_acc 0.998046875\n",
      "\n",
      "Epoch 117. Loss: 0.004203559760928399, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 117. Loss: 0.003968852846876753, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 117. Loss: 0.0036407899488636606, Train_acc 0.9983552631578947\n",
      "\n",
      "Epoch 117. Loss: 0.0033326563392247635, Train_acc 0.9984375\n",
      "\n",
      "Epoch 117. Loss: 0.0030302012949715595, Train_acc 0.9985119047619048\n",
      "\n",
      "Epoch 117. Loss: 0.002900017545553792, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 117. Loss: 0.002648248040788284, Train_acc 0.998641304347826\n",
      "\n",
      "Epoch 117. Loss: 0.0027484167959060473, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 117. Loss: 0.002615035890781838, Train_acc 0.99875\n",
      "\n",
      "Epoch 117. Loss: 0.002444820610316657, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 117. Loss: 0.0030600611374962893, Train_acc 0.9985532407407407\n",
      "\n",
      "Epoch 117. Loss: 0.0029781655078698903, Train_acc 0.9986049107142857\n",
      "\n",
      "Epoch 117. Loss: 0.0026899630043862315, Train_acc 0.9986530172413793\n",
      "\n",
      "Epoch 117. Loss: 0.0026060296846925957, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 117. Loss: 0.002429555255534104, Train_acc 0.9987399193548387\n",
      "\n",
      "Epoch 117. Loss: 0.002227208278423527, Train_acc 0.998779296875\n",
      "\n",
      "Epoch 117. Loss: 0.0022857317574062758, Train_acc 0.9988162878787878\n",
      "\n",
      "Epoch 117. Loss: 0.0027419230507080687, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 117. Loss: 0.0025292612316193375, Train_acc 0.9986607142857142\n",
      "\n",
      "Epoch 117. Loss: 0.0024006081385447554, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 117. Loss: 0.004259541281732974, Train_acc 0.9983108108108109\n",
      "\n",
      "Epoch 117. Loss: 0.0038647445793972683, Train_acc 0.9983552631578947\n",
      "\n",
      "Epoch 117. Loss: 0.0035313621206009035, Train_acc 0.9983974358974359\n",
      "\n",
      "Epoch 117. Loss: 0.0032615690926282386, Train_acc 0.9984375\n",
      "\n",
      "Epoch 117. Loss: 0.002949285241562038, Train_acc 0.9984756097560976\n",
      "\n",
      "Epoch 117. Loss: 0.0027629124916102674, Train_acc 0.9985119047619048\n",
      "\n",
      "Epoch 117. Loss: 0.0025109690297065246, Train_acc 0.998546511627907\n",
      "\n",
      "Epoch 117. Loss: 0.002389219444587952, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 117. Loss: 0.0024489530454681455, Train_acc 0.9986111111111111\n",
      "\n",
      "Epoch 117. Loss: 0.0022120332658530114, Train_acc 0.998641304347826\n",
      "\n",
      "Epoch 117. Loss: 0.0020048714533454, Train_acc 0.9986702127659575\n",
      "\n",
      "Epoch 117. Loss: 0.001904454976860954, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 117. Loss: 0.002248626262436158, Train_acc 0.9987244897959183\n",
      "\n",
      "Epoch 117. Loss: 0.0020414356231994485, Train_acc 0.99875\n",
      "\n",
      "Epoch 117. Loss: 0.0018448079650238876, Train_acc 0.9987745098039216\n",
      "\n",
      "Epoch 117. Loss: 0.0016759008552087746, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 117. Loss: 0.001598869555865905, Train_acc 0.9988207547169812\n",
      "\n",
      "Epoch 117. Loss: 0.0014529168274515997, Train_acc 0.9988425925925926\n",
      "\n",
      "Epoch 117. Loss: 0.0013237178952995284, Train_acc 0.9988636363636364\n",
      "\n",
      "Epoch 117. Loss: 0.0012969606817926477, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 117. Loss: 0.0012119924454594862, Train_acc 0.9989035087719298\n",
      "\n",
      "Epoch 117. Loss: 0.0010994200368290305, Train_acc 0.9989224137931034\n",
      "\n",
      "Epoch 117. Loss: 0.0009994845164993363, Train_acc 0.9989406779661016\n",
      "\n",
      "Epoch 117. Loss: 0.0009139102357092127, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 117. Loss: 0.0009282897032018862, Train_acc 0.9989754098360656\n",
      "\n",
      "Epoch 117. Loss: 0.001049459894378456, Train_acc 0.998991935483871\n",
      "\n",
      "Epoch 117. Loss: 0.0009677429380447545, Train_acc 0.9990079365079365\n",
      "\n",
      "Epoch 117. Loss: 0.0009019214614186103, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 117. Loss: 0.0008159475455190082, Train_acc 0.9990384615384615\n",
      "\n",
      "Epoch 117. Loss: 0.000737910173627909, Train_acc 0.9990530303030303\n",
      "\n",
      "Epoch 117. Loss: 0.0006895738931619087, Train_acc 0.9990671641791045\n",
      "\n",
      "Epoch 117. Loss: 0.0006256668529822995, Train_acc 0.9990808823529411\n",
      "\n",
      "Epoch 117. Loss: 0.0005809039281041349, Train_acc 0.9990942028985508\n",
      "\n",
      "Epoch 117. Loss: 0.0005442811609228783, Train_acc 0.9991071428571429\n",
      "\n",
      "Epoch 117. Loss: 0.0005516759137142003, Train_acc 0.9991197183098591\n",
      "\n",
      "Epoch 117. Loss: 0.0004989678946944343, Train_acc 0.9991319444444444\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117. Loss: 0.00046292130236279, Train_acc 0.9991438356164384\n",
      "\n",
      "Epoch 117. Loss: 0.00043039652666610655, Train_acc 0.9991554054054054\n",
      "\n",
      "Epoch 117. Loss: 0.0003977402170325228, Train_acc 0.9991666666666666\n",
      "\n",
      "Epoch 117. Loss: 0.0003652610828023788, Train_acc 0.9991776315789473\n",
      "\n",
      "Epoch 117. Loss: 0.0003347166542368914, Train_acc 0.9991883116883117\n",
      "\n",
      "Epoch 117. Loss: 0.0003061554838580987, Train_acc 0.999198717948718\n",
      "\n",
      "Epoch 117. Loss: 0.0002829207440012672, Train_acc 0.9992088607594937\n",
      "\n",
      "Epoch 117. Loss: 0.00035307971028631735, Train_acc 0.99921875\n",
      "\n",
      "Epoch 117. Loss: 0.0003220730303768765, Train_acc 0.9992283950617284\n",
      "\n",
      "Epoch 117. Loss: 0.0002906081304928973, Train_acc 0.9992378048780488\n",
      "\n",
      "Epoch 117. Loss: 0.00026259304699384955, Train_acc 0.9992469879518072\n",
      "\n",
      "Epoch 117. Loss: 0.0002402021925159538, Train_acc 0.9992559523809523\n",
      "\n",
      "Epoch 117. Loss: 0.00022164127123662405, Train_acc 0.9992647058823529\n",
      "\n",
      "Epoch 117. Loss: 0.00022687138646483636, Train_acc 0.9992732558139535\n",
      "\n",
      "Epoch 117. Loss: 0.00025948481441898834, Train_acc 0.9992816091954023\n",
      "\n",
      "Epoch 117. Loss: 0.00028142122902543416, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 117. Loss: 0.00026077733551103835, Train_acc 0.9992977528089888\n",
      "\n",
      "Epoch 117. Loss: 0.0002694306551250946, Train_acc 0.9993055555555556\n",
      "\n",
      "Epoch 117. Loss: 0.00024384254608813733, Train_acc 0.9993131868131868\n",
      "\n",
      "Epoch 117. Loss: 0.0002264679417688703, Train_acc 0.9993206521739131\n",
      "\n",
      "Epoch 117. Loss: 0.00020914372813789111, Train_acc 0.9993279569892473\n",
      "\n",
      "Epoch 117. Loss: 0.0001995940904340664, Train_acc 0.9993351063829787\n",
      "\n",
      "Epoch 117. Loss: 0.0001804638471556859, Train_acc 0.9993421052631579\n",
      "\n",
      "Epoch 117. Loss: 0.00020600589969652056, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 117. Loss: 0.00018703967170595446, Train_acc 0.9993556701030928\n",
      "\n",
      "Epoch 117. Loss: 0.00017555371496791157, Train_acc 0.9993622448979592\n",
      "\n",
      "Epoch 117. Loss: 0.0001592922213747835, Train_acc 0.9993686868686869\n",
      "\n",
      "Epoch 117. Loss: 0.00014968664604953923, Train_acc 0.999375\n",
      "\n",
      "[Epoch 117 Batch 100] Loss: 0.00014140111586023792 Training: accuracy=0.999381\n",
      "Epoch 117. Loss: 0.00014140111586023792, Train_acc 0.9993811881188119\n",
      "\n",
      "Epoch 117. Loss: 0.00014637533782838516, Train_acc 0.9993872549019608\n",
      "\n",
      "Epoch 117. Loss: 0.0001378419279406032, Train_acc 0.9993932038834952\n",
      "\n",
      "Epoch 117. Loss: 0.00012615831211331102, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 117. Loss: 0.00014786779174597663, Train_acc 0.9994047619047619\n",
      "\n",
      "Epoch 117. Loss: 0.00014052925540312136, Train_acc 0.9994103773584906\n",
      "\n",
      "Epoch 117. Loss: 0.00032943289272460946, Train_acc 0.9994158878504673\n",
      "\n",
      "Epoch 117. Loss: 0.0003094645174408766, Train_acc 0.9994212962962963\n",
      "\n",
      "Epoch 117. Loss: 0.00029761797102701104, Train_acc 0.9994266055045872\n",
      "\n",
      "Epoch 117. Loss: 0.00027885774416187755, Train_acc 0.9994318181818181\n",
      "\n",
      "Epoch 117. Loss: 0.00026795357169360833, Train_acc 0.9994369369369369\n",
      "\n",
      "Epoch 117. Loss: 0.0002579027119310096, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 117. Loss: 0.003270119275423711, Train_acc 0.9993777654867256\n",
      "\n",
      "Epoch 117. Loss: 0.002947330886298476, Train_acc 0.9993832236842105\n",
      "\n",
      "Epoch 117. Loss: 0.0026616142632971485, Train_acc 0.9993885869565218\n",
      "\n",
      "Epoch 117. Loss: 0.0034111967296073095, Train_acc 0.9993265086206896\n",
      "\n",
      "Epoch 117. Loss: 0.005209454464376205, Train_acc 0.9992654914529915\n",
      "\n",
      "Epoch 117. Loss: 0.004727545022393413, Train_acc 0.999271716101695\n",
      "\n",
      "Epoch 117. Loss: 0.0042844661128224265, Train_acc 0.9992778361344538\n",
      "\n",
      "Epoch 117. Loss: 0.0038643229124085774, Train_acc 0.9992838541666667\n",
      "\n",
      "Epoch 117. Loss: 0.003587090009120405, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 117. Loss: 0.0034274313480785194, Train_acc 0.9992955942622951\n",
      "\n",
      "Epoch 117. Loss: 0.003110481555772524, Train_acc 0.9993013211382114\n",
      "\n",
      "Epoch 117. Loss: 0.0029502616383062607, Train_acc 0.9993069556451613\n",
      "\n",
      "Epoch 117. Loss: 0.0029042785582253463, Train_acc 0.9993125\n",
      "\n",
      "Epoch 117. Loss: 0.002621368712209329, Train_acc 0.9993179563492064\n",
      "\n",
      "Epoch 117. Loss: 0.0024484223687851418, Train_acc 0.9993233267716536\n",
      "\n",
      "Epoch 117. Loss: 0.004404140031117557, Train_acc 0.999267578125\n",
      "\n",
      "Epoch 117. Loss: 0.00397092246667922, Train_acc 0.9992732558139535\n",
      "\n",
      "Epoch 117. Loss: 0.0036158817858446875, Train_acc 0.9992788461538461\n",
      "\n",
      "Epoch 117. Loss: 0.004393357088501684, Train_acc 0.9992247137404581\n",
      "\n",
      "Epoch 117. Loss: 0.007400852561296909, Train_acc 0.9991122159090909\n",
      "\n",
      "Epoch 117. Loss: 0.006675363269042982, Train_acc 0.9991188909774437\n",
      "\n",
      "Epoch 117. Loss: 0.006647815610401642, Train_acc 0.9990671641791045\n",
      "\n",
      "Epoch 117. Loss: 0.007028129969924223, Train_acc 0.9990162037037037\n",
      "\n",
      "Epoch 117. Loss: 0.00634900929536107, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 117. Loss: 0.005730638613928626, Train_acc 0.9990305656934306\n",
      "\n",
      "Epoch 117. Loss: 0.005180597576269972, Train_acc 0.9990375905797102\n",
      "\n",
      "Epoch 117. Loss: 0.004708485560825737, Train_acc 0.9990445143884892\n",
      "\n",
      "Epoch 117. Loss: 0.0048972607468467395, Train_acc 0.9990513392857143\n",
      "\n",
      "Epoch 117. Loss: 0.0044248140906966655, Train_acc 0.9990580673758865\n",
      "\n",
      "Epoch 117. Loss: 0.004168862507068538, Train_acc 0.9990647007042254\n",
      "\n",
      "Epoch 117. Loss: 0.004631500997683486, Train_acc 0.9990166083916084\n",
      "\n",
      "Epoch 117. Loss: 0.004395506574026716, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 117. Loss: 0.003983444688217243, Train_acc 0.9990301724137931\n",
      "\n",
      "Epoch 117. Loss: 0.004133406466614962, Train_acc 0.9990368150684932\n",
      "\n",
      "Epoch 117. Loss: 0.0037840555388637728, Train_acc 0.9990433673469388\n",
      "\n",
      "Epoch 117. Loss: 0.003504096124577523, Train_acc 0.999049831081081\n",
      "\n",
      "Epoch 117. Loss: 0.0037812260983955868, Train_acc 0.9990562080536913\n",
      "\n",
      "Epoch 117. Loss: 0.01069941608893025, Train_acc 0.9990104166666667\n",
      "\n",
      "Epoch 117. Loss: 0.010458848897699847, Train_acc 0.9989652317880795\n",
      "\n",
      "Epoch 117. Loss: 0.009437270626363774, Train_acc 0.9989720394736842\n",
      "\n",
      "Epoch 117. Loss: 0.008585916688516843, Train_acc 0.9989787581699346\n",
      "\n",
      "Epoch 117. Loss: 0.011780704987473883, Train_acc 0.9989346590909091\n",
      "\n",
      "Epoch 117. Loss: 0.010696968664536713, Train_acc 0.9989415322580645\n",
      "\n",
      "Epoch 117. Loss: 0.010442924574592565, Train_acc 0.9988982371794872\n",
      "\n",
      "Epoch 117. Loss: 0.00942380936355861, Train_acc 0.99890525477707\n",
      "\n",
      "Epoch 117. Loss: 0.008500733290438198, Train_acc 0.9989121835443038\n",
      "\n",
      "Epoch 117. Loss: 0.00795564375049562, Train_acc 0.9989190251572327\n",
      "\n",
      "Epoch 117. Loss: 0.007366709819600202, Train_acc 0.99892578125\n",
      "\n",
      "Epoch 117. Loss: 0.00728826834328343, Train_acc 0.9989324534161491\n",
      "\n",
      "Epoch 117. Loss: 0.006593706275100585, Train_acc 0.9989390432098766\n",
      "\n",
      "Epoch 117. Loss: 0.006004910806633601, Train_acc 0.9989455521472392\n",
      "\n",
      "Epoch 117. Loss: 0.006560686784074518, Train_acc 0.9989043445121951\n",
      "\n",
      "Epoch 117. Loss: 0.0060328784536592475, Train_acc 0.9989109848484848\n",
      "\n",
      "Epoch 117. Loss: 0.00633867590066245, Train_acc 0.9988704819277109\n",
      "\n",
      "Epoch 117. Loss: 0.00588162190373049, Train_acc 0.998877245508982\n",
      "\n",
      "Epoch 117. Loss: 0.00928886857618665, Train_acc 0.9987909226190477\n",
      "\n",
      "Epoch 117. Loss: 0.008456733537932712, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 117. Loss: 0.0115139957933609, Train_acc 0.9987591911764706\n",
      "\n",
      "Epoch 117. Loss: 0.010427328936264378, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 117. Loss: 0.009425220586545992, Train_acc 0.9987736191860465\n",
      "\n",
      "Epoch 117. Loss: 0.008590853635482693, Train_acc 0.9987807080924855\n",
      "\n",
      "Epoch 117. Loss: 0.008359930121388469, Train_acc 0.998742816091954\n",
      "\n",
      "Epoch 117. Loss: 0.007552002579064086, Train_acc 0.99875\n",
      "\n",
      "Epoch 117. Loss: 0.006874870791041552, Train_acc 0.9987571022727273\n",
      "\n",
      "Epoch 117. Loss: 0.006236261383298366, Train_acc 0.9987641242937854\n",
      "\n",
      "Epoch 117. Loss: 0.0060781428174853285, Train_acc 0.9987710674157303\n",
      "\n",
      "Epoch 117. Loss: 0.00594710078075647, Train_acc 0.9987779329608939\n",
      "\n",
      "Epoch 117. Loss: 0.005393590172386867, Train_acc 0.9987847222222223\n",
      "\n",
      "Epoch 117. Loss: 0.004862246983064277, Train_acc 0.9987914364640884\n",
      "\n",
      "Epoch 117. Loss: 0.004386306419381212, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 117. Loss: 0.004258225825459102, Train_acc 0.9988046448087432\n",
      "\n",
      "Epoch 117. Loss: 0.003905937656154042, Train_acc 0.9988111413043478\n",
      "\n",
      "Epoch 117. Loss: 0.0036891761804131915, Train_acc 0.9988175675675676\n",
      "\n",
      "Epoch 117. Loss: 0.005559692983434342, Train_acc 0.9987399193548387\n",
      "\n",
      "Epoch 117. Loss: 0.005092367631310144, Train_acc 0.9987466577540107\n",
      "\n",
      "Epoch 117. Loss: 0.004785217063528823, Train_acc 0.9987533244680851\n",
      "\n",
      "Epoch 117. Loss: 0.004490241655825103, Train_acc 0.9987599206349206\n",
      "\n",
      "Epoch 117. Loss: 0.004140053376698665, Train_acc 0.998766447368421\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117. Loss: 0.0037598238520914736, Train_acc 0.9987729057591623\n",
      "\n",
      "Epoch 117. Loss: 0.004282936275729039, Train_acc 0.9987386067708334\n",
      "\n",
      "Epoch 117. Loss: 0.0038991594015614674, Train_acc 0.9987451424870466\n",
      "\n",
      "Epoch 117. Loss: 0.0035780627456115767, Train_acc 0.9987516108247423\n",
      "\n",
      "Epoch 117. Loss: 0.0039511309070265664, Train_acc 0.9987580128205128\n",
      "\n",
      "Epoch 117. Loss: 0.004661967657763634, Train_acc 0.99876\n",
      "\n",
      "Epoch 118. Loss: 0.005486884611331409, Train_acc 0.9921875\n",
      "\n",
      "Epoch 118. Loss: 0.004971581526644218, Train_acc 0.99609375\n",
      "\n",
      "Epoch 118. Loss: 0.004498967874027137, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 118. Loss: 0.004759365668574134, Train_acc 0.998046875\n",
      "\n",
      "Epoch 118. Loss: 0.004361999164476985, Train_acc 0.9984375\n",
      "\n",
      "Epoch 118. Loss: 0.01045313891511112, Train_acc 0.99609375\n",
      "\n",
      "Epoch 118. Loss: 0.009433778533212017, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 118. Loss: 0.008509527695439108, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 118. Loss: 0.007717014003006159, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 118. Loss: 0.007866397055126016, Train_acc 0.996875\n",
      "\n",
      "Epoch 118. Loss: 0.007996463934007393, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 118. Loss: 0.0074964441061450005, Train_acc 0.9967447916666666\n",
      "\n",
      "Epoch 118. Loss: 0.00713878442648944, Train_acc 0.9969951923076923\n",
      "\n",
      "Epoch 118. Loss: 0.00664040843967107, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 118. Loss: 0.008464441674859886, Train_acc 0.996875\n",
      "\n",
      "Epoch 118. Loss: 0.007753406501184313, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 118. Loss: 0.007032378709330774, Train_acc 0.9972426470588235\n",
      "\n",
      "Epoch 118. Loss: 0.006342196525702283, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 118. Loss: 0.005826929036161517, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 118. Loss: 0.0052921879703141435, Train_acc 0.99765625\n",
      "\n",
      "Epoch 118. Loss: 0.0055378254575434785, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 118. Loss: 0.0052614812292146795, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 118. Loss: 0.004791392008120994, Train_acc 0.9979619565217391\n",
      "\n",
      "Epoch 118. Loss: 0.0045665912282364185, Train_acc 0.998046875\n",
      "\n",
      "Epoch 118. Loss: 0.00434921211132973, Train_acc 0.998125\n",
      "\n",
      "Epoch 118. Loss: 0.00503827617582294, Train_acc 0.9978966346153846\n",
      "\n",
      "Epoch 118. Loss: 0.008014909798055405, Train_acc 0.9976851851851852\n",
      "\n",
      "Epoch 118. Loss: 0.0072329565892541164, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 118. Loss: 0.006516810928019864, Train_acc 0.9978448275862069\n",
      "\n",
      "Epoch 118. Loss: 0.005884804870072905, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 118. Loss: 0.005764580009103332, Train_acc 0.9979838709677419\n",
      "\n",
      "Epoch 118. Loss: 0.0055904695654396845, Train_acc 0.998046875\n",
      "\n",
      "Epoch 118. Loss: 0.005289725157795962, Train_acc 0.9981060606060606\n",
      "\n",
      "Epoch 118. Loss: 0.005458496907215074, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 118. Loss: 0.004986862403253397, Train_acc 0.9982142857142857\n",
      "\n",
      "Epoch 118. Loss: 0.0044946127471543786, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 118. Loss: 0.004148323259197989, Train_acc 0.9983108108108109\n",
      "\n",
      "Epoch 118. Loss: 0.0037431999158212786, Train_acc 0.9983552631578947\n",
      "\n",
      "Epoch 118. Loss: 0.0034259663426219745, Train_acc 0.9983974358974359\n",
      "\n",
      "Epoch 118. Loss: 0.003123279668829008, Train_acc 0.9984375\n",
      "\n",
      "Epoch 118. Loss: 0.006363261498160211, Train_acc 0.9982850609756098\n",
      "\n",
      "Epoch 118. Loss: 0.006452086760533197, Train_acc 0.9981398809523809\n",
      "\n",
      "Epoch 118. Loss: 0.005822445809247484, Train_acc 0.9981831395348837\n",
      "\n",
      "Epoch 118. Loss: 0.0058237376855931194, Train_acc 0.998046875\n",
      "\n",
      "Epoch 118. Loss: 0.005324897347040163, Train_acc 0.9980902777777778\n",
      "\n",
      "Epoch 118. Loss: 0.005052487147991825, Train_acc 0.9981317934782609\n",
      "\n",
      "Epoch 118. Loss: 0.005389821053872975, Train_acc 0.9981715425531915\n",
      "\n",
      "Epoch 118. Loss: 0.004878871417466788, Train_acc 0.9982096354166666\n",
      "\n",
      "Epoch 118. Loss: 0.004446120271801044, Train_acc 0.9982461734693877\n",
      "\n",
      "Epoch 118. Loss: 0.004114505507825246, Train_acc 0.99828125\n",
      "\n",
      "Epoch 118. Loss: 0.003785743130321888, Train_acc 0.9983149509803921\n",
      "\n",
      "Epoch 118. Loss: 0.0036183723579650416, Train_acc 0.9983473557692307\n",
      "\n",
      "Epoch 118. Loss: 0.0032858101850117634, Train_acc 0.9983785377358491\n",
      "\n",
      "Epoch 118. Loss: 0.0029761796949757985, Train_acc 0.9984085648148148\n",
      "\n",
      "Epoch 118. Loss: 0.003314806989218639, Train_acc 0.9984375\n",
      "\n",
      "Epoch 118. Loss: 0.0032387707266308486, Train_acc 0.9984654017857143\n",
      "\n",
      "Epoch 118. Loss: 0.0033528738457498804, Train_acc 0.9984923245614035\n",
      "\n",
      "Epoch 118. Loss: 0.0031267041255716556, Train_acc 0.9985183189655172\n",
      "\n",
      "Epoch 118. Loss: 0.003129503100001878, Train_acc 0.9985434322033898\n",
      "\n",
      "Epoch 118. Loss: 0.002887147367120445, Train_acc 0.9985677083333333\n",
      "\n",
      "Epoch 118. Loss: 0.0026668650082925646, Train_acc 0.9985911885245902\n",
      "\n",
      "Epoch 118. Loss: 0.002405834892937448, Train_acc 0.9986139112903226\n",
      "\n",
      "Epoch 118. Loss: 0.0021828454986139666, Train_acc 0.9986359126984127\n",
      "\n",
      "Epoch 118. Loss: 0.0027167692375115633, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 118. Loss: 0.002459015181707665, Train_acc 0.9985576923076923\n",
      "\n",
      "Epoch 118. Loss: 0.002216484128301783, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 118. Loss: 0.0020173483927136532, Train_acc 0.9986007462686567\n",
      "\n",
      "Epoch 118. Loss: 0.0027509992090540415, Train_acc 0.9985064338235294\n",
      "\n",
      "Epoch 118. Loss: 0.0024877522436524925, Train_acc 0.9985280797101449\n",
      "\n",
      "Epoch 118. Loss: 0.002326522418142825, Train_acc 0.9985491071428572\n",
      "\n",
      "Epoch 118. Loss: 0.0021126033981332657, Train_acc 0.9985695422535211\n",
      "\n",
      "Epoch 118. Loss: 0.002119208302805377, Train_acc 0.9985894097222222\n",
      "\n",
      "Epoch 118. Loss: 0.0019222343994920804, Train_acc 0.9986087328767124\n",
      "\n",
      "Epoch 118. Loss: 0.0017551409995551724, Train_acc 0.9986275337837838\n",
      "\n",
      "Epoch 118. Loss: 0.0015972178469906549, Train_acc 0.9986458333333333\n",
      "\n",
      "Epoch 118. Loss: 0.001455550136026264, Train_acc 0.9986636513157895\n",
      "\n",
      "Epoch 118. Loss: 0.0013273499358862266, Train_acc 0.9986810064935064\n",
      "\n",
      "Epoch 118. Loss: 0.0012063558116744125, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 118. Loss: 0.001095042989940388, Train_acc 0.9987143987341772\n",
      "\n",
      "Epoch 118. Loss: 0.0019746295284845915, Train_acc 0.9986328125\n",
      "\n",
      "Epoch 118. Loss: 0.0017841865032158092, Train_acc 0.9986496913580247\n",
      "\n",
      "Epoch 118. Loss: 0.0016101465307348057, Train_acc 0.9986661585365854\n",
      "\n",
      "Epoch 118. Loss: 0.0014555028051013276, Train_acc 0.9986822289156626\n",
      "\n",
      "Epoch 118. Loss: 0.0013266641113864766, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 118. Loss: 0.003281610895428722, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 118. Loss: 0.0029595585973077156, Train_acc 0.9986373546511628\n",
      "\n",
      "Epoch 118. Loss: 0.0034792453626704043, Train_acc 0.9985632183908046\n",
      "\n",
      "Epoch 118. Loss: 0.0032169189985576416, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 118. Loss: 0.006431709999082966, Train_acc 0.9984199438202247\n",
      "\n",
      "Epoch 118. Loss: 0.005904192510777102, Train_acc 0.9984375\n",
      "\n",
      "Epoch 118. Loss: 0.005316454718017358, Train_acc 0.9984546703296703\n",
      "\n",
      "Epoch 118. Loss: 0.005711560982767146, Train_acc 0.9983865489130435\n",
      "\n",
      "Epoch 118. Loss: 0.013222788755568923, Train_acc 0.9983198924731183\n",
      "\n",
      "Epoch 118. Loss: 0.011912495300145017, Train_acc 0.9983377659574468\n",
      "\n",
      "Epoch 118. Loss: 0.010822825484231323, Train_acc 0.9983552631578947\n",
      "\n",
      "Epoch 118. Loss: 0.01203104792036582, Train_acc 0.998291015625\n",
      "\n",
      "Epoch 118. Loss: 0.010962018572986593, Train_acc 0.9983086340206185\n",
      "\n",
      "Epoch 118. Loss: 0.01034407623629314, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 118. Loss: 0.009822375101034722, Train_acc 0.998342803030303\n",
      "\n",
      "Epoch 118. Loss: 0.009002165390455617, Train_acc 0.998359375\n",
      "\n",
      "[Epoch 118 Batch 100] Loss: 0.011368312442365788 Training: accuracy=0.998221\n",
      "Epoch 118. Loss: 0.011368312442365788, Train_acc 0.9982209158415841\n",
      "\n",
      "Epoch 118. Loss: 0.010325175974425825, Train_acc 0.9982383578431373\n",
      "\n",
      "Epoch 118. Loss: 0.009580286061867017, Train_acc 0.9982554611650486\n",
      "\n",
      "Epoch 118. Loss: 0.008653641286035796, Train_acc 0.9982722355769231\n",
      "\n",
      "Epoch 118. Loss: 0.00793263463614397, Train_acc 0.9982886904761905\n",
      "\n",
      "Epoch 118. Loss: 0.007273427164186652, Train_acc 0.9983048349056604\n",
      "\n",
      "Epoch 118. Loss: 0.006602448491616576, Train_acc 0.9983206775700935\n",
      "\n",
      "Epoch 118. Loss: 0.006038804040410545, Train_acc 0.9983362268518519\n",
      "\n",
      "Epoch 118. Loss: 0.0055571369883754195, Train_acc 0.9983514908256881\n",
      "\n",
      "Epoch 118. Loss: 0.005071606047455669, Train_acc 0.9983664772727273\n",
      "\n",
      "Epoch 118. Loss: 0.00617093590572852, Train_acc 0.9983811936936937\n",
      "\n",
      "Epoch 118. Loss: 0.0069140831732038685, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 118. Loss: 0.008453414635653855, Train_acc 0.9982715707964602\n",
      "\n",
      "Epoch 118. Loss: 0.007733286220974978, Train_acc 0.9982867324561403\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118. Loss: 0.007259745446202686, Train_acc 0.9983016304347826\n",
      "\n",
      "Epoch 118. Loss: 0.008062095926574645, Train_acc 0.9982489224137931\n",
      "\n",
      "Epoch 118. Loss: 0.007439641365238379, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 118. Loss: 0.0067732981107898205, Train_acc 0.9982786016949152\n",
      "\n",
      "Epoch 118. Loss: 0.00788599003216037, Train_acc 0.9982274159663865\n",
      "\n",
      "Epoch 118. Loss: 0.00791393815452226, Train_acc 0.9981770833333333\n",
      "\n",
      "Epoch 118. Loss: 0.007202086225295377, Train_acc 0.9981921487603306\n",
      "\n",
      "Epoch 118. Loss: 0.006566994915612545, Train_acc 0.9982069672131147\n",
      "\n",
      "Epoch 118. Loss: 0.005934326119254982, Train_acc 0.9982215447154471\n",
      "\n",
      "Epoch 118. Loss: 0.005361356698651535, Train_acc 0.9982358870967742\n",
      "\n",
      "Epoch 118. Loss: 0.008152847763758382, Train_acc 0.998125\n",
      "\n",
      "Epoch 118. Loss: 0.0075021342288581865, Train_acc 0.9981398809523809\n",
      "\n",
      "Epoch 118. Loss: 0.006810688203394711, Train_acc 0.9981545275590551\n",
      "\n",
      "Epoch 118. Loss: 0.006770595066982777, Train_acc 0.99810791015625\n",
      "\n",
      "Epoch 118. Loss: 0.006142006144727338, Train_acc 0.9981225775193798\n",
      "\n",
      "Epoch 118. Loss: 0.005735640104648532, Train_acc 0.9981370192307693\n",
      "\n",
      "Epoch 118. Loss: 0.005243350694417562, Train_acc 0.9981512404580153\n",
      "\n",
      "Epoch 118. Loss: 0.0047817884312439905, Train_acc 0.9981652462121212\n",
      "\n",
      "Epoch 118. Loss: 0.004434379955224152, Train_acc 0.9981790413533834\n",
      "\n",
      "Epoch 118. Loss: 0.010783706325374802, Train_acc 0.9981343283582089\n",
      "\n",
      "Epoch 118. Loss: 0.009813270472790535, Train_acc 0.9981481481481481\n",
      "\n",
      "Epoch 118. Loss: 0.008997401763380977, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 118. Loss: 0.008434516934311163, Train_acc 0.9981751824817519\n",
      "\n",
      "Epoch 118. Loss: 0.0076703056987333495, Train_acc 0.9981884057971014\n",
      "\n",
      "Epoch 118. Loss: 0.007089045297760505, Train_acc 0.9982014388489209\n",
      "\n",
      "Epoch 118. Loss: 0.0065505992952663355, Train_acc 0.9982142857142857\n",
      "\n",
      "Epoch 118. Loss: 0.006616152489588737, Train_acc 0.9981715425531915\n",
      "\n",
      "Epoch 118. Loss: 0.007158995305960846, Train_acc 0.9981294014084507\n",
      "\n",
      "Epoch 118. Loss: 0.006468439836215091, Train_acc 0.9981424825174825\n",
      "\n",
      "Epoch 118. Loss: 0.006932976981023949, Train_acc 0.9981011284722222\n",
      "\n",
      "Epoch 118. Loss: 0.006264351938775928, Train_acc 0.998114224137931\n",
      "\n",
      "Epoch 118. Loss: 0.005726218721109705, Train_acc 0.998127140410959\n",
      "\n",
      "Epoch 118. Loss: 0.005190692969648684, Train_acc 0.9981398809523809\n",
      "\n",
      "Epoch 118. Loss: 0.0046937054444328875, Train_acc 0.9981524493243243\n",
      "\n",
      "Epoch 118. Loss: 0.00604697173526668, Train_acc 0.9981124161073825\n",
      "\n",
      "Epoch 118. Loss: 0.011766562810755821, Train_acc 0.9980729166666666\n",
      "\n",
      "Epoch 118. Loss: 0.010619900483329194, Train_acc 0.9980856788079471\n",
      "\n",
      "Epoch 118. Loss: 0.009596024351521891, Train_acc 0.9980982730263158\n",
      "\n",
      "Epoch 118. Loss: 0.009484342039857414, Train_acc 0.9981107026143791\n",
      "\n",
      "Epoch 118. Loss: 0.008552614406621774, Train_acc 0.9981229707792207\n",
      "\n",
      "Epoch 118. Loss: 0.007713372062033757, Train_acc 0.9981350806451613\n",
      "\n",
      "Epoch 118. Loss: 0.007216280646036277, Train_acc 0.9981470352564102\n",
      "\n",
      "Epoch 118. Loss: 0.008954542418042014, Train_acc 0.998109076433121\n",
      "\n",
      "Epoch 118. Loss: 0.008104745124588184, Train_acc 0.9981210443037974\n",
      "\n",
      "Epoch 118. Loss: 0.007438841619824415, Train_acc 0.9981328616352201\n",
      "\n",
      "Epoch 118. Loss: 0.006842185016614984, Train_acc 0.99814453125\n",
      "\n",
      "Epoch 118. Loss: 0.006208608681705854, Train_acc 0.9981560559006211\n",
      "\n",
      "Epoch 118. Loss: 0.005594306583645401, Train_acc 0.9981674382716049\n",
      "\n",
      "Epoch 118. Loss: 0.005156169363413714, Train_acc 0.9981786809815951\n",
      "\n",
      "Epoch 118. Loss: 0.004964624324266132, Train_acc 0.9981897865853658\n",
      "\n",
      "Epoch 118. Loss: 0.004497770761066168, Train_acc 0.9982007575757575\n",
      "\n",
      "Epoch 118. Loss: 0.006808308440101287, Train_acc 0.9981174698795181\n",
      "\n",
      "Epoch 118. Loss: 0.008457812825726397, Train_acc 0.9980819610778443\n",
      "\n",
      "Epoch 118. Loss: 0.008045264224979516, Train_acc 0.9980933779761905\n",
      "\n",
      "Epoch 118. Loss: 0.007286205200494553, Train_acc 0.9981046597633136\n",
      "\n",
      "Epoch 118. Loss: 0.007492363206870459, Train_acc 0.9980698529411764\n",
      "\n",
      "Epoch 118. Loss: 0.006778286830856482, Train_acc 0.9980811403508771\n",
      "\n",
      "Epoch 118. Loss: 0.0062237301807134575, Train_acc 0.9980922965116279\n",
      "\n",
      "Epoch 118. Loss: 0.00733907209401094, Train_acc 0.9980581647398844\n",
      "\n",
      "Epoch 118. Loss: 0.00860508716760364, Train_acc 0.9980244252873564\n",
      "\n",
      "Epoch 118. Loss: 0.007822550581227572, Train_acc 0.9980357142857142\n",
      "\n",
      "Epoch 118. Loss: 0.007060174254214017, Train_acc 0.998046875\n",
      "\n",
      "Epoch 118. Loss: 0.006402524740742369, Train_acc 0.9980579096045198\n",
      "\n",
      "Epoch 118. Loss: 0.005974405616518907, Train_acc 0.9980688202247191\n",
      "\n",
      "Epoch 118. Loss: 0.005419982582654031, Train_acc 0.9980796089385475\n",
      "\n",
      "Epoch 118. Loss: 0.006860228614800101, Train_acc 0.998046875\n",
      "\n",
      "Epoch 118. Loss: 0.007120012536012761, Train_acc 0.9980576657458563\n",
      "\n",
      "Epoch 118. Loss: 0.006967048833695322, Train_acc 0.9980683379120879\n",
      "\n",
      "Epoch 118. Loss: 0.006291876922785471, Train_acc 0.9980788934426229\n",
      "\n",
      "Epoch 118. Loss: 0.006155789422904757, Train_acc 0.9980893342391305\n",
      "\n",
      "Epoch 118. Loss: 0.005551715356488661, Train_acc 0.9980996621621622\n",
      "\n",
      "Epoch 118. Loss: 0.005001631490909565, Train_acc 0.9981098790322581\n",
      "\n",
      "Epoch 118. Loss: 0.011439365547171391, Train_acc 0.9980364304812834\n",
      "\n",
      "Epoch 118. Loss: 0.010302772307973645, Train_acc 0.998046875\n",
      "\n",
      "Epoch 118. Loss: 0.009308537010520958, Train_acc 0.998057208994709\n",
      "\n",
      "Epoch 118. Loss: 0.008390116288306613, Train_acc 0.9980674342105263\n",
      "\n",
      "Epoch 118. Loss: 0.007660392138902663, Train_acc 0.9980775523560209\n",
      "\n",
      "Epoch 118. Loss: 0.007028832808139311, Train_acc 0.9980875651041666\n",
      "\n",
      "Epoch 118. Loss: 0.006401124209167708, Train_acc 0.9980974740932642\n",
      "\n",
      "Epoch 118. Loss: 0.005769525913034624, Train_acc 0.9981072809278351\n",
      "\n",
      "Epoch 118. Loss: 0.005243052541957569, Train_acc 0.9981169871794872\n",
      "\n",
      "Epoch 118. Loss: 0.005059443292912488, Train_acc 0.99812\n",
      "\n",
      "Epoch 119. Loss: 0.004563500655028764, Train_acc 1.0\n",
      "\n",
      "Epoch 119. Loss: 0.004117502321433464, Train_acc 1.0\n",
      "\n",
      "Epoch 119. Loss: 0.0037097193964925196, Train_acc 1.0\n",
      "\n",
      "Epoch 119. Loss: 0.003356779299617048, Train_acc 1.0\n",
      "\n",
      "Epoch 119. Loss: 0.0030849323911989355, Train_acc 1.0\n",
      "\n",
      "Epoch 119. Loss: 0.004832421652393754, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 119. Loss: 0.004402219960876301, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 119. Loss: 0.00416566671002328, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 119. Loss: 0.003793288169435065, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 119. Loss: 0.0034371763278787447, Train_acc 0.99921875\n",
      "\n",
      "Epoch 119. Loss: 0.0031600386840156566, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 119. Loss: 0.0029074834826746747, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 119. Loss: 0.0031121502687626334, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 119. Loss: 0.0030129041201704667, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 119. Loss: 0.002733830437274703, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 119. Loss: 0.0025206342837339746, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 119. Loss: 0.0023909589118399715, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 119. Loss: 0.0027875332392726985, Train_acc 0.9995659722222222\n",
      "\n",
      "Epoch 119. Loss: 0.002516470049570842, Train_acc 0.9995888157894737\n",
      "\n",
      "Epoch 119. Loss: 0.002583199857697645, Train_acc 0.999609375\n",
      "\n",
      "Epoch 119. Loss: 0.002349135082810865, Train_acc 0.9996279761904762\n",
      "\n",
      "Epoch 119. Loss: 0.0022214653131326255, Train_acc 0.9996448863636364\n",
      "\n",
      "Epoch 119. Loss: 0.00215517207565548, Train_acc 0.9996603260869565\n",
      "\n",
      "Epoch 119. Loss: 0.003613516833627003, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 119. Loss: 0.003387289171008418, Train_acc 0.999375\n",
      "\n",
      "Epoch 119. Loss: 0.006436337761212722, Train_acc 0.9990985576923077\n",
      "\n",
      "Epoch 119. Loss: 0.006047696334164741, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 119. Loss: 0.005476450305836971, Train_acc 0.9991629464285714\n",
      "\n",
      "Epoch 119. Loss: 0.004956333619324744, Train_acc 0.9991918103448276\n",
      "\n",
      "Epoch 119. Loss: 0.004481958038583068, Train_acc 0.99921875\n",
      "\n",
      "Epoch 119. Loss: 0.004491856479547621, Train_acc 0.9992439516129032\n",
      "\n",
      "Epoch 119. Loss: 0.004163580972278596, Train_acc 0.999267578125\n",
      "\n",
      "Epoch 119. Loss: 0.0037907564166621325, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 119. Loss: 0.003426002836902488, Train_acc 0.9993106617647058\n",
      "\n",
      "Epoch 119. Loss: 0.0031468032862640607, Train_acc 0.9993303571428571\n",
      "\n",
      "Epoch 119. Loss: 0.0031658515756261816, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 119. Loss: 0.002931347537826297, Train_acc 0.9993665540540541\n",
      "\n",
      "Epoch 119. Loss: 0.002677218907595766, Train_acc 0.9993832236842105\n",
      "\n",
      "Epoch 119. Loss: 0.0024438914172633074, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 119. Loss: 0.00221240976904726, Train_acc 0.9994140625\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119. Loss: 0.0020143272266299477, Train_acc 0.9994283536585366\n",
      "\n",
      "Epoch 119. Loss: 0.001847108134682338, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 119. Loss: 0.0019259564875561243, Train_acc 0.9994549418604651\n",
      "\n",
      "Epoch 119. Loss: 0.0018208106257522772, Train_acc 0.9994673295454546\n",
      "\n",
      "Epoch 119. Loss: 0.001765245637119234, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 119. Loss: 0.0016384921625141088, Train_acc 0.9994904891304348\n",
      "\n",
      "Epoch 119. Loss: 0.0014965908433020518, Train_acc 0.999501329787234\n",
      "\n",
      "Epoch 119. Loss: 0.0013538268776849929, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 119. Loss: 0.0012277872703719307, Train_acc 0.9995216836734694\n",
      "\n",
      "Epoch 119. Loss: 0.0012567512936478707, Train_acc 0.99953125\n",
      "\n",
      "Epoch 119. Loss: 0.0012534931732530164, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 119. Loss: 0.0016836949545873496, Train_acc 0.9995492788461539\n",
      "\n",
      "Epoch 119. Loss: 0.0015246649365298415, Train_acc 0.9995577830188679\n",
      "\n",
      "Epoch 119. Loss: 0.0013863886949904791, Train_acc 0.9995659722222222\n",
      "\n",
      "Epoch 119. Loss: 0.0012835363523511693, Train_acc 0.9995738636363637\n",
      "\n",
      "Epoch 119. Loss: 0.0012393155928975587, Train_acc 0.9995814732142857\n",
      "\n",
      "Epoch 119. Loss: 0.0011244592489560782, Train_acc 0.9995888157894737\n",
      "\n",
      "Epoch 119. Loss: 0.0010191163074239086, Train_acc 0.9995959051724138\n",
      "\n",
      "Epoch 119. Loss: 0.0009395145729848586, Train_acc 0.9996027542372882\n",
      "\n",
      "Epoch 119. Loss: 0.0008541762873534661, Train_acc 0.999609375\n",
      "\n",
      "Epoch 119. Loss: 0.0007719531052353913, Train_acc 0.9996157786885246\n",
      "\n",
      "Epoch 119. Loss: 0.0006999315360860169, Train_acc 0.9996219758064516\n",
      "\n",
      "Epoch 119. Loss: 0.0009085445551284678, Train_acc 0.9996279761904762\n",
      "\n",
      "Epoch 119. Loss: 0.0008279328063915192, Train_acc 0.9996337890625\n",
      "\n",
      "Epoch 119. Loss: 0.0009468563585689681, Train_acc 0.9996394230769231\n",
      "\n",
      "Epoch 119. Loss: 0.0008607186595983874, Train_acc 0.9996448863636364\n",
      "\n",
      "Epoch 119. Loss: 0.0007933655522947263, Train_acc 0.9996501865671642\n",
      "\n",
      "Epoch 119. Loss: 0.0007393851534675212, Train_acc 0.9996553308823529\n",
      "\n",
      "Epoch 119. Loss: 0.000688667532338726, Train_acc 0.9996603260869565\n",
      "\n",
      "Epoch 119. Loss: 0.000674867106436441, Train_acc 0.9996651785714286\n",
      "\n",
      "Epoch 119. Loss: 0.0006335731563534585, Train_acc 0.9996698943661971\n",
      "\n",
      "Epoch 119. Loss: 0.0005772304401140285, Train_acc 0.9996744791666666\n",
      "\n",
      "Epoch 119. Loss: 0.0005261932837406396, Train_acc 0.9996789383561644\n",
      "\n",
      "Epoch 119. Loss: 0.0004854457577834386, Train_acc 0.999683277027027\n",
      "\n",
      "Epoch 119. Loss: 0.00045552552346969617, Train_acc 0.9996875\n",
      "\n",
      "Epoch 119. Loss: 0.00041261000626337783, Train_acc 0.9996916118421053\n",
      "\n",
      "Epoch 119. Loss: 0.0003941016978032903, Train_acc 0.9996956168831169\n",
      "\n",
      "Epoch 119. Loss: 0.0003569369336536355, Train_acc 0.9996995192307693\n",
      "\n",
      "Epoch 119. Loss: 0.0003286521391068114, Train_acc 0.9997033227848101\n",
      "\n",
      "Epoch 119. Loss: 0.00030043668811891174, Train_acc 0.99970703125\n",
      "\n",
      "Epoch 119. Loss: 0.00029870903817712095, Train_acc 0.9997106481481481\n",
      "\n",
      "Epoch 119. Loss: 0.0002709562161888031, Train_acc 0.9997141768292683\n",
      "\n",
      "Epoch 119. Loss: 0.0002584071459623365, Train_acc 0.9997176204819277\n",
      "\n",
      "Epoch 119. Loss: 0.0002356299278448197, Train_acc 0.9997209821428571\n",
      "\n",
      "Epoch 119. Loss: 0.000318394764477179, Train_acc 0.9997242647058824\n",
      "\n",
      "Epoch 119. Loss: 0.00035321458489224214, Train_acc 0.9997274709302325\n",
      "\n",
      "Epoch 119. Loss: 0.0003219992174037397, Train_acc 0.9997306034482759\n",
      "\n",
      "Epoch 119. Loss: 0.00029133537600788763, Train_acc 0.9997336647727273\n",
      "\n",
      "Epoch 119. Loss: 0.00026406570919139, Train_acc 0.9997366573033708\n",
      "\n",
      "Epoch 119. Loss: 0.0002417553681676183, Train_acc 0.9997395833333333\n",
      "\n",
      "Epoch 119. Loss: 0.0002188241439760602, Train_acc 0.999742445054945\n",
      "\n",
      "Epoch 119. Loss: 0.0002077025230990575, Train_acc 0.9997452445652174\n",
      "\n",
      "Epoch 119. Loss: 0.00019230400297532855, Train_acc 0.9997479838709677\n",
      "\n",
      "Epoch 119. Loss: 0.00017430874896064762, Train_acc 0.999750664893617\n",
      "\n",
      "Epoch 119. Loss: 0.0001583011323189456, Train_acc 0.9997532894736842\n",
      "\n",
      "Epoch 119. Loss: 0.00016878818106061687, Train_acc 0.999755859375\n",
      "\n",
      "Epoch 119. Loss: 0.00018223492564773384, Train_acc 0.9997583762886598\n",
      "\n",
      "Epoch 119. Loss: 0.00016475710859860588, Train_acc 0.9997608418367347\n",
      "\n",
      "Epoch 119. Loss: 0.00014945387119644538, Train_acc 0.9997632575757576\n",
      "\n",
      "Epoch 119. Loss: 0.0001350658524888472, Train_acc 0.999765625\n",
      "\n",
      "[Epoch 119 Batch 100] Loss: 0.00013529810002571043 Training: accuracy=0.999768\n",
      "Epoch 119. Loss: 0.00013529810002571043, Train_acc 0.9997679455445545\n",
      "\n",
      "Epoch 119. Loss: 0.0007706968633782181, Train_acc 0.9996936274509803\n",
      "\n",
      "Epoch 119. Loss: 0.00069576103623818, Train_acc 0.9996966019417476\n",
      "\n",
      "Epoch 119. Loss: 0.0006499256809071285, Train_acc 0.9996995192307693\n",
      "\n",
      "Epoch 119. Loss: 0.000587533109331034, Train_acc 0.999702380952381\n",
      "\n",
      "Epoch 119. Loss: 0.0005316657254948712, Train_acc 0.9997051886792453\n",
      "\n",
      "Epoch 119. Loss: 0.00047989552853725073, Train_acc 0.9997079439252337\n",
      "\n",
      "Epoch 119. Loss: 0.00043500266471708057, Train_acc 0.9997106481481481\n",
      "\n",
      "Epoch 119. Loss: 0.00044124624616686316, Train_acc 0.9997133027522935\n",
      "\n",
      "Epoch 119. Loss: 0.0003996564906043928, Train_acc 0.9997159090909091\n",
      "\n",
      "Epoch 119. Loss: 0.0006328936203154732, Train_acc 0.9997184684684685\n",
      "\n",
      "Epoch 119. Loss: 0.000586663167281495, Train_acc 0.9997209821428571\n",
      "\n",
      "Epoch 119. Loss: 0.0005411381787894337, Train_acc 0.9997234513274337\n",
      "\n",
      "Epoch 119. Loss: 0.0004895321630385837, Train_acc 0.9997258771929824\n",
      "\n",
      "Epoch 119. Loss: 0.00044830850064330065, Train_acc 0.9997282608695652\n",
      "\n",
      "Epoch 119. Loss: 0.00040627056547175023, Train_acc 0.9997306034482759\n",
      "\n",
      "Epoch 119. Loss: 0.0003664871405666309, Train_acc 0.999732905982906\n",
      "\n",
      "Epoch 119. Loss: 0.00033369248052172155, Train_acc 0.9997351694915254\n",
      "\n",
      "Epoch 119. Loss: 0.0003026728159889392, Train_acc 0.9997373949579832\n",
      "\n",
      "Epoch 119. Loss: 0.00029846263617618193, Train_acc 0.9997395833333333\n",
      "\n",
      "Epoch 119. Loss: 0.0002797230607385708, Train_acc 0.99974173553719\n",
      "\n",
      "Epoch 119. Loss: 0.000252850572228668, Train_acc 0.9997438524590164\n",
      "\n",
      "Epoch 119. Loss: 0.00025482741350943996, Train_acc 0.9997459349593496\n",
      "\n",
      "Epoch 119. Loss: 0.00023089027855052423, Train_acc 0.9997479838709677\n",
      "\n",
      "Epoch 119. Loss: 0.00022558739020138715, Train_acc 0.99975\n",
      "\n",
      "Epoch 119. Loss: 0.00020955546164756032, Train_acc 0.9997519841269841\n",
      "\n",
      "Epoch 119. Loss: 0.00019244623988098664, Train_acc 0.999753937007874\n",
      "\n",
      "Epoch 119. Loss: 0.00017424050913525458, Train_acc 0.999755859375\n",
      "\n",
      "Epoch 119. Loss: 0.00015773048348040949, Train_acc 0.9997577519379846\n",
      "\n",
      "Epoch 119. Loss: 0.00017528854166566496, Train_acc 0.9997596153846153\n",
      "\n",
      "Epoch 119. Loss: 0.0001584382436699951, Train_acc 0.9997614503816794\n",
      "\n",
      "Epoch 119. Loss: 0.00016463024337973382, Train_acc 0.9997632575757576\n",
      "\n",
      "Epoch 119. Loss: 0.005361469965456899, Train_acc 0.9997062969924813\n",
      "\n",
      "Epoch 119. Loss: 0.004831339112654391, Train_acc 0.9997084888059702\n",
      "\n",
      "Epoch 119. Loss: 0.004379046181277987, Train_acc 0.9997106481481481\n",
      "\n",
      "Epoch 119. Loss: 0.003948837898674276, Train_acc 0.9997127757352942\n",
      "\n",
      "Epoch 119. Loss: 0.003559093014351148, Train_acc 0.9997148722627737\n",
      "\n",
      "Epoch 119. Loss: 0.003232840466674933, Train_acc 0.9997169384057971\n",
      "\n",
      "Epoch 119. Loss: 0.003231469092378112, Train_acc 0.9997189748201439\n",
      "\n",
      "Epoch 119. Loss: 0.008128542793639683, Train_acc 0.9996651785714286\n",
      "\n",
      "Epoch 119. Loss: 0.007333032668460399, Train_acc 0.9996675531914894\n",
      "\n",
      "Epoch 119. Loss: 0.0066349147219172035, Train_acc 0.9996698943661971\n",
      "\n",
      "Epoch 119. Loss: 0.005973170948204932, Train_acc 0.9996722027972028\n",
      "\n",
      "Epoch 119. Loss: 0.005905747713605348, Train_acc 0.9996744791666666\n",
      "\n",
      "Epoch 119. Loss: 0.0053179150960555, Train_acc 0.9996767241379311\n",
      "\n",
      "Epoch 119. Loss: 0.004802857794197454, Train_acc 0.9996789383561644\n",
      "\n",
      "Epoch 119. Loss: 0.004353119313734371, Train_acc 0.9996811224489796\n",
      "\n",
      "Epoch 119. Loss: 0.004418736505151628, Train_acc 0.999683277027027\n",
      "\n",
      "Epoch 119. Loss: 0.004407653701803839, Train_acc 0.9996854026845637\n",
      "\n",
      "Epoch 119. Loss: 0.00399236902622663, Train_acc 0.9996875\n",
      "\n",
      "Epoch 119. Loss: 0.003678112287560028, Train_acc 0.9996895695364238\n",
      "\n",
      "Epoch 119. Loss: 0.003317584228347396, Train_acc 0.9996916118421053\n",
      "\n",
      "Epoch 119. Loss: 0.0030989942807307736, Train_acc 0.9996936274509803\n",
      "\n",
      "Epoch 119. Loss: 0.0027915729539630106, Train_acc 0.9996956168831169\n",
      "\n",
      "Epoch 119. Loss: 0.004793732028338667, Train_acc 0.9996471774193548\n",
      "\n",
      "Epoch 119. Loss: 0.004325680931506698, Train_acc 0.9996494391025641\n",
      "\n",
      "Epoch 119. Loss: 0.004141784510662983, Train_acc 0.9996516719745223\n",
      "\n",
      "Epoch 119. Loss: 0.003745900677945276, Train_acc 0.9996538765822784\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119. Loss: 0.0038354854134971437, Train_acc 0.9996560534591195\n",
      "\n",
      "Epoch 119. Loss: 0.0045686150839854365, Train_acc 0.999609375\n",
      "\n",
      "Epoch 119. Loss: 0.004890211656772711, Train_acc 0.9995632763975155\n",
      "\n",
      "Epoch 119. Loss: 0.004480361623624595, Train_acc 0.9995659722222222\n",
      "\n",
      "Epoch 119. Loss: 0.005147246360534101, Train_acc 0.9995207055214724\n",
      "\n",
      "Epoch 119. Loss: 0.004656414415141123, Train_acc 0.9995236280487805\n",
      "\n",
      "Epoch 119. Loss: 0.00419992095000662, Train_acc 0.9995265151515151\n",
      "\n",
      "Epoch 119. Loss: 0.004419829140756585, Train_acc 0.9995293674698795\n",
      "\n",
      "Epoch 119. Loss: 0.005437406211186104, Train_acc 0.9994854041916168\n",
      "\n",
      "Epoch 119. Loss: 0.004899733083153941, Train_acc 0.9994884672619048\n",
      "\n",
      "Epoch 119. Loss: 0.006497416369651417, Train_acc 0.9994452662721893\n",
      "\n",
      "Epoch 119. Loss: 0.005886438217603856, Train_acc 0.9994485294117647\n",
      "\n",
      "Epoch 119. Loss: 0.005308829516976789, Train_acc 0.9994517543859649\n",
      "\n",
      "Epoch 119. Loss: 0.004905163494383289, Train_acc 0.9994549418604651\n",
      "\n",
      "Epoch 119. Loss: 0.004463995390319819, Train_acc 0.9994580924855492\n",
      "\n",
      "Epoch 119. Loss: 0.004168091944844123, Train_acc 0.9994612068965517\n",
      "\n",
      "Epoch 119. Loss: 0.0037754650241331868, Train_acc 0.9994642857142857\n",
      "\n",
      "Epoch 119. Loss: 0.004113449930506642, Train_acc 0.9994229403409091\n",
      "\n",
      "Epoch 119. Loss: 0.0037672967376964055, Train_acc 0.9994262005649718\n",
      "\n",
      "Epoch 119. Loss: 0.003539391107498714, Train_acc 0.9994294241573034\n",
      "\n",
      "Epoch 119. Loss: 0.0032142771143732077, Train_acc 0.9994326117318436\n",
      "\n",
      "Epoch 119. Loss: 0.0035456211720273742, Train_acc 0.9993923611111111\n",
      "\n",
      "Epoch 119. Loss: 0.0034814308351083863, Train_acc 0.9993957182320442\n",
      "\n",
      "Epoch 119. Loss: 0.0031543973710082564, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 119. Loss: 0.0028892425511409425, Train_acc 0.9994023224043715\n",
      "\n",
      "Epoch 119. Loss: 0.002952829129208289, Train_acc 0.999405570652174\n",
      "\n",
      "Epoch 119. Loss: 0.0029438567782200838, Train_acc 0.9994087837837838\n",
      "\n",
      "Epoch 119. Loss: 0.0030198585539839384, Train_acc 0.9994119623655914\n",
      "\n",
      "Epoch 119. Loss: 0.0030197498051254498, Train_acc 0.9994151069518716\n",
      "\n",
      "Epoch 119. Loss: 0.0029449953440587413, Train_acc 0.9994182180851063\n",
      "\n",
      "Epoch 119. Loss: 0.0026972040494773787, Train_acc 0.9994212962962963\n",
      "\n",
      "Epoch 119. Loss: 0.0030673365259612203, Train_acc 0.9994243421052632\n",
      "\n",
      "Epoch 119. Loss: 0.002846735374384263, Train_acc 0.9994273560209425\n",
      "\n",
      "Epoch 119. Loss: 0.00336110056378228, Train_acc 0.9993896484375\n",
      "\n",
      "Epoch 119. Loss: 0.0034696465590993994, Train_acc 0.999392810880829\n",
      "\n",
      "Epoch 119. Loss: 0.0031823574216127784, Train_acc 0.9993959407216495\n",
      "\n",
      "Epoch 119. Loss: 0.004696285013344323, Train_acc 0.9993589743589744\n",
      "\n",
      "Epoch 119. Loss: 0.004229656028082923, Train_acc 0.99936\n",
      "\n",
      "Epoch 120. Loss: 0.0038097387852149248, Train_acc 1.0\n",
      "\n",
      "Epoch 120. Loss: 0.003433450783104236, Train_acc 1.0\n",
      "\n",
      "Epoch 120. Loss: 0.003097117012546504, Train_acc 1.0\n",
      "\n",
      "Epoch 120. Loss: 0.002848559350868503, Train_acc 1.0\n",
      "\n",
      "Epoch 120. Loss: 0.0025810844445195258, Train_acc 1.0\n",
      "\n",
      "Epoch 120. Loss: 0.002531357982587796, Train_acc 1.0\n",
      "\n",
      "Epoch 120. Loss: 0.0023019965111661725, Train_acc 1.0\n",
      "\n",
      "Epoch 120. Loss: 0.002097161372161547, Train_acc 1.0\n",
      "\n",
      "Epoch 120. Loss: 0.0019984282220437883, Train_acc 1.0\n",
      "\n",
      "Epoch 120. Loss: 0.0033671648873419844, Train_acc 0.99921875\n",
      "\n",
      "Epoch 120. Loss: 0.0030924434457523776, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 120. Loss: 0.0028567993880278452, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 120. Loss: 0.0025856972785040667, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 120. Loss: 0.0023347820668837647, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 120. Loss: 0.0021163757706521426, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 120. Loss: 0.0019084166310839295, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 120. Loss: 0.001866431083968649, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 120. Loss: 0.0017394329990015505, Train_acc 0.9995659722222222\n",
      "\n",
      "Epoch 120. Loss: 0.0015720185075456682, Train_acc 0.9995888157894737\n",
      "\n",
      "Epoch 120. Loss: 0.001874285114638935, Train_acc 0.999609375\n",
      "\n",
      "Epoch 120. Loss: 0.001719632830628765, Train_acc 0.9996279761904762\n",
      "\n",
      "Epoch 120. Loss: 0.001571982515000414, Train_acc 0.9996448863636364\n",
      "\n",
      "Epoch 120. Loss: 0.0015040875569986055, Train_acc 0.9996603260869565\n",
      "\n",
      "Epoch 120. Loss: 0.0015147265700778442, Train_acc 0.9996744791666666\n",
      "\n",
      "Epoch 120. Loss: 0.0014865193918300638, Train_acc 0.9996875\n",
      "\n",
      "Epoch 120. Loss: 0.0013568320440831454, Train_acc 0.9996995192307693\n",
      "\n",
      "Epoch 120. Loss: 0.001221680226006035, Train_acc 0.9997106481481481\n",
      "\n",
      "Epoch 120. Loss: 0.0011370771343771435, Train_acc 0.9997209821428571\n",
      "\n",
      "Epoch 120. Loss: 0.003485935692363723, Train_acc 0.9994612068965517\n",
      "\n",
      "Epoch 120. Loss: 0.003587606785631547, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 120. Loss: 0.0032501080966730743, Train_acc 0.9994959677419355\n",
      "\n",
      "Epoch 120. Loss: 0.0029288787535177766, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 120. Loss: 0.0027760261004504947, Train_acc 0.9995265151515151\n",
      "\n",
      "Epoch 120. Loss: 0.002513548742362661, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 120. Loss: 0.0025777025103603034, Train_acc 0.9995535714285714\n",
      "\n",
      "Epoch 120. Loss: 0.002415907320737174, Train_acc 0.9995659722222222\n",
      "\n",
      "Epoch 120. Loss: 0.004353205729150173, Train_acc 0.9993665540540541\n",
      "\n",
      "Epoch 120. Loss: 0.004219363633430061, Train_acc 0.9993832236842105\n",
      "\n",
      "Epoch 120. Loss: 0.0041065635937178645, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 120. Loss: 0.00370633085489767, Train_acc 0.9994140625\n",
      "\n",
      "Epoch 120. Loss: 0.0033468670206370514, Train_acc 0.9994283536585366\n",
      "\n",
      "Epoch 120. Loss: 0.003484077695274582, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 120. Loss: 0.00566586381339809, Train_acc 0.9990915697674418\n",
      "\n",
      "Epoch 120. Loss: 0.0051269790312324605, Train_acc 0.9991122159090909\n",
      "\n",
      "Epoch 120. Loss: 0.004917937223748086, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 120. Loss: 0.004570717268111454, Train_acc 0.9991508152173914\n",
      "\n",
      "Epoch 120. Loss: 0.0041165553422693735, Train_acc 0.9991688829787234\n",
      "\n",
      "Epoch 120. Loss: 0.003760367581969812, Train_acc 0.9991861979166666\n",
      "\n",
      "Epoch 120. Loss: 0.003388851034996111, Train_acc 0.9992028061224489\n",
      "\n",
      "Epoch 120. Loss: 0.0033033165451352587, Train_acc 0.99921875\n",
      "\n",
      "Epoch 120. Loss: 0.0030767126769578267, Train_acc 0.999234068627451\n",
      "\n",
      "Epoch 120. Loss: 0.0028040097808815145, Train_acc 0.9992487980769231\n",
      "\n",
      "Epoch 120. Loss: 0.003746740351406673, Train_acc 0.9991155660377359\n",
      "\n",
      "Epoch 120. Loss: 0.007529271987338012, Train_acc 0.9989872685185185\n",
      "\n",
      "Epoch 120. Loss: 0.007096400543459487, Train_acc 0.9990056818181818\n",
      "\n",
      "Epoch 120. Loss: 0.006402791794244574, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 120. Loss: 0.0057980133915412815, Train_acc 0.9990405701754386\n",
      "\n",
      "Epoch 120. Loss: 0.005440546644058978, Train_acc 0.9990571120689655\n",
      "\n",
      "Epoch 120. Loss: 0.005343849798137386, Train_acc 0.999073093220339\n",
      "\n",
      "Epoch 120. Loss: 0.006015852025235689, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 120. Loss: 0.007891760891155895, Train_acc 0.9988473360655737\n",
      "\n",
      "Epoch 120. Loss: 0.0071298952602850615, Train_acc 0.9988659274193549\n",
      "\n",
      "Epoch 120. Loss: 0.006429701373015245, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 120. Loss: 0.006164188661643327, Train_acc 0.9989013671875\n",
      "\n",
      "Epoch 120. Loss: 0.005598812285419295, Train_acc 0.9989182692307692\n",
      "\n",
      "Epoch 120. Loss: 0.009097574114819755, Train_acc 0.9988162878787878\n",
      "\n",
      "Epoch 120. Loss: 0.00960067961515819, Train_acc 0.9987173507462687\n",
      "\n",
      "Epoch 120. Loss: 0.008787508045749383, Train_acc 0.9987362132352942\n",
      "\n",
      "Epoch 120. Loss: 0.007918906711646688, Train_acc 0.9987545289855072\n",
      "\n",
      "Epoch 120. Loss: 0.008372500262208675, Train_acc 0.9986607142857142\n",
      "\n",
      "Epoch 120. Loss: 0.007559005760295297, Train_acc 0.9986795774647887\n",
      "\n",
      "Epoch 120. Loss: 0.006853531982672755, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 120. Loss: 0.006287672767625789, Train_acc 0.9987157534246576\n",
      "\n",
      "Epoch 120. Loss: 0.005942391002181059, Train_acc 0.9987331081081081\n",
      "\n",
      "Epoch 120. Loss: 0.007262586968245703, Train_acc 0.9986458333333333\n",
      "\n",
      "Epoch 120. Loss: 0.013706855699809728, Train_acc 0.9984580592105263\n",
      "\n",
      "Epoch 120. Loss: 0.012740017442383473, Train_acc 0.9984780844155844\n",
      "\n",
      "Epoch 120. Loss: 0.011528259309464117, Train_acc 0.9984975961538461\n",
      "\n",
      "Epoch 120. Loss: 0.010705115050673562, Train_acc 0.9985166139240507\n",
      "\n",
      "Epoch 120. Loss: 0.009775544409245322, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 120. Loss: 0.008985177575255248, Train_acc 0.9985532407407407\n",
      "\n",
      "Epoch 120. Loss: 0.008276878972776812, Train_acc 0.9985708841463414\n",
      "\n",
      "Epoch 120. Loss: 0.007514143863442316, Train_acc 0.9985881024096386\n",
      "\n",
      "Epoch 120. Loss: 0.007763733234217264, Train_acc 0.9985119047619048\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120. Loss: 0.007254822226764706, Train_acc 0.9985294117647059\n",
      "\n",
      "Epoch 120. Loss: 0.006572458583284979, Train_acc 0.998546511627907\n",
      "\n",
      "Epoch 120. Loss: 0.0061141586402829575, Train_acc 0.9985632183908046\n",
      "\n",
      "Epoch 120. Loss: 0.005624195144584872, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 120. Loss: 0.005167298179837553, Train_acc 0.9985955056179775\n",
      "\n",
      "Epoch 120. Loss: 0.005468034423416097, Train_acc 0.9986111111111111\n",
      "\n",
      "Epoch 120. Loss: 0.008828499847971117, Train_acc 0.998540521978022\n",
      "\n",
      "Epoch 120. Loss: 0.008030424385284824, Train_acc 0.9985563858695652\n",
      "\n",
      "Epoch 120. Loss: 0.007295455037853518, Train_acc 0.9985719086021505\n",
      "\n",
      "Epoch 120. Loss: 0.007290493677676975, Train_acc 0.9985871010638298\n",
      "\n",
      "Epoch 120. Loss: 0.006781609385643535, Train_acc 0.9986019736842106\n",
      "\n",
      "Epoch 120. Loss: 0.006142767800606571, Train_acc 0.9986165364583334\n",
      "\n",
      "Epoch 120. Loss: 0.005729552807629659, Train_acc 0.9986307989690721\n",
      "\n",
      "Epoch 120. Loss: 0.005170118034357887, Train_acc 0.9986447704081632\n",
      "\n",
      "Epoch 120. Loss: 0.005949718571879025, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 120. Loss: 0.005359819638213798, Train_acc 0.99859375\n",
      "\n",
      "[Epoch 120 Batch 100] Loss: 0.004833481697913523 Training: accuracy=0.998608\n",
      "Epoch 120. Loss: 0.004833481697913523, Train_acc 0.9986076732673267\n",
      "\n",
      "Epoch 120. Loss: 0.004538838690267368, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 120. Loss: 0.0044998187485304755, Train_acc 0.9986347087378641\n",
      "\n",
      "Epoch 120. Loss: 0.004080698002148289, Train_acc 0.9986478365384616\n",
      "\n",
      "Epoch 120. Loss: 0.003692259269631816, Train_acc 0.9986607142857142\n",
      "\n",
      "Epoch 120. Loss: 0.004092537362659198, Train_acc 0.9985996462264151\n",
      "\n",
      "Epoch 120. Loss: 0.003708280429069747, Train_acc 0.9986127336448598\n",
      "\n",
      "Epoch 120. Loss: 0.0036010289915200024, Train_acc 0.9986255787037037\n",
      "\n",
      "Epoch 120. Loss: 0.0032583209687084068, Train_acc 0.9986381880733946\n",
      "\n",
      "Epoch 120. Loss: 0.0032916187775382496, Train_acc 0.9986505681818182\n",
      "\n",
      "Epoch 120. Loss: 0.003076132992371836, Train_acc 0.9986627252252253\n",
      "\n",
      "Epoch 120. Loss: 0.0027934737713880106, Train_acc 0.9986746651785714\n",
      "\n",
      "Epoch 120. Loss: 0.0046858005787503805, Train_acc 0.9986172566371682\n",
      "\n",
      "Epoch 120. Loss: 0.00433987196702037, Train_acc 0.9986293859649122\n",
      "\n",
      "Epoch 120. Loss: 0.004844513663663928, Train_acc 0.9985733695652174\n",
      "\n",
      "Epoch 120. Loss: 0.004363738804482981, Train_acc 0.9985856681034483\n",
      "\n",
      "Epoch 120. Loss: 0.003990125879223106, Train_acc 0.9985977564102564\n",
      "\n",
      "Epoch 120. Loss: 0.0038227316789254174, Train_acc 0.9986096398305084\n",
      "\n",
      "Epoch 120. Loss: 0.003490718049726229, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 120. Loss: 0.003165283584226377, Train_acc 0.9986328125\n",
      "\n",
      "Epoch 120. Loss: 0.003072391154509074, Train_acc 0.9986441115702479\n",
      "\n",
      "Epoch 120. Loss: 0.0028664414948370636, Train_acc 0.9986552254098361\n",
      "\n",
      "Epoch 120. Loss: 0.003379473841888897, Train_acc 0.9986026422764228\n",
      "\n",
      "Epoch 120. Loss: 0.0034413832858531408, Train_acc 0.9986139112903226\n",
      "\n",
      "Epoch 120. Loss: 0.0034610600441615643, Train_acc 0.998625\n",
      "\n",
      "Epoch 120. Loss: 0.003331996786699074, Train_acc 0.9986359126984127\n",
      "\n",
      "Epoch 120. Loss: 0.0032946164734486143, Train_acc 0.9986466535433071\n",
      "\n",
      "Epoch 120. Loss: 0.0038153814630797565, Train_acc 0.99859619140625\n",
      "\n",
      "Epoch 120. Loss: 0.0036787411070249433, Train_acc 0.9986070736434108\n",
      "\n",
      "Epoch 120. Loss: 0.003817260887150343, Train_acc 0.9986177884615385\n",
      "\n",
      "Epoch 120. Loss: 0.004509356711886265, Train_acc 0.9985687022900763\n",
      "\n",
      "Epoch 120. Loss: 0.004123466634935383, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 120. Loss: 0.004086998852173606, Train_acc 0.9985902255639098\n",
      "\n",
      "Epoch 120. Loss: 0.003845376141366469, Train_acc 0.9986007462686567\n",
      "\n",
      "Epoch 120. Loss: 0.0034823484538213565, Train_acc 0.9986111111111111\n",
      "\n",
      "Epoch 120. Loss: 0.003136589026735165, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 120. Loss: 0.002912341060987209, Train_acc 0.9986313868613139\n",
      "\n",
      "Epoch 120. Loss: 0.002941077307463671, Train_acc 0.998641304347826\n",
      "\n",
      "Epoch 120. Loss: 0.0026788926777680834, Train_acc 0.9986510791366906\n",
      "\n",
      "Epoch 120. Loss: 0.0026627111473253476, Train_acc 0.9986607142857142\n",
      "\n",
      "Epoch 120. Loss: 0.0026042536987949407, Train_acc 0.9986702127659575\n",
      "\n",
      "Epoch 120. Loss: 0.002381014915911987, Train_acc 0.9986795774647887\n",
      "\n",
      "Epoch 120. Loss: 0.0032422892459708164, Train_acc 0.9986341783216783\n",
      "\n",
      "Epoch 120. Loss: 0.003893516689551864, Train_acc 0.9985894097222222\n",
      "\n",
      "Epoch 120. Loss: 0.003511508468538499, Train_acc 0.9985991379310345\n",
      "\n",
      "Epoch 120. Loss: 0.003266453365515896, Train_acc 0.9986087328767124\n",
      "\n",
      "Epoch 120. Loss: 0.0030228177995700197, Train_acc 0.9986181972789115\n",
      "\n",
      "Epoch 120. Loss: 0.0031912607214944263, Train_acc 0.9986275337837838\n",
      "\n",
      "Epoch 120. Loss: 0.002892074089589327, Train_acc 0.998636744966443\n",
      "\n",
      "Epoch 120. Loss: 0.002619404431701549, Train_acc 0.9986458333333333\n",
      "\n",
      "Epoch 120. Loss: 0.0023617378747562315, Train_acc 0.9986548013245033\n",
      "\n",
      "Epoch 120. Loss: 0.0025458780677109732, Train_acc 0.9986636513157895\n",
      "\n",
      "Epoch 120. Loss: 0.0022965357287042017, Train_acc 0.998672385620915\n",
      "\n",
      "Epoch 120. Loss: 0.0022914918288570053, Train_acc 0.9986810064935064\n",
      "\n",
      "Epoch 120. Loss: 0.0020969048765471345, Train_acc 0.9986895161290322\n",
      "\n",
      "Epoch 120. Loss: 0.0019697854076124667, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 120. Loss: 0.001839829356235037, Train_acc 0.9987062101910829\n",
      "\n",
      "Epoch 120. Loss: 0.0016822041504143729, Train_acc 0.9987143987341772\n",
      "\n",
      "Epoch 120. Loss: 0.001547334079538164, Train_acc 0.9987224842767296\n",
      "\n",
      "Epoch 120. Loss: 0.0014153258751827315, Train_acc 0.99873046875\n",
      "\n",
      "Epoch 120. Loss: 0.0013119464827196598, Train_acc 0.9987383540372671\n",
      "\n",
      "Epoch 120. Loss: 0.001189998933380668, Train_acc 0.9987461419753086\n",
      "\n",
      "Epoch 120. Loss: 0.001105814887217797, Train_acc 0.9987538343558282\n",
      "\n",
      "Epoch 120. Loss: 0.0010090101681247657, Train_acc 0.9987614329268293\n",
      "\n",
      "Epoch 120. Loss: 0.0009791720672707534, Train_acc 0.9987689393939394\n",
      "\n",
      "Epoch 120. Loss: 0.0009020802563117206, Train_acc 0.9987763554216867\n",
      "\n",
      "Epoch 120. Loss: 0.0021253376918154592, Train_acc 0.9987369011976048\n",
      "\n",
      "Epoch 120. Loss: 0.0035674070686505114, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 120. Loss: 0.00323956960282192, Train_acc 0.9987056213017751\n",
      "\n",
      "Epoch 120. Loss: 0.0029468493181076527, Train_acc 0.9987132352941176\n",
      "\n",
      "Epoch 120. Loss: 0.004348152527297158, Train_acc 0.9986750730994152\n",
      "\n",
      "Epoch 120. Loss: 0.013011926694886046, Train_acc 0.9986373546511628\n",
      "\n",
      "Epoch 120. Loss: 0.011726927878331963, Train_acc 0.9986452312138728\n",
      "\n",
      "Epoch 120. Loss: 0.010774721868333361, Train_acc 0.9986530172413793\n",
      "\n",
      "Epoch 120. Loss: 0.009891102065609074, Train_acc 0.9986607142857142\n",
      "\n",
      "Epoch 120. Loss: 0.009290691489323537, Train_acc 0.9986683238636364\n",
      "\n",
      "Epoch 120. Loss: 0.008398077652902135, Train_acc 0.9986758474576272\n",
      "\n",
      "Epoch 120. Loss: 0.007607643581376131, Train_acc 0.9986832865168539\n",
      "\n",
      "Epoch 120. Loss: 0.008992591487120678, Train_acc 0.9986469972067039\n",
      "\n",
      "Epoch 120. Loss: 0.008126636046595914, Train_acc 0.9986545138888889\n",
      "\n",
      "Epoch 120. Loss: 0.011802541567469427, Train_acc 0.9986187845303868\n",
      "\n",
      "Epoch 120. Loss: 0.010712453347576222, Train_acc 0.9986263736263736\n",
      "\n",
      "Epoch 120. Loss: 0.009692888615883197, Train_acc 0.9986338797814208\n",
      "\n",
      "Epoch 120. Loss: 0.008768676127793763, Train_acc 0.998641304347826\n",
      "\n",
      "Epoch 120. Loss: 0.00833807575476382, Train_acc 0.9986486486486487\n",
      "\n",
      "Epoch 120. Loss: 0.007740643157263522, Train_acc 0.9986559139784946\n",
      "\n",
      "Epoch 120. Loss: 0.007079895932555131, Train_acc 0.9986631016042781\n",
      "\n",
      "Epoch 120. Loss: 0.008498209095668733, Train_acc 0.9986286569148937\n",
      "\n",
      "Epoch 120. Loss: 0.0076909062805167044, Train_acc 0.9986359126984127\n",
      "\n",
      "Epoch 120. Loss: 0.007047765761678625, Train_acc 0.9986430921052631\n",
      "\n",
      "Epoch 120. Loss: 0.006968361025361904, Train_acc 0.9986092931937173\n",
      "\n",
      "Epoch 120. Loss: 0.00631963038807394, Train_acc 0.9986165364583334\n",
      "\n",
      "Epoch 120. Loss: 0.005767836050509201, Train_acc 0.9986237046632125\n",
      "\n",
      "Epoch 120. Loss: 0.005342128589997101, Train_acc 0.9986307989690721\n",
      "\n",
      "Epoch 120. Loss: 0.00555934017211146, Train_acc 0.9986378205128205\n",
      "\n",
      "Epoch 120. Loss: 0.005049861881160633, Train_acc 0.99864\n",
      "\n",
      "Epoch 121. Loss: 0.0049668024447773965, Train_acc 1.0\n",
      "\n",
      "Epoch 121. Loss: 0.004632199941997088, Train_acc 1.0\n",
      "\n",
      "Epoch 121. Loss: 0.004656953116289697, Train_acc 1.0\n",
      "\n",
      "Epoch 121. Loss: 0.005019965767888953, Train_acc 0.998046875\n",
      "\n",
      "Epoch 121. Loss: 0.004577887109506485, Train_acc 0.9984375\n",
      "\n",
      "Epoch 121. Loss: 0.004516677669738255, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 121. Loss: 0.00409879406280568, Train_acc 0.9988839285714286\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121. Loss: 0.003718532591594949, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 121. Loss: 0.0035116950243267667, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 121. Loss: 0.0031896911397828833, Train_acc 0.99921875\n",
      "\n",
      "Epoch 121. Loss: 0.00392994340898879, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 121. Loss: 0.003845637309147009, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 121. Loss: 0.0040764166572032174, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 121. Loss: 0.0037530071578923884, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 121. Loss: 0.005174946110770466, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 121. Loss: 0.008773353387110258, Train_acc 0.99755859375\n",
      "\n",
      "Epoch 121. Loss: 0.008234901280724547, Train_acc 0.9977022058823529\n",
      "\n",
      "Epoch 121. Loss: 0.007426930893934426, Train_acc 0.9978298611111112\n",
      "\n",
      "Epoch 121. Loss: 0.006797417898008219, Train_acc 0.9979440789473685\n",
      "\n",
      "Epoch 121. Loss: 0.006662946942325524, Train_acc 0.998046875\n",
      "\n",
      "Epoch 121. Loss: 0.008197393755205952, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 121. Loss: 0.007962854598169162, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 121. Loss: 0.0073410881040025956, Train_acc 0.9979619565217391\n",
      "\n",
      "Epoch 121. Loss: 0.006732287674995887, Train_acc 0.998046875\n",
      "\n",
      "Epoch 121. Loss: 0.007262312493341531, Train_acc 0.9978125\n",
      "\n",
      "Epoch 121. Loss: 0.0066659245609796336, Train_acc 0.9978966346153846\n",
      "\n",
      "Epoch 121. Loss: 0.006302321466689374, Train_acc 0.9979745370370371\n",
      "\n",
      "Epoch 121. Loss: 0.005952057319106221, Train_acc 0.998046875\n",
      "\n",
      "Epoch 121. Loss: 0.006300497515250646, Train_acc 0.998114224137931\n",
      "\n",
      "Epoch 121. Loss: 0.005917570506892566, Train_acc 0.9981770833333333\n",
      "\n",
      "Epoch 121. Loss: 0.005801424667935339, Train_acc 0.9982358870967742\n",
      "\n",
      "Epoch 121. Loss: 0.007573808798820467, Train_acc 0.998046875\n",
      "\n",
      "Epoch 121. Loss: 0.0073437224578535775, Train_acc 0.9981060606060606\n",
      "\n",
      "Epoch 121. Loss: 0.006644504449480136, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 121. Loss: 0.005994120773458691, Train_acc 0.9982142857142857\n",
      "\n",
      "Epoch 121. Loss: 0.0054407712849209484, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 121. Loss: 0.007051234054466764, Train_acc 0.9980996621621622\n",
      "\n",
      "Epoch 121. Loss: 0.00649857235707776, Train_acc 0.9981496710526315\n",
      "\n",
      "Epoch 121. Loss: 0.006449886404421356, Train_acc 0.9979967948717948\n",
      "\n",
      "Epoch 121. Loss: 0.005913812504828507, Train_acc 0.998046875\n",
      "\n",
      "Epoch 121. Loss: 0.005504639137681306, Train_acc 0.9980945121951219\n",
      "\n",
      "Epoch 121. Loss: 0.005177492291052026, Train_acc 0.9981398809523809\n",
      "\n",
      "Epoch 121. Loss: 0.005202334760414555, Train_acc 0.9981831395348837\n",
      "\n",
      "Epoch 121. Loss: 0.004749385626740302, Train_acc 0.9982244318181818\n",
      "\n",
      "Epoch 121. Loss: 0.005256622831487995, Train_acc 0.9980902777777778\n",
      "\n",
      "Epoch 121. Loss: 0.00483425668994502, Train_acc 0.9981317934782609\n",
      "\n",
      "Epoch 121. Loss: 0.004652260533861062, Train_acc 0.9981715425531915\n",
      "\n",
      "Epoch 121. Loss: 0.0042050536106955924, Train_acc 0.9982096354166666\n",
      "\n",
      "Epoch 121. Loss: 0.003947649689455949, Train_acc 0.9982461734693877\n",
      "\n",
      "Epoch 121. Loss: 0.004779670406377425, Train_acc 0.998125\n",
      "\n",
      "Epoch 121. Loss: 0.004345448582420373, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 121. Loss: 0.004182199526846073, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 121. Loss: 0.0037683446983482, Train_acc 0.9982311320754716\n",
      "\n",
      "Epoch 121. Loss: 0.003678211806228956, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 121. Loss: 0.003432816167819083, Train_acc 0.9982954545454545\n",
      "\n",
      "Epoch 121. Loss: 0.0030978597744988996, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 121. Loss: 0.002825521573461601, Train_acc 0.9983552631578947\n",
      "\n",
      "Epoch 121. Loss: 0.002553692225499319, Train_acc 0.9983836206896551\n",
      "\n",
      "Epoch 121. Loss: 0.0023184483424555816, Train_acc 0.9984110169491526\n",
      "\n",
      "Epoch 121. Loss: 0.003040487185931047, Train_acc 0.9983072916666667\n",
      "\n",
      "Epoch 121. Loss: 0.0027850030542427738, Train_acc 0.9983350409836066\n",
      "\n",
      "Epoch 121. Loss: 0.0026032693063629663, Train_acc 0.9983618951612904\n",
      "\n",
      "Epoch 121. Loss: 0.0025918342825394566, Train_acc 0.9983878968253969\n",
      "\n",
      "Epoch 121. Loss: 0.002341362349605824, Train_acc 0.9984130859375\n",
      "\n",
      "Epoch 121. Loss: 0.005916973959579705, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 121. Loss: 0.005326449994959254, Train_acc 0.9982244318181818\n",
      "\n",
      "Epoch 121. Loss: 0.004801400601175015, Train_acc 0.9982509328358209\n",
      "\n",
      "Epoch 121. Loss: 0.0044144277580402055, Train_acc 0.9982766544117647\n",
      "\n",
      "Epoch 121. Loss: 0.003976716165332719, Train_acc 0.9983016304347826\n",
      "\n",
      "Epoch 121. Loss: 0.003731324811936519, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 121. Loss: 0.006224212943161519, Train_acc 0.9982394366197183\n",
      "\n",
      "Epoch 121. Loss: 0.005804663624334328, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 121. Loss: 0.007842512519032948, Train_acc 0.9980736301369864\n",
      "\n",
      "Epoch 121. Loss: 0.008027253604714148, Train_acc 0.9979940878378378\n",
      "\n",
      "Epoch 121. Loss: 0.0072552802595428284, Train_acc 0.9980208333333334\n",
      "\n",
      "Epoch 121. Loss: 0.006567813227708861, Train_acc 0.998046875\n",
      "\n",
      "Epoch 121. Loss: 0.0059242815634517896, Train_acc 0.9980722402597403\n",
      "\n",
      "Epoch 121. Loss: 0.0053446657296361095, Train_acc 0.9980969551282052\n",
      "\n",
      "Epoch 121. Loss: 0.004853891002748898, Train_acc 0.9981210443037974\n",
      "\n",
      "Epoch 121. Loss: 0.004518652440430514, Train_acc 0.99814453125\n",
      "\n",
      "Epoch 121. Loss: 0.004074864493048676, Train_acc 0.9981674382716049\n",
      "\n",
      "Epoch 121. Loss: 0.0037560590857053443, Train_acc 0.9981897865853658\n",
      "\n",
      "Epoch 121. Loss: 0.0033852730948747607, Train_acc 0.9982115963855421\n",
      "\n",
      "Epoch 121. Loss: 0.003701277428181894, Train_acc 0.9982328869047619\n",
      "\n",
      "Epoch 121. Loss: 0.003902106070126826, Train_acc 0.9982536764705883\n",
      "\n",
      "Epoch 121. Loss: 0.003728494807390035, Train_acc 0.9982739825581395\n",
      "\n",
      "Epoch 121. Loss: 0.0033719048902139575, Train_acc 0.9982938218390804\n",
      "\n",
      "Epoch 121. Loss: 0.004691728182561294, Train_acc 0.9981356534090909\n",
      "\n",
      "Epoch 121. Loss: 0.004368493495332089, Train_acc 0.9981566011235955\n",
      "\n",
      "Epoch 121. Loss: 0.003932996046099387, Train_acc 0.9981770833333333\n",
      "\n",
      "Epoch 121. Loss: 0.003728157259515663, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 121. Loss: 0.005231279449902541, Train_acc 0.9981317934782609\n",
      "\n",
      "Epoch 121. Loss: 0.004710624490128005, Train_acc 0.9981518817204301\n",
      "\n",
      "Epoch 121. Loss: 0.004269053968240696, Train_acc 0.9981715425531915\n",
      "\n",
      "Epoch 121. Loss: 0.0038658582179009753, Train_acc 0.9981907894736842\n",
      "\n",
      "Epoch 121. Loss: 0.003534514318493143, Train_acc 0.9982096354166666\n",
      "\n",
      "Epoch 121. Loss: 0.0031869535510409856, Train_acc 0.9982280927835051\n",
      "\n",
      "Epoch 121. Loss: 0.0030364595698269296, Train_acc 0.9982461734693877\n",
      "\n",
      "Epoch 121. Loss: 0.003140038552980312, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 121. Loss: 0.007304704609305282, Train_acc 0.998125\n",
      "\n",
      "[Epoch 121 Batch 100] Loss: 0.006595468256509859 Training: accuracy=0.998144\n",
      "Epoch 121. Loss: 0.006595468256509859, Train_acc 0.9981435643564357\n",
      "\n",
      "Epoch 121. Loss: 0.00658191130896201, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 121. Loss: 0.005943320593609928, Train_acc 0.9981796116504854\n",
      "\n",
      "Epoch 121. Loss: 0.0055844178938488824, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 121. Loss: 0.005070200789289161, Train_acc 0.9982142857142857\n",
      "\n",
      "Epoch 121. Loss: 0.00457170723628609, Train_acc 0.9982311320754716\n",
      "\n",
      "Epoch 121. Loss: 0.004122206582702177, Train_acc 0.9982476635514018\n",
      "\n",
      "Epoch 121. Loss: 0.0037734842309857706, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 121. Loss: 0.0034565663728048177, Train_acc 0.9982798165137615\n",
      "\n",
      "Epoch 121. Loss: 0.003113941262354791, Train_acc 0.9982954545454545\n",
      "\n",
      "Epoch 121. Loss: 0.005086178773811763, Train_acc 0.9982404279279279\n",
      "\n",
      "Epoch 121. Loss: 0.004833260561716234, Train_acc 0.9982561383928571\n",
      "\n",
      "Epoch 121. Loss: 0.0077982140800580465, Train_acc 0.998133296460177\n",
      "\n",
      "Epoch 121. Loss: 0.007026916953345163, Train_acc 0.9981496710526315\n",
      "\n",
      "Epoch 121. Loss: 0.006485767559076866, Train_acc 0.9981657608695652\n",
      "\n",
      "Epoch 121. Loss: 0.00957062644886868, Train_acc 0.998114224137931\n",
      "\n",
      "Epoch 121. Loss: 0.008853501928996118, Train_acc 0.9981303418803419\n",
      "\n",
      "Epoch 121. Loss: 0.008380403350130683, Train_acc 0.998146186440678\n",
      "\n",
      "Epoch 121. Loss: 0.009381838721337288, Train_acc 0.9980304621848739\n",
      "\n",
      "Epoch 121. Loss: 0.008464225218291651, Train_acc 0.998046875\n",
      "\n",
      "Epoch 121. Loss: 0.007629556792075045, Train_acc 0.9980630165289256\n",
      "\n",
      "Epoch 121. Loss: 0.009170726690078922, Train_acc 0.9980148565573771\n",
      "\n",
      "Epoch 121. Loss: 0.008297222423250546, Train_acc 0.9980309959349594\n",
      "\n",
      "Epoch 121. Loss: 0.007505014622572127, Train_acc 0.998046875\n",
      "\n",
      "Epoch 121. Loss: 0.006899515870947894, Train_acc 0.9980625\n",
      "\n",
      "Epoch 121. Loss: 0.006690182052915624, Train_acc 0.998077876984127\n",
      "\n",
      "Epoch 121. Loss: 0.015036931123911142, Train_acc 0.9979699803149606\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121. Loss: 0.01359759454346788, Train_acc 0.99798583984375\n",
      "\n",
      "Epoch 121. Loss: 0.01343672105148815, Train_acc 0.9979408914728682\n",
      "\n",
      "Epoch 121. Loss: 0.012611877017993179, Train_acc 0.9979567307692307\n",
      "\n",
      "Epoch 121. Loss: 0.012223255308370394, Train_acc 0.9979126908396947\n",
      "\n",
      "Epoch 121. Loss: 0.011665315604791584, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 121. Loss: 0.012971968696938941, Train_acc 0.9978265977443609\n",
      "\n",
      "Epoch 121. Loss: 0.011748331421120008, Train_acc 0.9978428171641791\n",
      "\n",
      "Epoch 121. Loss: 0.01058564723356433, Train_acc 0.9978587962962963\n",
      "\n",
      "Epoch 121. Loss: 0.012913096837614779, Train_acc 0.9978170955882353\n",
      "\n",
      "Epoch 121. Loss: 0.015716456376685027, Train_acc 0.997776003649635\n",
      "\n",
      "Epoch 121. Loss: 0.014193483676571762, Train_acc 0.9977921195652174\n",
      "\n",
      "Epoch 121. Loss: 0.012863836073425367, Train_acc 0.9978080035971223\n",
      "\n",
      "Epoch 121. Loss: 0.011655997872077932, Train_acc 0.9978236607142857\n",
      "\n",
      "Epoch 121. Loss: 0.01067115103279666, Train_acc 0.9978390957446809\n",
      "\n",
      "Epoch 121. Loss: 0.009758801752907328, Train_acc 0.9978543133802817\n",
      "\n",
      "Epoch 121. Loss: 0.01046763810776081, Train_acc 0.9978146853146853\n",
      "\n",
      "Epoch 121. Loss: 0.011074712082109509, Train_acc 0.9977756076388888\n",
      "\n",
      "Epoch 121. Loss: 0.010221091281796985, Train_acc 0.9977909482758621\n",
      "\n",
      "Epoch 121. Loss: 0.010121577676915074, Train_acc 0.9977525684931506\n",
      "\n",
      "Epoch 121. Loss: 0.0109704384104457, Train_acc 0.9976615646258503\n",
      "\n",
      "Epoch 121. Loss: 0.010891100199912176, Train_acc 0.9976773648648649\n",
      "\n",
      "Epoch 121. Loss: 0.010630007846856878, Train_acc 0.9976929530201343\n",
      "\n",
      "Epoch 121. Loss: 0.010907753382955283, Train_acc 0.9977083333333333\n",
      "\n",
      "Epoch 121. Loss: 0.011158109374196194, Train_acc 0.9976717715231788\n",
      "\n",
      "Epoch 121. Loss: 0.010825344678626236, Train_acc 0.9976356907894737\n",
      "\n",
      "Epoch 121. Loss: 0.010651186021595397, Train_acc 0.9976511437908496\n",
      "\n",
      "Epoch 121. Loss: 0.011777198422636866, Train_acc 0.997564935064935\n",
      "\n",
      "Epoch 121. Loss: 0.013939586155432115, Train_acc 0.9975302419354839\n",
      "\n",
      "Epoch 121. Loss: 0.012852292599067972, Train_acc 0.9975460737179487\n",
      "\n",
      "Epoch 121. Loss: 0.011598826471007849, Train_acc 0.9975617038216561\n",
      "\n",
      "Epoch 121. Loss: 0.010580709408610597, Train_acc 0.9975771360759493\n",
      "\n",
      "Epoch 121. Loss: 0.00970230821767259, Train_acc 0.9975923742138365\n",
      "\n",
      "Epoch 121. Loss: 0.010568010909844711, Train_acc 0.99755859375\n",
      "\n",
      "Epoch 121. Loss: 0.010857591013749786, Train_acc 0.9975252329192547\n",
      "\n",
      "Epoch 121. Loss: 0.009968577322005047, Train_acc 0.9975405092592593\n",
      "\n",
      "Epoch 121. Loss: 0.009006963251645921, Train_acc 0.9975555981595092\n",
      "\n",
      "Epoch 121. Loss: 0.008200773775317647, Train_acc 0.9975705030487805\n",
      "\n",
      "Epoch 121. Loss: 0.010984259110455256, Train_acc 0.9975378787878788\n",
      "\n",
      "Epoch 121. Loss: 0.00992854104788877, Train_acc 0.9975527108433735\n",
      "\n",
      "Epoch 121. Loss: 0.008985351622781775, Train_acc 0.9975673652694611\n",
      "\n",
      "Epoch 121. Loss: 0.008208829263834615, Train_acc 0.9975818452380952\n",
      "\n",
      "Epoch 121. Loss: 0.007704240201030784, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 121. Loss: 0.00853760022054429, Train_acc 0.9975643382352941\n",
      "\n",
      "Epoch 121. Loss: 0.007753420181154298, Train_acc 0.9975785818713451\n",
      "\n",
      "Epoch 121. Loss: 0.007190907490249652, Train_acc 0.9975926598837209\n",
      "\n",
      "Epoch 121. Loss: 0.008348109677728574, Train_acc 0.9975614161849711\n",
      "\n",
      "Epoch 121. Loss: 0.007617833638642634, Train_acc 0.9975754310344828\n",
      "\n",
      "Epoch 121. Loss: 0.0070563592971081175, Train_acc 0.9975892857142857\n",
      "\n",
      "Epoch 121. Loss: 0.006754655337174056, Train_acc 0.9976029829545454\n",
      "\n",
      "Epoch 121. Loss: 0.00615225531324348, Train_acc 0.9976165254237288\n",
      "\n",
      "Epoch 121. Loss: 0.005817003485355686, Train_acc 0.9976299157303371\n",
      "\n",
      "Epoch 121. Loss: 0.005484263775238911, Train_acc 0.997643156424581\n",
      "\n",
      "Epoch 121. Loss: 0.00582488034888165, Train_acc 0.99765625\n",
      "\n",
      "Epoch 121. Loss: 0.005390958427778395, Train_acc 0.9976691988950276\n",
      "\n",
      "Epoch 121. Loss: 0.009741622006349128, Train_acc 0.9976390796703297\n",
      "\n",
      "Epoch 121. Loss: 0.008991132824341084, Train_acc 0.997651980874317\n",
      "\n",
      "Epoch 121. Loss: 0.00813364016441241, Train_acc 0.997664741847826\n",
      "\n",
      "Epoch 121. Loss: 0.007417860371811555, Train_acc 0.9976773648648649\n",
      "\n",
      "Epoch 121. Loss: 0.006712049224391237, Train_acc 0.9976898521505376\n",
      "\n",
      "Epoch 121. Loss: 0.006379919992087473, Train_acc 0.9977022058823529\n",
      "\n",
      "Epoch 121. Loss: 0.00578715049088957, Train_acc 0.9977144281914894\n",
      "\n",
      "Epoch 121. Loss: 0.005242109673763846, Train_acc 0.9977265211640212\n",
      "\n",
      "Epoch 121. Loss: 0.004777760984090821, Train_acc 0.9977384868421053\n",
      "\n",
      "Epoch 121. Loss: 0.0057417237333248754, Train_acc 0.9977094240837696\n",
      "\n",
      "Epoch 121. Loss: 0.0052127118668443585, Train_acc 0.9977213541666666\n",
      "\n",
      "Epoch 121. Loss: 0.004724791638415974, Train_acc 0.9977331606217616\n",
      "\n",
      "Epoch 121. Loss: 0.004332063198245545, Train_acc 0.9977448453608248\n",
      "\n",
      "Epoch 121. Loss: 0.003925526301516873, Train_acc 0.9977564102564103\n",
      "\n",
      "Epoch 121. Loss: 0.0036039394154545206, Train_acc 0.99776\n",
      "\n",
      "Epoch 122. Loss: 0.0036823235763069873, Train_acc 1.0\n",
      "\n",
      "Epoch 122. Loss: 0.003350098489358892, Train_acc 1.0\n",
      "\n",
      "Epoch 122. Loss: 0.003028967872997257, Train_acc 1.0\n",
      "\n",
      "Epoch 122. Loss: 0.0028297238772833043, Train_acc 1.0\n",
      "\n",
      "Epoch 122. Loss: 0.0026201371472975936, Train_acc 1.0\n",
      "\n",
      "Epoch 122. Loss: 0.0024965098762908273, Train_acc 1.0\n",
      "\n",
      "Epoch 122. Loss: 0.0022578617409230437, Train_acc 1.0\n",
      "\n",
      "Epoch 122. Loss: 0.003517597285690412, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 122. Loss: 0.0031903059622936, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 122. Loss: 0.003094248402644028, Train_acc 0.99921875\n",
      "\n",
      "Epoch 122. Loss: 0.0028539102351178196, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 122. Loss: 0.003967076077357782, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 122. Loss: 0.004891946402307617, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 122. Loss: 0.004436630221439169, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 122. Loss: 0.004097142893582075, Train_acc 0.9984375\n",
      "\n",
      "Epoch 122. Loss: 0.0039523521581377, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 122. Loss: 0.0038479408564345906, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 122. Loss: 0.0037014952678689544, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 122. Loss: 0.003560192931819783, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 122. Loss: 0.003435014604743266, Train_acc 0.998828125\n",
      "\n",
      "Epoch 122. Loss: 0.005118742177679488, Train_acc 0.9985119047619048\n",
      "\n",
      "Epoch 122. Loss: 0.00463652707399109, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 122. Loss: 0.004203352127766533, Train_acc 0.998641304347826\n",
      "\n",
      "Epoch 122. Loss: 0.003792037373663938, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 122. Loss: 0.0034571456879113594, Train_acc 0.99875\n",
      "\n",
      "Epoch 122. Loss: 0.003122889266612018, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 122. Loss: 0.002837279204329298, Train_acc 0.9988425925925926\n",
      "\n",
      "Epoch 122. Loss: 0.002689139405962479, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 122. Loss: 0.0024825567432433236, Train_acc 0.9989224137931034\n",
      "\n",
      "Epoch 122. Loss: 0.0022471139662491413, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 122. Loss: 0.002127554348176908, Train_acc 0.998991935483871\n",
      "\n",
      "Epoch 122. Loss: 0.0019435154824271276, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 122. Loss: 0.0017885909107664504, Train_acc 0.9990530303030303\n",
      "\n",
      "Epoch 122. Loss: 0.0018773524372135946, Train_acc 0.9990808823529411\n",
      "\n",
      "Epoch 122. Loss: 0.00222272770218748, Train_acc 0.9991071428571429\n",
      "\n",
      "Epoch 122. Loss: 0.0020193167475931364, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 122. Loss: 0.001835523130036855, Train_acc 0.9991554054054054\n",
      "\n",
      "Epoch 122. Loss: 0.0016557961550230072, Train_acc 0.9991776315789473\n",
      "\n",
      "Epoch 122. Loss: 0.002161035384330835, Train_acc 0.9989983974358975\n",
      "\n",
      "Epoch 122. Loss: 0.00224451761950733, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 122. Loss: 0.0025005909134568132, Train_acc 0.999047256097561\n",
      "\n",
      "Epoch 122. Loss: 0.002256246205334808, Train_acc 0.9990699404761905\n",
      "\n",
      "Epoch 122. Loss: 0.004190347273199212, Train_acc 0.9989098837209303\n",
      "\n",
      "Epoch 122. Loss: 0.005840626928849624, Train_acc 0.9987571022727273\n",
      "\n",
      "Epoch 122. Loss: 0.0054179574555697505, Train_acc 0.9987847222222223\n",
      "\n",
      "Epoch 122. Loss: 0.004888600861772966, Train_acc 0.9988111413043478\n",
      "\n",
      "Epoch 122. Loss: 0.004413256428567943, Train_acc 0.9988364361702128\n",
      "\n",
      "Epoch 122. Loss: 0.003996235637542552, Train_acc 0.9988606770833334\n",
      "\n",
      "Epoch 122. Loss: 0.0036018776050057433, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 122. Loss: 0.003250225111038896, Train_acc 0.99890625\n",
      "\n",
      "Epoch 122. Loss: 0.002941518475044292, Train_acc 0.9989276960784313\n",
      "\n",
      "Epoch 122. Loss: 0.002671236525535473, Train_acc 0.9989483173076923\n",
      "\n",
      "Epoch 122. Loss: 0.002408648528152837, Train_acc 0.9989681603773585\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122. Loss: 0.002185836245859385, Train_acc 0.9989872685185185\n",
      "\n",
      "Epoch 122. Loss: 0.001973750903437549, Train_acc 0.9990056818181818\n",
      "\n",
      "Epoch 122. Loss: 0.0020026046835452446, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 122. Loss: 0.0018290526839855427, Train_acc 0.9990405701754386\n",
      "\n",
      "Epoch 122. Loss: 0.00248282871077327, Train_acc 0.9989224137931034\n",
      "\n",
      "Epoch 122. Loss: 0.002242408303522257, Train_acc 0.9989406779661016\n",
      "\n",
      "Epoch 122. Loss: 0.0020947667176640225, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 122. Loss: 0.0019689328248157674, Train_acc 0.9989754098360656\n",
      "\n",
      "Epoch 122. Loss: 0.0023126192580778518, Train_acc 0.998991935483871\n",
      "\n",
      "Epoch 122. Loss: 0.002093303096978865, Train_acc 0.9990079365079365\n",
      "\n",
      "Epoch 122. Loss: 0.007050922864099445, Train_acc 0.998779296875\n",
      "\n",
      "Epoch 122. Loss: 0.006392377480429875, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 122. Loss: 0.005794542012135469, Train_acc 0.9988162878787878\n",
      "\n",
      "Epoch 122. Loss: 0.00523741719806052, Train_acc 0.9988339552238806\n",
      "\n",
      "Epoch 122. Loss: 0.004756719251875789, Train_acc 0.9988511029411765\n",
      "\n",
      "Epoch 122. Loss: 0.004343138300057987, Train_acc 0.9988677536231884\n",
      "\n",
      "Epoch 122. Loss: 0.004209717564442819, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 122. Loss: 0.00383890117826192, Train_acc 0.998899647887324\n",
      "\n",
      "Epoch 122. Loss: 0.003485775750453987, Train_acc 0.9989149305555556\n",
      "\n",
      "Epoch 122. Loss: 0.003318121543724732, Train_acc 0.998929794520548\n",
      "\n",
      "Epoch 122. Loss: 0.003029703252950144, Train_acc 0.9989442567567568\n",
      "\n",
      "Epoch 122. Loss: 0.0027476018525671945, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 122. Loss: 0.002497808117602161, Train_acc 0.9989720394736842\n",
      "\n",
      "Epoch 122. Loss: 0.002268781510730307, Train_acc 0.9989853896103896\n",
      "\n",
      "Epoch 122. Loss: 0.0020594077566220724, Train_acc 0.9989983974358975\n",
      "\n",
      "Epoch 122. Loss: 0.001970839911941084, Train_acc 0.9990110759493671\n",
      "\n",
      "Epoch 122. Loss: 0.0017822686303569071, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 122. Loss: 0.0016106478529837136, Train_acc 0.9990354938271605\n",
      "\n",
      "Epoch 122. Loss: 0.0015374128633513812, Train_acc 0.999047256097561\n",
      "\n",
      "Epoch 122. Loss: 0.0025845369723833888, Train_acc 0.9989646084337349\n",
      "\n",
      "Epoch 122. Loss: 0.002388735638121273, Train_acc 0.9989769345238095\n",
      "\n",
      "Epoch 122. Loss: 0.0022196390375188793, Train_acc 0.9989889705882353\n",
      "\n",
      "Epoch 122. Loss: 0.0023342956946142144, Train_acc 0.999000726744186\n",
      "\n",
      "Epoch 122. Loss: 0.002104097715897483, Train_acc 0.9990122126436781\n",
      "\n",
      "Epoch 122. Loss: 0.001908282522841168, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 122. Loss: 0.0018387566261035555, Train_acc 0.9990344101123596\n",
      "\n",
      "Epoch 122. Loss: 0.001723207025084706, Train_acc 0.9990451388888889\n",
      "\n",
      "Epoch 122. Loss: 0.0028644640080813873, Train_acc 0.9989697802197802\n",
      "\n",
      "Epoch 122. Loss: 0.0026359309411493072, Train_acc 0.9989809782608695\n",
      "\n",
      "Epoch 122. Loss: 0.002400946746481512, Train_acc 0.998991935483871\n",
      "\n",
      "Epoch 122. Loss: 0.002188081822245877, Train_acc 0.9990026595744681\n",
      "\n",
      "Epoch 122. Loss: 0.00200091384310888, Train_acc 0.9990131578947369\n",
      "\n",
      "Epoch 122. Loss: 0.0019317124775703259, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 122. Loss: 0.0017678897274415277, Train_acc 0.9990335051546392\n",
      "\n",
      "Epoch 122. Loss: 0.0018791715628621503, Train_acc 0.9990433673469388\n",
      "\n",
      "Epoch 122. Loss: 0.0016931470410396646, Train_acc 0.9990530303030303\n",
      "\n",
      "Epoch 122. Loss: 0.0017819938835981482, Train_acc 0.9990625\n",
      "\n",
      "[Epoch 122 Batch 100] Loss: 0.004215480225755244 Training: accuracy=0.998994\n",
      "Epoch 122. Loss: 0.004215480225755244, Train_acc 0.9989944306930693\n",
      "\n",
      "Epoch 122. Loss: 0.0038015629044729576, Train_acc 0.9990042892156863\n",
      "\n",
      "Epoch 122. Loss: 0.0034240423880609596, Train_acc 0.9990139563106796\n",
      "\n",
      "Epoch 122. Loss: 0.0030838248113503465, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 122. Loss: 0.0027779331728138026, Train_acc 0.9990327380952381\n",
      "\n",
      "Epoch 122. Loss: 0.0025026236149861755, Train_acc 0.9990418632075472\n",
      "\n",
      "Epoch 122. Loss: 0.0023067693860518348, Train_acc 0.9990508177570093\n",
      "\n",
      "Epoch 122. Loss: 0.006491766582535571, Train_acc 0.9989872685185185\n",
      "\n",
      "Epoch 122. Loss: 0.0058578761859052735, Train_acc 0.9989965596330275\n",
      "\n",
      "Epoch 122. Loss: 0.00531240181374185, Train_acc 0.9990056818181818\n",
      "\n",
      "Epoch 122. Loss: 0.004840839473276654, Train_acc 0.9990146396396397\n",
      "\n",
      "Epoch 122. Loss: 0.005027654045405375, Train_acc 0.9989536830357143\n",
      "\n",
      "Epoch 122. Loss: 0.004533208903578662, Train_acc 0.9989629424778761\n",
      "\n",
      "Epoch 122. Loss: 0.004092737144819865, Train_acc 0.9989720394736842\n",
      "\n",
      "Epoch 122. Loss: 0.0037551061760897663, Train_acc 0.9989809782608695\n",
      "\n",
      "Epoch 122. Loss: 0.0035091746126724986, Train_acc 0.9989897629310345\n",
      "\n",
      "Epoch 122. Loss: 0.0032027566869844834, Train_acc 0.9989983974358975\n",
      "\n",
      "Epoch 122. Loss: 0.0034288167266359783, Train_acc 0.9990068855932204\n",
      "\n",
      "Epoch 122. Loss: 0.0031096051032402016, Train_acc 0.999015231092437\n",
      "\n",
      "Epoch 122. Loss: 0.0028040191128855183, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 122. Loss: 0.0025471425044192027, Train_acc 0.9990315082644629\n",
      "\n",
      "Epoch 122. Loss: 0.002396820096592142, Train_acc 0.9990394467213115\n",
      "\n",
      "Epoch 122. Loss: 0.002171139919392981, Train_acc 0.999047256097561\n",
      "\n",
      "Epoch 122. Loss: 0.002179526573500977, Train_acc 0.999054939516129\n",
      "\n",
      "Epoch 122. Loss: 0.0020660067602420863, Train_acc 0.9990625\n",
      "\n",
      "Epoch 122. Loss: 0.0019036474077029168, Train_acc 0.9990699404761905\n",
      "\n",
      "Epoch 122. Loss: 0.0018386339008061416, Train_acc 0.9990772637795275\n",
      "\n",
      "Epoch 122. Loss: 0.0017687353598771984, Train_acc 0.99908447265625\n",
      "\n",
      "Epoch 122. Loss: 0.0016499113287674779, Train_acc 0.9990915697674418\n",
      "\n",
      "Epoch 122. Loss: 0.0015429173662608023, Train_acc 0.9990985576923077\n",
      "\n",
      "Epoch 122. Loss: 0.0014398415493007144, Train_acc 0.9991054389312977\n",
      "\n",
      "Epoch 122. Loss: 0.001318304208189176, Train_acc 0.9991122159090909\n",
      "\n",
      "Epoch 122. Loss: 0.0016630729460894403, Train_acc 0.9991188909774437\n",
      "\n",
      "Epoch 122. Loss: 0.0015147703767602484, Train_acc 0.9991254664179104\n",
      "\n",
      "Epoch 122. Loss: 0.001379960938350153, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 122. Loss: 0.002559625913848691, Train_acc 0.9990808823529411\n",
      "\n",
      "Epoch 122. Loss: 0.002403082903702002, Train_acc 0.9990875912408759\n",
      "\n",
      "Epoch 122. Loss: 0.002261548275798358, Train_acc 0.9990942028985508\n",
      "\n",
      "Epoch 122. Loss: 0.002036000250714417, Train_acc 0.9991007194244604\n",
      "\n",
      "Epoch 122. Loss: 0.0021915797242707574, Train_acc 0.9991071428571429\n",
      "\n",
      "Epoch 122. Loss: 0.002197433453539303, Train_acc 0.999113475177305\n",
      "\n",
      "Epoch 122. Loss: 0.0021462368863352757, Train_acc 0.9991197183098591\n",
      "\n",
      "Epoch 122. Loss: 0.0036891096068199236, Train_acc 0.9990712412587412\n",
      "\n",
      "Epoch 122. Loss: 0.0034672698707752607, Train_acc 0.9990776909722222\n",
      "\n",
      "Epoch 122. Loss: 0.003190624435955496, Train_acc 0.999084051724138\n",
      "\n",
      "Epoch 122. Loss: 0.002876041409471671, Train_acc 0.9990903253424658\n",
      "\n",
      "Epoch 122. Loss: 0.00312556294166956, Train_acc 0.9990965136054422\n",
      "\n",
      "Epoch 122. Loss: 0.002844391781709689, Train_acc 0.9991026182432432\n",
      "\n",
      "Epoch 122. Loss: 0.0025779613509678413, Train_acc 0.9991086409395973\n",
      "\n",
      "Epoch 122. Loss: 0.0023572892761982442, Train_acc 0.9991145833333334\n",
      "\n",
      "Epoch 122. Loss: 0.007325793503232923, Train_acc 0.9990687086092715\n",
      "\n",
      "Epoch 122. Loss: 0.007318183305270786, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 122. Loss: 0.006592605908469783, Train_acc 0.9990298202614379\n",
      "\n",
      "Epoch 122. Loss: 0.00594108464605284, Train_acc 0.9990361201298701\n",
      "\n",
      "Epoch 122. Loss: 0.005348657471716162, Train_acc 0.9990423387096774\n",
      "\n",
      "Epoch 122. Loss: 0.004865359969361282, Train_acc 0.9990484775641025\n",
      "\n",
      "Epoch 122. Loss: 0.004398407915201234, Train_acc 0.9990545382165605\n",
      "\n",
      "Epoch 122. Loss: 0.004145869457915229, Train_acc 0.9990605221518988\n",
      "\n",
      "Epoch 122. Loss: 0.004788195332909944, Train_acc 0.9990172955974843\n",
      "\n",
      "Epoch 122. Loss: 0.004358407820234364, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 122. Loss: 0.003934846960004307, Train_acc 0.99902950310559\n",
      "\n",
      "Epoch 122. Loss: 0.003768829211402956, Train_acc 0.9990354938271605\n",
      "\n",
      "Epoch 122. Loss: 0.003736893457003555, Train_acc 0.9990414110429447\n",
      "\n",
      "Epoch 122. Loss: 0.004296435431535352, Train_acc 0.998999618902439\n",
      "\n",
      "Epoch 122. Loss: 0.004635322769414165, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 122. Loss: 0.005268065568742853, Train_acc 0.9989175451807228\n",
      "\n",
      "Epoch 122. Loss: 0.004824993758890958, Train_acc 0.9989240269461078\n",
      "\n",
      "Epoch 122. Loss: 0.005295561290824948, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 122. Loss: 0.004783935953106506, Train_acc 0.9988905325443787\n",
      "\n",
      "Epoch 122. Loss: 0.0043202664280021395, Train_acc 0.9988970588235294\n",
      "\n",
      "Epoch 122. Loss: 0.003991940341994245, Train_acc 0.9989035087719298\n",
      "\n",
      "Epoch 122. Loss: 0.00533240826213814, Train_acc 0.9988644622093024\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122. Loss: 0.004821038519223955, Train_acc 0.9988710260115607\n",
      "\n",
      "Epoch 122. Loss: 0.004351574270238829, Train_acc 0.9988775143678161\n",
      "\n",
      "Epoch 122. Loss: 0.003967838841283637, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 122. Loss: 0.0036389637978748836, Train_acc 0.9988902698863636\n",
      "\n",
      "Epoch 122. Loss: 0.003293758570305193, Train_acc 0.9988965395480226\n",
      "\n",
      "Epoch 122. Loss: 0.002972271235215587, Train_acc 0.9989027387640449\n",
      "\n",
      "Epoch 122. Loss: 0.0026918482574013114, Train_acc 0.9989088687150838\n",
      "\n",
      "Epoch 122. Loss: 0.003206313449935964, Train_acc 0.9989149305555556\n",
      "\n",
      "Epoch 122. Loss: 0.002927689732722917, Train_acc 0.9989209254143646\n",
      "\n",
      "Epoch 122. Loss: 0.004555158151637744, Train_acc 0.9988410027472527\n",
      "\n",
      "Epoch 122. Loss: 0.004122298919060903, Train_acc 0.9988473360655737\n",
      "\n",
      "Epoch 122. Loss: 0.003720790652740387, Train_acc 0.9988536005434783\n",
      "\n",
      "Epoch 122. Loss: 0.0034183522341549887, Train_acc 0.9988597972972973\n",
      "\n",
      "Epoch 122. Loss: 0.0030844849301126763, Train_acc 0.9988659274193549\n",
      "\n",
      "Epoch 122. Loss: 0.0028105822967726068, Train_acc 0.9988719919786097\n",
      "\n",
      "Epoch 122. Loss: 0.002565315113779954, Train_acc 0.9988779920212766\n",
      "\n",
      "Epoch 122. Loss: 0.002628061074264692, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 122. Loss: 0.007865712402684553, Train_acc 0.9988075657894737\n",
      "\n",
      "Epoch 122. Loss: 0.007139260019488764, Train_acc 0.9988138089005235\n",
      "\n",
      "Epoch 122. Loss: 0.0065162855599099085, Train_acc 0.9988199869791666\n",
      "\n",
      "Epoch 122. Loss: 0.005884904626079159, Train_acc 0.9988261010362695\n",
      "\n",
      "Epoch 122. Loss: 0.005299642570256881, Train_acc 0.9988321520618557\n",
      "\n",
      "Epoch 122. Loss: 0.005828460298424684, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 122. Loss: 0.0052629478435245285, Train_acc 0.9988\n",
      "\n",
      "Epoch 123. Loss: 0.007664903900968474, Train_acc 0.984375\n",
      "\n",
      "Epoch 123. Loss: 0.006900626207252947, Train_acc 0.9921875\n",
      "\n",
      "Epoch 123. Loss: 0.006232946162371601, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 123. Loss: 0.0056520138943109794, Train_acc 0.99609375\n",
      "\n",
      "Epoch 123. Loss: 0.005101477067939223, Train_acc 0.996875\n",
      "\n",
      "Epoch 123. Loss: 0.004600642431913559, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 123. Loss: 0.004178462086034189, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 123. Loss: 0.0037677791624757236, Train_acc 0.998046875\n",
      "\n",
      "Epoch 123. Loss: 0.0034050697759364624, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 123. Loss: 0.0036050881248481195, Train_acc 0.9984375\n",
      "\n",
      "Epoch 123. Loss: 0.004616625522235076, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 123. Loss: 0.00762582748948846, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 123. Loss: 0.0068675685660271315, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 123. Loss: 0.006235477230444488, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 123. Loss: 0.005615740161416018, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 123. Loss: 0.005100221303874627, Train_acc 0.998046875\n",
      "\n",
      "Epoch 123. Loss: 0.011390890956915357, Train_acc 0.9967830882352942\n",
      "\n",
      "Epoch 123. Loss: 0.010314316487412024, Train_acc 0.9969618055555556\n",
      "\n",
      "Epoch 123. Loss: 0.009286268147683683, Train_acc 0.9971217105263158\n",
      "\n",
      "Epoch 123. Loss: 0.008362502281235445, Train_acc 0.997265625\n",
      "\n",
      "Epoch 123. Loss: 0.007720902894988765, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 123. Loss: 0.008929729574968018, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 123. Loss: 0.008085986276378496, Train_acc 0.9972826086956522\n",
      "\n",
      "Epoch 123. Loss: 0.007340708515060929, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 123. Loss: 0.0066285162119869775, Train_acc 0.9975\n",
      "\n",
      "Epoch 123. Loss: 0.006038926452477669, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 123. Loss: 0.005498450203963276, Train_acc 0.9976851851851852\n",
      "\n",
      "Epoch 123. Loss: 0.005123801802805653, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 123. Loss: 0.00949643204380118, Train_acc 0.9975754310344828\n",
      "\n",
      "Epoch 123. Loss: 0.009232934227010995, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 123. Loss: 0.008521987939257673, Train_acc 0.9974798387096774\n",
      "\n",
      "Epoch 123. Loss: 0.007764582160491572, Train_acc 0.99755859375\n",
      "\n",
      "Epoch 123. Loss: 0.007525810227211261, Train_acc 0.9976325757575758\n",
      "\n",
      "Epoch 123. Loss: 0.007349616410582612, Train_acc 0.9974724264705882\n",
      "\n",
      "Epoch 123. Loss: 0.006806281944605872, Train_acc 0.9975446428571428\n",
      "\n",
      "Epoch 123. Loss: 0.0074613048051236554, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 123. Loss: 0.006795946237664758, Train_acc 0.9974662162162162\n",
      "\n",
      "Epoch 123. Loss: 0.006364837510634666, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 123. Loss: 0.005741212205851206, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 123. Loss: 0.0056236010969556525, Train_acc 0.99765625\n",
      "\n",
      "Epoch 123. Loss: 0.005073216408772121, Train_acc 0.9977134146341463\n",
      "\n",
      "Epoch 123. Loss: 0.00457704251139335, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 123. Loss: 0.007880101145466913, Train_acc 0.9976380813953488\n",
      "\n",
      "Epoch 123. Loss: 0.007100531610324345, Train_acc 0.9976917613636364\n",
      "\n",
      "Epoch 123. Loss: 0.006435758951236855, Train_acc 0.9977430555555555\n",
      "\n",
      "Epoch 123. Loss: 0.005801521559991267, Train_acc 0.9977921195652174\n",
      "\n",
      "Epoch 123. Loss: 0.00524599742912251, Train_acc 0.9978390957446809\n",
      "\n",
      "Epoch 123. Loss: 0.006265534240213021, Train_acc 0.9977213541666666\n",
      "\n",
      "Epoch 123. Loss: 0.005699488028957234, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 123. Loss: 0.005143981993194515, Train_acc 0.9978125\n",
      "\n",
      "Epoch 123. Loss: 0.0046665261531679434, Train_acc 0.9978553921568627\n",
      "\n",
      "Epoch 123. Loss: 0.00423750521554763, Train_acc 0.9978966346153846\n",
      "\n",
      "Epoch 123. Loss: 0.0045283144073714155, Train_acc 0.9979363207547169\n",
      "\n",
      "Epoch 123. Loss: 0.004296825001272203, Train_acc 0.9979745370370371\n",
      "\n",
      "Epoch 123. Loss: 0.0038736487672173746, Train_acc 0.9980113636363637\n",
      "\n",
      "Epoch 123. Loss: 0.003723812544311026, Train_acc 0.998046875\n",
      "\n",
      "Epoch 123. Loss: 0.004621832488296872, Train_acc 0.9979440789473685\n",
      "\n",
      "Epoch 123. Loss: 0.004177224376202288, Train_acc 0.997979525862069\n",
      "\n",
      "Epoch 123. Loss: 0.0037644270612121433, Train_acc 0.9980137711864406\n",
      "\n",
      "Epoch 123. Loss: 0.0034392650773458163, Train_acc 0.998046875\n",
      "\n",
      "Epoch 123. Loss: 0.0034246286439075305, Train_acc 0.9980788934426229\n",
      "\n",
      "Epoch 123. Loss: 0.003264523873542181, Train_acc 0.9981098790322581\n",
      "\n",
      "Epoch 123. Loss: 0.0042493147185275835, Train_acc 0.998015873015873\n",
      "\n",
      "Epoch 123. Loss: 0.004945576510354568, Train_acc 0.9979248046875\n",
      "\n",
      "Epoch 123. Loss: 0.0044628773743821785, Train_acc 0.9979567307692307\n",
      "\n",
      "Epoch 123. Loss: 0.004074222223629902, Train_acc 0.9979876893939394\n",
      "\n",
      "Epoch 123. Loss: 0.003838348443716332, Train_acc 0.9980177238805971\n",
      "\n",
      "Epoch 123. Loss: 0.003763019231327979, Train_acc 0.998046875\n",
      "\n",
      "Epoch 123. Loss: 0.0035646587795334535, Train_acc 0.9980751811594203\n",
      "\n",
      "Epoch 123. Loss: 0.004143161697207464, Train_acc 0.9979910714285715\n",
      "\n",
      "Epoch 123. Loss: 0.003748635953208739, Train_acc 0.9980193661971831\n",
      "\n",
      "Epoch 123. Loss: 0.003407724825380647, Train_acc 0.998046875\n",
      "\n",
      "Epoch 123. Loss: 0.003145665596448693, Train_acc 0.9980736301369864\n",
      "\n",
      "Epoch 123. Loss: 0.003931402921399456, Train_acc 0.9979940878378378\n",
      "\n",
      "Epoch 123. Loss: 0.0036407456564085026, Train_acc 0.9980208333333334\n",
      "\n",
      "Epoch 123. Loss: 0.0033501579367080036, Train_acc 0.998046875\n",
      "\n",
      "Epoch 123. Loss: 0.003709410246726159, Train_acc 0.9979707792207793\n",
      "\n",
      "Epoch 123. Loss: 0.003440894914656535, Train_acc 0.9979967948717948\n",
      "\n",
      "Epoch 123. Loss: 0.004715600147536089, Train_acc 0.9979232594936709\n",
      "\n",
      "Epoch 123. Loss: 0.004321505629506951, Train_acc 0.99794921875\n",
      "\n",
      "Epoch 123. Loss: 0.005523836802083772, Train_acc 0.9978780864197531\n",
      "\n",
      "Epoch 123. Loss: 0.005203898733493854, Train_acc 0.9979039634146342\n",
      "\n",
      "Epoch 123. Loss: 0.00471298831627861, Train_acc 0.9979292168674698\n",
      "\n",
      "Epoch 123. Loss: 0.00426906878800645, Train_acc 0.9979538690476191\n",
      "\n",
      "Epoch 123. Loss: 0.0038864969324729996, Train_acc 0.9979779411764705\n",
      "\n",
      "Epoch 123. Loss: 0.003507672042644878, Train_acc 0.9980014534883721\n",
      "\n",
      "Epoch 123. Loss: 0.003177795140055926, Train_acc 0.9980244252873564\n",
      "\n",
      "Epoch 123. Loss: 0.0028674897916638633, Train_acc 0.998046875\n",
      "\n",
      "Epoch 123. Loss: 0.002606696045056249, Train_acc 0.9980688202247191\n",
      "\n",
      "Epoch 123. Loss: 0.0023966106673973192, Train_acc 0.9980902777777778\n",
      "\n",
      "Epoch 123. Loss: 0.0022477701525074893, Train_acc 0.9981112637362637\n",
      "\n",
      "Epoch 123. Loss: 0.0020369769893703376, Train_acc 0.9981317934782609\n",
      "\n",
      "Epoch 123. Loss: 0.0019206594843056812, Train_acc 0.9981518817204301\n",
      "\n",
      "Epoch 123. Loss: 0.0019155436206284475, Train_acc 0.9981715425531915\n",
      "\n",
      "Epoch 123. Loss: 0.0018975841892404834, Train_acc 0.9981907894736842\n",
      "\n",
      "Epoch 123. Loss: 0.0017198102780443373, Train_acc 0.9982096354166666\n",
      "\n",
      "Epoch 123. Loss: 0.0015530495199078196, Train_acc 0.9982280927835051\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123. Loss: 0.0014353853900370484, Train_acc 0.9982461734693877\n",
      "\n",
      "Epoch 123. Loss: 0.0016083541271809476, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 123. Loss: 0.0023692243590405946, Train_acc 0.998203125\n",
      "\n",
      "[Epoch 123 Batch 100] Loss: 0.004837771836917224 Training: accuracy=0.998144\n",
      "Epoch 123. Loss: 0.004837771836917224, Train_acc 0.9981435643564357\n",
      "\n",
      "Epoch 123. Loss: 0.004363257504606711, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 123. Loss: 0.003956068681478769, Train_acc 0.9981796116504854\n",
      "\n",
      "Epoch 123. Loss: 0.003569665649419893, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 123. Loss: 0.0040341698331110495, Train_acc 0.9981398809523809\n",
      "\n",
      "Epoch 123. Loss: 0.0036399035401117434, Train_acc 0.9981574292452831\n",
      "\n",
      "Epoch 123. Loss: 0.003290874023243577, Train_acc 0.9981746495327103\n",
      "\n",
      "Epoch 123. Loss: 0.0032701233109874643, Train_acc 0.9981915509259259\n",
      "\n",
      "Epoch 123. Loss: 0.002970530600780751, Train_acc 0.9982081422018348\n",
      "\n",
      "Epoch 123. Loss: 0.0034874164042781345, Train_acc 0.9981534090909091\n",
      "\n",
      "Epoch 123. Loss: 0.0032625397465931376, Train_acc 0.998170045045045\n",
      "\n",
      "Epoch 123. Loss: 0.003002308486533791, Train_acc 0.9981863839285714\n",
      "\n",
      "Epoch 123. Loss: 0.0033178818146580133, Train_acc 0.9982024336283186\n",
      "\n",
      "Epoch 123. Loss: 0.003336988202611537, Train_acc 0.9982182017543859\n",
      "\n",
      "Epoch 123. Loss: 0.003106956853908239, Train_acc 0.9982336956521739\n",
      "\n",
      "Epoch 123. Loss: 0.00524934303710634, Train_acc 0.9981815732758621\n",
      "\n",
      "Epoch 123. Loss: 0.004761156300751339, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 123. Loss: 0.004374645893132362, Train_acc 0.9982123940677966\n",
      "\n",
      "Epoch 123. Loss: 0.004102686172892755, Train_acc 0.9982274159663865\n",
      "\n",
      "Epoch 123. Loss: 0.003750417589790469, Train_acc 0.9982421875\n",
      "\n",
      "Epoch 123. Loss: 0.003382467339989703, Train_acc 0.9982567148760331\n",
      "\n",
      "Epoch 123. Loss: 0.003166918757962878, Train_acc 0.9982710040983607\n",
      "\n",
      "Epoch 123. Loss: 0.0028564589435899515, Train_acc 0.9982850609756098\n",
      "\n",
      "Epoch 123. Loss: 0.002572710733573068, Train_acc 0.9982988911290323\n",
      "\n",
      "Epoch 123. Loss: 0.002606289977321412, Train_acc 0.9983125\n",
      "\n",
      "Epoch 123. Loss: 0.0023614602355145017, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 123. Loss: 0.0021798112218047766, Train_acc 0.9983390748031497\n",
      "\n",
      "Epoch 123. Loss: 0.002045379955832564, Train_acc 0.99835205078125\n",
      "\n",
      "Epoch 123. Loss: 0.0024502243419120343, Train_acc 0.9983042635658915\n",
      "\n",
      "Epoch 123. Loss: 0.002323725988328871, Train_acc 0.9983173076923076\n",
      "\n",
      "Epoch 123. Loss: 0.0021244173315968368, Train_acc 0.9983301526717557\n",
      "\n",
      "Epoch 123. Loss: 0.001986861028950103, Train_acc 0.998342803030303\n",
      "\n",
      "Epoch 123. Loss: 0.0022559556241458847, Train_acc 0.9983552631578947\n",
      "\n",
      "Epoch 123. Loss: 0.0020400414945884746, Train_acc 0.9983675373134329\n",
      "\n",
      "Epoch 123. Loss: 0.001867457785193439, Train_acc 0.9983796296296297\n",
      "\n",
      "Epoch 123. Loss: 0.0016902326867065328, Train_acc 0.9983915441176471\n",
      "\n",
      "Epoch 123. Loss: 0.0023202704034818557, Train_acc 0.9983462591240876\n",
      "\n",
      "Epoch 123. Loss: 0.002095773708598727, Train_acc 0.9983582427536232\n",
      "\n",
      "Epoch 123. Loss: 0.002069623019644839, Train_acc 0.9983700539568345\n",
      "\n",
      "Epoch 123. Loss: 0.0035727859628342596, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 123. Loss: 0.0036489181638189863, Train_acc 0.9983377659574468\n",
      "\n",
      "Epoch 123. Loss: 0.003311214936302189, Train_acc 0.9983494718309859\n",
      "\n",
      "Epoch 123. Loss: 0.0035051463347161565, Train_acc 0.998361013986014\n",
      "\n",
      "Epoch 123. Loss: 0.0031712629105360587, Train_acc 0.9983723958333334\n",
      "\n",
      "Epoch 123. Loss: 0.0029210704644194647, Train_acc 0.9983836206896551\n",
      "\n",
      "Epoch 123. Loss: 0.0027071522089172667, Train_acc 0.998394691780822\n",
      "\n",
      "Epoch 123. Loss: 0.0029706017538752493, Train_acc 0.998405612244898\n",
      "\n",
      "Epoch 123. Loss: 0.0029457428129625028, Train_acc 0.9984163851351351\n",
      "\n",
      "Epoch 123. Loss: 0.002670052582617126, Train_acc 0.9984270134228188\n",
      "\n",
      "Epoch 123. Loss: 0.005239325591560175, Train_acc 0.9983854166666667\n",
      "\n",
      "Epoch 123. Loss: 0.004723073240768194, Train_acc 0.9983961092715232\n",
      "\n",
      "Epoch 123. Loss: 0.004270524853524034, Train_acc 0.9984066611842105\n",
      "\n",
      "Epoch 123. Loss: 0.0038539638333899956, Train_acc 0.9984170751633987\n",
      "\n",
      "Epoch 123. Loss: 0.0035172262315031006, Train_acc 0.9984273538961039\n",
      "\n",
      "Epoch 123. Loss: 0.0033251415992260973, Train_acc 0.9984375\n",
      "\n",
      "Epoch 123. Loss: 0.003130968155088067, Train_acc 0.9984475160256411\n",
      "\n",
      "Epoch 123. Loss: 0.00491997740413729, Train_acc 0.9984076433121019\n",
      "\n",
      "Epoch 123. Loss: 0.012383526340836143, Train_acc 0.998318829113924\n",
      "\n",
      "Epoch 123. Loss: 0.011207967054504251, Train_acc 0.9983294025157232\n",
      "\n",
      "Epoch 123. Loss: 0.010109797640090597, Train_acc 0.99833984375\n",
      "\n",
      "Epoch 123. Loss: 0.009127492593841251, Train_acc 0.9983501552795031\n",
      "\n",
      "Epoch 123. Loss: 0.010924174163147657, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 123. Loss: 0.010665546751086278, Train_acc 0.9982745398773006\n",
      "\n",
      "Epoch 123. Loss: 0.0102252848541567, Train_acc 0.9982374237804879\n",
      "\n",
      "Epoch 123. Loss: 0.01003042003996634, Train_acc 0.9982007575757575\n",
      "\n",
      "Epoch 123. Loss: 0.010822493544108839, Train_acc 0.9981645331325302\n",
      "\n",
      "Epoch 123. Loss: 0.00979097743979812, Train_acc 0.9981755239520959\n",
      "\n",
      "Epoch 123. Loss: 0.009658511241391781, Train_acc 0.9981398809523809\n",
      "\n",
      "Epoch 123. Loss: 0.009427520846678748, Train_acc 0.9981046597633136\n",
      "\n",
      "Epoch 123. Loss: 0.010514756186622919, Train_acc 0.9980698529411764\n",
      "\n",
      "Epoch 123. Loss: 0.011456058675484545, Train_acc 0.9980354532163743\n",
      "\n",
      "Epoch 123. Loss: 0.013022169288489241, Train_acc 0.9980014534883721\n",
      "\n",
      "Epoch 123. Loss: 0.011759523237201664, Train_acc 0.9980130057803468\n",
      "\n",
      "Epoch 123. Loss: 0.011604816966759943, Train_acc 0.997979525862069\n",
      "\n",
      "Epoch 123. Loss: 0.010532712945358336, Train_acc 0.9979910714285715\n",
      "\n",
      "Epoch 123. Loss: 0.010841069061919792, Train_acc 0.9979580965909091\n",
      "\n",
      "Epoch 123. Loss: 0.009820048980685095, Train_acc 0.9979696327683616\n",
      "\n",
      "Epoch 123. Loss: 0.009237018668894785, Train_acc 0.9979810393258427\n",
      "\n",
      "Epoch 123. Loss: 0.008353673896263377, Train_acc 0.9979923184357542\n",
      "\n",
      "Epoch 123. Loss: 0.00765905890551165, Train_acc 0.9980034722222222\n",
      "\n",
      "Epoch 123. Loss: 0.006927457775589796, Train_acc 0.998014502762431\n",
      "\n",
      "Epoch 123. Loss: 0.006285504718898137, Train_acc 0.9980254120879121\n",
      "\n",
      "Epoch 123. Loss: 0.005771493163394987, Train_acc 0.9980362021857924\n",
      "\n",
      "Epoch 123. Loss: 0.0089386536151362, Train_acc 0.9979619565217391\n",
      "\n",
      "Epoch 123. Loss: 0.008094965690410216, Train_acc 0.9979729729729729\n",
      "\n",
      "Epoch 123. Loss: 0.010465739390882325, Train_acc 0.9978998655913979\n",
      "\n",
      "Epoch 123. Loss: 0.013461398233442728, Train_acc 0.9978275401069518\n",
      "\n",
      "Epoch 123. Loss: 0.012248916424336335, Train_acc 0.9978390957446809\n",
      "\n",
      "Epoch 123. Loss: 0.015567195487340363, Train_acc 0.9978091931216931\n",
      "\n",
      "Epoch 123. Loss: 0.015379969020772046, Train_acc 0.9977796052631579\n",
      "\n",
      "Epoch 123. Loss: 0.013875164874349295, Train_acc 0.9977912303664922\n",
      "\n",
      "Epoch 123. Loss: 0.013042164320532314, Train_acc 0.997802734375\n",
      "\n",
      "Epoch 123. Loss: 0.011812260049201995, Train_acc 0.9978141191709845\n",
      "\n",
      "Epoch 123. Loss: 0.010751151524682746, Train_acc 0.9978253865979382\n",
      "\n",
      "Epoch 123. Loss: 0.009764432633194988, Train_acc 0.9978365384615384\n",
      "\n",
      "Epoch 123. Loss: 0.008952562671902328, Train_acc 0.99784\n",
      "\n",
      "Epoch 124. Loss: 0.008374204091282979, Train_acc 1.0\n",
      "\n",
      "Epoch 124. Loss: 0.009030152538763549, Train_acc 0.99609375\n",
      "\n",
      "Epoch 124. Loss: 0.008805223286313177, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 124. Loss: 0.00822654956575098, Train_acc 0.998046875\n",
      "\n",
      "Epoch 124. Loss: 0.008975181078873835, Train_acc 0.996875\n",
      "\n",
      "Epoch 124. Loss: 0.011685202058520403, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 124. Loss: 0.011733248322188694, Train_acc 0.9944196428571429\n",
      "\n",
      "Epoch 124. Loss: 0.010650777680026969, Train_acc 0.9951171875\n",
      "\n",
      "Epoch 124. Loss: 0.009807021597263944, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 124. Loss: 0.00918976485921836, Train_acc 0.99609375\n",
      "\n",
      "Epoch 124. Loss: 0.009246989799534346, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 124. Loss: 0.00867285223163223, Train_acc 0.9967447916666666\n",
      "\n",
      "Epoch 124. Loss: 0.007955826161920778, Train_acc 0.9969951923076923\n",
      "\n",
      "Epoch 124. Loss: 0.007392591671156662, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 124. Loss: 0.0071462536962399875, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 124. Loss: 0.006542061169828027, Train_acc 0.99755859375\n",
      "\n",
      "Epoch 124. Loss: 0.005928261937936439, Train_acc 0.9977022058823529\n",
      "\n",
      "Epoch 124. Loss: 0.005735730200773741, Train_acc 0.9978298611111112\n",
      "\n",
      "Epoch 124. Loss: 0.005832835116400956, Train_acc 0.9979440789473685\n",
      "\n",
      "Epoch 124. Loss: 0.005463862573055601, Train_acc 0.998046875\n",
      "\n",
      "Epoch 124. Loss: 0.00643569835345284, Train_acc 0.9973958333333334\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124. Loss: 0.0058152430261836615, Train_acc 0.9975142045454546\n",
      "\n",
      "Epoch 124. Loss: 0.005290527782443866, Train_acc 0.9976222826086957\n",
      "\n",
      "Epoch 124. Loss: 0.005751128174308275, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 124. Loss: 0.0052774227646604195, Train_acc 0.9975\n",
      "\n",
      "Epoch 124. Loss: 0.004826258702260481, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 124. Loss: 0.0049864882974465724, Train_acc 0.9976851851851852\n",
      "\n",
      "Epoch 124. Loss: 0.004544101362926367, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 124. Loss: 0.004096407290578353, Train_acc 0.9978448275862069\n",
      "\n",
      "Epoch 124. Loss: 0.003755583173995138, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 124. Loss: 0.006070878407625784, Train_acc 0.9977318548387096\n",
      "\n",
      "Epoch 124. Loss: 0.005648013040626135, Train_acc 0.997802734375\n",
      "\n",
      "Epoch 124. Loss: 0.005257415880259055, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 124. Loss: 0.004907699788563262, Train_acc 0.9979319852941176\n",
      "\n",
      "Epoch 124. Loss: 0.004453619312010424, Train_acc 0.9979910714285715\n",
      "\n",
      "Epoch 124. Loss: 0.004032270698115908, Train_acc 0.998046875\n",
      "\n",
      "Epoch 124. Loss: 0.003839057334541395, Train_acc 0.9980996621621622\n",
      "\n",
      "Epoch 124. Loss: 0.003524168506123079, Train_acc 0.9981496710526315\n",
      "\n",
      "Epoch 124. Loss: 0.00319478365277234, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 124. Loss: 0.002885574249564055, Train_acc 0.9982421875\n",
      "\n",
      "Epoch 124. Loss: 0.002686397091916674, Train_acc 0.9982850609756098\n",
      "\n",
      "Epoch 124. Loss: 0.003981174921725518, Train_acc 0.9981398809523809\n",
      "\n",
      "Epoch 124. Loss: 0.003659917362877124, Train_acc 0.9981831395348837\n",
      "\n",
      "Epoch 124. Loss: 0.003517205766788179, Train_acc 0.9982244318181818\n",
      "\n",
      "Epoch 124. Loss: 0.003188310541443538, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 124. Loss: 0.003010796034823368, Train_acc 0.9983016304347826\n",
      "\n",
      "Epoch 124. Loss: 0.0027240213772849087, Train_acc 0.9983377659574468\n",
      "\n",
      "Epoch 124. Loss: 0.0025409776906341326, Train_acc 0.9983723958333334\n",
      "\n",
      "Epoch 124. Loss: 0.0025471735450032363, Train_acc 0.998405612244898\n",
      "\n",
      "Epoch 124. Loss: 0.0027617316147598337, Train_acc 0.9984375\n",
      "\n",
      "Epoch 124. Loss: 0.002531284546514619, Train_acc 0.9984681372549019\n",
      "\n",
      "Epoch 124. Loss: 0.0022903367339424862, Train_acc 0.9984975961538461\n",
      "\n",
      "Epoch 124. Loss: 0.0022368651773313503, Train_acc 0.9985259433962265\n",
      "\n",
      "Epoch 124. Loss: 0.0022814396545243103, Train_acc 0.9985532407407407\n",
      "\n",
      "Epoch 124. Loss: 0.002061511451572065, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 124. Loss: 0.0018618175208913994, Train_acc 0.9986049107142857\n",
      "\n",
      "Epoch 124. Loss: 0.0017249240370033126, Train_acc 0.9986293859649122\n",
      "\n",
      "Epoch 124. Loss: 0.0016623020624537417, Train_acc 0.9986530172413793\n",
      "\n",
      "Epoch 124. Loss: 0.0015467098436506821, Train_acc 0.9986758474576272\n",
      "\n",
      "Epoch 124. Loss: 0.0019678406360076877, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 124. Loss: 0.0017763036019555463, Train_acc 0.998719262295082\n",
      "\n",
      "Epoch 124. Loss: 0.0018254969945059778, Train_acc 0.9987399193548387\n",
      "\n",
      "Epoch 124. Loss: 0.0016503540110866354, Train_acc 0.9987599206349206\n",
      "\n",
      "Epoch 124. Loss: 0.0015036851846369844, Train_acc 0.998779296875\n",
      "\n",
      "Epoch 124. Loss: 0.0013646786524264638, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 124. Loss: 0.0012368950267669075, Train_acc 0.9988162878787878\n",
      "\n",
      "Epoch 124. Loss: 0.0011213430285730913, Train_acc 0.9988339552238806\n",
      "\n",
      "Epoch 124. Loss: 0.0010713409566756149, Train_acc 0.9988511029411765\n",
      "\n",
      "Epoch 124. Loss: 0.0010126104018670524, Train_acc 0.9988677536231884\n",
      "\n",
      "Epoch 124. Loss: 0.0031102131362183874, Train_acc 0.9987723214285714\n",
      "\n",
      "Epoch 124. Loss: 0.002878251330294369, Train_acc 0.9987896126760564\n",
      "\n",
      "Epoch 124. Loss: 0.0025990985457504936, Train_acc 0.9988064236111112\n",
      "\n",
      "Epoch 124. Loss: 0.002372090949856578, Train_acc 0.9988227739726028\n",
      "\n",
      "Epoch 124. Loss: 0.00215246521489332, Train_acc 0.9988386824324325\n",
      "\n",
      "Epoch 124. Loss: 0.0019448877375386607, Train_acc 0.9988541666666667\n",
      "\n",
      "Epoch 124. Loss: 0.0018275586782041894, Train_acc 0.9988692434210527\n",
      "\n",
      "Epoch 124. Loss: 0.0017142590377403383, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 124. Loss: 0.0015482504496631363, Train_acc 0.9988982371794872\n",
      "\n",
      "Epoch 124. Loss: 0.0024181414727560287, Train_acc 0.9988132911392406\n",
      "\n",
      "Epoch 124. Loss: 0.0025683430229149705, Train_acc 0.998828125\n",
      "\n",
      "Epoch 124. Loss: 0.002326745684723514, Train_acc 0.9988425925925926\n",
      "\n",
      "Epoch 124. Loss: 0.002111720742785129, Train_acc 0.9988567073170732\n",
      "\n",
      "Epoch 124. Loss: 0.0019235376604931106, Train_acc 0.9988704819277109\n",
      "\n",
      "Epoch 124. Loss: 0.0025576768931928175, Train_acc 0.9987909226190477\n",
      "\n",
      "Epoch 124. Loss: 0.002306255545539486, Train_acc 0.9988051470588235\n",
      "\n",
      "Epoch 124. Loss: 0.0021185223461081407, Train_acc 0.9988190406976745\n",
      "\n",
      "Epoch 124. Loss: 0.0019165326473050963, Train_acc 0.9988326149425287\n",
      "\n",
      "Epoch 124. Loss: 0.001801727278554468, Train_acc 0.9988458806818182\n",
      "\n",
      "Epoch 124. Loss: 0.0016462014001869293, Train_acc 0.9988588483146067\n",
      "\n",
      "Epoch 124. Loss: 0.0014917242281171593, Train_acc 0.9988715277777778\n",
      "\n",
      "Epoch 124. Loss: 0.001585067575092576, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 124. Loss: 0.0023360627836723287, Train_acc 0.9988111413043478\n",
      "\n",
      "Epoch 124. Loss: 0.002121698568295184, Train_acc 0.9988239247311828\n",
      "\n",
      "Epoch 124. Loss: 0.0019405471083051651, Train_acc 0.9988364361702128\n",
      "\n",
      "Epoch 124. Loss: 0.0018652098090076467, Train_acc 0.9988486842105263\n",
      "\n",
      "Epoch 124. Loss: 0.001701652766060928, Train_acc 0.9988606770833334\n",
      "\n",
      "Epoch 124. Loss: 0.001562867082292601, Train_acc 0.9988724226804123\n",
      "\n",
      "Epoch 124. Loss: 0.0022885112803889196, Train_acc 0.9988042091836735\n",
      "\n",
      "Epoch 124. Loss: 0.0032440133847337557, Train_acc 0.9987373737373737\n",
      "\n",
      "Epoch 124. Loss: 0.00299015712940506, Train_acc 0.99875\n",
      "\n",
      "[Epoch 124 Batch 100] Loss: 0.0028118441283298597 Training: accuracy=0.998762\n",
      "Epoch 124. Loss: 0.0028118441283298597, Train_acc 0.9987623762376238\n",
      "\n",
      "Epoch 124. Loss: 0.0025327078480887545, Train_acc 0.9987745098039216\n",
      "\n",
      "Epoch 124. Loss: 0.0023069667519483167, Train_acc 0.9987864077669902\n",
      "\n",
      "Epoch 124. Loss: 0.003566774837048638, Train_acc 0.9987229567307693\n",
      "\n",
      "Epoch 124. Loss: 0.003229781686872632, Train_acc 0.998735119047619\n",
      "\n",
      "Epoch 124. Loss: 0.0033380577448997415, Train_acc 0.9987470518867925\n",
      "\n",
      "Epoch 124. Loss: 0.0030219190752491143, Train_acc 0.998758761682243\n",
      "\n",
      "Epoch 124. Loss: 0.002730960421186909, Train_acc 0.9987702546296297\n",
      "\n",
      "Epoch 124. Loss: 0.0024678548247556533, Train_acc 0.9987815366972477\n",
      "\n",
      "Epoch 124. Loss: 0.002226048087262597, Train_acc 0.9987926136363636\n",
      "\n",
      "Epoch 124. Loss: 0.0020060061978623474, Train_acc 0.998803490990991\n",
      "\n",
      "Epoch 124. Loss: 0.0019252527420997804, Train_acc 0.9988141741071429\n",
      "\n",
      "Epoch 124. Loss: 0.0017458467965404483, Train_acc 0.9988246681415929\n",
      "\n",
      "Epoch 124. Loss: 0.0015797101774301455, Train_acc 0.9988349780701754\n",
      "\n",
      "Epoch 124. Loss: 0.0015996689312855594, Train_acc 0.9988451086956521\n",
      "\n",
      "Epoch 124. Loss: 0.0016396483801931316, Train_acc 0.9988550646551724\n",
      "\n",
      "Epoch 124. Loss: 0.0015899175086249568, Train_acc 0.9988648504273504\n",
      "\n",
      "Epoch 124. Loss: 0.0014344702121379758, Train_acc 0.998874470338983\n",
      "\n",
      "Epoch 124. Loss: 0.0012998541349130471, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 124. Loss: 0.0011762349675106159, Train_acc 0.9988932291666667\n",
      "\n",
      "Epoch 124. Loss: 0.001064512302943679, Train_acc 0.9989023760330579\n",
      "\n",
      "Epoch 124. Loss: 0.0009726842034956139, Train_acc 0.9989113729508197\n",
      "\n",
      "Epoch 124. Loss: 0.0008775759385641487, Train_acc 0.9989202235772358\n",
      "\n",
      "Epoch 124. Loss: 0.0008090748984950063, Train_acc 0.9989289314516129\n",
      "\n",
      "Epoch 124. Loss: 0.0007853227448988506, Train_acc 0.9989375\n",
      "\n",
      "Epoch 124. Loss: 0.0013266528853054537, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 124. Loss: 0.0011944627728319882, Train_acc 0.9988927165354331\n",
      "\n",
      "Epoch 124. Loss: 0.001174675368480985, Train_acc 0.9989013671875\n",
      "\n",
      "Epoch 124. Loss: 0.001058720649831421, Train_acc 0.9989098837209303\n",
      "\n",
      "Epoch 124. Loss: 0.0009542273749053396, Train_acc 0.9989182692307692\n",
      "\n",
      "Epoch 124. Loss: 0.000863090880034661, Train_acc 0.9989265267175572\n",
      "\n",
      "Epoch 124. Loss: 0.000787715813733464, Train_acc 0.9989346590909091\n",
      "\n",
      "Epoch 124. Loss: 0.000738785306498066, Train_acc 0.9989426691729323\n",
      "\n",
      "Epoch 124. Loss: 0.0006729016293613419, Train_acc 0.9989505597014925\n",
      "\n",
      "Epoch 124. Loss: 0.0006065382806345864, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 124. Loss: 0.0005461242645415871, Train_acc 0.9989659926470589\n",
      "\n",
      "Epoch 124. Loss: 0.000850483069704462, Train_acc 0.9989735401459854\n",
      "\n",
      "Epoch 124. Loss: 0.0007660450893399813, Train_acc 0.9989809782608695\n",
      "\n",
      "Epoch 124. Loss: 0.0006924449127991582, Train_acc 0.998988309352518\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124. Loss: 0.000628306637641173, Train_acc 0.9989955357142857\n",
      "\n",
      "Epoch 124. Loss: 0.0005679964452663447, Train_acc 0.9990026595744681\n",
      "\n",
      "Epoch 124. Loss: 0.0005487509662045362, Train_acc 0.9990096830985915\n",
      "\n",
      "Epoch 124. Loss: 0.0004990634083566712, Train_acc 0.9990166083916084\n",
      "\n",
      "Epoch 124. Loss: 0.00046043466503498527, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 124. Loss: 0.0004155703518639735, Train_acc 0.9990301724137931\n",
      "\n",
      "Epoch 124. Loss: 0.0029807131186590256, Train_acc 0.9989833047945206\n",
      "\n",
      "Epoch 124. Loss: 0.0026851830750520608, Train_acc 0.9989902210884354\n",
      "\n",
      "Epoch 124. Loss: 0.002420239366942361, Train_acc 0.998997043918919\n",
      "\n",
      "Epoch 124. Loss: 0.0021842042669585823, Train_acc 0.9990037751677853\n",
      "\n",
      "Epoch 124. Loss: 0.007982717758261992, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 124. Loss: 0.007197286131137591, Train_acc 0.9989652317880795\n",
      "\n",
      "Epoch 124. Loss: 0.006487372195492799, Train_acc 0.9989720394736842\n",
      "\n",
      "Epoch 124. Loss: 0.005843688214362869, Train_acc 0.9989787581699346\n",
      "\n",
      "Epoch 124. Loss: 0.005290660266028308, Train_acc 0.9989853896103896\n",
      "\n",
      "Epoch 124. Loss: 0.004913908984780875, Train_acc 0.998991935483871\n",
      "\n",
      "Epoch 124. Loss: 0.0044273619768678855, Train_acc 0.9989983974358975\n",
      "\n",
      "Epoch 124. Loss: 0.004034330063355464, Train_acc 0.9990047770700637\n",
      "\n",
      "Epoch 124. Loss: 0.0039265539997823526, Train_acc 0.9990110759493671\n",
      "\n",
      "Epoch 124. Loss: 0.003544794273571781, Train_acc 0.9990172955974843\n",
      "\n",
      "Epoch 124. Loss: 0.0060683357362716905, Train_acc 0.998974609375\n",
      "\n",
      "Epoch 124. Loss: 0.009701770258972304, Train_acc 0.9989324534161491\n",
      "\n",
      "Epoch 124. Loss: 0.010132273700561457, Train_acc 0.9988908179012346\n",
      "\n",
      "Epoch 124. Loss: 0.009177563417523429, Train_acc 0.9988976226993865\n",
      "\n",
      "Epoch 124. Loss: 0.008271327836516129, Train_acc 0.9989043445121951\n",
      "\n",
      "Epoch 124. Loss: 0.0075292865855382035, Train_acc 0.9989109848484848\n",
      "\n",
      "Epoch 124. Loss: 0.006993928384591891, Train_acc 0.9989175451807228\n",
      "\n",
      "Epoch 124. Loss: 0.006310324944590557, Train_acc 0.9989240269461078\n",
      "\n",
      "Epoch 124. Loss: 0.005683674393785654, Train_acc 0.9989304315476191\n",
      "\n",
      "Epoch 124. Loss: 0.005141193464091003, Train_acc 0.9989367603550295\n",
      "\n",
      "Epoch 124. Loss: 0.004634676604266703, Train_acc 0.9989430147058823\n",
      "\n",
      "Epoch 124. Loss: 0.004223625239351681, Train_acc 0.9989491959064327\n",
      "\n",
      "Epoch 124. Loss: 0.003824044338245428, Train_acc 0.9989553052325582\n",
      "\n",
      "Epoch 124. Loss: 0.0036252548415437965, Train_acc 0.9989613439306358\n",
      "\n",
      "Epoch 124. Loss: 0.0034441411461882854, Train_acc 0.9989673132183908\n",
      "\n",
      "Epoch 124. Loss: 0.004132906027864194, Train_acc 0.9989732142857143\n",
      "\n",
      "Epoch 124. Loss: 0.0038614124302766705, Train_acc 0.9989790482954546\n",
      "\n",
      "Epoch 124. Loss: 0.005358891769769966, Train_acc 0.9989406779661016\n",
      "\n",
      "Epoch 124. Loss: 0.007056626306047898, Train_acc 0.9988588483146067\n",
      "\n",
      "Epoch 124. Loss: 0.008623748012844499, Train_acc 0.9987779329608939\n",
      "\n",
      "Epoch 124. Loss: 0.007874031403498002, Train_acc 0.9987847222222223\n",
      "\n",
      "Epoch 124. Loss: 0.010602337082179917, Train_acc 0.9987051104972375\n",
      "\n",
      "Epoch 124. Loss: 0.014400998765187741, Train_acc 0.9986692994505495\n",
      "\n",
      "Epoch 124. Loss: 0.013084827504026694, Train_acc 0.9986765710382514\n",
      "\n",
      "Epoch 124. Loss: 0.011811913010486487, Train_acc 0.9986837635869565\n",
      "\n",
      "Epoch 124. Loss: 0.010937028651803902, Train_acc 0.9986908783783783\n",
      "\n",
      "Epoch 124. Loss: 0.009882898293999364, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 124. Loss: 0.009716478936881599, Train_acc 0.9986631016042781\n",
      "\n",
      "Epoch 124. Loss: 0.008788678041790003, Train_acc 0.9986702127659575\n",
      "\n",
      "Epoch 124. Loss: 0.008961794406200119, Train_acc 0.9986359126984127\n",
      "\n",
      "Epoch 124. Loss: 0.021006333199165464, Train_acc 0.9985608552631579\n",
      "\n",
      "Epoch 124. Loss: 0.01943165908785659, Train_acc 0.998568390052356\n",
      "\n",
      "Epoch 124. Loss: 0.018389035356330855, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 124. Loss: 0.01814507630522965, Train_acc 0.9985022668393783\n",
      "\n",
      "Epoch 124. Loss: 0.01885689124067949, Train_acc 0.9984294458762887\n",
      "\n",
      "Epoch 124. Loss: 0.01750497283987993, Train_acc 0.9984375\n",
      "\n",
      "Epoch 124. Loss: 0.01580502630751284, Train_acc 0.99844\n",
      "\n",
      "Epoch 125. Loss: 0.01425518098237658, Train_acc 1.0\n",
      "\n",
      "Epoch 125. Loss: 0.012881499408064807, Train_acc 1.0\n",
      "\n",
      "Epoch 125. Loss: 0.011915235503803365, Train_acc 1.0\n",
      "\n",
      "Epoch 125. Loss: 0.01137098612535656, Train_acc 0.998046875\n",
      "\n",
      "Epoch 125. Loss: 0.013525174040931408, Train_acc 0.996875\n",
      "\n",
      "Epoch 125. Loss: 0.012511633886177492, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 125. Loss: 0.011519541620414691, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 125. Loss: 0.010653776575842116, Train_acc 0.998046875\n",
      "\n",
      "Epoch 125. Loss: 0.010890774935232352, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 125. Loss: 0.010628081568849162, Train_acc 0.996875\n",
      "\n",
      "Epoch 125. Loss: 0.01548574503550417, Train_acc 0.9950284090909091\n",
      "\n",
      "Epoch 125. Loss: 0.016368683901037157, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 125. Loss: 0.014944809961636706, Train_acc 0.9951923076923077\n",
      "\n",
      "Epoch 125. Loss: 0.01478721961079822, Train_acc 0.9949776785714286\n",
      "\n",
      "Epoch 125. Loss: 0.015182204675961607, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 125. Loss: 0.013904656820928223, Train_acc 0.9951171875\n",
      "\n",
      "Epoch 125. Loss: 0.012794377486498804, Train_acc 0.9954044117647058\n",
      "\n",
      "Epoch 125. Loss: 0.011741683676250265, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 125. Loss: 0.01064263336605503, Train_acc 0.9958881578947368\n",
      "\n",
      "Epoch 125. Loss: 0.00996318604458875, Train_acc 0.99609375\n",
      "\n",
      "Epoch 125. Loss: 0.009334208025346754, Train_acc 0.9962797619047619\n",
      "\n",
      "Epoch 125. Loss: 0.010612573284337425, Train_acc 0.9957386363636364\n",
      "\n",
      "Epoch 125. Loss: 0.012057075105693494, Train_acc 0.9952445652173914\n",
      "\n",
      "Epoch 125. Loss: 0.012329405298906465, Train_acc 0.9951171875\n",
      "\n",
      "Epoch 125. Loss: 0.011523307274128109, Train_acc 0.9953125\n",
      "\n",
      "Epoch 125. Loss: 0.012420957418094673, Train_acc 0.9951923076923077\n",
      "\n",
      "Epoch 125. Loss: 0.011285771745292633, Train_acc 0.9953703703703703\n",
      "\n",
      "Epoch 125. Loss: 0.011909984634382984, Train_acc 0.9952566964285714\n",
      "\n",
      "Epoch 125. Loss: 0.010947772965413445, Train_acc 0.9954202586206896\n",
      "\n",
      "Epoch 125. Loss: 0.009883082536499789, Train_acc 0.9955729166666667\n",
      "\n",
      "Epoch 125. Loss: 0.009195504139676175, Train_acc 0.9957157258064516\n",
      "\n",
      "Epoch 125. Loss: 0.008512709172239437, Train_acc 0.995849609375\n",
      "\n",
      "Epoch 125. Loss: 0.007738196656716719, Train_acc 0.9959753787878788\n",
      "\n",
      "Epoch 125. Loss: 0.0075672297770048875, Train_acc 0.99609375\n",
      "\n",
      "Epoch 125. Loss: 0.010100733109795961, Train_acc 0.9959821428571428\n",
      "\n",
      "Epoch 125. Loss: 0.01028476975275628, Train_acc 0.9958767361111112\n",
      "\n",
      "Epoch 125. Loss: 0.00967962536063986, Train_acc 0.9959881756756757\n",
      "\n",
      "Epoch 125. Loss: 0.010648457828288053, Train_acc 0.9956825657894737\n",
      "\n",
      "Epoch 125. Loss: 0.011086131053231455, Train_acc 0.9955929487179487\n",
      "\n",
      "Epoch 125. Loss: 0.010010656972070974, Train_acc 0.995703125\n",
      "\n",
      "Epoch 125. Loss: 0.010317870666242042, Train_acc 0.9956173780487805\n",
      "\n",
      "Epoch 125. Loss: 0.009408808247717232, Train_acc 0.9957217261904762\n",
      "\n",
      "Epoch 125. Loss: 0.008581175072224001, Train_acc 0.9958212209302325\n",
      "\n",
      "Epoch 125. Loss: 0.00782566405059939, Train_acc 0.9959161931818182\n",
      "\n",
      "Epoch 125. Loss: 0.007321478996920992, Train_acc 0.9960069444444445\n",
      "\n",
      "Epoch 125. Loss: 0.006599070986584735, Train_acc 0.99609375\n",
      "\n",
      "Epoch 125. Loss: 0.0073560244087659534, Train_acc 0.9960106382978723\n",
      "\n",
      "Epoch 125. Loss: 0.007731566819782545, Train_acc 0.9959309895833334\n",
      "\n",
      "Epoch 125. Loss: 0.007020929240161618, Train_acc 0.9960140306122449\n",
      "\n",
      "Epoch 125. Loss: 0.0063815352161465805, Train_acc 0.99609375\n",
      "\n",
      "Epoch 125. Loss: 0.005935315193249768, Train_acc 0.9961703431372549\n",
      "\n",
      "Epoch 125. Loss: 0.005371484374467681, Train_acc 0.9962439903846154\n",
      "\n",
      "Epoch 125. Loss: 0.005840909934458866, Train_acc 0.9961674528301887\n",
      "\n",
      "Epoch 125. Loss: 0.0065380433184663075, Train_acc 0.99609375\n",
      "\n",
      "Epoch 125. Loss: 0.0084045468851411, Train_acc 0.9960227272727272\n",
      "\n",
      "Epoch 125. Loss: 0.007953401214545994, Train_acc 0.99609375\n",
      "\n",
      "Epoch 125. Loss: 0.007265554717182544, Train_acc 0.9961622807017544\n",
      "\n",
      "Epoch 125. Loss: 0.006563291176650161, Train_acc 0.9962284482758621\n",
      "\n",
      "Epoch 125. Loss: 0.006894019167417199, Train_acc 0.9961599576271186\n",
      "\n",
      "Epoch 125. Loss: 0.006775184109771768, Train_acc 0.9962239583333333\n",
      "\n",
      "Epoch 125. Loss: 0.006797093702075947, Train_acc 0.9962858606557377\n",
      "\n",
      "Epoch 125. Loss: 0.008047916005001725, Train_acc 0.9962197580645161\n",
      "\n",
      "Epoch 125. Loss: 0.010396327832293148, Train_acc 0.996031746031746\n",
      "\n",
      "Epoch 125. Loss: 0.00972258984911588, Train_acc 0.99609375\n",
      "\n",
      "Epoch 125. Loss: 0.008801507057141712, Train_acc 0.9961538461538462\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125. Loss: 0.007956590307141461, Train_acc 0.9962121212121212\n",
      "\n",
      "Epoch 125. Loss: 0.007275538482041762, Train_acc 0.996268656716418\n",
      "\n",
      "Epoch 125. Loss: 0.008580855805669672, Train_acc 0.9962086397058824\n",
      "\n",
      "Epoch 125. Loss: 0.007790140062882257, Train_acc 0.9962635869565217\n",
      "\n",
      "Epoch 125. Loss: 0.0070335098649852, Train_acc 0.9963169642857143\n",
      "\n",
      "Epoch 125. Loss: 0.006338383744665032, Train_acc 0.996368838028169\n",
      "\n",
      "Epoch 125. Loss: 0.005999978679127734, Train_acc 0.9964192708333334\n",
      "\n",
      "Epoch 125. Loss: 0.0054153042922718, Train_acc 0.9964683219178082\n",
      "\n",
      "Epoch 125. Loss: 0.0049302254628567545, Train_acc 0.9965160472972973\n",
      "\n",
      "Epoch 125. Loss: 0.004613826484975545, Train_acc 0.9965625\n",
      "\n",
      "Epoch 125. Loss: 0.005387422832695242, Train_acc 0.9966077302631579\n",
      "\n",
      "Epoch 125. Loss: 0.005420912892682191, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 125. Loss: 0.004909298060736919, Train_acc 0.9966947115384616\n",
      "\n",
      "Epoch 125. Loss: 0.00458953023316878, Train_acc 0.9967365506329114\n",
      "\n",
      "Epoch 125. Loss: 0.00414976316065687, Train_acc 0.99677734375\n",
      "\n",
      "Epoch 125. Loss: 0.0038293633388937834, Train_acc 0.9968171296296297\n",
      "\n",
      "Epoch 125. Loss: 0.004095272224989056, Train_acc 0.9968559451219512\n",
      "\n",
      "Epoch 125. Loss: 0.004592356515836584, Train_acc 0.9967996987951807\n",
      "\n",
      "Epoch 125. Loss: 0.004154059111578756, Train_acc 0.9968377976190477\n",
      "\n",
      "Epoch 125. Loss: 0.0041687498397411345, Train_acc 0.996875\n",
      "\n",
      "Epoch 125. Loss: 0.0038016176617713814, Train_acc 0.9969113372093024\n",
      "\n",
      "Epoch 125. Loss: 0.0035061553996716776, Train_acc 0.9969468390804598\n",
      "\n",
      "Epoch 125. Loss: 0.003163609200106072, Train_acc 0.9969815340909091\n",
      "\n",
      "Epoch 125. Loss: 0.0028861793914349444, Train_acc 0.9970154494382022\n",
      "\n",
      "Epoch 125. Loss: 0.0031639545892695993, Train_acc 0.9970486111111111\n",
      "\n",
      "Epoch 125. Loss: 0.003384738075138963, Train_acc 0.9970810439560439\n",
      "\n",
      "Epoch 125. Loss: 0.0030765155951778997, Train_acc 0.9971127717391305\n",
      "\n",
      "Epoch 125. Loss: 0.0029223795002863624, Train_acc 0.9971438172043011\n",
      "\n",
      "Epoch 125. Loss: 0.0027867226959689692, Train_acc 0.9971742021276596\n",
      "\n",
      "Epoch 125. Loss: 0.0025389266917451537, Train_acc 0.9972039473684211\n",
      "\n",
      "Epoch 125. Loss: 0.002341570337812467, Train_acc 0.9972330729166666\n",
      "\n",
      "Epoch 125. Loss: 0.0023455250356275116, Train_acc 0.9972615979381443\n",
      "\n",
      "Epoch 125. Loss: 0.0021304278417309877, Train_acc 0.9972895408163265\n",
      "\n",
      "Epoch 125. Loss: 0.0019276819280174586, Train_acc 0.9973169191919192\n",
      "\n",
      "Epoch 125. Loss: 0.0017620544075343501, Train_acc 0.99734375\n",
      "\n",
      "[Epoch 125 Batch 100] Loss: 0.0016993274210764609 Training: accuracy=0.997370\n",
      "Epoch 125. Loss: 0.0016993274210764609, Train_acc 0.9973700495049505\n",
      "\n",
      "Epoch 125. Loss: 0.001554612027562102, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 125. Loss: 0.00154812340268696, Train_acc 0.9974211165048543\n",
      "\n",
      "Epoch 125. Loss: 0.001454926339499992, Train_acc 0.9974459134615384\n",
      "\n",
      "Epoch 125. Loss: 0.0015930164935107605, Train_acc 0.997470238095238\n",
      "\n",
      "Epoch 125. Loss: 0.0014384685987066667, Train_acc 0.9974941037735849\n",
      "\n",
      "Epoch 125. Loss: 0.001351588517192582, Train_acc 0.997517523364486\n",
      "\n",
      "Epoch 125. Loss: 0.001241590989192982, Train_acc 0.9975405092592593\n",
      "\n",
      "Epoch 125. Loss: 0.0012177506168915269, Train_acc 0.9975630733944955\n",
      "\n",
      "Epoch 125. Loss: 0.0011602272085867915, Train_acc 0.9975852272727272\n",
      "\n",
      "Epoch 125. Loss: 0.0010467329173779408, Train_acc 0.9976069819819819\n",
      "\n",
      "Epoch 125. Loss: 0.00106655603344702, Train_acc 0.9976283482142857\n",
      "\n",
      "Epoch 125. Loss: 0.0009647754988733889, Train_acc 0.9976493362831859\n",
      "\n",
      "Epoch 125. Loss: 0.0008843921358531716, Train_acc 0.9976699561403509\n",
      "\n",
      "Epoch 125. Loss: 0.0008001165417188465, Train_acc 0.9976902173913044\n",
      "\n",
      "Epoch 125. Loss: 0.00072287122627696, Train_acc 0.9977101293103449\n",
      "\n",
      "Epoch 125. Loss: 0.0006548115012343189, Train_acc 0.9977297008547008\n",
      "\n",
      "Epoch 125. Loss: 0.0009094066416289325, Train_acc 0.9977489406779662\n",
      "\n",
      "Epoch 125. Loss: 0.0008322747409356086, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 125. Loss: 0.0009704444823425218, Train_acc 0.9977864583333333\n",
      "\n",
      "Epoch 125. Loss: 0.0008786559257732711, Train_acc 0.9978047520661157\n",
      "\n",
      "Epoch 125. Loss: 0.001494174827604909, Train_acc 0.9977587090163934\n",
      "\n",
      "Epoch 125. Loss: 0.0013657761020964409, Train_acc 0.997776930894309\n",
      "\n",
      "Epoch 125. Loss: 0.0012412529754094578, Train_acc 0.9977948588709677\n",
      "\n",
      "Epoch 125. Loss: 0.0011379238432044354, Train_acc 0.9978125\n",
      "\n",
      "Epoch 125. Loss: 0.0010564513732007504, Train_acc 0.9978298611111112\n",
      "\n",
      "Epoch 125. Loss: 0.0009542478533264627, Train_acc 0.9978469488188977\n",
      "\n",
      "Epoch 125. Loss: 0.0009354604559680043, Train_acc 0.99786376953125\n",
      "\n",
      "Epoch 125. Loss: 0.0009006223544886904, Train_acc 0.9978803294573644\n",
      "\n",
      "Epoch 125. Loss: 0.0008130306962773669, Train_acc 0.9978966346153846\n",
      "\n",
      "Epoch 125. Loss: 0.0030836464432160977, Train_acc 0.9978530534351145\n",
      "\n",
      "Epoch 125. Loss: 0.0027801643200651453, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 125. Loss: 0.0025095686154014635, Train_acc 0.9978853383458647\n",
      "\n",
      "Epoch 125. Loss: 0.0023678625973862504, Train_acc 0.9979011194029851\n",
      "\n",
      "Epoch 125. Loss: 0.0021573468811055658, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 125. Loss: 0.001951655302791252, Train_acc 0.9979319852941176\n",
      "\n",
      "Epoch 125. Loss: 0.0017827465236648135, Train_acc 0.9979470802919708\n",
      "\n",
      "Epoch 125. Loss: 0.0024931508616028025, Train_acc 0.9979619565217391\n",
      "\n",
      "Epoch 125. Loss: 0.002259901468204435, Train_acc 0.997976618705036\n",
      "\n",
      "Epoch 125. Loss: 0.0020692509851205137, Train_acc 0.9979910714285715\n",
      "\n",
      "Epoch 125. Loss: 0.001872395855602238, Train_acc 0.9980053191489362\n",
      "\n",
      "Epoch 125. Loss: 0.001960868241377127, Train_acc 0.9980193661971831\n",
      "\n",
      "Epoch 125. Loss: 0.005765726061452137, Train_acc 0.997978583916084\n",
      "\n",
      "Epoch 125. Loss: 0.005201656233861258, Train_acc 0.9979926215277778\n",
      "\n",
      "Epoch 125. Loss: 0.005141921217674801, Train_acc 0.9980064655172414\n",
      "\n",
      "Epoch 125. Loss: 0.00669470436909925, Train_acc 0.9979130993150684\n",
      "\n",
      "Epoch 125. Loss: 0.006033112854231762, Train_acc 0.9979272959183674\n",
      "\n",
      "Epoch 125. Loss: 0.0054579893270978634, Train_acc 0.9979413006756757\n",
      "\n",
      "Epoch 125. Loss: 0.004985971317072895, Train_acc 0.9979551174496645\n",
      "\n",
      "Epoch 125. Loss: 0.004516410075840522, Train_acc 0.99796875\n",
      "\n",
      "Epoch 125. Loss: 0.0040798317600749265, Train_acc 0.9979822019867549\n",
      "\n",
      "Epoch 125. Loss: 0.0037478546226475235, Train_acc 0.9979954769736842\n",
      "\n",
      "Epoch 125. Loss: 0.003387147575207097, Train_acc 0.9980085784313726\n",
      "\n",
      "Epoch 125. Loss: 0.0031032774844244504, Train_acc 0.9980215097402597\n",
      "\n",
      "Epoch 125. Loss: 0.002805258976974186, Train_acc 0.9980342741935484\n",
      "\n",
      "Epoch 125. Loss: 0.0025439986479755244, Train_acc 0.998046875\n",
      "\n",
      "Epoch 125. Loss: 0.002326310613940187, Train_acc 0.9980593152866242\n",
      "\n",
      "Epoch 125. Loss: 0.002267560969686533, Train_acc 0.9980715981012658\n",
      "\n",
      "Epoch 125. Loss: 0.002239930649716578, Train_acc 0.9980837264150944\n",
      "\n",
      "Epoch 125. Loss: 0.0022248542861213584, Train_acc 0.998095703125\n",
      "\n",
      "Epoch 125. Loss: 0.0020682353194642336, Train_acc 0.9981075310559007\n",
      "\n",
      "Epoch 125. Loss: 0.0019330704879895542, Train_acc 0.9981192129629629\n",
      "\n",
      "Epoch 125. Loss: 0.0018226840240182605, Train_acc 0.9981307515337423\n",
      "\n",
      "Epoch 125. Loss: 0.0016529826759803334, Train_acc 0.9981421493902439\n",
      "\n",
      "Epoch 125. Loss: 0.0015127939971329382, Train_acc 0.9981534090909091\n",
      "\n",
      "Epoch 125. Loss: 0.002066032790798689, Train_acc 0.9981174698795181\n",
      "\n",
      "Epoch 125. Loss: 0.0019079418688895135, Train_acc 0.9981287425149701\n",
      "\n",
      "Epoch 125. Loss: 0.0019484231100870815, Train_acc 0.9981398809523809\n",
      "\n",
      "Epoch 125. Loss: 0.001823600936433105, Train_acc 0.9981508875739645\n",
      "\n",
      "Epoch 125. Loss: 0.0017229497245609864, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 125. Loss: 0.002034915435984144, Train_acc 0.998172514619883\n",
      "\n",
      "Epoch 125. Loss: 0.0024941772508690445, Train_acc 0.9981831395348837\n",
      "\n",
      "Epoch 125. Loss: 0.002333659643917056, Train_acc 0.9981936416184971\n",
      "\n",
      "Epoch 125. Loss: 0.00213734689530844, Train_acc 0.9982040229885057\n",
      "\n",
      "Epoch 125. Loss: 0.0024025132679383263, Train_acc 0.9982142857142857\n",
      "\n",
      "Epoch 125. Loss: 0.0021741417129177315, Train_acc 0.9982244318181818\n",
      "\n",
      "Epoch 125. Loss: 0.00195916487064759, Train_acc 0.9982344632768362\n",
      "\n",
      "Epoch 125. Loss: 0.0017829236760067571, Train_acc 0.9982443820224719\n",
      "\n",
      "Epoch 125. Loss: 0.002089067686289039, Train_acc 0.9982541899441341\n",
      "\n",
      "Epoch 125. Loss: 0.0020400222047622383, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 125. Loss: 0.0024070772778500955, Train_acc 0.9982734806629834\n",
      "\n",
      "Epoch 125. Loss: 0.0022090058758807785, Train_acc 0.998282967032967\n",
      "\n",
      "Epoch 125. Loss: 0.0020045328711792367, Train_acc 0.9982923497267759\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125. Loss: 0.0018076667563115764, Train_acc 0.9983016304347826\n",
      "\n",
      "Epoch 125. Loss: 0.0019373614202211984, Train_acc 0.9983108108108109\n",
      "\n",
      "Epoch 125. Loss: 0.0017444394544909752, Train_acc 0.9983198924731183\n",
      "\n",
      "Epoch 125. Loss: 0.0032443220182791672, Train_acc 0.9982870989304813\n",
      "\n",
      "Epoch 125. Loss: 0.0031726400762753476, Train_acc 0.998296210106383\n",
      "\n",
      "Epoch 125. Loss: 0.002913617810146745, Train_acc 0.9983052248677249\n",
      "\n",
      "Epoch 125. Loss: 0.002693926737844261, Train_acc 0.9983141447368421\n",
      "\n",
      "Epoch 125. Loss: 0.0027166050656640345, Train_acc 0.9983229712041884\n",
      "\n",
      "Epoch 125. Loss: 0.0024465805879986067, Train_acc 0.9983317057291666\n",
      "\n",
      "Epoch 125. Loss: 0.0022176626053951264, Train_acc 0.9983403497409327\n",
      "\n",
      "Epoch 125. Loss: 0.0020144851534536104, Train_acc 0.9983489046391752\n",
      "\n",
      "Epoch 125. Loss: 0.004397633733955379, Train_acc 0.9983173076923076\n",
      "\n",
      "Epoch 125. Loss: 0.0046319804993486605, Train_acc 0.99832\n",
      "\n",
      "Epoch 126. Loss: 0.004182277851940836, Train_acc 1.0\n",
      "\n",
      "Epoch 126. Loss: 0.0037789318826244958, Train_acc 1.0\n",
      "\n",
      "Epoch 126. Loss: 0.006717031720260979, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 126. Loss: 0.0062362881396533865, Train_acc 0.998046875\n",
      "\n",
      "Epoch 126. Loss: 0.006689541658251448, Train_acc 0.996875\n",
      "\n",
      "Epoch 126. Loss: 0.006025014866796002, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 126. Loss: 0.0054914005169929845, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 126. Loss: 0.0052545030989568035, Train_acc 0.998046875\n",
      "\n",
      "Epoch 126. Loss: 0.004864250966365242, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 126. Loss: 0.007919064475704823, Train_acc 0.99765625\n",
      "\n",
      "Epoch 126. Loss: 0.009380758238085742, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 126. Loss: 0.010455050519629094, Train_acc 0.9954427083333334\n",
      "\n",
      "Epoch 126. Loss: 0.009481255367596468, Train_acc 0.9957932692307693\n",
      "\n",
      "Epoch 126. Loss: 0.010336041253983547, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 126. Loss: 0.010266815228473756, Train_acc 0.9958333333333333\n",
      "\n",
      "Epoch 126. Loss: 0.014304999279867066, Train_acc 0.99560546875\n",
      "\n",
      "Epoch 126. Loss: 0.013629478884092378, Train_acc 0.9958639705882353\n",
      "\n",
      "Epoch 126. Loss: 0.012270435426970223, Train_acc 0.99609375\n",
      "\n",
      "Epoch 126. Loss: 0.011057415899672829, Train_acc 0.9962993421052632\n",
      "\n",
      "Epoch 126. Loss: 0.009985779339477582, Train_acc 0.996484375\n",
      "\n",
      "Epoch 126. Loss: 0.00901194714692324, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 126. Loss: 0.009154467015150991, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 126. Loss: 0.00860705510669989, Train_acc 0.9966032608695652\n",
      "\n",
      "Epoch 126. Loss: 0.01105700465346017, Train_acc 0.99609375\n",
      "\n",
      "Epoch 126. Loss: 0.011233318047713983, Train_acc 0.9959375\n",
      "\n",
      "Epoch 126. Loss: 0.013877109688811076, Train_acc 0.9954927884615384\n",
      "\n",
      "Epoch 126. Loss: 0.013567528931611096, Train_acc 0.9953703703703703\n",
      "\n",
      "Epoch 126. Loss: 0.012357553000078335, Train_acc 0.9955357142857143\n",
      "\n",
      "Epoch 126. Loss: 0.012085798428051832, Train_acc 0.9954202586206896\n",
      "\n",
      "Epoch 126. Loss: 0.013470580730372515, Train_acc 0.9950520833333333\n",
      "\n",
      "Epoch 126. Loss: 0.014114711742282373, Train_acc 0.9947076612903226\n",
      "\n",
      "Epoch 126. Loss: 0.013388544691962417, Train_acc 0.99462890625\n",
      "\n",
      "Epoch 126. Loss: 0.012964550646420494, Train_acc 0.9945549242424242\n",
      "\n",
      "Epoch 126. Loss: 0.011725180882574179, Train_acc 0.9947150735294118\n",
      "\n",
      "Epoch 126. Loss: 0.010622304954404584, Train_acc 0.9948660714285714\n",
      "\n",
      "Epoch 126. Loss: 0.009590531786339314, Train_acc 0.9950086805555556\n",
      "\n",
      "Epoch 126. Loss: 0.008655400029667241, Train_acc 0.995143581081081\n",
      "\n",
      "Epoch 126. Loss: 0.007848246420057586, Train_acc 0.9952713815789473\n",
      "\n",
      "Epoch 126. Loss: 0.014916730098097297, Train_acc 0.9947916666666666\n",
      "\n",
      "Epoch 126. Loss: 0.01348056114304999, Train_acc 0.994921875\n",
      "\n",
      "Epoch 126. Loss: 0.013358571826716719, Train_acc 0.9948551829268293\n",
      "\n",
      "Epoch 126. Loss: 0.012245274173401705, Train_acc 0.9949776785714286\n",
      "\n",
      "Epoch 126. Loss: 0.013518307473227005, Train_acc 0.9947311046511628\n",
      "\n",
      "Epoch 126. Loss: 0.012294078163174946, Train_acc 0.9948508522727273\n",
      "\n",
      "Epoch 126. Loss: 0.011196693377749466, Train_acc 0.9949652777777778\n",
      "\n",
      "Epoch 126. Loss: 0.010172230655489571, Train_acc 0.9950747282608695\n",
      "\n",
      "Epoch 126. Loss: 0.013238434259180613, Train_acc 0.9950132978723404\n",
      "\n",
      "Epoch 126. Loss: 0.014253930275813688, Train_acc 0.9949544270833334\n",
      "\n",
      "Epoch 126. Loss: 0.013630940284737303, Train_acc 0.9950573979591837\n",
      "\n",
      "Epoch 126. Loss: 0.012420071804199385, Train_acc 0.99515625\n",
      "\n",
      "Epoch 126. Loss: 0.011444118081523867, Train_acc 0.9952512254901961\n",
      "\n",
      "Epoch 126. Loss: 0.010478577949697278, Train_acc 0.9953425480769231\n",
      "\n",
      "Epoch 126. Loss: 0.009470154931136149, Train_acc 0.9954304245283019\n",
      "\n",
      "Epoch 126. Loss: 0.008682635099523375, Train_acc 0.9955150462962963\n",
      "\n",
      "Epoch 126. Loss: 0.008350187683477799, Train_acc 0.9955965909090909\n",
      "\n",
      "Epoch 126. Loss: 0.008044262769259333, Train_acc 0.9956752232142857\n",
      "\n",
      "Epoch 126. Loss: 0.010355267152879226, Train_acc 0.9954769736842105\n",
      "\n",
      "Epoch 126. Loss: 0.009345120732710552, Train_acc 0.9955549568965517\n",
      "\n",
      "Epoch 126. Loss: 0.008462372627516054, Train_acc 0.9956302966101694\n",
      "\n",
      "Epoch 126. Loss: 0.008629398400330064, Train_acc 0.9955729166666667\n",
      "\n",
      "Epoch 126. Loss: 0.007830521248331087, Train_acc 0.9956454918032787\n",
      "\n",
      "Epoch 126. Loss: 0.0072383808915022765, Train_acc 0.9957157258064516\n",
      "\n",
      "Epoch 126. Loss: 0.008034597776013949, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 126. Loss: 0.007615056847232584, Train_acc 0.9957275390625\n",
      "\n",
      "Epoch 126. Loss: 0.007569807093693022, Train_acc 0.9956730769230769\n",
      "\n",
      "Epoch 126. Loss: 0.007123538692015294, Train_acc 0.9957386363636364\n",
      "\n",
      "Epoch 126. Loss: 0.006506856389482662, Train_acc 0.9958022388059702\n",
      "\n",
      "Epoch 126. Loss: 0.005972694815913449, Train_acc 0.9958639705882353\n",
      "\n",
      "Epoch 126. Loss: 0.005636242174777041, Train_acc 0.9959239130434783\n",
      "\n",
      "Epoch 126. Loss: 0.005135706889373943, Train_acc 0.9959821428571428\n",
      "\n",
      "Epoch 126. Loss: 0.004674399683376001, Train_acc 0.9960387323943662\n",
      "\n",
      "Epoch 126. Loss: 0.004921945787891608, Train_acc 0.99609375\n",
      "\n",
      "Epoch 126. Loss: 0.004666703234545763, Train_acc 0.9961472602739726\n",
      "\n",
      "Epoch 126. Loss: 0.00447932402492974, Train_acc 0.9961993243243243\n",
      "\n",
      "Epoch 126. Loss: 0.004223432421156739, Train_acc 0.99625\n",
      "\n",
      "Epoch 126. Loss: 0.004077931938963212, Train_acc 0.9962993421052632\n",
      "\n",
      "Epoch 126. Loss: 0.0037751770419638554, Train_acc 0.9963474025974026\n",
      "\n",
      "Epoch 126. Loss: 0.003558531948053348, Train_acc 0.9963942307692307\n",
      "\n",
      "Epoch 126. Loss: 0.00442592634465412, Train_acc 0.9963409810126582\n",
      "\n",
      "Epoch 126. Loss: 0.004207934721911988, Train_acc 0.99638671875\n",
      "\n",
      "Epoch 126. Loss: 0.005515391336028315, Train_acc 0.9962384259259259\n",
      "\n",
      "Epoch 126. Loss: 0.005023460182499845, Train_acc 0.9962842987804879\n",
      "\n",
      "Epoch 126. Loss: 0.004889609403194748, Train_acc 0.9963290662650602\n",
      "\n",
      "Epoch 126. Loss: 0.004405855184710112, Train_acc 0.9963727678571429\n",
      "\n",
      "Epoch 126. Loss: 0.004007842155713069, Train_acc 0.9964154411764706\n",
      "\n",
      "Epoch 126. Loss: 0.0036398783181062887, Train_acc 0.9964571220930233\n",
      "\n",
      "Epoch 126. Loss: 0.004344330472852429, Train_acc 0.9964080459770115\n",
      "\n",
      "Epoch 126. Loss: 0.003936662518774545, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 126. Loss: 0.003619724383152344, Train_acc 0.9964887640449438\n",
      "\n",
      "Epoch 126. Loss: 0.0032674179570297206, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 126. Loss: 0.003099780655704719, Train_acc 0.9965659340659341\n",
      "\n",
      "Epoch 126. Loss: 0.003934281246485814, Train_acc 0.9965183423913043\n",
      "\n",
      "Epoch 126. Loss: 0.003551270413033296, Train_acc 0.9965557795698925\n",
      "\n",
      "Epoch 126. Loss: 0.0034728807292197313, Train_acc 0.996592420212766\n",
      "\n",
      "Epoch 126. Loss: 0.003526662438972071, Train_acc 0.9966282894736842\n",
      "\n",
      "Epoch 126. Loss: 0.0035697071010887104, Train_acc 0.9966634114583334\n",
      "\n",
      "Epoch 126. Loss: 0.003450175987074031, Train_acc 0.9966978092783505\n",
      "\n",
      "Epoch 126. Loss: 0.004148584633817601, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 126. Loss: 0.0041005061460289306, Train_acc 0.9966856060606061\n",
      "\n",
      "Epoch 126. Loss: 0.003706841737396813, Train_acc 0.99671875\n",
      "\n",
      "[Epoch 126 Batch 100] Loss: 0.003389837518383381 Training: accuracy=0.996751\n",
      "Epoch 126. Loss: 0.003389837518383381, Train_acc 0.9967512376237624\n",
      "\n",
      "Epoch 126. Loss: 0.0030613015767453193, Train_acc 0.9967830882352942\n",
      "\n",
      "Epoch 126. Loss: 0.0028375563304365945, Train_acc 0.9968143203883495\n",
      "\n",
      "Epoch 126. Loss: 0.0025828314743248397, Train_acc 0.9968449519230769\n",
      "\n",
      "Epoch 126. Loss: 0.002381696410471151, Train_acc 0.996875\n",
      "\n",
      "Epoch 126. Loss: 0.002194138668192729, Train_acc 0.9969044811320755\n",
      "\n",
      "Epoch 126. Loss: 0.0020942963055565695, Train_acc 0.9969334112149533\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126. Loss: 0.001933847187657184, Train_acc 0.9969618055555556\n",
      "\n",
      "Epoch 126. Loss: 0.0017562838291759282, Train_acc 0.9969896788990825\n",
      "\n",
      "Epoch 126. Loss: 0.0015979880345807962, Train_acc 0.9970170454545455\n",
      "\n",
      "Epoch 126. Loss: 0.0017092332507324063, Train_acc 0.997043918918919\n",
      "\n",
      "Epoch 126. Loss: 0.0015925390172792384, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 126. Loss: 0.0014504423474745074, Train_acc 0.9970962389380531\n",
      "\n",
      "Epoch 126. Loss: 0.0013100800030044816, Train_acc 0.9971217105263158\n",
      "\n",
      "Epoch 126. Loss: 0.0011844772395836298, Train_acc 0.9971467391304348\n",
      "\n",
      "Epoch 126. Loss: 0.001076745662414758, Train_acc 0.9971713362068966\n",
      "\n",
      "Epoch 126. Loss: 0.0010498149298511254, Train_acc 0.9971955128205128\n",
      "\n",
      "Epoch 126. Loss: 0.001289006371867565, Train_acc 0.997219279661017\n",
      "\n",
      "Epoch 126. Loss: 0.0011706040596720126, Train_acc 0.9972426470588235\n",
      "\n",
      "Epoch 126. Loss: 0.00106236603534676, Train_acc 0.997265625\n",
      "\n",
      "Epoch 126. Loss: 0.000956758365406355, Train_acc 0.9972882231404959\n",
      "\n",
      "Epoch 126. Loss: 0.0008637093563835348, Train_acc 0.9973104508196722\n",
      "\n",
      "Epoch 126. Loss: 0.0007832822967669558, Train_acc 0.9973323170731707\n",
      "\n",
      "Epoch 126. Loss: 0.0007394420450634457, Train_acc 0.9973538306451613\n",
      "\n",
      "Epoch 126. Loss: 0.0006680344709387566, Train_acc 0.997375\n",
      "\n",
      "Epoch 126. Loss: 0.0006046544244755897, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 126. Loss: 0.0005682366651375601, Train_acc 0.9974163385826772\n",
      "\n",
      "Epoch 126. Loss: 0.00052025942002971, Train_acc 0.9974365234375\n",
      "\n",
      "Epoch 126. Loss: 0.00047778174121449206, Train_acc 0.9974563953488372\n",
      "\n",
      "Epoch 126. Loss: 0.0004810053815198971, Train_acc 0.9974759615384615\n",
      "\n",
      "Epoch 126. Loss: 0.00043632873548955304, Train_acc 0.9974952290076335\n",
      "\n",
      "Epoch 126. Loss: 0.0003979471661143234, Train_acc 0.9975142045454546\n",
      "\n",
      "Epoch 126. Loss: 0.0003597510017651852, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 126. Loss: 0.0003453421077123466, Train_acc 0.9975513059701493\n",
      "\n",
      "Epoch 126. Loss: 0.0003146033231054, Train_acc 0.9975694444444444\n",
      "\n",
      "Epoch 126. Loss: 0.0002832743978749218, Train_acc 0.9975873161764706\n",
      "\n",
      "Epoch 126. Loss: 0.00025858440502201974, Train_acc 0.9976049270072993\n",
      "\n",
      "Epoch 126. Loss: 0.00023968674511245304, Train_acc 0.9976222826086957\n",
      "\n",
      "Epoch 126. Loss: 0.00023034042728562053, Train_acc 0.9976393884892086\n",
      "\n",
      "Epoch 126. Loss: 0.0004474899829189679, Train_acc 0.99765625\n",
      "\n",
      "Epoch 126. Loss: 0.00040462604190854103, Train_acc 0.9976728723404256\n",
      "\n",
      "Epoch 126. Loss: 0.0004023810104458589, Train_acc 0.9976892605633803\n",
      "\n",
      "Epoch 126. Loss: 0.0003646921844877672, Train_acc 0.9977054195804196\n",
      "\n",
      "Epoch 126. Loss: 0.00034342738623581426, Train_acc 0.9977213541666666\n",
      "\n",
      "Epoch 126. Loss: 0.0003097630090603138, Train_acc 0.9977370689655173\n",
      "\n",
      "Epoch 126. Loss: 0.0002854287166747124, Train_acc 0.9977525684931506\n",
      "\n",
      "Epoch 126. Loss: 0.00026232623494845485, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 126. Loss: 0.00029162374324812165, Train_acc 0.9977829391891891\n",
      "\n",
      "Epoch 126. Loss: 0.00028272020042385094, Train_acc 0.9977978187919463\n",
      "\n",
      "Epoch 126. Loss: 0.00025501407394209926, Train_acc 0.9978125\n",
      "\n",
      "Epoch 126. Loss: 0.0003011071639696457, Train_acc 0.9978269867549668\n",
      "\n",
      "Epoch 126. Loss: 0.0003321471925957231, Train_acc 0.9978412828947368\n",
      "\n",
      "Epoch 126. Loss: 0.00030021177786051053, Train_acc 0.9978553921568627\n",
      "\n",
      "Epoch 126. Loss: 0.00027750072704079066, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 126. Loss: 0.00025454307004827467, Train_acc 0.9978830645161291\n",
      "\n",
      "Epoch 126. Loss: 0.00023154901642473394, Train_acc 0.9978966346153846\n",
      "\n",
      "Epoch 126. Loss: 0.00020954267671475634, Train_acc 0.9979100318471338\n",
      "\n",
      "Epoch 126. Loss: 0.00019094653344551597, Train_acc 0.9979232594936709\n",
      "\n",
      "Epoch 126. Loss: 0.00017307190994522655, Train_acc 0.9979363207547169\n",
      "\n",
      "Epoch 126. Loss: 0.0001564540857848984, Train_acc 0.99794921875\n",
      "\n",
      "Epoch 126. Loss: 0.00022526746350213546, Train_acc 0.9979619565217391\n",
      "\n",
      "Epoch 126. Loss: 0.00020327180394104585, Train_acc 0.9979745370370371\n",
      "\n",
      "Epoch 126. Loss: 0.0005269249610400629, Train_acc 0.9979869631901841\n",
      "\n",
      "Epoch 126. Loss: 0.0004747172362531896, Train_acc 0.9979992378048781\n",
      "\n",
      "Epoch 126. Loss: 0.00043392128959518375, Train_acc 0.9980113636363637\n",
      "\n",
      "Epoch 126. Loss: 0.0004058106594170708, Train_acc 0.998023343373494\n",
      "\n",
      "Epoch 126. Loss: 0.0003718445987343002, Train_acc 0.9980351796407185\n",
      "\n",
      "Epoch 126. Loss: 0.0013142980522667653, Train_acc 0.9980003720238095\n",
      "\n",
      "Epoch 126. Loss: 0.0011830230287251577, Train_acc 0.9980122041420119\n",
      "\n",
      "Epoch 126. Loss: 0.0011789654025133884, Train_acc 0.9980238970588236\n",
      "\n",
      "Epoch 126. Loss: 0.0025124093662526998, Train_acc 0.9979897660818714\n",
      "\n",
      "Epoch 126. Loss: 0.0022691748380887994, Train_acc 0.9980014534883721\n",
      "\n",
      "Epoch 126. Loss: 0.0020425912206899935, Train_acc 0.9980130057803468\n",
      "\n",
      "Epoch 126. Loss: 0.003069035765427215, Train_acc 0.997979525862069\n",
      "\n",
      "Epoch 126. Loss: 0.0027633713928779573, Train_acc 0.9979910714285715\n",
      "\n",
      "Epoch 126. Loss: 0.0027737641900781344, Train_acc 0.9980024857954546\n",
      "\n",
      "Epoch 126. Loss: 0.0024990556582721447, Train_acc 0.9980137711864406\n",
      "\n",
      "Epoch 126. Loss: 0.002254592748483143, Train_acc 0.9980249297752809\n",
      "\n",
      "Epoch 126. Loss: 0.002032151272370356, Train_acc 0.9980359636871509\n",
      "\n",
      "Epoch 126. Loss: 0.0021282343030487936, Train_acc 0.998046875\n",
      "\n",
      "Epoch 126. Loss: 0.0019175972090583946, Train_acc 0.9980576657458563\n",
      "\n",
      "Epoch 126. Loss: 0.0017465685132951503, Train_acc 0.9980683379120879\n",
      "\n",
      "Epoch 126. Loss: 0.0015820083817451752, Train_acc 0.9980788934426229\n",
      "\n",
      "Epoch 126. Loss: 0.0014274867130289947, Train_acc 0.9980893342391305\n",
      "\n",
      "Epoch 126. Loss: 0.0014216891078140267, Train_acc 0.9980996621621622\n",
      "\n",
      "Epoch 126. Loss: 0.0013475365240188774, Train_acc 0.9981098790322581\n",
      "\n",
      "Epoch 126. Loss: 0.0012143901246512978, Train_acc 0.9981199866310161\n",
      "\n",
      "Epoch 126. Loss: 0.0012032680523037956, Train_acc 0.9981299867021277\n",
      "\n",
      "Epoch 126. Loss: 0.0015989591459906142, Train_acc 0.9981398809523809\n",
      "\n",
      "Epoch 126. Loss: 0.0014402673729090717, Train_acc 0.9981496710526315\n",
      "\n",
      "Epoch 126. Loss: 0.001756168142363026, Train_acc 0.9981593586387435\n",
      "\n",
      "Epoch 126. Loss: 0.0016633279072012853, Train_acc 0.9981689453125\n",
      "\n",
      "Epoch 126. Loss: 0.0015051769817500094, Train_acc 0.9981784326424871\n",
      "\n",
      "Epoch 126. Loss: 0.0013744704210379747, Train_acc 0.9981878221649485\n",
      "\n",
      "Epoch 126. Loss: 0.0012725913855036969, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 126. Loss: 0.001147781716455935, Train_acc 0.9982\n",
      "\n",
      "Epoch 127. Loss: 0.0010345394987351, Train_acc 1.0\n",
      "\n",
      "Epoch 127. Loss: 0.0009406495797770888, Train_acc 1.0\n",
      "\n",
      "Epoch 127. Loss: 0.0008515229437441717, Train_acc 1.0\n",
      "\n",
      "Epoch 127. Loss: 0.0007674604228380204, Train_acc 1.0\n",
      "\n",
      "Epoch 127. Loss: 0.0008142165549465609, Train_acc 1.0\n",
      "\n",
      "Epoch 127. Loss: 0.0007783441170634561, Train_acc 1.0\n",
      "\n",
      "Epoch 127. Loss: 0.0007135947686129682, Train_acc 1.0\n",
      "\n",
      "Epoch 127. Loss: 0.0006447539732553874, Train_acc 1.0\n",
      "\n",
      "Epoch 127. Loss: 0.0005918445145509096, Train_acc 1.0\n",
      "\n",
      "Epoch 127. Loss: 0.0005449430859023327, Train_acc 1.0\n",
      "\n",
      "Epoch 127. Loss: 0.0005051446575482036, Train_acc 1.0\n",
      "\n",
      "Epoch 127. Loss: 0.00045696113358176986, Train_acc 1.0\n",
      "\n",
      "Epoch 127. Loss: 0.0006719356430343143, Train_acc 1.0\n",
      "\n",
      "Epoch 127. Loss: 0.0006094045622103612, Train_acc 1.0\n",
      "\n",
      "Epoch 127. Loss: 0.0007174434718336046, Train_acc 1.0\n",
      "\n",
      "Epoch 127. Loss: 0.001463309820608382, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 127. Loss: 0.00131766431183492, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 127. Loss: 0.0012106193552710103, Train_acc 0.9995659722222222\n",
      "\n",
      "Epoch 127. Loss: 0.001090041856366992, Train_acc 0.9995888157894737\n",
      "\n",
      "Epoch 127. Loss: 0.0010083989035176634, Train_acc 0.999609375\n",
      "\n",
      "Epoch 127. Loss: 0.000936626277570045, Train_acc 0.9996279761904762\n",
      "\n",
      "Epoch 127. Loss: 0.0008447452924537485, Train_acc 0.9996448863636364\n",
      "\n",
      "Epoch 127. Loss: 0.0008176537787273817, Train_acc 0.9996603260869565\n",
      "\n",
      "Epoch 127. Loss: 0.0007367908472453262, Train_acc 0.9996744791666666\n",
      "\n",
      "Epoch 127. Loss: 0.000664856322879723, Train_acc 0.9996875\n",
      "\n",
      "Epoch 127. Loss: 0.0007797188118511122, Train_acc 0.9996995192307693\n",
      "\n",
      "Epoch 127. Loss: 0.0007300564390092281, Train_acc 0.9997106481481481\n",
      "\n",
      "Epoch 127. Loss: 0.0006571159860173319, Train_acc 0.9997209821428571\n",
      "\n",
      "Epoch 127. Loss: 0.0006010864088977479, Train_acc 0.9997306034482759\n",
      "\n",
      "Epoch 127. Loss: 0.0005416310974333772, Train_acc 0.9997395833333333\n",
      "\n",
      "Epoch 127. Loss: 0.0004905592666853103, Train_acc 0.9997479838709677\n",
      "\n",
      "Epoch 127. Loss: 0.0004994460512993008, Train_acc 0.999755859375\n",
      "\n",
      "Epoch 127. Loss: 0.0005037549326201323, Train_acc 0.9997632575757576\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127. Loss: 0.0023042243590396683, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 127. Loss: 0.0020794578360363945, Train_acc 0.9995535714285714\n",
      "\n",
      "Epoch 127. Loss: 0.0018728077507810133, Train_acc 0.9995659722222222\n",
      "\n",
      "Epoch 127. Loss: 0.0016863891698589825, Train_acc 0.9995777027027027\n",
      "\n",
      "Epoch 127. Loss: 0.0015178618234757964, Train_acc 0.9995888157894737\n",
      "\n",
      "Epoch 127. Loss: 0.0013693886931305573, Train_acc 0.9995993589743589\n",
      "\n",
      "Epoch 127. Loss: 0.0018207847809552057, Train_acc 0.9994140625\n",
      "\n",
      "Epoch 127. Loss: 0.0017758982322484765, Train_acc 0.9994283536585366\n",
      "\n",
      "Epoch 127. Loss: 0.005080574551987993, Train_acc 0.9990699404761905\n",
      "\n",
      "Epoch 127. Loss: 0.004577083328808181, Train_acc 0.9990915697674418\n",
      "\n",
      "Epoch 127. Loss: 0.004140075112802013, Train_acc 0.9991122159090909\n",
      "\n",
      "Epoch 127. Loss: 0.0037352467764800745, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 127. Loss: 0.005091249214653906, Train_acc 0.9989809782608695\n",
      "\n",
      "Epoch 127. Loss: 0.007172994032840195, Train_acc 0.9986702127659575\n",
      "\n",
      "Epoch 127. Loss: 0.006484963452538152, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 127. Loss: 0.005840094848819065, Train_acc 0.9987244897959183\n",
      "\n",
      "Epoch 127. Loss: 0.005257526352699783, Train_acc 0.99875\n",
      "\n",
      "Epoch 127. Loss: 0.008549943326142001, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 127. Loss: 0.010393090143704327, Train_acc 0.9984975961538461\n",
      "\n",
      "Epoch 127. Loss: 0.009453635463591438, Train_acc 0.9985259433962265\n",
      "\n",
      "Epoch 127. Loss: 0.01341592092765214, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 127. Loss: 0.013618999781783004, Train_acc 0.9981534090909091\n",
      "\n",
      "Epoch 127. Loss: 0.012718807533450944, Train_acc 0.9981863839285714\n",
      "\n",
      "Epoch 127. Loss: 0.011683188648955246, Train_acc 0.9982182017543859\n",
      "\n",
      "Epoch 127. Loss: 0.013455334176364141, Train_acc 0.998114224137931\n",
      "\n",
      "Epoch 127. Loss: 0.01764814886725777, Train_acc 0.9978813559322034\n",
      "\n",
      "Epoch 127. Loss: 0.01594693614119441, Train_acc 0.9979166666666667\n",
      "\n",
      "Epoch 127. Loss: 0.014755818591929828, Train_acc 0.9979508196721312\n",
      "\n",
      "Epoch 127. Loss: 0.013697559724152705, Train_acc 0.9979838709677419\n",
      "\n",
      "Epoch 127. Loss: 0.013238561420053798, Train_acc 0.998015873015873\n",
      "\n",
      "Epoch 127. Loss: 0.013391841461578511, Train_acc 0.9979248046875\n",
      "\n",
      "Epoch 127. Loss: 0.01688298680810884, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 127. Loss: 0.024337741122502882, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 127. Loss: 0.027868861603014588, Train_acc 0.9972014925373134\n",
      "\n",
      "Epoch 127. Loss: 0.027575845514779915, Train_acc 0.9971277573529411\n",
      "\n",
      "Epoch 127. Loss: 0.02687587961111572, Train_acc 0.9970561594202898\n",
      "\n",
      "Epoch 127. Loss: 0.02564150243598914, Train_acc 0.996875\n",
      "\n",
      "Epoch 127. Loss: 0.023582353988799716, Train_acc 0.996919014084507\n",
      "\n",
      "Epoch 127. Loss: 0.022530236474734483, Train_acc 0.9969618055555556\n",
      "\n",
      "Epoch 127. Loss: 0.02065854646431232, Train_acc 0.9970034246575342\n",
      "\n",
      "Epoch 127. Loss: 0.018825603067503794, Train_acc 0.997043918918919\n",
      "\n",
      "Epoch 127. Loss: 0.018156897777730007, Train_acc 0.9969791666666666\n",
      "\n",
      "Epoch 127. Loss: 0.017616630796564024, Train_acc 0.9969161184210527\n",
      "\n",
      "Epoch 127. Loss: 0.016132057673124135, Train_acc 0.9969561688311688\n",
      "\n",
      "Epoch 127. Loss: 0.014657012282621259, Train_acc 0.9969951923076923\n",
      "\n",
      "Epoch 127. Loss: 0.01355353129790997, Train_acc 0.9970332278481012\n",
      "\n",
      "Epoch 127. Loss: 0.013385905395926018, Train_acc 0.99697265625\n",
      "\n",
      "Epoch 127. Loss: 0.012724552609158437, Train_acc 0.9970100308641975\n",
      "\n",
      "Epoch 127. Loss: 0.01167916163832654, Train_acc 0.997046493902439\n",
      "\n",
      "Epoch 127. Loss: 0.011997552484548474, Train_acc 0.9969879518072289\n",
      "\n",
      "Epoch 127. Loss: 0.010867955028745652, Train_acc 0.9970238095238095\n",
      "\n",
      "Epoch 127. Loss: 0.010118045117839982, Train_acc 0.9970588235294118\n",
      "\n",
      "Epoch 127. Loss: 0.009512055104718932, Train_acc 0.997093023255814\n",
      "\n",
      "Epoch 127. Loss: 0.008656295582946833, Train_acc 0.9971264367816092\n",
      "\n",
      "Epoch 127. Loss: 0.008300218356293467, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 127. Loss: 0.007834959787071074, Train_acc 0.9971910112359551\n",
      "\n",
      "Epoch 127. Loss: 0.0072832970986726805, Train_acc 0.9972222222222222\n",
      "\n",
      "Epoch 127. Loss: 0.006666602511253618, Train_acc 0.9972527472527473\n",
      "\n",
      "Epoch 127. Loss: 0.006102242561788109, Train_acc 0.9972826086956522\n",
      "\n",
      "Epoch 127. Loss: 0.005606186811724973, Train_acc 0.9973118279569892\n",
      "\n",
      "Epoch 127. Loss: 0.0052957763919752885, Train_acc 0.9973404255319149\n",
      "\n",
      "Epoch 127. Loss: 0.005518606158303205, Train_acc 0.9972861842105263\n",
      "\n",
      "Epoch 127. Loss: 0.0051767343591141565, Train_acc 0.997314453125\n",
      "\n",
      "Epoch 127. Loss: 0.006582995107217538, Train_acc 0.9972615979381443\n",
      "\n",
      "Epoch 127. Loss: 0.00759760314265839, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 127. Loss: 0.006983630702163592, Train_acc 0.9972380050505051\n",
      "\n",
      "Epoch 127. Loss: 0.00640534770810528, Train_acc 0.997265625\n",
      "\n",
      "[Epoch 127 Batch 100] Loss: 0.006730890887146503 Training: accuracy=0.997215\n",
      "Epoch 127. Loss: 0.006730890887146503, Train_acc 0.9972153465346535\n",
      "\n",
      "Epoch 127. Loss: 0.0074485001642989905, Train_acc 0.9971660539215687\n",
      "\n",
      "Epoch 127. Loss: 0.007105698098643523, Train_acc 0.9971935679611651\n",
      "\n",
      "Epoch 127. Loss: 0.006508105447057397, Train_acc 0.9972205528846154\n",
      "\n",
      "Epoch 127. Loss: 0.0058824114760216055, Train_acc 0.9972470238095238\n",
      "\n",
      "Epoch 127. Loss: 0.0054417740367388116, Train_acc 0.9972729952830188\n",
      "\n",
      "Epoch 127. Loss: 0.005174042230475133, Train_acc 0.9972984813084113\n",
      "\n",
      "Epoch 127. Loss: 0.006363896455432342, Train_acc 0.9972511574074074\n",
      "\n",
      "Epoch 127. Loss: 0.006099392528666884, Train_acc 0.997276376146789\n",
      "\n",
      "Epoch 127. Loss: 0.0064299909147624654, Train_acc 0.9972301136363636\n",
      "\n",
      "Epoch 127. Loss: 0.006359225656658812, Train_acc 0.9972550675675675\n",
      "\n",
      "Epoch 127. Loss: 0.006803787406745914, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 127. Loss: 0.006722540073287514, Train_acc 0.9972345132743363\n",
      "\n",
      "Epoch 127. Loss: 0.006079313853927279, Train_acc 0.9972587719298246\n",
      "\n",
      "Epoch 127. Loss: 0.008324277951909147, Train_acc 0.9972146739130435\n",
      "\n",
      "Epoch 127. Loss: 0.008232360661411026, Train_acc 0.9971713362068966\n",
      "\n",
      "Epoch 127. Loss: 0.00786579214704073, Train_acc 0.9971955128205128\n",
      "\n",
      "Epoch 127. Loss: 0.0077339634825024295, Train_acc 0.997219279661017\n",
      "\n",
      "Epoch 127. Loss: 0.007113898476405438, Train_acc 0.9972426470588235\n",
      "\n",
      "Epoch 127. Loss: 0.006974553077691939, Train_acc 0.997265625\n",
      "\n",
      "Epoch 127. Loss: 0.0065942672862700944, Train_acc 0.9972882231404959\n",
      "\n",
      "Epoch 127. Loss: 0.006306418520876079, Train_acc 0.9973104508196722\n",
      "\n",
      "Epoch 127. Loss: 0.005900313861632325, Train_acc 0.9973323170731707\n",
      "\n",
      "Epoch 127. Loss: 0.005746036340636592, Train_acc 0.9973538306451613\n",
      "\n",
      "Epoch 127. Loss: 0.005201100001739224, Train_acc 0.997375\n",
      "\n",
      "Epoch 127. Loss: 0.005266709246119941, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 127. Loss: 0.00480607743902676, Train_acc 0.9974163385826772\n",
      "\n",
      "Epoch 127. Loss: 0.004455402162949795, Train_acc 0.9974365234375\n",
      "\n",
      "Epoch 127. Loss: 0.004036528270192754, Train_acc 0.9974563953488372\n",
      "\n",
      "Epoch 127. Loss: 0.0043288183908144935, Train_acc 0.9974158653846154\n",
      "\n",
      "Epoch 127. Loss: 0.003924779611868885, Train_acc 0.9974355916030534\n",
      "\n",
      "Epoch 127. Loss: 0.004355179627725387, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 127. Loss: 0.003938244780841608, Train_acc 0.9974154135338346\n",
      "\n",
      "Epoch 127. Loss: 0.003677472526585137, Train_acc 0.9974347014925373\n",
      "\n",
      "Epoch 127. Loss: 0.0061190832895830945, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 127. Loss: 0.005513182606049474, Train_acc 0.9974149816176471\n",
      "\n",
      "Epoch 127. Loss: 0.00496919550720432, Train_acc 0.9974338503649635\n",
      "\n",
      "Epoch 127. Loss: 0.00450324178016405, Train_acc 0.997452445652174\n",
      "\n",
      "Epoch 127. Loss: 0.004104735808122642, Train_acc 0.997470773381295\n",
      "\n",
      "Epoch 127. Loss: 0.003701837622594598, Train_acc 0.9974888392857143\n",
      "\n",
      "Epoch 127. Loss: 0.003807427587856439, Train_acc 0.9975066489361702\n",
      "\n",
      "Epoch 127. Loss: 0.0037568834085386278, Train_acc 0.9975242077464789\n",
      "\n",
      "Epoch 127. Loss: 0.0035160119266022397, Train_acc 0.9975415209790209\n",
      "\n",
      "Epoch 127. Loss: 0.003171639923883443, Train_acc 0.99755859375\n",
      "\n",
      "Epoch 127. Loss: 0.0038171550196107904, Train_acc 0.9975215517241379\n",
      "\n",
      "Epoch 127. Loss: 0.004547242348941864, Train_acc 0.9974850171232876\n",
      "\n",
      "Epoch 127. Loss: 0.004193790666321845, Train_acc 0.9975021258503401\n",
      "\n",
      "Epoch 127. Loss: 0.0039980877149640905, Train_acc 0.9975190033783784\n",
      "\n",
      "Epoch 127. Loss: 0.0036039147438025393, Train_acc 0.9975356543624161\n",
      "\n",
      "Epoch 127. Loss: 0.0032549785749250355, Train_acc 0.9975520833333333\n",
      "\n",
      "Epoch 127. Loss: 0.0030754968932912084, Train_acc 0.9975682947019867\n",
      "\n",
      "Epoch 127. Loss: 0.0027997014358574074, Train_acc 0.9975842927631579\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127. Loss: 0.004287457348549419, Train_acc 0.9974979575163399\n",
      "\n",
      "Epoch 127. Loss: 0.0074869510218298916, Train_acc 0.997463474025974\n",
      "\n",
      "Epoch 127. Loss: 0.006843962277509703, Train_acc 0.9974798387096774\n",
      "\n",
      "Epoch 127. Loss: 0.006192194540348292, Train_acc 0.9974959935897436\n",
      "\n",
      "Epoch 127. Loss: 0.005605924373874232, Train_acc 0.9975119426751592\n",
      "\n",
      "Epoch 127. Loss: 0.005047819213866068, Train_acc 0.9975276898734177\n",
      "\n",
      "Epoch 127. Loss: 0.004703223983689136, Train_acc 0.9975432389937107\n",
      "\n",
      "Epoch 127. Loss: 0.004238395620896925, Train_acc 0.99755859375\n",
      "\n",
      "Epoch 127. Loss: 0.0038414517874679798, Train_acc 0.9975737577639752\n",
      "\n",
      "Epoch 127. Loss: 0.0034875172374775037, Train_acc 0.9975887345679012\n",
      "\n",
      "Epoch 127. Loss: 0.0031552350046769556, Train_acc 0.9976035276073619\n",
      "\n",
      "Epoch 127. Loss: 0.0038713913505556384, Train_acc 0.9976181402439024\n",
      "\n",
      "Epoch 127. Loss: 0.0035206173963584853, Train_acc 0.9976325757575758\n",
      "\n",
      "Epoch 127. Loss: 0.0031807020494142844, Train_acc 0.9976468373493976\n",
      "\n",
      "Epoch 127. Loss: 0.0030371567007384903, Train_acc 0.9976609281437125\n",
      "\n",
      "Epoch 127. Loss: 0.002735704549427998, Train_acc 0.9976748511904762\n",
      "\n",
      "Epoch 127. Loss: 0.002467006168108317, Train_acc 0.9976886094674556\n",
      "\n",
      "Epoch 127. Loss: 0.003850322526402295, Train_acc 0.99765625\n",
      "\n",
      "Epoch 127. Loss: 0.003475306936907572, Train_acc 0.9976699561403509\n",
      "\n",
      "Epoch 127. Loss: 0.0031608874703110104, Train_acc 0.9976835029069767\n",
      "\n",
      "Epoch 127. Loss: 0.0028476164673780476, Train_acc 0.9976968930635838\n",
      "\n",
      "Epoch 127. Loss: 0.002564506932681727, Train_acc 0.9977101293103449\n",
      "\n",
      "Epoch 127. Loss: 0.002318389750868073, Train_acc 0.9977232142857143\n",
      "\n",
      "Epoch 127. Loss: 0.002096631962846491, Train_acc 0.9977361505681818\n",
      "\n",
      "Epoch 127. Loss: 0.0020954966640464425, Train_acc 0.9977489406779662\n",
      "\n",
      "Epoch 127. Loss: 0.0019179786035932863, Train_acc 0.9977615870786517\n",
      "\n",
      "Epoch 127. Loss: 0.0017299552582960627, Train_acc 0.997774092178771\n",
      "\n",
      "Epoch 127. Loss: 0.001566451978056538, Train_acc 0.9977864583333333\n",
      "\n",
      "Epoch 127. Loss: 0.0014295185383191814, Train_acc 0.9977986878453039\n",
      "\n",
      "Epoch 127. Loss: 0.0012944288063435692, Train_acc 0.997810782967033\n",
      "\n",
      "Epoch 127. Loss: 0.0011992533082890678, Train_acc 0.9978227459016393\n",
      "\n",
      "Epoch 127. Loss: 0.0011939563939462456, Train_acc 0.9978345788043478\n",
      "\n",
      "Epoch 127. Loss: 0.0010801122545501672, Train_acc 0.9978462837837838\n",
      "\n",
      "Epoch 127. Loss: 0.0010305952812478915, Train_acc 0.9978578629032258\n",
      "\n",
      "Epoch 127. Loss: 0.0009312129289690533, Train_acc 0.9978693181818182\n",
      "\n",
      "Epoch 127. Loss: 0.0009450654075436782, Train_acc 0.9978806515957447\n",
      "\n",
      "Epoch 127. Loss: 0.000859523558158639, Train_acc 0.9978918650793651\n",
      "\n",
      "Epoch 127. Loss: 0.0007766920279105236, Train_acc 0.9979029605263158\n",
      "\n",
      "Epoch 127. Loss: 0.0007581919485343751, Train_acc 0.997913939790576\n",
      "\n",
      "Epoch 127. Loss: 0.0007587364026673815, Train_acc 0.9979248046875\n",
      "\n",
      "Epoch 127. Loss: 0.000684589753140924, Train_acc 0.9979355569948186\n",
      "\n",
      "Epoch 127. Loss: 0.0006173055492138452, Train_acc 0.9979461984536082\n",
      "\n",
      "Epoch 127. Loss: 0.0005612768788761471, Train_acc 0.9979567307692307\n",
      "\n",
      "Epoch 127. Loss: 0.0005145961444700613, Train_acc 0.99796\n",
      "\n",
      "Epoch 128. Loss: 0.000488991005120786, Train_acc 1.0\n",
      "\n",
      "Epoch 128. Loss: 0.00044688943090237445, Train_acc 1.0\n",
      "\n",
      "Epoch 128. Loss: 0.00047245701811937034, Train_acc 1.0\n",
      "\n",
      "Epoch 128. Loss: 0.0011534193757524569, Train_acc 0.998046875\n",
      "\n",
      "Epoch 128. Loss: 0.0010519733763501475, Train_acc 0.9984375\n",
      "\n",
      "Epoch 128. Loss: 0.0009557445856144013, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 128. Loss: 0.0008656132181934391, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 128. Loss: 0.0008009364838510565, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 128. Loss: 0.0007222289814252099, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 128. Loss: 0.0006519899051404095, Train_acc 0.99921875\n",
      "\n",
      "Epoch 128. Loss: 0.0005969146136567418, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 128. Loss: 0.0005388703774356198, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 128. Loss: 0.0004895213500904494, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 128. Loss: 0.0004881972843778837, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 128. Loss: 0.0004409340968231252, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 128. Loss: 0.0004025241042526807, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 128. Loss: 0.0005439066507982235, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 128. Loss: 0.0004920453856171775, Train_acc 0.9995659722222222\n",
      "\n",
      "Epoch 128. Loss: 0.000447769774647578, Train_acc 0.9995888157894737\n",
      "\n",
      "Epoch 128. Loss: 0.0004039624755136957, Train_acc 0.999609375\n",
      "\n",
      "Epoch 128. Loss: 0.000364993496178829, Train_acc 0.9996279761904762\n",
      "\n",
      "Epoch 128. Loss: 0.00038015276459201576, Train_acc 0.9996448863636364\n",
      "\n",
      "Epoch 128. Loss: 0.0003498045932247827, Train_acc 0.9996603260869565\n",
      "\n",
      "Epoch 128. Loss: 0.0004382812439235678, Train_acc 0.9996744791666666\n",
      "\n",
      "Epoch 128. Loss: 0.00040606194119125843, Train_acc 0.9996875\n",
      "\n",
      "Epoch 128. Loss: 0.00038421144430992595, Train_acc 0.9996995192307693\n",
      "\n",
      "Epoch 128. Loss: 0.00040131961094542676, Train_acc 0.9997106481481481\n",
      "\n",
      "Epoch 128. Loss: 0.00040203441023562255, Train_acc 0.9997209821428571\n",
      "\n",
      "Epoch 128. Loss: 0.0003684166108888532, Train_acc 0.9997306034482759\n",
      "\n",
      "Epoch 128. Loss: 0.00034120731214380446, Train_acc 0.9997395833333333\n",
      "\n",
      "Epoch 128. Loss: 0.0003590698114438759, Train_acc 0.9997479838709677\n",
      "\n",
      "Epoch 128. Loss: 0.0007690690894189989, Train_acc 0.999755859375\n",
      "\n",
      "Epoch 128. Loss: 0.0006944049949573679, Train_acc 0.9997632575757576\n",
      "\n",
      "Epoch 128. Loss: 0.0006252960309732085, Train_acc 0.9997702205882353\n",
      "\n",
      "Epoch 128. Loss: 0.0005628925259056833, Train_acc 0.9997767857142857\n",
      "\n",
      "Epoch 128. Loss: 0.0005066716319828191, Train_acc 0.9997829861111112\n",
      "\n",
      "Epoch 128. Loss: 0.0004871331400376373, Train_acc 0.9997888513513513\n",
      "\n",
      "Epoch 128. Loss: 0.000458504826175863, Train_acc 0.9997944078947368\n",
      "\n",
      "Epoch 128. Loss: 0.000413538773404614, Train_acc 0.9997996794871795\n",
      "\n",
      "Epoch 128. Loss: 0.0003780442589278553, Train_acc 0.9998046875\n",
      "\n",
      "Epoch 128. Loss: 0.0003591791419736401, Train_acc 0.9998094512195121\n",
      "\n",
      "Epoch 128. Loss: 0.0003375105490241927, Train_acc 0.9998139880952381\n",
      "\n",
      "Epoch 128. Loss: 0.0003051846844157312, Train_acc 0.9998183139534884\n",
      "\n",
      "Epoch 128. Loss: 0.00028281409961056935, Train_acc 0.9998224431818182\n",
      "\n",
      "Epoch 128. Loss: 0.0002552075022492671, Train_acc 0.9998263888888889\n",
      "\n",
      "Epoch 128. Loss: 0.00023140478969877674, Train_acc 0.9998301630434783\n",
      "\n",
      "Epoch 128. Loss: 0.0002093330675026468, Train_acc 0.9998337765957447\n",
      "\n",
      "Epoch 128. Loss: 0.0001936163989898529, Train_acc 0.9998372395833334\n",
      "\n",
      "Epoch 128. Loss: 0.00020277214154313205, Train_acc 0.9998405612244898\n",
      "\n",
      "Epoch 128. Loss: 0.00019434602461309907, Train_acc 0.99984375\n",
      "\n",
      "Epoch 128. Loss: 0.00017712739053124898, Train_acc 0.9998468137254902\n",
      "\n",
      "Epoch 128. Loss: 0.0001615190872490129, Train_acc 0.9998497596153846\n",
      "\n",
      "Epoch 128. Loss: 0.00017832978981846312, Train_acc 0.9998525943396226\n",
      "\n",
      "Epoch 128. Loss: 0.00016519151698578326, Train_acc 0.9998553240740741\n",
      "\n",
      "Epoch 128. Loss: 0.00015051861934102162, Train_acc 0.9998579545454546\n",
      "\n",
      "Epoch 128. Loss: 0.00016738050448658989, Train_acc 0.9998604910714286\n",
      "\n",
      "Epoch 128. Loss: 0.000181540582208451, Train_acc 0.9998629385964912\n",
      "\n",
      "Epoch 128. Loss: 0.0001789909152160135, Train_acc 0.9998653017241379\n",
      "\n",
      "Epoch 128. Loss: 0.000176663921312545, Train_acc 0.9998675847457628\n",
      "\n",
      "Epoch 128. Loss: 0.00016324714826849483, Train_acc 0.9998697916666667\n",
      "\n",
      "Epoch 128. Loss: 0.00015665520836613222, Train_acc 0.9998719262295082\n",
      "\n",
      "Epoch 128. Loss: 0.00015591085324123108, Train_acc 0.9998739919354839\n",
      "\n",
      "Epoch 128. Loss: 0.00014095878571578389, Train_acc 0.9998759920634921\n",
      "\n",
      "Epoch 128. Loss: 0.0001752328156167286, Train_acc 0.9998779296875\n",
      "\n",
      "Epoch 128. Loss: 0.00015872511294643925, Train_acc 0.9998798076923077\n",
      "\n",
      "Epoch 128. Loss: 0.0001430238662798747, Train_acc 0.9998816287878788\n",
      "\n",
      "Epoch 128. Loss: 0.0001297994679787569, Train_acc 0.999883395522388\n",
      "\n",
      "Epoch 128. Loss: 0.00012370155335666243, Train_acc 0.9998851102941176\n",
      "\n",
      "Epoch 128. Loss: 0.00011550929872159329, Train_acc 0.9998867753623188\n",
      "\n",
      "Epoch 128. Loss: 0.00010823324096652772, Train_acc 0.9998883928571428\n",
      "\n",
      "Epoch 128. Loss: 0.000803261391646739, Train_acc 0.9997799295774648\n",
      "\n",
      "Epoch 128. Loss: 0.0007668145854342665, Train_acc 0.9997829861111112\n",
      "\n",
      "Epoch 128. Loss: 0.0007205849158070924, Train_acc 0.9997859589041096\n",
      "\n",
      "Epoch 128. Loss: 0.0006494011091098394, Train_acc 0.9997888513513513\n",
      "\n",
      "Epoch 128. Loss: 0.0005848672108197292, Train_acc 0.9997916666666666\n",
      "\n",
      "Epoch 128. Loss: 0.009502204458386666, Train_acc 0.9996916118421053\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128. Loss: 0.008554983203021928, Train_acc 0.9996956168831169\n",
      "\n",
      "Epoch 128. Loss: 0.007703417361004432, Train_acc 0.9996995192307693\n",
      "\n",
      "Epoch 128. Loss: 0.006987211333973659, Train_acc 0.9997033227848101\n",
      "\n",
      "Epoch 128. Loss: 0.0063734640722842096, Train_acc 0.99970703125\n",
      "\n",
      "Epoch 128. Loss: 0.009209679667237796, Train_acc 0.9996141975308642\n",
      "\n",
      "Epoch 128. Loss: 0.008424442280009447, Train_acc 0.9996189024390244\n",
      "\n",
      "Epoch 128. Loss: 0.007606170590550691, Train_acc 0.9996234939759037\n",
      "\n",
      "Epoch 128. Loss: 0.006866545428822516, Train_acc 0.9996279761904762\n",
      "\n",
      "Epoch 128. Loss: 0.008735902339211177, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 128. Loss: 0.007865646268847216, Train_acc 0.9995457848837209\n",
      "\n",
      "Epoch 128. Loss: 0.008137901159455743, Train_acc 0.9995510057471264\n",
      "\n",
      "Epoch 128. Loss: 0.12786769825130437, Train_acc 0.9994673295454546\n",
      "\n",
      "Epoch 128. Loss: 0.11807120442011715, Train_acc 0.9993855337078652\n",
      "\n",
      "Epoch 128. Loss: 0.10646105213681246, Train_acc 0.9993923611111111\n",
      "\n",
      "Epoch 128. Loss: 0.09628243690888035, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 128. Loss: 0.08818637438410473, Train_acc 0.9993206521739131\n",
      "\n",
      "Epoch 128. Loss: 0.08087307497376758, Train_acc 0.9992439516129032\n",
      "\n",
      "Epoch 128. Loss: 0.07832550809843444, Train_acc 0.9991688829787234\n",
      "\n",
      "Epoch 128. Loss: 0.07551547488030587, Train_acc 0.9990131578947369\n",
      "\n",
      "Epoch 128. Loss: 0.07641270026973004, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 128. Loss: 0.07235393314431116, Train_acc 0.9986307989690721\n",
      "\n",
      "Epoch 128. Loss: 0.06603319629389053, Train_acc 0.9986447704081632\n",
      "\n",
      "Epoch 128. Loss: 0.06048858740351801, Train_acc 0.9986584595959596\n",
      "\n",
      "Epoch 128. Loss: 0.05542176035498564, Train_acc 0.998671875\n",
      "\n",
      "[Epoch 128 Batch 100] Loss: 0.05033406344947205 Training: accuracy=0.998685\n",
      "Epoch 128. Loss: 0.05033406344947205, Train_acc 0.9986850247524752\n",
      "\n",
      "Epoch 128. Loss: 0.04646740647760319, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 128. Loss: 0.04341816660857755, Train_acc 0.9986347087378641\n",
      "\n",
      "Epoch 128. Loss: 0.03987087073561452, Train_acc 0.9986478365384616\n",
      "\n",
      "Epoch 128. Loss: 0.03787731800350758, Train_acc 0.9985863095238096\n",
      "\n",
      "Epoch 128. Loss: 0.03477210734894764, Train_acc 0.9985996462264151\n",
      "\n",
      "Epoch 128. Loss: 0.03274507017085753, Train_acc 0.9985397196261683\n",
      "\n",
      "Epoch 128. Loss: 0.030101596037892718, Train_acc 0.9985532407407407\n",
      "\n",
      "Epoch 128. Loss: 0.028473137571974, Train_acc 0.9984948394495413\n",
      "\n",
      "Epoch 128. Loss: 0.02683561910351819, Train_acc 0.9985085227272728\n",
      "\n",
      "Epoch 128. Loss: 0.024651541788077706, Train_acc 0.9985219594594594\n",
      "\n",
      "Epoch 128. Loss: 0.022593087236907797, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 128. Loss: 0.02299885640814309, Train_acc 0.9984789823008849\n",
      "\n",
      "Epoch 128. Loss: 0.020983524785036487, Train_acc 0.9984923245614035\n",
      "\n",
      "Epoch 128. Loss: 0.01951508443706749, Train_acc 0.9985054347826087\n",
      "\n",
      "Epoch 128. Loss: 0.017998936654137234, Train_acc 0.9985183189655172\n",
      "\n",
      "Epoch 128. Loss: 0.018394701896017784, Train_acc 0.9984642094017094\n",
      "\n",
      "Epoch 128. Loss: 0.017566569977616662, Train_acc 0.9984772245762712\n",
      "\n",
      "Epoch 128. Loss: 0.016083133081226404, Train_acc 0.9984900210084033\n",
      "\n",
      "Epoch 128. Loss: 0.015543152936961223, Train_acc 0.9984375\n",
      "\n",
      "Epoch 128. Loss: 0.01430454475033966, Train_acc 0.9984504132231405\n",
      "\n",
      "Epoch 128. Loss: 0.01320186278274972, Train_acc 0.9984631147540983\n",
      "\n",
      "Epoch 128. Loss: 0.012685767376881707, Train_acc 0.9984756097560976\n",
      "\n",
      "Epoch 128. Loss: 0.011619208731579962, Train_acc 0.9984879032258065\n",
      "\n",
      "Epoch 128. Loss: 0.010497333358340017, Train_acc 0.9985\n",
      "\n",
      "Epoch 128. Loss: 0.009687300730112987, Train_acc 0.9985119047619048\n",
      "\n",
      "Epoch 128. Loss: 0.008819391867173133, Train_acc 0.9985236220472441\n",
      "\n",
      "Epoch 128. Loss: 0.008036073664227799, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 128. Loss: 0.007333472806144215, Train_acc 0.998546511627907\n",
      "\n",
      "Epoch 128. Loss: 0.00662490371769417, Train_acc 0.9985576923076923\n",
      "\n",
      "Epoch 128. Loss: 0.006829903443805117, Train_acc 0.9985687022900763\n",
      "\n",
      "Epoch 128. Loss: 0.006362351107733016, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 128. Loss: 0.005857629384855834, Train_acc 0.9985902255639098\n",
      "\n",
      "Epoch 128. Loss: 0.005929702794188626, Train_acc 0.9985424440298507\n",
      "\n",
      "Epoch 128. Loss: 0.005391063318456516, Train_acc 0.9985532407407407\n",
      "\n",
      "Epoch 128. Loss: 0.005100514199373399, Train_acc 0.9985638786764706\n",
      "\n",
      "Epoch 128. Loss: 0.004638871739428289, Train_acc 0.9985743613138686\n",
      "\n",
      "Epoch 128. Loss: 0.004825376712266547, Train_acc 0.9985280797101449\n",
      "\n",
      "Epoch 128. Loss: 0.00494844686543996, Train_acc 0.9985386690647482\n",
      "\n",
      "Epoch 128. Loss: 0.004842754944170012, Train_acc 0.9985491071428572\n",
      "\n",
      "Epoch 128. Loss: 0.004477225278266066, Train_acc 0.9985593971631206\n",
      "\n",
      "Epoch 128. Loss: 0.004101314892126138, Train_acc 0.9985695422535211\n",
      "\n",
      "Epoch 128. Loss: 0.003708690572018171, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 128. Loss: 0.003531787531921039, Train_acc 0.9985894097222222\n",
      "\n",
      "Epoch 128. Loss: 0.0036044348849494194, Train_acc 0.9985991379310345\n",
      "\n",
      "Epoch 128. Loss: 0.0038712876747076753, Train_acc 0.9985552226027398\n",
      "\n",
      "Epoch 128. Loss: 0.003544136488495771, Train_acc 0.9985650510204082\n",
      "\n",
      "Epoch 128. Loss: 0.0035613889292778114, Train_acc 0.9985747466216216\n",
      "\n",
      "Epoch 128. Loss: 0.0034117409916655608, Train_acc 0.9985843120805369\n",
      "\n",
      "Epoch 128. Loss: 0.003107718688776617, Train_acc 0.99859375\n",
      "\n",
      "Epoch 128. Loss: 0.002879014377276696, Train_acc 0.9986030629139073\n",
      "\n",
      "Epoch 128. Loss: 0.0026136158830149785, Train_acc 0.9986122532894737\n",
      "\n",
      "Epoch 128. Loss: 0.002367649077244556, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 128. Loss: 0.0021654839323956873, Train_acc 0.998630275974026\n",
      "\n",
      "Epoch 128. Loss: 0.002110499411981473, Train_acc 0.9986391129032258\n",
      "\n",
      "Epoch 128. Loss: 0.001915916956476609, Train_acc 0.9986478365384616\n",
      "\n",
      "Epoch 128. Loss: 0.001740503199788975, Train_acc 0.998656449044586\n",
      "\n",
      "Epoch 128. Loss: 0.0015736484832035613, Train_acc 0.9986649525316456\n",
      "\n",
      "Epoch 128. Loss: 0.0014598091001816493, Train_acc 0.9986733490566038\n",
      "\n",
      "Epoch 128. Loss: 0.001878377168745509, Train_acc 0.998681640625\n",
      "\n",
      "Epoch 128. Loss: 0.0017014309114039717, Train_acc 0.9986898291925466\n",
      "\n",
      "Epoch 128. Loss: 0.0015531239687803153, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 128. Loss: 0.001401127019149871, Train_acc 0.9987059049079755\n",
      "\n",
      "Epoch 128. Loss: 0.0012713085196007965, Train_acc 0.9987137957317073\n",
      "\n",
      "Epoch 128. Loss: 0.0011897071644967508, Train_acc 0.998721590909091\n",
      "\n",
      "Epoch 128. Loss: 0.0010965516155113915, Train_acc 0.9987292921686747\n",
      "\n",
      "Epoch 128. Loss: 0.0010496861404501027, Train_acc 0.9987369011976048\n",
      "\n",
      "Epoch 128. Loss: 0.0010685856872861945, Train_acc 0.9987444196428571\n",
      "\n",
      "Epoch 128. Loss: 0.0009773177436741766, Train_acc 0.998751849112426\n",
      "\n",
      "Epoch 128. Loss: 0.0008926677874855208, Train_acc 0.9987591911764706\n",
      "\n",
      "Epoch 128. Loss: 0.0008092626984519165, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 128. Loss: 0.0007391304652500716, Train_acc 0.9987736191860465\n",
      "\n",
      "Epoch 128. Loss: 0.0012330330578036817, Train_acc 0.9987807080924855\n",
      "\n",
      "Epoch 128. Loss: 0.0011586199438521456, Train_acc 0.9987877155172413\n",
      "\n",
      "Epoch 128. Loss: 0.001094863270550149, Train_acc 0.9987946428571428\n",
      "\n",
      "Epoch 128. Loss: 0.0009951682098428816, Train_acc 0.9988014914772727\n",
      "\n",
      "Epoch 128. Loss: 0.0009249480030882726, Train_acc 0.9988082627118644\n",
      "\n",
      "Epoch 128. Loss: 0.0008759157747002724, Train_acc 0.9988149578651685\n",
      "\n",
      "Epoch 128. Loss: 0.0008277393372844338, Train_acc 0.9988215782122905\n",
      "\n",
      "Epoch 128. Loss: 0.0012026025086931001, Train_acc 0.998828125\n",
      "\n",
      "Epoch 128. Loss: 0.00172138870703801, Train_acc 0.9987914364640884\n",
      "\n",
      "Epoch 128. Loss: 0.0016458362993758127, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 128. Loss: 0.001492670007538959, Train_acc 0.9988046448087432\n",
      "\n",
      "Epoch 128. Loss: 0.001457650896508692, Train_acc 0.9988111413043478\n",
      "\n",
      "Epoch 128. Loss: 0.0013730199801598028, Train_acc 0.9988175675675676\n",
      "\n",
      "Epoch 128. Loss: 0.0014275138779512677, Train_acc 0.9988239247311828\n",
      "\n",
      "Epoch 128. Loss: 0.0013025516826538712, Train_acc 0.9988302139037433\n",
      "\n",
      "Epoch 128. Loss: 0.0012498796546164279, Train_acc 0.9988364361702128\n",
      "\n",
      "Epoch 128. Loss: 0.0011793032443295232, Train_acc 0.9988425925925926\n",
      "\n",
      "Epoch 128. Loss: 0.0011092851997389923, Train_acc 0.9988486842105263\n",
      "\n",
      "Epoch 128. Loss: 0.0011444168024077593, Train_acc 0.9988547120418848\n",
      "\n",
      "Epoch 128. Loss: 0.0010995070078412066, Train_acc 0.9988606770833334\n",
      "\n",
      "Epoch 128. Loss: 0.0010329089130649155, Train_acc 0.9988665803108808\n",
      "\n",
      "Epoch 128. Loss: 0.0018370154782255757, Train_acc 0.9988321520618557\n",
      "\n",
      "Epoch 128. Loss: 0.001669603155134754, Train_acc 0.9988381410256411\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128. Loss: 0.0015101689512065995, Train_acc 0.99884\n",
      "\n",
      "Epoch 129. Loss: 0.0013783336602338281, Train_acc 1.0\n",
      "\n",
      "Epoch 129. Loss: 0.0012510032299759893, Train_acc 1.0\n",
      "\n",
      "Epoch 129. Loss: 0.0013383722314479567, Train_acc 1.0\n",
      "\n",
      "Epoch 129. Loss: 0.0012318578007512646, Train_acc 1.0\n",
      "\n",
      "Epoch 129. Loss: 0.0011213259732570147, Train_acc 1.0\n",
      "\n",
      "Epoch 129. Loss: 0.0010767749440774377, Train_acc 1.0\n",
      "\n",
      "Epoch 129. Loss: 0.0009719156961727053, Train_acc 1.0\n",
      "\n",
      "Epoch 129. Loss: 0.0008798843288276711, Train_acc 1.0\n",
      "\n",
      "Epoch 129. Loss: 0.0008093714451929512, Train_acc 1.0\n",
      "\n",
      "Epoch 129. Loss: 0.0009635728547996804, Train_acc 1.0\n",
      "\n",
      "Epoch 129. Loss: 0.000940521331226962, Train_acc 1.0\n",
      "\n",
      "Epoch 129. Loss: 0.0008957263601313268, Train_acc 1.0\n",
      "\n",
      "Epoch 129. Loss: 0.0009334515385879787, Train_acc 1.0\n",
      "\n",
      "Epoch 129. Loss: 0.0008450366707425856, Train_acc 1.0\n",
      "\n",
      "Epoch 129. Loss: 0.0010137187964944431, Train_acc 1.0\n",
      "\n",
      "Epoch 129. Loss: 0.0025728701079393975, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 129. Loss: 0.005311675014302631, Train_acc 0.9990808823529411\n",
      "\n",
      "Epoch 129. Loss: 0.005375441076715738, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 129. Loss: 0.009010395329320386, Train_acc 0.9979440789473685\n",
      "\n",
      "Epoch 129. Loss: 0.008797517683616836, Train_acc 0.99765625\n",
      "\n",
      "Epoch 129. Loss: 0.007955649335264318, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 129. Loss: 0.00923575580633803, Train_acc 0.9975142045454546\n",
      "\n",
      "Epoch 129. Loss: 0.008375319536509353, Train_acc 0.9976222826086957\n",
      "\n",
      "Epoch 129. Loss: 0.00837665655477247, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 129. Loss: 0.014580780490607632, Train_acc 0.996875\n",
      "\n",
      "Epoch 129. Loss: 0.013260912597548021, Train_acc 0.9969951923076923\n",
      "\n",
      "Epoch 129. Loss: 0.012473055657331096, Train_acc 0.9971064814814815\n",
      "\n",
      "Epoch 129. Loss: 0.011372122987285805, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 129. Loss: 0.013773487574615079, Train_acc 0.9970366379310345\n",
      "\n",
      "Epoch 129. Loss: 0.016131014287553428, Train_acc 0.9966145833333333\n",
      "\n",
      "Epoch 129. Loss: 0.014842449835202574, Train_acc 0.9967237903225806\n",
      "\n",
      "Epoch 129. Loss: 0.014040028762827646, Train_acc 0.99658203125\n",
      "\n",
      "Epoch 129. Loss: 0.015151193256983457, Train_acc 0.9962121212121212\n",
      "\n",
      "Epoch 129. Loss: 0.01385361852140811, Train_acc 0.9963235294117647\n",
      "\n",
      "Epoch 129. Loss: 0.012780161675214053, Train_acc 0.9964285714285714\n",
      "\n",
      "Epoch 129. Loss: 0.01213341285227175, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 129. Loss: 0.012115782278225738, Train_acc 0.9966216216216216\n",
      "\n",
      "Epoch 129. Loss: 0.01175234340722494, Train_acc 0.9967105263157895\n",
      "\n",
      "Epoch 129. Loss: 0.011060261010856621, Train_acc 0.9967948717948718\n",
      "\n",
      "Epoch 129. Loss: 0.01009304759655329, Train_acc 0.996875\n",
      "\n",
      "Epoch 129. Loss: 0.00927514108124911, Train_acc 0.9969512195121951\n",
      "\n",
      "Epoch 129. Loss: 0.008410365343740189, Train_acc 0.9970238095238095\n",
      "\n",
      "Epoch 129. Loss: 0.008980310356453601, Train_acc 0.9969113372093024\n",
      "\n",
      "Epoch 129. Loss: 0.008102926908179299, Train_acc 0.9969815340909091\n",
      "\n",
      "Epoch 129. Loss: 0.007656976083586373, Train_acc 0.9970486111111111\n",
      "\n",
      "Epoch 129. Loss: 0.009093741066458605, Train_acc 0.9969429347826086\n",
      "\n",
      "Epoch 129. Loss: 0.008292140527828291, Train_acc 0.9970079787234043\n",
      "\n",
      "Epoch 129. Loss: 0.012071447340485831, Train_acc 0.9969075520833334\n",
      "\n",
      "Epoch 129. Loss: 0.012100404498282714, Train_acc 0.9968112244897959\n",
      "\n",
      "Epoch 129. Loss: 0.011435383052948394, Train_acc 0.996875\n",
      "\n",
      "Epoch 129. Loss: 0.010704469449511122, Train_acc 0.9969362745098039\n",
      "\n",
      "Epoch 129. Loss: 0.010082553463525431, Train_acc 0.9969951923076923\n",
      "\n",
      "Epoch 129. Loss: 0.009631444059175423, Train_acc 0.9970518867924528\n",
      "\n",
      "Epoch 129. Loss: 0.009129558485623156, Train_acc 0.9971064814814815\n",
      "\n",
      "Epoch 129. Loss: 0.008807828233205636, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 129. Loss: 0.01078754421075883, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 129. Loss: 0.009787017323641801, Train_acc 0.9971217105263158\n",
      "\n",
      "Epoch 129. Loss: 0.009480549999835036, Train_acc 0.9971713362068966\n",
      "\n",
      "Epoch 129. Loss: 0.009548626136417934, Train_acc 0.997219279661017\n",
      "\n",
      "Epoch 129. Loss: 0.013522587083252444, Train_acc 0.9970052083333333\n",
      "\n",
      "Epoch 129. Loss: 0.012618756003652967, Train_acc 0.9970543032786885\n",
      "\n",
      "Epoch 129. Loss: 0.011373273262394089, Train_acc 0.997101814516129\n",
      "\n",
      "Epoch 129. Loss: 0.010379267528049753, Train_acc 0.9971478174603174\n",
      "\n",
      "Epoch 129. Loss: 0.00977102143933708, Train_acc 0.9971923828125\n",
      "\n",
      "Epoch 129. Loss: 0.01088796457681359, Train_acc 0.9971153846153846\n",
      "\n",
      "Epoch 129. Loss: 0.010088239656686494, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 129. Loss: 0.009152339517537245, Train_acc 0.9972014925373134\n",
      "\n",
      "Epoch 129. Loss: 0.00882908390339925, Train_acc 0.9972426470588235\n",
      "\n",
      "Epoch 129. Loss: 0.008852897108734077, Train_acc 0.9971693840579711\n",
      "\n",
      "Epoch 129. Loss: 0.008548389189219855, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 129. Loss: 0.007915045391084, Train_acc 0.9972491197183099\n",
      "\n",
      "Epoch 129. Loss: 0.0072005982140440445, Train_acc 0.9972873263888888\n",
      "\n",
      "Epoch 129. Loss: 0.006570877735936004, Train_acc 0.9973244863013698\n",
      "\n",
      "Epoch 129. Loss: 0.005956683403037883, Train_acc 0.9973606418918919\n",
      "\n",
      "Epoch 129. Loss: 0.005380293668493704, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 129. Loss: 0.00511300652617372, Train_acc 0.9974300986842105\n",
      "\n",
      "Epoch 129. Loss: 0.004719175918199035, Train_acc 0.997463474025974\n",
      "\n",
      "Epoch 129. Loss: 0.004451105932114195, Train_acc 0.9974959935897436\n",
      "\n",
      "Epoch 129. Loss: 0.009172084128604239, Train_acc 0.9973299050632911\n",
      "\n",
      "Epoch 129. Loss: 0.008342992044441467, Train_acc 0.99736328125\n",
      "\n",
      "Epoch 129. Loss: 0.008018282238277106, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 129. Loss: 0.0073888154200157305, Train_acc 0.9974275914634146\n",
      "\n",
      "Epoch 129. Loss: 0.008590529050359796, Train_acc 0.9973644578313253\n",
      "\n",
      "Epoch 129. Loss: 0.00841391887375385, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 129. Loss: 0.010642626079398428, Train_acc 0.9972426470588235\n",
      "\n",
      "Epoch 129. Loss: 0.009632382264620544, Train_acc 0.9972747093023255\n",
      "\n",
      "Epoch 129. Loss: 0.008698048967217117, Train_acc 0.9973060344827587\n",
      "\n",
      "Epoch 129. Loss: 0.00790540517025713, Train_acc 0.9973366477272727\n",
      "\n",
      "Epoch 129. Loss: 0.008222849807025706, Train_acc 0.9972787921348315\n",
      "\n",
      "Epoch 129. Loss: 0.008120861067666156, Train_acc 0.9972222222222222\n",
      "\n",
      "Epoch 129. Loss: 0.011009254825973699, Train_acc 0.9970810439560439\n",
      "\n",
      "Epoch 129. Loss: 0.010752013998059204, Train_acc 0.9970278532608695\n",
      "\n",
      "Epoch 129. Loss: 0.009683259467773288, Train_acc 0.997059811827957\n",
      "\n",
      "Epoch 129. Loss: 0.0100099508789116, Train_acc 0.9970079787234043\n",
      "\n",
      "Epoch 129. Loss: 0.01122030878754859, Train_acc 0.996875\n",
      "\n",
      "Epoch 129. Loss: 0.01429164273761873, Train_acc 0.996826171875\n",
      "\n",
      "Epoch 129. Loss: 0.01434512090584485, Train_acc 0.9967783505154639\n",
      "\n",
      "Epoch 129. Loss: 0.012975578209849207, Train_acc 0.9968112244897959\n",
      "\n",
      "Epoch 129. Loss: 0.012037841382481464, Train_acc 0.9968434343434344\n",
      "\n",
      "Epoch 129. Loss: 0.010927183995250143, Train_acc 0.996875\n",
      "\n",
      "[Epoch 129 Batch 100] Loss: 0.010647332507017205 Training: accuracy=0.996906\n",
      "Epoch 129. Loss: 0.010647332507017205, Train_acc 0.9969059405940595\n",
      "\n",
      "Epoch 129. Loss: 0.013345217336097018, Train_acc 0.996859681372549\n",
      "\n",
      "Epoch 129. Loss: 0.013747531737874737, Train_acc 0.9968143203883495\n",
      "\n",
      "Epoch 129. Loss: 0.01242400609618161, Train_acc 0.9968449519230769\n",
      "\n",
      "Epoch 129. Loss: 0.011571666244781618, Train_acc 0.996875\n",
      "\n",
      "Epoch 129. Loss: 0.010742693923741524, Train_acc 0.9969044811320755\n",
      "\n",
      "Epoch 129. Loss: 0.009916221202832412, Train_acc 0.9969334112149533\n",
      "\n",
      "Epoch 129. Loss: 0.009302402844061211, Train_acc 0.9969618055555556\n",
      "\n",
      "Epoch 129. Loss: 0.009233810284760375, Train_acc 0.9969896788990825\n",
      "\n",
      "Epoch 129. Loss: 0.008470153522552652, Train_acc 0.9970170454545455\n",
      "\n",
      "Epoch 129. Loss: 0.007744223958420696, Train_acc 0.997043918918919\n",
      "\n",
      "Epoch 129. Loss: 0.0073777201983344035, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 129. Loss: 0.007410129875362946, Train_acc 0.9970962389380531\n",
      "\n",
      "Epoch 129. Loss: 0.010701664287228317, Train_acc 0.9970531798245614\n",
      "\n",
      "Epoch 129. Loss: 0.0097403337512573, Train_acc 0.9970788043478261\n",
      "\n",
      "Epoch 129. Loss: 0.008954691484663074, Train_acc 0.9971039870689655\n",
      "\n",
      "Epoch 129. Loss: 0.009502653396957982, Train_acc 0.9970619658119658\n",
      "\n",
      "Epoch 129. Loss: 0.010549682334214928, Train_acc 0.997020656779661\n",
      "\n",
      "Epoch 129. Loss: 0.009961732371658519, Train_acc 0.997045693277311\n",
      "\n",
      "Epoch 129. Loss: 0.009138506761053593, Train_acc 0.9970703125\n",
      "\n",
      "Epoch 129. Loss: 0.008266503231297262, Train_acc 0.9970945247933884\n",
      "\n",
      "Epoch 129. Loss: 0.008222874376836713, Train_acc 0.9971183401639344\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129. Loss: 0.0074856483610037374, Train_acc 0.997141768292683\n",
      "\n",
      "Epoch 129. Loss: 0.006998789359321899, Train_acc 0.9971648185483871\n",
      "\n",
      "Epoch 129. Loss: 0.0063669001320126265, Train_acc 0.9971875\n",
      "\n",
      "Epoch 129. Loss: 0.005791015692405189, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 129. Loss: 0.005288065680897043, Train_acc 0.9972317913385826\n",
      "\n",
      "Epoch 129. Loss: 0.004807142684631398, Train_acc 0.99725341796875\n",
      "\n",
      "Epoch 129. Loss: 0.005844082440232799, Train_acc 0.9972141472868217\n",
      "\n",
      "Epoch 129. Loss: 0.005662809372957556, Train_acc 0.997235576923077\n",
      "\n",
      "Epoch 129. Loss: 0.005138692575111397, Train_acc 0.997256679389313\n",
      "\n",
      "Epoch 129. Loss: 0.004717251693101444, Train_acc 0.9972774621212122\n",
      "\n",
      "Epoch 129. Loss: 0.0050035834717527495, Train_acc 0.9972979323308271\n",
      "\n",
      "Epoch 129. Loss: 0.004528149158946653, Train_acc 0.9973180970149254\n",
      "\n",
      "Epoch 129. Loss: 0.004239313803654445, Train_acc 0.997337962962963\n",
      "\n",
      "Epoch 129. Loss: 0.003845380305955067, Train_acc 0.9973575367647058\n",
      "\n",
      "Epoch 129. Loss: 0.006373477631547381, Train_acc 0.9972627737226277\n",
      "\n",
      "Epoch 129. Loss: 0.005752046209027801, Train_acc 0.9972826086956522\n",
      "\n",
      "Epoch 129. Loss: 0.005214852410152012, Train_acc 0.9973021582733813\n",
      "\n",
      "Epoch 129. Loss: 0.004795023181839544, Train_acc 0.9973214285714286\n",
      "\n",
      "Epoch 129. Loss: 0.004391560569546752, Train_acc 0.9973404255319149\n",
      "\n",
      "Epoch 129. Loss: 0.003999245986842036, Train_acc 0.9973591549295775\n",
      "\n",
      "Epoch 129. Loss: 0.003685314813612777, Train_acc 0.9973776223776224\n",
      "\n",
      "Epoch 129. Loss: 0.0036436324333627918, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 129. Loss: 0.004142259509755364, Train_acc 0.9973599137931034\n",
      "\n",
      "Epoch 129. Loss: 0.005425623202079408, Train_acc 0.9972709760273972\n",
      "\n",
      "Epoch 129. Loss: 0.007342917377132659, Train_acc 0.9972363945578231\n",
      "\n",
      "Epoch 129. Loss: 0.006673394788013162, Train_acc 0.9972550675675675\n",
      "\n",
      "Epoch 129. Loss: 0.008162063530420895, Train_acc 0.9972210570469798\n",
      "\n",
      "Epoch 129. Loss: 0.007730175703281733, Train_acc 0.9972395833333333\n",
      "\n",
      "Epoch 129. Loss: 0.007106735965734337, Train_acc 0.9972578642384106\n",
      "\n",
      "Epoch 129. Loss: 0.008123654569201721, Train_acc 0.9971731085526315\n",
      "\n",
      "Epoch 129. Loss: 0.00877498156131481, Train_acc 0.997140522875817\n",
      "\n",
      "Epoch 129. Loss: 0.00836130477161266, Train_acc 0.9971590909090909\n",
      "\n",
      "Epoch 129. Loss: 0.007788515205348053, Train_acc 0.9971774193548387\n",
      "\n",
      "Epoch 129. Loss: 0.007218397823681997, Train_acc 0.9971955128205128\n",
      "\n",
      "Epoch 129. Loss: 0.006681663758123428, Train_acc 0.9972133757961783\n",
      "\n",
      "Epoch 129. Loss: 0.014357565015463094, Train_acc 0.9971815664556962\n",
      "\n",
      "Epoch 129. Loss: 0.013309806578896695, Train_acc 0.9971992924528302\n",
      "\n",
      "Epoch 129. Loss: 0.012235919962451387, Train_acc 0.997216796875\n",
      "\n",
      "Epoch 129. Loss: 0.011142901218887892, Train_acc 0.9972340838509317\n",
      "\n",
      "Epoch 129. Loss: 0.01011074117522543, Train_acc 0.9972511574074074\n",
      "\n",
      "Epoch 129. Loss: 0.009112549329833698, Train_acc 0.9972680214723927\n",
      "\n",
      "Epoch 129. Loss: 0.010835300017925958, Train_acc 0.9972370426829268\n",
      "\n",
      "Epoch 129. Loss: 0.009839648217290218, Train_acc 0.9972537878787879\n",
      "\n",
      "Epoch 129. Loss: 0.009902968389835573, Train_acc 0.9972703313253012\n",
      "\n",
      "Epoch 129. Loss: 0.00979949320454593, Train_acc 0.9972398952095808\n",
      "\n",
      "Epoch 129. Loss: 0.00887419534214053, Train_acc 0.9972563244047619\n",
      "\n",
      "Epoch 129. Loss: 0.008006729097228544, Train_acc 0.9972725591715976\n",
      "\n",
      "Epoch 129. Loss: 0.007333899244776783, Train_acc 0.9972886029411765\n",
      "\n",
      "Epoch 129. Loss: 0.006886503372254745, Train_acc 0.9973044590643275\n",
      "\n",
      "Epoch 129. Loss: 0.012431378683742382, Train_acc 0.9972747093023255\n",
      "\n",
      "Epoch 129. Loss: 0.013621813711193054, Train_acc 0.9972001445086706\n",
      "\n",
      "Epoch 129. Loss: 0.012547918935679062, Train_acc 0.9972162356321839\n",
      "\n",
      "Epoch 129. Loss: 0.012052191494833825, Train_acc 0.9971875\n",
      "\n",
      "Epoch 129. Loss: 0.010860656866022984, Train_acc 0.9972034801136364\n",
      "\n",
      "Epoch 129. Loss: 0.00992738683647055, Train_acc 0.997219279661017\n",
      "\n",
      "Epoch 129. Loss: 0.008991538737351942, Train_acc 0.9972349016853933\n",
      "\n",
      "Epoch 129. Loss: 0.008316650715628489, Train_acc 0.9972503491620112\n",
      "\n",
      "Epoch 129. Loss: 0.008673544356667302, Train_acc 0.9972222222222222\n",
      "\n",
      "Epoch 129. Loss: 0.008594636529931398, Train_acc 0.9971944060773481\n",
      "\n",
      "Epoch 129. Loss: 0.00891561129487959, Train_acc 0.9971668956043956\n",
      "\n",
      "Epoch 129. Loss: 0.008687152211046881, Train_acc 0.9971823770491803\n",
      "\n",
      "Epoch 129. Loss: 0.007866172848185153, Train_acc 0.9971976902173914\n",
      "\n",
      "Epoch 129. Loss: 0.00714192070646085, Train_acc 0.9972128378378379\n",
      "\n",
      "Epoch 129. Loss: 0.006558335870128849, Train_acc 0.9972278225806451\n",
      "\n",
      "Epoch 129. Loss: 0.006190422542986553, Train_acc 0.9972426470588235\n",
      "\n",
      "Epoch 129. Loss: 0.0056547152887781995, Train_acc 0.9972573138297872\n",
      "\n",
      "Epoch 129. Loss: 0.005846686547189999, Train_acc 0.9972304894179894\n",
      "\n",
      "Epoch 129. Loss: 0.0057665962165058095, Train_acc 0.9972450657894737\n",
      "\n",
      "Epoch 129. Loss: 0.00528670286718216, Train_acc 0.9972594895287958\n",
      "\n",
      "Epoch 129. Loss: 0.005103417818060873, Train_acc 0.9972737630208334\n",
      "\n",
      "Epoch 129. Loss: 0.006034798399488353, Train_acc 0.9972474093264249\n",
      "\n",
      "Epoch 129. Loss: 0.006156297118258676, Train_acc 0.9972615979381443\n",
      "\n",
      "Epoch 129. Loss: 0.005578907895517082, Train_acc 0.997275641025641\n",
      "\n",
      "Epoch 129. Loss: 0.005035506321356596, Train_acc 0.99728\n",
      "\n",
      "Epoch 130. Loss: 0.004557954464020455, Train_acc 1.0\n",
      "\n",
      "Epoch 130. Loss: 0.004133082410824149, Train_acc 1.0\n",
      "\n",
      "Epoch 130. Loss: 0.0038846904662312707, Train_acc 1.0\n",
      "\n",
      "Epoch 130. Loss: 0.0035038793096997937, Train_acc 1.0\n",
      "\n",
      "Epoch 130. Loss: 0.0032123289454873893, Train_acc 1.0\n",
      "\n",
      "Epoch 130. Loss: 0.0038414581186082806, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 130. Loss: 0.0034857580937767934, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 130. Loss: 0.0031565347775082955, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 130. Loss: 0.002870767054095932, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 130. Loss: 0.00421117095989144, Train_acc 0.9984375\n",
      "\n",
      "Epoch 130. Loss: 0.003886766334888245, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 130. Loss: 0.003688675529785668, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 130. Loss: 0.0033282720684682542, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 130. Loss: 0.003110810315151532, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 130. Loss: 0.0028088136230355024, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 130. Loss: 0.002569367081473367, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 130. Loss: 0.002392256266370502, Train_acc 0.9990808823529411\n",
      "\n",
      "Epoch 130. Loss: 0.0023147924186059125, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 130. Loss: 0.002457718309351947, Train_acc 0.9991776315789473\n",
      "\n",
      "Epoch 130. Loss: 0.002348384513822925, Train_acc 0.99921875\n",
      "\n",
      "Epoch 130. Loss: 0.0024413940535793293, Train_acc 0.9992559523809523\n",
      "\n",
      "Epoch 130. Loss: 0.002315856005320065, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 130. Loss: 0.002093782910282117, Train_acc 0.9993206521739131\n",
      "\n",
      "Epoch 130. Loss: 0.0019145168217660055, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 130. Loss: 0.001783315057031384, Train_acc 0.999375\n",
      "\n",
      "Epoch 130. Loss: 0.0016532645475987233, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 130. Loss: 0.0015211882965442437, Train_acc 0.9994212962962963\n",
      "\n",
      "Epoch 130. Loss: 0.0013958659951444552, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 130. Loss: 0.001302413571129911, Train_acc 0.9994612068965517\n",
      "\n",
      "Epoch 130. Loss: 0.0016280781301862058, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 130. Loss: 0.0014825155867227182, Train_acc 0.9994959677419355\n",
      "\n",
      "Epoch 130. Loss: 0.0013493532189065344, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 130. Loss: 0.0014591491900757666, Train_acc 0.9995265151515151\n",
      "\n",
      "Epoch 130. Loss: 0.0017368381484933837, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 130. Loss: 0.001576964099740574, Train_acc 0.9995535714285714\n",
      "\n",
      "Epoch 130. Loss: 0.0014499879964433291, Train_acc 0.9995659722222222\n",
      "\n",
      "Epoch 130. Loss: 0.002170549314907984, Train_acc 0.9995777027027027\n",
      "\n",
      "Epoch 130. Loss: 0.00195957134761766, Train_acc 0.9995888157894737\n",
      "\n",
      "Epoch 130. Loss: 0.0017675181795730832, Train_acc 0.9995993589743589\n",
      "\n",
      "Epoch 130. Loss: 0.0016033139688001626, Train_acc 0.999609375\n",
      "\n",
      "Epoch 130. Loss: 0.001450625919555313, Train_acc 0.9996189024390244\n",
      "\n",
      "Epoch 130. Loss: 0.0013203640019982114, Train_acc 0.9996279761904762\n",
      "\n",
      "Epoch 130. Loss: 0.0012391919530132312, Train_acc 0.9996366279069767\n",
      "\n",
      "Epoch 130. Loss: 0.0011577314686710893, Train_acc 0.9996448863636364\n",
      "\n",
      "Epoch 130. Loss: 0.0010533019966546305, Train_acc 0.9996527777777777\n",
      "\n",
      "Epoch 130. Loss: 0.00107508137952509, Train_acc 0.9996603260869565\n",
      "\n",
      "Epoch 130. Loss: 0.0010083355862970799, Train_acc 0.9996675531914894\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130. Loss: 0.0017288108193047927, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 130. Loss: 0.001566887725353368, Train_acc 0.9995216836734694\n",
      "\n",
      "Epoch 130. Loss: 0.002394715320134277, Train_acc 0.99953125\n",
      "\n",
      "Epoch 130. Loss: 0.00216284658902702, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 130. Loss: 0.001967854094580417, Train_acc 0.9995492788461539\n",
      "\n",
      "Epoch 130. Loss: 0.002603468783565407, Train_acc 0.9994103773584906\n",
      "\n",
      "Epoch 130. Loss: 0.002346361855665057, Train_acc 0.9994212962962963\n",
      "\n",
      "Epoch 130. Loss: 0.002123745592822545, Train_acc 0.9994318181818181\n",
      "\n",
      "Epoch 130. Loss: 0.001922462811827955, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 130. Loss: 0.0017387862444726149, Train_acc 0.9994517543859649\n",
      "\n",
      "Epoch 130. Loss: 0.0015657650122312976, Train_acc 0.9994612068965517\n",
      "\n",
      "Epoch 130. Loss: 0.001434025882901395, Train_acc 0.9994703389830508\n",
      "\n",
      "Epoch 130. Loss: 0.00153261105106471, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 130. Loss: 0.0013887339958758103, Train_acc 0.9994877049180327\n",
      "\n",
      "Epoch 130. Loss: 0.0012603484198898086, Train_acc 0.9994959677419355\n",
      "\n",
      "Epoch 130. Loss: 0.0011446030130593113, Train_acc 0.9995039682539683\n",
      "\n",
      "Epoch 130. Loss: 0.0016679900831527827, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 130. Loss: 0.001581544061534612, Train_acc 0.9995192307692308\n",
      "\n",
      "Epoch 130. Loss: 0.0014573814334177305, Train_acc 0.9995265151515151\n",
      "\n",
      "Epoch 130. Loss: 0.0019265400327029823, Train_acc 0.9994169776119403\n",
      "\n",
      "Epoch 130. Loss: 0.0018222056542068423, Train_acc 0.9994255514705882\n",
      "\n",
      "Epoch 130. Loss: 0.0016569968219297486, Train_acc 0.9994338768115942\n",
      "\n",
      "Epoch 130. Loss: 0.0014969539330283378, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 130. Loss: 0.0014476698281657317, Train_acc 0.999449823943662\n",
      "\n",
      "Epoch 130. Loss: 0.0013039773255730646, Train_acc 0.9994574652777778\n",
      "\n",
      "Epoch 130. Loss: 0.0012939443046356717, Train_acc 0.999464897260274\n",
      "\n",
      "Epoch 130. Loss: 0.0014058354366873636, Train_acc 0.9994721283783784\n",
      "\n",
      "Epoch 130. Loss: 0.0013083426460430714, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 130. Loss: 0.0012348390217044823, Train_acc 0.9994860197368421\n",
      "\n",
      "Epoch 130. Loss: 0.0011176909295646119, Train_acc 0.9994926948051948\n",
      "\n",
      "Epoch 130. Loss: 0.001016290713582249, Train_acc 0.9994991987179487\n",
      "\n",
      "Epoch 130. Loss: 0.000924548569224504, Train_acc 0.9995055379746836\n",
      "\n",
      "Epoch 130. Loss: 0.0008357011746515177, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 130. Loss: 0.0008375240647982218, Train_acc 0.9995177469135802\n",
      "\n",
      "Epoch 130. Loss: 0.0009012249580419653, Train_acc 0.9995236280487805\n",
      "\n",
      "Epoch 130. Loss: 0.002918063697641783, Train_acc 0.9994352409638554\n",
      "\n",
      "Epoch 130. Loss: 0.0026492312964668174, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 130. Loss: 0.00239092351404908, Train_acc 0.9994485294117647\n",
      "\n",
      "Epoch 130. Loss: 0.0027637957292772773, Train_acc 0.9994549418604651\n",
      "\n",
      "Epoch 130. Loss: 0.0024894744903797023, Train_acc 0.9994612068965517\n",
      "\n",
      "Epoch 130. Loss: 0.0053710337654609185, Train_acc 0.9993785511363636\n",
      "\n",
      "Epoch 130. Loss: 0.004835401226293119, Train_acc 0.9993855337078652\n",
      "\n",
      "Epoch 130. Loss: 0.007808955832610494, Train_acc 0.99921875\n",
      "\n",
      "Epoch 130. Loss: 0.007123476761689752, Train_acc 0.9992273351648352\n",
      "\n",
      "Epoch 130. Loss: 0.006425720402970007, Train_acc 0.9992357336956522\n",
      "\n",
      "Epoch 130. Loss: 0.006279764949715816, Train_acc 0.9992439516129032\n",
      "\n",
      "Epoch 130. Loss: 0.005659761019816357, Train_acc 0.999251994680851\n",
      "\n",
      "Epoch 130. Loss: 0.00510241262468234, Train_acc 0.9992598684210526\n",
      "\n",
      "Epoch 130. Loss: 0.005936568746887464, Train_acc 0.999267578125\n",
      "\n",
      "Epoch 130. Loss: 0.009656572285225528, Train_acc 0.9991140463917526\n",
      "\n",
      "Epoch 130. Loss: 0.008703641597147394, Train_acc 0.9991230867346939\n",
      "\n",
      "Epoch 130. Loss: 0.007915348912185973, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 130. Loss: 0.010332318265652549, Train_acc 0.998984375\n",
      "\n",
      "[Epoch 130 Batch 100] Loss: 0.0132260285640501 Training: accuracy=0.998840\n",
      "Epoch 130. Loss: 0.0132260285640501, Train_acc 0.9988397277227723\n",
      "\n",
      "Epoch 130. Loss: 0.01688336844665495, Train_acc 0.9987745098039216\n",
      "\n",
      "Epoch 130. Loss: 0.015207591805311664, Train_acc 0.9987864077669902\n",
      "\n",
      "Epoch 130. Loss: 0.01543168074201282, Train_acc 0.9987229567307693\n",
      "\n",
      "Epoch 130. Loss: 0.015465266001022484, Train_acc 0.9986607142857142\n",
      "\n",
      "Epoch 130. Loss: 0.0141192347576141, Train_acc 0.9986733490566038\n",
      "\n",
      "Epoch 130. Loss: 0.012826567673042681, Train_acc 0.9986857476635514\n",
      "\n",
      "Epoch 130. Loss: 0.011587106336509861, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 130. Loss: 0.010444591521757144, Train_acc 0.9987098623853211\n",
      "\n",
      "Epoch 130. Loss: 0.009954235215071409, Train_acc 0.998721590909091\n",
      "\n",
      "Epoch 130. Loss: 0.008977274683392818, Train_acc 0.9987331081081081\n",
      "\n",
      "Epoch 130. Loss: 0.009450562171438434, Train_acc 0.9986746651785714\n",
      "\n",
      "Epoch 130. Loss: 0.008538845180796586, Train_acc 0.9986863938053098\n",
      "\n",
      "Epoch 130. Loss: 0.007817141203539374, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 130. Loss: 0.01281171991389108, Train_acc 0.9985054347826087\n",
      "\n",
      "Epoch 130. Loss: 0.011646711065458766, Train_acc 0.9985183189655172\n",
      "\n",
      "Epoch 130. Loss: 0.010513751626456166, Train_acc 0.9985309829059829\n",
      "\n",
      "Epoch 130. Loss: 0.010736092332402813, Train_acc 0.9984772245762712\n",
      "\n",
      "Epoch 130. Loss: 0.009797747668124688, Train_acc 0.9984900210084033\n",
      "\n",
      "Epoch 130. Loss: 0.01243694527730118, Train_acc 0.9984375\n",
      "\n",
      "Epoch 130. Loss: 0.011385706557271814, Train_acc 0.9984504132231405\n",
      "\n",
      "Epoch 130. Loss: 0.011505436984543147, Train_acc 0.9983990778688525\n",
      "\n",
      "Epoch 130. Loss: 0.010421326795434931, Train_acc 0.998412093495935\n",
      "\n",
      "Epoch 130. Loss: 0.009413663039586824, Train_acc 0.9984248991935484\n",
      "\n",
      "Epoch 130. Loss: 0.00872911587393154, Train_acc 0.9984375\n",
      "\n",
      "Epoch 130. Loss: 0.0079634008070867, Train_acc 0.9984499007936508\n",
      "\n",
      "Epoch 130. Loss: 0.007182418171605013, Train_acc 0.9984621062992126\n",
      "\n",
      "Epoch 130. Loss: 0.007254221206045635, Train_acc 0.99847412109375\n",
      "\n",
      "Epoch 130. Loss: 0.006803651399473686, Train_acc 0.9984859496124031\n",
      "\n",
      "Epoch 130. Loss: 0.006230199972333317, Train_acc 0.9984975961538461\n",
      "\n",
      "Epoch 130. Loss: 0.005628425420632244, Train_acc 0.9985090648854962\n",
      "\n",
      "Epoch 130. Loss: 0.005152103589761881, Train_acc 0.9985203598484849\n",
      "\n",
      "Epoch 130. Loss: 0.005316074048464264, Train_acc 0.9985314849624061\n",
      "\n",
      "Epoch 130. Loss: 0.005308616245896905, Train_acc 0.9985424440298507\n",
      "\n",
      "Epoch 130. Loss: 0.0048374462341487755, Train_acc 0.9985532407407407\n",
      "\n",
      "Epoch 130. Loss: 0.004371596584013806, Train_acc 0.9985638786764706\n",
      "\n",
      "Epoch 130. Loss: 0.004047933319509065, Train_acc 0.9985743613138686\n",
      "\n",
      "Epoch 130. Loss: 0.003678759961927342, Train_acc 0.9985846920289855\n",
      "\n",
      "Epoch 130. Loss: 0.003770056914929516, Train_acc 0.9985948741007195\n",
      "\n",
      "Epoch 130. Loss: 0.0038311812184548084, Train_acc 0.9986049107142857\n",
      "\n",
      "Epoch 130. Loss: 0.0035213057730536794, Train_acc 0.998614804964539\n",
      "\n",
      "Epoch 130. Loss: 0.0032094841202565923, Train_acc 0.9986245598591549\n",
      "\n",
      "Epoch 130. Loss: 0.0029679728032043335, Train_acc 0.9986341783216783\n",
      "\n",
      "Epoch 130. Loss: 0.003567069748570689, Train_acc 0.9985894097222222\n",
      "\n",
      "Epoch 130. Loss: 0.003325470541928859, Train_acc 0.9985991379310345\n",
      "\n",
      "Epoch 130. Loss: 0.003104652906594859, Train_acc 0.9986087328767124\n",
      "\n",
      "Epoch 130. Loss: 0.0028187600440184204, Train_acc 0.9986181972789115\n",
      "\n",
      "Epoch 130. Loss: 0.0025555748615059006, Train_acc 0.9986275337837838\n",
      "\n",
      "Epoch 130. Loss: 0.002307409397590164, Train_acc 0.998636744966443\n",
      "\n",
      "Epoch 130. Loss: 0.0023515452190813455, Train_acc 0.9986458333333333\n",
      "\n",
      "Epoch 130. Loss: 0.002274701215773258, Train_acc 0.9986548013245033\n",
      "\n",
      "Epoch 130. Loss: 0.0020501685090612326, Train_acc 0.9986636513157895\n",
      "\n",
      "Epoch 130. Loss: 0.0018584739598297435, Train_acc 0.998672385620915\n",
      "\n",
      "Epoch 130. Loss: 0.001711839583619202, Train_acc 0.9986810064935064\n",
      "\n",
      "Epoch 130. Loss: 0.001574461811077422, Train_acc 0.9986895161290322\n",
      "\n",
      "Epoch 130. Loss: 0.0014300950630895355, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 130. Loss: 0.004668778919970279, Train_acc 0.9986066878980892\n",
      "\n",
      "Epoch 130. Loss: 0.004249584729241649, Train_acc 0.9986155063291139\n",
      "\n",
      "Epoch 130. Loss: 0.0038503699651468793, Train_acc 0.998624213836478\n",
      "\n",
      "Epoch 130. Loss: 0.004598396590451211, Train_acc 0.998583984375\n",
      "\n",
      "Epoch 130. Loss: 0.00416676210251713, Train_acc 0.9985927795031055\n",
      "\n",
      "Epoch 130. Loss: 0.003794217456474655, Train_acc 0.9986014660493827\n",
      "\n",
      "Epoch 130. Loss: 0.0035949619720978317, Train_acc 0.99861004601227\n",
      "\n",
      "Epoch 130. Loss: 0.0032492871432265886, Train_acc 0.9986185213414634\n",
      "\n",
      "Epoch 130. Loss: 0.0029377386850361524, Train_acc 0.998626893939394\n",
      "\n",
      "Epoch 130. Loss: 0.002671910593933865, Train_acc 0.9986351656626506\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130. Loss: 0.005519489142322843, Train_acc 0.9985965568862275\n",
      "\n",
      "Epoch 130. Loss: 0.004988861417796773, Train_acc 0.9986049107142857\n",
      "\n",
      "Epoch 130. Loss: 0.005219569422849919, Train_acc 0.9985669378698225\n",
      "\n",
      "Epoch 130. Loss: 0.004803669073923445, Train_acc 0.9985753676470588\n",
      "\n",
      "Epoch 130. Loss: 0.004395220956294104, Train_acc 0.9985836988304093\n",
      "\n",
      "Epoch 130. Loss: 0.00406830815816748, Train_acc 0.9985919331395349\n",
      "\n",
      "Epoch 130. Loss: 0.003738485943861629, Train_acc 0.9986000722543352\n",
      "\n",
      "Epoch 130. Loss: 0.0033897301074809513, Train_acc 0.9986081178160919\n",
      "\n",
      "Epoch 130. Loss: 0.0030658132503758014, Train_acc 0.9986160714285715\n",
      "\n",
      "Epoch 130. Loss: 0.002779286404293211, Train_acc 0.9986239346590909\n",
      "\n",
      "Epoch 130. Loss: 0.002509060711050662, Train_acc 0.998631709039548\n",
      "\n",
      "Epoch 130. Loss: 0.002262735380951662, Train_acc 0.9986393960674157\n",
      "\n",
      "Epoch 130. Loss: 0.0020873222301296284, Train_acc 0.9986469972067039\n",
      "\n",
      "Epoch 130. Loss: 0.0019120066527180575, Train_acc 0.9986545138888889\n",
      "\n",
      "Epoch 130. Loss: 0.0017555205707537565, Train_acc 0.9986619475138122\n",
      "\n",
      "Epoch 130. Loss: 0.0015985363529665336, Train_acc 0.9986692994505495\n",
      "\n",
      "Epoch 130. Loss: 0.0038676921328791736, Train_acc 0.9986338797814208\n",
      "\n",
      "Epoch 130. Loss: 0.003537710686107465, Train_acc 0.998641304347826\n",
      "\n",
      "Epoch 130. Loss: 0.0032310092075697973, Train_acc 0.9986486486486487\n",
      "\n",
      "Epoch 130. Loss: 0.0029397290238711146, Train_acc 0.9986559139784946\n",
      "\n",
      "Epoch 130. Loss: 0.0027357897988906123, Train_acc 0.9986631016042781\n",
      "\n",
      "Epoch 130. Loss: 0.0024927324192759205, Train_acc 0.9986702127659575\n",
      "\n",
      "Epoch 130. Loss: 0.0037789662826392184, Train_acc 0.9985945767195767\n",
      "\n",
      "Epoch 130. Loss: 0.0034297461911244136, Train_acc 0.9986019736842106\n",
      "\n",
      "Epoch 130. Loss: 0.0031288862407705584, Train_acc 0.9986092931937173\n",
      "\n",
      "Epoch 130. Loss: 0.002828983988860281, Train_acc 0.9986165364583334\n",
      "\n",
      "Epoch 130. Loss: 0.0031289258370539833, Train_acc 0.9986237046632125\n",
      "\n",
      "Epoch 130. Loss: 0.0030351184139914473, Train_acc 0.9986307989690721\n",
      "\n",
      "Epoch 130. Loss: 0.0027822275692183968, Train_acc 0.9986378205128205\n",
      "\n",
      "Epoch 130. Loss: 0.0025280751745659696, Train_acc 0.99864\n",
      "\n",
      "Epoch 131. Loss: 0.0023112568688651775, Train_acc 1.0\n",
      "\n",
      "Epoch 131. Loss: 0.003008951944761949, Train_acc 0.99609375\n",
      "\n",
      "Epoch 131. Loss: 0.002737371519484872, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 131. Loss: 0.0025201793731819875, Train_acc 0.998046875\n",
      "\n",
      "Epoch 131. Loss: 0.002285455407768808, Train_acc 0.9984375\n",
      "\n",
      "Epoch 131. Loss: 0.002117279884300669, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 131. Loss: 0.0030224422629911065, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 131. Loss: 0.002873879707473221, Train_acc 0.998046875\n",
      "\n",
      "Epoch 131. Loss: 0.0026048662276267954, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 131. Loss: 0.0023656307954925066, Train_acc 0.9984375\n",
      "\n",
      "Epoch 131. Loss: 0.002140588782278519, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 131. Loss: 0.001930177412907042, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 131. Loss: 0.0017562847939604593, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 131. Loss: 0.0015868481064727634, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 131. Loss: 0.001929548580413228, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 131. Loss: 0.0017793926512883595, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 131. Loss: 0.0016115632193974714, Train_acc 0.9990808823529411\n",
      "\n",
      "Epoch 131. Loss: 0.0017312925752424055, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 131. Loss: 0.001569398723409133, Train_acc 0.9991776315789473\n",
      "\n",
      "Epoch 131. Loss: 0.001416077925846036, Train_acc 0.99921875\n",
      "\n",
      "Epoch 131. Loss: 0.0012869316527705206, Train_acc 0.9992559523809523\n",
      "\n",
      "Epoch 131. Loss: 0.0011829294642091153, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 131. Loss: 0.0010807762565155647, Train_acc 0.9993206521739131\n",
      "\n",
      "Epoch 131. Loss: 0.0009982731154712131, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 131. Loss: 0.0012485935923369608, Train_acc 0.999375\n",
      "\n",
      "Epoch 131. Loss: 0.0012367978413994802, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 131. Loss: 0.0011638414702650035, Train_acc 0.9994212962962963\n",
      "\n",
      "Epoch 131. Loss: 0.001053729400973551, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 131. Loss: 0.0009589681460146246, Train_acc 0.9994612068965517\n",
      "\n",
      "Epoch 131. Loss: 0.0012789453711674337, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 131. Loss: 0.0011610344003202017, Train_acc 0.9994959677419355\n",
      "\n",
      "Epoch 131. Loss: 0.0010839489814861711, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 131. Loss: 0.0011043006632044103, Train_acc 0.9995265151515151\n",
      "\n",
      "Epoch 131. Loss: 0.0009991362572496635, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 131. Loss: 0.0009046504238728976, Train_acc 0.9995535714285714\n",
      "\n",
      "Epoch 131. Loss: 0.0008469499965109793, Train_acc 0.9995659722222222\n",
      "\n",
      "Epoch 131. Loss: 0.000805164054670784, Train_acc 0.9995777027027027\n",
      "\n",
      "Epoch 131. Loss: 0.000973443932471144, Train_acc 0.9995888157894737\n",
      "\n",
      "Epoch 131. Loss: 0.0009240594969615052, Train_acc 0.9995993589743589\n",
      "\n",
      "Epoch 131. Loss: 0.0008358461534038858, Train_acc 0.999609375\n",
      "\n",
      "Epoch 131. Loss: 0.0007667984240738163, Train_acc 0.9996189024390244\n",
      "\n",
      "Epoch 131. Loss: 0.0007219544963723146, Train_acc 0.9996279761904762\n",
      "\n",
      "Epoch 131. Loss: 0.0030007212087529056, Train_acc 0.9994549418604651\n",
      "\n",
      "Epoch 131. Loss: 0.0032239156100914317, Train_acc 0.9994673295454546\n",
      "\n",
      "Epoch 131. Loss: 0.002928904586440401, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 131. Loss: 0.0026949827549232483, Train_acc 0.9994904891304348\n",
      "\n",
      "Epoch 131. Loss: 0.0024319468816652434, Train_acc 0.999501329787234\n",
      "\n",
      "Epoch 131. Loss: 0.002426700640964616, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 131. Loss: 0.002331820642834701, Train_acc 0.9995216836734694\n",
      "\n",
      "Epoch 131. Loss: 0.0021041892596407475, Train_acc 0.99953125\n",
      "\n",
      "Epoch 131. Loss: 0.0018955401072296236, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 131. Loss: 0.001708062984956326, Train_acc 0.9995492788461539\n",
      "\n",
      "Epoch 131. Loss: 0.0015577002865392723, Train_acc 0.9995577830188679\n",
      "\n",
      "Epoch 131. Loss: 0.0014675056291488938, Train_acc 0.9995659722222222\n",
      "\n",
      "Epoch 131. Loss: 0.0013330416338870681, Train_acc 0.9995738636363637\n",
      "\n",
      "Epoch 131. Loss: 0.0013284171464797638, Train_acc 0.9995814732142857\n",
      "\n",
      "Epoch 131. Loss: 0.004214886897154759, Train_acc 0.9994517543859649\n",
      "\n",
      "Epoch 131. Loss: 0.004957560832066634, Train_acc 0.9993265086206896\n",
      "\n",
      "Epoch 131. Loss: 0.0044789638754425265, Train_acc 0.9993379237288136\n",
      "\n",
      "Epoch 131. Loss: 0.0040341517466858405, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 131. Loss: 0.003635421645889935, Train_acc 0.999359631147541\n",
      "\n",
      "Epoch 131. Loss: 0.0033049421835786167, Train_acc 0.9993699596774194\n",
      "\n",
      "Epoch 131. Loss: 0.0029797387083589305, Train_acc 0.9993799603174603\n",
      "\n",
      "Epoch 131. Loss: 0.0026949854707867373, Train_acc 0.9993896484375\n",
      "\n",
      "Epoch 131. Loss: 0.003220507366164071, Train_acc 0.9992788461538461\n",
      "\n",
      "Epoch 131. Loss: 0.002918841141574458, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 131. Loss: 0.004542287467222997, Train_acc 0.9991837686567164\n",
      "\n",
      "Epoch 131. Loss: 0.006155390503974189, Train_acc 0.9990808823529411\n",
      "\n",
      "Epoch 131. Loss: 0.005544122641512726, Train_acc 0.9990942028985508\n",
      "\n",
      "Epoch 131. Loss: 0.0052919724460875756, Train_acc 0.9991071428571429\n",
      "\n",
      "Epoch 131. Loss: 0.004788323932106452, Train_acc 0.9991197183098591\n",
      "\n",
      "Epoch 131. Loss: 0.004330850834247238, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 131. Loss: 0.003948572889727444, Train_acc 0.9991438356164384\n",
      "\n",
      "Epoch 131. Loss: 0.0038101060279939385, Train_acc 0.9991554054054054\n",
      "\n",
      "Epoch 131. Loss: 0.0050128347953021955, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 131. Loss: 0.007271507697987, Train_acc 0.9988692434210527\n",
      "\n",
      "Epoch 131. Loss: 0.007547756140101647, Train_acc 0.9987824675324676\n",
      "\n",
      "Epoch 131. Loss: 0.006794876866018526, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 131. Loss: 0.006134077325208786, Train_acc 0.9988132911392406\n",
      "\n",
      "Epoch 131. Loss: 0.005665909092085483, Train_acc 0.998828125\n",
      "\n",
      "Epoch 131. Loss: 0.005123178416945641, Train_acc 0.9988425925925926\n",
      "\n",
      "Epoch 131. Loss: 0.004949096375405584, Train_acc 0.9988567073170732\n",
      "\n",
      "Epoch 131. Loss: 0.004623574872828836, Train_acc 0.9988704819277109\n",
      "\n",
      "Epoch 131. Loss: 0.004163818938024107, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 131. Loss: 0.004091960622172592, Train_acc 0.9988970588235294\n",
      "\n",
      "Epoch 131. Loss: 0.0037428530733743643, Train_acc 0.9989098837209303\n",
      "\n",
      "Epoch 131. Loss: 0.0043369527881705165, Train_acc 0.9988326149425287\n",
      "\n",
      "Epoch 131. Loss: 0.004251323256301588, Train_acc 0.9988458806818182\n",
      "\n",
      "Epoch 131. Loss: 0.003854205876236221, Train_acc 0.9988588483146067\n",
      "\n",
      "Epoch 131. Loss: 0.0036443633659363336, Train_acc 0.9988715277777778\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131. Loss: 0.004105276177705576, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 131. Loss: 0.0039017431512158363, Train_acc 0.9988111413043478\n",
      "\n",
      "Epoch 131. Loss: 0.00552400399667155, Train_acc 0.9987399193548387\n",
      "\n",
      "Epoch 131. Loss: 0.0049800818702345345, Train_acc 0.9987533244680851\n",
      "\n",
      "Epoch 131. Loss: 0.006834739234217875, Train_acc 0.9986842105263158\n",
      "\n",
      "Epoch 131. Loss: 0.006175744824900402, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 131. Loss: 0.0056105155954718645, Train_acc 0.9987113402061856\n",
      "\n",
      "Epoch 131. Loss: 0.005116405255772328, Train_acc 0.9987244897959183\n",
      "\n",
      "Epoch 131. Loss: 0.006336314306119969, Train_acc 0.9986584595959596\n",
      "\n",
      "Epoch 131. Loss: 0.005744438941419586, Train_acc 0.998671875\n",
      "\n",
      "[Epoch 131 Batch 100] Loss: 0.00532534669585046 Training: accuracy=0.998685\n",
      "Epoch 131. Loss: 0.00532534669585046, Train_acc 0.9986850247524752\n",
      "\n",
      "Epoch 131. Loss: 0.004821316390574315, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 131. Loss: 0.004382528833012773, Train_acc 0.9987105582524272\n",
      "\n",
      "Epoch 131. Loss: 0.004272715074571365, Train_acc 0.9987229567307693\n",
      "\n",
      "Epoch 131. Loss: 0.007307340195255632, Train_acc 0.9986607142857142\n",
      "\n",
      "Epoch 131. Loss: 0.006761922883668978, Train_acc 0.9986733490566038\n",
      "\n",
      "Epoch 131. Loss: 0.006513910479631519, Train_acc 0.9986857476635514\n",
      "\n",
      "Epoch 131. Loss: 0.006439077302622642, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 131. Loss: 0.0074526510639260826, Train_acc 0.9986381880733946\n",
      "\n",
      "Epoch 131. Loss: 0.00758887597575223, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 131. Loss: 0.006960450733623078, Train_acc 0.9985923423423423\n",
      "\n",
      "Epoch 131. Loss: 0.0067554003185819125, Train_acc 0.9986049107142857\n",
      "\n",
      "Epoch 131. Loss: 0.006557173304196346, Train_acc 0.9986172566371682\n",
      "\n",
      "Epoch 131. Loss: 0.005990916503629371, Train_acc 0.9986293859649122\n",
      "\n",
      "Epoch 131. Loss: 0.00550564076065536, Train_acc 0.998641304347826\n",
      "\n",
      "Epoch 131. Loss: 0.005728498545821152, Train_acc 0.9985856681034483\n",
      "\n",
      "Epoch 131. Loss: 0.006819240403952278, Train_acc 0.9984642094017094\n",
      "\n",
      "Epoch 131. Loss: 0.006770031029983232, Train_acc 0.9984110169491526\n",
      "\n",
      "Epoch 131. Loss: 0.007502683643255117, Train_acc 0.998358718487395\n",
      "\n",
      "Epoch 131. Loss: 0.006761257402427349, Train_acc 0.9983723958333334\n",
      "\n",
      "Epoch 131. Loss: 0.006202419831170011, Train_acc 0.998385847107438\n",
      "\n",
      "Epoch 131. Loss: 0.006295738252308997, Train_acc 0.9983350409836066\n",
      "\n",
      "Epoch 131. Loss: 0.006357424451983302, Train_acc 0.9983485772357723\n",
      "\n",
      "Epoch 131. Loss: 0.005862835433160212, Train_acc 0.9983618951612904\n",
      "\n",
      "Epoch 131. Loss: 0.005300941448374137, Train_acc 0.998375\n",
      "\n",
      "Epoch 131. Loss: 0.005607550484803508, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 131. Loss: 0.005063757157444492, Train_acc 0.9983390748031497\n",
      "\n",
      "Epoch 131. Loss: 0.004717336117173316, Train_acc 0.99835205078125\n",
      "\n",
      "Epoch 131. Loss: 0.005341669989924206, Train_acc 0.9983042635658915\n",
      "\n",
      "Epoch 131. Loss: 0.004826947373564868, Train_acc 0.9983173076923076\n",
      "\n",
      "Epoch 131. Loss: 0.004518224985356626, Train_acc 0.9983301526717557\n",
      "\n",
      "Epoch 131. Loss: 0.004098645497176123, Train_acc 0.998342803030303\n",
      "\n",
      "Epoch 131. Loss: 0.004671763426494365, Train_acc 0.998296522556391\n",
      "\n",
      "Epoch 131. Loss: 0.004216290873486544, Train_acc 0.9983092350746269\n",
      "\n",
      "Epoch 131. Loss: 0.0038734973747849423, Train_acc 0.9983217592592593\n",
      "\n",
      "Epoch 131. Loss: 0.0035172533776515313, Train_acc 0.9983340992647058\n",
      "\n",
      "Epoch 131. Loss: 0.0035996902282077305, Train_acc 0.9983462591240876\n",
      "\n",
      "Epoch 131. Loss: 0.0036427327490632148, Train_acc 0.9983582427536232\n",
      "\n",
      "Epoch 131. Loss: 0.0033029440668796224, Train_acc 0.9983700539568345\n",
      "\n",
      "Epoch 131. Loss: 0.002997006539485579, Train_acc 0.9983816964285714\n",
      "\n",
      "Epoch 131. Loss: 0.004195792080296628, Train_acc 0.9983377659574468\n",
      "\n",
      "Epoch 131. Loss: 0.0037820948990110407, Train_acc 0.9983494718309859\n",
      "\n",
      "Epoch 131. Loss: 0.0034891500164425833, Train_acc 0.998361013986014\n",
      "\n",
      "Epoch 131. Loss: 0.0031543486176088646, Train_acc 0.9983723958333334\n",
      "\n",
      "Epoch 131. Loss: 0.0033553337532867666, Train_acc 0.9983836206896551\n",
      "\n",
      "Epoch 131. Loss: 0.003037054364110445, Train_acc 0.998394691780822\n",
      "\n",
      "Epoch 131. Loss: 0.0031970553689230218, Train_acc 0.998405612244898\n",
      "\n",
      "Epoch 131. Loss: 0.0028849841480196995, Train_acc 0.9984163851351351\n",
      "\n",
      "Epoch 131. Loss: 0.002610030513303524, Train_acc 0.9984270134228188\n",
      "\n",
      "Epoch 131. Loss: 0.0023830511436286977, Train_acc 0.9984375\n",
      "\n",
      "Epoch 131. Loss: 0.0036675422577938507, Train_acc 0.9983961092715232\n",
      "\n",
      "Epoch 131. Loss: 0.0033023721382267144, Train_acc 0.9984066611842105\n",
      "\n",
      "Epoch 131. Loss: 0.0029920031752238975, Train_acc 0.9984170751633987\n",
      "\n",
      "Epoch 131. Loss: 0.0026965629663675363, Train_acc 0.9984273538961039\n",
      "\n",
      "Epoch 131. Loss: 0.002448596236805428, Train_acc 0.9984375\n",
      "\n",
      "Epoch 131. Loss: 0.0023894601693305157, Train_acc 0.9984475160256411\n",
      "\n",
      "Epoch 131. Loss: 0.002181055025228362, Train_acc 0.9984574044585988\n",
      "\n",
      "Epoch 131. Loss: 0.00196907257427672, Train_acc 0.998467167721519\n",
      "\n",
      "Epoch 131. Loss: 0.0017868314893502136, Train_acc 0.9984768081761006\n",
      "\n",
      "Epoch 131. Loss: 0.0016414127613417632, Train_acc 0.998486328125\n",
      "\n",
      "Epoch 131. Loss: 0.0015105497071705603, Train_acc 0.9984957298136646\n",
      "\n",
      "Epoch 131. Loss: 0.001477117704262943, Train_acc 0.9985050154320988\n",
      "\n",
      "Epoch 131. Loss: 0.001529356373692105, Train_acc 0.9985141871165644\n",
      "\n",
      "Epoch 131. Loss: 0.0014168577264163343, Train_acc 0.9985232469512195\n",
      "\n",
      "Epoch 131. Loss: 0.0013501723851633177, Train_acc 0.998532196969697\n",
      "\n",
      "Epoch 131. Loss: 0.0017360110335086678, Train_acc 0.9985410391566265\n",
      "\n",
      "Epoch 131. Loss: 0.0016026662785963621, Train_acc 0.9985497754491018\n",
      "\n",
      "Epoch 131. Loss: 0.0014576925203846909, Train_acc 0.9985584077380952\n",
      "\n",
      "Epoch 131. Loss: 0.0014413344516438558, Train_acc 0.9985669378698225\n",
      "\n",
      "Epoch 131. Loss: 0.0013022001692542362, Train_acc 0.9985753676470588\n",
      "\n",
      "Epoch 131. Loss: 0.0011808245488357143, Train_acc 0.9985836988304093\n",
      "\n",
      "Epoch 131. Loss: 0.0010651236618536089, Train_acc 0.9985919331395349\n",
      "\n",
      "Epoch 131. Loss: 0.0009659067164690493, Train_acc 0.9986000722543352\n",
      "\n",
      "Epoch 131. Loss: 0.0010158168925901829, Train_acc 0.9986081178160919\n",
      "\n",
      "Epoch 131. Loss: 0.0010409775886589807, Train_acc 0.9986160714285715\n",
      "\n",
      "Epoch 131. Loss: 0.0009431453387935964, Train_acc 0.9986239346590909\n",
      "\n",
      "Epoch 131. Loss: 0.0009341205928809948, Train_acc 0.998631709039548\n",
      "\n",
      "Epoch 131. Loss: 0.0008762540778260685, Train_acc 0.9986393960674157\n",
      "\n",
      "Epoch 131. Loss: 0.0007915785766365921, Train_acc 0.9986469972067039\n",
      "\n",
      "Epoch 131. Loss: 0.0009394091062670466, Train_acc 0.9986545138888889\n",
      "\n",
      "Epoch 131. Loss: 0.002764943765961425, Train_acc 0.9986187845303868\n",
      "\n",
      "Epoch 131. Loss: 0.0025026964332384664, Train_acc 0.9986263736263736\n",
      "\n",
      "Epoch 131. Loss: 0.0022719938786624825, Train_acc 0.9986338797814208\n",
      "\n",
      "Epoch 131. Loss: 0.0020557435177058912, Train_acc 0.998641304347826\n",
      "\n",
      "Epoch 131. Loss: 0.0018761128646460643, Train_acc 0.9986486486486487\n",
      "\n",
      "Epoch 131. Loss: 0.0017339395813256847, Train_acc 0.9986559139784946\n",
      "\n",
      "Epoch 131. Loss: 0.0017116594164470148, Train_acc 0.9986631016042781\n",
      "\n",
      "Epoch 131. Loss: 0.0015445304583938178, Train_acc 0.9986702127659575\n",
      "\n",
      "Epoch 131. Loss: 0.001511539676187002, Train_acc 0.9986772486772487\n",
      "\n",
      "Epoch 131. Loss: 0.0013946528495863645, Train_acc 0.9986842105263158\n",
      "\n",
      "Epoch 131. Loss: 0.001650492460565171, Train_acc 0.9986910994764397\n",
      "\n",
      "Epoch 131. Loss: 0.001512188022346185, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 131. Loss: 0.0013812684011626532, Train_acc 0.9987046632124352\n",
      "\n",
      "Epoch 131. Loss: 0.0012484478823736132, Train_acc 0.9987113402061856\n",
      "\n",
      "Epoch 131. Loss: 0.0011877571332733173, Train_acc 0.9987179487179487\n",
      "\n",
      "Epoch 131. Loss: 0.0010730781289631619, Train_acc 0.99872\n",
      "\n",
      "Epoch 132. Loss: 0.0009729592808766024, Train_acc 1.0\n",
      "\n",
      "Epoch 132. Loss: 0.0009193809994110411, Train_acc 1.0\n",
      "\n",
      "Epoch 132. Loss: 0.0010262218985079778, Train_acc 1.0\n",
      "\n",
      "Epoch 132. Loss: 0.0014812219290243733, Train_acc 1.0\n",
      "\n",
      "Epoch 132. Loss: 0.0013367537504120135, Train_acc 1.0\n",
      "\n",
      "Epoch 132. Loss: 0.0016354914933309076, Train_acc 1.0\n",
      "\n",
      "Epoch 132. Loss: 0.0015273397448631483, Train_acc 1.0\n",
      "\n",
      "Epoch 132. Loss: 0.0014164436704389252, Train_acc 1.0\n",
      "\n",
      "Epoch 132. Loss: 0.0014088152947475312, Train_acc 1.0\n",
      "\n",
      "Epoch 132. Loss: 0.0018769364932879626, Train_acc 0.99921875\n",
      "\n",
      "Epoch 132. Loss: 0.0017144420841491432, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 132. Loss: 0.0015449351463789319, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 132. Loss: 0.0016037572490341582, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 132. Loss: 0.0018885230277181076, Train_acc 0.9994419642857143\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132. Loss: 0.0017051707308100203, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 132. Loss: 0.0016117842217518276, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 132. Loss: 0.0015332140420958448, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 132. Loss: 0.0013880560556921778, Train_acc 0.9995659722222222\n",
      "\n",
      "Epoch 132. Loss: 0.001259021217915321, Train_acc 0.9995888157894737\n",
      "\n",
      "Epoch 132. Loss: 0.0011421051555254387, Train_acc 0.999609375\n",
      "\n",
      "Epoch 132. Loss: 0.001041642393082678, Train_acc 0.9996279761904762\n",
      "\n",
      "Epoch 132. Loss: 0.0009890515616106685, Train_acc 0.9996448863636364\n",
      "\n",
      "Epoch 132. Loss: 0.0008912767403806781, Train_acc 0.9996603260869565\n",
      "\n",
      "Epoch 132. Loss: 0.0008028609239803355, Train_acc 0.9996744791666666\n",
      "\n",
      "Epoch 132. Loss: 0.0007260614828401466, Train_acc 0.9996875\n",
      "\n",
      "Epoch 132. Loss: 0.0006702314183500888, Train_acc 0.9996995192307693\n",
      "\n",
      "Epoch 132. Loss: 0.0010281370534349218, Train_acc 0.9997106481481481\n",
      "\n",
      "Epoch 132. Loss: 0.0009274583006837439, Train_acc 0.9997209821428571\n",
      "\n",
      "Epoch 132. Loss: 0.0008357447581977172, Train_acc 0.9997306034482759\n",
      "\n",
      "Epoch 132. Loss: 0.0007581180215694152, Train_acc 0.9997395833333333\n",
      "\n",
      "Epoch 132. Loss: 0.0006882745928559394, Train_acc 0.9997479838709677\n",
      "\n",
      "Epoch 132. Loss: 0.000620019864484773, Train_acc 0.999755859375\n",
      "\n",
      "Epoch 132. Loss: 0.000580040133907275, Train_acc 0.9997632575757576\n",
      "\n",
      "Epoch 132. Loss: 0.000527772066768209, Train_acc 0.9997702205882353\n",
      "\n",
      "Epoch 132. Loss: 0.0005132623546199426, Train_acc 0.9997767857142857\n",
      "\n",
      "Epoch 132. Loss: 0.0015446198463031433, Train_acc 0.9995659722222222\n",
      "\n",
      "Epoch 132. Loss: 0.001392171346518349, Train_acc 0.9995777027027027\n",
      "\n",
      "Epoch 132. Loss: 0.0015051535711046618, Train_acc 0.9995888157894737\n",
      "\n",
      "Epoch 132. Loss: 0.0013851286324246133, Train_acc 0.9995993589743589\n",
      "\n",
      "Epoch 132. Loss: 0.0012488221252940077, Train_acc 0.999609375\n",
      "\n",
      "Epoch 132. Loss: 0.001171908374641342, Train_acc 0.9996189024390244\n",
      "\n",
      "Epoch 132. Loss: 0.0021731203721588876, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 132. Loss: 0.001973477532347756, Train_acc 0.9994549418604651\n",
      "\n",
      "Epoch 132. Loss: 0.001801054852488906, Train_acc 0.9994673295454546\n",
      "\n",
      "Epoch 132. Loss: 0.001660688907319624, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 132. Loss: 0.0015597457511329522, Train_acc 0.9994904891304348\n",
      "\n",
      "Epoch 132. Loss: 0.0014230046781180162, Train_acc 0.999501329787234\n",
      "\n",
      "Epoch 132. Loss: 0.0013311619984718733, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 132. Loss: 0.0012412499023376098, Train_acc 0.9995216836734694\n",
      "\n",
      "Epoch 132. Loss: 0.001129423198414246, Train_acc 0.99953125\n",
      "\n",
      "Epoch 132. Loss: 0.0010951964139192401, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 132. Loss: 0.0009911423391008643, Train_acc 0.9995492788461539\n",
      "\n",
      "Epoch 132. Loss: 0.0009014792299788071, Train_acc 0.9995577830188679\n",
      "\n",
      "Epoch 132. Loss: 0.0020530731020737478, Train_acc 0.9994212962962963\n",
      "\n",
      "Epoch 132. Loss: 0.001955974741544019, Train_acc 0.9994318181818181\n",
      "\n",
      "Epoch 132. Loss: 0.0017748445370374837, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 132. Loss: 0.0016019560627416308, Train_acc 0.9994517543859649\n",
      "\n",
      "Epoch 132. Loss: 0.0014428996235015933, Train_acc 0.9994612068965517\n",
      "\n",
      "Epoch 132. Loss: 0.0013009073758241839, Train_acc 0.9994703389830508\n",
      "\n",
      "Epoch 132. Loss: 0.001171460572814274, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 132. Loss: 0.002636948964537974, Train_acc 0.9992315573770492\n",
      "\n",
      "Epoch 132. Loss: 0.0023762232108540476, Train_acc 0.9992439516129032\n",
      "\n",
      "Epoch 132. Loss: 0.002147702598333783, Train_acc 0.9992559523809523\n",
      "\n",
      "Epoch 132. Loss: 0.0034575687673036107, Train_acc 0.9991455078125\n",
      "\n",
      "Epoch 132. Loss: 0.00312416198170186, Train_acc 0.9991586538461539\n",
      "\n",
      "Epoch 132. Loss: 0.0028210966310718644, Train_acc 0.9991714015151515\n",
      "\n",
      "Epoch 132. Loss: 0.0025422893705116566, Train_acc 0.9991837686567164\n",
      "\n",
      "Epoch 132. Loss: 0.008641942388607281, Train_acc 0.9988511029411765\n",
      "\n",
      "Epoch 132. Loss: 0.00778513279707077, Train_acc 0.9988677536231884\n",
      "\n",
      "Epoch 132. Loss: 0.0070076655844274185, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 132. Loss: 0.006439670258150073, Train_acc 0.998899647887324\n",
      "\n",
      "Epoch 132. Loss: 0.005944325621286547, Train_acc 0.9989149305555556\n",
      "\n",
      "Epoch 132. Loss: 0.00912906409385161, Train_acc 0.9988227739726028\n",
      "\n",
      "Epoch 132. Loss: 0.011093788350364772, Train_acc 0.9987331081081081\n",
      "\n",
      "Epoch 132. Loss: 0.009992672358367415, Train_acc 0.99875\n",
      "\n",
      "Epoch 132. Loss: 0.009020350979629001, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 132. Loss: 0.008531256674405492, Train_acc 0.9987824675324676\n",
      "\n",
      "Epoch 132. Loss: 0.008077426154473327, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 132. Loss: 0.007317002630416813, Train_acc 0.9988132911392406\n",
      "\n",
      "Epoch 132. Loss: 0.007465325645671125, Train_acc 0.99873046875\n",
      "\n",
      "Epoch 132. Loss: 0.008629094379007074, Train_acc 0.9986496913580247\n",
      "\n",
      "Epoch 132. Loss: 0.007776362361442189, Train_acc 0.9986661585365854\n",
      "\n",
      "Epoch 132. Loss: 0.010943230758843847, Train_acc 0.9985881024096386\n",
      "\n",
      "Epoch 132. Loss: 0.01145588168865862, Train_acc 0.9985119047619048\n",
      "\n",
      "Epoch 132. Loss: 0.010570137593818509, Train_acc 0.9985294117647059\n",
      "\n",
      "Epoch 132. Loss: 0.012322196120327238, Train_acc 0.9984556686046512\n",
      "\n",
      "Epoch 132. Loss: 0.01302477065858739, Train_acc 0.9983836206896551\n",
      "\n",
      "Epoch 132. Loss: 0.011730096278742398, Train_acc 0.9984019886363636\n",
      "\n",
      "Epoch 132. Loss: 0.010670376570550005, Train_acc 0.9984199438202247\n",
      "\n",
      "Epoch 132. Loss: 0.010965044835085333, Train_acc 0.9983506944444445\n",
      "\n",
      "Epoch 132. Loss: 0.011591542807705397, Train_acc 0.998282967032967\n",
      "\n",
      "Epoch 132. Loss: 0.010528204239055242, Train_acc 0.9983016304347826\n",
      "\n",
      "Epoch 132. Loss: 0.009981415747458987, Train_acc 0.9983198924731183\n",
      "\n",
      "Epoch 132. Loss: 0.010563967186679173, Train_acc 0.9982546542553191\n",
      "\n",
      "Epoch 132. Loss: 0.013971949793520327, Train_acc 0.9981907894736842\n",
      "\n",
      "Epoch 132. Loss: 0.02002715782310613, Train_acc 0.998046875\n",
      "\n",
      "Epoch 132. Loss: 0.018045115809972454, Train_acc 0.9980670103092784\n",
      "\n",
      "Epoch 132. Loss: 0.016407779681200118, Train_acc 0.9980867346938775\n",
      "\n",
      "Epoch 132. Loss: 0.017213362971706093, Train_acc 0.9980271464646465\n",
      "\n",
      "Epoch 132. Loss: 0.01675850374528429, Train_acc 0.99796875\n",
      "\n",
      "[Epoch 132 Batch 100] Loss: 0.01717568630452747 Training: accuracy=0.997912\n",
      "Epoch 132. Loss: 0.01717568630452747, Train_acc 0.9979115099009901\n",
      "\n",
      "Epoch 132. Loss: 0.016897965471230104, Train_acc 0.9978553921568627\n",
      "\n",
      "Epoch 132. Loss: 0.016192875188096305, Train_acc 0.9978003640776699\n",
      "\n",
      "Epoch 132. Loss: 0.014992685947794265, Train_acc 0.9978215144230769\n",
      "\n",
      "Epoch 132. Loss: 0.014911633320729626, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 132. Loss: 0.01492005393333497, Train_acc 0.9977152122641509\n",
      "\n",
      "Epoch 132. Loss: 0.017944489915018638, Train_acc 0.9975905373831776\n",
      "\n",
      "Epoch 132. Loss: 0.016192501974423925, Train_acc 0.9976128472222222\n",
      "\n",
      "Epoch 132. Loss: 0.01459694811864979, Train_acc 0.997634747706422\n",
      "\n",
      "Epoch 132. Loss: 0.013640970529967131, Train_acc 0.99765625\n",
      "\n",
      "Epoch 132. Loss: 0.013280174061823115, Train_acc 0.9976069819819819\n",
      "\n",
      "Epoch 132. Loss: 0.012957625825108492, Train_acc 0.99755859375\n",
      "\n",
      "Epoch 132. Loss: 0.011666451890750646, Train_acc 0.9975801991150443\n",
      "\n",
      "Epoch 132. Loss: 0.010568060428606871, Train_acc 0.9976014254385965\n",
      "\n",
      "Epoch 132. Loss: 0.009570021701677802, Train_acc 0.9976222826086957\n",
      "\n",
      "Epoch 132. Loss: 0.009939539527437834, Train_acc 0.9975754310344828\n",
      "\n",
      "Epoch 132. Loss: 0.011032679464407337, Train_acc 0.9975293803418803\n",
      "\n",
      "Epoch 132. Loss: 0.011247057965535736, Train_acc 0.9974841101694916\n",
      "\n",
      "Epoch 132. Loss: 0.010276859957811668, Train_acc 0.9975052521008403\n",
      "\n",
      "Epoch 132. Loss: 0.013183964901123137, Train_acc 0.9974609375\n",
      "\n",
      "Epoch 132. Loss: 0.012905458704042755, Train_acc 0.9974173553719008\n",
      "\n",
      "Epoch 132. Loss: 0.011667839464817186, Train_acc 0.9974385245901639\n",
      "\n",
      "Epoch 132. Loss: 0.010579366766552245, Train_acc 0.9974593495934959\n",
      "\n",
      "Epoch 132. Loss: 0.009638655802062258, Train_acc 0.9974798387096774\n",
      "\n",
      "Epoch 132. Loss: 0.010087518557564411, Train_acc 0.9975\n",
      "\n",
      "Epoch 132. Loss: 0.009513608196815248, Train_acc 0.9975198412698413\n",
      "\n",
      "Epoch 132. Loss: 0.009414989609516021, Train_acc 0.9974778543307087\n",
      "\n",
      "Epoch 132. Loss: 0.00850281033049012, Train_acc 0.99749755859375\n",
      "\n",
      "Epoch 132. Loss: 0.007669767107684494, Train_acc 0.9975169573643411\n",
      "\n",
      "Epoch 132. Loss: 0.009386509797977581, Train_acc 0.9974759615384615\n",
      "\n",
      "Epoch 132. Loss: 0.008520911493177422, Train_acc 0.9974952290076335\n",
      "\n",
      "Epoch 132. Loss: 0.007786805665999837, Train_acc 0.9975142045454546\n",
      "\n",
      "Epoch 132. Loss: 0.00740692739100175, Train_acc 0.9975328947368421\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132. Loss: 0.007278386228107663, Train_acc 0.9975513059701493\n",
      "\n",
      "Epoch 132. Loss: 0.006715154027482795, Train_acc 0.9975694444444444\n",
      "\n",
      "Epoch 132. Loss: 0.006251715971640581, Train_acc 0.9975873161764706\n",
      "\n",
      "Epoch 132. Loss: 0.006199674186732025, Train_acc 0.9976049270072993\n",
      "\n",
      "Epoch 132. Loss: 0.00791270707037358, Train_acc 0.9975656702898551\n",
      "\n",
      "Epoch 132. Loss: 0.008062425134953635, Train_acc 0.9975269784172662\n",
      "\n",
      "Epoch 132. Loss: 0.007745852799379924, Train_acc 0.9975446428571428\n",
      "\n",
      "Epoch 132. Loss: 0.008036514373419373, Train_acc 0.9975066489361702\n",
      "\n",
      "Epoch 132. Loss: 0.007238428721327365, Train_acc 0.9975242077464789\n",
      "\n",
      "Epoch 132. Loss: 0.006522227705258485, Train_acc 0.9975415209790209\n",
      "\n",
      "Epoch 132. Loss: 0.006040398839869371, Train_acc 0.99755859375\n",
      "\n",
      "Epoch 132. Loss: 0.005750504700660649, Train_acc 0.9975754310344828\n",
      "\n",
      "Epoch 132. Loss: 0.0060331693529962985, Train_acc 0.9975385273972602\n",
      "\n",
      "Epoch 132. Loss: 0.00608014095484133, Train_acc 0.9975552721088435\n",
      "\n",
      "Epoch 132. Loss: 0.00790209162526353, Train_acc 0.9975190033783784\n",
      "\n",
      "Epoch 132. Loss: 0.007594179406401729, Train_acc 0.9975356543624161\n",
      "\n",
      "Epoch 132. Loss: 0.007107285100828602, Train_acc 0.9975520833333333\n",
      "\n",
      "Epoch 132. Loss: 0.0064147614528812045, Train_acc 0.9975682947019867\n",
      "\n",
      "Epoch 132. Loss: 0.006447403316057659, Train_acc 0.9975328947368421\n",
      "\n",
      "Epoch 132. Loss: 0.005852600192402173, Train_acc 0.9975490196078431\n",
      "\n",
      "Epoch 132. Loss: 0.005493516004792782, Train_acc 0.997564935064935\n",
      "\n",
      "Epoch 132. Loss: 0.006738220067362724, Train_acc 0.9974798387096774\n",
      "\n",
      "Epoch 132. Loss: 0.0098493347271151, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 132. Loss: 0.010214721478122473, Train_acc 0.9973626592356688\n",
      "\n",
      "Epoch 132. Loss: 0.009290585641902015, Train_acc 0.9973793512658228\n",
      "\n",
      "Epoch 132. Loss: 0.009143090654022686, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 132. Loss: 0.008278029629507013, Train_acc 0.997412109375\n",
      "\n",
      "Epoch 132. Loss: 0.007496786086854166, Train_acc 0.9974281832298136\n",
      "\n",
      "Epoch 132. Loss: 0.006878543054063761, Train_acc 0.9974440586419753\n",
      "\n",
      "Epoch 132. Loss: 0.007488618072867075, Train_acc 0.9974118098159509\n",
      "\n",
      "Epoch 132. Loss: 0.007563970224857044, Train_acc 0.9974275914634146\n",
      "\n",
      "Epoch 132. Loss: 0.007391163117557507, Train_acc 0.9974431818181818\n",
      "\n",
      "Epoch 132. Loss: 0.0068167369422455805, Train_acc 0.9974585843373494\n",
      "\n",
      "Epoch 132. Loss: 0.006999522263450042, Train_acc 0.9974270209580839\n",
      "\n",
      "Epoch 132. Loss: 0.006345199296071112, Train_acc 0.9974423363095238\n",
      "\n",
      "Epoch 132. Loss: 0.005748828437506427, Train_acc 0.9974574704142012\n",
      "\n",
      "Epoch 132. Loss: 0.005190195573427341, Train_acc 0.9974724264705882\n",
      "\n",
      "Epoch 132. Loss: 0.004684207975036221, Train_acc 0.9974872076023392\n",
      "\n",
      "Epoch 132. Loss: 0.005018959952145503, Train_acc 0.9974563953488372\n",
      "\n",
      "Epoch 132. Loss: 0.004568021574280876, Train_acc 0.997471098265896\n",
      "\n",
      "Epoch 132. Loss: 0.004423507894869642, Train_acc 0.9974856321839081\n",
      "\n",
      "Epoch 132. Loss: 0.004184171270545718, Train_acc 0.9975\n",
      "\n",
      "Epoch 132. Loss: 0.0038203941288103734, Train_acc 0.9975142045454546\n",
      "\n",
      "Epoch 132. Loss: 0.005068039395139522, Train_acc 0.9974841101694916\n",
      "\n",
      "Epoch 132. Loss: 0.009372948555105245, Train_acc 0.9974104634831461\n",
      "\n",
      "Epoch 132. Loss: 0.008535535612642005, Train_acc 0.9974249301675978\n",
      "\n",
      "Epoch 132. Loss: 0.007810299489443811, Train_acc 0.9974392361111111\n",
      "\n",
      "Epoch 132. Loss: 0.007096071824481244, Train_acc 0.9974533839779005\n",
      "\n",
      "Epoch 132. Loss: 0.006426444023869139, Train_acc 0.9974673763736264\n",
      "\n",
      "Epoch 132. Loss: 0.006023348313961955, Train_acc 0.9974812158469946\n",
      "\n",
      "Epoch 132. Loss: 0.007001575552577853, Train_acc 0.997452445652174\n",
      "\n",
      "Epoch 132. Loss: 0.006808723466683995, Train_acc 0.9974662162162162\n",
      "\n",
      "Epoch 132. Loss: 0.007474091219535087, Train_acc 0.9974378360215054\n",
      "\n",
      "Epoch 132. Loss: 0.007021954241139246, Train_acc 0.9974515374331551\n",
      "\n",
      "Epoch 132. Loss: 0.006426988678921807, Train_acc 0.9974650930851063\n",
      "\n",
      "Epoch 132. Loss: 0.006114031879454447, Train_acc 0.9974785052910053\n",
      "\n",
      "Epoch 132. Loss: 0.0055744826146546834, Train_acc 0.9974917763157894\n",
      "\n",
      "Epoch 132. Loss: 0.005064070241026625, Train_acc 0.9975049083769634\n",
      "\n",
      "Epoch 132. Loss: 0.00481297438099761, Train_acc 0.9975179036458334\n",
      "\n",
      "Epoch 132. Loss: 0.004456404062589518, Train_acc 0.9975307642487047\n",
      "\n",
      "Epoch 132. Loss: 0.0040742339708202445, Train_acc 0.9975434922680413\n",
      "\n",
      "Epoch 132. Loss: 0.0036935773549677457, Train_acc 0.9975560897435898\n",
      "\n",
      "Epoch 132. Loss: 0.0033568390063823633, Train_acc 0.99756\n",
      "\n",
      "Epoch 133. Loss: 0.003035788267225597, Train_acc 1.0\n",
      "\n",
      "Epoch 133. Loss: 0.0033933266514872677, Train_acc 0.99609375\n",
      "\n",
      "Epoch 133. Loss: 0.0030862901926750094, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 133. Loss: 0.0027870147043208672, Train_acc 0.998046875\n",
      "\n",
      "Epoch 133. Loss: 0.002617452784366047, Train_acc 0.9984375\n",
      "\n",
      "Epoch 133. Loss: 0.0023689750720301364, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 133. Loss: 0.0021587526486180285, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 133. Loss: 0.001998689688828548, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 133. Loss: 0.001891578667222971, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 133. Loss: 0.002234789603897495, Train_acc 0.99921875\n",
      "\n",
      "Epoch 133. Loss: 0.0020175991488998947, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 133. Loss: 0.0034491027996098236, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 133. Loss: 0.0031149573236772814, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 133. Loss: 0.00280716814747235, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 133. Loss: 0.0025461768336221538, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 133. Loss: 0.008966204246323554, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 133. Loss: 0.00807164310359673, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 133. Loss: 0.007299015511395108, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 133. Loss: 0.00662559024011596, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 133. Loss: 0.006003675937698072, Train_acc 0.998828125\n",
      "\n",
      "Epoch 133. Loss: 0.005415328380157198, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 133. Loss: 0.004898898550516051, Train_acc 0.9989346590909091\n",
      "\n",
      "Epoch 133. Loss: 0.004468247924186154, Train_acc 0.9989809782608695\n",
      "\n",
      "Epoch 133. Loss: 0.00444980469400051, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 133. Loss: 0.004016121638912597, Train_acc 0.9990625\n",
      "\n",
      "Epoch 133. Loss: 0.0036728570264062785, Train_acc 0.9990985576923077\n",
      "\n",
      "Epoch 133. Loss: 0.005213460868729487, Train_acc 0.9988425925925926\n",
      "\n",
      "Epoch 133. Loss: 0.004725309504929932, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 133. Loss: 0.0042875914272006614, Train_acc 0.9989224137931034\n",
      "\n",
      "Epoch 133. Loss: 0.00392390108029198, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 133. Loss: 0.005634330988706512, Train_acc 0.9987399193548387\n",
      "\n",
      "Epoch 133. Loss: 0.0050986862766324624, Train_acc 0.998779296875\n",
      "\n",
      "Epoch 133. Loss: 0.004613179819339512, Train_acc 0.9988162878787878\n",
      "\n",
      "Epoch 133. Loss: 0.0041767304318881026, Train_acc 0.9988511029411765\n",
      "\n",
      "Epoch 133. Loss: 0.0037799808862038473, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 133. Loss: 0.004704071035882356, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 133. Loss: 0.004394284130879214, Train_acc 0.9987331081081081\n",
      "\n",
      "Epoch 133. Loss: 0.003995757455311764, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 133. Loss: 0.0036490690798920084, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 133. Loss: 0.0033776014282095456, Train_acc 0.998828125\n",
      "\n",
      "Epoch 133. Loss: 0.003328727838996472, Train_acc 0.9988567073170732\n",
      "\n",
      "Epoch 133. Loss: 0.0030005587448708577, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 133. Loss: 0.002807743675320509, Train_acc 0.9989098837209303\n",
      "\n",
      "Epoch 133. Loss: 0.002587252001964297, Train_acc 0.9989346590909091\n",
      "\n",
      "Epoch 133. Loss: 0.002421074892965254, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 133. Loss: 0.0030802923575526152, Train_acc 0.9988111413043478\n",
      "\n",
      "Epoch 133. Loss: 0.0028789950171547243, Train_acc 0.9988364361702128\n",
      "\n",
      "Epoch 133. Loss: 0.002629813965089584, Train_acc 0.9988606770833334\n",
      "\n",
      "Epoch 133. Loss: 0.0024187625274438096, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 133. Loss: 0.0024091174725781473, Train_acc 0.99890625\n",
      "\n",
      "Epoch 133. Loss: 0.0027880064866623814, Train_acc 0.9989276960784313\n",
      "\n",
      "Epoch 133. Loss: 0.0025347649266770364, Train_acc 0.9989483173076923\n",
      "\n",
      "Epoch 133. Loss: 0.003023228798250933, Train_acc 0.9989681603773585\n",
      "\n",
      "Epoch 133. Loss: 0.0029164972098385507, Train_acc 0.9989872685185185\n",
      "\n",
      "Epoch 133. Loss: 0.0026494769197000756, Train_acc 0.9990056818181818\n",
      "\n",
      "Epoch 133. Loss: 0.0024083612252624657, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 133. Loss: 0.002178925218645274, Train_acc 0.9990405701754386\n",
      "\n",
      "Epoch 133. Loss: 0.0019696492845099403, Train_acc 0.9990571120689655\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133. Loss: 0.0018164617324722917, Train_acc 0.999073093220339\n",
      "\n",
      "Epoch 133. Loss: 0.0016537939109521906, Train_acc 0.9990885416666667\n",
      "\n",
      "Epoch 133. Loss: 0.0015499956930701705, Train_acc 0.9991034836065574\n",
      "\n",
      "Epoch 133. Loss: 0.0014368741085309332, Train_acc 0.9991179435483871\n",
      "\n",
      "Epoch 133. Loss: 0.0013703512316915584, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 133. Loss: 0.0012407314589325585, Train_acc 0.9991455078125\n",
      "\n",
      "Epoch 133. Loss: 0.0014763430541638136, Train_acc 0.9991586538461539\n",
      "\n",
      "Epoch 133. Loss: 0.0013647274252211912, Train_acc 0.9991714015151515\n",
      "\n",
      "Epoch 133. Loss: 0.001242632763658504, Train_acc 0.9991837686567164\n",
      "\n",
      "Epoch 133. Loss: 0.001121452994110001, Train_acc 0.9991957720588235\n",
      "\n",
      "Epoch 133. Loss: 0.0011551390961588735, Train_acc 0.9992074275362319\n",
      "\n",
      "Epoch 133. Loss: 0.0010825466687791106, Train_acc 0.99921875\n",
      "\n",
      "Epoch 133. Loss: 0.0009910107657010718, Train_acc 0.9992297535211268\n",
      "\n",
      "Epoch 133. Loss: 0.0009048379656865774, Train_acc 0.9992404513888888\n",
      "\n",
      "Epoch 133. Loss: 0.0016601790962095181, Train_acc 0.9991438356164384\n",
      "\n",
      "Epoch 133. Loss: 0.0016538074545912552, Train_acc 0.9991554054054054\n",
      "\n",
      "Epoch 133. Loss: 0.0015034082812991462, Train_acc 0.9991666666666666\n",
      "\n",
      "Epoch 133. Loss: 0.0013587748201869805, Train_acc 0.9991776315789473\n",
      "\n",
      "Epoch 133. Loss: 0.0013011224681507391, Train_acc 0.9991883116883117\n",
      "\n",
      "Epoch 133. Loss: 0.001854829025435821, Train_acc 0.9990985576923077\n",
      "\n",
      "Epoch 133. Loss: 0.0017078153215177739, Train_acc 0.9991099683544303\n",
      "\n",
      "Epoch 133. Loss: 0.0015465928420712956, Train_acc 0.99912109375\n",
      "\n",
      "Epoch 133. Loss: 0.0018650591627768047, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 133. Loss: 0.0016795255547248794, Train_acc 0.9991425304878049\n",
      "\n",
      "Epoch 133. Loss: 0.0015137543862786037, Train_acc 0.9991528614457831\n",
      "\n",
      "Epoch 133. Loss: 0.0013653698624504819, Train_acc 0.9991629464285714\n",
      "\n",
      "Epoch 133. Loss: 0.0012294969350307842, Train_acc 0.999172794117647\n",
      "\n",
      "Epoch 133. Loss: 0.0011102665880963927, Train_acc 0.9991824127906976\n",
      "\n",
      "Epoch 133. Loss: 0.001019557957978444, Train_acc 0.9991918103448276\n",
      "\n",
      "Epoch 133. Loss: 0.000920979940738078, Train_acc 0.9992009943181818\n",
      "\n",
      "Epoch 133. Loss: 0.0008332633271593033, Train_acc 0.9992099719101124\n",
      "\n",
      "Epoch 133. Loss: 0.0017888237874011557, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 133. Loss: 0.0016166060097574581, Train_acc 0.9991414835164835\n",
      "\n",
      "Epoch 133. Loss: 0.0014586903598090414, Train_acc 0.9991508152173914\n",
      "\n",
      "Epoch 133. Loss: 0.0013610823257670913, Train_acc 0.9991599462365591\n",
      "\n",
      "Epoch 133. Loss: 0.0012416956698754682, Train_acc 0.9991688829787234\n",
      "\n",
      "Epoch 133. Loss: 0.0011246282727992987, Train_acc 0.9991776315789473\n",
      "\n",
      "Epoch 133. Loss: 0.001049543876235131, Train_acc 0.9991861979166666\n",
      "\n",
      "Epoch 133. Loss: 0.0026847122613648565, Train_acc 0.9991140463917526\n",
      "\n",
      "Epoch 133. Loss: 0.004458957404261231, Train_acc 0.9990433673469388\n",
      "\n",
      "Epoch 133. Loss: 0.004014693377911319, Train_acc 0.9990530303030303\n",
      "\n",
      "Epoch 133. Loss: 0.003621548199836909, Train_acc 0.9990625\n",
      "\n",
      "[Epoch 133 Batch 100] Loss: 0.003269768889590278 Training: accuracy=0.999072\n",
      "Epoch 133. Loss: 0.003269768889590278, Train_acc 0.9990717821782178\n",
      "\n",
      "Epoch 133. Loss: 0.0038109136283494605, Train_acc 0.9990042892156863\n",
      "\n",
      "Epoch 133. Loss: 0.0034700192246766453, Train_acc 0.9990139563106796\n",
      "\n",
      "Epoch 133. Loss: 0.004044496635401091, Train_acc 0.9989483173076923\n",
      "\n",
      "Epoch 133. Loss: 0.0037577127455842565, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 133. Loss: 0.003453609164581186, Train_acc 0.9989681603773585\n",
      "\n",
      "Epoch 133. Loss: 0.0043228915365268175, Train_acc 0.9989047897196262\n",
      "\n",
      "Epoch 133. Loss: 0.004001310932492857, Train_acc 0.9989149305555556\n",
      "\n",
      "Epoch 133. Loss: 0.003633467506516184, Train_acc 0.9989248853211009\n",
      "\n",
      "Epoch 133. Loss: 0.0032749104048932463, Train_acc 0.9989346590909091\n",
      "\n",
      "Epoch 133. Loss: 0.0029565332791155552, Train_acc 0.9989442567567568\n",
      "\n",
      "Epoch 133. Loss: 0.00266817603484454, Train_acc 0.9989536830357143\n",
      "\n",
      "Epoch 133. Loss: 0.002759159875257274, Train_acc 0.9989629424778761\n",
      "\n",
      "Epoch 133. Loss: 0.002528405692614356, Train_acc 0.9989720394736842\n",
      "\n",
      "Epoch 133. Loss: 0.00236132219077996, Train_acc 0.9989809782608695\n",
      "\n",
      "Epoch 133. Loss: 0.002590336796419486, Train_acc 0.9989897629310345\n",
      "\n",
      "Epoch 133. Loss: 0.002352936363574674, Train_acc 0.9989983974358975\n",
      "\n",
      "Epoch 133. Loss: 0.0023345790240005947, Train_acc 0.9990068855932204\n",
      "\n",
      "Epoch 133. Loss: 0.002162857144654062, Train_acc 0.999015231092437\n",
      "\n",
      "Epoch 133. Loss: 0.001974425652760133, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 133. Loss: 0.0018425961074627474, Train_acc 0.9990315082644629\n",
      "\n",
      "Epoch 133. Loss: 0.0016858646341507467, Train_acc 0.9990394467213115\n",
      "\n",
      "Epoch 133. Loss: 0.0015750393323238044, Train_acc 0.999047256097561\n",
      "\n",
      "Epoch 133. Loss: 0.0014380488847428872, Train_acc 0.999054939516129\n",
      "\n",
      "Epoch 133. Loss: 0.0013146932177520302, Train_acc 0.9990625\n",
      "\n",
      "Epoch 133. Loss: 0.0013165252485932268, Train_acc 0.9990699404761905\n",
      "\n",
      "Epoch 133. Loss: 0.0011971547322719269, Train_acc 0.9990772637795275\n",
      "\n",
      "Epoch 133. Loss: 0.0011053437090068137, Train_acc 0.99908447265625\n",
      "\n",
      "Epoch 133. Loss: 0.0009973143080677243, Train_acc 0.9990915697674418\n",
      "\n",
      "Epoch 133. Loss: 0.0009103071228683392, Train_acc 0.9990985576923077\n",
      "\n",
      "Epoch 133. Loss: 0.0008410029497071713, Train_acc 0.9991054389312977\n",
      "\n",
      "Epoch 133. Loss: 0.001307653996243293, Train_acc 0.9991122159090909\n",
      "\n",
      "Epoch 133. Loss: 0.0012175037341690122, Train_acc 0.9991188909774437\n",
      "\n",
      "Epoch 133. Loss: 0.0011098427637276256, Train_acc 0.9991254664179104\n",
      "\n",
      "Epoch 133. Loss: 0.0010132703360335824, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 133. Loss: 0.0009294823489603704, Train_acc 0.9991383272058824\n",
      "\n",
      "Epoch 133. Loss: 0.0010401088888511633, Train_acc 0.9991446167883211\n",
      "\n",
      "Epoch 133. Loss: 0.0009554521287105002, Train_acc 0.9991508152173914\n",
      "\n",
      "Epoch 133. Loss: 0.0011159927540306614, Train_acc 0.9991569244604317\n",
      "\n",
      "Epoch 133. Loss: 0.0011801247468733221, Train_acc 0.9991629464285714\n",
      "\n",
      "Epoch 133. Loss: 0.0015550561886558023, Train_acc 0.9991688829787234\n",
      "\n",
      "Epoch 133. Loss: 0.0014115963519951724, Train_acc 0.999174735915493\n",
      "\n",
      "Epoch 133. Loss: 0.0032331409282691202, Train_acc 0.9991258741258742\n",
      "\n",
      "Epoch 133. Loss: 0.002947307062625759, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 133. Loss: 0.0026563832854526615, Train_acc 0.9991379310344828\n",
      "\n",
      "Epoch 133. Loss: 0.002394939776392233, Train_acc 0.9991438356164384\n",
      "\n",
      "Epoch 133. Loss: 0.002156963074294128, Train_acc 0.9991496598639455\n",
      "\n",
      "Epoch 133. Loss: 0.002570895868468939, Train_acc 0.9991554054054054\n",
      "\n",
      "Epoch 133. Loss: 0.0028502859428632186, Train_acc 0.9991610738255033\n",
      "\n",
      "Epoch 133. Loss: 0.010712528326073997, Train_acc 0.9991145833333334\n",
      "\n",
      "Epoch 133. Loss: 0.010795798929446678, Train_acc 0.9990687086092715\n",
      "\n",
      "Epoch 133. Loss: 0.009721348252653556, Train_acc 0.9990748355263158\n",
      "\n",
      "Epoch 133. Loss: 0.008768078349846506, Train_acc 0.9990808823529411\n",
      "\n",
      "Epoch 133. Loss: 0.007904214670467365, Train_acc 0.9990868506493507\n",
      "\n",
      "Epoch 133. Loss: 0.007247129294369061, Train_acc 0.9990927419354839\n",
      "\n",
      "Epoch 133. Loss: 0.007927701570624208, Train_acc 0.9990484775641025\n",
      "\n",
      "Epoch 133. Loss: 0.007508901665092197, Train_acc 0.9990545382165605\n",
      "\n",
      "Epoch 133. Loss: 0.0110122270817882, Train_acc 0.9989121835443038\n",
      "\n",
      "Epoch 133. Loss: 0.010368401849448042, Train_acc 0.9989190251572327\n",
      "\n",
      "Epoch 133. Loss: 0.009483699155889622, Train_acc 0.99892578125\n",
      "\n",
      "Epoch 133. Loss: 0.008555388543215548, Train_acc 0.9989324534161491\n",
      "\n",
      "Epoch 133. Loss: 0.009329633460826117, Train_acc 0.9988425925925926\n",
      "\n",
      "Epoch 133. Loss: 0.012311047953116692, Train_acc 0.9987538343558282\n",
      "\n",
      "Epoch 133. Loss: 0.01189056986577612, Train_acc 0.9987614329268293\n",
      "\n",
      "Epoch 133. Loss: 0.016609717494314627, Train_acc 0.9986742424242424\n",
      "\n",
      "Epoch 133. Loss: 0.015081611995234237, Train_acc 0.9986822289156626\n",
      "\n",
      "Epoch 133. Loss: 0.013599630340222066, Train_acc 0.9986901197604791\n",
      "\n",
      "Epoch 133. Loss: 0.013370392563298535, Train_acc 0.9986514136904762\n",
      "\n",
      "Epoch 133. Loss: 0.016137771614511482, Train_acc 0.9986131656804734\n",
      "\n",
      "Epoch 133. Loss: 0.014599627415458566, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 133. Loss: 0.013843318646508639, Train_acc 0.9986293859649122\n",
      "\n",
      "Epoch 133. Loss: 0.013652885977499054, Train_acc 0.9986373546511628\n",
      "\n",
      "Epoch 133. Loss: 0.013894058599238724, Train_acc 0.9986000722543352\n",
      "\n",
      "Epoch 133. Loss: 0.013259610897673784, Train_acc 0.9986081178160919\n",
      "\n",
      "Epoch 133. Loss: 0.012480791156849521, Train_acc 0.9986160714285715\n",
      "\n",
      "Epoch 133. Loss: 0.011512563345531754, Train_acc 0.9986239346590909\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133. Loss: 0.010396168254308521, Train_acc 0.998631709039548\n",
      "\n",
      "Epoch 133. Loss: 0.0094462877699108, Train_acc 0.9986393960674157\n",
      "\n",
      "Epoch 133. Loss: 0.008581356491505748, Train_acc 0.9986469972067039\n",
      "\n",
      "Epoch 133. Loss: 0.008364433687576335, Train_acc 0.9986545138888889\n",
      "\n",
      "Epoch 133. Loss: 0.01057413560895504, Train_acc 0.9985756215469613\n",
      "\n",
      "Epoch 133. Loss: 0.009553367245601919, Train_acc 0.9985834478021978\n",
      "\n",
      "Epoch 133. Loss: 0.008988420618205345, Train_acc 0.9985911885245902\n",
      "\n",
      "Epoch 133. Loss: 0.008267668562032203, Train_acc 0.9985988451086957\n",
      "\n",
      "Epoch 133. Loss: 0.008426326578316766, Train_acc 0.9986064189189189\n",
      "\n",
      "Epoch 133. Loss: 0.008087750843576502, Train_acc 0.9986139112903226\n",
      "\n",
      "Epoch 133. Loss: 0.007845062258239308, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 133. Loss: 0.007645338925253498, Train_acc 0.9986286569148937\n",
      "\n",
      "Epoch 133. Loss: 0.0071476840148027064, Train_acc 0.9986359126984127\n",
      "\n",
      "Epoch 133. Loss: 0.009124757111339747, Train_acc 0.9986019736842106\n",
      "\n",
      "Epoch 133. Loss: 0.008422730616161805, Train_acc 0.9986092931937173\n",
      "\n",
      "Epoch 133. Loss: 0.012245074958887322, Train_acc 0.9984944661458334\n",
      "\n",
      "Epoch 133. Loss: 0.011251917583155593, Train_acc 0.9985022668393783\n",
      "\n",
      "Epoch 133. Loss: 0.010131366001324861, Train_acc 0.9985099871134021\n",
      "\n",
      "Epoch 133. Loss: 0.012682492536387154, Train_acc 0.998477564102564\n",
      "\n",
      "Epoch 133. Loss: 0.011498971733495645, Train_acc 0.99848\n",
      "\n",
      "Epoch 134. Loss: 0.01047667497296189, Train_acc 1.0\n",
      "\n",
      "Epoch 134. Loss: 0.010983469137391937, Train_acc 0.99609375\n",
      "\n",
      "Epoch 134. Loss: 0.010125701890222572, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 134. Loss: 0.009359131641871342, Train_acc 0.998046875\n",
      "\n",
      "Epoch 134. Loss: 0.008757128982971558, Train_acc 0.9984375\n",
      "\n",
      "Epoch 134. Loss: 0.00886352777710299, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 134. Loss: 0.008024219769719157, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 134. Loss: 0.007304330539930236, Train_acc 0.998046875\n",
      "\n",
      "Epoch 134. Loss: 0.006733417012579028, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 134. Loss: 0.00617815144905384, Train_acc 0.9984375\n",
      "\n",
      "Epoch 134. Loss: 0.005602748271445541, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 134. Loss: 0.007622090944606163, Train_acc 0.998046875\n",
      "\n",
      "Epoch 134. Loss: 0.008565365569852082, Train_acc 0.9975961538461539\n",
      "\n",
      "Epoch 134. Loss: 0.007964197010900637, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 134. Loss: 0.009920879344140942, Train_acc 0.996875\n",
      "\n",
      "Epoch 134. Loss: 0.00968408116548847, Train_acc 0.99658203125\n",
      "\n",
      "Epoch 134. Loss: 0.009637165141251005, Train_acc 0.9963235294117647\n",
      "\n",
      "Epoch 134. Loss: 0.009203810663205074, Train_acc 0.9965277777777778\n",
      "\n",
      "Epoch 134. Loss: 0.00860721590401085, Train_acc 0.9967105263157895\n",
      "\n",
      "Epoch 134. Loss: 0.01001455665929334, Train_acc 0.996484375\n",
      "\n",
      "Epoch 134. Loss: 0.010085221939264684, Train_acc 0.9962797619047619\n",
      "\n",
      "Epoch 134. Loss: 0.009233260029423786, Train_acc 0.9964488636363636\n",
      "\n",
      "Epoch 134. Loss: 0.008595402696089645, Train_acc 0.9966032608695652\n",
      "\n",
      "Epoch 134. Loss: 0.007791860122953012, Train_acc 0.9967447916666666\n",
      "\n",
      "Epoch 134. Loss: 0.007031185226580303, Train_acc 0.996875\n",
      "\n",
      "Epoch 134. Loss: 0.006666678479000152, Train_acc 0.9969951923076923\n",
      "\n",
      "Epoch 134. Loss: 0.006240365522966582, Train_acc 0.9971064814814815\n",
      "\n",
      "Epoch 134. Loss: 0.005865371984570443, Train_acc 0.9972098214285714\n",
      "\n",
      "Epoch 134. Loss: 0.005337863151762681, Train_acc 0.9973060344827587\n",
      "\n",
      "Epoch 134. Loss: 0.005206673289791164, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 134. Loss: 0.009094739507545906, Train_acc 0.9969758064516129\n",
      "\n",
      "Epoch 134. Loss: 0.010920880147138129, Train_acc 0.996826171875\n",
      "\n",
      "Epoch 134. Loss: 0.009916566799614704, Train_acc 0.9969223484848485\n",
      "\n",
      "Epoch 134. Loss: 0.008938869093812557, Train_acc 0.9970128676470589\n",
      "\n",
      "Epoch 134. Loss: 0.008113304049250454, Train_acc 0.9970982142857143\n",
      "\n",
      "Epoch 134. Loss: 0.007307902284128141, Train_acc 0.9971788194444444\n",
      "\n",
      "Epoch 134. Loss: 0.006583958867163085, Train_acc 0.9972550675675675\n",
      "\n",
      "Epoch 134. Loss: 0.006051242074791155, Train_acc 0.997327302631579\n",
      "\n",
      "Epoch 134. Loss: 0.005477261631811614, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 134. Loss: 0.0049327242130797425, Train_acc 0.9974609375\n",
      "\n",
      "Epoch 134. Loss: 0.00471605590028417, Train_acc 0.9975228658536586\n",
      "\n",
      "Epoch 134. Loss: 0.00429276160652412, Train_acc 0.9975818452380952\n",
      "\n",
      "Epoch 134. Loss: 0.004234680379412827, Train_acc 0.9976380813953488\n",
      "\n",
      "Epoch 134. Loss: 0.003829473145534719, Train_acc 0.9976917613636364\n",
      "\n",
      "Epoch 134. Loss: 0.0035663632743255422, Train_acc 0.9977430555555555\n",
      "\n",
      "Epoch 134. Loss: 0.003466974353882324, Train_acc 0.9977921195652174\n",
      "\n",
      "Epoch 134. Loss: 0.00335896236807941, Train_acc 0.9978390957446809\n",
      "\n",
      "Epoch 134. Loss: 0.0036556384916082495, Train_acc 0.9978841145833334\n",
      "\n",
      "Epoch 134. Loss: 0.0033852412169125354, Train_acc 0.9979272959183674\n",
      "\n",
      "Epoch 134. Loss: 0.003053087618118041, Train_acc 0.99796875\n",
      "\n",
      "Epoch 134. Loss: 0.002765251281258085, Train_acc 0.9980085784313726\n",
      "\n",
      "Epoch 134. Loss: 0.0024920136017673685, Train_acc 0.998046875\n",
      "\n",
      "Epoch 134. Loss: 0.0022547108420869835, Train_acc 0.9980837264150944\n",
      "\n",
      "Epoch 134. Loss: 0.0034216324789054214, Train_acc 0.9979745370370371\n",
      "\n",
      "Epoch 134. Loss: 0.0031847003466093852, Train_acc 0.9980113636363637\n",
      "\n",
      "Epoch 134. Loss: 0.003261441889363913, Train_acc 0.998046875\n",
      "\n",
      "Epoch 134. Loss: 0.002976251679323663, Train_acc 0.9980811403508771\n",
      "\n",
      "Epoch 134. Loss: 0.002769288313487589, Train_acc 0.998114224137931\n",
      "\n",
      "Epoch 134. Loss: 0.003830163661777454, Train_acc 0.9980137711864406\n",
      "\n",
      "Epoch 134. Loss: 0.0034540628095496434, Train_acc 0.998046875\n",
      "\n",
      "Epoch 134. Loss: 0.004082079074534364, Train_acc 0.9979508196721312\n",
      "\n",
      "Epoch 134. Loss: 0.0036841265209263505, Train_acc 0.9979838709677419\n",
      "\n",
      "Epoch 134. Loss: 0.0035150646068003127, Train_acc 0.998015873015873\n",
      "\n",
      "Epoch 134. Loss: 0.004734148545325966, Train_acc 0.9979248046875\n",
      "\n",
      "Epoch 134. Loss: 0.004403148966124956, Train_acc 0.9979567307692307\n",
      "\n",
      "Epoch 134. Loss: 0.004011392332154933, Train_acc 0.9979876893939394\n",
      "\n",
      "Epoch 134. Loss: 0.003750220893469533, Train_acc 0.9980177238805971\n",
      "\n",
      "Epoch 134. Loss: 0.003421333745053222, Train_acc 0.998046875\n",
      "\n",
      "Epoch 134. Loss: 0.003905213365641961, Train_acc 0.9979619565217391\n",
      "\n",
      "Epoch 134. Loss: 0.0038937272318640913, Train_acc 0.9979910714285715\n",
      "\n",
      "Epoch 134. Loss: 0.0038816265315657467, Train_acc 0.9980193661971831\n",
      "\n",
      "Epoch 134. Loss: 0.004269005616084839, Train_acc 0.9979383680555556\n",
      "\n",
      "Epoch 134. Loss: 0.003861631892626696, Train_acc 0.997966609589041\n",
      "\n",
      "Epoch 134. Loss: 0.003495124117871751, Train_acc 0.9979940878378378\n",
      "\n",
      "Epoch 134. Loss: 0.003185046744427648, Train_acc 0.9980208333333334\n",
      "\n",
      "Epoch 134. Loss: 0.002872252830873061, Train_acc 0.998046875\n",
      "\n",
      "Epoch 134. Loss: 0.002900780173251148, Train_acc 0.9980722402597403\n",
      "\n",
      "Epoch 134. Loss: 0.0026224240845299806, Train_acc 0.9980969551282052\n",
      "\n",
      "Epoch 134. Loss: 0.0023644108486318973, Train_acc 0.9981210443037974\n",
      "\n",
      "Epoch 134. Loss: 0.0021360151604489525, Train_acc 0.99814453125\n",
      "\n",
      "Epoch 134. Loss: 0.002018879600125272, Train_acc 0.9981674382716049\n",
      "\n",
      "Epoch 134. Loss: 0.0018285982738923375, Train_acc 0.9981897865853658\n",
      "\n",
      "Epoch 134. Loss: 0.005896830746322097, Train_acc 0.9981174698795181\n",
      "\n",
      "Epoch 134. Loss: 0.005314530961320412, Train_acc 0.9981398809523809\n",
      "\n",
      "Epoch 134. Loss: 0.005138360430767189, Train_acc 0.9981617647058824\n",
      "\n",
      "Epoch 134. Loss: 0.004683602998192654, Train_acc 0.9981831395348837\n",
      "\n",
      "Epoch 134. Loss: 0.004839418813170981, Train_acc 0.998114224137931\n",
      "\n",
      "Epoch 134. Loss: 0.0046949385620641635, Train_acc 0.9981356534090909\n",
      "\n",
      "Epoch 134. Loss: 0.00438663361657303, Train_acc 0.9981566011235955\n",
      "\n",
      "Epoch 134. Loss: 0.003982598495889416, Train_acc 0.9981770833333333\n",
      "\n",
      "Epoch 134. Loss: 0.0035883011495518613, Train_acc 0.9981971153846154\n",
      "\n",
      "Epoch 134. Loss: 0.0032430637617879557, Train_acc 0.9982167119565217\n",
      "\n",
      "Epoch 134. Loss: 0.002921606821777777, Train_acc 0.9982358870967742\n",
      "\n",
      "Epoch 134. Loss: 0.0031801027190348713, Train_acc 0.9982546542553191\n",
      "\n",
      "Epoch 134. Loss: 0.00287943545608034, Train_acc 0.9982730263157895\n",
      "\n",
      "Epoch 134. Loss: 0.002618496830884161, Train_acc 0.998291015625\n",
      "\n",
      "Epoch 134. Loss: 0.002365136995619257, Train_acc 0.9983086340206185\n",
      "\n",
      "Epoch 134. Loss: 0.002134532133977619, Train_acc 0.9983258928571429\n",
      "\n",
      "Epoch 134. Loss: 0.0019266188314331157, Train_acc 0.998342803030303\n",
      "\n",
      "Epoch 134. Loss: 0.0017351356032191943, Train_acc 0.998359375\n",
      "\n",
      "[Epoch 134 Batch 100] Loss: 0.0017694107729374674 Training: accuracy=0.998376\n",
      "Epoch 134. Loss: 0.0017694107729374674, Train_acc 0.9983756188118812\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134. Loss: 0.0015939890741184888, Train_acc 0.9983915441176471\n",
      "\n",
      "Epoch 134. Loss: 0.0014435286609905788, Train_acc 0.9984071601941747\n",
      "\n",
      "Epoch 134. Loss: 0.0016965271790544238, Train_acc 0.9984224759615384\n",
      "\n",
      "Epoch 134. Loss: 0.0015299544293043432, Train_acc 0.9984375\n",
      "\n",
      "Epoch 134. Loss: 0.0013824642796760305, Train_acc 0.9984522405660378\n",
      "\n",
      "Epoch 134. Loss: 0.0012447933939619279, Train_acc 0.9984667056074766\n",
      "\n",
      "Epoch 134. Loss: 0.0012182621228529586, Train_acc 0.9984809027777778\n",
      "\n",
      "Epoch 134. Loss: 0.0011927178485896654, Train_acc 0.9984948394495413\n",
      "\n",
      "Epoch 134. Loss: 0.0011169857549814702, Train_acc 0.9985085227272728\n",
      "\n",
      "Epoch 134. Loss: 0.0010101655438993955, Train_acc 0.9985219594594594\n",
      "\n",
      "Epoch 134. Loss: 0.0009245304424861819, Train_acc 0.99853515625\n",
      "\n",
      "Epoch 134. Loss: 0.0008358872726346843, Train_acc 0.9985481194690266\n",
      "\n",
      "Epoch 134. Loss: 0.0007572887121519875, Train_acc 0.9985608552631579\n",
      "\n",
      "Epoch 134. Loss: 0.0006836709225673623, Train_acc 0.9985733695652174\n",
      "\n",
      "Epoch 134. Loss: 0.0006407349698216824, Train_acc 0.9985856681034483\n",
      "\n",
      "Epoch 134. Loss: 0.0005941520251121618, Train_acc 0.9985977564102564\n",
      "\n",
      "Epoch 134. Loss: 0.0005390964661726065, Train_acc 0.9986096398305084\n",
      "\n",
      "Epoch 134. Loss: 0.0004910344630341193, Train_acc 0.9986213235294118\n",
      "\n",
      "Epoch 134. Loss: 0.00046923030492533396, Train_acc 0.9986328125\n",
      "\n",
      "Epoch 134. Loss: 0.0004235770723728406, Train_acc 0.9986441115702479\n",
      "\n",
      "Epoch 134. Loss: 0.0005191127201214195, Train_acc 0.9986552254098361\n",
      "\n",
      "Epoch 134. Loss: 0.0005144992558688829, Train_acc 0.9986661585365854\n",
      "\n",
      "Epoch 134. Loss: 0.00047737207030781295, Train_acc 0.9986769153225806\n",
      "\n",
      "Epoch 134. Loss: 0.0004452414314719574, Train_acc 0.9986875\n",
      "\n",
      "Epoch 134. Loss: 0.00040625489015287116, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 134. Loss: 0.0003701776040611995, Train_acc 0.9987081692913385\n",
      "\n",
      "Epoch 134. Loss: 0.0003625315981542319, Train_acc 0.99871826171875\n",
      "\n",
      "Epoch 134. Loss: 0.0003465495356486961, Train_acc 0.9987281976744186\n",
      "\n",
      "Epoch 134. Loss: 0.0003272848666179046, Train_acc 0.9987379807692308\n",
      "\n",
      "Epoch 134. Loss: 0.0009512653152317881, Train_acc 0.9986879770992366\n",
      "\n",
      "Epoch 134. Loss: 0.0008606354532072308, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 134. Loss: 0.0007749999283713405, Train_acc 0.9987077067669173\n",
      "\n",
      "Epoch 134. Loss: 0.00070660107875744, Train_acc 0.9987173507462687\n",
      "\n",
      "Epoch 134. Loss: 0.0006697242083315208, Train_acc 0.9987268518518518\n",
      "\n",
      "Epoch 134. Loss: 0.000618395889448243, Train_acc 0.9987362132352942\n",
      "\n",
      "Epoch 134. Loss: 0.0006108821623597601, Train_acc 0.9987454379562044\n",
      "\n",
      "Epoch 134. Loss: 0.0005619366760983687, Train_acc 0.9987545289855072\n",
      "\n",
      "Epoch 134. Loss: 0.0005234392026064207, Train_acc 0.9987634892086331\n",
      "\n",
      "Epoch 134. Loss: 0.00047735534019884777, Train_acc 0.9987723214285714\n",
      "\n",
      "Epoch 134. Loss: 0.00047448777296871524, Train_acc 0.9987810283687943\n",
      "\n",
      "Epoch 134. Loss: 0.00043735979893879366, Train_acc 0.9987896126760564\n",
      "\n",
      "Epoch 134. Loss: 0.0004345247853138784, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 134. Loss: 0.0004019486374168368, Train_acc 0.9988064236111112\n",
      "\n",
      "Epoch 134. Loss: 0.00038810633172732046, Train_acc 0.9988146551724137\n",
      "\n",
      "Epoch 134. Loss: 0.0006364932288242112, Train_acc 0.9988227739726028\n",
      "\n",
      "Epoch 134. Loss: 0.0024707964252989947, Train_acc 0.9987776360544217\n",
      "\n",
      "Epoch 134. Loss: 0.002255331033971068, Train_acc 0.9987858952702703\n",
      "\n",
      "Epoch 134. Loss: 0.0020659224023818136, Train_acc 0.998794043624161\n",
      "\n",
      "Epoch 134. Loss: 0.0018686868639193192, Train_acc 0.9988020833333333\n",
      "\n",
      "Epoch 134. Loss: 0.0017154831224583207, Train_acc 0.9988100165562914\n",
      "\n",
      "Epoch 134. Loss: 0.0015775587653086068, Train_acc 0.9988178453947368\n",
      "\n",
      "Epoch 134. Loss: 0.0014443704012238293, Train_acc 0.9988255718954249\n",
      "\n",
      "Epoch 134. Loss: 0.0013083937245619182, Train_acc 0.998833198051948\n",
      "\n",
      "Epoch 134. Loss: 0.0013930284957300323, Train_acc 0.9988407258064517\n",
      "\n",
      "Epoch 134. Loss: 0.0012646977946047923, Train_acc 0.998848157051282\n",
      "\n",
      "Epoch 134. Loss: 0.0011458970236267936, Train_acc 0.9988554936305732\n",
      "\n",
      "Epoch 134. Loss: 0.0014146063749107384, Train_acc 0.9988627373417721\n",
      "\n",
      "Epoch 134. Loss: 0.0020203075616758463, Train_acc 0.9988207547169812\n",
      "\n",
      "Epoch 134. Loss: 0.0018256234170364533, Train_acc 0.998828125\n",
      "\n",
      "Epoch 134. Loss: 0.0017736082626238939, Train_acc 0.9988354037267081\n",
      "\n",
      "Epoch 134. Loss: 0.0017192314461563953, Train_acc 0.9988425925925926\n",
      "\n",
      "Epoch 134. Loss: 0.005580782925697708, Train_acc 0.9987538343558282\n",
      "\n",
      "Epoch 134. Loss: 0.005037328824808861, Train_acc 0.9987614329268293\n",
      "\n",
      "Epoch 134. Loss: 0.004548447899130861, Train_acc 0.9987689393939394\n",
      "\n",
      "Epoch 134. Loss: 0.004207188432778758, Train_acc 0.9987763554216867\n",
      "\n",
      "Epoch 134. Loss: 0.003803761116684143, Train_acc 0.9987836826347305\n",
      "\n",
      "Epoch 134. Loss: 0.003446219558981096, Train_acc 0.9987909226190477\n",
      "\n",
      "Epoch 134. Loss: 0.0036343685050013977, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 134. Loss: 0.003296320180183759, Train_acc 0.9988051470588235\n",
      "\n",
      "Epoch 134. Loss: 0.003064715544211368, Train_acc 0.9988121345029239\n",
      "\n",
      "Epoch 134. Loss: 0.0027651566588407384, Train_acc 0.9988190406976745\n",
      "\n",
      "Epoch 134. Loss: 0.0025319170966357552, Train_acc 0.9988258670520231\n",
      "\n",
      "Epoch 134. Loss: 0.0022863371940586848, Train_acc 0.9988326149425287\n",
      "\n",
      "Epoch 134. Loss: 0.0023412454241186873, Train_acc 0.9988392857142857\n",
      "\n",
      "Epoch 134. Loss: 0.0023649101787361947, Train_acc 0.9988458806818182\n",
      "\n",
      "Epoch 134. Loss: 0.0025109933428663117, Train_acc 0.9988524011299436\n",
      "\n",
      "Epoch 134. Loss: 0.0022790444352491926, Train_acc 0.9988588483146067\n",
      "\n",
      "Epoch 134. Loss: 0.0021703802477506607, Train_acc 0.9988652234636871\n",
      "\n",
      "Epoch 134. Loss: 0.0019742093027048093, Train_acc 0.9988715277777778\n",
      "\n",
      "Epoch 134. Loss: 0.004821093741692256, Train_acc 0.998748273480663\n",
      "\n",
      "Epoch 134. Loss: 0.004351240134592321, Train_acc 0.9987551510989011\n",
      "\n",
      "Epoch 134. Loss: 0.003925869780966311, Train_acc 0.9987619535519126\n",
      "\n",
      "Epoch 134. Loss: 0.0035390207474631005, Train_acc 0.9987686820652174\n",
      "\n",
      "Epoch 134. Loss: 0.0047701753054739775, Train_acc 0.9987331081081081\n",
      "\n",
      "Epoch 134. Loss: 0.004297840357511372, Train_acc 0.9987399193548387\n",
      "\n",
      "Epoch 134. Loss: 0.0038725617791604628, Train_acc 0.9987466577540107\n",
      "\n",
      "Epoch 134. Loss: 0.003552569402128082, Train_acc 0.9987533244680851\n",
      "\n",
      "Epoch 134. Loss: 0.003204204743732546, Train_acc 0.9987599206349206\n",
      "\n",
      "Epoch 134. Loss: 0.0029207602930528603, Train_acc 0.998766447368421\n",
      "\n",
      "Epoch 134. Loss: 0.003171597594466449, Train_acc 0.9987729057591623\n",
      "\n",
      "Epoch 134. Loss: 0.0028952020627621335, Train_acc 0.998779296875\n",
      "\n",
      "Epoch 134. Loss: 0.0026291139732086085, Train_acc 0.9987856217616581\n",
      "\n",
      "Epoch 134. Loss: 0.002421843145077311, Train_acc 0.998791881443299\n",
      "\n",
      "Epoch 134. Loss: 0.004896840311990574, Train_acc 0.9987580128205128\n",
      "\n",
      "Epoch 134. Loss: 0.004408826242394119, Train_acc 0.99876\n",
      "\n",
      "Epoch 135. Loss: 0.004005145929950843, Train_acc 1.0\n",
      "\n",
      "Epoch 135. Loss: 0.0036899259037714775, Train_acc 1.0\n",
      "\n",
      "Epoch 135. Loss: 0.0033236589313180454, Train_acc 1.0\n",
      "\n",
      "Epoch 135. Loss: 0.0037925918055145033, Train_acc 0.998046875\n",
      "\n",
      "Epoch 135. Loss: 0.0034338094703471626, Train_acc 0.9984375\n",
      "\n",
      "Epoch 135. Loss: 0.008181288800726768, Train_acc 0.9973958333333334\n",
      "\n",
      "Epoch 135. Loss: 0.007374036880658771, Train_acc 0.9977678571428571\n",
      "\n",
      "Epoch 135. Loss: 0.006666167381390592, Train_acc 0.998046875\n",
      "\n",
      "Epoch 135. Loss: 0.006199064455800945, Train_acc 0.9982638888888888\n",
      "\n",
      "Epoch 135. Loss: 0.0055980900286498915, Train_acc 0.9984375\n",
      "\n",
      "Epoch 135. Loss: 0.005045189896785535, Train_acc 0.9985795454545454\n",
      "\n",
      "Epoch 135. Loss: 0.005100450908747302, Train_acc 0.9986979166666666\n",
      "\n",
      "Epoch 135. Loss: 0.004608705832071329, Train_acc 0.9987980769230769\n",
      "\n",
      "Epoch 135. Loss: 0.004153766996956021, Train_acc 0.9988839285714286\n",
      "\n",
      "Epoch 135. Loss: 0.003907363749206349, Train_acc 0.9989583333333333\n",
      "\n",
      "Epoch 135. Loss: 0.0037661086220237183, Train_acc 0.9990234375\n",
      "\n",
      "Epoch 135. Loss: 0.0036103522703745277, Train_acc 0.9990808823529411\n",
      "\n",
      "Epoch 135. Loss: 0.003410395091741381, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 135. Loss: 0.0031269285238630456, Train_acc 0.9991776315789473\n",
      "\n",
      "Epoch 135. Loss: 0.003055650478282292, Train_acc 0.99921875\n",
      "\n",
      "Epoch 135. Loss: 0.002823768779636892, Train_acc 0.9992559523809523\n",
      "\n",
      "Epoch 135. Loss: 0.002585706374725712, Train_acc 0.9992897727272727\n",
      "\n",
      "Epoch 135. Loss: 0.0023333331891289186, Train_acc 0.9993206521739131\n",
      "\n",
      "Epoch 135. Loss: 0.0025577304335734994, Train_acc 0.9993489583333334\n",
      "\n",
      "Epoch 135. Loss: 0.0023196224228627686, Train_acc 0.999375\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135. Loss: 0.0021117330326786005, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 135. Loss: 0.0019118831065224342, Train_acc 0.9994212962962963\n",
      "\n",
      "Epoch 135. Loss: 0.0018058144661271631, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 135. Loss: 0.0017162124899201745, Train_acc 0.9994612068965517\n",
      "\n",
      "Epoch 135. Loss: 0.0015567227972146337, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 135. Loss: 0.0014099166385543166, Train_acc 0.9994959677419355\n",
      "\n",
      "Epoch 135. Loss: 0.001527305289034112, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 135. Loss: 0.0013879801488757145, Train_acc 0.9995265151515151\n",
      "\n",
      "Epoch 135. Loss: 0.0012720003374215598, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 135. Loss: 0.0011787554690972687, Train_acc 0.9995535714285714\n",
      "\n",
      "Epoch 135. Loss: 0.0010818797939639811, Train_acc 0.9995659722222222\n",
      "\n",
      "Epoch 135. Loss: 0.0011797119164724521, Train_acc 0.9995777027027027\n",
      "\n",
      "Epoch 135. Loss: 0.001078721312504634, Train_acc 0.9995888157894737\n",
      "\n",
      "Epoch 135. Loss: 0.0011004972231655938, Train_acc 0.9995993589743589\n",
      "\n",
      "Epoch 135. Loss: 0.0011747531533594093, Train_acc 0.999609375\n",
      "\n",
      "Epoch 135. Loss: 0.0010710515866746153, Train_acc 0.9996189024390244\n",
      "\n",
      "Epoch 135. Loss: 0.0010539386615591926, Train_acc 0.9996279761904762\n",
      "\n",
      "Epoch 135. Loss: 0.0012984694156442, Train_acc 0.9996366279069767\n",
      "\n",
      "Epoch 135. Loss: 0.001179769515448311, Train_acc 0.9996448863636364\n",
      "\n",
      "Epoch 135. Loss: 0.001137636377732604, Train_acc 0.9996527777777777\n",
      "\n",
      "Epoch 135. Loss: 0.002039891465890988, Train_acc 0.9994904891304348\n",
      "\n",
      "Epoch 135. Loss: 0.0018509299977571153, Train_acc 0.999501329787234\n",
      "\n",
      "Epoch 135. Loss: 0.001676859985000209, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 135. Loss: 0.001519806517984777, Train_acc 0.9995216836734694\n",
      "\n",
      "Epoch 135. Loss: 0.002329758219861665, Train_acc 0.999375\n",
      "\n",
      "Epoch 135. Loss: 0.002100354799931805, Train_acc 0.9993872549019608\n",
      "\n",
      "Epoch 135. Loss: 0.0019079801645440404, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 135. Loss: 0.0017228186421870525, Train_acc 0.9994103773584906\n",
      "\n",
      "Epoch 135. Loss: 0.0015568023801011185, Train_acc 0.9994212962962963\n",
      "\n",
      "Epoch 135. Loss: 0.0019986450620885794, Train_acc 0.9994318181818181\n",
      "\n",
      "Epoch 135. Loss: 0.001806250240230957, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 135. Loss: 0.0016279809599167652, Train_acc 0.9994517543859649\n",
      "\n",
      "Epoch 135. Loss: 0.0014922711086035414, Train_acc 0.9994612068965517\n",
      "\n",
      "Epoch 135. Loss: 0.0013514750558291766, Train_acc 0.9994703389830508\n",
      "\n",
      "Epoch 135. Loss: 0.0012209674473343134, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 135. Loss: 0.0011810745182920552, Train_acc 0.9994877049180327\n",
      "\n",
      "Epoch 135. Loss: 0.001066421700233011, Train_acc 0.9994959677419355\n",
      "\n",
      "Epoch 135. Loss: 0.0013210065648008482, Train_acc 0.9995039682539683\n",
      "\n",
      "Epoch 135. Loss: 0.0011948986438531089, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 135. Loss: 0.00107891407172905, Train_acc 0.9995192307692308\n",
      "\n",
      "Epoch 135. Loss: 0.0010451112147288912, Train_acc 0.9995265151515151\n",
      "\n",
      "Epoch 135. Loss: 0.0009440051799375981, Train_acc 0.9995335820895522\n",
      "\n",
      "Epoch 135. Loss: 0.0008886961062853041, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 135. Loss: 0.0008056801516231217, Train_acc 0.9995471014492754\n",
      "\n",
      "Epoch 135. Loss: 0.0022646246738806056, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 135. Loss: 0.0020630539938175773, Train_acc 0.999449823943662\n",
      "\n",
      "Epoch 135. Loss: 0.0019089438754589794, Train_acc 0.9994574652777778\n",
      "\n",
      "Epoch 135. Loss: 0.0018331988163982126, Train_acc 0.999464897260274\n",
      "\n",
      "Epoch 135. Loss: 0.0018470234393949175, Train_acc 0.9994721283783784\n",
      "\n",
      "Epoch 135. Loss: 0.0016818239156696823, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 135. Loss: 0.0015196098520714448, Train_acc 0.9994860197368421\n",
      "\n",
      "Epoch 135. Loss: 0.0013698085338837416, Train_acc 0.9994926948051948\n",
      "\n",
      "Epoch 135. Loss: 0.0013427259678326408, Train_acc 0.9994991987179487\n",
      "\n",
      "Epoch 135. Loss: 0.0012129642384878887, Train_acc 0.9995055379746836\n",
      "\n",
      "Epoch 135. Loss: 0.0010936914830967956, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 135. Loss: 0.0009888533559006237, Train_acc 0.9995177469135802\n",
      "\n",
      "Epoch 135. Loss: 0.0008947890567289956, Train_acc 0.9995236280487805\n",
      "\n",
      "Epoch 135. Loss: 0.002097623600140855, Train_acc 0.9994352409638554\n",
      "\n",
      "Epoch 135. Loss: 0.0018939504992404202, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 135. Loss: 0.001724600015506714, Train_acc 0.9994485294117647\n",
      "\n",
      "Epoch 135. Loss: 0.0015724115827479832, Train_acc 0.9994549418604651\n",
      "\n",
      "Epoch 135. Loss: 0.0014271518370087184, Train_acc 0.9994612068965517\n",
      "\n",
      "Epoch 135. Loss: 0.0012987112046663862, Train_acc 0.9994673295454546\n",
      "\n",
      "Epoch 135. Loss: 0.0011693913976053422, Train_acc 0.9994733146067416\n",
      "\n",
      "Epoch 135. Loss: 0.0010567249937407461, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 135. Loss: 0.0009982308076191878, Train_acc 0.9994848901098901\n",
      "\n",
      "Epoch 135. Loss: 0.0009012322959855482, Train_acc 0.9994904891304348\n",
      "\n",
      "Epoch 135. Loss: 0.0008343994954766775, Train_acc 0.9994959677419355\n",
      "\n",
      "Epoch 135. Loss: 0.0007580155484341333, Train_acc 0.999501329787234\n",
      "\n",
      "Epoch 135. Loss: 0.0007117699287705347, Train_acc 0.9995065789473684\n",
      "\n",
      "Epoch 135. Loss: 0.000860525297399407, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 135. Loss: 0.0007857578594097901, Train_acc 0.9995167525773195\n",
      "\n",
      "Epoch 135. Loss: 0.0018158815516778298, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 135. Loss: 0.0016490295593578862, Train_acc 0.999447601010101\n",
      "\n",
      "Epoch 135. Loss: 0.001608272985280834, Train_acc 0.999453125\n",
      "\n",
      "[Epoch 135 Batch 100] Loss: 0.001468066968626651 Training: accuracy=0.999459\n",
      "Epoch 135. Loss: 0.001468066968626651, Train_acc 0.9994585396039604\n",
      "\n",
      "Epoch 135. Loss: 0.0018158085776330884, Train_acc 0.9994638480392157\n",
      "\n",
      "Epoch 135. Loss: 0.0017538063137459926, Train_acc 0.9994690533980582\n",
      "\n",
      "Epoch 135. Loss: 0.001602784019767218, Train_acc 0.9994741586538461\n",
      "\n",
      "Epoch 135. Loss: 0.001456468288136287, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 135. Loss: 0.005253147170572963, Train_acc 0.9994103773584906\n",
      "\n",
      "Epoch 135. Loss: 0.005166748391654629, Train_acc 0.9994158878504673\n",
      "\n",
      "Epoch 135. Loss: 0.004650909615680112, Train_acc 0.9994212962962963\n",
      "\n",
      "Epoch 135. Loss: 0.004192778802424019, Train_acc 0.9994266055045872\n",
      "\n",
      "Epoch 135. Loss: 0.0037817404174003487, Train_acc 0.9994318181818181\n",
      "\n",
      "Epoch 135. Loss: 0.0034142998974365877, Train_acc 0.9994369369369369\n",
      "\n",
      "Epoch 135. Loss: 0.003101006481075582, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 135. Loss: 0.002809723292899621, Train_acc 0.9994469026548672\n",
      "\n",
      "Epoch 135. Loss: 0.0025682256733840264, Train_acc 0.9994517543859649\n",
      "\n",
      "Epoch 135. Loss: 0.0024421485602713127, Train_acc 0.9994565217391305\n",
      "\n",
      "Epoch 135. Loss: 0.0023474084628990143, Train_acc 0.9994612068965517\n",
      "\n",
      "Epoch 135. Loss: 0.002130643133284619, Train_acc 0.999465811965812\n",
      "\n",
      "Epoch 135. Loss: 0.005624285507764193, Train_acc 0.9994041313559322\n",
      "\n",
      "Epoch 135. Loss: 0.00511055521487551, Train_acc 0.9994091386554622\n",
      "\n",
      "Epoch 135. Loss: 0.004627697451753381, Train_acc 0.9994140625\n",
      "\n",
      "Epoch 135. Loss: 0.004186605629210123, Train_acc 0.9994189049586777\n",
      "\n",
      "Epoch 135. Loss: 0.004290636263982459, Train_acc 0.9994236680327869\n",
      "\n",
      "Epoch 135. Loss: 0.003942181784555469, Train_acc 0.9994283536585366\n",
      "\n",
      "Epoch 135. Loss: 0.0035696201650652548, Train_acc 0.9994329637096774\n",
      "\n",
      "Epoch 135. Loss: 0.003322404176296585, Train_acc 0.9994375\n",
      "\n",
      "Epoch 135. Loss: 0.0030170812773655372, Train_acc 0.9994419642857143\n",
      "\n",
      "Epoch 135. Loss: 0.0028340866496071684, Train_acc 0.9994463582677166\n",
      "\n",
      "Epoch 135. Loss: 0.0026292564293098866, Train_acc 0.99945068359375\n",
      "\n",
      "Epoch 135. Loss: 0.002836449569793262, Train_acc 0.9994549418604651\n",
      "\n",
      "Epoch 135. Loss: 0.002612511673968704, Train_acc 0.9994591346153846\n",
      "\n",
      "Epoch 135. Loss: 0.002582070133672659, Train_acc 0.9994632633587787\n",
      "\n",
      "Epoch 135. Loss: 0.0023322670630801417, Train_acc 0.9994673295454546\n",
      "\n",
      "Epoch 135. Loss: 0.0021006872401285706, Train_acc 0.9994713345864662\n",
      "\n",
      "Epoch 135. Loss: 0.0018916409091233018, Train_acc 0.9994752798507462\n",
      "\n",
      "Epoch 135. Loss: 0.0017037469143743244, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 135. Loss: 0.00153739309392026, Train_acc 0.9994829963235294\n",
      "\n",
      "Epoch 135. Loss: 0.0017138772070257448, Train_acc 0.9994867700729927\n",
      "\n",
      "Epoch 135. Loss: 0.001942615559832625, Train_acc 0.9994904891304348\n",
      "\n",
      "Epoch 135. Loss: 0.001764589387949945, Train_acc 0.999494154676259\n",
      "\n",
      "Epoch 135. Loss: 0.001632301195851132, Train_acc 0.9994977678571428\n",
      "\n",
      "Epoch 135. Loss: 0.0014705490826453485, Train_acc 0.999501329787234\n",
      "\n",
      "Epoch 135. Loss: 0.001365020392791395, Train_acc 0.9995048415492958\n",
      "\n",
      "Epoch 135. Loss: 0.0012297907751626113, Train_acc 0.9995083041958042\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135. Loss: 0.0011080460019190074, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 135. Loss: 0.001012686079865117, Train_acc 0.9995150862068966\n",
      "\n",
      "Epoch 135. Loss: 0.0011912063077840977, Train_acc 0.9995184075342466\n",
      "\n",
      "Epoch 135. Loss: 0.0010756708527331822, Train_acc 0.9995216836734694\n",
      "\n",
      "Epoch 135. Loss: 0.001066064478451038, Train_acc 0.9995249155405406\n",
      "\n",
      "Epoch 135. Loss: 0.0009608859314669516, Train_acc 0.9995281040268457\n",
      "\n",
      "Epoch 135. Loss: 0.0008694880416013415, Train_acc 0.99953125\n",
      "\n",
      "Epoch 135. Loss: 0.0007831427803080912, Train_acc 0.9995343543046358\n",
      "\n",
      "Epoch 135. Loss: 0.0007061932187223779, Train_acc 0.9995374177631579\n",
      "\n",
      "Epoch 135. Loss: 0.0006419073254597907, Train_acc 0.9995404411764706\n",
      "\n",
      "Epoch 135. Loss: 0.0006387191703359984, Train_acc 0.9995434253246753\n",
      "\n",
      "Epoch 135. Loss: 0.0005795902299733669, Train_acc 0.9995463709677419\n",
      "\n",
      "Epoch 135. Loss: 0.0005344571792020129, Train_acc 0.9995492788461539\n",
      "\n",
      "Epoch 135. Loss: 0.00048358538040054296, Train_acc 0.9995521496815286\n",
      "\n",
      "Epoch 135. Loss: 0.000483325180080637, Train_acc 0.9995549841772152\n",
      "\n",
      "Epoch 135. Loss: 0.001746385651082192, Train_acc 0.9995086477987422\n",
      "\n",
      "Epoch 135. Loss: 0.0015782461823177325, Train_acc 0.99951171875\n",
      "\n",
      "Epoch 135. Loss: 0.0014215347785068706, Train_acc 0.999514751552795\n",
      "\n",
      "Epoch 135. Loss: 0.0012810289896430336, Train_acc 0.9995177469135802\n",
      "\n",
      "Epoch 135. Loss: 0.0011568145865272445, Train_acc 0.9995207055214724\n",
      "\n",
      "Epoch 135. Loss: 0.0010420176829582777, Train_acc 0.9995236280487805\n",
      "\n",
      "Epoch 135. Loss: 0.0017255722273009713, Train_acc 0.9994791666666667\n",
      "\n",
      "Epoch 135. Loss: 0.001653184090934041, Train_acc 0.9994823042168675\n",
      "\n",
      "Epoch 135. Loss: 0.0014950930571582346, Train_acc 0.9994854041916168\n",
      "\n",
      "Epoch 135. Loss: 0.0033333206098699357, Train_acc 0.9993954613095238\n",
      "\n",
      "Epoch 135. Loss: 0.003001695688628064, Train_acc 0.9993990384615384\n",
      "\n",
      "Epoch 135. Loss: 0.0027826287862103343, Train_acc 0.9994025735294118\n",
      "\n",
      "Epoch 135. Loss: 0.003602649008462533, Train_acc 0.999360380116959\n",
      "\n",
      "Epoch 135. Loss: 0.004391301074829434, Train_acc 0.9993186773255814\n",
      "\n",
      "Epoch 135. Loss: 0.003969813405234335, Train_acc 0.9993226156069365\n",
      "\n",
      "Epoch 135. Loss: 0.0035755875324326282, Train_acc 0.9993265086206896\n",
      "\n",
      "Epoch 135. Loss: 0.003221464305567236, Train_acc 0.9993303571428571\n",
      "\n",
      "Epoch 135. Loss: 0.002899798970468384, Train_acc 0.9993341619318182\n",
      "\n",
      "Epoch 135. Loss: 0.0032299347614922003, Train_acc 0.9992937853107344\n",
      "\n",
      "Epoch 135. Loss: 0.0030019363975013385, Train_acc 0.9992977528089888\n",
      "\n",
      "Epoch 135. Loss: 0.0027801185582639358, Train_acc 0.9993016759776536\n",
      "\n",
      "Epoch 135. Loss: 0.0026206733677703064, Train_acc 0.9993055555555556\n",
      "\n",
      "Epoch 135. Loss: 0.003360489049755149, Train_acc 0.999266229281768\n",
      "\n",
      "Epoch 135. Loss: 0.0031541873376206573, Train_acc 0.999270260989011\n",
      "\n",
      "Epoch 135. Loss: 0.004278719125893952, Train_acc 0.9992315573770492\n",
      "\n",
      "Epoch 135. Loss: 0.0038540970390542194, Train_acc 0.9992357336956522\n",
      "\n",
      "Epoch 135. Loss: 0.00798562044848536, Train_acc 0.9991976351351352\n",
      "\n",
      "Epoch 135. Loss: 0.00726456032089473, Train_acc 0.9992019489247311\n",
      "\n",
      "Epoch 135. Loss: 0.006601784133411925, Train_acc 0.99920621657754\n",
      "\n",
      "Epoch 135. Loss: 0.009028932976869478, Train_acc 0.9991688829787234\n",
      "\n",
      "Epoch 135. Loss: 0.00919292547462678, Train_acc 0.9991319444444444\n",
      "\n",
      "Epoch 135. Loss: 0.009556936389133, Train_acc 0.9990953947368421\n",
      "\n",
      "Epoch 135. Loss: 0.018432178049616214, Train_acc 0.9990183246073299\n",
      "\n",
      "Epoch 135. Loss: 0.019582138426004828, Train_acc 0.9989827473958334\n",
      "\n",
      "Epoch 135. Loss: 0.01815603461882381, Train_acc 0.998988018134715\n",
      "\n",
      "Epoch 135. Loss: 0.01937353122551061, Train_acc 0.998912693298969\n",
      "\n",
      "Epoch 135. Loss: 0.01980309884982244, Train_acc 0.9988381410256411\n",
      "\n",
      "Epoch 135. Loss: 0.021364458959432862, Train_acc 0.9988\n",
      "\n",
      "Epoch 136. Loss: 0.019729243236302516, Train_acc 1.0\n",
      "\n",
      "Epoch 136. Loss: 0.019774354488419753, Train_acc 0.99609375\n",
      "\n",
      "Epoch 136. Loss: 0.023384958050340948, Train_acc 0.9895833333333334\n",
      "\n",
      "Epoch 136. Loss: 0.053823548145613555, Train_acc 0.98046875\n",
      "\n",
      "Epoch 136. Loss: 0.050091815631855864, Train_acc 0.9828125\n",
      "\n",
      "Epoch 136. Loss: 0.045857402855175144, Train_acc 0.984375\n",
      "\n",
      "Epoch 136. Loss: 0.04609458544017441, Train_acc 0.984375\n",
      "\n",
      "Epoch 136. Loss: 0.06614100693012685, Train_acc 0.9755859375\n",
      "\n",
      "Epoch 136. Loss: 0.06942454807471106, Train_acc 0.9756944444444444\n",
      "\n",
      "Epoch 136. Loss: 0.06862962282458725, Train_acc 0.97578125\n",
      "\n",
      "Epoch 136. Loss: 0.06320911529743477, Train_acc 0.9772727272727273\n",
      "\n",
      "Epoch 136. Loss: 0.06437481835261408, Train_acc 0.9778645833333334\n",
      "\n",
      "Epoch 136. Loss: 0.06287896613575897, Train_acc 0.9777644230769231\n",
      "\n",
      "Epoch 136. Loss: 0.05794816549016132, Train_acc 0.9787946428571429\n",
      "\n",
      "Epoch 136. Loss: 0.05786250608020807, Train_acc 0.978125\n",
      "\n",
      "Epoch 136. Loss: 0.059128306748155814, Train_acc 0.9775390625\n",
      "\n",
      "Epoch 136. Loss: 0.060120053537205516, Train_acc 0.9774816176470589\n",
      "\n",
      "Epoch 136. Loss: 0.056637298268838815, Train_acc 0.9782986111111112\n",
      "\n",
      "Epoch 136. Loss: 0.05998597476133474, Train_acc 0.9773848684210527\n",
      "\n",
      "Epoch 136. Loss: 0.059276811926800926, Train_acc 0.977734375\n",
      "\n",
      "Epoch 136. Loss: 0.05465741915932797, Train_acc 0.9787946428571429\n",
      "\n",
      "Epoch 136. Loss: 0.05210981876490864, Train_acc 0.9786931818181818\n",
      "\n",
      "Epoch 136. Loss: 0.047311809578955345, Train_acc 0.9796195652173914\n",
      "\n",
      "Epoch 136. Loss: 0.04512740005053893, Train_acc 0.9801432291666666\n",
      "\n",
      "Epoch 136. Loss: 0.04386008452473118, Train_acc 0.980625\n",
      "\n",
      "Epoch 136. Loss: 0.04217196800051362, Train_acc 0.9810697115384616\n",
      "\n",
      "Epoch 136. Loss: 0.03961986830298511, Train_acc 0.9817708333333334\n",
      "\n",
      "Epoch 136. Loss: 0.03895458308277495, Train_acc 0.9818638392857143\n",
      "\n",
      "Epoch 136. Loss: 0.03711344486401648, Train_acc 0.9822198275862069\n",
      "\n",
      "Epoch 136. Loss: 0.036005331934328415, Train_acc 0.9825520833333333\n",
      "\n",
      "Epoch 136. Loss: 0.03476282517090637, Train_acc 0.9828629032258065\n",
      "\n",
      "Epoch 136. Loss: 0.03228148405976771, Train_acc 0.9833984375\n",
      "\n",
      "Epoch 136. Loss: 0.03043319184164118, Train_acc 0.9839015151515151\n",
      "\n",
      "Epoch 136. Loss: 0.02949936709028403, Train_acc 0.9841452205882353\n",
      "\n",
      "Epoch 136. Loss: 0.027878635659562827, Train_acc 0.9845982142857143\n",
      "\n",
      "Epoch 136. Loss: 0.026277012558055472, Train_acc 0.9850260416666666\n",
      "\n",
      "Epoch 136. Loss: 0.02500970201010038, Train_acc 0.9854307432432432\n",
      "\n",
      "Epoch 136. Loss: 0.022812504599447815, Train_acc 0.9858141447368421\n",
      "\n",
      "Epoch 136. Loss: 0.021057840733563097, Train_acc 0.9861778846153846\n",
      "\n",
      "Epoch 136. Loss: 0.020197815528960696, Train_acc 0.986328125\n",
      "\n",
      "Epoch 136. Loss: 0.018609973097400374, Train_acc 0.9866615853658537\n",
      "\n",
      "Epoch 136. Loss: 0.017085115553228416, Train_acc 0.9869791666666666\n",
      "\n",
      "Epoch 136. Loss: 0.015686991693113765, Train_acc 0.987281976744186\n",
      "\n",
      "Epoch 136. Loss: 0.01600908801543819, Train_acc 0.9873934659090909\n",
      "\n",
      "Epoch 136. Loss: 0.014583350594291304, Train_acc 0.9876736111111111\n",
      "\n",
      "Epoch 136. Loss: 0.014970138408645285, Train_acc 0.9877717391304348\n",
      "\n",
      "Epoch 136. Loss: 0.013855836445827151, Train_acc 0.988031914893617\n",
      "\n",
      "Epoch 136. Loss: 0.01393426543897885, Train_acc 0.98828125\n",
      "\n",
      "Epoch 136. Loss: 0.012625541705353538, Train_acc 0.9885204081632653\n",
      "\n",
      "Epoch 136. Loss: 0.011814417794090641, Train_acc 0.98875\n",
      "\n",
      "Epoch 136. Loss: 0.011630115435041905, Train_acc 0.9888174019607843\n",
      "\n",
      "Epoch 136. Loss: 0.010660738951523979, Train_acc 0.9890324519230769\n",
      "\n",
      "Epoch 136. Loss: 0.009640717752787737, Train_acc 0.9892393867924528\n",
      "\n",
      "Epoch 136. Loss: 0.010077109726232231, Train_acc 0.9891493055555556\n",
      "\n",
      "Epoch 136. Loss: 0.009892713893468923, Train_acc 0.9893465909090909\n",
      "\n",
      "Epoch 136. Loss: 0.009268048959090483, Train_acc 0.9895368303571429\n",
      "\n",
      "Epoch 136. Loss: 0.008953732312498247, Train_acc 0.9897203947368421\n",
      "\n",
      "Epoch 136. Loss: 0.008112264090074827, Train_acc 0.9898976293103449\n",
      "\n",
      "Epoch 136. Loss: 0.007579997313918528, Train_acc 0.9900688559322034\n",
      "\n",
      "Epoch 136. Loss: 0.008227004881562463, Train_acc 0.9901041666666667\n",
      "\n",
      "Epoch 136. Loss: 0.007956541706646983, Train_acc 0.9902663934426229\n",
      "\n",
      "Epoch 136. Loss: 0.0073046895389859414, Train_acc 0.9904233870967742\n",
      "\n",
      "Epoch 136. Loss: 0.0066535225975420656, Train_acc 0.9905753968253969\n",
      "\n",
      "Epoch 136. Loss: 0.0061017602597540545, Train_acc 0.99072265625\n",
      "\n",
      "Epoch 136. Loss: 0.005551466540738129, Train_acc 0.9908653846153846\n",
      "\n",
      "Epoch 136. Loss: 0.005072264318256096, Train_acc 0.9910037878787878\n",
      "\n",
      "Epoch 136. Loss: 0.004680091358539625, Train_acc 0.9911380597014925\n",
      "\n",
      "Epoch 136. Loss: 0.004251295064924729, Train_acc 0.9912683823529411\n",
      "\n",
      "Epoch 136. Loss: 0.0038718429900585017, Train_acc 0.9913949275362319\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136. Loss: 0.0035259674427316774, Train_acc 0.9915178571428571\n",
      "\n",
      "Epoch 136. Loss: 0.003590066676951008, Train_acc 0.991637323943662\n",
      "\n",
      "Epoch 136. Loss: 0.0032653645690687884, Train_acc 0.9917534722222222\n",
      "\n",
      "Epoch 136. Loss: 0.0030009161984317057, Train_acc 0.9918664383561644\n",
      "\n",
      "Epoch 136. Loss: 0.0027656096236944993, Train_acc 0.9919763513513513\n",
      "\n",
      "Epoch 136. Loss: 0.0025556105709503563, Train_acc 0.9920833333333333\n",
      "\n",
      "Epoch 136. Loss: 0.0023391486707118577, Train_acc 0.9921875\n",
      "\n",
      "Epoch 136. Loss: 0.0022603621094185794, Train_acc 0.992288961038961\n",
      "\n",
      "Epoch 136. Loss: 0.0021570863442875758, Train_acc 0.9923878205128205\n",
      "\n",
      "Epoch 136. Loss: 0.001955132395501016, Train_acc 0.9924841772151899\n",
      "\n",
      "Epoch 136. Loss: 0.0019988032123596177, Train_acc 0.992578125\n",
      "\n",
      "Epoch 136. Loss: 0.0018143592382901979, Train_acc 0.9926697530864198\n",
      "\n",
      "Epoch 136. Loss: 0.002474054655173487, Train_acc 0.9926638719512195\n",
      "\n",
      "Epoch 136. Loss: 0.0022467457833089902, Train_acc 0.9927522590361446\n",
      "\n",
      "Epoch 136. Loss: 0.0020528650308410203, Train_acc 0.9928385416666666\n",
      "\n",
      "Epoch 136. Loss: 0.0022328631378495585, Train_acc 0.9929227941176471\n",
      "\n",
      "Epoch 136. Loss: 0.0022327486980140707, Train_acc 0.9930050872093024\n",
      "\n",
      "Epoch 136. Loss: 0.002039257093412176, Train_acc 0.9930854885057471\n",
      "\n",
      "Epoch 136. Loss: 0.0018541142832038883, Train_acc 0.9931640625\n",
      "\n",
      "Epoch 136. Loss: 0.0017232010172369108, Train_acc 0.9932408707865169\n",
      "\n",
      "Epoch 136. Loss: 0.001563100758269387, Train_acc 0.9933159722222222\n",
      "\n",
      "Epoch 136. Loss: 0.0014290303250094494, Train_acc 0.9933894230769231\n",
      "\n",
      "Epoch 136. Loss: 0.0013682678073684343, Train_acc 0.9934612771739131\n",
      "\n",
      "Epoch 136. Loss: 0.0012332836470721749, Train_acc 0.9935315860215054\n",
      "\n",
      "Epoch 136. Loss: 0.0011589822330931058, Train_acc 0.9936003989361702\n",
      "\n",
      "Epoch 136. Loss: 0.0010725428138398435, Train_acc 0.9936677631578947\n",
      "\n",
      "Epoch 136. Loss: 0.0009801453830678365, Train_acc 0.9937337239583334\n",
      "\n",
      "Epoch 136. Loss: 0.0009243576738614532, Train_acc 0.993798324742268\n",
      "\n",
      "Epoch 136. Loss: 0.0008477763316215523, Train_acc 0.9938616071428571\n",
      "\n",
      "Epoch 136. Loss: 0.0007721946073925765, Train_acc 0.9939236111111112\n",
      "\n",
      "Epoch 136. Loss: 0.000723954299210759, Train_acc 0.993984375\n",
      "\n",
      "[Epoch 136 Batch 100] Loss: 0.0006922815542244184 Training: accuracy=0.994044\n",
      "Epoch 136. Loss: 0.0006922815542244184, Train_acc 0.9940439356435643\n",
      "\n",
      "Epoch 136. Loss: 0.0007070411454225274, Train_acc 0.9941023284313726\n",
      "\n",
      "Epoch 136. Loss: 0.0008112784560920023, Train_acc 0.9941595873786407\n",
      "\n",
      "Epoch 136. Loss: 0.0007469518181584007, Train_acc 0.9942157451923077\n",
      "\n",
      "Epoch 136. Loss: 0.0007015218999260718, Train_acc 0.9942708333333333\n",
      "\n",
      "Epoch 136. Loss: 0.0006671181777141143, Train_acc 0.9943248820754716\n",
      "\n",
      "Epoch 136. Loss: 0.0006128118865923754, Train_acc 0.9943779205607477\n",
      "\n",
      "Epoch 136. Loss: 0.0006114897982596611, Train_acc 0.9944299768518519\n",
      "\n",
      "Epoch 136. Loss: 0.0005849977761568953, Train_acc 0.9944810779816514\n",
      "\n",
      "Epoch 136. Loss: 0.0005399735202416625, Train_acc 0.99453125\n",
      "\n",
      "Epoch 136. Loss: 0.000508291157691167, Train_acc 0.9945805180180181\n",
      "\n",
      "Epoch 136. Loss: 0.0013333980248348293, Train_acc 0.99462890625\n",
      "\n",
      "Epoch 136. Loss: 0.0012561396680062004, Train_acc 0.9946764380530974\n",
      "\n",
      "Epoch 136. Loss: 0.0011425368272968185, Train_acc 0.9947231359649122\n",
      "\n",
      "Epoch 136. Loss: 0.0010378181356806057, Train_acc 0.9947690217391304\n",
      "\n",
      "Epoch 136. Loss: 0.0009484428113208858, Train_acc 0.9948141163793104\n",
      "\n",
      "Epoch 136. Loss: 0.0009144836387304944, Train_acc 0.9948584401709402\n",
      "\n",
      "Epoch 136. Loss: 0.0018450739767791463, Train_acc 0.9948358050847458\n",
      "\n",
      "Epoch 136. Loss: 0.0023728611762799294, Train_acc 0.9948792016806722\n",
      "\n",
      "Epoch 136. Loss: 0.0021369475590983867, Train_acc 0.994921875\n",
      "\n",
      "Epoch 136. Loss: 0.0019266902424156756, Train_acc 0.9949638429752066\n",
      "\n",
      "Epoch 136. Loss: 0.0017378241403937283, Train_acc 0.9950051229508197\n",
      "\n",
      "Epoch 136. Loss: 0.001571362678490425, Train_acc 0.995045731707317\n",
      "\n",
      "Epoch 136. Loss: 0.0014305654363926045, Train_acc 0.995085685483871\n",
      "\n",
      "Epoch 136. Loss: 0.001335473591504801, Train_acc 0.995125\n",
      "\n",
      "Epoch 136. Loss: 0.0012140590175500387, Train_acc 0.9951636904761905\n",
      "\n",
      "Epoch 136. Loss: 0.001102296689661959, Train_acc 0.9952017716535433\n",
      "\n",
      "Epoch 136. Loss: 0.0010023668750255503, Train_acc 0.9952392578125\n",
      "\n",
      "Epoch 136. Loss: 0.0010761529328640578, Train_acc 0.9952761627906976\n",
      "\n",
      "Epoch 136. Loss: 0.001025993344823609, Train_acc 0.9953125\n",
      "\n",
      "Epoch 136. Loss: 0.0009267370385613633, Train_acc 0.9953482824427481\n",
      "\n",
      "Epoch 136. Loss: 0.000838505697183812, Train_acc 0.9953835227272727\n",
      "\n",
      "Epoch 136. Loss: 0.004060745214163963, Train_acc 0.995359492481203\n",
      "\n",
      "Epoch 136. Loss: 0.003659457520523682, Train_acc 0.9953941231343284\n",
      "\n",
      "Epoch 136. Loss: 0.0033046436751204117, Train_acc 0.9954282407407408\n",
      "\n",
      "Epoch 136. Loss: 0.0029797939672845824, Train_acc 0.9954618566176471\n",
      "\n",
      "Epoch 136. Loss: 0.0029613314137037, Train_acc 0.9954949817518248\n",
      "\n",
      "Epoch 136. Loss: 0.0026822387847996675, Train_acc 0.9955276268115942\n",
      "\n",
      "Epoch 136. Loss: 0.0024287446721456057, Train_acc 0.9955598021582733\n",
      "\n",
      "Epoch 136. Loss: 0.002194755356259331, Train_acc 0.9955915178571428\n",
      "\n",
      "Epoch 136. Loss: 0.0020025977702041132, Train_acc 0.9956227836879432\n",
      "\n",
      "Epoch 136. Loss: 0.00262285991037783, Train_acc 0.9955985915492958\n",
      "\n",
      "Epoch 136. Loss: 0.002378690129752747, Train_acc 0.9956293706293706\n",
      "\n",
      "Epoch 136. Loss: 0.0021629442596215387, Train_acc 0.9956597222222222\n",
      "\n",
      "Epoch 136. Loss: 0.0019673303913047765, Train_acc 0.9956896551724138\n",
      "\n",
      "Epoch 136. Loss: 0.0018033494700148722, Train_acc 0.9957191780821918\n",
      "\n",
      "Epoch 136. Loss: 0.0016543654514885341, Train_acc 0.9957482993197279\n",
      "\n",
      "Epoch 136. Loss: 0.0014992028800882343, Train_acc 0.995777027027027\n",
      "\n",
      "Epoch 136. Loss: 0.0014929221957091193, Train_acc 0.9958053691275168\n",
      "\n",
      "Epoch 136. Loss: 0.0019452180260417194, Train_acc 0.99578125\n",
      "\n",
      "Epoch 136. Loss: 0.0017712475178751571, Train_acc 0.9958091887417219\n",
      "\n",
      "Epoch 136. Loss: 0.0016064934278036183, Train_acc 0.995836759868421\n",
      "\n",
      "Epoch 136. Loss: 0.0014833638322981845, Train_acc 0.9958639705882353\n",
      "\n",
      "Epoch 136. Loss: 0.0013473733361486669, Train_acc 0.995890827922078\n",
      "\n",
      "Epoch 136. Loss: 0.001219005636308539, Train_acc 0.9959173387096775\n",
      "\n",
      "Epoch 136. Loss: 0.0011298149608602657, Train_acc 0.9959435096153846\n",
      "\n",
      "Epoch 136. Loss: 0.0010495692844697568, Train_acc 0.995969347133758\n",
      "\n",
      "Epoch 136. Loss: 0.0009910432305222734, Train_acc 0.9959948575949367\n",
      "\n",
      "Epoch 136. Loss: 0.0010108147369729862, Train_acc 0.9960200471698113\n",
      "\n",
      "Epoch 136. Loss: 0.0009133266280934764, Train_acc 0.996044921875\n",
      "\n",
      "Epoch 136. Loss: 0.0009206270562495786, Train_acc 0.9960694875776398\n",
      "\n",
      "Epoch 136. Loss: 0.0008471255164044498, Train_acc 0.99609375\n",
      "\n",
      "Epoch 136. Loss: 0.0007856721727195665, Train_acc 0.9961177147239264\n",
      "\n",
      "Epoch 136. Loss: 0.0007173369149065161, Train_acc 0.9961413871951219\n",
      "\n",
      "Epoch 136. Loss: 0.0006632637813485505, Train_acc 0.9961647727272728\n",
      "\n",
      "Epoch 136. Loss: 0.000603482384656553, Train_acc 0.9961878765060241\n",
      "\n",
      "Epoch 136. Loss: 0.0007493556466025274, Train_acc 0.9962107035928144\n",
      "\n",
      "Epoch 136. Loss: 0.000683177228803446, Train_acc 0.9962332589285714\n",
      "\n",
      "Epoch 136. Loss: 0.0006168671385340134, Train_acc 0.9962555473372781\n",
      "\n",
      "Epoch 136. Loss: 0.000650227015694282, Train_acc 0.9962775735294118\n",
      "\n",
      "Epoch 136. Loss: 0.0005958548827083684, Train_acc 0.9962993421052632\n",
      "\n",
      "Epoch 136. Loss: 0.0006781661442841687, Train_acc 0.9963208575581395\n",
      "\n",
      "Epoch 136. Loss: 0.0007947144843310653, Train_acc 0.9963421242774566\n",
      "\n",
      "Epoch 136. Loss: 0.0007179366377891827, Train_acc 0.9963631465517241\n",
      "\n",
      "Epoch 136. Loss: 0.0007694061710299606, Train_acc 0.9963839285714285\n",
      "\n",
      "Epoch 136. Loss: 0.0006979308731179538, Train_acc 0.9964044744318182\n",
      "\n",
      "Epoch 136. Loss: 0.0006318979846940617, Train_acc 0.9964247881355932\n",
      "\n",
      "Epoch 136. Loss: 0.0005787115620163673, Train_acc 0.9964448735955056\n",
      "\n",
      "Epoch 136. Loss: 0.0005268452150711409, Train_acc 0.9964647346368715\n",
      "\n",
      "Epoch 136. Loss: 0.00048049380057635084, Train_acc 0.996484375\n",
      "\n",
      "Epoch 136. Loss: 0.0004392014029937693, Train_acc 0.9965037983425414\n",
      "\n",
      "Epoch 136. Loss: 0.00039763778420316524, Train_acc 0.9965230082417582\n",
      "\n",
      "Epoch 136. Loss: 0.000519179541367537, Train_acc 0.9965420081967213\n",
      "\n",
      "Epoch 136. Loss: 0.00047090484256233687, Train_acc 0.9965608016304348\n",
      "\n",
      "Epoch 136. Loss: 0.0005111006341175965, Train_acc 0.9965793918918919\n",
      "\n",
      "Epoch 136. Loss: 0.00046287171986331117, Train_acc 0.9965977822580645\n",
      "\n",
      "Epoch 136. Loss: 0.0005404200309772453, Train_acc 0.9966159759358288\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136. Loss: 0.0004895981789998519, Train_acc 0.9966339760638298\n",
      "\n",
      "Epoch 136. Loss: 0.0004940423358434267, Train_acc 0.9966517857142857\n",
      "\n",
      "Epoch 136. Loss: 0.00045642189978581615, Train_acc 0.9966694078947368\n",
      "\n",
      "Epoch 136. Loss: 0.0004350345059606346, Train_acc 0.9966868455497382\n",
      "\n",
      "Epoch 136. Loss: 0.0003929331263032098, Train_acc 0.9967041015625\n",
      "\n",
      "Epoch 136. Loss: 0.00035682904488374274, Train_acc 0.9967211787564767\n",
      "\n",
      "Epoch 136. Loss: 0.00042092500259977115, Train_acc 0.9967380798969072\n",
      "\n",
      "Epoch 136. Loss: 0.0003832467701632434, Train_acc 0.9967548076923077\n",
      "\n",
      "Epoch 136. Loss: 0.0003488959232453217, Train_acc 0.99676\n",
      "\n",
      "Epoch 137. Loss: 0.00033765605261822806, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 0.0003084824140736764, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 0.000281382813331744, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 0.0002562962452458292, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 0.00024220352390585205, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 0.00023093732574173013, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 0.00023886817748141172, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 0.0002211467442810555, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 0.00020001501862101898, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 0.00018344495732278956, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 0.00017284481552446893, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 0.00015826840646964788, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 0.0001432965404098109, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 0.0001301331587097543, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 0.00012211130364861222, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 0.0001244452098217894, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 0.00011491795748777202, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 0.000103742704139464, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 9.470148765871221e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 8.610487226505528e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 8.225139375757495e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 7.739810558042551e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 7.071997019753429e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 6.726595583435939e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 6.500879765918446e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 6.033543890281132e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 6.817373957942303e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 6.405794178035074e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 6.875906715777483e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 6.238967368472357e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 5.870389841452697e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 5.682790489326921e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 5.6428047529214684e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 5.4720532491011454e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 5.006954359193091e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.67497744822038e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.2675263716937414e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.4477485250956246e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 5.5429122027722536e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 5.4258800599387696e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 5.172252381397407e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.855008948311206e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.489302466447252e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.4760307320903004e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.9715246246654775e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.6368056967685025e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.2513853999493854e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.130200807832191e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.7438249541402824e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.551086886083496e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.331734342502846e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.5542350317139195e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.456013719820866e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.244329558244122e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.110856729348695e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.111768957421824e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.188286078942771e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 2.958435438655701e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 5.074966055275473e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.647222612683884e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.413770102072288e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.158580408877869e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.26110080583605e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.59635144109432e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.197238494585109e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 5.628868963331865e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 6.988296325989488e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 7.534994949212677e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 6.85470154685708e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 6.299592432818047e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 5.985675577103237e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 5.468407350606727e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 5.3835046498234634e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.880614441936227e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.8455217044104934e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.520897938142559e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.2246388201225805e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.050252005336727e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.8732622649710845e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.9408225784296e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.680016637360485e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.4014357923918304e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.176569120461373e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 2.911416237059998e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 5.3654826527681365e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.949152006533119e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.861102680418006e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.555614185700879e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.396220549056551e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.988187616650905e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.911155829367936e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.592769795605398e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 0.00012721347947782747, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 0.0001153362728529313, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 0.00011230120125722263, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 0.00010418144132561441, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 9.483940986899918e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 8.63645926348369e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 9.284503834999359e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 8.7635894053541e-05, Train_acc 1.0\n",
      "\n",
      "[Epoch 137 Batch 100] Loss: 8.228225567124586e-05 Training: accuracy=1.000000\n",
      "Epoch 137. Loss: 8.228225567124586e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 7.426878640504155e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 6.71380607944591e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 6.441754872762958e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 5.914510281670138e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 5.451217970919351e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.977841131322373e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.512345139664402e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.16987217671665e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.826439906493414e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.470151107792896e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.302580793244716e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.160267520304865e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.989270441627216e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.733094720902046e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.4479890727187924e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.208896441818988e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 2.897273414053515e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 2.6687503094201912e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 2.5015776529057514e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 2.4362602611645535e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 2.2639842535637572e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 2.1119458603658194e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 2.8787016050364824e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 2.8051971629534293e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 2.7174623291870266e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.979891776985777e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.814935278094121e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.9218907183836735e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.570490610360736e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.328301216844003e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.851617359049571e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.796448274478647e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.496783135285899e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.12182537761553e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.992298404514649e-05, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137. Loss: 4.176251991870128e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.5892351254456104e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 6.114951142738345e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 5.593389829528546e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 5.3108768412363036e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 5.192417408182364e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.7267588387573845e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.650500372386937e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.36070678094843e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.953450582118425e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.7123681944552155e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.491723379511654e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.1703963837347483e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 2.9544120477274225e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.1369003042946345e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.0151180397037213e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 2.7936742930199024e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 2.8076631064821876e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 2.6265541502738103e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 2.4844297115927742e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 2.48299633372843e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 2.392419434357751e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 2.2407888154105105e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 2.143691183064983e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 2.1762064752026663e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 2.0935705211141607e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 2.4622887016272867e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 2.2382805014263837e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 2.1742894148595446e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 5.225946483196376e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.720897470150302e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.2825270959580874e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.196771391838895e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.805479664151862e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.4412014028931224e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.145804794621713e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 4.0655081605655674e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.84066527278633e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.63652400959986e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.432752773658179e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 3.154541437584826e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 2.886061030797611e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 2.6408060972697474e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 2.48956451249329e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 2.426397656223685e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 2.2375039615906077e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 2.0542161161459843e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 1.9836959610080408e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 1.933930395890061e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 1.7466281570537e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 1.667012649043825e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 1.591661850530747e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 1.615990387046095e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 1.563814947838435e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 1.602074377801228e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 1.7638654992506467e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 1.6567742692433102e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 1.552950903960477e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 1.7891001504202133e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 137. Loss: 1.638531520510272e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.5507372366761776e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.413395253635474e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.3052080925390793e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.2438798121117053e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.301609977668142e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.1829226682474142e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.0754895328300874e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.0698649950502416e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 9.979504893521408e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.4382248175831457e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.4710194766483408e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.3500123758002111e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.2370738244048441e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.1947018437380453e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.2636607534876621e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.2290473867519535e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.1190319137670771e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.276260628342605e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.231363204025782e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.1764444295819635e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.3264794295372715e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.325812792041429e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.2791189901630274e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.1897985566010987e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.1695909897067472e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.1139599279269056e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.055635824985923e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 9.750028383150854e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 9.629831147847978e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.3077584834282353e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.2006655246903819e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.1103611517866396e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.1232998783072128e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.0352114212858684e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.0100167450394096e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 9.605802277995906e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 9.669519630639405e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.805662598212335e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 9.909010418874476e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 9.562608973078949e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.798382697930608e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.32942771357747e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.752756695156023e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 9.441434290489682e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.1643751810651164e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.1134617994752197e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.0905446888924905e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.0291181928932822e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.0134909075511945e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 9.720587092924784e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.93851423255191e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.188082916020799e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.035911367026526e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.280156261244607e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.3748749988859915e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.2644131022282604e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.3301646480532026e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.255897766579401e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.216446715158567e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.4282999992229523e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.4485190980742838e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.4248177487838359e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.3052830868441617e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.5098325987965432e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.380250424549422e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.248716661786025e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.1475077376310116e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.0578736786914358e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.0082022294186257e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.2127360486883106e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.2474164470953173e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.2024261827121282e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.510987688098671e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.3700401727799348e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.2931958876311914e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.2287328753685327e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.1290114803237033e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.0318491881277222e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.0513139590438098e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.020116656191659e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 9.771760529962476e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 9.8325275702179e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 9.533260349139176e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 9.087271741050219e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.719990318823398e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 9.084593216063175e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.782631391303573e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.712179445399587e-06, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138. Loss: 7.898889332990727e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 7.491531870369004e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 6.979573037090345e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 6.471503084024713e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 6.025322796691467e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 6.274509022168303e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 6.546855607315158e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 5.9867910900285735e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 6.530702898905432e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 7.214635477255122e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.854996156211684e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.059553137081711e-06, Train_acc 1.0\n",
      "\n",
      "[Epoch 138 Batch 100] Loss: 7.654938553978256e-06 Training: accuracy=1.000000\n",
      "Epoch 138. Loss: 7.654938553978256e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.405490057165392e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.17536365458001e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.807892536021621e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.510521032441367e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.211045042336394e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 7.943552555131836e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 7.379869962456258e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 7.339165769440969e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.926224737941399e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.376741268291436e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.672940097878163e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.695631673762895e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.311749363696096e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 7.626229617280173e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 6.9361561952613e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 6.647175314250766e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 7.144248315758772e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 6.655464754118191e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 6.782652687311983e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 6.725496766356712e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 6.125496379319141e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 6.1591515490955e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 5.573783669473013e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 5.48780650184581e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 5.298964928249718e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 4.972368741081486e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 5.0303998010059374e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 4.5881747018586746e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 5.8026095680044504e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 5.404602334073069e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 5.123221534483295e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 5.259304984022589e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 6.3536764042126334e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 5.9470269907269676e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 6.0752273332598755e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 6.322293470358666e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 7.894378783370911e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 7.362888472694996e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.559871949520512e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 7.85056435387949e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 7.612347428698606e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.196322652358838e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 7.465910146170364e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 6.88360034098934e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 6.531339958467066e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 7.951981939516645e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 7.349283869850269e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 6.746227598936705e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 6.3986552911854654e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.616168184116724e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 7.88791200628017e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.612503982295555e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 7.979975903727756e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.405971553628538e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.3755684676107e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.176794133246205e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 7.704512886167599e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 7.863723252941941e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.4964379842058368e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.368111359162864e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.279669548005401e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.2011592870917565e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.1388735153301836e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.356288890205632e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.4054903521028328e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.2798142382759071e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.164554337483314e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.1857457518234622e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.1167873231391266e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 1.0412967574574146e-05, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 9.66558267019432e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.929893266757033e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.502967587845134e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 8.472761019306157e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 7.971265753517327e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 7.218190531308598e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 6.56631334878401e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 6.3695702381191096e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 6.241896686945542e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 5.77444404871658e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 6.110766424131018e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 5.540108823342689e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 5.33932324139526e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 4.9399615041073574e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 4.800402669460412e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 4.487623162068127e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 4.220460073605615e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 3.902534372577388e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 3.6969494575713896e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 3.7764930532920763e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 3.88670798372817e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 3.533333992610134e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 3.4489379492897e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 3.1792943021625834e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 138. Loss: 3.005904566648287e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.816045158136415e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.9627745390298184e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.099668649839957e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 5.632323532586262e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 5.248087706083872e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 5.185373912158632e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.815285746832405e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.5651814641456825e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.154670073114247e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.854033956909799e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.766252174972837e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.515909273635185e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 6.013499128776513e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 5.6046472483463365e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 5.0769648905548855e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.784021746561887e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 5.066054367571486e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.78546429865784e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.768204577533737e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.8958572178451366e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 5.2625965918710855e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 5.502946560728512e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 5.195800561064836e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.991737813949173e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.542016914521483e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.904705629055094e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.869015659067399e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.61994816275476e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.513139790291556e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.383301720266622e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.189790787254719e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.994593061799416e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.309966214089957e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 5.411381217474856e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.894550404604185e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 5.354600102089739e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 5.217430968427291e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.726980173667436e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 5.154397512062647e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 5.0807129344532855e-06, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139. Loss: 4.7992097769938284e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 5.196774926432118e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 5.4972852128159435e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 5.012469204232706e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.7230909163142105e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.316066889148359e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.743812003462015e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.427098917413662e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.8996841208552516e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.435699412491704e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.013922369750544e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.6889903405406843e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.505231151630183e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.3287672348106217e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.7149849529220204e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.7025801134182743e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.4941835099089224e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.4956707930679978e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.2426795569060176e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.725543558536378e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.420804890428783e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.1278222675281616e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.981295092204089e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.781887876322186e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.711198280768798e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.399327075513824e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.064817741460057e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.123852053792653e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.348219823382955e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.170406673749401e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.149040857835542e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.8695467770386126e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.8322515211069815e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.6112517907144595e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.293618892708496e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.272198426199006e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.9731975240079203e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.9533040327709105e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.0887180964331788e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.8665500992750724e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.8599302588007504e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.69593773897383e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.6561847813224437e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.8845066456843695e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.7302563808865666e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.317241995372533e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.096351241470496e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.283170609875304e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.600440252375562e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.415304574957297e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.125202097661082e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.883665516217548e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.832511996848996e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.3166772718121495e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.708565273488108e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.982533338541735e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.6831045504926715e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.655216040756978e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 6.366473962734277e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 5.92399524972601e-06, Train_acc 1.0\n",
      "\n",
      "[Epoch 139 Batch 100] Loss: 5.57166410450662e-06 Training: accuracy=1.000000\n",
      "Epoch 139. Loss: 5.57166410450662e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 5.24340718772734e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 5.243504669909653e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 5.042646166090961e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.820742501523792e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.3697742463068005e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 4.100333942563694e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.7441306065848506e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.4485996528172533e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.1694894981093622e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.059284883017104e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.902457137134644e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.668462744178108e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.786460057868494e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.5452527165169302e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.6238371098724516e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.488575451502985e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.2789259728350746e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.2087042865456237e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.1860131399426306e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.3917740047675053e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.235297173527959e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.0839435744127845e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.0705606607646977e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 1.8957282875578209e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 1.7839195693307718e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 1.7434504034524288e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 1.8693304736571313e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.005265680734583e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 1.9116532616617835e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 1.9175450602467596e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 1.850583629650981e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 1.7083657924793912e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 1.5955500866705428e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.004217874780752e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.7458914242966293e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.567040855558017e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.369102530970742e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.2209465916387614e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.1000850592451247e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 1.960204478121157e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.102390458150256e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.3107400733127785e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.4902390318291785e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.3045442792809332e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.1325755391122975e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.325635107016004e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.1639373973260818e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.5014709393397652e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.7766298291093724e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.422715446795608e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.1026091349651945e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.2313199774802717e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 3.2311485478876396e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.9284296063238777e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.7885993863027926e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.906258855913661e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.8112053222354374e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.682069994877817e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.4909752653816658e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.3196424803341813e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.281571702469168e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.6784414374765957e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.886712495037794e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.653174649509575e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.507716285336448e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.3407630348188793e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.383834414273621e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.3467943187531936e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.1467598649642365e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.880427464528031e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.647239310765618e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.7193406034014233e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.8695418695778628e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.764922646103376e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.548127550301309e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.392497136544441e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.224679091292508e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.066099262766904e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 1.8762530703579334e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 1.94267980601405e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 1.8128580174400348e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 1.9793100570623562e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 1.8082941543913285e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 1.7276732744661525e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 1.7010247746348198e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 1.7295660581671027e-06, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139. Loss: 1.6211488391630043e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 1.7330954952865424e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.0888834425953823e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 1.9264676343774635e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 1.7763821193320203e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 1.6279871236029406e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 1.5883046740272526e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.108876525916949e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 139. Loss: 2.417115352373536e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.222714725393896e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.2706042202294836e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.079772075828821e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.8895830896307012e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.7688897817861927e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.6917440188947358e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.8108920794436353e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.675902690927763e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.603119934431149e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.5373351132110587e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.902204393888954e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.7968261109115275e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.7288063366639815e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.6020257753792885e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.47423307848726e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.3903247424094623e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.3904279727262184e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.520517231472458e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.4384059578460122e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.7177308732266912e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.0556942323785847e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.024271739616853e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.953716681726631e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.9723540281525274e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.6401753250321075e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 3.19671782773737e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.9533204884359903e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 3.1520795308333804e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.9518885059982666e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.7622157632495847e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.5445738425398026e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.4981582099339474e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.4163478541248037e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.4690662086192125e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.321153754576757e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 3.3975627854595208e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 4.119154354921723e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 3.872261992325115e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 3.5218226539390087e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 3.2240293426855574e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.997642491678931e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.7768532486013695e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.6469567996339617e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.563850149705522e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.3226456756481765e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.4158551557965736e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.283139680311105e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.261570729119699e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.177994458483645e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.0445712633327407e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.8553877902749382e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.728707887420407e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.76564049608909e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.6307062017676122e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.5075890074030513e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.3881223376913474e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.691440580507802e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.5347762279038436e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.6147688281789833e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.5021860849426197e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.3696625655756587e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.3208909424810828e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.305302958147654e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.4067403319389812e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.3851782496254073e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.3224690817923947e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.2277541607313552e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.2309825621714848e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.2817491907547596e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.2835831514299595e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.228146376382158e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.3236076477358694e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.2572772385455623e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.2677054190199222e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.1728790055270527e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.1367079597186706e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.353243039544932e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.241853612071219e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.5439412780516595e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.45753218047414e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.4624608045415896e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.651358064722544e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.5315772185710544e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.232997544151775e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.074423628647415e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.9604836477974495e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.7748660780898297e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.7152824753288391e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.5838005528075996e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.6416457688146796e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.5691209629048082e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.093415168647715e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.0223688013372675e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.912329564856521e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.3121424268807523e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.1251657563758695e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.150209810750295e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.035211350785342e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.9100119488058816e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.78261911943341e-06, Train_acc 1.0\n",
      "\n",
      "[Epoch 140 Batch 100] Loss: 1.7568953851346701e-06 Training: accuracy=1.000000\n",
      "Epoch 140. Loss: 1.7568953851346701e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.9027559703930887e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.8125019963378387e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.686757144222247e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.5452759352919565e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.4259521474999436e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.3273147329941925e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.7033941588860764e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.6591497487232702e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.5496723420697688e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.4585002778983108e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.5095202235873768e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.5177243852827935e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.491860915339068e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.683195256278729e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.5788559658051602e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.461482170782485e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.4473903561396464e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.3203463044926578e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.317855460940949e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.2076765232604033e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.1067459110338092e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.0420780923665862e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.085106288562133e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.3896581399260252e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.395873771465639e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.293446003042489e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.3512861216632222e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.5360025126019016e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.7834461783505035e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.6389083312316357e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.5379728577893994e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.539507524111283e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.3928210820978137e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.2945169227444124e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.3240380831296157e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.4652410447682383e-06, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140. Loss: 1.7782725168177415e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.212053394610884e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.0677744812678026e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.8895884144923838e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.0665834109428692e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.8954083178328848e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.8575759544151377e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.8722259257819043e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.959545200132926e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.8457314837896055e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.8986179660360257e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.8637169226394017e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.77410792920676e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.8956225334324607e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.0287192825388692e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.911992560808707e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.7698736406121912e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.709668295272978e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.705205116434945e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.6602213626693038e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.5256777731049747e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.393412719918599e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.2726045852626466e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.2568189710251322e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.1834766124924866e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.1223116912085937e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.1020914919531759e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.076166234268353e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 9.847545739018357e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 9.576178288712998e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 9.618769982158863e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 8.792865625089486e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 8.008573879926188e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 8.454667606741894e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 7.814090746669006e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.0598955234685015e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.0167691194085027e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.0509638605962133e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.0058437274784433e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.066094625165799e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 9.827681701711871e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 9.62441404190237e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 8.901320947772583e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 8.61933015919734e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 8.427008297358091e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 8.579839458688227e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 8.010564601455502e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 9.479986403599495e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 8.979013447264539e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 9.344851238985924e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 8.572415816744783e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 9.736893645620155e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.0534462834220763e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.0152638117669868e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.8342264789149225e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 1.6870320319071004e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.6308653122770793e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 2.465937531510524e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 140. Loss: 4.637250722533792e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 4.324572529462517e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 3.93691165077074e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 3.6089710295476033e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 3.7789213821860184e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 3.4659416372945933e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 3.291352612230688e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 3.097903524060437e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 2.794446158766894e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 2.530740860295155e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 2.393890329134706e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 2.384976234910675e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 2.1610072066353868e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 2.894697260001528e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 2.6686497941561414e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 2.505066237265997e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 2.28110213070134e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 2.1034690156881505e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.9433200314088874e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.7698495885694538e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.6364499833498626e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.5810192907977706e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.5622390693108922e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.5172111783303574e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.3965960866965896e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.3176580732455688e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.5061187338413046e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.3627711651704912e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.2390668749890417e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.998987948334862e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.8564580215574493e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.6967959487032198e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.5541246289159603e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.6544325175851042e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.5019345941914156e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.5272895738464654e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.4659216557290314e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.327059451182954e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.2006864945982447e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.1338888995505277e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.1003133822175588e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.0089084102229842e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.153678909359817e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.261533941947116e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.3767519150901104e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.2554679639461096e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.6142725255059367e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.4736135389955927e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.3324920399510725e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.5891391673545968e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.621408904060977e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.5452261825931843e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.4506798115913754e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.3371833814946084e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.2128713899800802e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.1232488803006562e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.0844024159716805e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.0250416746606102e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 9.397669250869441e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 9.322145346042388e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 8.944984002402977e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 8.896102284617099e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 9.892323294879156e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 9.874436536479263e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 9.251137053648208e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 8.864316939318131e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 8.086849595817825e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 7.897484257600454e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 9.026983156462528e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 8.32638104369997e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 8.966069569721736e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.0717032839804093e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.057756594524077e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 9.813174029044328e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 9.262124728176176e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 8.992470284635779e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 8.198462593416912e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 7.513657837388227e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 6.964388228111389e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 6.341523796324317e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 6.619109841894088e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 6.331588031589672e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 6.476987502281355e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 6.341510142689334e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 7.148959162433791e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.4768257963653517e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.3773851121849746e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.3003668660491137e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.2086068437711885e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.1095389840056358e-06, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141. Loss: 1.0570713247456928e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 9.774410538301002e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.2234081839202555e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.3474628270732647e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.3080807814064232e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.3212484089344895e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.2279595488722495e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.1327305659790443e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.0440443145063217e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 9.471835902257331e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 8.61778437054118e-07, Train_acc 1.0\n",
      "\n",
      "[Epoch 141 Batch 100] Loss: 8.789742841116708e-07 Training: accuracy=1.000000\n",
      "Epoch 141. Loss: 8.789742841116708e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 9.064622429897834e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.2465350197785145e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.225253230412651e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.1443577763456548e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.0666158267760157e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 9.755072756721592e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 9.103662013771684e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 8.779078328221821e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 8.517695807979691e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 7.753470314716475e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 7.354375784400077e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 9.377294210011236e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.031608700840072e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.259034989470544e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.3170461780916662e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.257516473439641e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.2858889578638621e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.1669857699576562e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.3513616806138217e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.2635360683809567e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.1680091478131632e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.0865051198674142e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.1147536603304078e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.0348498851501307e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 9.412368626353365e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 8.603379327728896e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 8.555144334518471e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 8.036766456184092e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 8.671864044540666e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 7.95089495745157e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 8.030301215739392e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.0021160601467537e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 9.923337331303502e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 9.641576972536019e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.2438400419578657e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.179525661703751e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.2767845076024145e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.2893513676734062e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.1948749046871114e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.1546417033942787e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.1425516671964826e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.0923703510576603e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.0026909464891869e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 9.184404636994492e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 8.453158959189505e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 7.710288013571206e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 7.51666835138268e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 7.173847124279748e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 7.140955627737368e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 7.14397048933891e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 7.061934306298153e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 6.52337808644784e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 5.937164116651909e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 5.352760928956516e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 5.150895816662775e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 5.156401854942605e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 6.551650510387496e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 6.009175263503544e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 5.538642499695425e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 5.787566769830397e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 5.423944555980284e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 5.62939394234617e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 5.161449251770366e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 4.990819402698914e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 4.501982008973436e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 4.5640065061108404e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 4.382343258105508e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 4.799964762945356e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 4.4233449290083093e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 4.283688368602977e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 6.328801104194098e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 5.760182166158028e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 5.272639452022148e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 5.217543944501764e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 5.39984991916822e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 6.270766786595848e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 5.788976088515765e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 7.042737020143504e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 6.736134163715771e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.3514329616862766e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.2227157870192392e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.1322020409476345e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 1.022520859794239e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 9.361012334248252e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 9.051684997606988e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 8.570264204991883e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 7.985182896255456e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 7.352439570164115e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 6.730816334867758e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 6.591370542674272e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 5.944340678324132e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 5.67214243074098e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 5.563129458370166e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 5.655938911032606e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 141. Loss: 5.090345019929346e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.272338737471339e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 4.828923795963615e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 4.4866608124953874e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 4.123676230474789e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 3.8528692692866405e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 3.582134592710039e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.827733978775541e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 7.441767271233494e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 6.828906842389815e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 7.749682804738786e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 7.287637374563399e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 1.1408687286450618e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 1.032649172368693e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 9.507114184560822e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 8.697031764328942e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 8.048982849063762e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 7.429416477528941e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 7.019886378812147e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 6.996825531362704e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 6.579331728815264e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 6.048989578125801e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 6.424755101489286e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.918252204065158e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.533180211530201e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.330968356740205e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.08378439666339e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.607274080388229e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.182519214019932e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 4.952974960168564e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 4.7622173028319926e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.458475442186548e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 4.978751743922174e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.564878520842486e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.857720874923415e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 6.207908875530893e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.805046290936885e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 6.62149028084672e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 7.418602537015492e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 8.6686352698665e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 7.948919743330975e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 7.954938353073488e-07, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142. Loss: 7.699600583419857e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 7.988498813238862e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 7.553791994285179e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 1.312254418586784e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 1.2734110204318705e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 1.1909592742655592e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 1.074843576768509e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 1.0081505851099694e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 9.120852642688127e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 9.385932851073766e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 8.545128272876186e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 8.39745864111895e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 7.762601910222202e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 7.077611025978922e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 6.929564729439794e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 6.533698111435073e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.92223776641127e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.862719929574289e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.721609696515698e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.42884308340347e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 6.280049193279488e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 7.023828766172735e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 6.424822297433848e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.898755133722014e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.399217654292129e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.256030239123801e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.956953125381006e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 6.233885294228184e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 6.779244522934396e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 6.134847662010832e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.752328648999343e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.351251513936776e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 4.841272050741434e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.711188393175191e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.284424112386575e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.353874082085909e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 4.894854805251556e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 4.671724028352749e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 4.981263738810362e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 6.598961282776919e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 6.37119379847824e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 6.254669583829172e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.732579246487462e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 6.040317689252616e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.532211974982493e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.652330064034134e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.66078505607043e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.60692350731283e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 6.062258156004595e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.596661764953978e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.227915295169282e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 6.187716999611405e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.739376449731906e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.659032493347305e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 6.639991466325059e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 6.124072111676499e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 8.031497051446724e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 8.357040048270299e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 7.656377489912856e-07, Train_acc 1.0\n",
      "\n",
      "[Epoch 142 Batch 100] Loss: 7.280959920646135e-07 Training: accuracy=1.000000\n",
      "Epoch 142. Loss: 7.280959920646135e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 6.736333807870599e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 7.709114688896873e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 7.247400609476959e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 7.131736815284701e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 8.802498813728869e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 1.3411481012791597e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 1.2549026462088719e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 1.453208366101693e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 1.31729386404723e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 1.2220718990839633e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 1.2118069427915586e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 1.1135365706851227e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 1.0595515486146666e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 1.4134171334598289e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 1.2785946724518123e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 1.1595827611389654e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 1.0676523999716694e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 1.0701253976300202e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 9.64230444778921e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 8.788901062539873e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 8.858988300991668e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 8.390317493690146e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 7.681670506863366e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 9.696800988182264e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 9.218847840077239e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 1.2082049220567868e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 1.1450323990937883e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 1.0383522425210983e-06, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 9.432714305751775e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 8.695263714659437e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 7.925388659725383e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 7.20363015310422e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 6.495374324158372e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 6.628126538137464e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 9.026241495255404e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 8.462612623800662e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 7.856630283512925e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 7.207871190461048e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 6.88009546195754e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 6.368104816550007e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 6.104747979792388e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.742002542393855e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.265590973747985e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 4.909463452780467e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 4.472533791961123e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 4.117481120278268e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 3.7811700302128846e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 4.193715424967628e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 4.347097318261084e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 4.1126210589043116e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 3.808460708034148e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.758487440444157e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.236655331120452e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 4.808915710554998e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.034886150201523e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 4.7139362766369443e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 4.3254300170535145e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 4.93591441135642e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 4.464674703129765e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 4.148591938515605e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 3.8566671255613216e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.563579465264869e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.590217797546805e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.637479112631579e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 5.10819012241834e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 4.772458446805583e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 4.5084844201087204e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 4.1787075291047836e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 3.7990209662264035e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 3.512250871269926e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 3.310968150221837e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 3.1763798300093313e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 2.95559914607845e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 2.739201515309801e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 2.8731929207554357e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 3.284357487876023e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 3.148703948839806e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 3.3460545466880073e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 3.2284443386793966e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 3.016426950130186e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 2.747380527465141e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 2.919672905169095e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 2.7180437622813396e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 3.3691638002793507e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 3.145868518559119e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 2.944902843170611e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 3.007103875336743e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 2.981128844045741e-07, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142. Loss: 3.4233982502283165e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 3.28967377242465e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 3.2885304066745243e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 3.2390726320411156e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 3.09397859262044e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 3.189702642710998e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 142. Loss: 4.3012203198738646e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.050841910538973e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.914150055676104e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.403759986202348e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.935095697929812e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.832732770323699e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.299355313959064e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.948233262141979e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.36608411749127e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.293267867750902e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.951135454755488e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.450625988376401e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.978206394039367e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.455461618242775e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.995596877487737e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.120004442716272e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.302756655626753e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.913109789336313e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.551251895098934e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.1454867665165244e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.0233712182442154e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 3.934884858687769e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.288393472690797e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.011010026856101e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.6570568114587946e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.458636502814562e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.172028586466711e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 6.186214748605031e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.73802436698275e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.388667757541589e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.260511480287042e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.01292262725862e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.870186514636808e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.563842396285451e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.242499517861364e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.260625003690056e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.1344455017545823e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 3.8886386455276877e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 3.893721700505127e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 3.5462590036797467e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 3.2437871177522476e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.9501420367284787e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.9019273205689027e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 3.171444335506498e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 3.051739520388175e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 3.045518182124685e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.8517935087069284e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.619699509062181e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.385669217630859e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.3929702050110445e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.6565726523568135e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.473802748095969e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.2292164407881742e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.0482042805926303e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 1.978425256370389e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.3822080758313503e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.7493288655410786e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.355443616639926e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.0130313987506437e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 3.7896094353308096e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 3.6118127041966365e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 3.336313011165614e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 7.984514881817865e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 7.37884604392396e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 6.690321443615628e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 6.089275761935867e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.927380293073605e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.645699399370886e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.225484060595265e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.980465774310122e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.575551262494119e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.249519185724872e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 6.469698538643505e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 6.146823739572515e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.91584134940111e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 6.063700622298824e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.508553259040229e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.819142892946094e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.309871664995509e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.002401149017519e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.973404885168118e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.7014413617419235e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.00892343787932e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.630965361301827e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.756635788494641e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 6.169054984356251e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.595921554556997e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.061475090852348e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.681986997167467e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.6887564440417016e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 7.125155213571044e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 6.426609518398674e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.899432381070015e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.445461897796361e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.327458235537449e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 9.017203000274089e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 8.22724102550746e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 8.119758619936943e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 7.488457831068051e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 7.219240502247531e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 6.544813853590176e-07, Train_acc 1.0\n",
      "\n",
      "[Epoch 143 Batch 100] Loss: 6.024442506861001e-07 Training: accuracy=1.000000\n",
      "Epoch 143. Loss: 6.024442506861001e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.823394704698784e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.559562922008763e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.377060530500654e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.999540951313766e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.787362860097886e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.183098283354897e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.71601113977984e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.734394950575891e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.191689089822473e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.850401058867507e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.376536820323428e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 3.9491276848354984e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 3.861549603829072e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 3.6523440567902834e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 3.7145792947935984e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 3.394344028758389e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 3.2048520345940176e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.9244136769740857e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.754906604908826e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.5315699730692735e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 3.5002211095401595e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 3.152992966087945e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.9112680320815087e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.730968302613796e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.502574934617677e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 3.02993705963091e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.489774869984329e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.2754896486074576e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 3.858185230291125e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 3.4919244742235106e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 3.4593767567929816e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 3.170249687110954e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 3.0599763546556897e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.952349972835867e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.865729995921787e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.6909152931686796e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.4329996329708403e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.2129827198282888e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.1369699878884653e-07, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143. Loss: 1.9744956703073375e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 1.8124363362429962e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.1964853828400152e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.3484295496067298e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.6034537992243883e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.386880558992595e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.7190761314635467e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.527262153152713e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.392813393222838e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.8687662475494937e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.596790773330251e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.940597639881378e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.806724790292914e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.771919822502962e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.997636971480746e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 2.726744251053112e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 3.199110150493499e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 3.023553509231941e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 3.943944663245115e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.5991273190236776e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.193231225394734e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.222039673069433e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.019277643553033e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.329422180157428e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.06842243068547e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 8.948781630640437e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 8.270900973762484e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 7.578851768632487e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 7.317354248081675e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 7.380000485945602e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 6.71836873215011e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 6.074471525515422e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.697990921961338e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.430869762260704e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.71104931831401e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.179991211005797e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.001921106395932e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.628388595897804e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.061457553574585e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.660550808612179e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.383760322109936e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.5419845855677e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 5.140522688187356e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.6832810466821737e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.708544811613142e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.261904710286403e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.0732003447054775e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.2237359954364324e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.4914439451300097e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.1223929154462896e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 3.9057299008528757e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 3.577555423790842e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 3.4787046297187897e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.942213259688845e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.5271540967668913e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 143. Loss: 4.2592123980885446e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.918041242563459e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.5783911469584434e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.608905644642032e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.2852679334244563e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.328336118869481e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.4015561083919726e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.4283334917640867e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.6377632311811413e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.887719958221799e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.833289299238025e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 4.016185565821953e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.85670948597602e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.490596304339916e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.291479423677905e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.0340432342903785e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.8703368280954566e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 4.056576900722732e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.71704302818303e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.5790978636331236e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 4.008122854167208e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.7479397801375096e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.6348435802382254e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.715590171129395e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.727727357714947e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 4.0366564849024695e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.642304057717485e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.2883181949374365e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 5.235323607889758e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 4.754631996715253e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 4.3089710732461454e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.980518902011327e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 4.3908367029955565e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.9638602243896454e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.9101986925158416e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.5704015115774034e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.6361780576294455e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.525878883715243e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.7264889876471857e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 4.787952253016162e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 4.433953826387378e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 4.037124437476294e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 4.201506429222214e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.809295449327602e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.989938523912234e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.6254035463856504e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.5478439205401016e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.880365754640852e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.512818258054739e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.901920655512656e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.810681857436035e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.4631412630623065e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.131728292620853e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.0215826193348557e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.764127816113917e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 6.71333974153522e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 6.201260961302824e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 5.694755920847681e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 5.233313321092667e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 4.899970515228034e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 5.0600124054904e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 4.6210663121539736e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 4.261404766242347e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 4.114659669338994e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.7497597671870227e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.5917809698047515e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.860294961352696e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.4891666210822036e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.5435053009814524e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.270179742504298e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.110798367966619e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.8397653841148545e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.8193521111380103e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.5951588037271e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.538669780902528e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.528806674142554e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.13178269002998e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.0905483959213665e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.9463370267585624e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.1676422743123175e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.110713691437092e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.190791437168971e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.8977892971195986e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.62756813792185e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.3992702416268693e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.2291922755572237e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.2232689199392985e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.1899996863627374e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.1209419274859652e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.16216642342953e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.0325626455226967e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.0369900361327545e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.270071713476351e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.2228085484742883e-07, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144. Loss: 2.798657952399149e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.5681522003231496e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.3169249144062597e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.213754682467185e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.0855112940463306e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 1.917938322397642e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 1.7671225981758306e-07, Train_acc 1.0\n",
      "\n",
      "[Epoch 144 Batch 100] Loss: 2.5300971946854183e-07 Training: accuracy=1.000000\n",
      "Epoch 144. Loss: 2.5300971946854183e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 7.273653551659708e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 6.796811780593675e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 6.180460423921323e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 5.717943858826214e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 6.358642675672684e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 5.868063862883293e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 5.333411462613729e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 4.823353366506888e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 4.3419493523753033e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.9403506788276053e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 4.79419088605701e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 4.426530108501234e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 4.110536385153773e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.744186194692802e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.429372116970216e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.608893568272464e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.3066774768025736e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.170655408252506e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.888980107499075e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.79492439474044e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.432195758056761e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.111327918712786e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.919404103753485e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.636776917347935e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.5072089800258894e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.5908271735466617e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.388555055083839e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.590203531311129e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.254072974764075e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.1726709697034176e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.321991650924828e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.749727150361628e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 5.286613707111409e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 4.787754623260827e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 4.710371403045632e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 4.393001833853306e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 4.7564814735294037e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 4.323674125528925e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.893169358014241e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.543899268052287e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.1969599209558037e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.069114730771865e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.9540543580342693e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.2360566971573843e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.138760224601581e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.9711009226504964e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.726144866142204e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.4824013615774953e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.2509250282101107e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 4.0446947583333295e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.7100743974364565e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.357693402079693e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.116918559473143e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.869487783538613e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.5974401628258854e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.860162881308045e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.7110504858440914e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.520039050778921e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.3229830852327865e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.133525572509256e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 1.9564945672466246e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.497503020305351e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.5105500729589695e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.288017211477786e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.000193630322383e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.9469725042482015e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.809667916282114e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.7540797097819584e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.535482337695606e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.28752203848556e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.2673850823801866e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.089075276967899e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.162356215642845e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.0075878342651906e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.143033118091437e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 1.986471763275889e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 1.9023767591406615e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 1.792232710956689e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.0218555026437065e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 1.8708926229289135e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.2099831075207586e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.5684326226299625e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.3298670004934736e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.0183007072257844e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.7881822686912047e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.5997020899752553e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.7616120260183615e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.6176981742645723e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 3.0106235704358487e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.8995504501796325e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.873157249510839e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.660347202631301e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.649491428785971e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.517720930908327e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 144. Loss: 2.2778697651738513e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.0556707232159808e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.8817685829041723e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.7457457035270935e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.5897975793376232e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.4736586314144635e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.6829836584305689e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.6832532432965874e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.3177087652098963e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.486401934613216e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.3150614011581417e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 3.143364880661373e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.897014798433619e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.6576046345907963e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.4765941772557847e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.244767236193242e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.1711642580708558e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.1328608144626762e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.077898220669842e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.876627656181077e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.7690584543442166e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.6919702183388053e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.4292924527508764e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.2003330434304857e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.019415244588723e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.0316757238197847e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.8536538467415695e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.2671217152743888e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.0757997660552014e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.0302692068900387e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.2342199342274758e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.0378062741522951e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.9103939912741246e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.9605663431642572e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.8539162852124128e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.6843571315778504e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.5615561961545142e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.6121534775609636e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.4909849720916232e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.4918282298946118e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.1547402747021372e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.4002592971874283e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.558836331437782e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.3280983935977672e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.2647876143588605e-07, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145. Loss: 2.4471545746451474e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.3486561787502195e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.611103343829593e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.3648941670877676e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.280209875293963e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.515046430280415e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.3091765578813954e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.1462453292479205e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.955835161946849e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.8682848228230294e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.714983928357888e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.5630432971545265e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.6667187075371347e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.4857282649580877e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.6608987402429115e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.7682615163561716e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.723332909442969e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.8561163266784484e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.6217273077167627e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.5923842542608355e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.384368510042471e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.2223000319969922e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.3549001212167267e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.267490057398402e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.5427099358952653e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.335936329662282e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.134007642916698e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.9494778500163988e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.0339235404811088e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.6733681688617053e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.4553914057975913e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.216371521907873e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.0357125416838847e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.9494872497960203e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.2024978335744908e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.0148443048014468e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.8385055731777791e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.9675768998203722e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.9170362287753578e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.776555262236545e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.7683997624718815e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.4977037958294527e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.2656285327297038e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.61926600102165e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.529633650897707e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.3437254401259773e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.2723330676941639e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 3.037829030380342e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 3.2052813666167e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.9564649758298665e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.9960916492506713e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.6974138068447087e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.43605432755542e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 5.197312523830174e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 5.089215447081547e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 4.662250153936435e-07, Train_acc 1.0\n",
      "\n",
      "[Epoch 145 Batch 100] Loss: 4.3990524934708456e-07 Training: accuracy=1.000000\n",
      "Epoch 145. Loss: 4.3990524934708456e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 4.0364467904431704e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 3.672848960791037e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 3.4778580873164796e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 3.1654625186566515e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 3.2558979507001663e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.931239478149254e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.6613985840415747e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.773371939265657e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.529562322498112e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.6752083720963713e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 3.009309298849346e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.7270048151276505e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.4785187134494606e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.4113417731207706e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.1776581750733498e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.043711289805425e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.1960343194790188e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.1729383165266907e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.0580894564909546e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.92119823214943e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.0531742311140022e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.850650775504404e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.7698935278829482e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.632950956985277e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.4826943737786522e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.713639772961792e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.4776660179738645e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 3.349286736790374e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 3.1168033544725007e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 4.326833847481231e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 3.915570876620193e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 3.771742637948111e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 3.807137169280599e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 3.6229308102938395e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 3.340731129620873e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 3.069987880678365e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.799310619729827e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.523104847833262e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.335986879324173e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 3.672455375212112e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 3.8211459457495687e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 3.457657795561494e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 3.207818077765909e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 3.282841884051147e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.9610769527801625e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.70781004974918e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.456586815288474e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.2137221012614282e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.0044570819407515e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.8738604389451447e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.9474335472556625e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 4.997437792166417e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 4.5582299376672175e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 4.3967005289574443e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 4.269951109466856e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 3.89697262258274e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 3.721478046135426e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 3.411728775861419e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 3.349019728047868e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 3.228320327367204e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 3.0926825405124664e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 3.060943638849448e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.804209293259423e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.71470818433102e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.68631093783512e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.502430006495078e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.2801266546623252e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.1778417978047373e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.5365317966394354e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.391843088199263e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.2094694066928895e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.012736845858176e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.1849159819401662e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.1135727678903517e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.9580947745239716e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.7743924887652187e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.6919480146017833e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.5646626863667373e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.5695016670276476e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.5248911715043896e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.2956851098375535e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 3.7656173842885917e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 3.394643580419247e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 3.120371639175577e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.892153251178028e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.6234270120436243e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.553867231133383e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.341321300267079e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.59332562755203e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.4932485855676117e-07, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145. Loss: 2.2700007448892291e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 2.049519927534436e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.9572576678815165e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.7959908043797145e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 145. Loss: 1.6193719560028772e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.4639540175367195e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.3957895273096365e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.3726254771853937e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.3024180269414766e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.2653082401243466e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.358567895262018e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.2469254820176777e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.373688437346361e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.2568086795951243e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.047502101863007e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.8893179635640615e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.7255318642877756e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.713165038035338e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.6070408728703578e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.502216015715272e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.395766525412681e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.2414759513745356e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.2278066328225728e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.235061380704269e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.086060878072824e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.12239026838753e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.9436788187077976e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.8368549746337787e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.6680706321469997e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.5059201809171987e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.3553281628254787e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.6928939983527088e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.1401275236738977e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.9549857426978784e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.8749709260958798e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.722864070005398e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.6250833552872587e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.585508860643331e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.5023949041708856e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.3651939262457e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.3255316337392163e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.2116049094231064e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.1155901066791316e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.140934562352428e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.2205550079254086e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.1068814085280502e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.0017812022347597e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.1362954328979732e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.0701632840701464e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 9.920179341599296e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.0008490833356992e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 9.22184587112858e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 8.998151793891859e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 8.7223212473553e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 8.00841387148656e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 7.440403021410363e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 6.87331388410129e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 6.362933731577396e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 8.837209724946417e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.0617054831260575e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.303842671244249e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.195810128147027e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.0911302711971016e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.0034376490826928e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.405066747450447e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.2673540399851596e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.219780948247549e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.1471628646122863e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.034309223078244e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.379769017368236e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.2939461229664602e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.1813153099074654e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.6415262870230077e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.530672546430273e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.4098522163096513e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.4585031142112743e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.2201033807225355e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.021376094581171e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.8834995793466927e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.7081881303512127e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.5457512195994525e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.4479865863972267e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.4028391945514027e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.2793190761102706e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.1597690707826044e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.396758104623947e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.436825874181483e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.4253902681291593e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.3312799832218253e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.5287696230553153e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.2308005137038404e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.0831574771904725e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.8804296640309397e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.0276593570408675e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.835137966993016e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.610842539028297e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.385148514539146e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.586207231740991e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.3415563391925184e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.1446535549671807e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.9618531172693974e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.8848767469272982e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.9711261053580974e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.8215108857315445e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.0938337027784243e-07, Train_acc 1.0\n",
      "\n",
      "[Epoch 146 Batch 100] Loss: 1.9934147895134984e-07 Training: accuracy=1.000000\n",
      "Epoch 146. Loss: 1.9934147895134984e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.0911601812219172e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.1046289794559007e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.1782177330437565e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.9771597625297458e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.8846829174640894e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.8573324221554735e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.6892942964231224e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.6675128672319351e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.6581535892681578e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.6543876477816996e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.1725161195958826e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.9925173928573452e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.7988535872429467e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.6534270891724377e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.5560708145152862e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.4386479373067102e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.906652070656689e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.729956696881182e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.635191867665379e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 3.9030071320017256e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 3.92434124813526e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 3.551464892059589e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 3.5381067107318626e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 3.2681149292655225e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 3.0055645589843185e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.712458681906454e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.51664981436197e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.2854739224618865e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.1826545804088726e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.07521626005727e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.9477881480947986e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.0370576879004705e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.893887815406156e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.9550211684582973e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.0649886496733488e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.529028054948119e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.5229238558935866e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.4093975391621044e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.4478505217477986e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.2496315094859507e-07, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146. Loss: 2.093586030106935e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.9186863410407322e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.8897986601144527e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.720376553959078e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.2784635668432113e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.4045122851814823e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 4.070261907162197e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 3.7684747197356027e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 3.420498212047986e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 4.087016851590671e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 4.53696991018329e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 4.1968937616772796e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 3.820976475462206e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 3.4463294067365526e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 4.384041931432769e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 4.1412145410423316e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 3.7513074596672463e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 3.472102562298266e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 3.2850784815036677e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 3.003136694582515e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.7400759032398867e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.7035539067728437e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 3.8235469320483174e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 3.774601684673088e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 3.415767957039948e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 3.390837767160597e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 3.12253430005792e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.8540529884264913e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.7297654291782166e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.4642394659691404e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.2597249997027861e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.0384091117174067e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.8531946449325482e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.7088533381952378e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.5668389793197982e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.4688283289816063e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.445810517434312e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.3515208349821253e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.3821438287049547e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.0588029336321998e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.120209035952166e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.2341491007961256e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 2.078720518395195e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.9770188279470534e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.8752430140183406e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.7473232792321962e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.9935423033071323e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.800707330110549e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.8488076436007963e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.7179434251435851e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.6010970718989758e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.6719529473684155e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.5252467279568324e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.496587644946204e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 146. Loss: 1.4005730202484991e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.2968372773173707e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.4847287210790786e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.336255848971171e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.2240506744084258e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.1249286500166881e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.3505000815717142e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.2685352931900822e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.1537889555647183e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.3513311765824627e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.3866293226926944e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.2572796135050445e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.2293399540549766e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.133414288444332e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.0722267674589638e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 9.70592025716671e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 8.921592622028156e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 8.122565581759751e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 8.027425558626583e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 8.332952532245657e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 8.91525906592379e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 8.86192027904303e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 8.55314739474904e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 8.126240613271615e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 7.602326407966705e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 8.890993483725786e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 8.122966034526084e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 7.53418676016335e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.506920930639538e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 3.7001080971453877e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 3.869318278844307e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 3.498218929399269e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 3.81054828762221e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 3.4360127155500297e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 3.1305956411325517e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 3.004730450798972e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 3.5545208671351093e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 3.4225831003629854e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 3.2358548929013176e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 3.552994437529174e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 3.2116648270664185e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 2.945446266127966e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 2.678841306095493e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 2.428652290192783e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 2.194168963456866e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 2.0008290565678485e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.8659386103418822e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.7976219773194146e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.708197721159234e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.5587983504958984e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.4699736484480676e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.6088881360189265e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.4684884012950059e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.3486479016184996e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.6226278952624117e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 3.0304733305049446e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 2.7618848900826584e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 2.5071167989742665e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 2.292726681723275e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 2.1649677762801026e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.997831059579576e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.8520645705787605e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.6677894360399888e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.6742357381391691e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.5114687767542405e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.4441407460530982e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.30624592769374e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.5490737008448232e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.429556524646883e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.3508620303546796e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.27817424797191e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.1987855046841684e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.5240724657802342e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.6501272015636883e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.624812142846051e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.4856139751632644e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.5465990626996077e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.3984584135637768e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.261406539709201e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.1678621580862543e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.0808782184800463e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.306200979330021e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.5909445537428665e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.458858417505292e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.3148352207929716e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.220604555513016e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.2866695831531845e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.3414713104151477e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.2622721650906683e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.7823563831749732e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.6264724759901062e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.5699957247855932e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.8944820789914334e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.747874645575756e-07, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147. Loss: 1.7817010076758912e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.7013195072366877e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.739802477406543e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 2.4300598498009885e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 2.229894667726065e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 2.0944493098044928e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.9380896838647112e-07, Train_acc 1.0\n",
      "\n",
      "[Epoch 147 Batch 100] Loss: 1.8104045259053833e-07 Training: accuracy=1.000000\n",
      "Epoch 147. Loss: 1.8104045259053833e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.6898999269780134e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.5879650601765436e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.4710780415948765e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.4562172188012134e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.3310845846808483e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.428010386297485e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.30476710574745e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.4033928068811867e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.3263833404746555e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.344618339809341e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.2362335237067853e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.8334252518488003e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.9164379418810382e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 2.018157518621935e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.8470753833003427e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.685650891572127e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.645607891386209e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.538789030819474e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.5041186925347174e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.398410214492233e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 2.8584354023327674e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 2.578179796659005e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 2.3250184285339142e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 2.3113744348573796e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 2.357766599555255e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 2.1834571442592227e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.977218617974231e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.9536531112917818e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.763875734722118e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.7644375888048795e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.8487614223326203e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.9972921679751118e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 2.6617939206326943e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 2.4468371635918657e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 2.2543074261460178e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 2.06519819643986e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.8596096993149783e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.6866872418753835e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.535713627065614e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.4380215335708533e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.8436846357309022e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.6611788170849986e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.5295198280047075e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.5069523661619415e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.5034054000031121e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.6659865165894965e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.6549177685532113e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.5397173609891346e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.4732897408466827e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.4237493741958276e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.3316658096202027e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.219919621228986e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.2767396465451635e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.3818952881521225e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.326593177155166e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.221873511809118e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.216100828755824e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.1540952769687945e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.2156350773509053e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.101522148880471e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.2670377780997984e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.2083203137576458e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.1387109813531685e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.0276338507196535e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 9.472221985566755e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 8.82302283325135e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 8.052479214471152e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 7.573193980976633e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 7.38398092706877e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 7.865612280720133e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.623342331732287e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.475909256200192e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.3339062651396874e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.247081721171215e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.334712438636591e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.2617770342252456e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.2808843308332473e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.4787541945484124e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.4240108051814435e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.353321463432708e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.4033220831122762e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.2667151646554212e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.1447002601747782e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.0442000638947484e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 9.658570789363659e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 8.953483711575397e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.0619255936018954e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.0740105322596661e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 1.0001370704035747e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 9.187498024210289e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 8.34325400999493e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 7.527555059377523e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 7.333592281084911e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 6.721304952149296e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 147. Loss: 6.078976777545705e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 6.411710423733533e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.1162713484140881e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.0074381808524366e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.1851575388404666e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.0722297195159344e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.0087788730441317e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.2767016557428296e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.1844217302403664e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.0669108797354342e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 3.2510832409232975e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 3.05263393432739e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 2.7762415264968766e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 3.0667035670450033e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 2.7842475848460076e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 2.83643941291383e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 2.5770098407988813e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 2.654578986599876e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 2.6442995227669187e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 2.486039938987032e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 2.316598193400388e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 2.1873832675175813e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 2.1418692627634459e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.9667978419883873e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.7747746702185366e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.6326874148467934e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.472212640863916e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.330579311781128e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.4070679651316678e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.2821936470578937e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.1632875045455454e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.1801372285616875e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.0686427628396486e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 9.897181495832935e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 9.149607073541119e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 8.644427872692176e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.7474800702390348e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.6155728661203064e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.5173453156301623e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 2.357426807155323e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 2.1682501556945817e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 2.1330324026866798e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.9402182430723408e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 2.2416469544742033e-07, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148. Loss: 2.0482158755673844e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.8880977431704796e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.7980075720122017e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.6424211928691997e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.523813805131451e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.605192543435678e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.5024151679260046e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.473245045820937e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.3994948256815e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.2679272445085324e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.1625549357211216e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.7838771921364043e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.6399483548928315e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.7572102937184457e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.62898667657214e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.5228985189889274e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.4441829728489737e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.3835835509600676e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.2564010596540193e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.1568379768960666e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.0728191218743904e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.534554839146219e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.4462917151864323e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.3137697291441845e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.2559670975158418e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.1489968321511399e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.0909077300643007e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 9.874048920614743e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.1531568023929572e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.1244537876378151e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.0492612692260887e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 9.55511007869795e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 9.15839098134915e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 8.577827477168754e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 7.813176960268075e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 7.544086111845591e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 7.022508019969922e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 6.348196892990949e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 6.104532329758987e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 6.686170002771241e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 7.163075932340384e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 6.58646668977153e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 9.364370762547685e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 9.53620286050328e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.2447516973642176e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.2255156090771223e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.1886454123952304e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.0884073155425897e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.0093688690725324e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 9.382342832366925e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 8.853889877999717e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 8.02438023579489e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 7.417519846303242e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 6.796839769727578e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 6.163721908162917e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 5.7243008466514514e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 5.179810434783878e-08, Train_acc 1.0\n",
      "\n",
      "[Epoch 148 Batch 100] Loss: 4.792214516224521e-08 Training: accuracy=1.000000\n",
      "Epoch 148. Loss: 4.792214516224521e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 4.3502459653662425e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 7.333127469196582e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 6.692946944211334e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 9.05041054268021e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.3453789360974997e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.2117723650068542e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.2768576396987497e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.2367159916853364e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.1558851243677044e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.1772002203806906e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.0790379617514056e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.2179308109185939e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.2824004683929908e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.1588170335385908e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.14165501860863e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.059154466521125e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.0622032068756897e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 2.257874074820119e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 2.0572323608655137e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.8841053971269358e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.7599559942704454e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.6258698538576784e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.6076366454038044e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.4645681026756908e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.4447708214953134e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.3058816730171181e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.18088144071901e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.2425370045647325e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.1322531391747777e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.0395169076879858e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.1208963629045884e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.0739992215720848e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 9.94538941126204e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.0049806987034234e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 9.044826288330811e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 8.401113838281517e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 7.626195025794664e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 7.059153157303038e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 7.107606000623235e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 7.262974044922108e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 6.592555986025043e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 6.259262720103767e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 5.754408365029834e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 6.15685218177951e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 5.839189725625734e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 5.98169930592947e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 5.5139144558466326e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 5.4468103937906505e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 5.36779014433941e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 6.004472742230369e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 6.335345768886057e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 7.173286933252287e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 6.912305804108728e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 6.276954573733891e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 5.6771987891580745e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 5.1746714815835667e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 4.759649745578639e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 5.205692556696081e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 5.234602980561143e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 4.8787807104086785e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 4.735491316959939e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 4.355074407198356e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 4.18965028219062e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 6.229344734424764e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 7.832246345317531e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 8.054845259679893e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 7.416998726088416e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 9.320215459211425e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 9.217067594092926e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 8.341926958973516e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 8.057213836029424e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 7.614707972309425e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 7.281644848858866e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 8.071522944501325e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 8.642723797225685e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 9.575885370291314e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 8.767308418555306e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.2174620492669397e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.1031664222726343e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.0096135792830222e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 9.384545224261332e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 9.8058165448661e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 8.946306807315933e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 8.601155592956189e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.4241477768418296e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.4074607509228722e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.2723026103900995e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.1692867238565941e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.1212757656730783e-07, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148. Loss: 1.3406955582203304e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 2.7311243184283735e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 2.464531143275577e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 2.2394984428351048e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 2.0490761792633284e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 148. Loss: 1.8501290250151741e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.712613552502764e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.6242395298056153e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.4776480534880897e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.34292175707847e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.2244620527045885e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.1094664262546966e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.1233160138678711e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.0296108533152525e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 9.555207145061019e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 8.711445121745206e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 7.896179959606722e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 7.274199920495426e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 7.059005852344652e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 6.474177166283063e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 6.115469021459914e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 5.764692262570573e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 5.7563281725806655e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 5.515970807168572e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.001198632989993e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 9.290184060732508e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.7301353053934858e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.563641031988267e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.4491864020145728e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 2.0651460839389065e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.9210298535651504e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.8034323686444972e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.7329848332078787e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.5745875030873327e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.5931474261931458e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.5791177262369216e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.5767361272421334e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.4395516040540333e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.720274904934651e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.6432421180999988e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 2.4623639633245976e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 2.2552430831515648e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 2.126575924692486e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.9595530886414046e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.7691857143367785e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.607168298767878e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.4697344977293404e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.5369628526943745e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.417725445842291e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.4268264478030336e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.3102208226774659e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.7146952941759987e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.6102807343353285e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.5982635907192458e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.4812780274470693e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.351776665536531e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.2342941243478585e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.4433403340576297e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.5867821340371066e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.4569749026829074e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.3448049966790645e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.8007716406335993e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.650496742114516e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.6465642532741047e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.989473060457082e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.8128774837676474e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.6660486457826596e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.5022377487061957e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.380884950556017e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.2744613839574913e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.1637790412466797e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.0921045674128496e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 9.987265873346004e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 9.584585165331122e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 8.700632437003679e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 8.920212839726921e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 8.074757675603219e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.8181627601933833e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.8254042136456873e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.6735974230325746e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.6207899310813798e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.632866724654027e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.6353538646435967e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.501620782803364e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.4315522896205567e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.3079548240672852e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.3410707931833925e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.2367659829620433e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.232298276312688e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.1146563827968445e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.0125039675987796e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 9.68995485199933e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 8.842031274854057e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 8.004394267217642e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 7.241207741260051e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 7.010686688230461e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 6.374810590748714e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 5.877027855693675e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 6.51866632114323e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 5.941305468352792e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 5.4309939443511214e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 5.3349289594057974e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 5.267095965214622e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 4.759012819075247e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 4.9070963831831685e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 5.468777275141022e-08, Train_acc 1.0\n",
      "\n",
      "[Epoch 149 Batch 100] Loss: 5.4248123878880804e-08 Training: accuracy=1.000000\n",
      "Epoch 149. Loss: 5.4248123878880804e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.240714811418694e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.1399263875367842e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.227097236428423e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.1379150686283192e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.4543828530718437e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.370411637421033e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.238027086107918e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.3107319201795377e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.184315340146483e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.1031366345094666e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 2.411107085210422e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 2.1737216665437524e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 2.0876649455177656e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.985999985718008e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.8796006093943358e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.6972284821262382e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.5312309237679872e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.6817158643277972e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.5284454355361515e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.4044718651502637e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.2714752565676258e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.1741300302059196e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.1144589273355043e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.0076696465868529e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 9.087653269663763e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 8.737680563761117e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 8.003610858050189e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 7.687537013665304e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 7.002602299605247e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 6.637617663599243e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 6.039048459698834e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 5.574841982157704e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 5.110490005876345e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 4.9160905385494255e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 6.128784032672415e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 5.6090378602213694e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 5.3368437170586634e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 4.933544488035396e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 4.617141204063819e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 4.825976495209639e-08, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149. Loss: 5.172254587065253e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 5.465277920863081e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 5.552048768972563e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 5.192421437345305e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 6.424047686102387e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 7.094801494923898e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 6.552959337808021e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 5.9162898544093055e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 5.43641955127688e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 5.228053119049439e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 5.98115575532838e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 7.282916631511951e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.0680338499172237e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 9.677497225037206e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.1047337464131982e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.0166120975754383e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 9.475471637185815e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 8.593117044808532e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 7.882816881211882e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 7.727832056929644e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 6.982988524034252e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 6.806229602872759e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 6.283931409215841e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 6.791748825045651e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 6.22433258044067e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 8.013990968816471e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 7.687565887608803e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 6.993315087053592e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 7.765470404069746e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 7.529088716110046e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 7.055576297139455e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 6.461777358615798e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 7.948313255117666e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 7.42356535189941e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 8.050243480121563e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 7.934395137262465e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 7.58798999749887e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.2081677514586947e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.1134279870857766e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.1054613688819096e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 9.949152319937187e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 9.047369327641448e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 8.300957143744093e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 7.536054000710983e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 7.043218726132966e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 6.432029093217649e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 5.984403764693019e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 5.5442881548540754e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 5.977059278941416e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 5.761195180313979e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 5.6414230843557034e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 5.608134110543904e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 6.984459859680295e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.1315014236522887e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 149. Loss: 1.039212897721391e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.0023467196347287e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.1340080860430707e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.528163642375809e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.4591661748505014e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.3942743584561857e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.300481647054311e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.2877795938433784e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.29683619600119e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.173671833535201e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.3878485802693996e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.3040115658509477e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.2080693232103438e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.1375537566278401e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.0508067178653367e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 9.773909780885926e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 9.336684155244608e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 8.691725489160989e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 8.42791161898512e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 7.650313028427907e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.885281725585116e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.224693228044624e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 5.974752473233575e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 5.693926688116659e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 8.13267495564971e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 7.468419036496079e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.805396137916511e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.162109422668587e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 7.995254682707081e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 7.260921785777672e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.693154356066694e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.182163687090383e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 5.675706009571634e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 5.126761857886334e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 4.7537840227628855e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 4.539175586107563e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 4.560231830007965e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 4.588495675264482e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 4.1762122231461315e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 3.96348189619265e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.845357621122402e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.188761534028181e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.97617081539387e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.474131385705891e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.059548748680625e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.692243660995584e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.321042394428e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.406053908430996e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.631576096134989e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.480644801218763e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.52175781838969e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.670517674363193e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.692642764731215e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.908132091971856e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.245258557792689e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 5.667298817421518e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.488229766366676e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 5.913912577935678e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.53895612862306e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.8935479190553203e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.7144376736942017e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.830770109192244e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.6868086037743057e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.542342093033384e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.4244294357183399e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.4198210536886553e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.317885733763127e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.2326632429323105e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.1429244886926726e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.0295633623425097e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 9.517527160829514e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.1238646928091253e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.0403491824850853e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 9.428335209266176e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 8.513441361137131e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 7.885614483059017e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 7.218124898398854e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.924719762595122e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 7.862053481182773e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 7.122414252913487e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 9.287940256421554e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 9.495356219096604e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 9.337443222416083e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 8.459578236887835e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 7.706752652897032e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.2654295677592418e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.1500624783259898e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.2483273947777695e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.1560909027789703e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.0563142891641091e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 9.646526953142166e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.235120306307268e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.1153335657529586e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.020564010191671e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 9.185076091725039e-08, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150. Loss: 8.620470776689322e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 8.51279285283072e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 7.810525099550067e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 7.541699330617976e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 7.160057716859634e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.453365170364715e-08, Train_acc 1.0\n",
      "\n",
      "[Epoch 150 Batch 100] Loss: 5.8080286533282434e-08 Training: accuracy=1.000000\n",
      "Epoch 150. Loss: 5.8080286533282434e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 5.227225787995419e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.036290227639597e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 9.63282597197425e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.0690501993008643e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 9.891535144947016e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 9.628811391241274e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 8.759062491815126e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 7.911095917651632e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.2884694574421059e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.1726610250779767e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.1187246942192024e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.0133714814873229e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 9.390426684625143e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 9.429267248329816e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 8.681918139821107e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 8.027930411419145e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 8.696617090571386e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 7.910774395466073e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 9.177894692606827e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 8.269418448537188e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 8.401736581800658e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 8.1762336912386e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 7.600753978351945e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.859305030898837e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.303759590555494e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 5.682696856690988e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 5.1703065166170335e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 5.3424535754109546e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 5.190050260299385e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 4.726924579864591e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 4.338051135829957e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 4.649301452931222e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.143903821928721e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.0369640194445943e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 9.388555520596494e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 8.617337960913358e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 7.969808285929308e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 8.849199423022864e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 8.029472047620985e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.1557088697041288e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.1993928640160384e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.1297449362475379e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.193720282292544e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.1563044558883405e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.1487070594726794e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.1185864591254624e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.0179036796674099e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 9.915501844491377e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 9.333732562586084e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.1035960128359323e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.0044122797831896e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 9.589190126529103e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 8.872414805640533e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 8.804734774892799e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.1109327659169595e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.1767887747716896e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.060041219813625e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.406648244616228e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.284609860988774e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.1682560648071841e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.0803014439286909e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 9.797218792445672e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 9.22727813548918e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 8.32317677232235e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 7.54673844068526e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.8507265850153822e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.668447894015646e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.5416499255845555e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.4722349249393133e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.347363167130726e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.2172834628466416e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.132807937834182e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 1.0269777237595093e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 9.345244925989013e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 9.593496053058176e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 9.518898488272103e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 8.613574763734775e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 7.76153051255234e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 7.218207856261018e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.496387070634917e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.209963670291548e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.157072155312449e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 5.597244276494564e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 5.363482394689158e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 4.929579620664376e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 8.301573679247009e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 7.92776394655825e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 7.200180123243724e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.554667899125021e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 7.249611452760512e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.617782529418872e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.356472273018905e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 5.720825045717015e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 6.480526148983902e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 150. Loss: 5.8324735340855117e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 7.07459838961815e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.441644338862004e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.955804653842594e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.4906092867320126e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 4.9415483580588114e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 4.44739352225293e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.889701571173174e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 7.141364940680736e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.753190992456713e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.124438017500924e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.601638359554357e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.053233179262074e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.45722308652691e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.37716149674777e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.3982371510125774e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.491711507672921e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.072925410770386e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 4.696017976848809e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 4.254355851961501e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 4.2573279405457354e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 3.8967877178324615e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.136907961794664e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 4.781541932245555e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 9.75150201873681e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 9.437588571103365e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.434238655282082e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.3066472628641958e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.1769138590968807e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.1607361648620741e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.0567697382931544e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 9.864829725612356e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.0983112323771823e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.0573978943958812e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 9.553833948106658e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 8.626390228314011e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 8.15490636707688e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 7.833015486992744e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 8.269737700309824e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 8.290265057333626e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 7.461238551600264e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 8.745387677286585e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 8.019860485969267e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 7.245814112390359e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 7.2662886292155e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.996007472584167e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.585116439239455e-08, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151. Loss: 6.345699314404012e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.316486853781192e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.308821877550142e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.050468080152858e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 9.375524661531053e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 8.531104435075927e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 7.77112622238453e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 7.133711888638773e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.66248424943069e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.396703963138089e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.706977477024371e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.073532627865661e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.7083230213162984e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.370321220729991e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 4.898481661116507e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 4.455199619294738e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 4.344955286846922e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 4.031531675098674e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 3.740137163251959e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 3.3661234469267636e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 3.7186881021469757e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 3.365445742314365e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 3.2803580500662864e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 4.7497549188709304e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.174660284065208e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.292937526410897e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.766089221450373e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.353629041155449e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.8579644699415206e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.914778823075209e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.804095592110565e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.226131480580075e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.612831557713111e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.172620292232891e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 4.776430162182477e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 4.4198590451371045e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 4.7136161271585095e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.806862797376136e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.235489742829566e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 4.7771333398879086e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 4.355299355935154e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 4.310924333245951e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 7.465361000213107e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.765391024481679e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.247176670900302e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.743530911864931e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 7.86996667545986e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 7.194728663577026e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 7.117867521052721e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.946247222735964e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.484452877662711e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.83600758989644e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.230293544733388e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.970479745670127e-08, Train_acc 1.0\n",
      "\n",
      "[Epoch 151 Batch 100] Loss: 5.410684669646842e-08 Training: accuracy=1.000000\n",
      "Epoch 151. Loss: 5.410684669646842e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.065193783479292e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 4.5866140801493816e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.301412010722589e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.09723335549438e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 4.9227858625894195e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.035866239287803e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 4.6160986115472787e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 4.238307764344376e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.7143574186656675e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.319872788340358e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.141787732588836e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.232966785418901e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.408160758861696e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.090861994301831e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 4.60971546766922e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 4.158057146093341e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 4.1985984272314877e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 4.6448650261870554e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 4.394582573621363e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 3.9830639890567994e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.438078997603432e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.3506184488619375e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.094953109906861e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.060431814590154e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 7.255202499016859e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 7.19091864808404e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.546332571481306e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.891699314333176e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.423601246545597e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 4.965060135842862e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 4.664131791873553e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 4.356043397080124e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 4.041510965426771e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 3.6839259887330834e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.27710507108568e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.668021014359199e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.321243527590916e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.838130733479596e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.5989066929951326e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 8.214763759590749e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 7.439853503480665e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 7.39435894722583e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 7.185775250258642e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.2744065177703246e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.6219306872442706e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.4876772797710961e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.3919948106493765e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.3822481300635962e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.2663750446371536e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.911768825296814e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.731767809221626e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.663829932113106e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.4974469389017953e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.552591861395823e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.403851930614014e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.271848638947795e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.1455950975721198e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.0431427777321955e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.0822515511721522e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.326991626431804e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.2157128634648545e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.0997295121219727e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 9.925505284115774e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 9.007460543909866e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 9.550257658962608e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 8.818749239919789e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 8.113825480759772e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 7.442141265585412e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.79105937872485e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.233025322261673e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.702855029733485e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 5.1511959771422235e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 7.225142336609448e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 7.545703275850312e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.847012298301318e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.618658206327214e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.580025581671965e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.4238856685429772e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.2889476809533358e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.1600529128580023e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.5190128691488218e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.3764248035392023e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.3924495106044417e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.4133910334071752e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.272983252585562e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.1503415393119048e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 1.0455519319251279e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 9.624171330797754e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 9.350931481847962e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 8.760427402053799e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 8.070649034662969e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 7.263584131196673e-08, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151. Loss: 7.896946303091662e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 7.163131013936748e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 151. Loss: 6.953456874437696e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 6.481628498320232e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 6.224620525865385e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.6114716984698895e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.068950979004987e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.748320253919037e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 1.3660690568421564e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 1.2359814074038922e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 1.1459108082953866e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 1.0639159571812572e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 1.086977602478785e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 1.1002823889627984e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 9.977047279989071e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 9.100414468926608e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 8.358010943356187e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 9.058883712731827e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 8.227501129664314e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 7.535136097207992e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 7.023766285832944e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 6.349329332267669e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.788902187246572e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 6.392782827553648e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 6.414741583255613e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.959531868798874e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.7547339500946665e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.421404300140246e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.8885770953172645e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.5952969843462414e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.5734876525311046e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.0660822290438964e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.043760288326947e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.911912436689161e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.457974091563972e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.440584746986464e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.4249337684325184e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.053455668055181e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.808880244506313e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.436258338932282e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.116149851892495e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.8653049744327587e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.741989890291015e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 7.331787317847636e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 6.766246578439386e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 6.201380585140385e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.618495420729181e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.121838449997562e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.233639166796158e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.775467803694273e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 7.762401778935412e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 7.92679214338726e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 8.382079778908483e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 7.739449364051201e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 8.213470993288936e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 7.45731646086045e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 6.804717054472385e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 8.69465614878776e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 7.936949207335705e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 7.152567511793178e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 1.453953237424003e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 1.3169398133004284e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 1.2169107781910298e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 1.099876312800915e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 1.004789833832887e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 1.3150169435842478e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 1.2030730055291798e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 1.1125679936131773e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 1.052533879012292e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 9.882586417615797e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 9.453119686375212e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 8.535747390535263e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 7.803244515127476e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 7.916985258826353e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 7.916908150250205e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 7.227662791787534e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 6.719100491607521e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 7.406912164329803e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 6.805919227507735e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 6.404723881742353e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 6.649005594661795e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 9.653430998269403e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 8.70671434882455e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 1.1095631566268878e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 1.0498294155905075e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 1.1217964415989092e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 1.0478009341804109e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 9.793423785398093e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 9.140043846120923e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 8.468183117746035e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 7.667930925820422e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 6.957017178833525e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 6.438266590254998e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.8037531564205416e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.288570412119787e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.6072132900399414e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.120997740359833e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.6927169802756747e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.1733898319366605e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.711930198779031e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.454941228954141e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.6858128189691374e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.173110882667368e-08, Train_acc 1.0\n",
      "\n",
      "[Epoch 152 Batch 100] Loss: 4.739618808352456e-08 Training: accuracy=1.000000\n",
      "Epoch 152. Loss: 4.739618808352456e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.684751659768535e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.846075509537129e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 7.245169552682747e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 7.265710017618393e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 6.650897653756138e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 7.727372007964452e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 6.99188770793218e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 6.292698937138962e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 6.594750054846526e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.944588274552917e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.918234583364775e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.456796232183759e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.9483695075091106e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.500098676607189e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.469183150399289e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.09677062356503e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 3.9664898717403924e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 3.5884673349484396e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 6.330876458017108e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.716415262597484e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.237905967153931e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.058704296720624e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.372395956353344e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 8.625556532228565e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 7.958578513093549e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 7.162720661784194e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 7.2566950433191e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 7.22020175730307e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 6.498181581572764e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 6.230205039519372e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.653750659857317e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.0976888190626285e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.6344860525644636e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.2269167929031616e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 3.8135383388038886e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 3.6743281789242715e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.200963682631506e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 3.864686301674827e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.633051837580105e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 7.690070952555706e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 6.939690307682222e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 6.310913839373515e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 6.015098084917822e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.432214726808126e-08, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152. Loss: 7.813298389948073e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 7.078534670802256e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 6.389307654104117e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 6.15084516945272e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.545073877698491e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.1116383979833015e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 1.041173472459562e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 1.0776850239618244e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 1.0015814606808589e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 9.10736538582571e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 9.547042459287716e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 8.610964662630808e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 8.755691461044747e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 7.898748764212135e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 7.118187112981965e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 6.909281526162023e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 6.34873851622842e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.918755506676005e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.3734460802982864e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.975799778524722e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.7389899439288995e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.302343848079737e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 3.8907359125436266e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.3025967511790856e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.785031635990328e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.306528472391295e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.062139997966714e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 3.8328772518198464e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 3.542721730808704e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 3.318834682646864e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 3.0893966798263114e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 3.069166814575226e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 2.7901898081357218e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 2.520484052513193e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 3.1066221274850316e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 2.8052731399275718e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 2.9997195573916994e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 2.8021930404513113e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 2.8013701357558874e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 2.6050521361321232e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 2.7729541699736538e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 2.5608513154358035e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 3.8693775932137385e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 3.771149601096774e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 6.318347450669403e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 6.83203172746368e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 6.446851565431444e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.839419309652473e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.553500211765674e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 5.1844146522214974e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 152. Loss: 4.695775507610686e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.412462294137029e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 7.687144820533054e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 6.955683237023476e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 6.362560369883478e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 8.380532174853476e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 7.663550856541004e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 6.906508996077948e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 7.603524327282254e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 1.3334390195206717e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 1.2103396623366611e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 1.1917507743013383e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 1.1433559496411686e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 1.0411275428179825e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 9.40740078390557e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 9.025453433160154e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 8.476810490562337e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 1.557291253060992e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 1.4229825363129078e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 1.280684282681617e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 1.1554098216932127e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 1.0650145135113726e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 9.901779941700249e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 9.051300280431842e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 8.211362814848173e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 7.54855133552085e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 7.101032473956189e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 6.465435005884456e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 6.265925310824473e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 5.751091453168746e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 8.836030003882105e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 1.1938418273877131e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 1.1154357349033263e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 1.004823483932098e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 1.0142368014395826e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 9.509972864587264e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 8.791806026383156e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 8.704245775237223e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 8.28085528745906e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 7.49002265725688e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 7.085609317813278e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 1.1415340942523748e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 1.0338999410730888e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 9.323725918929662e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 8.391353327036695e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 7.747795521839456e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 7.075461399572508e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 6.81494895856231e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 6.152080513088166e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 5.574125355882184e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 5.240229971748155e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.7627730988632214e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.3144354639949174e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.702551520000632e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.269549268764742e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.861220792270354e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.596170550043705e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.5904555049590275e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 5.103356392322276e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.918983441042646e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.5202173011092236e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.682867475484687e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 5.313536463237606e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 7.147727092931164e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 6.526086623336027e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 5.985236652192713e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 5.554350961586386e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 5.017542315809834e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.56235420407784e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.73010277703422e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.443356801091073e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.166659131122047e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.7965593422997246e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.454156308833925e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.118053903141576e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 2.8528146371173e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 2.56753317340557e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 2.3200930812560564e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 2.19052918528388e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 1.9901027171375785e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 2.750349794532887e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 2.6243263204366643e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 2.492278751139539e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 2.634206002092718e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 2.4732308584457963e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 2.328353238045351e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 8.782207089935299e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 8.01574503660492e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 7.43768777321646e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 6.740485115743804e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 6.411025388342962e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 5.928247616139024e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 5.7638301730341383e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 5.327145488632341e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 7.579057016159957e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 7.100547767184375e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 6.716455536309987e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 6.091376102527978e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 5.6312499976322467e-08, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153. Loss: 5.459279484447693e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 5.1648082758777355e-08, Train_acc 1.0\n",
      "\n",
      "[Epoch 153 Batch 100] Loss: 5.1139878474192815e-08 Training: accuracy=1.000000\n",
      "Epoch 153. Loss: 5.1139878474192815e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.7050345103579194e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.3556029229678664e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.929355855862123e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.3839199762452234e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.9920941029105834e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.030605805308885e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.702051021865451e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.3504723700609924e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.155123448192942e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.128320568597394e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.5326056152146486e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.281790510255534e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.158502319063975e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 2.87059175995515e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 2.8536159529624396e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 2.9221564386401626e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 2.6299407947761464e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 2.488018596707839e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 2.49067365454755e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 2.5210025996246606e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 2.5017326280446964e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 2.3167519276997417e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 2.1316428592196495e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 1.955731471841412e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 1.918483109051197e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.98619957623694e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.5341457384622354e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.1086708396340304e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.7536830923839876e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.4528205624694745e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.163417856258563e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 2.9029554162278515e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 2.6592259988949483e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 2.4864356475852172e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.985170940574813e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 5.31552781153707e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.8212279289270905e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.851331095460287e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.403450884457985e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.009671915861176e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.701836963973038e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.527230848372869e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.360772154113699e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.425162722081428e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.4924276721613604e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.422581268767795e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.098949592273102e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.040511568319856e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.1928074782896245e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 2.9014664054786803e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 2.7975840666910875e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.300134917396415e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.5009740852649454e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.374393952537619e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.325664342251835e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.030350806570379e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.4351197457527276e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.492075874300785e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.236000508805118e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 2.9403401307221782e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 5.2353672431408036e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.7490834173704506e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.320741195482395e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.121497648533752e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 6.540551457485774e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 6.03550789703032e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 5.767232807863219e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 5.265015315282567e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 5.939913936449298e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 5.690511717776411e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 5.2332191750165697e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 5.4456403151043015e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.9383291843580444e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.51900205412791e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 5.44544817467935e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 6.968429098933836e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 6.327465534635596e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 5.70403220636308e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 5.18019510113487e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.680802041403469e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 7.649264905154884e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 7.256867160268492e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 7.173792310183589e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 6.465726304356273e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 5.828466899111689e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 5.403944975830877e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 5.059127970227083e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.5718416224762376e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.775893717088934e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.5683876255650036e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 4.1860546600959574e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.823328539681506e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 3.468935360731374e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 5.971837175470437e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 153. Loss: 5.3746534579233934e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.874441010674781e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 5.9143596792006134e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 5.816523681066926e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 5.2721242115039605e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.810104361694864e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 5.2417884854545285e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.997006036258783e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.9350264742679904e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.562595663841578e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.10633609745742e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.826087621512493e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.490044983651126e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.3645576900309076e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.447196191426362e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.186295568471982e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.324013327116496e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 2.991611994404847e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.046352875938329e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.747541776727072e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.512485914192413e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.226429885232687e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 5.027173803014732e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.6641547556148757e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.262931846953795e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.8366386622584157e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.328414534511719e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.998018546504681e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.654096037449358e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.335252553553412e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.402195650011358e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.1981838706449466e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.899437382753327e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.5374333172755665e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.202316435930097e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 2.984530257781222e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 2.6860772320030996e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 2.4174695088027898e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 2.6134432442862292e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 2.519736912234119e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.6181758382954536e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.78721158908968e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.6320076526891744e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.3433126578623585e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.074173954535638e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 2.8598887987800536e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.4737755179671747e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.231288826004452e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.013050767710865e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.676938262281078e-08, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154. Loss: 3.327870885324833e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.032336695336077e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 2.7384162509935127e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.019874230554993e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.046294623388425e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.7254841750014075e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.4088151030964116e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.5522206920983574e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.569527226409072e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.29639351771999e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.32996961477666e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.732714929291374e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.769224836285995e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.4668081453039575e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.185319906555753e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 2.959920137834589e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 2.7943132489701603e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 2.5800744954144437e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 2.3500067208910175e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 2.1895118458893698e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 5.7516808604648676e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 5.260331761724853e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 5.926382670330257e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 5.445503032315031e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 5.012711420273817e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.558006398095425e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.688937310518205e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.247983254484403e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.953570062836777e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.567526281744143e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.3225323269964496e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.018218767094377e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 2.725710115575983e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 7.221390746435838e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 6.797274433816429e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 6.12686021562583e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 5.5607403139122365e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 5.0139795077120565e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.540521231958869e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.235480614120048e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.9050647924060224e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.7194491374722786e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 8.395110574397191e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 7.583539191975491e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 6.825185272777943e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 7.222995247712219e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 8.195693429577056e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 7.441316649078866e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 7.116279147988115e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 8.248660267546744e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 7.433107465983113e-08, Train_acc 1.0\n",
      "\n",
      "[Epoch 154 Batch 100] Loss: 7.760811924796443e-08 Training: accuracy=1.000000\n",
      "Epoch 154. Loss: 7.760811924796443e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 7.906736599526718e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 7.48859129440464e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 6.925996484488019e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 6.270649734582944e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 1.265613906725411e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 1.1455717722988214e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 1.0412591389488174e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 9.687981748272936e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 8.765749697735524e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 7.926427628726145e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 7.394555044637318e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 7.241831447677276e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 6.526961528100593e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 7.653071597609497e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 7.008836292612502e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 6.373145239133444e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 6.136298676234882e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 6.686817763624329e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 6.91220118247352e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 6.239607514608255e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 6.621472159452656e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 6.015204293543427e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 5.711706803848943e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 5.764520969479495e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 5.979689224023929e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 5.474852541319515e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.9459937375696505e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.6469720334276625e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.200901280466983e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.827377276710167e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.5098321114986656e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.168162125539843e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.1773082456670874e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 2.8595774211003786e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 2.582932904181384e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 2.3432660641453322e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 2.9191880370723318e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 2.7297146988092328e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 5.446259987517471e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 5.0878982905259987e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.616361355576233e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 6.315367018828204e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 6.298502647757411e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 5.7245317285768143e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 5.152078555719133e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.785882249913207e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.3445469256860594e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 6.685388030736491e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 6.23105311784374e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 5.8594045814613145e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 5.273464123315183e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.820623508071119e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.6365840613967294e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.955235338957134e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 5.260645098082865e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.762520263292597e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.425966552101386e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.374524667687013e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.1233365914964285e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.850701211957697e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.4935707635595e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.5167424683597843e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.5282835992982014e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.231334580522634e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.07583915037402e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 2.9452063291143066e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 2.6786253690004484e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 2.5877140324595025e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 6.249755530228423e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 8.316256174675037e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 7.52188345575126e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 7.104970881766338e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 6.683183614084819e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 6.02417847786738e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 6.381018618678171e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 5.761543207192441e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 5.83731205969591e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 5.2628940789173624e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.894929419892416e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.9642287081684004e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.532998399811076e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 7.69318751677388e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 6.95180844011451e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 6.6570958058078e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 6.177650633568706e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 5.6157649158069804e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 5.184573540263528e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.6754294114282186e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.2265129206674834e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.9342467179926285e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 3.550135271384409e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.443085751934975e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.0360300752852044e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.368169770074705e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 154. Loss: 4.1399690284648195e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.1264401932145316e-08, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155. Loss: 5.874437830594124e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 6.05067529022282e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 5.622558979323205e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 5.358325807887923e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 5.204335056365835e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.7490941131887665e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.3486904989573445e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.2490973272332244e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.8335008197009456e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.524656525936521e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.768235189468568e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.6894346279451387e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.559145215590061e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.131170369049073e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.718053332144166e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.3555612241207926e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.0945108943552753e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.8781920446177275e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.627625738699682e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.5325011572062263e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.5120815785580632e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.7172207717211056e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.603823425652216e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.7439091506831883e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.478831460805913e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.428845006039194e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.8148345415092866e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.7896984739043437e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.338668301531928e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.997933711076714e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.644706464258925e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.4106209161067105e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.0788720496870826e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.864117084416354e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.434517881364544e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.972316377669284e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.5961566568388e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 5.2913735229793876e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 5.4048465444836486e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.892301562832856e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.980490123834243e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.482441111450819e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.0714498944085714e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.2230971352329406e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 6.427080133903036e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 5.9426969049066594e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 5.357740439607037e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.924411861090468e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.562355764373315e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.8046094188351966e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.566291991080334e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.267987523075521e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.869128443565541e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.096887503695373e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.882776245305129e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.522438295792634e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.2353870375546706e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.004980573497183e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.7137957413385077e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.9453288653572705e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.9208793122972115e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.7964292668625927e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.9265673493015875e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.8667409382810673e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.464819595515439e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.1555905367280687e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.9797297804297416e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.6817568023867675e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.5160265698286567e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.264423912845791e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.037981521561212e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.0355818167975116e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.7413368603088038e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.5975882903151692e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.356455911665739e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 6.004328822833647e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 9.967258321854897e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 8.970532489669407e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 8.213177529195163e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 7.559497733125021e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 6.989812261572794e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 8.823989216410602e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 8.211673539427368e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 7.586083784045335e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 6.920607645338781e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 6.228546880804903e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 6.9561052363348e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 6.269807937892364e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 5.642827144103127e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 5.972609411741618e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 5.524360029215228e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.9998637013117235e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.5371302319447246e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.325560811696751e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.2469066693924955e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.120238835531694e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.471896052558085e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.155091527812386e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.615022042456018e-08, Train_acc 1.0\n",
      "\n",
      "[Epoch 155 Batch 100] Loss: 4.1628330634014597e-08 Training: accuracy=1.000000\n",
      "Epoch 155. Loss: 4.1628330634014597e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.7465497570613136e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.806119893362153e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.5024590866214686e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.136032191911147e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.271907941711967e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.8540303727318135e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.5582682818198467e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.1862604498261184e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.767634404843507e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.4467503099543006e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.130014951756443e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.9194589220249328e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.158365511794928e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.8704686356334532e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 5.293533800195985e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.875939093603107e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 6.893563403782325e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 7.144839879486236e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 6.653873114046075e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 5.997799027832511e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 5.3980191250492606e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 5.873355976704263e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 6.887887533510914e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 6.264291351501121e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 6.019704010090577e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 5.6412509204078245e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 5.151631621013604e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.664408133930262e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.225906995555254e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.8312559710177465e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.4667568242980584e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.120081141868253e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.873265599022727e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.856022301541849e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.598359746405682e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.580667481293023e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.331913958354764e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.40605840818107e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.2306451298224782e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.026207066112094e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.7083388263462693e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.4654446165092148e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.047774972529315e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.9478883351103784e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.7369184889058124e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.2455350447383845e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.9302947654555894e-08, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155. Loss: 4.3974496072101926e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.994957540592008e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.78172623040163e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.487372594667939e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.4366583814424146e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.446894659799277e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.372288598349291e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.109565526720032e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.3818417189541555e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.9902236713486224e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.187246188773648e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.280748133283513e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.9737452191280374e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.585683922406277e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.469259133112148e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.14095967018302e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.9293091419634997e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.859895432512044e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.179263857458335e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.861337471712502e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.5938301738131152e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.3530736057036673e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.127079470324344e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 1.9423111983099278e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 1.8318990835489758e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 1.7139017376535934e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 1.626330551194706e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 1.5847694130116793e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 1.4356056969015548e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 1.3199848000089716e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.879484117976698e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.5101621554508915e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.242964936094059e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 2.9745477880797976e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.319704946268036e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.57446650125347e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 3.3753446177584806e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 9.03531323681721e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 8.280793418492556e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 7.54584631634128e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 7.145163694626846e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 6.52377956486214e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 5.927280949530179e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 5.418371868528986e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 5.686783189963347e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 5.304369190490855e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.8204983957316516e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 155. Loss: 4.338448556158487e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.9046037005426384e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.5513962312525476e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.289388847825272e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.007016082891735e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.525874787550504e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.201226983813472e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.9556100736377948e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.7066151905638972e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.618729504338392e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.2754830042866395e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.441534389427255e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.19982640704688e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.038168497445413e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.935753789915519e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.55149163611501e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.280161486455334e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.0266511260154704e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.7239860134139234e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 4.500479881092379e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 4.1156244643244404e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.722688468274083e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.434238626516715e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.090814763865044e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.791046512669583e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.521255086593668e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.3250089190885533e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.092508027179698e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 1.9763894641597077e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 1.9650148905582854e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 1.8523324154542816e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 1.899929497818492e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 1.8868877661593102e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.5270738072144007e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.50719696356542e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.265790492399921e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.0578378935420156e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 1.9079334542238506e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 1.838212016856125e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 1.6916437137142397e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 1.5783586879379605e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.174892115063042e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.1064144622045094e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.575636434879424e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.7930465583755032e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.5323683529200394e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.5119620369369264e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.288705506040806e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.301978469565382e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.0717806226088438e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 1.920481910383996e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 1.774999839194586e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 1.690632077209539e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 1.521568869488585e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 1.583615926011329e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 1.4345675586012395e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 1.402869467286052e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 1.2625825205574468e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 1.3132754866243694e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 1.2378272746752929e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.2129990035322274e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.019638775976577e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 1.836301348761006e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.36978654100506e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.3935779946340674e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 6.019129299038492e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 6.898005336135633e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 6.217518027713113e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 5.707524880604954e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 5.1740252866472935e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 4.740441745289036e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 4.657552625772992e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 7.991501381288291e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 7.369302336937151e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 6.632372103243436e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 6.658311963886255e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 6.020420442515649e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 5.9212918069594334e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 5.357102301281508e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 5.2497992830809635e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 4.7341325799639106e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 4.2886589947650916e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.962238507442011e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.5846411059696736e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 4.22268582638092e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 4.1636325859900864e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.7658957777731646e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.389306199995848e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.06900203037835e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.762101827340515e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.541770985760716e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.3248467857283718e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.0923621071555346e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 1.929692020729863e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 1.9695532491479257e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 1.772597924233133e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 4.389273454907505e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 4.5091379133563386e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 4.1234166889211115e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.729701469300864e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.431237110576448e-08, Train_acc 1.0\n",
      "\n",
      "[Epoch 156 Batch 100] Loss: 3.088113399518803e-08 Training: accuracy=1.000000\n",
      "Epoch 156. Loss: 3.088113399518803e-08, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156. Loss: 2.7979285099490095e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.6578340096192937e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.4013638338484076e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.1798539008456536e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.1388196223023453e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.2602135737708624e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.1273244383281876e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 1.9145919944953687e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.021155841287101e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.0611839844498682e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.9598271776862626e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 6.488169206717904e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 5.8486655112371565e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 5.831903670054949e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 1.0547765380184002e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 1.0936534853780273e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 1.0243349222835619e-07, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 9.25626720131623e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 8.451712380357483e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 7.988382580789935e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 7.673830889115476e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 7.00889323900271e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 6.317317140293482e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 6.244378153909276e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 5.6385667889004346e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 5.1585291150804315e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 4.651989428763432e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 6.16117700682915e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 5.572998981164253e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 6.151907081845372e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 5.611222161866505e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 5.096666069969737e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 4.642878808567908e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 4.336915658814338e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 4.2105602583389183e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.975768640846712e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.708576910562855e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.365658894524588e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.029093005072129e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 4.300103934267624e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 4.2239956928691025e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.810909348773236e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.550890321950572e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.37275241906034e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.0541036264261693e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.767319714165639e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.9003693558356546e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.982860952718366e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.7125145324645474e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.018682151774133e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.893765154719387e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.678894418571334e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.9383616356399833e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.6655973357217235e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 4.090659374727407e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 4.529092503735517e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 4.094809703744052e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.759834526016209e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.6911870967120545e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.3220683870408494e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.0736805356432364e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.822191818792273e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.1360179477985746e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.5954120425384516e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.5245806232525845e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 4.513222378791559e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 6.343630359013478e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 7.730211588380684e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 6.975816878814479e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 6.324801315222914e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 5.822706273092516e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 5.3428811023456146e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 4.855159116400935e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 4.4068961055250146e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.9941461699905314e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.725116642383372e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.576122147362792e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.25576283117024e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.9581262230712342e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.690253275782129e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.514360179020111e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.9148473343408127e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.005204536754847e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.704684083079362e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.434215674771426e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.3770584978724003e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 2.1766055466288874e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 4.231341378581582e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.808207240723424e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.4273865166510815e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 4.164979280423259e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 4.018564650329465e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.6912139779430806e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.3500322551667905e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 156. Loss: 3.015029029650112e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.7694054722802453e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.6973556250141e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.4369332877037334e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.295685406613926e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.76460716266585e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 7.247059851966265e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 6.680678580109291e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 6.012610722098363e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 5.4299760991603895e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 5.073242862058899e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 4.5845450262350955e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 4.1447169739936727e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.7954378390538204e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.592845184453264e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.40119855180304e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.1355844848284064e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 4.41457584392862e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 4.494657622343502e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 4.101071205704296e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.774783072440338e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.415931214468168e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.18609678421164e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.9140532300803577e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.6319611322633654e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.396704694055047e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.2315400217369963e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.0922050423969057e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.112325931284685e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.856972688192253e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.766853000170163e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.7975038655591606e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.0672319150881275e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.90020701207201e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.206231834913159e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.453713432417625e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.136281764193881e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.8412800381565794e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.7061635752251245e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.603185139024851e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.9295981773546884e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.7763366214665627e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.591835199017886e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.3419649043071405e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.1450213079792616e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.020162184116484e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.736772416086922e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.546914170666486e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.394668183516835e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.701182059737942e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.461448952037826e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.189809853921498e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.9360214398706473e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.6610457451554463e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.4135676199117654e-08, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157. Loss: 2.2467166283626903e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.0872375324268287e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.0834046390181407e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.5642412460834887e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.267077383809423e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.0148754336341506e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 4.706392762517919e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 4.273006380368962e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.976090831723959e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.727493298317551e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.4199365309453106e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.357339294964055e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.040231814739513e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.9504126300278693e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.6646845922161256e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.7148655952009552e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.853160684294576e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.6702900813092525e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.636091592487218e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.4004221060360685e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.18831957045048e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 5.1452344966492783e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 5.021866173051484e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 4.7804496457122805e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 4.3210311304129156e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 5.72361188886495e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 5.169877149250318e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 4.783274488190043e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 5.98131914716607e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 5.4576930295369174e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 5.237886094791591e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 5.0400599601022085e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 4.713005075633244e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 5.117143382843508e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 5.238725908398107e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 5.357463691360496e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 4.8217173222244465e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 4.3674852627995744e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.986616082114761e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.653147045244585e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.287832340720126e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.3315775325329794e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.007733004470725e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.734899379041671e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.461409441137504e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.2152684970237534e-08, Train_acc 1.0\n",
      "\n",
      "[Epoch 157 Batch 100] Loss: 2.478027893981682e-08 Training: accuracy=1.000000\n",
      "Epoch 157. Loss: 2.478027893981682e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.2488515549656006e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.4058081221543352e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.2211066555340463e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.101441402134071e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 1.8912972619206637e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 1.711480760919641e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 1.577585583371404e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 1.540898924207139e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 1.3961222569774685e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 1.7128568138643817e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 1.858220665738659e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 1.7375911616243085e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 1.573145270652921e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 1.4996497575394534e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 1.8432845739361978e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 1.696209010645413e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 1.5824674551760163e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 1.992325419599923e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 1.8396590019298125e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.192369665510485e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 5.02446098780578e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 4.549954561822774e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 4.1694648982870586e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.948095900437646e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.786116776412067e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.6962147238667224e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.410412265431875e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.0786842640797305e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.7801290628628008e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.9305236527212215e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.9168676867988067e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.8486982294452303e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.7035267571658926e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.6287516622464384e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 4.731413098177566e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 4.360717227158591e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 4.055030558307489e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 4.0779347144043464e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.726020588559056e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.390671428246878e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.107483626576443e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.8991807115993645e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.711708088119994e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.775812695626831e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.498231426064148e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.406732996797386e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.184686146389511e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 4.2013789210584643e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.809180703970636e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.446889082845436e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.167392745902192e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.8785931463299912e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.1308990420357196e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.03201308130375e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.747438222445239e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.4820076253917586e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.243120088043626e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.4937814554247802e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.3375355318167134e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.1317216514326146e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.0023684913593937e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.0070223421853336e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 1.8715126704263155e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 1.7402407534197207e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.196018962319781e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.885730291278846e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.606470487342005e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.457582112034525e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 5.750785451306579e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 5.250212685499807e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 6.224606835443126e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 5.71390481644375e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 5.161140785181461e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 4.7102192691228306e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 4.360269205856286e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 5.013884510608797e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 5.881529728200181e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 5.4610147832838125e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 4.961479424804421e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 4.558463722021958e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 4.121243800201849e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.820878084726601e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 4.295602923752314e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.866042631377083e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.5166912690035475e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.239527921427079e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.9621412535742526e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.7124932525067093e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.459870377638125e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.223196565065356e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 2.0101901337498635e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 1.8557372446647588e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 1.8284882335379357e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 1.6549526353751856e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 157. Loss: 3.277591883408783e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 8.034736286591376e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 7.268515552035073e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 6.578916895375293e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 6.116602804398468e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 5.504942523958621e-08, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158. Loss: 5.7740100055961725e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 5.289741244734534e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 4.7607671202610807e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 4.8155426059903666e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 4.594758293248728e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 4.396052429544821e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 4.170651201116215e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.753586081004593e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.452733243346235e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.1074599190116115e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.7967139271104505e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.6753672655026265e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.407830538952364e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.9586699681777185e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.7745616003777465e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.506418665531015e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.2557767989779136e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.030199119080122e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.8271792071721098e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.8458583127618483e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.57989893186775e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.6758113683448995e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.5199888694099932e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.463567581029697e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.2824033765044582e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.0914159373977397e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.891587568849009e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.987643875226621e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.884456979683252e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.623950956732945e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.370869086250694e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.357299435661224e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.4940980600885148e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.2819411526233905e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.1003131616509332e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.918221520503858e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.0954377266877925e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.7858939540190132e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.8239539497692802e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.5415585547923522e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.3060291485849806e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.131305579321627e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.936801470661328e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.8455667801575455e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.7075762219907806e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.2353083991251042e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.514690292892344e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.3097873834520992e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.1067483179044614e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.8960734861140153e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.706466137502614e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.563759198770371e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.4539493987423236e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.3178676840591345e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.1953941408442644e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.1317340723549825e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.0558135636632113e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.1364966156385756e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.3674358093025301e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.0653772367339804e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.7867791858581548e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.7781846540387126e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.9287734005624476e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.635896060506203e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.4281858044916195e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.3436919196185418e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.276960666742495e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.9247055464700408e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.632234991823037e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.6949737542676885e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.9097626610283602e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.7957376130481916e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.9352584418861493e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.6510458228885777e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.7212171187713348e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.7995016292943257e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.419551466364893e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.105535992525976e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.990559991834082e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.7473833426867102e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.078003331886902e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.7981426737162303e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.713906022668879e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.479768321166164e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.269044389813721e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.135272181648544e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.1732018987577536e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.067640382308699e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.0657671861482558e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.2561649502925364e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.9305484552632828e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.646806834927998e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.6207765070524086e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 4.283149709384874e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.873461188828473e-08, Train_acc 1.0\n",
      "\n",
      "[Epoch 158 Batch 100] Loss: 3.4861150699456255e-08 Training: accuracy=1.000000\n",
      "Epoch 158. Loss: 3.4861150699456255e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.137503562951063e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.345292782626521e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.038703179381887e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.7627725364617163e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.5889407216143265e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.4697449379455895e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.287963011051438e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.0871063827438665e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.87839574446948e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.8209412949415623e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.6481603906384494e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.5112840243721766e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.4160349675301035e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.4886354853029694e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.4049645081139717e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.3296606286438738e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.3922720577587795e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.336863857052942e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.2218039217297344e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.500091810315775e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.067199377489824e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.0560571093558187e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.8690778488023234e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.8404948305524488e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 5.530694677735149e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 5.0335045555567783e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 4.5301541000011005e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 4.086451915192034e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.715059622216558e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.93028482142872e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.807339690525085e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 5.2147291485770147e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 5.4755637147369106e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 4.92800734326322e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 4.444519834127941e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 4.0373207492588745e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.754660564624078e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.416447406705397e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.1213687858838476e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.8185451324865063e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.6111963985617415e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.368703209087654e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.2249651278768683e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.4867554657108104e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.3032724860401367e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.072945237436123e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.9494697187625513e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.7638359720773396e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.717837499788636e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.6205595380154425e-08, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158. Loss: 1.4771300334857618e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.3480434794090493e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.2411788042657166e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.2195063715197108e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 1.3024466297288715e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.314226266911738e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.08524908790113e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.009554467493519e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.997308787948576e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 5.5101223465009607e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 5.014989457446009e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 5.8639024184434186e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 5.454463270376766e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 4.964896284493342e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 4.4684066560440084e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 4.06813211472949e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 4.117666041112569e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.7152126621923553e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.371631070991138e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.062407638910042e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.7747933254011244e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.571819785507574e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.882743511658155e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.613095609764203e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.5846164259881267e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.3447812326611777e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.488650003793479e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.167724676211703e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.055843068424528e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 4.696701910463447e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 4.3015375076227726e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.8713837568604955e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.549437943633961e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.213120598542428e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.8918085386881854e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.589824071678435e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.854826510526038e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.5904157142373886e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 3.296566705273165e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.9762232599368918e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.706540606740775e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.501079117407997e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.2509712056671972e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.4822214005921896e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 158. Loss: 2.2339992605329708e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.0105993344796738e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.1634415530599468e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.9750370727719705e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.8427259279542886e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.4314478746473962e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.3093749685919635e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.2088225522428764e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.025193195562316e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.8226738760060843e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.6869726126953576e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.54621502644384e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.4195331988174744e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.6687348984214497e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.6694994009558174e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.511862686051279e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.4258689799056663e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.3298482062049815e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.299308833265049e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.5232797822225536e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.4733972339172957e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.400563298731236e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.4467713771997978e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.3114074646708613e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.6459266199531797e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.5185868565015887e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.8975803686068236e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.7543884471542392e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.970104621924538e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.9127924482247796e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.740139652674165e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.584752137788835e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.2737772694677262e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.6890108400287094e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.4946155531132926e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.7201279779488058e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.494681295562023e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.2917792902957024e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 3.217433750982053e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.951569721478992e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.786797829841202e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.9085862920889597e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.6736070084752083e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.4155595328187307e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.183316804727901e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.9649851242551107e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.196893823757206e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.0144573399252125e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.8688909426460516e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.8217001724012788e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.328707723508228e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.0958369511574052e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.9700722699934892e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.7730650429941403e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.6050717638857695e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.4445645874971925e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.8030213598071384e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.669285343675414e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.511670034498916e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.3605030310490245e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.2337659531351654e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.175581920281164e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.514370439783434e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.390873070823109e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.4473634155922067e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.302627074032986e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.2003040416477057e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.1175265360266622e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.0150871076150392e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.8262694751232804e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.6436425276109526e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.7027955861761617e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.541829252749589e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.4155860024926483e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.3299067389567438e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.3924936991489096e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.262557554425062e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.164241474000574e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.3458403017875123e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.2112562716087611e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.0994438696389282e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 9.894994826750355e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.4214026203413454e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.372394580241622e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.337600587661594e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.2131537540864779e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.3805480037736922e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.3169989916019929e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.3808765844210866e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.307981488438493e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.1958097899767303e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.4301306432630666e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.479201663714649e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 4.131160791230537e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 5.562049056882869e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 5.5180707856360863e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 8.831163147559102e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 8.078431957722222e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 7.363720975002626e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 6.636662102693408e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 5.972995892424067e-08, Train_acc 1.0\n",
      "\n",
      "[Epoch 159 Batch 100] Loss: 5.506081428100691e-08 Training: accuracy=1.000000\n",
      "Epoch 159. Loss: 5.506081428100691e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 4.9927261838343496e-08, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159. Loss: 4.502766790641958e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 4.0618033367688056e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 3.7953213182299735e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 5.092152483472085e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 4.6481298020252836e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 4.2857622872668893e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 4.276280186830199e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 3.969724085083623e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 3.600691351593279e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 3.2406222164339516e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.9444996675881287e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.6593629260203592e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.412053082690187e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.2081006685240032e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.0059170520536894e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.9357104095948613e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.47788136041066e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.2300932243695942e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.0443367960354697e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.8957824620270673e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.976287513772892e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.8252248866854845e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.8755328995622587e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.72523250814976e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.962490124351491e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.924565843019563e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.2722750730176597e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.1009269113110384e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.900147445370978e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.7473855993776073e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.5726470394398468e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.5643938941436335e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.6035320677628367e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.4711185337841253e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.3426331307877994e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.4598265398202624e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.4407363140985982e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.3363610333539236e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.149291049867521e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.9902412860350212e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.9122890210772578e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.2425994817772756e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.2139170966331147e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.551318150142081e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.305499560318916e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.0749496042870245e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.8674546438583222e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.6993356287443535e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 1.548028515141782e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 3.898443314732944e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 5.3246699035726454e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 4.810829363597468e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 4.366999321340556e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 3.9582390620040726e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 3.571728380994709e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 3.214555542895238e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 3.06073794545509e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.829169930233467e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.9187814696763965e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.6920958940500565e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.562584655310236e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.418084827678796e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 4.606990463783773e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 4.2580500819503326e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 3.841558298946343e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 3.522595040393008e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 3.635995544684522e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 4.399292113298658e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 3.987302576986811e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 3.5885723192881296e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 3.360100167869426e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 3.0240901510824836e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 4.2117850340239456e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 3.8185462056395694e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 3.4553180354576994e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 3.147039126014764e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.88821455456754e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.6087063243018293e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.36646214114351e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.167068821131994e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.341516674287423e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.116678232049724e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.8828930015234765e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 3.097516399523742e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.8529573264717752e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 3.722493059834962e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 3.592387481142943e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 3.233148733028649e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 3.2544224662636385e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 2.9289802196372746e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 3.0738025642930345e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 3.00856601739164e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 3.3316931958538185e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 159. Loss: 3.028326196879775e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.7813729227869422e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.5125488556992913e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.3544262098273417e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.3797535011748684e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.3746084749670202e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.3047856376103992e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.0836202990404027e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.893884719518449e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.7138094727576474e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.6076210790596137e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.042903997822087e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.8479268232309217e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.7655795797066113e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.66934834759118e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 3.5572473236334545e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 3.229462266288127e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.9344557146773327e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 3.6188928779968714e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 3.312882931351437e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 3.1492325773021004e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 3.625931447421114e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 3.7196852984264836e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 3.794750467530888e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 3.4245886459688424e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 3.110069456389977e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.8083757359420224e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.5927307292482273e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.342770881514448e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.1457466919067304e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.977738138124155e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.8079039971093117e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.9682065940523502e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.6713859346471152e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.506692753335833e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.4329746783613485e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.1896772105252136e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.9800227146637356e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.7913336683884053e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.612200301549565e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.3543603266006798e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.156177192484339e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 3.8125023583813776e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 3.440565347734283e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 3.124448487978873e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 3.137965936335078e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.852109017719588e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.5668981159476293e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.394027318304691e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.424707848895616e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.1822370640060546e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.9919530304030216e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.053527835092233e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.8947411758728915e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.161614231668767e-08, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160. Loss: 1.9827057092660634e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.8123748111370294e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.8360281720937532e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.9038823612127152e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.9090717591792838e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.8357448515896664e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.719808323280076e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.4571407161431115e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.230053093800664e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.0163610096116408e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.0848083131804185e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.0998448287158183e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.0109322006081907e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.0519825302031648e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.8840371712856835e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.6956334541571152e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.6750816407438223e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.5541396009593218e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.3987256408633897e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.2774795271591373e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.2521770043602211e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.2107783267578079e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.2852779860613202e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 7.005352501018067e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 6.33275692593428e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 5.8391794951881946e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 6.112075898470315e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 5.6312534335423134e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 5.1705735378686485e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 5.901480760204979e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 5.311332684184481e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 5.0968484871739706e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 4.605790087728437e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 4.2849093852118575e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 3.949550668625083e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 3.582535276780593e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 3.680628531687194e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 3.312565678518475e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 3.7915583294966224e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 3.542787550411717e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 3.235074910778643e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.9581335439906607e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.690259864609613e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.5236793080656492e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.3085642758028116e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.1056475232405485e-08, Train_acc 1.0\n",
      "\n",
      "[Epoch 160 Batch 100] Loss: 1.904395996107537e-08 Training: accuracy=1.000000\n",
      "Epoch 160. Loss: 1.904395996107537e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.1051109896568648e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.0156717898640536e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.860670726285746e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.786362327083892e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.6542922186653847e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.5168026718168646e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.3651224046351782e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.2472366145537469e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.197018741304042e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.0866300923646812e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 9.779670831282131e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 9.360497248514286e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 8.98324089079646e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.74912222251707e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.3006403294885118e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.880824946935467e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.5927424522419204e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.3986607739181356e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.2146740421214664e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.0770256518611445e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.6516316335067307e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.684491161125959e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.546427107759904e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.5898073366437724e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.6567888646063506e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.4004232033367588e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.19763378154681e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.5739145774092812e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.3444627924659255e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.110016513219333e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.8990148618973996e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.7929323896594842e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.358694155052155e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.1321379647379828e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 3.157573529121565e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 3.02808051349682e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.7252724621471383e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.4620584411234677e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.3276112260289207e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.2066087324438284e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.013887531997018e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.8311252280691798e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.6573259304533053e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.5381594528160725e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.4309096229425629e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.3157583356663249e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.2400618388130528e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.1998746688835721e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.0798872019952149e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 3.3560530089309454e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 3.020447708037851e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.7649690570830554e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.5070986006466136e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.2563887405819523e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.0307498665237572e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.846301330253468e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.6616711972281214e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.5700098657109794e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.4968278664463533e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.3657715290735816e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.7786735583209786e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.7032516501694467e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.8216359503762487e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.8164234668798807e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.9793698688382943e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 3.308787267143493e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 3.005848213226716e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.7425162904477714e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 3.269198451804353e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.9609050570060046e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.6741277764964474e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.4253414492288894e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.1921205294970437e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.0008481515653575e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.0149672798804244e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 2.0276746197089633e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.9366657867558667e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.74299920808028e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.6059521858159793e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.4639834176164679e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.4107173155528007e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.418657098236371e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.3233575082617238e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.2562143110132823e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.1305928799119542e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.0175335919207588e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 9.15780232728683e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 9.91840095250917e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 8.926560857258254e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.1945452124218712e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.1030303661977025e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.0020405547689755e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 9.94968730108273e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.1655552793909558e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 160. Loss: 1.1384067132858757e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.024566041957288e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 9.96615217085445e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.0180255323772866e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 9.627891034294397e-09, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161. Loss: 8.665101930864957e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 8.171120723215732e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.983363451692951e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.7943403317146993e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.7546045603905727e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.5884573295425586e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.4296115965883028e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.1527757417398114e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.9374981675658304e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.7437483508092473e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.5786867409193658e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.7840330538033196e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.63356942122056e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.4795257042895473e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.3408863590516358e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.2161109483375156e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.0944998535037641e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.0223027666971147e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.907271719057415e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.7910503353573434e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.1800500117631175e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.0179243561819503e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.909264133616382e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.718337720254744e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.6023832893835218e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.4607714108272561e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.3798868410858298e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.2977775025723914e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.5777807969675432e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.4293159424618322e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.4540223405921616e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.3086201065329454e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.2056977686772232e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.792931727431793e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.6322650050707003e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.524917850158775e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.5307507962461183e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.4894343545210904e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.3777438131718163e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.249282657045678e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.2454262727504172e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.1674497697652573e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.0972709081968291e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.5835882756113925e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.499735227374139e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.3497617046367252e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.5873136758408244e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.4937748795980412e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.4002767283515975e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.3440680694682623e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.7032612678349466e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.9613424595604685e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.8117743290125194e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.6585365689088398e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.529935810561683e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.4141951236083499e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.365907833181926e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.2945096256459248e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 3.288446279929382e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 3.043420639242916e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.8228975715068807e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 3.16459209193745e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.8481328827437053e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.8054633395243805e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.7204944975512357e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.448445047796112e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.268793109916908e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.060540248197081e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.854486223377373e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.591041478729894e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.4343827607739023e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.2188841597145304e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.05287508489733e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.9593462498343176e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.1918189433599027e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.1775278378036337e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.00634117387226e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.1875484594260973e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.1643711587534857e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.078319176678952e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.8704872590110566e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.8510764366686214e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.6659687930017593e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.648383472349355e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.893326560565315e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.7039939045087838e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.8223039792816522e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.6959529269486315e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.638116272153352e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.6046896988027734e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.8260624160806538e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.7459016221531544e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.6085643584815662e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.5594665605329933e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.4221463548617804e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.2799317193756025e-08, Train_acc 1.0\n",
      "\n",
      "[Epoch 161 Batch 100] Loss: 1.5151539252124374e-08 Training: accuracy=1.000000\n",
      "Epoch 161. Loss: 1.5151539252124374e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.3822649830732802e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.6165670172322287e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.414166669858242e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.182063228063461e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.991796580275133e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.829869820791347e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.6561960639032556e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.6209615380230394e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.4681786094117788e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.4610590813722176e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.8830591266262918e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.722692886761235e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.615616169426411e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.5006206723327595e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.7789661012441842e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.656948827833126e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.537820069339695e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.4306041866956074e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.2875437680260468e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.1587893912234422e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.0894765719500878e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.1854198101162108e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.1320703915641048e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.387895742083034e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.204985509028983e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.394268109359886e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.173467747695761e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.956120972926185e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.7605088756335666e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.593771213261253e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.4343940919351279e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.3002679079326584e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.2261204582936449e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.2618331435675013e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.1635895042287695e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.224181683110718e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.1390164089024813e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.0437412172840967e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 3.9847379133003844e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 3.707335985616085e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 3.336602387054476e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 3.328904374448847e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 3.312663150520447e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 3.1769743807384003e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.8685901678556037e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.7307427008360306e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.504234550601417e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.607713212042379e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.365568340110005e-08, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161. Loss: 2.2128304934054765e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.177811745825204e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.0438495851945083e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.9512232823382097e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.811980290817749e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.6400954869270174e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.485399163425359e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.3368592470828231e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.4639432347048018e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.3361753616164082e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.2211842758368539e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.1456319681021583e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.1707671041935591e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 1.0723168430460668e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 9.650851587414601e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 8.685766428673141e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 8.469115410400979e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 7.715336121271315e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 7.875124728488293e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 8.484594874112894e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 9.219383053005184e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 9.042502540943522e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 8.138252286849169e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 3.67539248302353e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 3.307853234721177e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.986381136440103e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 3.5352423024397636e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 3.1817180721957876e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 3.7389850797497975e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 3.3837130221569044e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 5.6716514851602625e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 5.11379956183528e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 4.602419605651752e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 4.188743760494674e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 3.863001624143186e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 3.784037627134881e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 4.1506892951056535e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 3.735620365595088e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 4.3026888713809676e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 3.8817332094339144e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 3.78226935371427e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 3.8603897693616913e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 3.5022904674435404e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 3.180001093496759e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 2.9365067545891847e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 161. Loss: 3.00048367777637e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.700435309998733e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.439705004189903e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.2423006280607944e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 3.470922128753995e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 5.042331255893296e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 4.612603918509637e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 4.5890644261852125e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 4.1580976563642635e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 3.93786538270713e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 3.553392069627461e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 3.31912476183759e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 3.015151960671849e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.806768977657291e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.55403175490958e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.5966513059156603e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.3462994005151374e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.1116694604636237e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.9005025144172613e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.56726455520254e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 3.2418566952584444e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 3.19706738955517e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.8773606505996532e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.8317682773040285e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.557904674764669e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 3.326565202434456e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 3.114980563600318e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.980433601017975e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.6823902409161774e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.442090891842578e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.412085852711333e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.319888826087971e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.0972131686702173e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.8874918518031956e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.8011880787763052e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.937718519942296e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.7439466679480666e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.671997439952042e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.5606770415519822e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.4418622381609572e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.3814950105331178e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.3644174086526815e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.2466021170592769e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.1219419053533492e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.587166041304182e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.614713881042586e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.4998086127873173e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.3498277515085856e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.4011093846994125e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.2609984462294712e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.1814647258964058e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.0633182533067652e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.0408054508096977e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.0205439196805525e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 9.464292027305156e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.0287373939987211e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 3.906049281764915e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 3.571323699183568e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 3.214191329265211e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 3.1535420909053824e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.8847540016638338e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.801169443567877e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.6328111282288892e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 3.0028282292761486e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.8329305401493484e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.6241432832218677e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 3.358237785907895e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 3.0317272325081485e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.737867734448377e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.4733941861945825e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.244681217957211e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.02021309616149e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.8461314593429132e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.7045948363416283e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.4341353527074655e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.293167273999069e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.1476695339056343e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.2402384617039905e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.0255278407246348e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.8788544022473158e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.1752552086828883e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.9670429130056428e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.7703386217050787e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.593304759534571e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.4339742835811139e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.2905768552230026e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.2639646351448367e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.1468813968213962e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.0415064823303e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 9.746087282001051e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.1286046307820426e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.062310283111936e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 9.840189298187607e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.0253153342113644e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 9.320970259812714e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.2766081873825466e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.1768870436623103e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.180270202941818e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.0622431826476362e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.7848931136197052e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.755415387550859e-08, Train_acc 1.0\n",
      "\n",
      "[Epoch 162 Batch 100] Loss: 1.6543796370014432e-08 Training: accuracy=1.000000\n",
      "Epoch 162. Loss: 1.6543796370014432e-08, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162. Loss: 1.9173492049731363e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.8094332717822948e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.7961278481627358e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.6258282885375055e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.4818719100658414e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.3336847190592572e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.2561955927484761e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.2143950207801006e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.0929555187020906e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.542452516841339e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.449907752682946e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.251483097263641e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.0449612379193635e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.933597327180054e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.8519962678887693e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.6667966410998925e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.5001169769899034e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.3501052792909131e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.2244079765528652e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.1205936292796652e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.0551003906415806e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 9.775300265954409e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 9.263431437848865e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 8.523352797884844e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 8.322943231509352e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 9.912084049644982e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 9.386536843170382e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.040365878918901e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 9.363292910270109e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.6680678603227635e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.4105742994815303e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.2160829849414752e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.0317275849910547e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.8378680516829927e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.6633944717057367e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.037220554618122e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.870751397700037e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.8420009357425492e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.6764272914401578e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.5739771247556573e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.4258926374711348e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.2833033737240214e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.1549730363516193e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.1326079724144369e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.0193471751729932e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.3458200603818046e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.3043702585144669e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.3567076444084332e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.186229442427105e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.976919723375438e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.8537335392435642e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.1805860381637026e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.9718406595383755e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.7839698187755814e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.6055728368980232e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.4543287783992641e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.5754849386551823e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.3179364447896642e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.663560664944087e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.4717103777735642e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.233852565187251e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.019780533859569e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.6280496387296733e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.5328826494696502e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.298220833794549e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.18947058741548e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.970523528673932e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.7734711758065388e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.596124058225885e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.5296438654559233e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.6001967902366353e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.4401771112129719e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.2961594000916748e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.4552530851783694e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.384233547102634e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.3203159894798247e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.5235600910677732e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.3898305312328595e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.2508474781095736e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.2934007226751288e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.164060650407616e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.1221603780134163e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.1030765799100541e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.002082147110092e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 9.018739323990828e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.3984186598256855e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.258576793843117e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.1606587894768237e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.556819544970645e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.410450815664624e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.2880321844802481e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.17785541641431e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.1345756629785488e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 1.2539485449353112e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 162. Loss: 2.1418306194711965e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.927647557524077e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.8745811524368545e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.7243759357368962e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.579878017181225e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.5243356453801e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.5116004137437064e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.4349461428114373e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.30658666892227e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.1318073476251874e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.927939838053712e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.8282780939463202e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.7665221393156425e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.5991831505751214e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.5044573979771242e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.4005777735875095e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.316399341823903e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.2592651780836143e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.2357841079558186e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.1587718125683343e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.1546532603293007e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.2533920198765202e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.1373660430799115e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.0422558891540068e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 9.473435254296494e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.4579665726499912e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.3214831405760354e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.5339237883276543e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.445723971954404e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.310464799950007e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.4867542011439257e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.5674156266834942e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.310674064015145e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 4.5475731110369174e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 4.25114049550931e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 3.835339671149422e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 3.479745379052498e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 3.215589828453721e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.959223416949648e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.886818173418167e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.6074495812673937e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.449150053057652e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.204235047751887e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.1421362918434877e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.9838020082542833e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.8785540115996976e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.690698610439728e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.521628749395755e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.151772929148135e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.9645353112513396e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.768081780126206e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.2711360973033945e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.0719621625910733e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.0230907307258923e-08, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163. Loss: 1.904600671605128e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.7327670548267018e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.568803574535075e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.4119232170815675e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.2893573446452744e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.1790480605628335e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.0704564796975934e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 9.63410831727834e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 8.95009423573069e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.1035311366585267e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.0211176957902464e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 9.190059262112219e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 8.271053335900997e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 7.537080254221331e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 6.8765044807096305e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 7.865233245861057e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.5553706980968074e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.427773301084699e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.3036224202480927e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.191886627495147e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.957449365776913e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.7803308795813083e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.6116110168142206e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.5249556855749e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.3817733422084534e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.2529092331786513e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.2859431297818491e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.492624339703911e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 3.029037718002048e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.8937718319969456e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.6323343238152694e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.3691008914337424e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.2160097984786245e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.1527335142068464e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 3.157483356368327e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.8510482459225374e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.593883094127856e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.353121235097157e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.1178091115874414e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.9712207628882124e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.3608305585759447e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.8139245026312384e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.700170026981059e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.7188625605609733e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.446976304504876e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.248844793903378e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.079839660108185e-08, Train_acc 1.0\n",
      "\n",
      "[Epoch 163 Batch 100] Loss: 1.983614367524087e-08 Training: accuracy=1.000000\n",
      "Epoch 163. Loss: 1.983614367524087e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.027396622536019e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.8339701854734602e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.4887613524518376e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.565847620942156e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.318576084038984e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.0867184756350857e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.878046628071577e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.699555190455463e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.7717431677750045e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.7435804096452755e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.569222368680748e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.5799381241891858e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.4405707621523539e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.3710194652610041e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.2804836341430013e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.297957774249325e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.077475222015436e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.888354149085756e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.6995187341771803e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.57613297616756e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.8376141265850337e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.672479164308617e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.9615785633694672e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.8864925440329065e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.051745335076446e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 3.5788140215450276e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 3.248872294408543e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 3.6690412772489586e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 3.488401451284338e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 3.1488745313469476e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.9736853578231644e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.685630047231891e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.4356934928907886e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.4063281758911542e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.3240200716416916e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 2.0916180644775225e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.8824562580297704e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.6942106322267933e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.6086085651923702e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.6898912583289264e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.5302153576870772e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.6845299162701095e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.5160769246430986e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.5134807908265602e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.3621327117439042e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.5053157511013792e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.5783013274454303e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.4949769829065573e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.4199850772624636e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.3618055746062578e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.2349382423366754e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.19526340540948e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.112989958971367e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.0389438571770654e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 9.350494714593588e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 8.41544524313423e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 7.946429704258078e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 7.338051226550905e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 9.398208853943101e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 8.551520220459224e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 8.348293911826295e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 8.537919086267166e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 7.68412717764045e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 8.87149009021207e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 8.356870088832595e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 9.66322198175831e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 8.790032035492912e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 8.004161083854053e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 7.203744975468648e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 8.718541637192305e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 7.939819725383507e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 7.145837752845157e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 6.990047433512086e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 6.8498360572944815e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.3336009986022995e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.2468070185910593e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.1221263167319535e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.727028799016092e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.8337223717548955e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.7062294757336584e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.591485873755437e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.795552593100015e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.6905031264365754e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.521452813792918e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.518319099943182e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.3944268649668821e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.2549841784701939e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.1294857606231746e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 1.0165371845608572e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 9.521363646484984e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 8.662359533746918e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 7.796123580372227e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 7.109643474245437e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 6.398679126820894e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 163. Loss: 5.7588112141388045e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 5.555459078162194e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 5.6518387061232845e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 9.836393571165274e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 8.94588646595918e-09, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164. Loss: 1.0658999429565446e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.1362611490199892e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.0971408223236602e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.1178118028378352e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.0060306225540517e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 9.240540106807331e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 8.502750599947464e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 8.67692966148701e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 8.088633423314032e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.7431140669556255e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.568802660260063e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.4119223942340567e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.2707301548106511e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.4789328043383801e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.3496659731764057e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.2333258251306288e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.2683179737207869e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.2066787388082233e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.086010864927401e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.1264213282006482e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.0324056457626699e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.1061162993090702e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.0141311197602498e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 9.499709085483978e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.0784911290198625e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 9.892684653897398e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 8.99654844041809e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 8.376290346556464e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 8.19058698090489e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 7.371528282814402e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 6.820639947251597e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 6.138575952526437e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 5.617850609184227e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 5.149197800176237e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 5.844997011887368e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 6.005555015119647e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 8.012699525088711e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 7.21142957257984e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 6.862815600759126e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 6.362798533401848e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 7.402897715648369e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 9.363439147212005e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 8.799624217928075e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 7.919661796135267e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 7.2208278684321734e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 9.851500665862793e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 8.959482851186947e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 8.156666817978684e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.0414360013884113e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 9.745452953524053e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.1844269312231783e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.8110408767077718e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.6299367890369946e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.4669431101332951e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.3202487991199657e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.1882239192079691e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.143907306611058e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.0481430263320388e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 9.805816178016699e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 9.756556957194825e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 9.5259590547142e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 8.759627641961416e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.2912795412005086e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.3577290790597509e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.2312693963448192e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.1174556819013805e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.0057101137112425e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.5384359661790686e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.3845923695611617e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.2833860311487727e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.2947457076448069e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.1652711368803263e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.0953101386003914e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 9.857791247403523e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 9.151408872843354e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 8.236267985559019e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 7.412641187003117e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 6.950773818482989e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 6.62822542207196e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 6.989857179034739e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 6.663400446568536e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 6.183324905732548e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.1991092600467608e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.749748314028475e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.6772188947790567e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.546749899403986e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.5224599633283442e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.3795271921865531e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 4.966820149346007e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 4.544643922617076e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 4.118119205373387e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 3.7249337341079114e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 3.380380033494693e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 3.042342030145224e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 2.7381078271307016e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 2.5201763855718837e-08, Train_acc 1.0\n",
      "\n",
      "[Epoch 164 Batch 100] Loss: 2.4171702878988983e-08 Training: accuracy=1.000000\n",
      "Epoch 164. Loss: 2.4171702878988983e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 2.194079708380872e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.974671737542785e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.7772045637885064e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.608797332600699e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.4851704978843562e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.578797051042419e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.4302305711292204e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.3617133022219682e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.2348551971908147e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.1206829026627765e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.0179278375875422e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 9.254482790198313e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.0377942221340011e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.0364602387193826e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 9.886935515608047e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.3834244504081921e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.2730216803853912e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.3599234380548863e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.6243987710470867e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 2.1511345438240683e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.9453343146327048e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.7787405581874527e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 2.1224054743779465e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.9287913773222383e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 2.313330423967635e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 2.0819973815708714e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 2.0228091931797715e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.885720845203094e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.7716545400066704e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 2.0601497338252804e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.9472669823771635e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.7525402841394473e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 3.486485880786367e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 3.156463743089817e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 2.8780702673245628e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 3.2421863427605456e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 2.917967708484491e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 2.6727370574850315e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 2.4054633517365284e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 2.1928566915808937e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.992197472804891e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.8116041759064885e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.6304437583158396e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.4673993824842557e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.581429356566091e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.423286420909482e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.2809577788185338e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.2087413509727171e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.0971804410664887e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.238919083543946e-08, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164. Loss: 1.1150271751895515e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.0780302369944821e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.3800086487459294e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.325826797823161e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 2.3201369726268488e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 2.1626290458062654e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 2.0301851285321107e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 2.1251894132302116e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 2.0337423089075766e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.830368078016819e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.6659577194870007e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 2.9801509145392908e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 2.7193887238495347e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 2.6523406047171658e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 2.4057329946275358e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 2.1930993701828006e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.992415883546607e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 2.026004583574448e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.9165363471514145e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.724882712436273e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.990114985447817e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.8376696023111332e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.65390264208002e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.5164520506695903e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.8118411840381458e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.6585967406523494e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.502050291778158e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.3797849353979144e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.27905934040185e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.1977195217697625e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.7391838264531065e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.5838918930796595e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.6862727937376385e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.5362719636357384e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.3826447672721646e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.2443802905449481e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.1292554866814966e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 1.016329938013347e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 9.146969442120124e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 8.232272497908111e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 7.688441998297483e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 8.502845109499945e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 8.770147332817157e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 8.358793798025339e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 164. Loss: 8.118960786040654e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 7.307064707436589e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 6.948887244334661e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 6.347130771811628e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 6.550607834148712e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 6.174943778709564e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 5.836846151018791e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 5.439426028635548e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 5.826805822751787e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 6.082315379994855e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 6.591670665080419e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 5.932503598572377e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 5.618649966690862e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 5.336181697997498e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 7.410262651500358e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 6.669236386350322e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 7.026767402156633e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 6.417222913851403e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 7.079351427567355e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 6.557680777529255e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.1676105556964938e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.0508495001268445e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 9.4576455011416e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 8.698145454848306e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 8.480256445140786e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 7.632230800626708e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 9.942367598267333e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 2.925070574858769e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 2.67912963278099e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 2.420529894693934e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 2.1784769052245408e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 2.6311787683628353e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 2.423940228239912e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 2.190859430606964e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.9717734875462675e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.7745961387916406e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.755461273779266e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.6078548214193575e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.475009012074994e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 2.314703787183827e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 2.1670524312990536e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.9782868609667204e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.8177110734137756e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.878083586782465e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.6902752281042186e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.6795724363970178e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.5302416420291797e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.4144703763699887e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.282336563924033e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.3683068865303692e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 2.19073496807187e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 2.5490795490608935e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 2.3034848193458476e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 2.082449562602306e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.9021442791396476e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.721243076416726e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.5491187687750535e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.4314597860003832e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.2976270325913883e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.1864907786041131e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.1237210374570623e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.0206621589023993e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.1514262313946612e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.036283608255195e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 9.512816978117622e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 8.654667532216293e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.039690025756864e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.0381664708617434e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 9.343498237755691e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 9.619866961619667e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 8.6578802654577e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 7.79209223891193e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 7.757940808259594e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 7.2615434776138175e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 7.839239934953528e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 9.476750905109057e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 9.087869270549597e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 8.179082343494637e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 7.454306361055606e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.3321248951694284e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.208225630843529e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.087403067759176e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 9.879759861743017e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 9.264312861005986e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 8.710410560342659e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 8.584427208729409e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 8.377910023633778e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 7.633251273180833e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 6.8699261458627496e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 7.952445712503148e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 2.205825006934824e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.9852425062413415e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.87985045978805e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.757057967386976e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.5813521706482786e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.4232169535834509e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.5044124274428632e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.391224078801412e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.261414896112314e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.321537726024926e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.2545765203228408e-08, Train_acc 1.0\n",
      "\n",
      "[Epoch 165 Batch 100] Loss: 1.2501907052909429e-08 Training: accuracy=1.000000\n",
      "Epoch 165. Loss: 1.2501907052909429e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.1251716347618486e-08, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165. Loss: 1.0964734763557042e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.0240790272638607e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.0613694485573072e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.039051517653401e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 9.444595910791042e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 9.431458716691733e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 8.674577337741197e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 8.552177397205934e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 7.883224150203977e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 7.09490173518358e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 6.944204928798826e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 7.181106832898737e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 6.649260642327499e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 6.077466830005181e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 5.562852398915096e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 5.751625041080286e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 5.828388072749567e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.92153125671768e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 3.722394229868321e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 3.992764896466594e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 3.602801632010978e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 3.279774362912715e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 2.951796926621444e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 2.6659304591503428e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 2.4365903117790357e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 2.5840858382340767e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 2.325677254410669e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 2.0931095289696022e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 2.1259420902012986e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.9599140054710504e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 2.3506539084663102e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 2.6091887360960106e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 2.3575830876774528e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 2.131138004100751e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.9366506540727624e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.947876341918071e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.846220920778891e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 2.080693134626684e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.928503157877376e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.9126039358673267e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.7306567674716374e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.585530763522046e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.4269776871698415e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.302906367724721e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.880419111303173e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.8320754797837674e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.6674943810772543e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 2.310991745954222e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 2.1916512536673045e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 2.2611957178692993e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 2.081642261490467e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.9479838235470905e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.9115101722956026e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.7203591550660425e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.566949689941525e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.438194395965391e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.4806392758926954e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.556092517521183e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.5308683196338214e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.3870947128614825e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.667479476446743e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.5007315288020687e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.3879112744655889e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.472637387291061e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.6047701012023672e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.4536063162731739e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.3175589098368998e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.2230559173969368e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.1845693218454994e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.0661123896609494e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 9.688143758858978e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.0395709306738206e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.084625360727073e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 1.0692950643523452e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 9.623655579171108e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 8.661290021253998e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 7.795161019128598e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 7.015644917215738e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 6.407212677404597e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 5.85962366157457e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 5.2736612954171135e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 4.746295165875402e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 9.67331775267514e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 9.823572622856989e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 8.84121536057129e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 8.050226076424593e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 7.990261350838833e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 7.470631943730671e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 6.723568749357604e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 6.237476367140479e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 5.613728730426431e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 5.145488109294221e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 5.096600496854697e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 165. Loss: 4.5869404471692275e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 4.128246402452305e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 3.9016862660279405e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 8.820038195893612e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 8.68309225836095e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 7.814783032524855e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 8.616552395575947e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 9.431276013969375e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 8.860677353600788e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 7.974609618240709e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 7.177148656416638e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.055724459257025e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 9.594652385223658e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 8.821451650522159e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 8.032438737380376e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 7.229194863642338e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 6.971936575768002e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 6.274742918191202e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 5.7404008782825145e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 5.259493042364696e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 5.385469273905536e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 5.591980228571682e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.751240522957892e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 2.1535343352954924e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 2.180324558003147e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 4.150878409941493e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 3.847549197965143e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 3.54661328323867e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 3.191951954914803e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 2.8727567594233226e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 2.594794308672034e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 2.4563867148052166e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 2.266627384478947e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 2.1610365540857123e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.9914990229670228e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.8389152360784183e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.6829633874885946e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.5146670487397353e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.428392915207061e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.9188516243936825e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.8294119185166643e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.6557839518560413e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.5181452316884555e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.403583602622445e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.2911649151577728e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.525263410617886e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.3820502947471406e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.2624717156545132e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.648450290352146e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.5022317116990178e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.4172011118704153e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.2754810006833737e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.1572461258060797e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.0508347384165151e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.9329477224882057e-08, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166. Loss: 1.9911096368234914e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.8292515716848696e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.86053030469728e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.683790499418595e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 2.0928293141101248e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.939425728294257e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.7454831554648313e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.7199463896843354e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.7621557652417782e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.5859401887176005e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.511165183797665e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.3600486654178986e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.438247689057006e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.313049369423169e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.1910576576718954e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.3140953882697941e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.1826858494428148e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.0644172644985334e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.479515185073518e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.3315636665661663e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.2170337502916362e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.1046436004535158e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.0593718117494635e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.0279404098984029e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.3628668065823236e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.2358933511151345e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.1216172411946643e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.046708415618925e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 9.699772468546048e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 8.91605972551231e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.0073360930215556e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 9.066024837194e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 8.438819081450323e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.4207299741908494e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.2786569767717645e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.1973573989435779e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.2731992220827865e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.2110718667749152e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.155157246997831e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.1514001513158475e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.0828262515923604e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 9.838568516241677e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 8.85471166461751e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 8.714298380212457e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 9.519247400142234e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 8.56732266012801e-09, Train_acc 1.0\n",
      "\n",
      "[Epoch 166 Batch 100] Loss: 7.803722646025642e-09 Training: accuracy=1.000000\n",
      "Epoch 166. Loss: 7.803722646025642e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 7.2096148852439435e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 7.326843358602112e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.0598838632889733e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.2053522878891608e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.1593228384241304e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.127209568533542e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.0238018368712312e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 9.773009898974684e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 8.888841160987648e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 9.86260130594142e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.0738985258764133e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 9.66508673288772e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 8.698578059598949e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 8.573778046877912e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 7.995796992370303e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 7.196217293133274e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 6.849124504848296e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 6.629873297262284e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 5.966885967536056e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 5.370197370782451e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 4.9263098856146385e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 6.855114571246792e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 7.194057590927772e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 6.66091632455363e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 9.626978825113586e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.0806319844411202e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 9.725687859970082e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 8.753119073973074e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 9.554186202162472e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 8.598767581946226e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 7.832023075662036e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 7.048820768095833e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 6.34393869128625e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 5.8958093259784905e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 5.3062283933806415e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 5.42753126745557e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 5.81610018241844e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 5.327622416087029e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 6.28497487277762e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 7.3328571316293e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 6.97210040390364e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 6.6474193489505464e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 6.820867287120213e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.5079426115639812e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.3571483504075831e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.2214335153668248e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.1551695094252868e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.0396525584827582e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 9.54313751906346e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 8.588823767157115e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.4901093951100215e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.3969778011941638e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.834697885708137e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.6512280971373234e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.4861052874235912e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.3561212079530957e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.4347130128658205e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.309868160851102e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.188194569957035e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.0786883381523748e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 9.801327295281806e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.087010245355084e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 9.783092208195755e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 8.897915239286613e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.0243295229899842e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 9.684626949808676e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 9.461221959248824e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 8.515099763323942e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 8.0361187280199e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 7.605035862859641e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 6.9376645284841096e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 6.523294825815882e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.8257467478320924e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 2.118145236071579e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.9156439376554645e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.7333927690809613e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.5693667173639085e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.421743270818561e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.5962182638346e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.5297286771491194e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.497827664198162e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.357358122969389e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.2588752092161772e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.207493458736661e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.1333102282710925e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.206243631549237e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.0856192683943134e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 1.014310235657717e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 9.221924372829887e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 9.044789817603596e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 8.140310835843237e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 7.326279752258913e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 7.245577312810331e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 6.707284085350164e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 166. Loss: 6.036555676815148e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 5.526032361044066e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 5.625354838352652e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 8.508708972609612e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 9.427349190761221e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 8.484614271685099e-09, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167. Loss: 7.729285096427022e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.2823670688022073e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.2658890442304914e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.1672398148254606e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.4137309624273523e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.272357866184617e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.1451220795661554e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.2448138861354161e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.1296457227129177e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.1284398238683467e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.015595841481512e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.1189269572952403e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.0256607119478028e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 9.882872120943218e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.4389369269697721e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.2950432342727949e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.1655389108455155e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.700908477200771e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 2.089609362366005e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.8806484261294046e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.9067874736973614e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.716108726327625e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.5444978536948628e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.3993612935164197e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.268738389355821e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.141864550420239e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.0369913205692583e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 9.426054137033758e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 8.483448723330382e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 7.914500601177528e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 8.33376908869932e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 7.500392179829388e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 6.750352961846449e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.9020617608774136e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.7677349259439246e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.5909614333495322e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.469118188558306e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.3501460425000476e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.3082636779480224e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.1867505353442634e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.068075481809837e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.1661587401721432e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.0774825411729472e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 9.88360737437739e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 9.733436776457898e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 8.85322535072254e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 8.061035067560719e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 7.53432831098483e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 8.643538497489096e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.113193916619992e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.0018745249579929e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 9.11000297653237e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 8.292134930789566e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 7.556053689621043e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 7.172977261687288e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 6.548811787428992e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.0084871536314709e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 9.262648875401874e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 8.336383987861686e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 9.179124802297907e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 8.447476814786753e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 7.602729133308078e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 7.21498516100562e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 7.331676517969779e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 6.598508866172802e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 6.124922472274157e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.0262163631630542e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 9.515343996443211e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 8.56380959679889e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 7.893693140939868e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 7.104323826845881e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 6.85955259824227e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 6.359861842238909e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 7.400254515966039e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 6.660229064369436e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 6.366735143369763e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 6.475119422271644e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 6.0138719727631145e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 7.1819969567134765e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 6.463797261042129e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 5.817417534937916e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 5.235675781444125e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 5.364033916712706e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 5.200159510478706e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 4.86640805214947e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 4.379767246934523e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 8.13273642366884e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 7.319462781301956e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 6.58751650317176e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 8.070804642841977e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 8.75383958739981e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 7.878455628659829e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 7.090610065793846e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 7.312871100922889e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 8.909887940469721e-09, Train_acc 1.0\n",
      "\n",
      "[Epoch 167 Batch 100] Loss: 8.298295896602932e-09 Training: accuracy=1.000000\n",
      "Epoch 167. Loss: 8.298295896602932e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 7.468466306942639e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 6.721619676248375e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 6.1425899605339705e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 5.528330964480574e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.4009280656524835e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.2701484842782784e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.2083261983099657e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.0968068036700124e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.0057525725748747e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 9.703698777769023e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 8.826461151902555e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.0737779918387792e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.6835159461006975e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.580356922831927e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.4968270276361885e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.66379336075337e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.5067272498690766e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.3560545248821689e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.2297622975849953e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.1533521832345934e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.2335944568904272e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.1102350112013845e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.0178379604633327e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.1581977140727928e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.0889440625145034e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.0079893290606253e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 9.72382958614078e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 8.844578879437134e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.2523588106797287e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.229568341765185e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.1438644016915016e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.0853573026766038e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.0978934538182504e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.1371156493206285e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.079283425542818e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 9.806683081795794e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 8.826014773616215e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 8.036545548165027e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 7.41915549716939e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 6.770372199362884e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 6.279599472145231e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 5.651639524930708e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 5.552136770927535e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 5.835112966899503e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 5.437866162928188e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 4.894079546635369e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 4.4046715919718324e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 4.150468936595515e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 4.666744173462232e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 4.479466484091732e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 4.776577717739257e-09, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167. Loss: 4.298919945965332e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 3.869027951368799e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 3.575257408142352e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 3.3108639192385496e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 3.9110995690231214e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 3.613121864031242e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 3.3449419295385506e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 3.5692411037182988e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 4.423035985075223e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 2.1955088967475327e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 2.0038976820907977e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.8128211390727613e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.7060447956075865e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.535440316046828e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.4377756300372898e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.3591906339339681e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.2232715705405713e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 2.1812711393417438e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.9910837004255877e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.866481118588699e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.949916233624087e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 2.8445696067164867e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 2.6066787614529358e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 2.858237519749146e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 2.6655459985904267e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 2.398991398731384e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 2.1590922588582456e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.9524962581634644e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.766559857538161e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.6178435468023632e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.4746856425042134e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.364469972356627e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.2280229751209644e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.1145339027999113e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.049646636809802e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.894626664925922e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.70516399843333e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.54396082378104e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.5665159062348983e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.4098643156114085e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.3713232962036968e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.2993835201610581e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.1787583933359957e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 167. Loss: 1.0608825540023961e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 9.827339713997287e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 9.496531456010552e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.4507329998179316e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.3522258241260202e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.2170032417134182e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.1046161427331197e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.0220942012573801e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 9.198847811316421e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 8.372095282095212e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 7.534885753885691e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 6.874529430407555e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 6.280208739277232e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.0774446393794456e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.0535191627479732e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 9.574804716642191e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 8.896720995158155e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 9.12463527463818e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 9.609154365647791e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 8.648238929083013e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 7.783415036174712e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 7.377602517994511e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 9.620068820622706e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 8.751194190470869e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.2812071982387942e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.1810261512124872e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.0722367612822818e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 9.743263103450969e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.035218357123103e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 9.596361964288112e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.0685633300385146e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 9.803334463065268e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 9.009265509477377e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 8.10833895852964e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 7.483769566497543e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 7.852979344114996e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 7.160813661613929e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 7.282922434970783e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 6.927159132502055e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 6.234443219251849e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 7.194245853087506e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 6.940482466268653e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 8.481606622362096e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 8.564768090652156e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 7.801423533497373e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 7.766338973386493e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 8.852348093650594e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 8.712171166342233e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 9.331069103278672e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 8.397962192950806e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 9.048281382497756e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.5780280592526512e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.4202252533273861e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.3154556265383746e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.1839100638845371e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.0655190574960834e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 2.0579232423192308e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.8521309180873076e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.8345557120736793e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.6883530349691464e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.54745740649025e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.4485910025545855e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.3316715773171452e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.1985044195854307e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.1159068761706146e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.0043161885535532e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 9.597639064115583e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 8.637875157704024e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 7.774087641933622e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 6.99667887774026e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 6.855804445917679e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 8.405396048774852e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 7.564856443897367e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.1278709210063628e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.0150838289057265e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 9.22888671206197e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 8.399130292766206e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 8.118010719441031e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.0472701072119037e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 9.611695468728e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 8.836790414573835e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 8.232508123296636e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 7.409257310966972e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.868232742247826e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.6907226932140865e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.5682165437416675e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.6162856426200854e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.4639703035491202e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.3361997235762947e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.2025797512186653e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.1009482253686623e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.0001666280228393e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 9.001499652205555e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 8.194481938895432e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 7.933827200957334e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 7.792370105456752e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 7.0131330949110764e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.646317118933973e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.490998632231619e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.3698384440264756e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.232854599623828e-08, Train_acc 1.0\n",
      "\n",
      "[Epoch 168 Batch 100] Loss: 1.1095691396614452e-08 Training: accuracy=1.000000\n",
      "Epoch 168. Loss: 1.1095691396614452e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.026551900713319e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 9.704628260500847e-09, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168. Loss: 8.827297686361195e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 9.62094730858315e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 8.658852577724836e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 7.792967319952353e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 7.10680283986755e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 6.396122555880795e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 5.756510300292715e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 5.273991522173877e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 5.491650252013188e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 5.4081464253017665e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 4.86733178277159e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 4.473730856404864e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 4.026357770764377e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 3.903118743868123e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 5.002921923051973e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 4.5957619826572085e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 9.444706340859953e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 8.500235706773958e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 8.209005592048008e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 7.481237284753639e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 6.919378048996911e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 6.22744024409722e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 5.604696219687498e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 5.044226597718748e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 4.726068441767739e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 4.253461597590965e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 4.293776636321766e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 3.8643989726895895e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 3.5710913273310635e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 3.5865111356263065e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 3.9729178153025325e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 4.413816173290526e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.2261167100731502e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.1500711544739328e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.0443772642175828e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 9.95818883390969e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 9.055502202429153e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 8.149951982186238e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 7.52122127668625e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 6.769099149017625e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 9.631209333312794e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 8.85435289270015e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 8.341446544458486e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 7.507301890012639e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 7.315365068144979e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 6.583828561330481e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 6.76363584471568e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 6.832330142300811e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 6.80102266384804e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 6.2140526493736684e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 9.969852116445279e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 8.97286690480075e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 2.2604080217373292e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 2.0343672195635962e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 2.5387340911209815e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 2.303487131280747e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 2.0731384181526723e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.865824576337405e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.6885553438947078e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.603518796811709e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.4711065899281104e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.3239959309352994e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.2009095630328128e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.3602150771335123e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.3918315262695368e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.3644070470693038e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.600494519557282e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.710528401077222e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.5394755609694998e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.6649246173850777e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.49843215564657e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.3951550599309028e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.3767114442289038e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.4346178450760116e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.3004692857594537e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.1704223571835084e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.0533801214651577e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.0039214504728942e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 9.128425306166482e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.473481948157611e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.4658320151891929e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.3192488136702737e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.3177089861680031e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.1859380875512029e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.2536086693741995e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.1468742517086432e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 1.0321868265377789e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 9.848474850382533e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 9.143024115524463e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 8.321853955882451e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 7.489668560294205e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 6.9269662080856505e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 168. Loss: 7.128339116799398e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 9.209467955166745e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 8.28852115965007e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 7.459669043685063e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 7.365627763911708e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 7.467254860585258e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.1004602559616898e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.0090406796373844e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 9.360762866916643e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 8.517818832135412e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.1205058469204275e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.10158749304458e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.0566213150814211e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 9.975252989813767e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 9.909049998994343e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.7765673930805168e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.645476769180563e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.5833745310612884e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.452976752973178e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.3076790776758602e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.3445490557033764e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.219407375324082e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.5631266816496253e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 2.44988975482066e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 2.2142140045296373e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.9927926040766737e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.9611512827548136e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.7650361544793323e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.737544079915602e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.563789671924042e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.435350379749656e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.3849475548273173e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.274392472142158e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.1655796753100287e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.0583349329700691e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 9.804411146910806e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 8.823970032219726e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 9.617952064584459e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 8.656156858126013e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 7.790541172313412e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 7.197751547800707e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 7.409298612364747e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.2442548818547639e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.1570822877721225e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.2276383785187536e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.1048745406668783e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 9.943870866001905e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 8.949483779401715e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 8.147667653371977e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.4876578925826104e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.4227111083943898e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.3083796703525232e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.1775417033172709e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.0877272080035621e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.258350833262208e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.2070215203780888e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.08631936834028e-08, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169. Loss: 1.4060946434338582e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.2934248518880447e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.1733955918902836e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.0560560327012552e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 9.970165537210115e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 8.973148983489104e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 8.26209857785883e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 7.435888720072947e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 6.785432099976085e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 7.131343277966294e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.0795412616364538e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.1671646629792382e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.2739654902440505e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.2024482868147899e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.1008299085153975e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.074565913852114e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 9.95048997484921e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 8.95544097736429e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 8.153029131538294e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 7.337726218384464e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 7.255879221141169e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 6.5302912990270526e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 5.877262169124347e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 5.289535952211913e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 4.853714608901155e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 5.113401030067739e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 4.602060927060965e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 5.631969532654162e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 5.068772579388746e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 4.655027573360304e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 5.4933753546718405e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 5.409698973285632e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.4275031657240014e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.3685718364580734e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.2782807682203637e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.3180906482477031e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.1862815834229329e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.1980385055907489e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.0875478802227172e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.0253592120494354e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 9.693894106934816e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.217039076161988e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.0953351685457892e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 9.858016516912103e-09, Train_acc 1.0\n",
      "\n",
      "[Epoch 169 Batch 100] Loss: 8.965347117131325e-09 Training: accuracy=1.000000\n",
      "Epoch 169. Loss: 8.965347117131325e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 8.161944657328625e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 7.625146919571486e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 8.259615023723453e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 7.4336535213511075e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 7.062817110244346e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 6.542799903040777e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 5.981652164647132e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 5.476619200092852e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 5.674014984504583e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 5.292877978772759e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 5.508647885316499e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 4.957783096784849e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 4.462004787106364e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 4.481465506885625e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 4.871508829261784e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 4.384357946335606e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 4.039054403612479e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 4.3802068453079296e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 4.221582888752859e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 4.358218055829019e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 4.57432196365911e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 4.210022019203632e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 6.582982567330554e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 5.924684310597499e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.0454475473796799e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 9.781556911854389e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 8.80340122066895e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 8.10932560242292e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 2.0802463792694704e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 2.0305464369186078e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.827491793226747e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.9707050886938484e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.7736345798244635e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.5962711218420173e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.4459572348488589e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.301361511363973e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.180538585418619e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.0811111761486207e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.1965172632786528e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.1979373739511737e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.0874568617470997e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.1370359066756108e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.1350909716712019e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.2171594375376482e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.0954434937838834e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.0045255947875816e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 9.22699484580687e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 8.304295361226184e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 7.846394766131917e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 7.154887541429158e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 6.439398787286243e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 6.540516612978634e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 9.425483274520864e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 8.76233169724896e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 8.0723630202427e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 7.26512671821843e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 6.911143031833857e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 6.220028728650471e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 5.691158107695857e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 5.308306800747137e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 4.8706083725828565e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 4.476679787235004e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 4.587805264462949e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 4.5946859809154725e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 4.321481875542561e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 4.261862673425575e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 4.0219408988016524e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 6.599976205520076e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 6.405639783457966e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 6.137604746140518e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 5.6169765234368994e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 5.05527887109321e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 4.549750983983889e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 4.0947758855855e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 3.778430548937383e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 3.4005874940436446e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 3.153660996549713e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 2.8382948968947417e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 2.5544654072052675e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 2.299018866484741e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 2.1622492317466995e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.9460243085720297e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.7514218777148267e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 1.7625441937642095e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 2.1450832303392337e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 6.028385353829219e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 5.425546818446298e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 5.162388864577391e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 4.6461499781196514e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 4.181534980307686e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 7.488665030582843e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 7.019195277704743e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 6.317275749934269e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 7.268794953066e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 169. Loss: 8.330054161532657e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 8.8008993728448e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 7.92080943556032e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 7.40812521998001e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 6.667312697982009e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.0936580770776176e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 9.936054945608992e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 9.314978436485363e-09, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170. Loss: 8.569745096657692e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 8.085299594633655e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.4354790648910288e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.2919311584019259e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.6470247155476786e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.4823222439929108e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.3340900195936197e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.2006810176342577e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.4345149968447988e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.4773278166841623e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.329595035015746e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.2152619807860351e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.12167545772545e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.009507911952905e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 9.085571207576146e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 9.573996882927647e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 8.616597194634883e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.3715385254956167e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.234384672946055e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.1202594308424928e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.0268599381403301e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 9.707400597343947e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 9.481718419666252e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.114124765499476e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.0027122889495285e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 9.862600740064002e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 8.876340666057602e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 7.988706599451843e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 7.189835939506659e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 6.4708523455559934e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 6.661957072882957e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 5.995761365594662e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.4243704923689889e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 2.1014942534599473e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 2.2918125049116414e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 2.0626312544204774e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.9029342443865277e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.712640819947875e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.625195743023128e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.4626761687208152e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.4840464909345412e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.4474004708588869e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.3026604237729982e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.256213395347523e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.1305920558127707e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.0175328502314937e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.1020438847321878e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.1035981252767687e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 9.932383127490918e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 9.77733477662439e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 8.892733550872384e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 8.003460195785146e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 7.203114176206631e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 6.4828027585859685e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 5.9276547346378045e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 5.3348892611740245e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 5.26706153354652e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 4.740355380191868e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 5.3839061323506775e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 5.031780011834245e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 4.621734262561253e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 5.463411907859746e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 4.917070717073771e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 4.7047603733421165e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 4.513681086188088e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 4.155445229479712e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 4.298694073665345e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 3.9619569182092435e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 3.752025719106954e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 3.563087639914894e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 3.4861756038991275e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 3.137558043509215e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 3.6619922898586983e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 3.388925312783261e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 3.2362972853258007e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 3.0057998087036536e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 7.641221657325231e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 7.156496241772891e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 7.185904322016618e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.0099465180659334e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.4770573577978576e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.3293516220180718e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.1964164598162647e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.2071598943447475e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.20751578631958e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.0960774328786652e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 9.864696895907987e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 8.87822720631719e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 7.990404485685471e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 7.470760787297107e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 7.00308145874758e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 6.675302320514553e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 8.894867984150351e-09, Train_acc 1.0\n",
      "\n",
      "[Epoch 170 Batch 100] Loss: 8.005381185735317e-09 Training: accuracy=1.000000\n",
      "Epoch 170. Loss: 8.005381185735317e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 8.601825685635215e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 7.834775368982127e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.8785874164939708e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.9049327248975868e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.714439452407828e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.5429955071670454e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.3980091816413842e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.2954611575800807e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.1752282670131159e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.2067169279053022e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.9614838367255396e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.7653354530529858e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.6074283570195508e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.4932516411665854e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.4184322563738126e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.4069741467736775e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.5829262298298885e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.4711997266958895e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.3613326547904737e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.2251993893114263e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.111992675571327e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 1.0007934080141944e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 9.752198554184448e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 8.776978698766003e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 7.899280828889404e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 7.388749496180647e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 6.8361390503834475e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 6.152525145345103e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 5.537272630810593e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 5.262942095705256e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 4.922912378853366e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 4.430621140968029e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 3.987559026871226e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 3.5888031241841034e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 6.6758095876869734e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 6.101360880828709e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 7.447000778352872e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 6.795432952428017e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 9.561775722563761e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 8.605598150307385e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 7.745038335276647e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 6.970534501748983e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 6.366613303484517e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 5.729951973136066e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 5.715750231773904e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 5.330439701315149e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 4.797395731183635e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 4.410788409975704e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 3.969709568978134e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 3.945267597517591e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 3.643873089676265e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 4.955864993931029e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 4.739675222513648e-09, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170. Loss: 4.358839952172716e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 3.922955956955445e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 5.393303734134018e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 4.853973360720616e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 5.2067658977132755e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 4.686089307941948e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 4.590009384789484e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 7.204366902928361e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 6.67019470535416e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 6.375704220256014e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 5.738133798230413e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 5.350584911126006e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 5.188055405450676e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 5.041778850342879e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 4.537600965308591e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 4.828898795243352e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 4.62540564369474e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 4.5353940647625365e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 4.7337801940635926e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 5.843649130418075e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 5.53868094535199e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 4.984812850816792e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 4.672596069555978e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 4.205336462600381e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 4.250464014830241e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 3.825417613347217e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 3.4428758520124956e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 3.098588266811246e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 6.234615505508666e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 5.6111539549578e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 6.72641777268441e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 6.053775995415969e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 5.448398395874372e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 4.996690808197368e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 5.5214758489119214e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 4.96932826402073e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 4.844924423055927e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 4.639828708726057e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 4.175845837853452e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 3.944525757888972e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 3.550073182100075e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 170. Loss: 5.579250446983042e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 5.11445765419517e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 4.696144140686086e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 4.412794230438343e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 4.064647059304942e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 4.775768643552444e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 4.484456283018065e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 5.89865420522606e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 5.401921036613887e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 6.351843631251793e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 7.113641886600045e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 6.4954099498504735e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 6.1252657050456096e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 5.605871386451482e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 5.231548740524969e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 4.708393866472472e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 4.982612273064082e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 4.577483297668107e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 4.119734967901297e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 6.501725642243924e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 5.944685329929964e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 5.350216796936968e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 5.280856315733169e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 4.845902936070285e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 4.361312642463256e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 4.483974878577297e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 4.035577390719568e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 9.964987579494377e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 8.96848882154494e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 8.164772191300878e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 8.465881884073681e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 8.271219409079305e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 7.537229720081807e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 9.298074146821738e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 8.461398984049998e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 8.732845375822995e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 7.859560838240695e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 7.353001504596809e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 7.3627592361938275e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 6.626483312574445e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 9.595987337975481e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 8.636388604177934e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 7.772749743760142e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 7.08860702129456e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 6.659143047140827e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 5.993228742426744e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 5.7664348092124195e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 5.28292358020161e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 4.75463122218145e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 4.372300351873738e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 4.028202568596797e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 3.6253823117371172e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 3.2628440805634054e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 2.936559672507065e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 3.2948292410336674e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 3.617272030343294e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 3.2555448273089647e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 3.023122596488501e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 3.559000387540056e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 3.296232600696483e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 3.5254027521693592e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 3.265994728862856e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 3.2187919839522933e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 2.896912785557064e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 3.3522793890580567e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 3.017051450152251e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 2.9947430331127485e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 9.49389794495598e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 8.637640402370816e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 7.773876362133734e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 6.996488725920361e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 7.973218711279347e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 7.3621613328700476e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 6.625945199583043e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 5.9633506796247386e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 5.739544552690614e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 5.165590097421553e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 4.649031087679398e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.2100333625463502e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.1262829270558883e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.1440397148604087e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.1600207972391244e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.044018717515212e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.237639536733592e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.1511284771630677e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.073268527990488e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.1056399548023507e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.023015634340134e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 9.207140709061206e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 8.286426638155085e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.1183065746288663e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.0437288112688147e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 9.486691553329765e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 8.53802239799679e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 7.684220158197111e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 7.102062646198265e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 6.391856381578439e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 5.845802995331028e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 5.3543549477083575e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 5.470844988714831e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 6.413875543414011e-09, Train_acc 1.0\n",
      "\n",
      "[Epoch 171 Batch 100] Loss: 5.7724879890726095e-09 Training: accuracy=1.000000\n",
      "Epoch 171. Loss: 5.7724879890726095e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 5.381503682883983e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 4.843353314595585e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 4.824679226034845e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 4.4353435553417934e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 3.991809199807614e-09, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171. Loss: 5.175875590859063e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 8.662969063006461e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 8.169201097734165e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 7.352280987960749e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 6.6170528891646744e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 7.352330662810848e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 7.082758750610739e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 6.653879625729849e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 6.081623915067297e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 5.752858273740751e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 7.505875330191693e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 6.941552300993389e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 6.61992605633132e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.02420105437734e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 9.310941741306494e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 8.379847567175844e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 7.634995062368692e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.2086891315837466e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.1064466688074586e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.005115227117756e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 9.977359085768231e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 8.979623177191408e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 8.081660859472268e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.1464437832781866e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.1249316091212106e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.478098385485631e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.3489149962089316e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.4002879049297239e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.2788855637086151e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.2161895609154846e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 2.3239088715633688e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 2.1194576572046043e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.907511891484144e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.7167607023357297e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.5450846321021567e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.511648050301248e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.3697964704621665e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.2421300486069932e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.4438793053732493e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.3460574946849142e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.2114517452164228e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.0903065706947805e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.1861667379321607e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.0675500641389446e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.1377462225570123e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.0239716003013111e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 9.308876654622233e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 8.37798898916001e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 7.633322342154442e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 7.987576398116995e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 7.375083262126162e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 7.19636834745607e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 7.594317891706302e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 6.834886102535672e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 6.1513974922821056e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 5.536257743053895e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 5.075764220658938e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 5.220113512006038e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 5.443159954044291e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 4.991976210550295e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 4.492778589495266e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 4.602294186497185e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 4.235197019757899e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 5.208659936255539e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 7.109229083916551e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 6.677702903500619e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 6.382461598587828e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 6.023612166704768e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 8.96026856233165e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 8.157373958008917e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 7.4347688141184585e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 6.877556425425248e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 6.376065275601358e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 5.924723240759857e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 5.425383168594304e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 4.882844851734874e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 5.4190144880956774e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 4.8771130392861094e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 4.575666228076134e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 4.1180996052685205e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 3.7062896447416686e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 3.5219251729861367e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 1.0806541529854923e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 9.725887376869432e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 8.753298639182488e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 8.436762142397844e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 8.431275890040623e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 8.333206094275418e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 7.499885484847877e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 171. Loss: 6.749896936363089e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 6.168039494637213e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.551235545173492e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.648037659660215e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.176366145604626e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 4.658729531044163e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 4.192856577939747e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 4.0529676703259556e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 3.64767090329336e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 7.660107479158897e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 7.359757885323983e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 6.716914348702018e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 6.231487406550451e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.608338665895406e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 9.70410914587043e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 8.733698231283387e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 7.953460660065482e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 7.251246845969366e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 6.6192544132828626e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 6.0504612238650095e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 6.0973407260736595e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 6.139532189243603e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 6.922562032881883e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 7.534156901148314e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 7.2464023651144584e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 6.521762128603013e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.962718167653145e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.552710843606465e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.369968700274168e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 4.832971830246752e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 4.722203588250426e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 4.622512214862653e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.091583035084815e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 4.861821459552056e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 6.797074810154784e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 6.396764079319489e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.75708767138754e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.367643408069652e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 4.830879067262687e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 4.9997166963137275e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 4.68600953050322e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 7.75643045300667e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 6.980787407706003e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 1.3267596712671119e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 1.1940837041404008e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 1.1864339627441605e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 1.0677905664697445e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 9.889511848407884e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 8.900560663567097e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 8.28990132518611e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 7.460911192667498e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 8.94999123267127e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 8.148124361314575e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 7.519576417901753e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 7.047015526291761e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 6.621710723842769e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.959539651458492e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.642982414288365e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 6.568799048794507e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 6.00505139582549e-09, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172. Loss: 5.404546256242941e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.7954140275984415e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.867798338251591e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.374150756336865e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 4.929867932613612e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 6.578921284611011e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.921029156149911e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 6.2602482822433465e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.634223454019012e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.443330094054381e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.644054966705641e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.079649470035078e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 4.851081251007293e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 4.459105377816996e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 4.1994593438561624e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 3.7795134094705465e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 3.587826561242127e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 3.508440633093637e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 3.5301255552215436e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 3.549641940727739e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 4.2191324010963076e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 3.797219160986677e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 3.6968939950681925e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 3.3272045955613733e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 1.0072513676258064e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 9.065262308632258e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 8.251868329679465e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 7.799210437739867e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 7.298686144146064e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 6.66194978164189e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.995754803477701e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.675576073310115e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 6.4118690046266695e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 6.981400474167863e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 6.2832604267510775e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.65493438407597e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.461969931105643e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.195169665970801e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.2344460665073245e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 4.711001459856592e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 4.239901313870933e-09, Train_acc 1.0\n",
      "\n",
      "[Epoch 172 Batch 100] Loss: 3.81591118248384e-09 Training: accuracy=1.000000\n",
      "Epoch 172. Loss: 3.81591118248384e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 3.99311347577798e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 3.593802128200182e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 3.700083158278982e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 3.795736040940981e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 3.602426929565518e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 3.6147132442506973e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 3.905167633238621e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 3.5146508699147586e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 3.2563180348337154e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 3.1169507351712096e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 2.8052556616540887e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 2.6178623473991128e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 2.3560761126592015e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 2.1204685013932813e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 1.9084216512539533e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 1.717579486128558e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 1.5458215375157022e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 4.185202844354153e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 1.0751570605654454e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 1.2842906035525221e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 2.1523705873683042e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 1.946446753822517e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 1.7518020784402654e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 1.8746445260390035e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 1.7803122776059458e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 1.602281049845351e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 1.4513661700518592e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 1.3062295530466734e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 1.1849198229330494e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 1.0664278406397444e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 9.690982817668133e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 9.001281263877042e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 8.101153137489337e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 1.1016321727317697e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 1.1311672350695041e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 1.045990184360126e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 9.413911659241134e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 8.472520493317021e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 7.99779738501367e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 7.291149898422735e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 9.449129916089296e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 1.0646256359196392e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 9.581630723276752e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 8.623467650949077e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 7.761120885854169e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 7.078141049179185e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 6.463459196171699e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 6.003377769273164e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.775568933374197e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.29114429194721e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 4.948294355471124e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.198522624345027e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.423728243967224e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 4.881355419570502e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 4.765748885255183e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 4.382306248640097e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 4.03720787568652e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 1.0245856762148429e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 9.407535589754451e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 8.466782030779006e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 7.620103827701106e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 8.348208320865973e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 7.513387488779376e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 7.786502861435729e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 8.218570945296016e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 7.58297835458728e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 6.824680519128552e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 6.23534471912613e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 6.1706036587560415e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.553543292880437e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 4.998188963592393e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 4.9640312657230514e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 8.565440362031496e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 7.708896325828347e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 6.938006693245512e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 7.361792314098958e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 1.1561613846366902e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 1.0498584713640645e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 1.3546539175700065e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 1.3123207388656327e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 1.1904018901701128e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 1.0713617011531015e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 9.921652038353636e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 9.8608088762267e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 8.967860240514462e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 8.536735414952915e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 7.683061873457624e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 6.914755686111862e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 6.316412369411108e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.684771132469998e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.2094262711334314e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 4.688483644020089e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.709749977917374e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.5113039877673675e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 172. Loss: 5.258196795104015e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.943095663233158e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 6.838900972844821e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 6.155010875560339e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 1.4200779889133355e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 1.2966966392938656e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 1.1763402005555223e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 1.1145855172133304e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 1.1055723954089949e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 1.0043283810591386e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 9.038955429532248e-09, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173. Loss: 8.135059886579023e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 7.321553897921121e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 6.589398508129009e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.930458657316108e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.43054504349493e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 8.14711315541499e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 7.518666332592126e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 6.766799699332914e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 6.183251981310055e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.751191275897684e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.176072148307916e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.84472942619576e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 6.409163483194978e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.76824713487548e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.8433480459830834e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.9109387771620846e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 6.5305632694497364e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.970639194415196e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 1.1706543202820443e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 1.174660769663147e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 1.0571946926968325e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 9.701016726990128e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 9.0103118044713e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 8.109280624024169e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 7.298352561621752e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 7.4067071785242984e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 6.852300953390504e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 6.260203109961886e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.634182798965698e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 6.281483510797883e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.6533351597180946e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 6.112455765280575e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.501210188752518e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.3236181109056155e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.3500497557664995e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.81504478018985e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.892333669304469e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.403100302374022e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.242187022316804e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.004232812803759e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 3.6969417834338157e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.537965975094295e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.2017556677628615e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.2403735569380205e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.716336201244219e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 6.38674237110719e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 6.120597119433741e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.5085374074903674e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.050815918651763e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.6388665786970195e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.268112172737751e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.865755076998266e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.4723118212088724e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.3976095801163345e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.6097742466998525e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.173251210017683e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.655926089015915e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.283465732024756e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 1.4099614188887363e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 1.278278502190906e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 1.1504506519718154e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 1.2496096368276468e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 1.1432751235269687e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 1.0289476111742719e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 9.53992525074863e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 9.796651539766838e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 9.096383113765877e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 8.373009306210156e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 7.535708375589141e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 6.782137538030227e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 6.197056036137637e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 6.5086724742323e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.950937478719503e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.728372716284823e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.5280644300936105e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.068390238994683e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.654683467005647e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.189215120305083e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 3.95655810099321e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 3.560902290893889e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 3.5773410472417707e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 3.4058714352362285e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 3.530945490202503e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 3.1778509411822526e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 3.884520235051844e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 3.589200463457092e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 8.538800973579849e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 1.0013223760046882e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 9.105033635952626e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 1.117475682678501e-08, Train_acc 1.0\n",
      "\n",
      "[Epoch 173 Batch 100] Loss: 1.0616074511240112e-08 Training: accuracy=1.000000\n",
      "Epoch 173. Loss: 1.0616074511240112e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 1.0206392684711252e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 1.142092599659612e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 1.270026924876581e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 1.1523374575799662e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 1.0371037118219696e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 9.42706565830816e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 8.577491344387776e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 7.812874461859431e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 7.031587015673488e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 7.07348624057176e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 6.366137616514584e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 8.430354702720232e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 7.587319232448209e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 7.201116294640658e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 6.667269168997458e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 6.000542252097712e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.493620278798373e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 1.015964726046819e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 9.236814786331804e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 8.313133307698624e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 7.481819976928762e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 7.29243134636949e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 6.749452704451176e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 6.260771926724693e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.820959226770859e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.890788928688924e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.301710035820032e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.771539032238028e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.294385129014226e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.144343344088526e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 3.729909009679673e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 3.822579262792682e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 3.5334535884238467e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 3.180108229581462e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 2.862097406623316e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.27671851381809e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.028443412616464e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.525599071354818e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.376889791684744e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.1185975404919924e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.606737786442793e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.332328500517149e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.364756848955332e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 8.119223512773887e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 7.679830146933768e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 6.911847132240392e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 6.500059146992075e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 8.178356116117885e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 7.639917232481819e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 6.96905776114407e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 7.855399118426189e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 7.069859206583571e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 6.82853444000619e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 6.3319454887242065e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.791883191762219e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.398959376406863e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.95219569067661e-09, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173. Loss: 4.456976121608949e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.011278509448054e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 3.610150658503249e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 3.435400085371559e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 3.091860076834403e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 3.1552030545882333e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.447381694796336e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.088908018035337e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.580017216231803e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.122015494608623e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.454871649568776e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.0093844846118985e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 3.7015782880611416e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.262742589781296e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 3.836468330803166e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 3.4528214977228497e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 3.2006715998609976e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 2.880604439874898e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 2.5925439958874084e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 3.264611993278462e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 3.124415286669251e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.8853325698915195e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.483063805621002e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.934757425058902e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.5344139344634444e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.174104792927533e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 3.942958806353415e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 3.6417951776285063e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 3.743276858355553e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 7.653025555052474e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 7.260251984984497e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 6.62735903839648e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 6.244019862532555e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.992146817307649e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 5.486064387487317e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.937457948738585e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.5368444057751595e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 173. Loss: 4.0831599651976436e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 3.6748439686778794e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 3.3073595718100916e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 2.9766236146290824e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 3.7034159076075168e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 3.6124710670269483e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 4.555074587789662e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 4.099567129010696e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 3.875874908828262e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 3.581419669855869e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 3.223277702870282e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 2.900949932583254e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 2.7971194320435635e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 2.517407488839207e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 2.5450634901354694e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 2.4768216338405576e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 2.229139470456502e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 2.0993577753212846e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 2.2619509832264265e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 4.6434548305707095e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 4.179109347513639e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 3.761198412762275e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 3.385078571486048e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 3.046570714337443e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 3.021310370879421e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 2.719179333791479e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 2.447261400412331e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 2.202535260371098e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 2.354810675362338e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 2.678123019368629e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 2.5034429693421987e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 2.4393631651266137e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 2.1954268486139526e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 2.06901641566299e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 1.862114774096691e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 1.7690355485974546e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 1.9646609347660587e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 1.768194841289453e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 5.223529134904459e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 7.681403486384394e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 6.913263137745955e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 1.0785412821059422e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 9.706871538953481e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 8.736184385058133e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 7.955698198462753e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 1.0047223030853943e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 9.042500727768549e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 9.16270504297951e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 1.2251113083015288e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 1.102600177471376e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 9.923401597242385e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 9.676119408392687e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 8.987904217733603e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 8.089113795960242e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 7.373334668274651e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 9.429966438394046e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 8.580102046465075e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 7.722091841818568e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 6.949882657636712e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 6.2548943918730405e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 6.001933893714086e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 6.0536661733467495e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 5.820828541449345e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 7.660182604947816e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 8.943071876978881e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 8.048764689280993e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 7.337020472263326e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 6.789582917755629e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 7.04194702295986e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 6.337752320663874e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 5.703977088597487e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 5.785505093150732e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 5.300086835746091e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 6.167061214734123e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 5.5503550932607105e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 5.088451835845073e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 4.859003402440749e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 4.373103062196674e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 4.773982629041728e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 5.600434904785122e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 5.04039141430661e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 5.0020134269569245e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 4.6880765880820975e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 4.4055334330947535e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 8.24905718286049e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 7.796680405602791e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 7.575805820993959e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 7.097621966870285e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 6.853520924264233e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 6.820094367615119e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 7.25567148748513e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 6.62323659064705e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 6.70597063600336e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 6.1285058243134565e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 5.515655241882111e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 4.9640897176939e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 4.46768074592451e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 4.0209126713320594e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 8.834211479562612e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 8.043922583516783e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 7.239530325165105e-09, Train_acc 1.0\n",
      "\n",
      "[Epoch 174 Batch 100] Loss: 6.608709544559027e-09 Training: accuracy=1.000000\n",
      "Epoch 174. Loss: 6.608709544559027e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 5.947838590103124e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 5.446186983003245e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 4.90156828470292e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 5.435865577766919e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 4.892279019990227e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 4.403051117991204e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 4.14901051001295e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 3.734109459011655e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 3.826359667191466e-09, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174. Loss: 3.44372370047232e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 3.192483582335521e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 2.873235224101969e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 2.6790439536022048e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 1.0420489541482084e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 1.0961687898366086e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 1.0983105398707474e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 9.884794858836728e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 9.361976527034031e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 8.51891112624106e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 7.667020013616954e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 7.086582504973894e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 7.495510633472343e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 6.839091822035541e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 6.7139760513745115e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 6.042578446237061e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 5.438320601613355e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 5.546414210456091e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 4.991772789410482e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 4.585727762379867e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 4.965344948024443e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 5.400132583748267e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 5.139516075553624e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 4.625564467998261e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 4.163008021198435e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 5.795614218697386e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 5.216052796827648e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 4.694447517144883e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 4.225002765430395e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 3.802502488887356e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 3.42225223999862e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 3.0800270159987583e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 2.7720243143988825e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 2.494821882958994e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 6.995070259075952e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 7.13375319505092e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 6.699774603521551e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 6.122929395079828e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 5.603768707482278e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 5.322788586914234e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 4.976774232043676e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 4.572229060749741e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 4.115006154674767e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 3.7035055392072902e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 3.5194194780051965e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 6.240837052636606e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 5.616753347372946e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 5.055078012635652e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 4.549570211372087e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 4.0946131902348785e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 3.7782841231218235e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 3.493587962720074e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 1.1432958158504417e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 1.1407248899285497e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 1.0732185163437923e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 9.65896664709413e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 8.693069982384717e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 7.823762984146245e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 7.50704792863044e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 7.594533275285641e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 7.11447669793726e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 6.4030290281435345e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 5.9489906180478166e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 5.354091556243035e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 7.426381879192709e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 6.683743691273439e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 6.015369322146095e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 5.786361375368756e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 5.580254223269151e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 5.022228800942236e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 4.520005920848012e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 4.068005328763211e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 4.406262677943589e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 3.96563641014923e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 3.569072769134307e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 3.3052977441313093e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 2.9747679697181786e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 3.6086132144547874e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 3.2477518930093087e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 2.922976703708378e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 2.723811285247973e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 3.289620029787897e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 3.0537902787195398e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 3.493469132904285e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 9.570228089264056e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 174. Loss: 8.61320528033765e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 7.751884752303886e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 7.06982852898393e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 7.666696303550947e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 6.993158925106285e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 7.97022189054668e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 7.173199701492012e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 6.455879731342811e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.903424010118963e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.313081609107066e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.968037940914995e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.471234146823496e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 1.0822750605436688e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 9.74047554489302e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 8.859560242314151e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 8.159868721903601e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 7.530146342431876e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 6.870263960099121e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 6.369502067910074e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.732551861119067e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.438693402982883e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 1.0389608068262054e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 9.816308415516825e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 8.834677573965143e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 8.04434206847906e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 7.984965743687854e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 9.887300017176175e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 9.643627719879573e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 8.679264947891616e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 7.811338453102454e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 7.030204607792209e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 7.165374108895551e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 6.541968949916428e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 6.260301062566517e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.727403208220298e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.154662887398268e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.104857752739417e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.966900962902746e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 6.425985786405402e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.783387207764862e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.391312990809241e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.8521816917283165e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.6463602727356685e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.647385443951999e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.5551758405851485e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.192790508437066e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.239172611674335e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 6.981750683114058e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 6.4698401075212875e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 6.474781810182152e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.8273036291639365e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.244573266247543e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.720115939622789e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.3412365975709435e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 3.907112937813849e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 6.124100767335073e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.791087418577289e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.2119786767195604e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.528970948565852e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.976073853709267e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.571598720248773e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.114438848223896e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.913713333405366e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.42234200006483e-09, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175. Loss: 4.25950452803407e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 3.833554075230663e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 3.5433309196180295e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 3.934055532077241e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 3.726914471588153e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 3.44735527633977e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 3.2888842525266588e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 3.239392577454176e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 2.9154533197087586e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 2.623907987737883e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 2.4546494408745276e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 2.674845650868051e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 2.7798900268095957e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 3.6194877583958427e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 3.3506712344666912e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 3.2018686148408876e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 2.881681753356799e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 3.245439247025191e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.22474639387729e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.664915127363679e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.098423614627311e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.681713505075013e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.213542154567511e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.16471692454803e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 3.7482452320932275e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 3.55968520160254e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.0419068209605325e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 3.8239806315831145e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 1.079899609129303e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 9.719096482163728e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 1.116862197523392e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 1.0051759777710529e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 9.046583799939476e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 8.141925419945529e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 7.327732877950976e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 6.594959590155878e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.935463631140291e-09, Train_acc 1.0\n",
      "\n",
      "[Epoch 175 Batch 100] Loss: 5.435049519936694e-09 Training: accuracy=1.000000\n",
      "Epoch 175. Loss: 5.435049519936694e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.891544567943025e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.495522363059155e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.139102378663673e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 3.911456633515941e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.265368674585362e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 6.5396631878909836e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.885696869101886e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 6.321581481361672e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 9.04217749641387e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 8.417356496952666e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 7.5756208472574e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 7.004323266352526e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 6.303890939717274e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.95289859592573e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.3576087363331566e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.660037735764562e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.094033962188106e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.770895069790161e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.480070066632011e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.870252933033531e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.383227639730178e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 8.508371991061025e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 7.657534791954923e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 6.891781312759431e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 6.388867674202123e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.749980906781911e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.361247319924585e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.825122587932127e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.342610329138914e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.957256295843817e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.640927416439619e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.076834674795657e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.569151207316091e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.298500579303117e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 3.868650521372805e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 3.4817854692355248e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 3.878664626732988e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 3.490798164059689e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.4700212314787375e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.016151360241297e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.514536224217167e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.156214853705883e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.206254566825193e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 3.785629110142674e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.269709572002524e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.301531981935875e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.771378783742287e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.294240905368058e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.796138856539679e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.316524970885711e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 3.8848724737971404e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 3.589517478327859e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.348152287126596e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.006469310324369e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 3.6058223792919323e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 3.4315046340813742e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 3.2746186633918717e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 2.9471567970526845e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.167009937181002e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.650308943462902e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.4891289430355455e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.940216048731991e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.539326695769224e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.178526278102735e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 3.760673650292462e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 3.3846062852632158e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 3.232410149455529e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 2.9091691345099763e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 2.7113844729694114e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 2.533378277582903e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 2.2800404498246125e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 2.7039620294373025e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 2.4335658264935724e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 2.190209243844215e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 1.9711883194597936e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 2.1465984729510847e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 8.078650565092477e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 8.202107550291656e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 7.38189679526249e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 6.9231038437119634e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 6.3239257112512e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 8.858026341105029e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 8.344752692431797e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 7.78967415116434e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 9.990934356289654e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 8.99184092066069e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 8.092656828594621e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 7.562787895915342e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 7.737831503303603e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 7.057180604883676e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 6.351462544395308e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.716316289955778e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 5.237816912870633e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.900299714302205e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 175. Loss: 4.410269742871985e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 8.812105235187823e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 8.117159204387677e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 7.398575535859343e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 6.658717982273408e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 7.669225752539826e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 6.995435429196276e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 6.2958918862766485e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 7.622077617441914e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 7.232398841134993e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 6.5091589570214945e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 7.0689620530481e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 7.200255720808012e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 6.573362400637643e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 6.474819572116403e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 5.827337614904763e-09, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176. Loss: 6.641586915976927e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 6.0705604762896676e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 5.5566366805711335e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 5.00097301251402e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.500875711262618e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.050788140136356e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.738841578033154e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.296279461938265e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.866651515744439e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 5.715157523440516e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 5.143641771096464e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 6.3987887093993885e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 5.8520420903698825e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 5.266837881332894e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 8.092908966930706e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 7.283618070237636e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 7.3934461362785935e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 6.654101522650734e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 1.0924685383907511e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 1.0018481349337626e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 9.109765466314297e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 8.2919211715933e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 7.742125804614154e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 7.712971017391596e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 7.03480616756287e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 6.331325550806583e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 5.698192995725925e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 5.314638199974198e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.969438883797644e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.47249499541788e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.584038951827537e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.218767308555216e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.7968905776996945e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.417201519929725e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.0754813679367526e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 7.145137963152055e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 6.710020894812572e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 6.411547790768585e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 5.7703930116917266e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 5.379618214343419e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.841656392909078e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.3574907536181706e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.921741678256354e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.5295675104307184e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.176610759387647e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.0452141761675172e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.7406927585507654e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.9322846367766655e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.5703785700787934e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.3996052168917797e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.0596446952026017e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.6850024450264524e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.3165022005238073e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.9848519804714266e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 5.014669666249302e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.513202699624372e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 7.135243373179336e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 6.607983528580037e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 5.947185175722034e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 6.0043922827449815e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 5.497085306380916e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 5.13364126846146e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.620277141615314e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.903307131874798e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.971769874638763e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.474592887174887e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.5859270099999225e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.406731036975653e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.152322437098954e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.830222445299491e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.6334646934881768e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.2701182241393592e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.5950320707294956e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.2355288636565463e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.9119759772908917e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.9001751075375252e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.7032898486942057e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.432960863824785e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.1896647774423065e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.622623835475385e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.3603614519278465e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.52130828047986e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.727970819565478e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.286495779317357e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.882300500555596e-09, Train_acc 1.0\n",
      "\n",
      "[Epoch 176 Batch 100] Loss: 4.394070450500036e-09 Training: accuracy=1.000000\n",
      "Epoch 176. Loss: 4.394070450500036e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.954663405450032e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.5591970649050293e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.2032773584145263e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.0692141152917088e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.762292703762538e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.4860634333862845e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.00696838309591e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 7.983475210981192e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 7.185127689883073e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 6.559747172805198e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 5.903772455524679e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 5.592791937947934e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 6.616759699913983e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 7.445198428221879e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 6.8869430781183265e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 6.198248770306494e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 5.578423893275845e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 5.858771377012982e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 5.645423246953415e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 7.036656374958055e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 6.33299073746225e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 6.072220604744374e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 8.072698022843915e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 1.4157185429919164e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 1.2927731379645885e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 1.1634958241681296e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 1.05645946694236e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 9.601267454391673e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 8.641140708952506e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 7.777026638057256e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 6.99932397425153e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 6.485656080647243e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 5.837090472582519e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 5.53277815329999e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 5.258897065945714e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 5.850593649529139e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 5.265534284576225e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.8321131080290356e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.3489017972261324e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.472805029046044e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.3049212541171625e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.153825856681169e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.831575522923485e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.541550222541569e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.2805274521978446e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.95247470697806e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.7503594881906868e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.568455791282051e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.311610212153846e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.408752962941899e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.967877666647709e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.316147604403953e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.884532843963557e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.4960795595672016e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.1464716036104815e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.6700143163141544e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.396145136593172e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.056530622933855e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.750877560640469e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.4757898045764224e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.929042204882937e-09, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176. Loss: 4.436137984394644e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.178788689776045e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.4128354898025125e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.157816444643127e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.742034800178815e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.3678313201609334e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.1241804400552728e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.998026899870611e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.6982242098835497e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.5215340408056275e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.3625128886354975e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.4056583499521307e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.493395398781935e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.044055858903742e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 4.0121792584506375e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.797225836426439e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.4175032527837953e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.075752927505416e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.861309886665307e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.7614433907174116e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.6715635443643057e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.4044071899278753e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.1639664709350877e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.7857596969063e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.50718372721567e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.256465354494103e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 2.217083311763328e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 1.9953749805869952e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.658481921216517e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.2926337290948654e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.149634848904014e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.859125752001429e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.4732131768012863e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 176. Loss: 3.1258918591211577e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.813302673209042e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.8113691560683208e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.530232240461489e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.27720901641534e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 6.612955230077672e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 6.69671741149092e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 6.12017792225226e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 5.8806891154643045e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 5.292620203917874e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.763358183526087e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.3801546170839116e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 5.9910463326299975e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 5.48507395127743e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 5.02969880806012e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.619861179164541e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.25100731315852e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.919038833753101e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.992796193276609e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.9904996365115884e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.49144967286043e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.042304705574387e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.731206486927382e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 7.362762606211532e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 7.65094046712467e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 6.978978672322637e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 8.05059174286726e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 7.245532568580534e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 7.545433699710297e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 6.790890329739267e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 6.111801296765341e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 5.500621167088807e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 5.22995580056011e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.706960220504099e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.3293964503641225e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.734646856028115e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.261182170425304e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 5.604575068795344e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 7.558685315935291e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 6.802816784341762e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 6.215667357818019e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 5.87349735001194e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 5.751808769091722e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 5.921685596603565e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 5.329517036943208e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.796565333248887e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.316908799923998e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.885217919931599e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 1.1226647207165689e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 1.0662775942400566e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 9.596498348160509e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 9.475038386409179e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 8.900063488796612e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 8.75511502197365e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 7.879603519776285e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 7.184775419709089e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 6.559430129648613e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 5.903487116683752e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 5.313138405015377e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.781824564513839e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.303642108062455e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.87327789725621e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.485950107530589e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.1373550967775303e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.848074063905436e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.6495311502335274e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.284578035210175e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.9561202316891573e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.7536404604306745e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 6.94861873292865e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 6.440021363456651e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 6.63420927781139e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 7.088374906661774e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 6.379537415995597e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 5.741583674396038e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 5.167425306956434e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 5.209476143394395e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.688528529054956e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.499072426329644e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.04916518369668e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.6442486653270116e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.838617254745755e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.944870227570474e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.450383204813427e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.005344884332084e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.884207146079059e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.775183181651336e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.3976648634862025e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.2441628698562173e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 5.154917742141117e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.732558219837439e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 5.935681611076085e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 5.528377953789342e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 5.0686724103208404e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 5.306862873709772e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 6.266291284638089e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 5.63966215617428e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 5.075695940556852e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.568126346501166e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.204445963761483e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.7840013673853345e-09, Train_acc 1.0\n",
      "\n",
      "[Epoch 177 Batch 100] Loss: 3.4056012306468013e-09 Training: accuracy=1.000000\n",
      "Epoch 177. Loss: 3.4056012306468013e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.065041107582121e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.689859304985862e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.3208733744872756e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.988786037038548e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.6899074333346932e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.7934456754384946e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.8866300489229943e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.597967044030695e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.6175670898078085e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.3558103808270276e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.120229342744325e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 1.9082064084698924e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.462443472043918e-09, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177. Loss: 2.4955958750197095e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.8048296546513417e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.6174789410966403e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 6.826069457542973e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 6.143462511788676e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 5.529116260609809e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.976204634548828e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.478584171093945e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.310122481960273e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.972242485674679e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.575018237107211e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.4037809061151253e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.063402815503613e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.8501947858636847e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.658307559187749e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.392476803268974e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.153229122942077e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.1241707033665043e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.0048858849402865e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.08379402442198e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.8067367525060508e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.3642529503201664e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.1209599071985826e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.019582819389636e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.7107567893611056e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.339681110424995e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.0057129993824957e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.705141699444246e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.0865530652771305e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.7778977587494175e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.5932402347849086e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.6133129392821402e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.445113897264359e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.945660389594622e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.744226602545593e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.4698039422910335e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.457994707332452e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.477856390680183e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.309467479587887e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.064785235449964e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 5.2415542005728615e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.717398780515575e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.245658902464018e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.821093012217616e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.4389837109958546e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.188217591806702e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.869395832626032e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.724495506443771e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.345178207709826e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.910660386938843e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 6.313557098292245e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 5.6822013884630205e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 5.1139812496167186e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.6025831246550465e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.328589304908177e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 4.081994867135995e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.766927632332828e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.5764993618181805e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.2188494256363626e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.8969644830727266e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.352325828004311e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 3.01709324520388e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.715383920683492e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.443845528615143e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.3857254684722637e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.1471529216250374e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.0255698813729663e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 1.8230128932356697e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 1.6407116039121028e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 1.8491694511626234e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 1.8505170098672266e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 1.665465308880504e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 1.6851832707110888e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 1.5166649436399798e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 1.364998449275982e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 1.2284986043483837e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 1.3850454718892679e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 1.339673176610774e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 1.5782347999780461e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 2.1654690244012566e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 7.350581330775767e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 177. Loss: 6.615523197698191e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 6.0471031298388044e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 6.839375435328354e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 6.527966877232789e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 5.87517018950951e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 5.287653170558559e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.758887853502703e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.5623957961281555e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.292420720336205e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.863178648302585e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.942521981962224e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 7.366687365890313e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 6.8162831220199165e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 6.414051559998108e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 6.145175345026647e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 5.623790062434415e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 5.433939997219323e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 5.169942725473114e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.7460807048362356e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.550869384532796e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 5.027104665423627e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.990055441780083e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.491049897602074e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.973267038368136e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.475940334531322e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.121478552988623e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.709330697689761e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.3383976279207847e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.190822357847341e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.454987077823449e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.009488370041105e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.6085395330369942e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.2476855797332948e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 6.182543190743197e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 5.65742112357931e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 9.655150745053027e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 8.689635670547725e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 7.820672103492953e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 7.969927112487768e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 7.452331129214713e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 6.707098016293242e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 6.036388214663918e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 5.4327493931975265e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.889474453877774e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.400527008489996e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.0536065595514295e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.6482459035962864e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.3765535651470904e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 5.739730477574959e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 5.817682965594773e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 5.235914669035295e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 5.550513075196487e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.995461767676838e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.495915590909155e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.139456283728672e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.818642907266238e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.4367786165396142e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.0931007548856528e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.1563196204254373e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.5857453628039086e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.2271708265235178e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.9975859957815987e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.6978273962034387e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.6143091604039605e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.3528782443635645e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.142044896732867e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.920972658970013e-09, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178. Loss: 2.815139896893877e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.303136844981376e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.872823160483238e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.4855408444349143e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.136986759991423e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.1026848341724637e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.0718131009354004e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.7646317908418603e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.4881686117576743e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.3324840024923397e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.378632352423289e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.1407691171809603e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.2992211464912138e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.0692990318420927e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 1.955501380568316e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 1.94621574633235e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 1.9378586644177504e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 1.837205049886408e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 1.6534845448977673e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.630174992216964e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.453421996816133e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.10807979713452e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.797271817421068e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.5175446356789615e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.2657901721110654e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.2254756587208245e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.189192585567377e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 5.974950094987528e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 5.377455085488776e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 6.9817497221986595e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 6.283574749978794e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 6.027746216009264e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 5.4249715944083375e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.882474434967504e-09, Train_acc 1.0\n",
      "\n",
      "[Epoch 178 Batch 100] Loss: 4.394226991470754e-09 Training: accuracy=1.000000\n",
      "Epoch 178. Loss: 4.394226991470754e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.420465446404654e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.071551153674622e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.850660531025795e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 7.563403148090285e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 7.73838514144321e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 7.895868757825157e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 7.1062818820426416e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 8.444561403999908e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 7.786369756318554e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 7.193997284507564e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 6.56772980796724e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 5.910956827170516e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 7.182504162056214e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 6.464253745850593e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 5.817828371265534e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 5.236045534138981e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 6.761348157979561e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 6.085213342181605e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 5.6629565117843105e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 5.282925364426745e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.940897320702706e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 5.005600955766039e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.784437588165158e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.399126081259075e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.0523457250436e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.6471111525392404e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.2824000372853164e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.954160033556785e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.6587440302011065e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.392869627180996e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.1535826644628964e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.0313566499270394e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 1.8282209849343356e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 1.7385311383513348e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.589132146050492e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.516483424164078e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.2648350817476703e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.0383515735729035e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 1.8345164162156133e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 1.651064774594052e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 8.470856290468663e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 7.623770661421797e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 7.047658087998253e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 6.342892279198427e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 5.8017353031890174e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 5.314694024780549e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.7832246223024935e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.304902160072244e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.87441194406502e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.1388962854358275e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.725006656892245e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 6.984655505690558e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 6.379322207031935e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 6.0207867365089246e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 5.418708062858032e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 5.342498455062127e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.8082486095559145e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.5136882413189585e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.155451669097496e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.739906502187746e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.3659158519689717e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.401853207800424e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 5.389973257744974e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 5.502901467747787e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.952611320973008e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.457350188875708e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.197879662706772e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.871223948346527e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.4841015535118744e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.135691398160687e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.8221222583446184e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.6330422844205893e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.3697380559785305e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.1327642503806777e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 1.91948782534261e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.286332498759794e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.0576992488838147e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 1.8519293239954332e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 1.66673639159589e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 1.5931950043467337e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 1.4338755039120604e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.221809995229281e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.2790257236820755e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.6343702847103938e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.3640655081497872e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.400187942772079e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.6189625156284743e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.933445832559384e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 4.440101249303446e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.996091124373101e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.596482011935791e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.236833810742212e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 3.2856794373097218e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.9571114935787495e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 178. Loss: 2.6614003442208746e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.8609215082886845e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.6679616093702487e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.7736943894615733e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.496324950515416e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.2466924554638747e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.022023209917487e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.3786142560593416e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.1407528304534075e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 1.926677547408067e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.3859353284445694e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.1473417956001125e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.863929657748528e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 3.043197890463572e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.738878101417215e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 5.910876356654039e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 5.5060532248095e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 7.470014768169612e-09, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179. Loss: 7.281806658486254e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 6.553625992637629e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 6.45705676050747e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 5.811351084456723e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 5.509612703986773e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 8.404537498966641e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 9.79925544124755e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 8.91246214903323e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 8.393744875158256e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 8.20629592341974e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 7.3856663310777665e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 7.205893109512514e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 6.485303798561263e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 5.92990567061557e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 5.336915103554013e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 4.803223593198612e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 5.719883852352182e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 5.147895467116964e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 4.633105920405268e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 4.449192056340463e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 4.004272850706417e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 3.6969778175462084e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 3.4204122877020205e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 3.171503310842251e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.9474852316684586e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.7458689604120456e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.750678814551024e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.4756109330959217e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.321182091696762e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 4.1379714150529314e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 3.7241742735476384e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 3.3517568461928746e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 3.10971341348402e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.798742072135618e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.891396850359327e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.6022571653233943e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.5282959526119204e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 3.1136564968689753e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.988555339900713e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.6896998059106417e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.4207298253195776e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 3.0168468934880246e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.808294456049655e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.5274650104446895e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.2747185094002204e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.0472466584601983e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 1.8425219926141785e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 1.6582697933527607e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 1.4924428140174847e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 1.436330784526169e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 1.2926977060735521e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 1.163427935466197e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 1.0470851419195773e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 9.423766277276196e-10, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 8.481389649548576e-10, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 7.633250684593719e-10, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 6.869925616134348e-10, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 7.11425557362524e-10, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 6.402830016262716e-10, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 5.762547014636445e-10, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 5.1862923131728e-10, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 4.667663081855521e-10, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 4.2008967736699686e-10, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 3.7808070963029717e-10, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 3.4027263866726746e-10, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 3.062453748005407e-10, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 5.550175652962093e-10, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 8.720447942038589e-10, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 8.779725666939058e-10, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 8.833075619349479e-10, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 8.881090576518859e-10, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.8482058620482268e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.563385275843404e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.3070467482590636e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.5420033163319755e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.3809352366092106e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.329106216769155e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.282460098913105e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.0542140890217947e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 3.152643218767182e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.837378896890464e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.6467732591118504e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.754624918637936e-09, Train_acc 1.0\n",
      "\n",
      "[Epoch 179 Batch 100] Loss: 2.6654269194927777e-09 Training: accuracy=1.000000\n",
      "Epoch 179. Loss: 2.6654269194927777e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.3988842275435e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.1589958047891503e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.222492952285958e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.000243657057362e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 1.8933515432620584e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 1.7971486408462853e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 1.9899627621989272e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.3497598531126375e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.2079161197118066e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.080256759651059e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.0584955875068184e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.690835990638699e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.4217523915748294e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.1795771524173464e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 1.9616194371756117e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.324250905000575e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.3712225424762398e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.879158081467473e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.591242273320726e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.425250297899086e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.1827252681091774e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 1.9644527412982595e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 1.954271959887069e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 1.758844763898362e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 3.4456036603826438e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 3.1010432943443793e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.7909389649099413e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.511845068418947e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.2606605615770525e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.0345945054193473e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 3.1349856823428207e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.8214871141085388e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 3.4706604444061115e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 3.1235943999655005e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 7.933492422599792e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 7.1401431803398135e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 7.823111658414946e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 7.1339327444838845e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 6.420539470035496e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 7.64112871827038e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 7.063280339161977e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 6.543216797964414e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 6.447688485301576e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 6.64110950983614e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 6.908320778196637e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 6.496885428352696e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 5.847196885517427e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 5.262477196965684e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 4.736229477269116e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 4.262606529542205e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 4.022610369306619e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 4.272274868153267e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 3.84504738133794e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 3.553674895114579e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 3.291439657513554e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.9622956917621987e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.852330615304614e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 3.2190231783693036e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.990253112442806e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 2.784360053108958e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 4.368567953579232e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 4.024843410131742e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 3.9017558192987506e-09, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179. Loss: 5.467356045340226e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 5.758810313870924e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 5.1829292824838316e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 4.757768606145881e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 4.281991745531293e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 7.48594244073707e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 1.0648894128264175e-08, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 9.584004715437758e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 8.811868747714847e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 9.513928651068522e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 8.56253578596167e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 7.706282207365503e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 6.935653986628953e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 6.242088587966057e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 5.711011981079884e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 7.095686058036194e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 6.386117452232575e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 5.84063795891975e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 5.442838655746411e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 5.0848192939926356e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 4.576337364593372e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 4.863761510190734e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 4.377385359171661e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 4.032779075164927e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 3.6295011676484347e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 3.359683302794024e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 3.955037191858733e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 3.5595334726728596e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 3.2035801254055735e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 3.628279817286031e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 4.196774054901539e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 179. Loss: 3.777096649411386e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.399386984470247e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.0594482860232223e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 4.429882315371922e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 4.1731585876555954e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.755842728890036e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 5.056637491587738e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 4.550973742428964e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 4.095876368186068e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 4.338214267144771e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 4.090657344251159e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.6815916098260433e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.6859614342807096e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 4.062422995273654e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.6561806957462885e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 4.128752676872065e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 4.274670776318461e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 4.219732639714964e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.7977593757434684e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.4179834381691216e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.2624495870708443e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.0293368802741926e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.7264031922467735e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.4537628730220963e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.2083865857198867e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 1.987547927147898e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 1.9750576382539738e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 1.870684126339009e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 1.869880217525974e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 1.7760244476838093e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.9954052431137527e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.4409226008590764e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.1899625926836016e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.8709663334152414e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.6770019519841502e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.6886985069659183e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.4198286562693267e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.550374731670744e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.4816017512223045e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.3265738280105066e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.093916445209456e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 1.8845248006885107e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 5.048827194350761e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 6.685985330717181e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 6.017386797645464e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 5.69504484585664e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 5.125540361270976e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 4.612986325143878e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 4.15168769262949e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.7365189233665415e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 4.201057170548134e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.7809514534933205e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.4028563081439886e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.06257067732959e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.756313609596631e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 5.833436411825333e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 5.2500927706428e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 6.494594431355406e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 5.845134988219866e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 5.446885993218744e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 5.088461897717736e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 4.5796157079459625e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 4.1216541371513665e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 5.013339350901638e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 6.281516353588361e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 5.932761446205248e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 5.525749794303358e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 5.2525715428487455e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 6.031164927211437e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 5.521180686400726e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 4.969062617760654e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 5.217214060405604e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 4.6954926543650436e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 4.225943388928539e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.98961354275432e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.5906521884788883e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.2315869696309996e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.9084282726679e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.61758544540111e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.355826900860999e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.306508703493534e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.075857833144181e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 1.868272049829763e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 1.8677093375654217e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 1.6809384038088796e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 1.5128445634279917e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 1.3615601070851926e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 1.4116685890953087e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.2949562069914366e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.065460586292293e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 1.8589145276630639e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 1.6730230748967575e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 1.5057207674070818e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.5903196723012115e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.2312877050710903e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.9081589345639814e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.7104752930180163e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.439427763716215e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.3817494800632286e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.329839024775541e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.0968551222979866e-09, Train_acc 1.0\n",
      "\n",
      "[Epoch 180 Batch 100] Loss: 1.887169610068188e-09 Training: accuracy=1.000000\n",
      "Epoch 180. Loss: 1.887169610068188e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 1.791584900971802e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 1.6124264108746218e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.1031093055644688e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 1.892798375008022e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 1.7035185375072197e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 1.5331666837564977e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 1.6592467433565705e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.0521154805634377e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 1.9400361844175264e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.491090448032473e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.2419814032292256e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.2971800130864863e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.533123165858814e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.2798108492729327e-09, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180. Loss: 2.0518297643456394e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 1.8466467879110755e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.407039813540983e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.656450530486179e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.290805477437561e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.961724929693805e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.7586846886348573e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.8553452052086424e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.569810684687778e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.7098125899637982e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.431963582877851e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.7406927603673754e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.4597557362410705e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.486309148054234e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 4.814057091199832e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 4.518915885900715e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 4.0670242973106435e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 5.05730448605301e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 4.5515740374477094e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 4.562077787783914e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 4.199002260915956e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.965366527542996e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.84822662496888e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.5565362143824245e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.294014844854615e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.0577456122795863e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.7519710510516277e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.7561706739221876e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.6668181103508343e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.400136299315751e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.3463871732050414e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.3911452060647204e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.245162937368681e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.020646643631813e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 1.8185819792686318e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 1.7298560332522014e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.6744567201049777e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.40701104809448e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.259442195195465e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.0334979756759185e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 1.8301481781083267e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 1.647133360297494e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 4.555778836156938e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 4.28646545636211e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 4.137215638701621e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.723494074831459e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.3511446673483133e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.202294693332117e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.8820652239989054e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.152652068732618e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.8373868618593564e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.6467804275838537e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.3821023848254683e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.2370243982533543e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.013321958428019e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 1.9982542664060826e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.2640899938464506e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.223945498282671e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.094683200364837e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 1.8852148803283532e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 8.122803525202133e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 7.496787665400555e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 7.678431029386769e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 7.283116867476441e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 6.647937432639229e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 5.983143689375307e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 5.384829320437776e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 4.846346388393999e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 4.361711749554599e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.9255405745991394e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.905515458167575e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.6080961642612505e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.2472865478351256e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.481351260185216e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.3194806268853295e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.732590268617812e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.3593312417560308e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 3.2096626102990627e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 2.8886963492691564e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 6.138845392453702e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 180. Loss: 5.524960853208332e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 5.158729271708365e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.642856344537529e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.457967438059499e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.105302946163981e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.998623456648676e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 5.523215587789467e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.97089402901052e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.473804626109468e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.026424163498521e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.623781747148669e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.4476680651524373e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.4754302440744643e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.127887219667018e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.815098497700316e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.7198531406489197e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.6585868183127817e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.5721248866616867e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.214912397995518e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.079685650914601e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.864849337733574e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.5783644039602164e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.4136602154746275e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.2654264458375976e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.0388838012538378e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 1.834995421128454e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 1.6514958790156087e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 1.4863462911140478e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 1.337711662002643e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 1.390204988521014e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 1.2511844896689126e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 1.219198292612454e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.7736573213022306e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.4962915891720076e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.3397946821652396e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.105815213948716e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.7334238320720913e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.460081448864882e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 5.287432115867587e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 5.41061452887598e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 5.148949803964105e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.634054823567695e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.263781593121358e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 5.141253972456788e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 5.3721863684499665e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.83496773160497e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.3514709584444734e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.916323862600026e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.6178237282504564e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.90796689120272e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.703434705903314e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 6.9652435919714625e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 6.5481159829545e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 5.89330438465905e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 5.397106198103578e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.85739557829322e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.464788272374331e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.018309445136898e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.616478500623208e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.720491893459706e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.348442704113735e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.1998629375232273e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.8798766437709048e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.591888979393814e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.984625617231742e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.686163055508568e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.4175467499577112e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.17579207496194e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.6101384920608973e-09, Train_acc 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181. Loss: 2.3491246428548078e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.114212178569327e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 1.995923212622827e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 1.7963308913605444e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 1.61669780222449e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 1.5481602739124738e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 1.3933442465212266e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 1.3471420737795366e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 1.3055601183120156e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 1.1750041064808141e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.223994054640738e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.801594649176665e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.4214351842589985e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.0792916658330986e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.8644947511602215e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.7643097687628343e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.487878791886551e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.3322231646083287e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.099000848147496e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.0998195774258168e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.789837619683235e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.6039861096253443e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.34358749866281e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.9474186218612496e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.652676759675125e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.480541335618045e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.3256194539666734e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.186189760480439e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.0607030363428277e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.344747431007839e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.010272687907055e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.8955099118349847e-09, Train_acc 1.0\n",
      "\n",
      "[Epoch 181 Batch 100] Loss: 2.699091172561919e-09 Training: accuracy=1.000000\n",
      "Epoch 181. Loss: 2.699091172561919e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.429182055305727e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.279396101685587e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.0514564915170283e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 1.8463108423653255e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 1.7548120100392257e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 1.6724630609457359e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 1.5052167548511623e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 1.3546950793660462e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 5.689562560899966e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 5.1206063048099695e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.6085456743289725e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.240823358806508e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.816741022925857e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.92518179656825e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.432663616911425e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.9893972552202825e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.9629865151355245e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.659820115532405e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.2938381039791644e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.709511998002263e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.338560798202037e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.0047047183818334e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.983630996723833e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.0577968380797994e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.7520171542718197e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.4768154388446376e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.5085306229358965e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.257677560642307e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.2181742972967114e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.1139431577450367e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.802548841970533e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.6154262096839126e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.6332803388957045e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.3699523050061343e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 5.206319794379761e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.685687814941785e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.310251285358039e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.996812447000232e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.776527930275932e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.298875137248338e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.427781035066029e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.078135183469859e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.763453917033306e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.573373029150841e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.216035726235757e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.3600933076931577e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.024083976923842e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.770582578850252e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 6.901225220624676e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 6.2111026985622085e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 5.589992428705988e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 5.2172576896562544e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 5.161193074771605e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.645073767294445e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.459963118540723e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.1070990585970834e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 5.186503851036669e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.667853465933003e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.573597060368052e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 5.699484132456406e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 5.1295357192107655e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.616582147289689e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.15492393256072e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.925696032023283e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.5331264288209547e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 3.272946037849292e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.9456514340643627e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.8373507833765617e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.926144690476176e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.6335302214285585e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.3701771992857028e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 2.1331594793571325e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 1.9198435314214194e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 1.7278591782792775e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 1.6482055123617825e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 1.4833849611256043e-09, Train_acc 1.0\n",
      "\n",
      "Epoch 181. Loss: 4.408405276902238e-09, Train_acc 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "smoothing_constant = .1\n",
    "metric = mx.metric.Accuracy()\n",
    "\n",
    "for e in range(epochs):\n",
    "    metric.reset()\n",
    "    for i, (d, l) in enumerate(train_data):\n",
    "        data = d.as_in_context(ctx)\n",
    "        label = l.as_in_context(ctx)\n",
    "        with autograd.record():\n",
    "            output = alex_net(data)\n",
    "            loss = softmax_cross_entropy(output, label)\n",
    "        \n",
    "        loss.backward()\n",
    "        trainer.step(data.shape[0])\n",
    "                \n",
    "        ##########################\n",
    "        #  Keep a moving average of the losses\n",
    "        ##########################\n",
    "        metric.update([label], [output])\n",
    "        curr_loss = nd.mean(loss).asscalar()\n",
    "        moving_loss = (curr_loss if ((i == 0) and (e == 0))\n",
    "                       else (1 - smoothing_constant) * moving_loss + (smoothing_constant) * curr_loss)\n",
    "\n",
    "        \n",
    "        if i % 100 == 0 and i > 0:\n",
    "                name, acc = metric.get()\n",
    "                print('[Epoch %d Batch %d] Loss: %s Training: %s=%f'%(e, i, moving_loss, name, acc))\n",
    "\n",
    "        _, train_accuracy = metric.get()\n",
    "        print(\"Epoch %s. Loss: %s, Train_acc %s\\n\" % (e, moving_loss, train_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
